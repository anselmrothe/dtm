UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Quantifying Text Difficulty with Automated Indices of Cohesion and Semantics
Permalink
https://escholarship.org/uc/item/62114025
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Duran, Nicholas D.
Bellissens, Cedrick
Taylor, Roger S.
et al.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                                            Quantifying Text Difficulty with
                                 Automated Indices of Cohesion and Semantics
                                          Nicholas D. Duran (nduran@memphis.edu)
                                         Cedrick Bellissens (cbellissens@memphis.edu)
                                            Roger S. Taylor (rstaylor@memphis.edu)
                                      Danielle S. McNamara (dsmcnamr@memphis.edu)
                                                       Institute for Intelligent Systems
                                                         Department of Psychology
                                                          202 Psychology Building
                                                         Memphis, TN 38152 USA
                              Abstract                                      expressed on a straightforward scale of 1-100 (higher scores
                                                                            indicating easier texts).
   We evaluated the effectiveness of new indices of text                       While readability formulas are easy to use, they lack the
   comprehension in measuring relative text difficulty.                     sophistication of current theories of cognition. Indeed,
   Specifically, we examined the efficacy of automated indices
                                                                            readability formulas have remained tied to superficial
   produced by the web-based computational tool Coh-Metrix.
   In an analysis of 60 instructional science texts, we divided             aspects of language, despite reading comprehension
   texts into groups that were considered to be more or less                research that has demonstrated that text difficulty is more
   difficult to comprehend. The defining criteria were based on             aptly gauged by deep-structure features related to text
   Coh-Metrix indices that measure independent factors                      cohesion and semantic information (Davison & Kantor,
   underlying text coherence: referential overlap and vocabulary            1982). Both cohesion and semantic features are important
   accessibility. In order to validate the text difficulty groups,          textual constructs that positively correlate with the
   participants read and recalled two “difficult” and two “easy”            psychological constructs of text coherence and difficulty
   texts that were similar in topic and length. Easier texts                (McNamara & Kintsch, 1996; Stahl et al., 1989). A cohesive
   facilitated faster reading times and better recall compared to
                                                                            text passage, for example, explicitly links linguistic
   difficult texts. We discuss the implications of these results in
   the context of theoretically motivated techniques for                    elements (e.g., constituents, propositions) that help readers
   improving textbook selection.                                            in generating inferences and bridge conceptual gaps, thereby
                                                                            improving text comprehension (McNamara, 2001).
   Keywords: text difficulty; readability; textbooks; natural               Additionally, the semantic information in a text (e.g.,
   language processing; Coh-Metrix; cohesion; semantics.                    ambiguity, word frequency) also facilitates comprehension
                                                                            by activating reader’s prior knowledge of the text topic
                         Introduction                                       (Graves et al., 1991).
For many students, learning largely depends on information                     The purpose of this study is to manipulate groups of
acquired from textbooks. Consequently, educators are often                  mutually exclusive features of cohesion and semantics to
faced with the daunting challenge of selecting texts that are               create an automated technique for identifying levels of text
at the appropriate level for their student’s learning ability. A            difficulty. We focus on factors of cohesion and semantics
text that is either too difficult or too easy can adversely                 that are hypothesized to underlie the difficulty of a text,
affect comprehension and hinder academic progress. The                      namely, referential overlap and vocabulary accessibility.
challenges of selecting appropriate texts are also                          (Freebody & Anderson, 1983; Stahl et al., 1989). The
compounded by the vast amount of material available to                      referential overlap factor of cohesion is an approximation of
educators, thus making a thorough assessment of each text                   conceptual redundancy that increases relatedness between
virtually impossible (Shnick, 2000). Fortunately, educators                 sentences. The presence of referential overlap is typically
have long had the assistance of standardized formulas that                  established by the repetition of lexical items, such as
assess the “readability” (or difficulty) level of instructional             pronouns, common nouns, and noun-phrases. Ideally, texts
texts (Hiebert, 2002). There are nearly 200 readability                     with high referential overlap allow readers to easily
formulas available, all of which track simple linguistic                    integrate content into a coherent mental representation
features that serve as proxies of syntactic and semantic                    (McNamara & Kintsch, 1996). As a result, an integrated
difficulty. One of the best-known readability formulas, the                 mental representation influences long-term retention and
Flesch-Kincaid Reading Ease formula (Klare, 1974, 1975),                    recall of the text (van Oostendorp et al., 1999).
provides a simple technique that is based on the average                       The vocabulary accessibility factor of semantic
number of syllables per text, as well as the average length of              information is the word-level information that varies in
all sentences. The result is a single index of difficulty,                  familiarity, ambiguity, and abstractness. These word
                                                                            characteristics are particularly important in influencing the
                                                                       233

activation of concepts from memory while reading (Paivio,          Argument overlap is a proportion of all sentence pairs that
1969). Accordingly, texts with high vocabulary accessibility       share one or more nouns with a common stem, whereas
are usually easier to process and understand because the text      stem overlap is the proportion of sentence pairs that share
vocabulary is easily retrievable and therefore more apparent       one or more words (of any grammatical category) with a
(Freebody & Anderson, 1983).                                       common stem.
   Both referential overlap and vocabulary accessibility have         Coh-Metrix also assesses the contextual similarity
been used extensively to improve the comprehensibility of          between sentences by adopting a computational model
instructional texts (e.g., Graves et al., 1991). By adding or      called Latent Semantic Analysis (LSA; Landauer &
deleting the corresponding linguistic features to a text,          Dumais, 1997). For LSA, similarity is defined as the
difficult and easy versions can be validated with human            likelihood that any group of words will occur in the same
comprehension norms. Unfortunately, these text revisions           context in the language environment. Contexts are derived
are usually time-consuming and require a great deal of             from a large corpus of texts, and each context can range
experimenter training. The additional constraints imposed          from the sentence, paragraph, or document level. LSA
by text revisions are particularly disadvantageous                 computes word meaning by populating a large word X
considering the popularity of readability formulas.                context co-occurrence matrix based on the number of times
Educators who use readability formulas may do so because           word Wi appears in context Cj. Words, now reinterpreted as
they prefer the practical advantage of quick and easy              vector representations, are projected into high-dimensional
techniques to evaluate text difficulty. However, these same        space and compared using the cosine between the vectors.
educators may risk an evaluation that is tangentially related         In this study, we used a combination of 30 LSA and
to factors underlying text coherence. In this study, we            overlap measures (as calculated by Coh-Metrix) to represent
attempt to balance the trade-off between established theory        the various aspects of referential overlap.
of text difficulty and automaticity of evaluation. In order to
do so, we take advantage of advances in computational              Indices of Vocabulary Accessibility Coh-Metrix computes
linguistics that reliably generate comprehensive profiles of       word-level information that varies on four conceptual
language and cohesion. At the forefront of the                     dimensions: meaningfulness, concreteness, imagability, and
computational techniques is a web-based software tool              familiarity. These indices are based on human ratings of
called Coh-Metrix (Graesser et al., 2004). Coh-Metrix is           over 150,000 words compiled in the MRC database
particularly useful as it provides a multivariate analysis of      (Coltheart, 1981). Coh-Metrix also assesses word properties
the linguistic features that index referential overlap and         that affect the accessibility of a word from memory, such as
vocabulary accessibility. Using a subset of these indices, we      abstractness and ambiguity. Coh-Metrix computes
attempt to uncover difficult and easy texts within a large         abstractness and ambiguity scores by incorporating a
corpus of naturalistic science texts.                              module based upon WordNet (Miller, 1995). WordNet is an
                                                                   online lexicon tool that groups words into sets of synonyms
Using Coh-Metrix                                                   that are connected by semantic relations. One such
Coh-Metrix harnesses sophisticated developments in                 relationship, the hypernym value, refers to the number of
computational linguistics and discourse processing,                levels a word has above it in a conceptual, taxonomic
featuring advanced syntactic parsers, part-of-speech taggers,      hierarchy. A low hypernym value is a proxy for word
distributional models, and psycholinguistic databases. These       abstractness because the word has few distinctive features.
modules are integrated into the automated Coh-Metrix tool          Ambiguity, on the other hand, is inferred by the number of
and used to generate over 400 indices of language, text, and       senses, or polysemy value, of a word. A polysemy value is
readability. Coh-Metrix has been involved in many research         simply a function of the number of synonym sets a word is
endeavors, ranging from learning assessment (Best et al.,          assigned to. Coh-Metrix translates the hypernym value, as
2005) to text classification (Louwerse et al., 2004). These        well as the polysemy value, into a mean composite score for
successful applications allow us to proceed with confidence        any text.
in our current analysis of using linguistic features in               In this study, we used a combination of 23 MRC database
identifying psychological differences of text difficulty.          and WordNet measures (as calculated by Coh-Metrix) to
   Two sets of Coh-Metrix indices were selected that capture       represent the various aspects of vocabulary accessibility.
the text difficulty dimensions of referential overlap and
vocabulary accessibility. A summary of the Coh-Metrix                                         Method
technique for computing these text difficulty variables is         The primary goal of this study was to provide a theoretically
provided in the following sections.                                grounded and automated technique that extends traditional
                                                                   metrics of text difficulty. In doing so, we also wanted to
Indices of Coreference Coh-Metrix tracks four major types          demonstrate that groups of more or less difficult texts could
of lexical co-reference: common noun overlap, pronoun              be identified without manipulating or revising texts. To this
overlap, argument overlap, and stem overlap. Common                end, it was necessary to establish groups of naturalistic text
noun and pronoun overlap is a proportion of all sentence           that were distinguishable only in terms of referential overlap
pairs that share one or more common nouns or pronouns.             and vocabulary accessibility. Using the Coh-Metrix indices
                                                               234

that measure our two factors of text difficulty, a corpus of        photosynthesis is not dependent on images or complex
science texts were categorized into groups considered to be         formula, thus satisfying criterion three. Lastly, meeting the
“difficult to understand” or “easy to understand”. We               fourth criterion required obtaining three specific textbook
hypothesized that the difficult texts would have lower scores       passages (one from junior high school, high school, and
in both referential overlap and vocabulary accessibility than       college textbooks) that were of the correct length (i.e., 400-
that of easy texts. To ensure that our groups of difficulty         500 words) while accurately presenting the complete set of
were truly different, we evaluated comprehension of the             concepts and principles contained in this topic.
texts by using sentence reading times and content recall.
Based on the goals of our study, the method section that            Data Reduction The large numbers of Coh-Metrix indices
follows is divided into two parts: (a) Creating Groups of           that measure referential overlap and vocabulary accessibility
Text Difficulty and (b) Validating Groups of Text                   were reduced to six indices, three for each group. Typically,
Difficulty.                                                         one would reduce a set of independent variables based on
                                                                    how well each independent variable differentiates the levels
Creating Groups of Text Difficulty                                  of a dependent variable (e.g., text difficulty). Because we do
Corpus Selection In order to provide a diverse source of            not have an a priori dependent variable, we used a Principle
expository science texts, we collected an initial corpus of         Components Analysis (PCA), with varimax rotation. A PCA
161 candidate texts, compiled from 23 different science             is appropriate for our purposes because it is a mathematical
textbooks. The textbooks were from three different levels -         technique that reduces a large number of observations (or
junior high school (6-8th grade), high school (9-12th grade),       indices) to N components. Each component is composed of
and college (introductory undergraduate courses).                   observations that capture as much of the information from
   We initially examined two science domains: physical              the original set of observations as possible. The final N
science and life science. Each domain consisted of 10               components are rank-ordered according to the total variance
subtopics that were specifically chosen to align with               explained. In turn, the observations in each component are
national science education standards (National Research             rank-ordered according to how well they load onto their
Council [NRC], 1996). For the physical science domain,              respective component.
there were 9 textbooks from 9 different publishers (2 junior           The PCA reduction for the 30 Coh-Metrix referential
high school textbooks, 2 high school textbooks, and 3               overlap indices and 26 Coh-Metrix vocabulary accessibility
undergraduate level textbooks). For the life science domain,        indices were conducted within the sample space of the 60-
there were 14 textbooks from 11 different publishers (2             text corpus. We maintained a 2:1 ratio of data points (i.e.,
junior high school textbooks, 7 high school textbooks – of          science texts) to observations (i.e., Coh-Metrix index
which four were from different publishers, and 5                    scores) in order to avoid spurious variance or “over-fitting”
undergraduate level textbooks).                                     of the data (Witten & Frank, 2005). Because the indices
   From this initial corpus of 161 candidate texts, a subset of     would eventually be used as classification variables in
60 texts was chosen. This subset consisted of 10 physical           distinguishing difficult and easy texts (see clustering
science subtopics and 10 life science subtopics selected            technique section below), we selected three of the most
from all three grade levels. This selection process was an          representative indices from the entirety of the referential
iterative process of seeking to satisfy multiple constraint         overlap indices, as well as three of the most representative
criteria. The first two criteria were concept-oriented while        indices from the entirety of the vocabulary accessibility
the last two were text-oriented. The concept-oriented               indices. In the PCA, an index is considered most
criteria were focused on higher level factors of the text           representative if it has the highest factor loading score in the
selection: (a) Maintaining topic alignment with national            principal component that accounts for the most overall
science education standards, and (b) Ensuring that the              unique variance.
subtopics were taught at three different education levels –            For referential overlap, the PCA generated four
junior high school, high school, and college. The text-             significant principal components, with the first component
oriented criteria were focused on lower level, pragmatic            explaining 68% of the overall variance. The three referential
constraints in text selection: (a) Excluding subtopics that         overlap indices selected were (a) unweighted proportional
were reliant on images or complex formula, and (b)                  score of content words across adjacent sentences, (b)
Obtaining text passages that were of approximately the              weighted proportional score of content words across two-
same length (400 – 500 words) that still formed complete            sentence windows, and (c) weighted proportional score of
conceptual units.                                                   content words across three-sentence windows. For
   For instance, “the biological cell” is one of the main life      vocabulary accessibility, the PCA generated six significant
science content standards. Within this content standard,            principal components, with the first component explaining
“photosynthesis” is an important subtopic; thus, it meets the       37% of the overall variance. The three vocabulary
first criteria for inclusion in the corpus. The subtopic of         accessibility indices selected were (a) average of content
photosynthesis is also covered in junior high, high school,         word concreteness, (b) average of all words concreteness
and college classes, satisfying the second criteria of being        and (c) average of content word imagability.
taught at three different educational levels. The subtopic of          For each respective group, we found the intercorrelations
                                                                235

between the three indices to be statistically significant. The      in the original 60-text corpus, four emerged that contained a
correlations between each group (taking the mean of each            difficult and easy text version. These topics fall under the
group) and the Flesh-Kincaid Reading Ease score were also           classification of Life Sciences, and describe the function of
significant. However, there was no significant correlation          (a) The Mammalian Eye, (b) The Biological Cell, (c)
when groups were compared to each other (see Table 1).              Photosynthesis, and (d) Chemistry of Life (e.g., proteins,
                                                                    carbohydrates, and lipids).
    Table 1. Pearson correlations between Flesch-Kincaid
    Readability Ease index, combined mean for referential           Experiment Procedure Participants were tested in small
  overlap, and combined mean for vocabulary accessibility.          groups of 2 to 4 participants. Prior to the experiment, the
                                                                    participants were informed that the goal of the study was to
   Indices of text difficulty          1        2        3          assess reading comprehension. As such, participants were
   1. Reading ease                     -      .54**    .32**        expected to read a short passage from a science textbook
                                                -      .01**        and recall everything they could after reading each passage.
   2. Referential overlap
                                                                    The texts were presented on a computer monitor, with only
   3. Vocabulary accessibility                           -
                                                                    a single sentence displayed on the monitor at any time.
 **Correlation significant at p < .001.                             Participants advanced at their own pace by pressing the
                                                                    spacebar on the keyboard, thereby removing the currently
Clustering Technique The PCA-selected Coh-Metrix                    displayed sentence and replacing it with the subsequent
indices of referential overlap and concept accessibility were       sentence. When the last sentence of the text had been read,
used in an unsupervised cluster analysis to identify groups         participants were automatically instructed via the computer
of text difficulty. A two-step clustering algorithm with the        to type their recall in a text box. The dependent variables of
Akaike Information Criterion (AIC) computed Euclidean               recall and reading time per sentence were recorded.
distances between data points in the 60-text corpus using the          Participants read four texts, one in each topic, and two at
referential overlap or concept accessibility scores. Within         each level of text difficulty. We combined two
each of these groups, the algorithm converged on two                counterbalancing methods to control for topic at each level
distinct text clusters by partitioning the variance so as to        of text difficulty. First, the order of topic presentation was
maximize the within-cluster variation and minimize the              counterbalanced by a four-order Latin square. Next, the
between-cluster variation (Kaufman & Rousseeuw, 1990).              order of text difficulty was counterbalanced by blocked
In order to classify the emergent text clusters as containing       randomization, resulting in six possible orders. Finally, the
“difficult to understand” or “easy to understand” texts (per        six blocked orders were mapped onto each row of the Latin
referential overlap and vocabulary accessibility scores), we        square, thus resulting in 24 unique orders of topic combined
took the mean differences of the combined indices in each           with difficulty.
group as a defining criterion. As such, a text was considered
difficult if it had been assigned to clusters with the lowest       Scoring Procedure To score the free recall protocols, each
mean scores for referential overlap and vocabulary                  sentence was divided into idea units by the Conceptual Unit
accessibility. Conversely, a text was considered easy if it         Tagger, a web-based software developed at the University
had been assigned to clusters with the highest mean scores          of Memphis (for additional information, visit
for both referential overlap and vocabulary accessibility.          http://141.225.14.229/cut/webform1.aspx).         This     tool
   For the referential overlap clusters, the cluster with the       systematically isolates idea units by analyzing the structural
highest Coh-Metrix mean score was 0.217, whereas the                representation of a sentence in a syntactic parse tree. The
cluster with the lowest Coh-Metrix mean score was 0.122.            syntactic tree, composed of an underlying formal grammar,
For the vocabulary accessibility clusters, the cluster with the     is generated using the Charniak (1997) parser. The root of
highest Coh-Metrix mean score was 0.416, whereas the                the tree (i.e., the sentence under analysis) is separated into
cluster with the lowest Coh-Metrix mean score was 0.323.            intermediate branches that specify nodes that include noun
In the end, we selected 4 topics for which we could obtain 4        phrases (NP), verb phrases (VB), prepositional phrases (PP),
difficult and 4 easy texts.                                         and embedded sentence constituents. The tool selects a node
                                                                    as a single coherent concept if it adheres to simple
Validating Groups of Text Difficulty                                guidelines, such as containing a finite verb with related
Participants Twenty-four undergraduates enrolled in an              arguments (e.g., dependent and independent clausal phrases)
introductory psychology course participated for course              or a prepositional phrase that contains a gerund. For
credit.                                                             example, here are two sentences (1) The phase of a
                                                                    substance can be changed | by adding or removing heat and
Materials The materials consisted of eight texts that were          (2) It is not affected | in reproducing for the rest of it’s
classified as either difficult or easy in terms of the selected     lifespan. Based upon the preceding guidelines each sentence
Coh-Metrix indices of referential overlap and vocabulary            would each be identified as having two distinct idea units
accessibility. Topic was also held constant between levels of       (delineated by the “|” symbol).
difficulty to ensure that comprehension differences were not
confounded with topic. Of the 20 topics that were involved
                                                                236

                            Results                                  the normalized reading time scores for the easy texts. We
                                                                     used a one-way within-subjects ANOVA to determine if
Free Recall                                                          differences between levels of text difficulty were
The mean number of idea units recalled for the difficult             significant.
texts was compared with the mean number of idea units
recalled for the easy texts. We conducted a one-way within-                Table 3. Reading times for difficult and easy texts
subject ANOVA to evaluate the differences in idea units                 normalized by character, syllable, word, and idea units.
recalled. There was a significant effect for type of text
(difficult vs. easy), F(1,22) = 24.59, p < .001, η² = .528.                                        Level of text difficulty
Participants recalled more from the easy texts than from the                                 Easy texts           Difficult texts
difficult texts (see Table 2).                                        Reading time:
                                                                                             Mean(SD)               Mean(SD)
   In addition to number of idea units recalled, we also
                                                                      by character          61.84 (3.41)           68.74 (5.40)
computed the number of words recalled (see Table 2). A
one-way within-subject ANOVA demonstrated a significant               by syllable          230.93 (12.15)         247.48 (19.62)
effect for type of text (difficult vs. easy), F(1,22) = 41.80, p      by word              363.23 (19.74)         426.63 (34.25
< .001, η² = .655. Again, participants recalled more from the         by idea units       3113.67 (162.62)      4014.96 (320.40)
easy texts than from the difficult texts.
  The last analysis involved the qualitative differences of             There was a statistically significant effect when reading
recall for difficult and easy texts. We used LSA to assess the       times were normalized by number of characters, F(1,23) =
contextual similarity between the free recall and the text           4.25, p < .05, η² = .162, number of words F(1,23) = 8.09, p
from which the free recall was generated. We used the                < .01, η² = .269, and number of idea units F(1,23) = 18.58, p
TASA (general college) semantic space and “document x                < .01, η² = .458. Overall, these results suggest that
document” comparison metric. The LSA cosine scores for               participants spend more time (per sentence) reading the
each of the four texts (2 difficult and 2 easy) that the             difficult texts (see Table 3). It should also be noted that the
participants read and recalled were submitted to a one-way           normalization by syllables was not significant. However,
within-subjects ANOVA. There was a significant effect for            there was a trend of slower reading time when processing
type of text (difficult vs. easy), F(1,22) = 13.19, p < .001, η²     the difficult texts.
= .528. Participant’s recall was more contextually similar to
the text for the easy texts than for the difficult texts (see                                 Discussion
Table 2).
                                                                     In this study, we addressed a challenge faced by many
                                                                     educators: Given a diverse set of instructional texts, how is
 Table 2: Recall based on number of words, number of idea
                                                                     text difficulty established? Using Coh-Metrix, a
        units, and LSA scores between text and recall.
                                                                     computational language processing tool, we demonstrated
                                                                     that two independent factors of cohesion and semantics
                                  Level of text difficulty           could uncover divergent groups of text difficulty in a large
                               Easy texts      Difficult texts       corpus. Specifically, a subset of three indices for referential
  Unit of analysis
                               Mean(SD)          Mean(SD)            overlap (a factor of cohesion) and a subset of three indices
  Number of idea units        12.09(4.55)         8.37(2.92)         for vocabulary accessibility (a factor of semantics) were
  Number of words             87.67(31.62)      57.00(20.59          used in identifying texts that were difficult or easy to
  LSA                          0.78(0.07)         0.69(0.11)         understand. Texts that had high scores in referential overlap
                                                                     and vocabulary accessibility (i.e., easy texts) were read
Reading Times                                                        faster and recalled better than texts with low scores in
                                                                     referential overlap and vocabulary accessibility (i.e.,
The reading times for each sentence were recorded for the
                                                                     difficult texts). Our results contribute to a large body of
difficult and easy texts. Before analyzing the data, it was
                                                                     reading comprehension research that makes use of text-level
necessary to normalize each sentence for differences in
                                                                     features to vary text coherence. However, where previous
length. Four techniques were used: (a) reading time divided
                                                                     research varied coherence by hand, we used an automated
by number of characters, (b) reading time divided by
                                                                     technique that allows natural differences between texts to
number of syllables, (c) reading time divided by number of
                                                                     emerge.
words, and (c) reading time divided by number of idea units.
                                                                        Our technique also has many of the advantages of
After normalizing for length, we also removed reading
                                                                     traditional readability formulas. For example, the Flesch-
times that were possible outliers for each participant. A
                                                                     Kincaid Reading Ease (FKRE) formula is widely used by
reading time was excluded if the time was two standard
                                                                     educators because of its proven effectiveness in identifying
deviations above or below the mean of reading time for all
                                                                     text difficulty. As reported earlier, the correlations between
sentences. Across all participants, we removed 1.36% of the
                                                                     Coh-Metrix indices and FKRE scores are statistically
reading times per character, 2.00% per syllable, 1.80% per
                                                                     significant, thus suggesting the two techniques are on par
word, and 1.12% per idea unit. The remaining normalized
                                                                     with each other. In similar fashion, the Coh-Metrix indices
reading times for the difficult texts were compared against
                                                                 237

and FKRE scores also provide text assessments that are             Graesser, A. C., McNamara, D. S., Louwerse, M. M., &
reliable and automatic.                                              Cai, Z. (2004). Coh-Metrix: Analysis of text on cohesion
   There are also notable discrepancies between the                  and language. Behavior Research Methods, Instruments,
techniques that may favor one technique over the other. For          and Computers, 36, 193-202.
example, educators and researchers can use Coh-Metrix to           Graves, M. F., Prenn, M. C., Earle, J., Thompson, M.,
identify texts that vary along two independent dimensions of         Johnson, V., & Slater, W. H. (1991). Improving
coherence (e.g., cohesion and semantic information).                 instructional texts: Some lessons learned. Reading
Moreover, future research will provide educators and                 Research Quarterly, 26, 110-122.
researchers additional options by incorporating Coh-Metrix         Hiebert, E. H. (2002). Standards, assessment, and text
indices of temporal/causal, anaphor resolution, and syntactic        difficulty. In A. E. Farstrup & S. J. Samuels (Eds.). What
complexity. The FKRE formula, in contrast, does not allow            research has to say about reading comprehension (3rd
such an in depth analysis because the scores are based on            Ed.). Newark, DE: International Reading Association.
shallow linguistic features that converge on a generalized         Kaufman, L., & Rousseeuw, P. J. (1990). Finding groups in
index of difficulty.                                                 data: An introduction to cluster analysis NY: John Wiley
   A possible advantage for the FKRE formula, however, is            & Sons.
the ability to identify texts on an absolute scale. At this        Klare, G. R. (1974-1975). Assessing readability. Reading
point, the technique used in this study is based on relative         Research Quarterly, 10, 62-102.
text difficulty. Further analyses are required to determine if     Landauer, T. K., & Dumais, S. T. (1997). A solution to
the difficulty thresholds reported here are reflections of the       Plato's problem: The latent semantic analysis theory of
true population (i.e., junior high, high school, and college         the acquisition, induction, and representation of
level instructional texts). If so, identifying text difficulty       knowledge. Psychological Review, 104, 211-240.
will not necessitate a cluster-like analysis for each              Louwerse, M.M., McCarthy, P. M., McNamara, D. S., &
evaluation.                                                          Graesser, A. C. (2004). Variation in language and
   While much work remains to be done, this initial                  cohesion across written and spoken registers. In K.
investigation contributes to the field by demonstrating that         Forbus, D. Gentner, & T. Regier (Eds.), Proceedings of
Coh-Metrix derived indices accurately identify texts that            the 26th Annual Meeting of the Cognitive Science Society
have unique influences on human comprehension. In doing              (pp. 843-848). Mahwah, NJ: Erlbaum.
so, we hope to provide educators a simple and theoretically        Miller, J. R., & Kintsch, W. (1980). Readability and recall
grounded technique to select appropriate texts that match            of short prose passages: A theoretical analysis. Journal of
their students’ individual reading abilities.                        Experimental Psychology: Human Learning and Memory,
                                                                     6, 335-354.
                    Acknowledgements                               McNamara, D. S. (2001). Reading both high and low
The research was supported by the Institute for Educational          coherence texts: Effects of text sequence and prior
Sciences (IES R305G020018-02, IES R3056040046). Any                  knowledge. Canadian Journal of Experimental
opinions, findings, and conclusions or recommendations               Psychology, 55, 51-62.
expressed in this material are those of the authors and do not     McNamara, D. S., & Kintsch, W. (1996). Learning from
necessarily reflect the views of the IES.                            text: Effects of prior knowledge and text coherence.
                                                                     Discourse Processes, 22, 247-288.
                         References                                National Research Council (NRC). (1996). National science
                                                                     education standards. Washington, DC: National
Best, R. M., Rowe, M., Ozuru, Y., & McNamara, D. S.                  Academy Press.
   (2005). Deep-level comprehension of science texts: The          Paivio, A (1969). Mental Imagery in associative learning
   role of the reader and the text. Topics in Language               and memory. Psychological Review, 76, 241-263.
   Disorders, 25, 65-83.                                           Stahl, S. A., Jacobson, M. G., Davis, C. E., & Davis, R. L.
Charniak, E. (1997). Statistical techniques for natural              (1989). Prior knowledge and difficult vocabulary in the
   language processing. AI Magazine, 18, 33-44.                      comprehension of unfamiliar texts. Reading Research
Coltheart, M. (1981). The MRC psycholinguistics database.            Quarterly, 24, 27-43.
   Quarterly Journal of Experimental Psychology, 33A, 497-         Schnick, T. (2000). The Lexile framework: An introduction
   505.                                                              for educators. New York, NY: MetaMetrics.
Davison, A., & Kantor, R. N. (1982). On the failure of             van Oostendorp, H., & Goldman, S. R. (Eds.). (1999). The
   readability formulas to define readable texts: A case study       construction of mental representations during reading.
   from adaptations. Reading Research Quarterly, 17, 187-            Mahwah, NJ: Lawrence Erlbaum Associates, Inc.
   209.                                                            Witten, I. H., & Frank, E. (2005). Data mining: Practical
Freebody, P., & Anderson, R. C. (1983). Effects of                   machine learning tools and techniques. San Francisco,
   vocabulary difficulty, text cohesion, and schema                  CA: Morgan Kaufmann Publishers.
   activation on reading comprehension. Reading Research
   Quarterly, 18, 277-294.
                                                               238

