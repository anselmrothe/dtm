UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cognitive Components of Speech at Different Time Scales
Permalink
https://escholarship.org/uc/item/63p8302r
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Feng, Ling
Hansen, Lars Kai
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                       Cognitive Components of Speech at Different Time Scales
                                                        Ling Feng (lf@imm.dtu.dk)
                                                    Informatics and Mathematical Modelling
                                                        Technical University of Denmark
                                                           2800 Kgs. Lyngby, Denmark
                                                   Lars Kai Hansen (lkh@imm.dtu.dk)
                                                    Informatics and Mathematical Modelling
                                                        Technical University of Denmark
                                                           2800 Kgs. Lyngby, Denmark
                               Abstract                                   statistics. This has been demonstrated by a variety of inde-
                                                                          pendent component analysis (ICA) algorithms, whose rep-
    Cognitive component analysis (COCA) is defined as unsu-               resentations closely resemble those found in natural percep-
    pervised grouping of data leading to a group structure well-
    aligned with that resulting from human cognitive activity. We         tual systems. Examples are, e.g., visual features (Bell & Se-
    focus here on speech at different time scales looking for pos-        jnowski, 1997; Hoyer & Hyvrinen, 2000), and sound features
    sible hidden â€˜cognitive structureâ€™. Statistical regularities have     (Lewicki, 2002).
    earlier been revealed at multiple time scales corresponding to:
    phoneme, gender, height and speaker identity. We here show               Within an attempt to generalize these findings to higher
    that the same simple unsupervised learning algorithm can de-          cognitive functions we proposed and tested the independent
    tect these cues. Our basic features are 25-dimensional short-         cognitive component hypothesis, which basically asks the
    time Mel-frequency weighted cepstral coefficients, assumed to
    model the basic representation of the human auditory system.          question: Do humans also use information theoretically opti-
    The basic features are aggregated in time to obtain features at       mal ICA methods in more generic and abstract data analysis?
    longer time scales. Simple energy based filtering is used to          Cognitive component analysis (COCA) is thus simply defined
    achieve a sparse representation. Our hypothesis is now basi-
    cally ecological: We hypothesize that features that are essen-        as the process of unsupervised grouping of abstract data such
    tially independent in a reasonable ensemble can be efficiently        that the ensuing group structure is well-aligned with that re-
    coded using a sparse independent component representation.            sulting from human cognitive activity (Hansen, Ahrendt, &
    The representations are indeed shown to be very similar be-
    tween supervised learning (invoking cognitive activity) and un-       Larsen, 2005). For the preliminary research on COCA, hu-
    supervised learning (statistical regularities), hence lending ad-     man cognitive activity is restricted to the human labels in su-
    ditional support to our cognitive component hypothesis.               pervised learning methods. This interpretation is not compre-
    Keywords: Cognitive component analysis; time scales; en-              hensive, however it is capable of representing some intrinsic
    ergy based sparsification; statistical regularity; unsupervised       mechanism of human cognition. Further more, COCA is not
    learning; supervised learning.
                                                                          limited to one specific technique, but rather a conglomerate
                                                                          of different techniques. We envision that efficient representa-
                           Introduction                                   tions of high level processes are based on sparse distributed
The evolution of human cognition is an on-going interplay                 codes and approximate independence, similar to what has
between statistical properties of the ecology, the process of             been found for more basic perceptual processes. As men-
natural selection, and learning. Robust statistical regularities          tioned, independence can dramatically reduce the perception-
will be exploited by an evolutionary optimized brain (Barlow,             to-action mappings by using factorial codes rather than com-
1989). Statistical independence may be one such regularity,               plex codes based on the full joint distribution. Hence, it is a
which would allow the system to take advantage of factorial               natural starting point to look for high-level statistically inde-
codes of much lower complexity than those pertinent to the                pendent features when aiming at high-level representations.
full joint distribution. In (Wagensberg, 2000), the success of            In this paper we focus on cognitive processes in digital speech
given â€˜life formsâ€™ is linked to their ability to recognize in-            signals. The paper is organized as follows: First we discuss
dependence between predictable and un-predictable process                 the specifics of the cognitive component hypothesis in rela-
in a given niche. This represents a precision of the classical            tion to speech, then we describe our specific methods, present
Darwinian paradigm by arguing that natural selection sim-                 results obtained for the TIMIT database, and finally, we con-
ply favors innovations which increase the independence of                 clude and draw some perspectives.
the agent and un-predictable processes. The agent can be an
individual or a group. The resulting human cognitive sys-                             Cognitive Component Analysis
tem can model complex multi-agent scenery, and use a broad                In sensory coding it is proposed that visual system is near
spectrum of cues for analyzing perceptual input and for iden-             to optimal in representing natural scenes by invoking â€˜sparse
tification of individual signal producing processes.                      distributedâ€™ coding (Field, 1994). The sparse signal consists
    The optimized representations for low level perception are            of relatively few large magnitude samples in a background
indeed based on independence in relevant natural ensemble                 of numbers of small signals. When mixing such indepen-
                                                                      983

                  60
                                                                                                                   Speech signal                                                          Principal
                                                                                                                                    Fe a ture         Fe ature        Energy Based
                                                                                                                                                                                         Component
                                                                                                                                   Extraction       Integration       Sparsification
                                                                                                                                                                                          Analysis
                  40
                                                                                                                                                  25 MFCCs with
                                                                                                                                                                     retains ?% energy
                                                                                                                                                20ms & 50% overlap
                  20
             x
              2
                   0                                                                                              Figure 2: Preprocessing pipeline for speech COCA. MFCCs
                                                                                                                  are extracted at the basic time scale (20ms). According to
                 âˆ’20
                                                                                                                  applications, features are averaged/stacked into longer time
                                                                                                                  scales. Energy based sparsification is followed as a method
                 âˆ’40
                                                                                                                  to reduce intrinsic noise. PCA on sparsified features projects
                 âˆ’60
                                                                                                                  on a relevant subspace that makes it possible to visualize the
                  âˆ’100            âˆ’50                    0           50                  100          150
                                                             x
                                                              1
                                                                                                                  â€˜rayâ€™-structure. A subsequent ICA can be used to identify the
                  15
                                                                                                                  actual ray coordinates and source signals.
                  10
                                                                                                                  (Hansen et al., 2005; Hansen & Feng, 2006). Within so-
                   5
                                                                                                                  called bag-of-words representations of text, COCA is a gen-
              2
                                                                                                                  eralization of principal component analysis based â€˜latent se-
             x     0
                                                                                                                  mantic analysisâ€™ (LSA), originally developed for information
                  âˆ’5
                                                                                                                  retrieval on text (Deerwester, Dumais, Furnas, Landauer, &
                                                                                                                  Harshman, 1990). The key observation is that by using ICA,
                 âˆ’10                                                                                              rather than PCA, we are not restricted to orthogonal basis
                                                                                                                  vectors. Hence, in ICA based latent semantic analysis topic
                 âˆ’15
                  âˆ’20       âˆ’15         âˆ’10         âˆ’5        0           5         10         15      20         vocabularies can have large overlaps. We envision that these
                                                             x
                  4
                                                                 1
                                                                                                                  implemented by overlapping receptive fields can detect more
                                                                                                                  subtle differences than â€˜orthogonalâ€™ receptive fields.
                 3.5
                                                                                                                     Here we are going to elaborate on our earlier findings re-
                  3                                                                                               lated to speech. The basic preprocessing pipeline for COCA
                 2.5
                                                                                                                  of speech is shown in Figure 2. First, basic features are ex-
                                                                                                                  tracted from a digital speech signal leading to a fundamental
             x2   2
                                                                                                                  representation that shares two basic aspects with the human
                 1.5                                                                                              auditory system: A logarithmic dependence on signal power
                  1
                                                                                                                  and a simple bandwidth-to-center frequency scaling so that
                                                                                                                  our frequency resolution is better at lower frequencies. These
                                                                                                                  so-called mel-frequency cepstral coefficients1 (MFCC) fea-
                 0.5
                  0
                       0   0.5     1          1.5        2   2.5     3        3.5         4     4.5    5          tures are next aggregated in time. Simple energy based filter-
                                                             x
                                                                 1                                                ing leads to sparse representations. Sparsification is regarded
                                                                                                                  as a simple means to emulate a saliency based attention pro-
Figure 1: Prototypical feature distributions produced by a lin-                                                   cess.
ear mixture, based on sparse (top), normal (middle), or dense                                                        We have earlier reported our preliminary findings of ICA
source signals (bottom), respectively. The characteristics of                                                     ray structure related to phonemes and speaker identity in a rel-
a sparse signal is that it consists of relatively few large mag-                                                  atively small database (Feng & Hansen, 2005, 2006). Figure
nitude samples on a background of weak signals, hence, pro-                                                       3 illustrates the phoneme relevant ray structure at the basic
duces a characteristic ray structure in which the ray is defined                                                  time scale. This analysis was carried out on four simple utter-
by the vector of linear mixing coefficients: One for each for a                                                   ances: â€˜sâ€™, â€˜oâ€™, â€˜fâ€™ and â€˜aâ€™. As shown in the figure, cognitive
sparse source.                                                                                                    components of /e/ phoneme opening â€˜sâ€™ and â€˜fâ€™ are identified.
                                                                                                                     We speculate that these phoneme-relevant cognitive com-
                                                                                                                  ponents contribute towards the well-known basic invariant
dent sparse signals in a simple linear mixing process, we ob-                                                     â€˜cueâ€™ characteristics of speech (Blumstein & Stevens, 1979).
tain the â€˜ray structureâ€™ which we consider emblematic for our                                                     The theory of acoustic invariants points out that the perceived
approach, see the top panel in Figure 1. If a signal repre-                                                       signals are derived as stable phonetic features despite of the
sentation exists with a ray structure ICA can be used to re-                                                      different acoustic properties produced by different speakers.
cover both the line directions (mixing coefficients) and the                                                      Moreover Damper has shown that although the speech signal
original independent sources signals. Thus, we used ICA to                                                        may vary due to coarticulation, the relation between key fea-
model the ray structure and represent semantic structure in                                                           1 For a complete description of MFCC and related cepstral coef-
text, social networks, and other abstract data such as music                                                      ficients, see (Deller, Hansen, & Proakis, 2000).
                                                                                                            984

                                                                                                                                         s
                                                           o
                                                                                                     SPARSIFIED FEATURES: |z| > 1.7
                                             0.3
                                                                                                                o
                                                                                                               o                                                                                                              s    s
                                                                                                                       ss
                                             0.2                                                            o
                                                                                                               s sffsf
                                                                                                              so  f
                                                                                                                                                                                                                                         ss ss
                                                                                                                                                                                                                                               sss
                                              o                    aa                        s              ss s
                                                                      aaaaaa aa              s
                                                                           aaaaa                                             ss
                                                                               aa
                                             0.1                                                                            s
                                                                                                                                                                                           s
                                                                                                oo                                                                                                   s
                                                                                              oo
                                                                                              o
                                                                                             ao
                                                                                         a
                                                  0                                      f
                                                                                              faso
                                                                                                                            ff fffffff
                                                                                             s
                                                                                                     o                      ss
                                            f f                                                                                                                            a
                                           âˆ’0.1 fff                                 o                                                                                             a
                                  PC 2
                                                                                                 o
                                                                                                 o  o
                                                                                                 oo                                                         fsssssfss
                                                                             oo oo               o
                                                                            o oo
                                                                                                 o
                                                                                                 o
                                                                                                 o
                                                                                                    oo                                                               fssfssf
                                                                                                                                                                             ssfsfss             sssssss                  a aa a a
                                                                          ooo o                  o oo
                                                                                                 o   o                                                                            ssfs
                                                                                                                                                                                                                                 aa
                                           âˆ’0.2                          oo o                        oo
                                                                                                                                                          f
                                                                        oo o
                                                                                                  oo
                                                                                                  o                                                                                              a           a
                                                                                                                                                                                                         a
                                                                                                                                                                                                                 a
                                                                                                                                                                                                                     sa
                                                                                    o
                                           âˆ’0.3                    oo
                                                                                    o
                                                                                                                                                                   
                                                                                                                                                                                                                          a
                                                                                                                                                                                                                                  a s   
                                                                  oo                oo
                                                                oo                                                                           f
                                                                                                                                                 f
                                                                                                                                          ff ff                                                                                                           ZOOM-IN
                                      aa   âˆ’0.4                                                             f
                                                                                                          o s ss s s s s s ss
                                                                                                                              s
                                                                                                          oo                             f s
                                                                                                                                                      s          fs
                                                                                                                                                                                      s fs s s
                                           âˆ’0.5                                                                                                                                                                  f
                                                                                                                                                                                                                              sss f
                                                                                                                                                                                                                                             s s
                                                                                                                                                                                                                                                        fs fs s
                                                                                                                                                                                                                                                                  sf s   s
                                           âˆ’0.6
                                  s                       ss
                                                      s
                                                               âˆ’0.2                          0                          0.2                          0.4                                 0.6                         0.8                           1               1.2 f
                                                                                                                                                       PC1
                                                                                                                                                                                                                                                                             f
Figure 3: The latent space is formed by the two first principal components of data consisting of four separate utterances
representing the sounds â€˜sâ€™, â€˜oâ€™, â€˜fâ€™, â€˜aâ€™. The structure clearly shows the sparse component mixture, with â€˜raysâ€™ emanating from
the origin (0,0). The ray embraced in a rectangle contains a mixture of â€˜sâ€™ and â€˜fâ€™ features, a cognitive component associated
with the vowel /e/ sound.
tures follows a consistent and invariant form (Damper, 1998).
Experiments involving labels related to speaker identification
also provided the signature of linear â€˜rayâ€™-structures. Is lin-
earity related to perceptually distinguishable categories? The
discussion on linear correlations in the speech signal and lo-
cus equation is still on-going (Sussman, Fruchter, Hillbert, &                                                                                                                                                                            â€¦                                      â€¦          â€¦
Sirosh, 1998).                                                                                                                                                                                                                                          10-40ms                                       10-40ms
   During the itinerary of searching for spoken cognitive com-
ponents, we have thus already reported (Feng & Hansen,
2005, 2006) on generalizable phoneme relevant components                                                                                                                                                                                                 Feature
                                                                                                                                                                                                                                                                                      25*N -by- 1
at a time scale of 20 âˆ¼ 40ms, and generalizable speaker spe-                                                                                                                                                                                 .
                                                                                                                                                                                                                                                        Extraction
                                                                                                                                                                                                                                                                                     Feature Matrix
                                                                                                                                                                                                                                             .
cific components at an intermediate time scale of 1000ms.                                                                                                                                                                                    .
   In this paper we will further expand on our findings in                                                                                                                                                                                             25-by-1
                                                                                                                                                                                                                                                        MFCC
speech by applying COCA on speech features at various time
scales. We will systematically investigate the performance of
unsupervised and supervised learning and test whether the                                                                                                                                                    Figure 4: Speech feature extraction and stacking
tasks are learned in equivalent representations, hence, in-
dicating consistency of statistical regularities (unsupervised
                                                                                                                                                                     2. Apply hamming window on each frame;
learning) and human cognitive processes (supervised learn-
ing of human labels).                                                                                                                                                3. Extract MFCCs from each windowed frame, which forms
                                                                                                                                                                        a 25-dimensional vector;
                         Methods                                                                                                                                     4. According to the time scale, N original 25-dimensional
Our speech analysis follows the basic preprocessing scheme                                                                                                              MFCCs are stacked into one 25 âˆ— N-dimensional vector;
shown in Figure 2.                                                                                                                                                   5. Repeat 4 until all the frames are stacked.
Feature Stacking                                                                                                                                                         25 âˆ— N dimensional features representing long time scales are
Since speech signals are non-stationary features have to be                                                                                                              then used in both supervised and unsupervised learning meth-
extracted from short-time scales. A simple method to get fea-                                                                                                            ods.
tures at longer time scales is stacking or vector â€˜concatena-
                                                                                                                                                                         Mixture of Factor Analyzers
tionâ€™ of signals. Figure 4 illustrates the stacking procedure
used in our experiments.                                                                                                                                                 To test whether supervised and unsupervised learning lead to
                                                                                                                                                                         similar representations we need a model that can incorporate
1. Truncate speech signal into overlapped frames, 20ms long                                                                                                              both. In particular we need a generative representation to al-
   with 50% overlap;                                                                                                                                                     low unsupervised learning, and we want the representation to
                                                                                                                                                     985

allow sparse linear ray like features. This can be achieved          we clamp the mixture density model and train only the cluster
in a simple generalization of so-called mixture of factor an-        tables p(y|i), i = 1, ..., K, using the training set labels. This
alyzers (MFA). The unsupervised version is inspired by the           is also referred to as unsupervised-then-supervised learning.
so-called Soft-LOST (Line Orientation Separation Technique)          This is a simple protocol for checking the cognitive consis-
(Oâ€™Grady & Pearlmutter, 2004).                                       tency: Do we find the same representations when we train
   Factor analysis is one of the basic dimensionality reduc-         them with and without using â€˜human cognitive labelsâ€™.
tion forms. It models the covariance structure of multi-
dimensional data by expressing the correlations in lower di-                                      Results
mensional latent subspace, mathematical expression is
                                                                     In this section we will present experimental results of analysis
                           x = Î›z + u,                       (1)     on speech signals gathered from TIMIT database (Garofolo et
                                                                     al., 1993). TIMIT is a reading speech corpus designed for the
where x is the p-dimensional observation; Î› is the factor            acquisition of acoustic-phonetic knowledge and for automatic
loading matrix; z is the k-dimensional hidden factor vector          speech recognition systems. It contains a total of 6300 sen-
which is assumed Gaussian distributed, N (z|0, I); u is the          tences, 10 sentences spoken by each of 630 speakers from the
independent noise which is N (u|0, Î¨), with a diagonal ma-           United States. For each utterance we have several labels that
trix Î¨. Given eq. (1), observations are also distributed as          we think as cognitive indicators, labels that humans can infer
N (x|0, Î£), with Î£ = Î›Î›T + Î¨. Factor analysis aims at es-            given sufficient among of data. While each sentence lasts ap-
timating Î› and Î¨ in order to give a good approximation of            proximately 3s we will investigate performance at time scales
covariance structure of x.                                           ranging from basic 20ms to long about 1000ms. The cognitive
   While the simple factor analysis model is globally linear         labels we will focus on here are phonemes, gender, height and
and Gaussian, we can model non-linear non-Gaussian pro-              speaker identity. Training and test sets are recommended in
cesses by invoking a so-called mixture of factor analyzers           TIMIT, which contain 462 speakers reading for training and
                       K  Z                                          168 for test. The total speech covers 59 phonemes, and the
              p(x) = âˆ‘       p(x|i, z)p(z|i)p(i)dz,          (2)     heights from all speakers range from 4â€² 9â€²â€² to 6â€² 8â€²â€² , and have to-
                      i=1                                            tally 22 different values. In order to gather sufficient amount
                                                                     of speech signals we chose 46 speakers with equal gender dis-
where p(i) are mixing proportions and K is the number of fac-
                                                                     tribution, and speech signals cover all 59 phonemes, and all
tor analyzers. MFA combines factor analysis and the Gaus-
                                                                     22 heights.
sian mixture model, and hence can simultaneously perform
                                                                        Following the preprocessing pipeline, we first extracted
clustering, and dimensionality reduction within each cluster,
                                                                     25-dimensional MFCCs from original digital speech signals.
see (Ghahramani & Hinton, 1996) for a detailed review.
                                                                     To investigate various time scales, we stacked basic features
   To meet our request for unsupervised learning model, MFA
                                                                     into a variety of time scales, from the basic 20ms scale up to
is modified to form an ICA-like line based density model sim-
                                                                     1100ms. Energy based sparsification was used afterwards as
ilar to Soft-LOST by reducing the factor loadings to hold a
                                                                     a means to reduce the intrinsic noise and to obtain sparse sig-
single column vector, i.e., the â€˜rayâ€™ vector. It uses an EM
                                                                     nals. Sparsification is done by thresholding the amplitude of
procedure to identify orientations within a scatter plot: in the
                                                                     stacked MFCC coefficients, and only coefficients with super
E-step, all observations are soft assigned into K clusters de-
                                                                     threshold energy were retained. By adjusting the threshold,
pending on the number of mixtures, which is represented by
                                                                     we examine the role of sparsification in our experiments. We
orientation vectors vi , then it calculates posterior probabili-
                                                                     changed the threshold leading to a retained energy from 100%
ties assigning data points to lines; and in M-step, covariance
                                                                     to 41%. Unsupervised and supervised modes of MFA were
matrices are calculated for K clusters, and the principal eigen-
                                                                     then performed respectively. To classify a new datum point
vectors of covariance matrices are used as new line orienta-
                                                                     xnew we first calculate the set of p(i|xnew )â€™s and then compute
tions vnew
       i , by this means it re-positions the lines to match the
                                                                     the posterior label probability.
points assigned to them. Finally we end up with a mixture
of lines which can be used as a classifier. We purposed a su-           Figure 5 presents the results of MFA for gender detection.
pervised mode of the modified MFA, which models the joint            The two plots (a) and (b) show the error rates for the super-
distribution of features set x and a possible labels set y           vised mode of MFA for the training and test set separately,
                                                                     while (c) and (d) are training and test error rates for unsu-
                      K  Z                                           pervised MFA (soft-LOST). First, we note that sparsification
           p(x, y) = âˆ‘      p(x|i, z)p(z)dzp(y|i)p(i).       (3)     does play a role: when high percentage of features was re-
                     i=1
                                                                     tained from sparsification, e.g. 100% and 99.8%, error rates
In the sequel we will compare the performance of the two             did not change much while increasing time scales, meaning
modes of modified MFA at multiple time scales. In particu-           the intrinsic noise covers up the informative part, and longer
lar we will train supervised and unsupervised models on the          time scales do not assist to recover it. With the increasing of
same feature set. For the unsupervised model we first train          time scales all the curves tend to converge at the time scale
using only the features x. When the density model is optimal         around 400 âˆ¼ 500ms.
                                                                 986

                                                                   (a)                                               (b)
                                                0.65                                              0.65
                                                 0.5                                               0.5
                                  ERROR RATE                                        ERROR RATE
                                               0.375                                             0.375
                                               0.25                                               0.25
                                               0.125                                             0.125
                                                                                                 100%
                                                 0                                                  0
                                                                                                 99.8%
                                                       200   400   600   800 1000                        200   400   600   800 1000
                                                                                                 95%
                                                                   ms                                                ms
                                                                                                 84%
                                                                                                 75%
                                                                   (c)                           63%                 (d)
                                                0.65                                             56%
                                                                                                  0.65
                                                                                                 41%
                                                 0.5                                               0.5
                                  ERROR RATE                                        ERROR RATE
                                               0.375                                             0.375
                                                0.25                                              0.25
                                               0.125                                             0.125
                                                 0                                                 0
                                                       200   400   600   800 1000                        200   400   600   800 1000
                                                                    ms                                               ms
Figure 5: Error rates as function of time scales for different thresholds in gender detection. (a), (b): Training error rates and
test error rates of supervised MFA respectively; (c), (d): Training error rates and test error rates of unsupervised MFA; The 8
curves represent feature sparsification with retained energy from 100% to 41%. The dashed lines are the baseline error rates for
random guessing. Results indicate that the relevant time scale is about 400 âˆ¼ 500ms for this task.
                                                                                                     Figure 6 presents the correlation of test performance for
Table 1: Timescales recommended for modeling Phonemes,
                                                                                                  supervised and unsupervised learning modes of MFA. For
Gender, Height, Identity
                                                                                                  all the four classification tasks, for the given time scales and
    (ms)       Phoneme Gender        Height     ID
                                                                                                  thresholds, data show a remarkable correlation. Hence, in line
 Timescale         20     400-500 â‰¥ 1000 â‰¥ 1000                                                   with the cognitive component hypothesis the statistical reg-
                                                                                                  ularities captured by unsupervised learning are highly com-
                                                                                                  patible with the cognitive structure represented by the label
                                                                                                  structures.
   Similar experiments have been performed on phoneme,
height and speaker identity. For phoneme recognition, the 59
phonemes from TIMIT database include vowels, fricatives,
                                                                                                                                  Conclusion
stops, affricates, nasals, semivowels and glides. To simplify                                     Cognitive component analysis of speech have revealed sta-
the problem, we grouped these phonemes into 3 large cate-                                         tistical regularities at multiple time scales corresponding to
gories: Vowels, fricatives and others. Stacking features into                                     phoneme, gender, height and speaker identity.
longer time scales for phoneme recognition degrades the per-                                         We have devised a protocol for testing the cognitive com-
formance, which shows consistency with our previous work                                          ponent hypothesis based. We propose to compare the perfor-
that phonemes are best modeled at short time scale. The re-                                       mance of supervised learning and unsupervised learning un-
sults of all experiments are summarized in Table 1.                                               der closely matched conditions, so that the only difference is
   To illustrate how well supervised and unsupervised rep-                                        that â€˜cognitive labelsâ€™ are used for supervised learning while
resentations are aligned, we follow the approach outlined                                         not for unsupervised learning.
above. We trained with appropriate labels in supervised mode                                         We preprocessed speech in a pipeline starting from the
to represent the human observer, and with the unsupervised-                                       basic features: short time (20ms) 25-dimensional Mel-
then-supervised scheme to represent the â€˜ecologicalâ€™ group-                                       frequency Cepstral Coefficients (MFCCs). Feature stacking
ing. In both cases we can measure the test performance of the                                     was used to aggregate features at multiple time scales. En-
resulting classifier. High correlation between the error rates                                    ergy based sparsification was invoked to obtain a sparse dis-
of the two schemes indicates similarity of the representations.                                   tributed representation and for noise reduction. We found that
                                                                                    987

                                                                                                                                       References
                             PHONEME                                             GENDER
                   0.6                                                0.5                                      Barlow, H. (1989). Unsupervised learning. Neural Compu-
                                                                     0.45                                        tation, 1, 295â€“311.
                  0.58
                                                                      0.4                                      Bell, A. J., & Sejnowski, T. J. (1997). The â€˜independent com-
     SUPERVISED                                         SUPERVISED
                  0.56                                               0.35                                        ponentsâ€™ of natural scenes are edge filters. Vision Research,
                                             100%
                                             99.8%                    0.3                                        37, 3327â€“3338.
                                             95%
                  0.54
                                             84%
                                                                     0.25                                      Blumstein, S. E., & Stevens, K. N. (1979). Acoustic invari-
                  0.52
                                             75%
                                             63%
                                                                      0.2                                        ance in speech production: Evidence from measurements
                                             56%                     0.15                                        of the spectral characteristics of stop consonants. The Jour-
                                             41%
                   0.5
                     0.5           0.55          0.6
                                                                      0.1
                                                                        0.1    0.2   0.3    0.4   0.5
                                                                                                                 nal of the Acoustical Society of America, 66, 1001â€“1017.
                            UNSUPERVISED                                       UNSUPERVISED                    Damper, R. I. (1998). Self-learning and self-organization as
                                                                                                                 tools for speech research. Behavioral and brain sciences,
                                  HEIGHT                                         IDENTITY
                  0.75                                               0.95                                        21, 262â€“263.
                                                                                                               Deerwester, S. C., Dumais, S. T., Furnas, G. W., Landauer,
                   0.7                                                0.9                                        T. K., & Harshman, R. A. (1990). Indexing by latent se-
     SUPERVISED                                         SUPERVISED
                                                                                                                 mantic analysis. Journal of the American Society for Infor-
                  0.65                                               0.85                                        mation Science, 41, 391â€“407.
                                                                                                               Deller, J. R., Hansen, J. H., & Proakis, J. G. (2000). Discrete
                   0.6                                                0.8                                        time processing of speech signals. IEEE Press Marketing.
                                                                                                               Feng, L., & Hansen, L. K. (2005). On low level cognitive
                  0.55
                     0.55   0.6    0.65    0.7   0.75
                                                                     0.75
                                                                        0.75   0.8   0.85   0.9   0.95
                                                                                                                 components of speech. In Proc. international conference
                            UNSUPERVISED                                       UNSUPERVISED                      on computational intelligence for modelling (Vol. 2, pp.
                                                                                                                 852â€“857).
                                                                                                               Feng, L., & Hansen, L. K. (2006). Phonemes as short time
                                                                                                                 cognitive components. In Proc. icassp (Vol. 5, p. 869-872).
Figure 6: Correlation between test error rates of supervised                                                   Field, D. J. (1994). What is the goal of sensory coding?
and unsupervised learning on four label sets: phoneme, gen-                                                      Neural Computation, 6, 559â€“601.
der, height and identity. Solid lines indicate y = x in the given                                              Garofolo, J. S., Lamel, L. F., Fisher, W. M., Fiscus, J. G.,
coordinate systems. All data locate along this line. We can                                                      Pallett, D. S., & Dahlgren, N. L. (1993). The darpa timit
conclude that high correlation between supervised and unsu-                                                      acoustic phonetic continuous speech corpus cdrom. In Nist
pervised learning has been found for a wide variety of er-                                                       order number pb91-100354.
ror rates substantiating our claim that two representations are                                                Ghahramani, Z., & Hinton, G. E. (1996). The em algorithm
highly similar.                                                                                                  for mixtures of factor analyzers (Tech. Rep. No. CRG-TR-
                                                                                                                 96-1). 6 Kingâ€™s College Road, Toronto, Canada M5S 1A4:
                                                                                                                 University of Toronto, Department of Computer Science.
the following time scales are characteristic: 20ms of speech
                                                                                                               Hansen, L. K., Ahrendt, P., & Larsen, J. (2005). Towards cog-
provides phonemes information; gender is found in the range
                                                                                                                 nitive component analysis. In Akrrâ€™05 -international and
400 âˆ¼ 500ms; while, height and identity may require longer
                                                                                                                 interdisciplinary conference on adaptive knowledge repre-
time scales, say > 1000ms.
                                                                                                                 sentation and reasoning.
   Our finding indeed indicates the consistency of statistical
                                                                                                               Hansen, L. K., & Feng, L. (2006). Cogito componentiter ergo
regularities (unsupervised learning) and human cognitive pro-
                                                                                                                 sum. In Proc. ica (pp. 446â€“453).
cesses (supervised learning of human labels), for phonemes,
                                                                                                               Hoyer, P., & Hyvrinen, A. (2000). Independent compo-
gender, speaker identity all of which are effortless recognized
                                                                                                                 nent analysis applied to feature extraction from colour and
by humans. Height is also predicted from speech features
                                                                                                                 stereo images. Network: Comput. Neural Syst., 11, 191â€“
corresponding to human ability to guess the speakers size. It
                                                                                                                 210.
would be interesting to test whether our representations lead
                                                                                                               Lewicki, M. S. (2002). Efficient coding of natural sounds.
to similar errors in predicting a persons height from speech as
                                                                                                                 Nature Neuroscience, 5, 356â€“363.
in humans.
                                                                                                               Oâ€™Grady, P. D., & Pearlmutter, B. A. (2004). Soft-lost: Em
                                     Acknowledgments                                                             on a mixture of oriented lines. In Proc. ica (p. 430-436).
                                                                                                               Sussman, H. M., Fruchter, D., Hillbert, J., & Sirosh, J. (1998).
This work is supported by the Danish Technical Re-                                                               Linear correlations in the speech signal: The orderly output
search Council, through the framework project â€˜Intelligent                                                       constraint. Behavioral and brain sciences, 21, 241â€“299.
Soundâ€™ (STVF No. 26-04-0092), www.intelligentsound.org.                                                        Wagensberg, J. (2000). Complexity versus uncertainty: The
We thank Tobias Andersen for useful comments on the                                                              question of staying alife. Biology and philosophy, 15, 493â€“
manuscript. LF thanks the Niels Bohr Legatet for generous                                                        508.
financial support for external research stay.
                                                                                                         988

