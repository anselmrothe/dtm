UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Decision Making Using Learned Causal Structures
Permalink
https://escholarship.org/uc/item/8ht006pv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Nichols, William
Danks, David
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                             Decision Making Using Learned Causal Structures
                                             William Nichols (wn@andrew.cmu.edu)
                               Department of Philosophy, Carnegie Mellon University, 135 Baker Hall
                                                         Pittsburgh, PA 15213 USA
                                                  David Danks (ddanks@cmu.edu)
                               Department of Philosophy, Carnegie Mellon University, 135 Baker Hall
                                                      Pittsburgh, PA 15213 USA; and
                                     Institute for Human & Machine Cognition, 40 S. Alcaniz St.
                                                         Pensacola, FL 32502 USA
                             Abstract                                     expected value of eating Thai is U(pleasant), since that
                                                                          outcome is guaranteed; the expected value of steak is 0.9 
   Decision making and causal reasoning are clearly relevant for          U(very enjoyable) + 0.1  U(unpleasant). Standard decision
   one another, but have often been studied in relative isolation.
                                                                          theory prescribes that I do the action with greater expected
   In this paper, we report the results of two experiments that
   investigated whether people can make appropriate decisions             value, where that clearly depends on the precise utility
   using causal beliefs learned from sequences of cases. We               function U().
   found that people behave close-to-optimally for various                    Much of the work in, for example, behavioral economics
   causal and payoff structures, even though they are relatively          aims to determine features of the utility function. In
   poor at providing verbal reports of causal strength.                   contrast, the long-running philosophical debate between
   Keywords: causal learning; decision making; Bayes nets;                evidential and causal decision theorists centers on the proper
   intervention; causal reasoning.                                        method to calculate the probabilities (e.g., Glymour &
                                                                          Meek, 1994; Hurley, 1994; Joyce 2000; Seidenfield 1984).
         Introduction and Related Research                                Evidential decision theorists argue that the probabilities
                                                                          should be based on straightforward conditionalization;
Causal knowledge and reasoning are clearly relevant to our
                                                                          causal decision theory holds that the relevant probabilities
decision making, as we take various actions because we                    are causal ones that depend on the results of the action,
think that they will cause desired effects (Sloman, 2005). At             understood as an exogenous force on the causal system.
the same time, our decision making is relevant for our                        In recent years, Bayes1 nets have emerged as a relatively
causal learning and reasoning, both because our decisions                 standard representation of causal structures. A causal Bayes
shape the data we observe and because we may adjust our                   net is composed of two related components: a directed
causal learning in light of anticipated future decisions. In              acyclic graph that encodes the qualitative causal structure,
light of the close connection between causal reasoning and                and a joint probability distribution over the variables in the
decision making, it seems entirely natural to aim for an                  network that encodes the quantitative strengths of the causal
integrated theory of the two. Such a theory has emerged in                relationships. These components are connected by a Markov
the artificial intelligence and machine learning literatures
                                                                          assumption and there is a rich technical literature on
through the combination of Bayesian networks as a
                                                                          inference and search for Bayes nets; details about these are
representation of causal knowledge, and causal decision                   not required for our purposes. Causal Bayes nets require
theory. In contrast, examination of an integrated model                   only minimal metaphysical assumptions about the nature of
along these lines has only recently been explored in                      causation; no strong theory is presupposed.
cognitive psychology (Hagmayer & Sloman, 2005, 2006;                          Given some fully specified Bayes net, there is a precise
Sloman & Hagmayer, in press).                                             method for predicting post-intervention probability
     At the coarsest level, decision theory recommends that               distributions (Pearl, 2000; Spirtes, Glymour, & Scheines,
decision makers choose the option that maximizes the                      1993). We can compute the probability of any variable (or
subjective expected utility. That is, given actions A1, …, An,            set) in the system conditional on an intervention on any
do the Ai with largest  P(Oj | Ai)  U(Oj), where Oj ranges              other variable (or set). In the Bayes net framework,
over the possible outcomes, and U() is a utility function. For            interventions are most commonly understood as exogenous
example, suppose I have the choice of Thai food or steak for              manipulations of particular variables. These interventions
dinner. I enjoy good steak the most, but 10% of the time it is
                                                                          sometimes called ‘hard’ interventionschange the
overcooked and so quite awful. In contrast, the Thai food is
always pleasant.                                                          1
     We can think about the problem as involving three                      There is nothing inherently Bayesian about ‘Bayesian networks.’
                                                                          The name arises from the original uses of Bayes nets in Bayesian
possible outcomes corresponding to a very enjoyable (good
                                                                          updating, and not because of any necessary connection between the
steak), pleasant (Thai), or unpleasant (bad steak) dinner. The            framework and Bayesianism more generally.
                                                                     1343

underlying causal structure by eliminating the influence of          when making decisions? Experiment 1 aims to begin to
all normal causes upon a variable within the system.                 answer these two questions.
     Continuing the food example from before, the                        The previous research has also focused on cases of equal
underlying causal structure is a simple one: Food Choice            intervention cost/outcome payoffs. It thus does not provide
Enjoyment. Suppose, however, that I apply anesthetic to my           a strong test of causal decision theory, as expected utility
tongue before dinner so that I cannot taste anything. In that        maximization is not separated from payoff probability
case, food choice is no longer a cause of enjoyment; rather,         maximization. That is, “correct” choices might simply be
it is entirely determined by the intervention. Graphically, we       due to maximizing the probability of some payoff, rather
remove (“break”) the edge. Hard interventionsthose that             than taking the utilities of the payoffs into account. In
control the state of a variableare the most commonly                Experiment 2, we use a causal structure and payoff system
discussed interventions, but the Bayes net theory of                 for which these two methods make differing predictions.
interventions is also well-defined for weaker types of                   Finally, we wanted all participants to have a strong
interventions, such as those that simply perturb some                interest in the outcome of the decision making. We thus
variable away from its current value (e.g., adjusting my             provided participants with cash payoffs depending on
enjoyment by having a particularly sour fruit before dinner).        whether their intervention was successful in bringing about
     Bayes nets thus provide a natural complement to causal          the desired outcome. While the amounts of money involved
decision theory, as they provide both a robust framework for         are small ($1 to $3), we believe that the use of outcome-
modeling causal structures, and the methods required to              based payoffs provides important incentive for participants.
compute the relevant post-action probabilities for causal
decision theory. Various AI and machine learning models                                     Experiment 1
use Bayes nets (or related ‘influence diagrams’) and causal          Experiment 1 had two conditions with different causal
decision theory in exactly this way (e.g., Jensen, 1996, and         structures; all participants did both conditions in random
references therein).                                                 order. In each condition, participants were shown cases with
     A psychological model that integrates causal decision           two potential causes of a specified effect variable. All
theory and Bayes nets in the natural way has only recently           participants learned causal structures through the sequential
emerged (Hagmayer & Sloman, 2005, 2006; Sloman &                     presentation of cases, where the sequence ensured that
Hagmayer, in press). Sloman and Hagmayer’s theory                    participants saw exactly the desired frequency distribution.
models choices as hard interventions, and expected utilities         In condition A, one potential cause was a distractor variable
are all computed conditional on those interventions.                 that was uncorrelated with the effect. In condition B, both
     To date, this psychological model has been tested almost        potential causes were actual causes, but one was much
entirely by experiments in which participants are explicitly         stronger. Condition B should be more difficult, as both
told the causal structure. Sloman & Hagmayer (2005) found            variables are actual causes, and so participants need to track
that people make different choices about intervening on A to         more information to make the final decision.
obtain T if they are explicitly told that an AT correlation
is due to direct causation (A  T), versus an unobserved             Participants
common cause (A  B  T). In other words, people want                48 Carnegie Mellon University students participated and
to intervene on A when it is causal, but are comparatively           were compensated $5 for participation, plus $0 to $2,
indifferent when A is not actually a cause. Importantly,             depending on the outcome of their choices.
participants are simply told the causal structure; they do not
have to do any learning besides text processing.                     Design and Materials
     There are a number of recent studies arguing that people        The experiment was done on computers in the Laboratory
can learn causal structurerepresented as a Bayes net               for Empirical Approaches to Philosophy at Carnegie Mellon
from observational data, and in particular, from sequences           University. The cover story placed participants in the role of
of cases (e.g., Gopnik, Glymour, Sobel, Schulz, Kushnir, &           plant biologists attempting to get certain flowers to bloom.
Danks, 2004; Griffiths & Tenenbaum, 2005; Steyvers,                  Participants were first provided an introduction to the
Tenenbaum, Wagenmakers, & Blum, 2003). There is also                 information they would be given, and then instructed that
evidence that people use that causal knowledge to predict            their goal was to learn what causes blooming so that they
the outcome of interventions (e.g., Gopnik, et al., 2004;            could subsequently intervene to produce blooming. During
Kushnir, Gopnik, Schulz, & Danks, 2003; Steyvers, et al.,            the learning phase, participants were (passively) shown a
2003; Waldmann & Hagmayer, 2005), though this research               series of cases that they examined in a self-paced manner. In
has not been done in a standard decision-theoretic setting.          both conditions, the potential causes were (potential)
     In this paper, we aim to test the beginnings of an              fertilizers. Each had a distinct name; for simplicity, we refer
integration of these two literatures by asking: are people           to them below simply as ‘Fertilizer 1’ and ‘Fertilizer 2’.
capable of using the products of causal learning from                    In condition A, the underlying causal structure was:
sequences to make well-informed choices? If so, are people           Fertilizer 1  Blooming Fertilizer 2 (i.e., Fertilizer 2 was
sensitive to perceived causal strength (and not just structure)      not a cause). Participants saw 48 cases in this condition. The
                                                                     fertilizers were uncorrelated with each other, and the
                                                                1344

unconditional frequency of each was 0.5. Table 1 shows the           cause), which is significantly different from random
conditional frequency of blooming given the fertilizers.             (p<.001, binomial test). The difference in choice
      Table 1: Distribution of blooming for condition A              percentages between conditions is significant (p=.041,
                                                                     McNemar’s test). Participants almost universally act to
           Fertilizer 1    Fertilizer 2    P(Bloom)                  maximize P(Bloom), and therefore expected utility.
             Present         Present          0.75                       Beyond simple choices, we were interested in whether
             Present         Absent           0.75                   participants were internally coherent: did they choose the
             Absent          Present           0                     fertilizer to which they subjectively assigned greater causal
             Absent          Absent            0                     strength? 47 of the 48 participants (97.91%) gave coherent
                                                                     responses in condition A, and 43 (89.58%) were coherent in
Blooming occurs only if Fertilizer 1 is present. Fertilizer 2        condition B. Both of these percentages are significantly
does not affect the probability of the bloom, and is simply a        different from random (p<.001 for both, binomial test). No
distractor. Participants were told that the Fertilizers were         participants were incoherent in both conditions. There is a
each applied before the bloom (if applied at all).                   trend towards greater coherency in A than B, but it is not a
    In condition B, the underlying causal structure was              significant trend (p=.22, McNemar’s test). In any case,
Fertilizer 1  Blooming  Fertilizer 2; both fertilizers are         participants were clearly highly coherent in their choices.
                                                                         Interestingly, participant performance at the rating task
actual causes of blooming. Participants saw 40 cases in this
                                                                     was comparatively worse. Mean causal strength ratings for
condition. The fertilizers were again uncorrelated with each
                                                                     both conditions are shown in Figure 1. In Condition A, the
other and occurred with an unconditional frequency of 0.5;
                                                                     mean strength rating of Fertilizer 1 was 63, which is
the conditional frequency of blooming is given in Table 2.
                                                                     significantly lower than the true strength of 75 (p=.01, t-
                                                                     test). The mean strength rating of Fertilizer 2 was -23,
       Table 2: Frequency distribution for condition B
                                                                     which is significantly lower than the true strength of 0
                                                                     (p<.001, t-test).
            Fertilizer 1   Fertilizer 2  P(Bloom)
              Present        Present         0.8
              Present        Absent          0.6
              Absent         Present         0.2
              Absent         Absent           0
During the test phase of each condition, participants were
asked “To get the [PLANT NAME] to bloom, what do you
want to apply?” where the actual plant name was used and
participants were shown both the pictures and names of the
two fertilizers. After choosing a fertilizer but before being
told the outcome of their choice, participants were asked to
rate the causal power of each variable for blooming. Ratings
were provided on a slider that ranged from +100 (the cause
always produces the bloom) to -100 (the cause always
prevents the bloom), with 0 indicating no relationship. The
slider moved in increments of 5, and participants were                     Figure 1: Mean strength ratings for both conditions
required to move the slider to give a response (i.e., they
could not simply “click through”). The outcome of the                    In Condition B, the value for the “true” causal strength is
intervention was determined by a pseudo-random sample                not obvious. There is significant debate in the causal
from the underlying probability distribution, conditional on         learning literature about whether conditional P (Shanks,
the participant’s choice. If the flower bloomed, participants        1995; Spellman, 1996) or causal power (Cheng, 1997)
immediately received $1. After completing one condition,             provides the most appropriate measure of causal strength. In
participants moved on to the other condition.                        condition B, the two methods yield different values; we
                                                                     focus on P since the causal power value depends on the
Results and Discussion
                                                                     focal set. The mean reported causal strength of Fertilizer 1
There were no significant order effects, either for the ratings      was 57, and is not significantly different from the P value
or the choices, and so we ignore condition order in these            of 60 (p=0.542, t-test). The mean strength rating of
analyses. 45 of the 48 participants (93.75%) chose to                Fertilizer 2 was -10, which is significantly lower than the
intervene on Fertilizer 1 (i.e., the actual cause) in condition      P value of 20 (p=.002, t-test.)
A. This pattern is significantly different from random choice            Despite the largely inaccurate mean ratings, 45 out of 48
(p<.001, binomial test). In condition B, 39 of 48 participants       participants (93.75%) in condition A gave the correct rank
(81.25%) chose to intervene on Fertilizer 1 (i.e., the stronger      order for the causes (i.e., rating for Fertilizer 1 is greater
                                                                1345

than the rating for Fertilizer 2). 42 out of 48 participants              If you use nitrogen and the rose blooms, you will
(87.5%) gave the correct rank order for the causes in                     receive $1. If you use fertilizer and the rose
condition B. In both conditions, the numbers of participants              blooms, you will receive $3. Fertilizer makes roses
with correct rank order are significantly better than random              bloom by adding nitrogen to the soil. If you add
(p<.001 for both, binomial tests); participants were accurate             fertilizer, you have 3 chances in 4 of triggering the
about the strength ordering, though they did not get the                  nitrogen. If the soil has nitrogen in it, there are 4
exact numbers correct. The number with correct rank order                 chances out of 5 of making the rose bloom. The
in A was not significantly different from in B (p=.37,                    soil will only have in it what you put it in. There
McNemar’s test). The one incoherent participant in                        will be no naturally occurring nitrogen or fertilizer.
condition A also gave an incorrect rank order, but only one               Which would you rather use, nitrogen or fertilizer?
individual (of six) who gave an incorrect rank order in              In the Stepwise condition, participants were shown a
condition B acted incoherently. There is no clear evidence           sequence of cases that captured the relevant frequency
of a correlation between incoherent behavior and incorrect           distribution. The fertilizer occurred with an unconditional
rank ordering (in this very small sample).                           probability of 0.5. The nitrogen never occurred without
                                                                     fertilizer; when fertilizer was present, the nitrogen occurred
                       Experiment 2                                  with probability 0.833. This conditional probability is
Experiment 2 had the same domain as Experiment 1, but                slightly different from that in the Story condition, and was
used the structure: Fertilizer  Nitrogen  Blooming,                due to a programming error. Since we do not compare
where both F and N are potential targets of intervention.            across conditions, we do not believe that the slight change
This causal structure is more difficult to learn than either of      makes a significant difference. Blooming never occurred
those used in Experiment 1 (e.g., Lagnado & Sloman,                  without nitrogen; when nitrogen was present, blooming
2002), and so provides a stronger test. More importantly,            occurred 80% of the time. The resulting distribution of cases
however, this experiment aimed to distinguish between two            is shown in Table 3; for reasons of space, we omit cases that
plausible decision strategies: (i) maximize expected utility;        never occur. As in Experiment 1, participants passively
and (ii) maximize the probability of payoff.                         observed the 48 cases.
    Participants were paid more if they caused blooming by
intervention on F; for our probabilities, the larger payoff                 Table 3: Case distribution for Stepwise condition
meant that intervention on F maximized expected utility
(assuming a natural utility function). At the same time, an               Fertilizer     Nitrogen       Blooming      # of cases
intervention on N necessarily had a higher probability of                    Yes            Yes            Yes            16
success. Thus, participants who seek to maximize expected                    Yes            Yes            No              4
value should intervene on F; those who seek to maximize                      Yes            No             No              4
the probability of a payoff should intervene on N. Of course,                 No            No             No             24
these different predictions are based on the true probabilities
and payoffs; participant behavior will depend on their                   In both conditions, participants first gave a response.
subjective beliefs.                                                  Before being told the outcome, they were asked to rate the
    Since prior research has not examined this type of causal        causal strength of each variable on blooming, with the same
or payoff structure, we used two conditions: a “Stepwise”            prompt and rating slider as in Experiment 1. Participants
condition in which participants were shown a sequence of             were then told the result of the intervention, which was
cases (as in Experiment 1); and a “Story” condition in which         determined by a pseudo-random draw from the appropriate
they were explicitly told the causal story using exact               conditional distribution. If the flower bloomed and the
statistics. The Story condition connects this experiment with        participant used the fertilizer, the reward was $3; if she used
the research of Sloman and Hagmayer, who have not                    nitrogen, then the reward was only $1. The objective
previously considered a causal structure such as this one.           expected value from using the nitrogen was $0.80 in both
                                                                     conditions. The objective expected value for an intervention
Participants                                                         on the fertilizer was $1.80 in the Story condition, and $2.00
The same 48 Carnegie Mellon students participated and                in the Stepwise condition. At the same time, P(Bloom |
were compensated an additional $0, $1, or $3, depending on           Intervene on N) = 0.8 > 0.66 = P(Bloom | Intervene on F in
the outcome of their choice. Sixteen participants were in the        Stepwise) > 0.6 = P(Bloom | Intervene on F in Story).
Story condition; 32 were in the Stepwise condition.                      Expected utility maximization and payoff probability
                                                                     maximization thus make different predictions in both
Design and Materials                                                 conditions. Note that there is no correct answer for this
                                                                     experiment, as the “right” answer depends on what the
The experiment was conducted in the same location, and the           participant wishes to maximize. Although we report
cover story was nearly identical. Participants were asked to         participant responses below, we are more concerned with
learn what causes blooming so that they can intervene either         their strength ratings, and whether they acted to maximize
on the fertilizer, or on the soil nitrogen, to produce               subjective expected utility or payoff probability (or neither).
blooming. In the Story condition, participants were told:
                                                                1346

Results and Discussion                                                      Table 4: Classification of Story condition behavior
Story Condition. Five of the sixteen participants chose to
intervene on the nitrogen; the other eleven chose the                                         Expected utility   Not an expected
fertilizer. The mean causal strength rating for the fertilizer                                  maximizer        utility maximizer
(60) is identical to the true value of 60 (see Figure 2 below).            Payoff prob.              5                    3
However, the distribution of responses was not unimodal:                    maximizer
six participants (37.5%) gave a response within five units of              Not a payoff              6                    2
60, while seven participants (43.75%) gave a response                   prob. maximizer
within five units of 75, which is the strength of the fertilizer
on the nitrogen. Of the three participants who gave other             Stepwise Condition. Fifteen of the 32 participants in this
types of responses, two gave responses very near the middle           condition chose to intervene on the nitrogen. The mean
of the slider, which suggests that they did the minimum               causal strength rating for the nitrogen was 50, which is
required to move to the next question. The last gave a                significantly lower than the true value of 80 (p<.001, t-test).
response of 50.                                                       The mean causal strength rating for the fertilizer was 23,
                                                                      which is significantly lower than the correct value of 66
                                                                      (p<.001, t-test), but the plurality of participants gave a
                                                                      response of 0. This value is the causal strength of the
                                                                      fertilizer conditional on the presence of nitrogen, implying
                                                                      that in this condition, many participants reported conditional
                                                                      strengths. Even if ratings near the middle of the slider are
                                                                      removed, both mean strength ratings were significantly less
                                                                      than the actual causal strengths (both p<.001, t-tests).
                                                                      Twenty participants (62.5%) gave the correct rank order for
                                                                      the causal strengths, which is not significantly different
                                                                      from chance (p=.108, binomial test).
                                                                          The classification of participant behavior is shown in
                                                                      Table 5. 25 participants (78.13%) acted as if they were
                                                                      maximizing subjective expected utility, which is
      Figure 2: Mean strength ratings for both conditions
                                                                      significantly more than chance (p=.001, binomial test). 21
                                                                      participants (65.6%) acted as if they were maximizing
    The causal strength ratings for the nitrogen were more
                                                                      payoff probability, which is not significantly different from
surprising. The mean rating was 50, which is significantly
                                                                      chance (p=.11, binomial test). Notably, 17 of the 20
less than the true strength of 80 (p=.004, t-test). Only eight
                                                                      participants who gave the correct rank order for the causal
participants estimated the strength of the nitrogen within 5
                                                                      strengths acted as expected utility maximizers, which is
units of the true strength. Four participants gave causal
                                                                      significantly different from chance (p=.003, binomial test).
values very near the middle of the slider. One gave a rating
of -20, suggesting that the nitrogen inhibited blooming.
                                                                          Table 5: Classification of Stepwise condition behavior
    Only two participants gave correct answers for the
strengths of both causal variables: one intervened on the
                                                                                              Expected utility   Not an expected
nitrogen, the other on the fertilizer. The general failure of
                                                                                                maximizer        utility maximizer
participants to give the corrector even plausiblestrength
                                                                           Payoff prob.             19                    2
ratings is quite surprising, particularly since participants
                                                                            maximizer
were paid based on the success of their intervention, and
                                                                           Not a payoff              6                    5
they had just finished reading a story that explicitly
                                                                        prob. maximizer
provided the causal strengths.
    Having noted that participants may not have provided
accurate ratings, we analyzed participant behavior to                     Many participants gave causal strengths that allowed
determine whether subjective expected utility maximization            them to both maximize utility as well as the probability of a
or payoff probability maximization better explains their              payoff. While they chose the wrong causal strengths, these
behavior. The classification of participant behavior is shown         participants were at least coherent when they intervened.
in Table 4.
    Eleven participants (68.75%) gave responses that                                           Conclusion
maximize subjected expected utility, and eight (50%) sought           These experiments are part of a larger project to try to tie
to maximize subjective payoff probability. Neither of these           together causal learning and reasoning, and causal decision
is significantly different from chance (respectively p=.21,           theory. They provide further support that the causal learning
p=.50, binomial tests) Notice that some participants were             and decision making elements of our cognitive systems are
able to maximize both expected utility and payoff                     closely connected. In particular, people seem to be quite
probability given their subjective beliefs.                           capable of learning simple causal structures from
                                                                 1347

experience, and then using those beliefs in sensible ways for         Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure and
decision making in novel situations.                                    strength in causal induction. Cognitive Psychology, 51,
     Experiment 1 showed that people can use the results of             334-384.
causal learning from sequences to generate sensible                   Hagmayer, Y., & Sloman, S. A. (2005). A causal model
decisions. Although people did not necessarily learn the true           theory of choice. In B. G. Bara, L. Barsalou & M.
causal strengths, they largely used their (incorrect)                   Bucciarelli (Eds.), Proceedings of the 27th annual
subjective beliefs in a coherent manner. Not surprisingly,              conference of the cognitive science society (pp. 881-886).
condition A was easier for participants than condition B.               Mahwah, NJ: Erlbaum.
This finding suggests that people are not overly distracted           Hagmayer, Y., & Sloman, S. A. (2006). Causal vs.
by a potential cause that is uncorrelated with the effect, but          evidential decision making in Newcomb's Paradox. In R.
they are affected by the presence of other actual causes and            Sun & N. Miyake (Eds.), Proceedings of the 28th annual
will rank secondary causes as a prohibitive cause. This                 conference of the cognitive science society. Mahwah, NJ:
result is, in some ways, not particularly surprising in light of        Erlbaum.
empirical evidence that people sometimes focus more on                Hurley, S. L. (1994). A new take from Nozick on
causal structure than causal strength (e.g., Griffiths &                Newcomb’s Problem and Prisoner’s Dilemma. Analysis,
Tenenbaum, 2005; Steyvers, et al., 2003).                               54.
     In the Stepwise condition of Experiment 2, a majority of         Jensen, F. V. (1996). An introduction to Bayesian networks.
participants acted to maximize both expected utility and                London: UCL Press.
payoff probability. That is, their subjective beliefs led to a        Joyce, J. (2000). Why we still need the logic of choice.
choice problem that does not distinguish between these two              Philosophy of science, 67, S1-S13.
principles. We are currently developing an experiment that            Kushnir, T., Gopnik, A., Schulz, L. E., & Danks, D. (2003).
more directly tests these two principles. The Story condition           Inferring hidden causes. In R. Alterman & D. Kirsh
is more troubling, as participants did not seem to read the             (Eds.), Proceedings of the 25th annual meeting of the
story carefully (as evidenced by their failure to rate the              cognitive science society (pp. 699-703). Boston:
causes appropriately). Thus, our next experiment will use               Cognitive Science Society.
various incentives to improve participant comprehension, as           Lagnado, D. A., & Sloman, S. A. (2002). Learning causal
well as explicit measures of story comprehension. We also               structure. In W. D. Gray & C. D. Schunn (Eds.),
intend to provide causal diagrams rather than text, thereby             Proceedings of the 24th annual conference of the
perhaps avoiding typical problems of story comprehension.               cognitive science society (pp. 560-565). Mahwah, NJ:
     Ordering effects over the two experiments may also                 Erlbaum.
have played a role, as all participants were first exposed to         Pearl, J. (2000). Causality: Models, reasoning, and
experiment 1. Finally, we aim to understand better the                  inference. Cambridge: Cambridge University Press.
individual differences that lead to variations in choice              Seidenfield, T. (1984). Comments of decision theory. In
behavior. Our participants are relatively high-functioning,             Proceedings of the biennial meeting of the philosophy of
and so fine-grained measures of particular cognitive abilities          science association, Vol. 2.
may be required to separate out individual variation.                 Shanks, D. R. (1995). Is human learning rational? The
                                                                        Quarterly Journal of Experimental Psychology, 48A, 257-
                                                                        279.
                    Acknowledgments                                   Sloman, S. (2005). Causal models: How people think about
D. Danks was partially supported by grants from the Office              the world and its alternatives. Oxford: Oxford University
of Naval Research and the National Institutes of Health, as             Press.
well as intellectual support from the James S. McDonnell              Sloman, S. A., & Hagmayer, Y. (in press). The causal logic
Foundation Causal Learning Collaborative. We thank four                 of choice. Trends in Cognitive Sciences.
anonymous reviewers for helpful comments.                             Spellman, B. A. (1996). Conditionalizing causality. In D. R.
                                                                        Shanks, K. J. Holyoak & D. L. Medin (Eds.), Causal
                         References                                     learning: The psychology of learning and motivation, vol.
Cheng, P. W. (1997). From covariation to causation: A                   34 (pp. 167-206). San Diego, CA: Academic Press.
   causal power theory. Psychological Review, 104, 367-               Spirtes, P., Glymour, C., & Scheines, R. (1993). Causation,
   405.                                                                 prediction, and search. Berlin: Springer-Verlag.
Glymour, C., & Meek, C. (1994). Conditioning and                      Steyvers, M., Tenenbaum, J. B., Wagenmakers, E.-J., &
   intervening. British Journal for the Philosophy of Science,          Blum, B. (2003). Inferring causal networks from
   45, 1001-1021.                                                       observations and interventions. Cognitive Science, 27,
Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E.,                   453-489.
   Kushnir, T., & Danks, D. (2004). A theory of causal                Waldmann, M. R., & Hagmayer, Y. (2005). Seeing versus
   learning in children: Causal maps and Bayes nets.                    doing: Two modes of accessing causal knowledge.
   Psychological Review, 111, 3-32.                                     Journal of Experimental Psychology: Learning, Memory,
                                                                        & Cognition, 31, 216-227.
                                                                 1348

