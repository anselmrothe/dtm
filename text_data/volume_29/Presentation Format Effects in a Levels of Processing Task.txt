UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Presentation Format Effects in a Levels of Processing Task

Permalink
https://escholarship.org/uc/item/9bx4b4bq

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)

Authors
Goolkasian, Paula
Foos, Paul W.

Publication Date
2007-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Presentation Format Effects in a Levels of Processing Task
Paula Goolkasian (pagoolka@uncc.edu)
Department of Psychology, 9201 University City Blvd,
Charlotte, NC 28223 USA

Paul W. Foos (pwfoos@uncc.edu)
Department of Psychology, 9201 University City Blvd,
Charlotte, NC 28223 USA

Abstract
Three experiments were conducted to examine better
performance in long-term memory when stimulus items are
pictures or spoken words compared to printed words.
Hypotheses regarding the allocation of attention to printed
words, the semantic link between pictures and processing, and
a rich long-term representation for pictures were tested. Using
levels of processing tasks eliminated format effects when no
memory test was expected and processing was deep (E1) and
when study and test formats did not match (E3). Pictures
produced superior performance when a memory test was
expected (E1 & 2) and when study and test formats were the
same (E3). Results of all experiments support the attenuation
of attention model and that picture superiority is due to a more
direct access to semantic processing and a richer visual code.
Keywords: Presentation Format; Levels of Processing;
Picture/Word, Memory, Auditory/Visual

Introduction
One of the benefits of living in the information age is that
we have the tools to present information in one of a number
of formats and modalities. Which one we choose should be
guided by our desire as scientists and educators to maximize
the impact of the flow of that piece of information.
Although the effect of presentation format has had a long
and rich research history, it is somewhat fragmented: and as
a result, there are few general principles that psychological
science can offer as a guide for efficient processing of
stimulus information. The present research integrates
previous work with picture/word (e.g., Kosslyn, 1980;
Paivio, 1975) and auditory/visual (e.g., Greene, 1985;
Penney, 1989) comparisons by exploring why printed words
are not recalled as well as other presentation formats (e.g.,
pictures and spoken words) (Foos & Goolkasian, 2005;
Goolkasian & Foos, 2002). Three experiments extend the
investigation of format effects beyond encoding processes
and working memory by using a levels of processing (LoP)
approach (e.g., Craik & Lockhart, 1972) to examine whether
effects of presentation format remain in long-term memory
even after participants have encoded the stimulus items to
the same levels.
The present experiments examine two complementary
explanations for picture superiority (i.e., Nelson, 1979 and
Larkin & Simon, 1987). In Experiment 1 we use a LoP task
with three styles of presentation under conditions of shallow

and deep processing. The question of main interest is
whether effects of presentation format remain in long-term
memory even after participants have been forced to encode
stimulus items to varying levels of depth.
In this
experiment we also compare intentional vs. incidental
learning conditions since one might expect greater
conscious attention to encoding under intentional learning.
Experiment 2 repeats some of these conditions in a recall
experiment to rule out test format as a possible alternative
explanation for improved performance with printed words.
In both of these experiments Nelson’s (1979) model predicts
better performance with pictures.
Finally, in Experiment 3, we force deep processing on
items presented as pictures, spoken words, and printed
words and test long term recognition under conditions
where the test items are presented in the same or a different
format. If presentation format is an essential component in
processing the stimulus item, that is, if format is encoded
together with semantic information, then recognition of test
items presented in a different format at study and test should
be relatively low. Furthermore a comparison of performance
with same and different study-test formats allows us to
examine the effect, if any, of the hypothesized rich, visual,
long-term representation for pictures compared to semantic
codes for all items processed at a deep level (e.g., Larkin &
Simon, 1987)

Experiment 1

1049

In Experiment 1 we investigate presentation format effects
in long-term memory. According to the attention allocation
hypothesis (Foos & Goolkasian, 2005) printed words are at
somewhat of a disadvantage because of attenuated
conscious processing. If we control the processing level we
control the amount of conscious encoding and might
therefore eliminate format effects in retrieval from longterm memory. At the very least we should eliminate those
components that results from differences in semantic
coding. Furthermore, we manipulate levels of processing to
direct the allocation of attention to meaning as well as to
physical features of the presented items.
During the study phase, stimulus items are presented in
one of three formats—picture, spoken word, or printed
words and participants perform a deep or shallow
processing task on each of the items presented. In the

incidental memory condition, participants respond without
any expectation that a recognition memory test will follow;
while in the intentional learning condition, participants are
informed of the test. In a third control condition, participants
study the items for a later test without the LoP task.

Method
Participants.
Seventy-one men and women student
volunteers drawn from the University of North Carolina,
Charlotte participated to obtain credit in psychology. Fifty
were randomly assigned to one of the two levels of
processing groups (incidental and intentional processing)
and 21 to a control group. Participation was restricted to
those with normal (or corrected-to-normal) color vision.
Materials. The stimuli used in the levels of processing task
were 60 items randomly selected from a pool of items used
in prior work (Foos & Goolkasian, 2005). The items
appeared as either a picture, printed word or spoken word.
Three versions of the stimulus lists were developed so that
across participants, all 60 items appeared equally often as
pictures, spoken words, and printed words. Each picture was
imported into Adobe Photoshop and its size was adjusted to
approximately 4 X 4 cm. A black border (.1 cm ) was added
to some of the pictures. The printed words were either
uppercase or lowercase characters printed with a Geneva
font in a character size of 24 points. Spoken words were
sound files created by a human female or male voice as a
Macintosh system sound file.
The items were randomly assigned to either shallow or
deep processing tasks. For both, an orienting question
preceded the presentation of the item and participants
answered by depressing the “F” (for “yes) or “J” (for “no”)
keys with their left or right index fingers. The orienting
questions followed the guideline established by Intraub and
Nicklos (1985) that shallow questions could be answered
without reference to meaning and could be answered for
meaningless stimuli. Shallow tasks always focused attention
on some physical feature of the items. For pictures, the
question asked was “Is the item framed?”; for spoken words
the question was “Is the item in a female voice?”; for
printed words the question was “Is the word printed in
uppercase?”. The deep task for all item types was whether
the item belonged to some category (e.g., Is the item a type
of food? Is the item found in a garden?). For half of all
items in each condition the correct answer was yes and for
the other half the correct answer was no.
All stimuli were centered on a 15” Apple flat screen
monitor. Stimulus presentation and data collection were
controlled by SuperLab running on a Power Mac G4.

indicate whether the item had been presented and indicated
confidence in their answer by using a three point scale
where 1 = not very confident, 2 = somewhat confident, and
3 = very confident.
Procedure. All participants were randomly assigned to one
of three conditions and run individually in sessions of
around 30 minutes. In the incidental and intentional
processing condition, an orienting question appeared for 2 s
followed by an item presented as a picture, spoken word or
printed word. Participants considered whether the item had a
physical feature (shallow processing) or belonged to a
semantic category (deep processing) and responded with a
(yes or no) key press. The next trial started as soon as the
participant made a response. The procedure continued until
60 items were presented. Within the list of 60 items there
was random arrangement of shallow and deep items and
presentation formats. There were 5 practice trials before the
experimental trials.
Following the levels of processing task, participants were
asked to engage in a filler task. They counted backwards by
two out loud starting with the number 99. Participants were
then given a printed recognition test. The groups differed in
their expectation for the memory test. The intentional
processing group was instructed to study the items for a
recognition test but the incidental processing group was not
and for them the test was a surprise. In the control condition
items were presented without the orienting question for
1200 msec each. The exposure duration was determined by
averaging response times to the LoP task in the other two
conditions. We wanted to make sure that study time was
equated across the three groups of participants.
The 60 items in the levels of processing task represented 5
replications of each presentation format (picture, spoken
word, printed word) by levels of processing (shallow, deep)
by response type (yes, no) condition. Response times and
accuracy were recorded on each trial of the levels of
processing task.
Hit and false alarm rates were calculated from the yes
responses to the recognition test. Hit rates were calculated
from the number of times the participants correctly
identified an old item and false alarm rate noted the number
of times a new item was incorrectly labeled as old. To
correct for guessing, recognition memory scores were
computed by subtracting the proportion of false alarms from
the proportion of hits. Confidence ratings were combined
with the recognition responses to produce a 6-point scale
where 6=very confident yes, 5=somewhat confident yes,
4=not very confident yes, 3=not very confident no,
2=somewhat confident no, 1= very confident no.

Results

Recognition memory test contained a list of 120 item
names presented alphabetically. The 60 old items were
mixed together with 60 new items matched for concept
frequency with the old items and selected from the same
item pool. For each item the participant wrote a yes/no to
1050

Table 1 presents the means computed from the recognition
memory scores and confidence scale data for each
participant across the 10 items within each of the
presentation format by level of processing conditions. Data

from one participant in the intentional study condition was
removed because the participant’s performance was at
chance.
Data from the remaining 49 participants were
analyzed with a 2 X 3 X 2 ANOVA where study condition
was
between-subjects
(i.e.,
intentional/incidental
processing) and presentation format (i.e., pictures, spoken
words, and printed words) and level of processing (i.e., deep
and shallow) were within-subjects.
Recognition memory. The analyses on recognition memory
and confidence scores were similar so only the ANOVA on
recognition scores are reported. Study condition was found
to interact with presentation format and LoP, F (2, 94) =
3.73, p < .03, η2 = .07. There was also a significant
interaction of study condition with LoP, F (1,47) = 7.05, p <
.01, η2 = .12. The interaction of condition by format was
not significant F (2, 94) = 2.33, p < .10. There were also
significant main effects of presentation format, F (2, 94) =
15.04, p < .01, η2 = .25; and LoP, F (1,47) = 330.32, p < .01,
η2 = .88;. However, there was no main effect of study
condition, F (1,47) = 1.30, p < .26.
To understand what was happening to recognition
memory with these complex interactions, simple
interactions of presentation format by LoP were conducted
for each of the study conditions. Under incidental study, the
effects of presentation format were found only when items
were shallowly encoded. For those items, pictures were
recognized more readily than either spoken or printed
words. When items were deeply encoded, there were no
differences evident across presentation formats. There was
a significant interaction effect of format by LoP, F (2, 48) =
3.97, p = .027, η2 = .14; and follow-up within subject
contrasts (at p<.05 significant level) showed no format
differences with deeply processed items and an advantage
for pictures relative to the other format conditions with
shallow processed items. The analysis on the incidental
study condition also showed two significant main effects of
presentation format, F (2, 48) = 7.31, p = .01, η2 = .23; and
LoP, F (1,24) = 198.16, p = .01, η2 = .89. As expected the
main effect of LoP indicated that recognition memory was
higher for deep rather than shallow processed items. In the
intentional study condition, there were similar main effects
but no interaction effect. Pictures were recognized better
than the other two formats, F (2, 46) = 10.36, p = .01, η2 =
.32; and recognition was higher for deeply encoded items, F
(1, 23) = 134.53, p = .01, η2 = .86. The interaction was not
significant, F < 1. The data from the control condition was
also treated with a repeated measures analysis; and these
data show a strong effect of presentation format, F (2, 40 =
24.92, p = .01, η2 = .55. Follow- up within subject contrasts
(at the p<.05 ) showed that pictures (.64) were remembered
better than words and spoken words (.47) better than printed
words (.34).
Table 1:Mean (SD) recognition scores
______________________________________________
Condition
Recognition
Confidence Score

______________________________________________
Incidental—Deep
Picture
.69 (.17)
4.9 (.7)
Spoken Word
.64 (.22)
4.7 (.8)
Printed Word
.69 (.19)
5.0 (.8)
Incidental—Shallow
Picture
.37 (.20)
3.5 (.9)
Spoken Word
.15 (.20)
2.6 (.9)
Printed Word
.23 (.20)
3.0 (.9)
Intentional—Deep
Picture
.68 (.17)
5.3 (.6)
Spoken Word
.55 (.25)
4.7 (.8)
Printed Word
.54 (.23)
4.6 (.9)
Intentional—Shallow
Picture
.35 (.18)
3.9 (.7)
Spoken Word
.27 (.19)
3.6 (.8)
Printed Word
.20 (.18)
3.3 (.8)
Control
Picture
.64 (.18)
5.2 (.6)
Spoken Word
.47 (.19)
4.4 (.7)
Printed Word
.34 (.19)
3.8 (.9)
______________________________________________
Note. Confidence was measured on a 6-point scale (1 = not
very confident no 2 = somewhat confident no 3 = very
confident no 4 = not very confident yes 5 = somewhat
confident yes 6 = very confident yes) Discussion
As expected, under the control condition both pictures and
spoken words produced superior performance to printed
words. This replicates previous work on picture superiority
and long-term modality effects. However, when individuals
were directed to process each presented item at a deep or
shallow level, the advantage of pictures and spoken words
over printed words was greatly reduced and, in the
incidental/deep processing condition, entirely eliminated.
These results provide strong support for the attention
allocation model (Foos & Goolkasian, 2005). When
participants’ attention is fully focused on semantically
processing the stimulus item, the item’s format does not
influence recognition from long-term memory. A small
effect of format is found in the intentional learning
condition when participants are aware that a memory test
will occur however the format effect is limited to a picture
advantage. Differences are not found for recognition of
material presented in spoken and printed word formats.
The present results also support the sensory-semantic
model of picture memory (Nelson, 1979).
Pictures
produced superior performance in both intentional learning
conditions and in the incidental shallow processing
condition. As expected, with few processing questions,
pictures were better remembered following deep processing
than after shallow processing (e.g., Intraub & Nicklos,
1985). The expected interaction between LoP condition and
format, whereby the difference between pictures and the
other formats would be greater when a shallow task was
used, was obtained.
While the present findings support the attention allocation
model of format effects and Nelson’s sensory-semantic

1051

recalled at a higher rate than spoken (.24) or printed words
(.22).
When a LoP task is required and conscious attention is
thereby directed to semantic processing irrespective of
presentation format, then memory differences between the
verbal formats disappear. The only lingering format effects
are associated with pictures. The previously obtained
reduction (i.e., Experiment 1) cannot be attributed to a test
format that offers some advantage to printed words. In the
present experiment any advantage resulting from such
coding was eliminated by the use of an auditory recall task.
Pictures were again remembered better than words even
though the levels of processing were equivalent.

model of picture superiority, there is a need to see if similar
findings occur when test format is changed. A number of
recent studies suggest that printed words are coded
orthographically as well as semantically and phonologically
(e.g., Cleary & Greene, 2002; Gallo, McDermott, Percer, &
Roediger, 2001). Perhaps the improved recall of printed
words in the present experiment is due, in part, to
orthographic coding for printed words and use of a visual
recognition test of memory. Experiment 2 is designed to
test this hypothesis by eliminating any advantage
attributable to orthographic coding for printed words.

Experiment 2

Experiment 3

The intentional and the control conditions from Experiment
1 were run with the same procedure except that an auditory
recall task replaced the written recognition test. Twenty
seven participants, drawn from the same subject pool as E1,
were in the intentional study condition and 32 were in the
control. The materials and procedure were the same as the
previous experiment except that participants were asked to
verbally recall as many of the presented words as they
could. Minimum recall time was 5 minutes.
Table 2: Mean (SD) proportion of items recalled.
________________________________________________
Condition
Mean SD
________________________________________________
Intentional--Deep
Picture
.40
.15
Spoken Word
.21
.13
Printed Word
.22
.15
Intentional--Shallow
Picture
.15
.13
Spoken Word
.08
.07
Printed Word
.12
.09
Control
Picture
.37
.17
Spoken Word
.24
.12
Printed Word
.22
.16
________________________________________________

In Experiment 3 we again used the levels of processing task
but this time the questions required only deep processing
and half of the old items presented in the recognition test
were in a changed presentation format. We were interested
in whether participants would be able to recognize an item
as being presented in the study phase even when it appeared
in a changed format at test. Participants were not informed
about the memory test and they were not informed about the
change in presentation format. Since the LoP instructions
ask participants to focus on processing the items
semantically, there is no need to retain any information
about presentation format.
The present study also examines the richness of the visual
and semantic codes for pictures compared to verbal items.
If the long-term visual representation of pictures is richer
than that for verbal items, as suggested by Larkin and
Simon (1987), then one would expect to find picture
superiority when study and test format are the same. This
superiority should be absent when study and test formats
differ since, in that case, only semantic information can be
used.

Method

Results and Discussion

The participants were 27 students drawn from the same
subject pool as the previous experiments. The study
materials were the same 60 items used in Experiments 1 and
2 and the item list was comprised of 20 pictures, 20 spoken
words and 20 printed words. Three versions of the stimulus
list were developed to counterbalance item format across
participants.
The recognition memory test consisted of 120 items—60
old and 60 new items. Half of the old items in each of the
format conditions were presented in the same format at
study and test, and the remaining half of the items appeared
in a different format. When an item appeared in a different
format an effort was made to change the format an equal
number of times into each of the two remaining formats so
that across all of the old items that appeared with a different
format there were an equal number of pictures, spoken
words and printed words.

Table 2 presents the mean recall. Significantly more items
presented as pictures (.27) were recalled than items
presented as spoken (.14) or printed (.18) words, F (2, 50) =
12.43, p < .01, η2 = .33. Deep processing led to higher
recall (.28) than shallow processing (.12), F (1, 25) = 87.79,
p < .01, η2 = .77, and processing level interacted with format
condition, F (2, 50) = 6.80, p < .01, η2 = .21. The picture
advantage was more evident with deeply processed items
than with shallow items. However, consistent with the
results of Experiment 1, there were no differences between
long-term memory for spoken and printed words. For the
control group, there was only a significant effect of format,
F (2, 62) = 30.58, p < .01, η2 = .50. Pictures (.37) were

1052

switched. However, when the change involved pictures the
fall in recognition was 30% (from .73 to .43). Follow-up
within subject contrasts (at p <.05 level of significance)
showed that these drops in recognition were significantly
different from each other and from the recognition rate for
the old items presented in the same format.

The new items were matched in concept frequency with
the old items and selected from the same item pool. The test
items were presented in a different random order for
each of the participants. Recognition test items appeared
one at a time on the screen and participants used the number
keypad to respond to the question “Was this item
presented in the study list?” For the spoken items, the sound
file played while the response scale was shown on the
screen.
All participants were run individually in 20 minute
sessions. They studied each of the items under incidental
learning instructions. Following the levels of processing
task, participants were asked to engage in the filler task of
counting backwards. After that they took the computerized
recognition test with 120 items.

Results and Discussion
Mean proportion of yes responses to the recognition test are
presented in Figure 1. To correct for guessing, mean
recognition scores were calculated by subtracting the
proportion of false alarms from the proportion of hits. A
repeated measures analysis was conducted separately on the
recognition scores and the confidence scale data. Since the
results of both analyses were the same, only the recognition
analysis is reported.
There were significant main effects of presentation format
F (2.52) = 6.89, p < . 01, η2 = .21; and same/different test
item, F (1.26) = 32.12, p < . 01, η2 = .55. The analyses also
showed significant interaction effects of presentation format
and test conditions, F (2,52) = 8.25, p < . 01, η2 = .24. The
type of test item showed the strongest effect. When
corrected for guessing, recognition of old items presented in
the same format at study and test (.73) were significantly
higher than recognition of old items presented in a different
format (.46). And the old items with the changed format
were recognized more often than new items (.09; this is, of
course, a false alarm rate). Follow-up within subject
contrasts (at p < .05 level of significance) showed that
format differences within each of these item types were very
different. As can be seen in Figure 1, format effects are
totally absent when the test format is different from the
study format. When, however, study and test formats are
the same a distinct advantage for pictures over the two
verbal formats is evident. The recognition rate is highest
with pictures in the same format compared to other
conditions.
Since this study was primarily interested in responses to
the old items presented in different formats, we calculated
mean recognition and confidence scale data for each of the 6
possible study-test change conditions. When the 9
conditions were analyzed with a single factor repeated
measures design, significant differences were found among
the conditions, F (8,208) = 14.84, p < .01. Recognition
memory and confidence scale data showed that changes
between spoken and printed words were not as recognizable
as changes to or from pictures. Recognition scores fell
around 11% (from .67 to .56) when verbal formats were

Discussion
These findings show that presentation formats are not
irrelevant for recognition from long-term memory.
Recognition memory and confidence scores were
significantly higher when old items appeared in the same
format in the study and test phases. On average, recognition
dropped 27% when old items appeared in a different format.
Since an incidental leaning task was used, these format
results suggest some automatic coding of format for spoken
and printed words and not just for pictures (Intraub &
Nicklos, 1985).
The fact that recognition memory and confidence scores
were higher for old items presented in picture format
provides support for those who believe that pictures are
more richly coded (e.g., Larkin & Simon, 1987). Moreover,
it made a difference whether the change in format at test
involved a switch between the two verbal formats or
between picture and verbal formats. Changes to or from
pictures were more noticeable than changes between the
spoken and printed words.

General Discussion

1053

When taken together these findings show that varying the
manner of encoding by using LoP tasks and instructions for
incidental/intentional learning can have significant effects
on the pictorial advantage and the advantage of spoken over
written words. The pictorial advantage was consistently

obtained in all three experiments while the advantage of
spoken over written words was eliminated when participants
were asked to process the stimulus items semantically and
no memory test was expected. Additionally, the effects
were obtained when both visual and auditory recognition
and recall were used.
These findings contribute theoretically by providing
support for sensory semantic models to explain picture
processing and the attention allocation hypothesis for verbal
material. In contrast to our earlier prediction, however, both
theories are necessary to explain presentation format effects
on memory. The attentional allocation hypothesis is not
sufficient by itself to explain the picture advantage in long
term memory. On a more practical level these findings
help to identify some principles to guide efficient processing
of and memory for stimulus information.
When a LoP approach was used to control the level of
processing required, we found evidence for a strong
although not exclusive role of attention to conscious
processing underlying effects of presentation format. In
Experiment 1 when participants were required to
semantically process the stimulus items with no expectation
of a memory test (incidental study), long-term recognition
was comparable in spite of presentation format differences
in study items. A general principle is then that focused
processing can diminish format effects and when that
processing is semantic, format effects can be eliminated.
An effect of presentation format is found when
participants are aware that a memory test will follow. The
awareness of a memory test improves recognition for items
presented as pictures compared to both spoken and printed
words. The picture advantage can be explained by the
sensory-semantic model of picture memory (Nelson,
1979; Nelson et al, 1977) because pictures are not just well
attended but also have a more direct link with semantic
processing and a richer encoding (Larkin & Simon, 1987).
A second general principle is that pictures are remembered
better when individuals expect a memory test and/or are
occupied by a shallow processing task.
The effect of presentation format on long-term memory
was particularly evident in the findings from Experiment 3
when we compared recognition for items presented in
same/different formats during study and test phases of the
experiment. Recognition of items presented in the same
format was better than items presented in a changed format.
This finding provides some evidence that information about
presentation format is retained together with semantic
information and that this automatic retention of format
occurs for spoken and printed words in addition to pictures

(Intraub & Nicklos, 1985). A third general principle is that
performance is best when study and test formats match.

Acknowledgments
These experiments were partially supported by an NSF
grant (Award #SES-0552160). Thanks are due to Amina
Saadaoui, Taylor Grayson, and Teneya Mormon for their
assistance with data collection and data analysis.

References
Cleary, A. M., & Greene, R. L. (2002). Paradoxical effects
of presentation modality on false memory. Memory, 10,
55-61.
Craik, F. I. M., & Lockhart, R. S. (1972). Levels of
processing: A framework for memory research. Journal
of Verbal Learning & Verbal Behavior, 11, 671- 684.
Foos, P. W., & Goolkasian, P. (2005). Presentation format
effects in working memory: The role of attention.
Memory & Cognition, 33, 499-513.
Gallo, D. A., McDermott, K. B., Percer, J. M., & Roediger,
H. L., III (2001). Modality effects in false recall and
false recognition. Journal of Experimental Psychology:
Learning, Memory, & Cognition, 27, 339-353.
Goolkasian, P., & Foos, P. W. (2002). Presentation format
and its effects on working memory.
Memory &
Cognition, 30, 1096-1105.
Greene, R. L. (1985). Constraints on the long-term
modality effect. Journal of Memory & Language, 24,
526-541.
Intraub, H., & Nicklos, S. (1985). Levels of processing
and picture memory: The physical superiority effect.
Journal of Experimental Psychology: Learning, Memory,
& Cognition, 11, 284-298.
Kosslyn, S. M. (1980). Image and mind. Cambridge, MA:
Harvard U. Press.
Nelson, D. L. (1979). Remembering pictures and words:
Appearance, significance, and name. In L. S. Cermak &
F. I. M. Craik (Eds.), Levels of processing in human
memory. Hillsdale, NJ: Erlbaum.
Nelson, D. L., Reed, V. S., & McEvoy, C. (1977).
Encoding strategy and sensory and semantic interference.
Memory & Cognition, 5, 462-467.
Paivio, A. (1975). Perceptual comparisons through the
mind’s eye. Memory & Cognition, 3, 63-647.
Penney, C. G. (1989). Modality effects and the structure of
short-term verbal memory. Memory & Cognition, 17,
398-422.

1054

