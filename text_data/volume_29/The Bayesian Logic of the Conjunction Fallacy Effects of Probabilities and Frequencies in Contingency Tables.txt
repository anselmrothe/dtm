UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Bayesian Logic of the Conjunction Fallacy: Effects of Probabilities and Frequencies in
Contingency Tables
Permalink
https://escholarship.org/uc/item/40g5b899
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Author
Momme, Momme Momme
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                      University of California

                                  The Bayesian Logic of the Conjunction Fallacy:
                    Effects of Probabilities and Frequencies in Contingency Tables
                               Momme von Sydow (momme.von-sydow@bio.uni-goettingen.de)
                                              Department of Psychology, Universität Göttingen,
                                                Gosslerstr. 14, D-37073 Göttingen, Germany
                               Abstract                                    is the union of n other disjoint subsets of events Ei is the
                                                                           sum of the probabilities of those subsets:
   In this paper a Bayesian logic of the conjunction fallacy (CF)
   is advocated as a normative and descriptive proposal for
                                                                                      P( E1 ∪ E 2 ∪ ... ∪ E n ) = ∑ P ( Ei )            (2)
                                                                                                                    i
   testing hypotheses about dyadic logical connectors. Accor-
   ding to traditional extensional probability a violation of addi-           There are alternative calculi of probability or belief which
   tivity and, in particular, a violation of P(A) ≥ P(A ∧ B) or of         have abandoned or extended the axioms of probability
   P(Linda is a bank teller) ≥ P(Linda is a bank teller AND an             theory. In our context, the most prominent approaches are
   active feminist) is a fallacy. The psychological literature has         the Dempster-Shafer theory of belief functions, Cohen’s
   adopted this interpretation. In contrast, the proposed Bayesian         Baconian probabilities, and different formalizations of
   model formulates qualitative as well as quantitative condi-             multi-valued or fuzzy logic (cf. e. g., Hájek, 2001, Hayek,
   tions under which such a judgment is reasonable. Qualitati-             2003). The belief functions postulated by Dempster-Shafer
   vely, the model is applicable to situations in which probabili-         theory are non-additive, but they meet the requirement of
   ties have to be taken (or are taken) not directly as extensional        Equation 1. Likewise, the Baconian probability of a con-
   probabilities, but as (posterior) probabilities for alternative         junction violates Equation 2 – it is equal to the minimum of
   logical hypotheses about whole situations. If the preconditions         the probabilities of their conjuncts, but does not violate
   of the model are given, Bayesian logic should be applicable to          Equation 1. Finally, in multi-valued or fuzzy logic there are
   novel situations, like highly transparent tasks, even if frequen-       quite different t-norms (Łukasiewicz, Gödel, product), but
   cy information is provided in a fully specified contingency
                                                                           these t-norms are all consistent with P(A) ≥ P(A ∧ B).
   table. Quantitatively, the model makes predictions about the
   effects of extensional probability patterns and resulting
   Bayesian probabilities and corresponding ‘CFs’. Additionally,           The Conjunction Fallacy Debate in Psychology
   while keeping the probability patterns constant, the model              When Tversky and Kahneman (1983) initiated a broad psy-
   predicts effects of different underlying frequencies (sample            chological debate on the conjunction fallacy as a corner-
   sizes). In the experiment two quantitative factors were varied          stone of their ‘heuristic and biases’ program, they took the
   using highly transparent tasks with explicit frequency                  conjunctive rule (1) as a general norm of rational thought.
   information in a contingency table. Despite using these strict             The conjunction debate was mostly concerned with tasks
   conditions, the results supported the predicted occurrence of
                                                                           of the sort of the Linda task. In this task subjects read:
   ‘double CFs’ and the differential effects of sample size.
                                                                           “Linda is 31 years old, single, outspoken, and very bright.
   Keywords: Bayesian logic, conjunction fallacy, probability              She majored in philosophy. As a student, she was deeply
   theory, hypothesis testing, noise, frequency format, logic              concerned with issues of discrimination and social justice,
                                                                           and also participated in anti-nuclear demonstrations.”
                                                                           Subjects were asked to rank several statements about Linda
  The Additivity of Probability in Classical and                           to their probability, including: “Linda is a bank teller” (T)
           Non-Classical Probability Theories                              and “Linda is a bank teller and she’s active in the feminist
                                                                           movement” (T and F). Tversky and Kahneman (1983) found
It is a basic truth of standard extensional probability theory
                                                                           that a majority of subjects judged ‘T and F’ to be more
that the probability of a set X can never become larger than
                                                                           probable than ‘T’ and concluded that subjects committed a
the probability of a set Y if the latter has a larger extension            conjunction fallacy (CF) due to ‘representativeness’ of ‘F’.1
than the former (inclusion rule). Applied to logical                          In the subsequent debate all aspects of the task and its
connectors and, particularly, to conjunctions, no conjunction              interpretation became objects of closer scrutiny.
‘A ∧ B’ can be more probable than one of its conjuncts, ‘A’                   One group of objections concerned subtle linguistic or
or ‘B’, since the intersection of both is a subset of each                 pragmatic aspects of the task which makes the interpretation
conjunct. The conjunction is true for A & B cases only,                    of ‘T’ as well as of ‘T and F’ logically ambiguous, perhaps
whereas, for instance, the conjunct ‘A’ is additionally true               exculpating participants from committing a fallacy. A
for A & non-B cases. Correspondingly, probabilities have to                precondition for calling a judgment a ‘conjunction fallacy’
satisfy the (extensional) conjunction rule:                                is that natural language roughly corresponds to the meant
                                                                           ideal connectors in the first place.
                P(A) ≥P(A ∧ B); P(B) ≥ P(A ∧ B)                    (1)        Firstly, in natural language ‘A and B’ is not always to be
                                                                           interpreted as a conjunction ‘A ∧ B’, with the common truth
   Taking the classical axioms of probability theory of
Kolmogorov, this can be derived directly from his third                    1
                                                                             Conjunction tasks which have been explained by availability are
axiom (σ-additivity): The probability of an event set which                not topic of this paper.
                                                                       1617

table function ‘1, 0, 0, 0’ (for A & B, A & ¬B, ¬A & B,             they do not prove a violation of internal inconsistency (also
¬A & ¬B). As Hertwig (1997, cf. Mellers, Hertwig &                  affecting Mellers, Hertwig, and Kahneman, 2001, findings).
Kahneman, 2001) made clear, the sentence “we invite                    Hertwig and Chase (1998) showed that besides a fre-
friends and colleagues to the party” often implies an               quency format an estimation response mode also reduces
inclusive disjunction of friends and colleagues (with a truth       CFs. Hertwig and Gigerenzer (1999) showed that the word
function ‘1, 1, 1, 0’), not their intersection. Hertwig sug-        ‘probability’ is polysemous, whereas the natural language
gested that the phrase ‘bank tellers who are active in the          sense of frequency ‘is primarily mathematical’. Sloman,
feminist movement’ would exclude this unintended interpre-          Over, Slovak and Stibel (2003) emphasised the importance
tation as union, not testing true CFs. In Mellers, Hertwig          of the ranking vs. rating responds mode and suggested that
and Kahneman (2001), Kahneman conceded that ‘and’                   ranking may lead to understanding the options as alter-
might have indeed been semantically ambiguous. However,             natives. Recently, the existence of CFs was also shown by
in regard of Hertwig’s ‘who are’ formulation he objected            Tentori, et al. (2004) in transparent within-subject tasks both
that this phrase is also inadequate, since it too strongly cued     with a probability and a frequency format and also by Sides,
participants to interpret AND as a subset only. In their ad-        Osherson, Bonini and Viale (2002) in betting contexts.
versarial collaboration they settled on an “and are” formula-
tion (we shall even use the stricter ‘who’ formulation). Their                          The Bayesian Logic
between-subject tests in a frequency format did not lead to a                      of the Conjunction Fallacy
clear decision of their dispute (Mellers, et al. 2001).
   Secondly, a proposition ‘A’, if presented in the context of      Building on the result that ‘probability’ is polysemous (cf.
a proposition ‘A and B’, needs not to be interpreted as the         Hertwig and Gigerenzer, 1999), a specific interpretation of
dyadic connector ‘affirmation A’ (with the truth function ‘1,       probability is proposed that differs from standard
1, 0, 0’), but it may be interpreted as ‘A but not B’ (‘0, 1, 0,    extensional probability but is neither non-mathematical nor
0’). “Linda is a bank teller and is active in the feminist          irrational. Bayesian logic provides probabilities about hypo-
movement” might itself prompt an interpretation of “Linda           theses concerning dyadic logical relations and whole
is a bank teller” as “Linda is a bank teller and not active in      situations (not particular cases, as in other Bayesian accounts:
the feminist movement”. Actually, Tversky and Kahneman              e. g. Fisk, 1998, cf. e. g. the BLOG model in machine
(1983) themselves in one experimental condition aimed to            learning). Although the proposed Bayesian logic may well
remove this problem by using the phrase “Linda is a bank            be applicable more generally, the current article is confined
teller whether or not she is active in the feminist                 to the discussion of the conjunction fallacy.
movement”, but this only partially reduced the number of               The advocated Bayesian logic is related to Oaksford and
observed CFs. However, Hilton (1995, 260, cf. Tentori,              Chater’s Bayesian optimal information gain approach
Bonini & Osherson, 2004) noted that this formulation might          (Oaksford and Chater, 2003) elaborated for the Wason
still be misinterpreted as asserting that Linda is a bank teller    selection task (for an extension to different probabilistic
even if she is a feminist. Moreover, Tversky and Kahneman           connectors, see von Sydow, 2006). However, the Bayesian
did not simultaneously remove the other mentioned mis-              logic advocated here is a model of hypotheses evaluation
understanding. Actually, Macdonald and Gilhooly (1990, cf.          based on complex data patterns integrating over many noise
Tentori et al., 2004) did observe a much larger reduction           levels and not one of information selection which is only
with some problem alterations and the wording “Linda is a           concerned with single data points and one noise level.
bank teller who may or may not be active in the feminist               The proposed Bayesian logic of hypothesis testing
movement” (we shall use a similar formulation).                     (‘Bayesian logic’ for short) inherits aspects of probability
   Another group of objections concerned the concepts of            theory and of propositional logic of dyadic connectors.
probability and of representativeness. Fiedler (1988) men-          Nonetheless, it does not subscribe to the inclusion rule or,
tioned alternative understandings of the term ‘probability’         more particularly, to the conjunction rule. Based on an
and experimentally significantly reduced the portion of CFs         observed pattern of data, D, given in a 2 × 2 contingency
by using a frequency formulation instead (cf. Tversky &             matrix, the Bayesian model specifies the posterior probability,
Kahneman, 1983). Gigerenzer (1991, cf. 1996) criticised             P(H|D), of different ‘logical’ hypotheses, Hk, like ‘pupils
Kahneman and Tversky’s bias and heuristic approach and              from the Linda school generally become bank tellers’ (B) or
argued that the errors in probabilistic reasoning, like CFs,        they ‘generally become bank tellers and feminists’ (A and B).
are in fact not violations of probabilistic theory, since from         (1.) Similar to other kinds of multi-valued or fuzzy logics,
a frequentist perspective extensional probability theory is         this probabilistic Bayesian logic replaces the two values ‘true’
not applicable to single events. Kahneman and Tversky               (‘T’ or ‘1’) and ‘false’ (‘F’ or ‘0’) of bivalent propositional
(1996) objected that giving up the inclusion rule for single        logic by instead admitting truth values in the whole interval,
events leads to normative agnosticism and empirically they          [0, 1], normally used for probabilities. On the logical side,
showed CFs also to occur in a frequency format, at least in         Bayesian logic is basically still concerned with all 14
between-subject tasks. Gigerenzer (1996) defended his               possible dyadic connectors, i, of propositional logic (like
position and objected to a content-blind application of             AND, OR, etc.) which may relate any atomic propositions A
norms like the conjunction rule and to vague heuristics, like       and B, A i, B, without tautology or contradiction.
‘representativeness’, as one-word explanations. To                     (2.) More specifically, Bayesian logic assesses proba-
Gigerenzer, between-subject designs are not decisive, since         bilities for hypotheses PH(X) that concern patterns of pro-
                                                                    babilities or ‘probability tables’ (PTs), probabilistic
                                                                    analogues to deterministic truth tables. PTs are hypothetical
                                                                1618

Tables 1a, b, c. Probability tables for three different connectors i and different uncertainty levels R = r.
 Table 1a                                           Table 1b                                                 Table 1c
 A AND B              B       Non-B                 ONLY A               B          Non-B                    A OR B                 B      Non-B
 A              t - (t-c)r cr                       A              t - (t-c)r t - (t-c)r                     A               t - (t-c)r t - (t-c)r
 Non-A          cr          cr                      Non-A          cr             cr                         Non-A           t - (t-c)r cr
Note: The probability c of convergence for maximal uncertainty is here set to .25.
constructs that can be tested against data. Dyadic Bayesian
                                                                                                               n         x1 x2 x3 x4
logic is confined to PTs based on tuples of four probabilities                    P ( x l | n, p m ) =                  p1 p 2 p 3 p 4 (3)
(P(A ∧ B) + P(A ∧ ¬B) + P(¬A ∧ B) + P(¬A & ¬ B) = 1).                                                    x1 x 2 x 3 x 4 
   (3.) Logical connectors and hypotheses about probability
                                                                                (5.) In order to calculate the posterior probabilities of each
tables are linked by the two assumptions of idealization and
                                                                             combination of connector and uncertainty level, Hk, given the
uncertainty. According to the assumption of idealization the
                                                                             observed pattern of data, D, Bayes’ theorem is used:
connector is based on a deterministic relation with a
basically equal probability distribution for true cases. The                                                  P( D | H k ) P( H k )
                                                                                          ´ P( H    | D) =                                         (4)
assumption of uncertainty (noise, error, risk, or randomness)                                     k
assumes some general level of uncertainty R for a natural set                                                           P( D)
of observations of a relation. This corresponds to the fact
                                                                                The normalizing probability P(D) of the data D under all
that we live in an uncertain world, with only probabilistic
                                                                             hypotheses Hk (connector-uncertainty combinations, i × Rj )
relations (objective uncertainty) or limited knowledge
                                                                             is calculated by:
(subjective uncertainty). Rational models of testing hypotheses
about logical relations under uncertainty are needed. Only in
the borderline case of R = 0 a single disconfirmatory case                                   P(D) =     ∑ P(D | H
                                                                                                        k =1
                                                                                                                           k )P ( H k )            (5)
should falsify a hypothesis. The model asserts that uncer-
                                                                                As simple measure of information gain, one can calculate
tainty/noise is equally distributed over the PT. The actual R
                                                                             the impact of the data on the probability of each hypotheses:
value r (0 ≤ r ≤ 1) may be fixed by prior knowledge or can be
calculated from the model itself.
                                                                                     PDiff ( H k , D ) = P ( H k | D ) − P ( H k )                 (6)
   Mathematically, the probability of a false case in a PT with R
= 0 is zero: P(F°i) = f = 0. The probability of a true case, P(T),
                                                                                Since we are here concerned with logical hypotheses (Hi
in such a PT is weighted by the number of true cells of the
                                                                             = i) without a specified error level, and since we
connector under investigation: P(T°i | R = 0) = 1 / N(T°i) = t (cf.
                                                                             calculated the posterior error levels from the data, we have
Table 1). If the error term approaches its maximum the PTs of
                                                                             to formulate an integration rule to determine the global pro-
all connectors i in question converge at a pattern where all
                                                                             bability of the logical hypotheses in question. Here for each
cases have the same probability, c = .25. Formally, for any
                                                                             Hi the sum of the posterior probabilities over all error levels
PT(I, r) the probability of a true case T (now with noise) is t -
                                                                             rj is calculated, resulting in a probability mass function:2
r (t - c). Likewise, noise increases the zero probability of a false
case F by r multiplied with the convergence value c. This
formalization of randomness levels is coherent with the idea
                                                                                             P(H i | D) =       ∑ P(H
                                                                                                                  j
                                                                                                                              i, j | D)            (7)
that of all true cases of a connector a portion r is distributed at
random over all four possible cases (including other true cases).
Table 1 provides examples for the PTs of the hypothesis of a
                                                                                            Predictions of Bayesian Logic
conjunction ‘A AND B’, an affirmation ‘A’ and an inclusive                   Bayesian logic provides a suitable alternative to traditional ex-
disjunction ‘A OR B’. Here the error level is modeled as a                   tensional probability, not replacing it, but supplementing it.
discrete variable (in steps of .10). Please note that the combined           Bayesian logic (itself based on extensional probabilities) is
hypothesis Hk represent a connector combined with an                         meant as a rational formalization of probabilities for alternative
uncertainty level (Hk = i ∧ Rj). For the experiment, the prior              hypotheses of connectors corresponding to the whole of a
probabilities for the hypotheses Hk are assumed to be equal.                 probabilistic truth table (‘hypotheses probability’ or PH(X) for
   (4.) We now calculate the probability of some observed data               short). In contrast, extensional probability theory provides us
pattern given one hypothesis, P(D | Hk). A data sample, ordered              with probabilities of those subsets of a PT which are specified
in a 2 × 2 contingency matrix, D, consists of four frequencies,              by true extensions of the corresponding logical connectors
x1, x2 , x3, x4 (with Σ xl = n). The multinomial distribution gives          (‘extensional probability’ or PE(X) for short). Here we are
the discrete probability distribution P(x1, x2, x3, x4 | n, p1, p2, p3,      concerned with PH(X) in the context of the conjunction fallacy,
p4) = P(xl | n, pm) of obtaining a particular pattern of the four            considering two kinds of predictions, although only the latter
disjoint outcomes, x1, x2, x3, x4, in a total sample of n                    one is varied in our study:
independent trials given a hypothesis with the respective
probabilities p1, p2, p3, p4 (with 0 ≤ pm ≤ 1, Σ pm = 1). It has the         2
                                                                               Alternatively one may weight R values by their reciprocal, 1/ r. In
following probability mass function:
                                                                             the experiments conducted here, data sets have been used, for
                                                                             which both models lead to the same predictions.
                                                                        1619

   (1.) Qualitative predictions. From the preconditions of the                                 (2.) Quantitative predictions. Here we are particularly
model one can derive constraints for a situation in which the                               concerned with two novel predictions of the model, both di-
outlined model should be normatively and descriptively                                      stinguishing PH(X) from PE(X). According to Bayesian logic
applicable: In the reported experiment we are going to                                      there are quantitative conditions, in which a hypothesis with
construct situations in which it is plausible to understand                                 a narrower extension may have a higher hypothesis
probabilities as alternative hypotheses (cf. Hertwig &                                      probability, PH(X), than a one with a broader extension.
Chase, 1998, Sloman et al., 2003) about connectors, each                                       Firstly, one prediction is concerned with the probability
relating to a whole situation (not to a subset). If such                                    pattern given by the data if the sample sizes are large, as in
preconditions of the model are met, it is claimed that one can                              Example 1 and 2 of Figure 1. Here, whether a CF should
achieve a substantial portion of ‘conjunction fallacies’ even                               occur or not, should depend on the probability pattern of the
with extremely transparent tasks, salient frequency                                         data. Example 1 provides a data pattern under which a novel
information, and excluded misunderstandings (concerning ‘A                                  double CF effect (with PH(A) ≅ PH(B) <PH (A ∧ B)) is
and B’ and ‘A’). Here I will use explicit contingency tables                                predicted. In contrast, Kahneman and Tversky were con-
(going beyond the experiments of Sloman et al., 2003, and                                   cerned only with single CFs, if feature A is more
Tentori et al., 2002). Nonetheless, Bayesian logics (unlike                                 ‘representative’ than feature B (the prediction P(B)
e. g. Gigerenzer, 1996) predicts CFs.                                                       < P(A ∧ B)). However, for Example 1 a double focus effect
Figure 1: Graphs of information gain for three hypotheses ‘A ∧ B’, ‘A’, and ‘B’ given the observed frequencies, for each
uncertainty level (P(Hk|D)-P(Hk), r = .1 to 1.0, left) or summing up the weighted noise levels (P(Hi|D)-P(Hi), right).
                                                                                                           0, 8
                         0, 35
                                                                                                                                                                                       P (A &B | D ) - P (A &B )
    Figure 1a:
                                          P (A &B | D ) - P (A &B )
                          0, 3
                                                                                                           0, 6                                                                        P (A | D ) - P (A )
                                          P (A | D ) - P (A )
                         0, 25                                                                                                                                                         P (B |D ) - P (B )
    Example 1,
                                          P (B |D ) - P (B )                                                           P (A &B | D ) - P (A &B )
                                                                                                           0, 4
                          0, 2
    Graphs for           0, 15
                                                                                                           0, 2
                          0, 1
 frequency pattern       0, 05
                                                                                                              0
                                                                                                                                                               1
  ‘26, 13, 14, 12’.          0
                                  1   2         3                4     5   6   7   8    9     10
                                                                                                          -0, 2
                                                                                                                                                      P (A | D ) - P (A )
                                                                                                                                                                             P (B |D ) - P (B )
                        -0, 05
                                                                                                          -0, 4
                         -0, 1
                                                                                                           0, 8
                         0, 35
    Figure 1b:
                                                                                                                                                      P (A |D) - P (A )                P ( A &B | D ) - P (A &B )
                                          P ( A &B | D ) - P (A &B )
                          0, 3
                                                                                                           0, 6                                                                        P (A |D ) - P (A )
                                          P (A | D) - P (A )
                         0, 25                                                                                                                                                         P ( B |D ) - P (B )
    Example 2,
                                          P ( B |D ) - P ( B )
                                                                                                           0, 4
                          0, 2
    Graphs for           0, 15
                                                                                                           0, 2
                          0, 1
 frequency pattern       0, 05
                                                                                                              0
                                                                                                                                                               1
  ‘26, 25, 14, 12’.
                             0
                                                                                                          - 0, 2
                                  1   2         3                4     5   6   7   8    9     10
                        - 0, 05
                                                                                                                       P (A &B | D ) - P ( A &B )
                                                                                                          - 0, 4                                                             P ( B |D ) - P (B )
                         -0,1
                                                                                                             0 , 02
                         0, 04
     Figure 1c:
                                                                                                                                                                                        P ( A &B | D ) - P (A &B )
                                          P ( A &B | D ) - P (A &B )                                       0, 015
                         0, 03                                                                                                                                                          P (A | D) - P (A )
                                          P (A | D) - P (A )
                                                                                                             0 , 01                                                                     P ( B |D ) - P (B )
    Example 3,
                         0, 02            P ( B |D ) - P ( B )
                                                                                                           0, 005
                         0, 01
                                                                                                                                                       P (A | D ) - P (A )    P (B |D ) - P ( B )
    Graphs for               0
                                                                                                                   0
                                                                                                                         P (A &B | D ) - P ( A &B )                1
                                  1   2         3                4     5   6   7   8    9     10
 frequency pattern
                                                                                                          - 0, 00 5
                        - 0, 01
                                                                                                           -0 , 01
                        - 0, 02
    ‘2, 1, 1, 1’.       - 0, 03
                                                                                                          - 0, 01 5
                                                                                                           -0 , 02
                        - 0, 04
                                                                                                           0, 8
                         0, 04
                                                                                                                                                                                       P ( A &B | D ) - P (A &B )
                                          P ( A &B | D ) - P (A &B )
    Figure 1d:           0, 03
                                          P (A | D) - P (A )
                                                                                                           0, 6                                                                        P (A | D ) - P (A )
                                                                                                                                                                                       P ( B |D ) - P (B )
                         0, 02            P ( B |D ) - P ( B )
    Example 4,           0, 01
                                                                                                           0, 4
                                                                                                                                                      P (A | D) - P (A )
    Graphs for               0
                                  1   2         3                4     5   6   7   8    9     10
                                                                                                           0, 2
 frequency pattern
                        - 0, 01                                                                               0
                                                                                                                                                               1
                        - 0, 02                                                                                        P (A &B | D ) - P ( A &B )                            P ( B |D ) - P (B )
    ‘2, 2, 1, 1’.       - 0, 03
                                                                                                          - 0, 2
                                                                                                          - 0, 4
                        - 0, 04
                                                                                       1620

and for Example 2 no or only a weak single CF effect is                   (s)he regards to be most probable. Subjects were asked to
predicted (the latter point is not tested here). The Bayesian             make this judgment intuitively. The hypotheses read:
logic of hypotheses concerning whole PTs obviously differs                   A hypothesis: “Today, the girls in the Linda [Maria, etc.]
from Fisk’s (1998) Bayesian model related to extensional                  school are generally bank tellers, whether they are feminists
subsets only, which never allows for P(A ∧ B | D) > P(A | D).             or not.” (“[…] sind heute in der Regel Bankangestellte, egal
   Secondly, when keeping the probabilities PE(X) constant                ob sie aktive Feministinnen sind oder nicht.“)
the model predicts no change in the discussed Bayesian pro-                  B hypothesis: “[…] are generally active in the feminist
babilities, PH(X), provided there is a substantial sample size.           movement, whether they are bank tellers or not.”
Whereas extensional probabilities should remain unaffected                   AND hypothesis: “[…] are generally bank tellers who are
by sample size and traditional extensional sampling sta-                  active feminists” (“Bankangestellte, die”, cf. Introduction).
tistics would differ for large and medium sample sizes,                      No hypothesis (‘?’): “Based on the data no single hypo-
Bayesian probabilities should change in a specific way if the             thesis is really better supported than the other hypotheses.”
sample size is very low. Bayesian models integrate aspects
of reliability into the probability measure. The Examples 3               Results
and 4 show that despite constant extensional probabilities                  Table 3: Percentage and Number of Choosing Hypotheses
the predicted Bayesian patterns get less pronounced, but the                                    as Being most Probable
Bayesian pattern of ‘A AND B’ in Example 3 is clearly                                         A         B       AND          ?         n
more affected than the pattern ‘ONLY A’ in Example 4.                      High AND 17 % 8 17 % 8 42 % 20 25 % 12                        48
                                                                           High A         67 % 32 6 % 3 15 % 7 13 % 6                    48
                           Experiment
                                                                           Low AND 10 % 5 6 % 3 19 % 9 65 % 31                           48
The reported experiment tests the mentioned qualitative and                Low A          52 % 25 4 % 2 6 % 3 38 % 18                    48
quantitative predictions of the advocated Bayesian logics.
                                                                           Note: The predicted cells are darkened.
   Qualitatively, extremely transparent ranking tasks were
used, where all hypotheses, A & B, A and B, but no filler
hypotheses were formulated. Simultaneously, the aim was                   For each condition, Table 3 summarizes the number and
to exclude the misunderstandings concerning P(A & B) and                  percentage of participants choosing a particular hypothesis
P(A) (cf. Tentori et al. 2004). The task was conducted as                 as the most probable one. As predicted, the portion of
within-subjects task. One objective was to test whether CFs               ‘AND’ choices was significantly larger in the ‘high AND’
could even be elicited under conditions where frequency                   condition than in the ‘high A’ condition (χ2(1, n = 96) = 8.71;
information is explicitly provided in a contingency table.                p < .01). Apart from the ‘?’ answers, 56 % of the participants
   Quantitatively, the frequencies of all logical cases were              in the ‘high AND’ condition committed a ‘double CF’ (single
shown and varied according to Table 2, investigating both                 CFs were not tested). Likewise, the portion of ‘A’ choices
the effects of the probability patterns (AND versus A condi-              was lower in the ‘high A’ condition than in the ‘high AND’
tions) and of sample size (small versus large sample size).3              condition, χ2(1, n = 96) = 24.69; p < .001). Moreover, it was
                                                                          confirmed that the AND selections were significantly reduced
   Table 2: The Observed Frequencies of Different Cases in                in the ‘low AND’ relative to the ‘high AND’ condition (χ2(1,
    Different Schools/Conditions (Linda, Maria, Sara, Nina)               n = 96) = 5.98, pone-tailed < .01). In contrast, it was likewise
                                                                          corroborated that the A selections were not significantly
                A∧B           A ∧ ¬B         ¬A ∧ B        ¬A ∧ ¬B        reduced in the ‘low A’ relative to the ‘high A’ condition (χ2(1,
High AND 102                  51             52            50             n = 96) = 2.12; p = .15) and there were more A choices in the
High A          102           100            50            52             ‘low A’ than in the ‘low AND’ condition (χ2(1, n = 96) =
Low AND 2                     1              1             1              19.39; p < .001). Finally, it was shown that there were more
Low A           2             2              1             1              ‘?’ choices in the two high frequency conditions than in the
                                                                          two corresponding low frequency conditions (χ2(1, n = 96) =
   Method The 98 participants were told in the instructions               15.21; p < .001; χ2(1, n = 96) = 8.00; p < .01) and that there
that they had to find out which ‘hypotheses’ about schools are            were more such choices in the ‘low AND’ condition than in
most probable and closest to truth. In order to fulfill the               the ‘low A’ condition (χ2(1, n = 96) = 7.04; p < .01). A
preconditions of the model (alternative hypotheses interpre-              slightly different replication of the study led to similar results.
tation and whole PT interpretation) the task concerned dif-
ferent schools, such as a Linda school. Each hypothesis con-                                         Discussion
cerned a school as a whole. A 2×2 contingency table with in-              The results of the experiment were predicted by Bayesian
formation about a sample of pupils was given, using side la-              logic. The effects of probability patterns as well as the
bels like “bank tellers”, “no bank tellers” etc. (Table 2).               differential effects of sample size were corroborated.
   Each participant investigated two schools in which the ob-                The ‘high AND’ condition elicited estimations
served patterns differed both in probability and sample size.             corresponding to P(A ∧ B) > P(A) and P(A ∧ B) > P(B). The
Subjects were asked to tick for each school the option, which             expected double CFs were confirmed for the first time in
                                                                          situations with extremely transparent tasks, clear set inclusion
3
                                                                          and explicit frequency information in a contingency table.
  The predictions are almost identical to those in Figure 1. The          According to extensional probability the correct answer in the
different examples led to broader distributions and were used to          ‘high AND’ condition would have been ‘B’, but the ‘B’
visualize that there are probability distributions over error levels.
                                                                      1621

choices occurred only as often as the ‘A’ choices. It is                                  Acknowledgements
particularly problematic for the frequentist position (e. g.         I thank Björn Meder and three reviewers for helpful com-
Gigerenzer, 1996) that CFs occur even if a full contingency          ments. Thanks to my research group for inspiration. I also
table is provided.                                                   want to thank the Deutsche Forschungsgemeinschaft for a
   Furthermore, the specific predictions regarding set size          grant ‘Bayeslogik’ (Sy 111/1-1) that made this work possible.
were also confirmed. High and low sample conditions had
roughly the same extensional probabilities, but the posterior                                  References
probabilities of the tested hypotheses, PH(Hi|D), differed and
                                                                     Fiedler, K. (1988). The dependence of the conjunction fallacy
were actually judged differently. The number of answers
                                                                         on subtle linguistic factors. Psychological Research, 50,
without a clear preference rose. More importantly, as
                                                                         123-129.
predicted, in the ‘Low AND’ condition the ‘A AND B’                  Fisk, J. E. (1996). The Conjunction Effect: Fallacy or Bayesian
selection did not remain the modal answer, whereas in the                Inference? Organizational Behavior and Human Decision
‘Low A’ condition the ‘A’ selection was reduced but                      Processes, 67, 76-90.
remained predominant. This supports Bayesian logic.                  Gigerenzer, G. (1996). On Narrow Norms and Vague
   One may perhaps think that the results are post hoc also              Heuristics: A Reply to Kahneman and Tversky (1996).
explainable by another formal model in the CF debate. As                 Psychological Review, 103, 592-596.
mentioned before, Fisk’s (1996) Bayesian model, based on             Hájek, A. (2001). Probability, Logic, and Probability Logic. In
extensional subsets, does not allow for any rational CFs.                L. Goble (Ed.), The Blackwell Companion to Logic (362-
Tversky and Koehler’s (1994) support theory cannot explain               384), Oxford: Blackwell.
the results, since there should be an equal unpacking in all         Hajek, P. (2002). Fuzzy Logic. In Zelta, E. N. (Ed.), The
conditions. Replacing probability by reverse probability is              Stanford       Encyclopedia      of     Philosophy.       URL:
another plausible candidate (cf. Fisk, 1996; Hertwig &                   http://plato.stanford.edu/entries/logic-fuzzy/ (3rd Sep.).
Chase, 1998; Sides et al. 2002, p. 191-192) but it is difficult      Hertwig, R., & Chase, V. M. (1998). Many reasons or just one:
to see how one may apply this interesting idea to our                    How response mode affects reasoning in the conjunction
frequency table tasks. In traditional Linda tasks inverse                problem. Thinking and Reasoning, 4, 319-352.
probability may indeed partially exculpate participants since        Hertwig, R., & Gigerenzer, G. (1999). The ‚Conjunction
P(D|A&B) > P(D|A) appears reasonable, because “Linda is                  Fallacy’ Revisited. Journal of Behavioral Decision Making,
more likely to be single, outspoken, and so on, on the                   12, 275-305.
assumption that she is a feminist bank teller than on the mere       Kahneman, D., & Tversky, A. (1996). On the reality of
assumption that she is a bank teller” (Sides, et al., 2002, 192).        cognitive illusions. Psychological Review, 103, 582-591.
Nonetheless, in our current study there are no varying               Mellers, B. A., Hertwig, R., & Kahneman, D. (2001). Do
characteristics of Linda, but only different frequencies. Any            frequency representations eliminate conjunction effects?
single-cue explanation (Hertwig & Chase, 1998) is excluded,              Psychological Science, 12, 269–275.
since, given that this effect appears to refer to an interaction     Moutier, S., & Houdé, O. (2003). Judgement under uncertainty
of two cues, it cannot account for the novel double focus                and conjunction fallacy inhibition training. Thinking and
effects. But how to formalize inverse probability here? Using            Reasoning, 9, 185-201.
the formalization of Bayesian logic would go beyond                  Oaksford, M., & Chater, N. (2003). Optimal data selection:
previous models. Interpretations which lead to P(D|H) = 1 or             Revision, review, and reevaluation. Psychological Bulletin &
collapse with extensional probability (P(D|A&B)= PE(A&B))                Review, 10, 289-318.
have to be excluded. Interpreting P(A) as average probability        Sides, A., Osherson, D., Bonini N., & Viale, R. (2002). On the
(P(A)AV = PE(A ∧ B) + PE(A ∧ ~B)) / 2) allows for violation              reality of the conjunction fallacy. Memory and Cognition,
of the conjunction rule, but this measure would here falsely             30, 191-198.
predict CFs for the ‘high A’ condition as well. This would           Sloman, St. A, Over, D, Slovak, L., & Stibel, J. M. (2003).
not be improved, if we assumed different prior probabilities             Frequency illusions. Organizational Behavior and Human
for A ∧ B and A: Without frequency information the original              Processes, 91, 296-309.
probability P(Bank teller ∧ Feminist) would be judged to be          von Sydow, M. (2006). Towards a flexible Bayesian and
lower than the probability for its compounds. Hence, the                 deontic logic of testing descriptive and prescriptive rules:
difference between the original estimation and the resulting             Explaining Content Effects in the Wason Selection Task.
estimation given the frequencies would even clearly lead to              Doctoral dissertation, Universität Göttingen.
falsely predict CFs in the ‘low A’ condition as well.                Tentori, K., Bonini, N., & Osherson, D. (2004). The con-
   In conclusion, the results corroborate Bayesian logic and             junction fallacy: a misunderstanding about conjunction?
have not been predicted by any other theory of the CF.                   Cognitive Science, 28, 467-477.
   It remains an open question, whether the developed                Tversky, A., & Kahneman, D. (1983). Extensional versus
Bayesian logic has to be understood as a more precise                    intuitive reasoning: The conjunction fallacy in probability
formalization of the vague heuristic ‘representativeness’, or            judgment. Psychological Review, 90, 293-315.
whether it constitutes a third concept beside extensional pro-       Tversky, A., & Koehler, D. J. (1994). Support theory: A
bability and representativeness (cf. Gigerenzer, 1996,                   nonextensional representation of subjective probability.
Gigerenzer et al. 1999). In any case, Bayesian logic shows               Psychological Review, 101, 547-567.
that ‘CFs’ may (partly) not be ‘fallacies’ at all, even if we
are concerned with the evaluation of contingency tables.
                                                                 1622

