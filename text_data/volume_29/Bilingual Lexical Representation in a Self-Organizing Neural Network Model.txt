UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Bilingual Lexical Representation in a Self-Organizing Neural Network Model
Permalink
https://escholarship.org/uc/item/5qd578w7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Zhao, X.
Li, P.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

       Bilingual Lexical Representation in a Self-Organizing Neural Network Model
                                                Xiaowei Zhao (xzhao2@richmond.edu)
                                                      Ping Li (pli@richmond.edu)
                                           Department of Psychology, University of Richmond
                                                          Richmond, VA 23173 USA
                              Abstract                                      The DevLex and DevLex-II models have been developed
   In this paper we present a self-organizing neural network
                                                                         to capture the interactive developmental dynamics in
   model of bilingual lexical development. We focus on how the           language acquisition. These models rely on simple but
   representational structure of the bilingual lexicon can emerge,       powerful computational principles of self-organization and
   develop, and change as a function of the learning history. Our        Hebbian learning. We have applied them successfully to
   results show that (1) distinct representations for the two            account for a variety of empirical phenomena in early
   lexicons can develop in our network during simultaneous               monolingual lexical development (see Li et al., 2004; Li,
   acquisition, (2) the representational structure is highly             Zhao & Macwhiney, 2007). Here we apply a variant of the
   dependent on the onset time of L2 learning if the two
   languages are learned sequentially, and (3) L2 representation         DevLex-II model to the bilingual context and focus on how
   becomes parasitic on L1 representation when L2 learning               the representational structure of the bilingual lexicon can
   occurs late. The results suggest a dynamic developmental              emerge, develop, and change as a function of the learning
   picture for bilingual lexical acquisition: the acquisition of two     history. In particular, we manipulate the onset time of L2
   languages entails strong competition in a highly interactive          lexical learning, in three scenarios: simultaneous – onset
   context and limited plasticity as a function of the timing of         time of L2 co-occurs with that of L1, early learning – onset
   learning.
                                                                         time of L2 is slightly delayed relative to that of L1, and late
   Keywords: SOM; DevLex; Bilingual Lexicon.                             learning – onset time of L2 lags significantly behind that of
                                                                         L1. We hypothesize that the representational structure for
                           Introduction                                  the two lexicons in our model would differ as a function of
Mechanisms underlying early bilingual lexical acquisition are            the learning history defined by L2 onset time. In addition,
so far poorly understood. This lack of knowledge may be                  through analyzing the model’s comprehension and
partly due to the methodological limitations associated with             production errors, we hope to show how the two developing
studying young bilingual children at early stages of language            lexicons compete and interact with each other.
development (e.g., Bialystok, 2001). Work in the
monolingual context has shown that neural network models                                         The Model
are ideally suited for identifying mechanisms of early lexical
acquisition (e.g., Li, Farkas & MacWhinney, 2004; Regier,
2005). Unfortunately, the gap between neural networks and
bilingualism is still wide open: to date, there have been only a
handful of neural network models that are designed
specifically to account for bilingual language processing and
representation (see reviews in Li & Farkas, 2002; French &
Jacquet, 2004; Thomas & van Heuven, 2005). Furthermore,
no neural network model has been devoted to capture the
impact of developmental time on bilingual children’s lexical
representations. Our study here attempts to bridge the gap by
examining bilingual lexical representations with a self-
organizing neural network.
   An issue of enduring interest in bilingualism has been
whether bilingual representation takes the form of a single,
shared lexical storage or a separate, distinct storage in the
mental lexicon (see French & Jacquet, 2004 and Kroll &
Tokowicz, 2005 for recent reviews). The issue has been                      Figure 1: DevLex-II (Li, Farkas, & MacWhinney, 2007)
highly controversial, and has recently been further
complicated by conflicting neuroimaging data (see Hernandez              A Sketch of the Model
& Li, 2007), but researchers have come to recognize that a               DevLex-II is a multi-layer self-organizing neural network
host of variables must be taken into consideration in dealing            model as diagrammatically depicted in Figure 1 (see Li, et
with this issue, such as bilingual proficiency, learning history         al. 2007 for details). It includes three basic levels for the
(including age of acquisition), modality (comprehension vs.              representation and organization of linguistic information:
production), and word types (cognates vs. noncognates,                   phonological content, semantic content, and output
abstract vs. concrete words).                                            sequence of the lexicon. The core of the model is a two-
                                                                     755

dimensional self-organizing, topography-preserving, feature           The first is a self-adjustable neighborhood function. In
map (SOM; Kohonen, 2001), which handles lexical-                   standard SOM, the radius of the neighborhood usually
semantic representations. This feature map is connected to         decreases according to a fixed training timetable. This type
two other feature maps, one for input (auditory) phonology,        of development in the network, though practically useful, is
and another for articulatory sequence of output phonology.         subject to the criticisms that 1) learning is tied directly and
Upon training of the network, the word meaning                     only to time (amount) of training, and is rather independent
representations, input phonology, and output phonemic              of the input-driven self-organizing process; and 2) the
sequence of a word are presented to and processed by the           network often loses its plasticity for new inputs when
network. This process can be analogous to the child’s              neighborhood radius becomes very small. In DevLex-II, we
analysis of a word’s semantic, phonological, and phonemic          attempt to correct these problems by using a learning
information upon hearing a word. On the semantic and               process in which the neighborhood size is not totally locked
phonological levels, the network forms representational            with time, but is adjusted according to the network’s
patterns of activation according to standard SOM algorithm.        learning outcome (experience). In particular, neighborhood
   Here, given a stimulus x (the phonological or semantic          function will depend on the network’s average quantization
information of a word), a winner node (or BMU, best                error on each layer, with quantization errors defined as the
matching unit) on the SOM is found if its weight vector has        Euclidean distances between an input pattern and the input
the smallest Euclidean distances to x. After a winner is           weight vector of its BMU (Kohonen, 2001). We implement
identified, the weights of the nodes surrounding the winner        this process as follows: (1) at each epoch (training with all
in a given area (the neighborhood) are updated proportional        available words), the network checks the quantization errors
to a constant learning rate α. Unlike the SOMBIP model (Li         on each layer responding to input patterns and calculates
& Farkas, 2002), DevLex-II has a separate output sequence          their average errors for each layer; (2) the average errors
level. This level is slightly different from the other two         from the current epoch are compared with those from
levels where standard SOM is used. The addition of this            previous epochs, and the neighborhood sizes on each layer
level in the model is inspired by models of word learning          are adjusted accordingly (either increase by 1 if the current
based on temporal sequence acquisition. It is designed to          error is larger than the previous average error, or decrease
simulate the challenge that language learners face when they       by 1 if it is smaller); (3) the neighborhood size should not be
need to develop better articulatory control of the phonemic        negative, and not larger than the final neighborhood size of
sequences of words. Here, the activation pattern                   the previous training stage; we split the training process into
corresponding to phonemic sequence information of a word           several stages to gradually present the network with new
is formed according to the algorithms of SARDNET (James            words. This method gives DevLex-II certain plasticity by
& Miikkulainen, 1995), a type of temporal or sequential            increasing the neighborhood size a little when facing new
SOM network (see Li et al., 2007 for further details). In          patterns (due to the increment of error), but there is also
DevLex-II, the activation of a word form can evoke the             certain degree of stability due to the restrictions in step (3).
activation of a word meaning via form-to-meaning links (to         The learning process will thus no longer be fixed a prior,
model word comprehension) and the activation of a word             but be dependent on the experience level of the network.
meaning can trigger the activation of an output sequence via          A second way in which we attempt to solve the plasticity-
meaning-to-sequence links (word production). Concurrent            stability problem is to manage the training process as
with the training of the three maps, the associative               follows: for the input phonology map and the semantic map,
connections between maps are trained via Hebbian learning          during each training epoch, once a unit is activated as a
with a constant learning rate β.                                   BMU, it will become ineligible to response to other inputs
                                                                   in the current training epoch. In this way, the old words are
Plasticity and Stability in the Model                              kept untouched in the training; the new words can be
To realistically model bilingual lexical development               represented by novel units (new resources) in the maps. A
(especially the L2 acquisition) we must consider a core            similar procedure is also used in the output sequence map
issue called “catastrophic interference” (see French, 1999;        on the word level, where the same phoneme in different
Li et al., 2004). For example, if we train a network to            locations of a word will be mapped to different (but adjacent)
acquire an L1 lexicon with 500 words and then train it on          nodes in the map. This mechanism resembles a process in
another 500 words in L2, in many traditional networks, the         which new neurons are recruited for novel inputs as
additional L2 words may disrupt the network’s knowledge            computational resources become scarce (see Li et al., 2004).
of L1. This problem has been a “plasticity-stability”              The use of a different but adjacent unit for new input is also
dilemma in neural networks. Keeping the network’s                  empirically motivated: psycholinguistic research suggests
plasticity for new words often causes it to lose its stability     that when young children encounter a novel word they tend
for old knowledge; conversely, a network too stable often          to map it to a different category or meaning for which the
cannot adapt itself very well to the new learning task. To         child has not acquired a name yet (see Markman, 1984,
resolve this problem for our bilingual study, we introduced        Principle of Mutual Exclusivity; Mervis & Bertrand, 1994,
two new features into DevLex-II.                                   Principle of Novel-Name-Nameless-Category).
                                                               756

Bilingual Lexicons and Input Representations                          two lexicons were presented to the network gradually and in
To control for a host of extraneous variables in the study of         parallel. At the first stage, the training vocabulary included
bilingual lexicon, we used as our basis the vocabulary from           50 English words and 50 Chinese words. Then at every new
CDI, the MacArthur-Bates Communicative Development                    stage, 50 more English words along with 50 more Chinese
Inventories (Dale & Fenson, 1996). Each lexicon included              words were added to the training pool until the final stage
500 words and was ordered roughly according to their order            when the size of each lexicon reached 500. Here, a training
of acquisition. The English lexicon was identical to that of          stage included 10 epochs, which means that each available
Li et al. (2004). The Chinese lexicon was derived from the            word was presented to the network 10 times at each stage.
Chinese version of the CDI (Wu, 1997; Tardif et al., 1999).           In the sequential learning situation, learning of L2 is
   To derive the input representations of the bilingual               delayed relatively to that of L1, either only slightly (early
lexicons for our model, first, we used PatPho, a generic              learning) or significantly (late learning). In the case of early
phonological pattern generator for neural networks (Li &              L2 learning, the network was first trained on 100 L1 words
MacWhinney, 2002), to construct the basic input                       (English) 1 . Then the L2 words were presented to the
phonological patterns of the English and Chinese words. A             network stage by stage (each stage with 50 more new L2
left-justified template with 54 dimensions was adopted. In            words) along with the corresponding increment of L1 words.
addition, a separate group of 9 units was used to represent           The training would end 10 stages later, when the entire 500
lexical tones in Chinese, and the values of these units were          L2 words were seen by the network. In the case of late
left empty for English. Thus, each word in the bilingual              learning, L2 words began to join the training only after 400
lexicon was represented by a vector of 63 units for its input         L1 words had been presented to the network during the first
phonological representation. Second, there were 55                    4 stages. Then the training continued for another 10 stages
phonemes from the two languages, which we represented as              until all the 500 L2 words were seen by the network (so
vectors of articulatory features of the phonemes to the               exposure to L2 words in all three scenarios was 10 stages).
output sequence map (as in PatPho). Third, for each                   Comparison of the three learning scenarios should allow us
language, we constructed two sets of lexical semantic                 to see the effects that the consolidation of lexical
representations through two different methods, and then               organization in one language has on the lexical
combined them to increase the accuracy of the lexical                 representation in the other language.
representation (see Li et al., 2004 for rationale). The first set
was generated by WCD (the word co-occurrence detector,                                   Results and Discussion
Li et al., 2004), a special recurrent network that learns the
lexical co-occurrence constraints of words by reading
through input speech in linguistic corpus (here it is the
child-directed parental speech from the database of
CHILDES: http://childes.psy.cmu.edu). The second set of
semantic representations was generated from computational
thesauruses available for each of the two languages
(WordNet for English and HowNet for Chinese:
http://www.keenage.com). Our method allows for a lexical
representation with both semantic and syntactic information.
It makes our semantic representation a kind of “language
specific semantic representation” and closer to the “lemma
component” of a lexical entry, which allows inter-language
synonyms to have different representations.
Simulation Parameters
In the simulations reported below, the input phonology map
and the semantic map each consisted of 70 x 60 nodes, and
the output sequence map included 25 x 20 nodes. During
training, both learning rate α and β were kept constant (0.25
and 0.1 respectively). The radii of a winner’s neighborhood
on each map were adjusted automatically according to the
neighborhood function mentioned above. The initial radius                Figure 2: Examples of bilingual lexical representations
on the SOM layer was set to be 20 and that on the                     on semantic map and phonological map. Dark areas
SARDNET was 10. These numbers were chosen to be large                 correspond to L2 (Chinese) words. (a-b): simultaneously
enough to discriminate among the words and phonemes in                learning; (c-d): early L2 learning; (e-f) late L2 learning.
the lexicon while keeping the computation process tractable.
   Our simulation included three learning scenarios:                     1
                                                                           In separate simulations (not reported here) we obtained similar
simultaneous, early, and late. In simultaneous training, the          results when Chinese was L1 and English was L2.
                                                                  757

Bilingual Lexical Representations                                        and nv3hai (girl) were close to girl and boy; qiao3ke4li4
First we examine the phonological and semantic                           (chocolate), dan4gao1(cake) and pu2tao2gan1 (raisin) were
organizations of the bilingual lexicon in the corresponding              projected to the location of English words for food like
maps in our model. Figure 2 shows the examples of the                    coffee, chocolate, milk and egg.
distribution of the two lexicons on each map in different                   Why is the late L2 learning so different from the other
learning situations. Due to the large size of the lexicons and           two situations? We believe that this is due to the significant
maps, only broad areas of the active neurons are displayed.              difference in developmental changes as a function of
In Figure 2, the boxes on the left represent the distributions           learning history. In the late learning situation, L2 is
of bilingual lexicons in the semantic map; and the boxes on              introduced at a time when the learning system has dedicated
the right indicate the distributions in the phonological maps.           its resources and representational structure to L1, and L1
Black regions represent those neurons that can be best                   representations are consolidated such that L2 can only use
labeled by L2 words, whereas white regions indicate those                existing structures and associative connections that are
neurons that best represent L1 words in the input space. 2               already established by the L1 lexicon. In this sense we say
  Here, Figures 2a & 2b represent the simultaneous                       that the L2 lexicon is parasitic on the L1 lexicon (see
acquisition situation. We can see that our network shows                 Hernandez, Li, & MacWhinney, 2005). This is because the
clear distinct lexical representations of L1 and L2 on both              network’s re-organizational ability (plasticity) has been
the input phonological and the semantic level and within                 significantly weakened with the decrement of the
each language. The results are similar to Li and Farkas’s                neighborhood sizes on each map. Even though our model
(2002) previous work, and the network’s ability to develop               has certain degree of plasticity by recruiting new resources
distinct representations for each language shows that                    into the computation when needed, it is still not enough to
simultaneous learning of two languages allows the system to              make the radical restructuring or complete reorganization of
easily separate the lexicon during learning (See also French             the map’s topology. In contrast, for the early L2 learning,
& Janquet, 2004). In the case of sequential acquisition,                 the network still has significant plasticity and can
however, the results are not so clear-cut. If L2 was                     continually reorganize the lexical space for L2. Rather than
introduced into learning early on, then the lexical                      becoming parasitic on the L1 lexicon, early learning allows
organization patterns were similar (though not identical) to             the increase of the L2 lexicon to present a significant
those found in simultaneous acquisition, as shown in 2c and              competition against the L1 lexicon.
2d. The differences are reflected as the slightly smaller
spaces occupied by the L2 words (Chinese, the dark areas                 Word Density and Learning History
on each map) as compared to the lexical space occupied by                Another way in which learning history has impacted
L1, and more dispersed and fragmental distributions of L2                bilingual representation in our model is the degree to which
on the phonological map (Figure 2d) as compared to                       within–language lexical distributions are packaged.
simultaneous learning results (Figure 2b). We can dub these              Inspecting the bilingual representations in the semantic and
as the “L2 islands”. However, if L2 was introduced to                    phonological map, we found that the words were not evenly
learning late, the lexical organization patterns were                    distributed in L1 and L2. Some areas were very dense while
significantly different from those found in simultaneous                 other areas were sparse. It was obvious that in some dense
acquisition, as shown in Figures 2e and 2f. No L2 islands                areas, the retrieval of the sound or the semantic content of a
appeared this time. In fact, we can say that the L2                      word could become difficult. In densely populated areas, the
representations were parasitic on or auxiliary to those of L1            competition between words was often strong and thus might
words: compared with L1 words, the L2 words occupied                     result in a higher confusion rate. Here we wanted to see if
only small and fragmented regions, and were dispersed                    L2 words acquired during late L2 learning were distributed
throughout the map. There were small L2 chunks that were                 as a group in high density. For this purpose, we defined the
isolated from each other, and interspersed with L1 regions.              average word density of a group represented on a map as the
A close investigation shows that the locations of the L2                 vocabulary size of the group divided by the total number of
words depended on how similar they were to the L1 words                  units on the map which can be best labeled by the members
in meaning (for semantic map) or in sound (for                           of the same group. Obviously, if the vocabulary size for the
phonological map). For example, in Figure 2f, Chinese                    group is fixed, then the larger the density measure is, the
words lang2 (wolf), leng3(cold) and tang1 (soup) were                    more crowded the group members will be in the map. We
located close to the English words long and leg since they               may expect to find more competitions, confusions, and
sound similar. 3 Other examples: tou2 (head) is close to toe,            errors in a highly dense group. Table 1 shows the average
and gou3 (dog) close to go. Examples like these could also               word densities of L1 and L2 words in both the semantic and
be found in the semantic map (Figure 2e): mei4mei (sister)               the phonological map. We can see that under the late L2
                                                                         learning situation, the density of the L2 words reached a
   2
     Just as finding BMU for an input pattern, we can find the “best     very high level (0.99 on a 0-1 scale).
matching word” in the input space for each unit on the map. Then           Our density analysis is consistent with our previous
the unit can be marked by the label of its best matching word.           representation analysis. Moreover, high density and small
   3
     The number in the Chinese phonetic transcription indicates the      islands (i.e., the fragmental representations) may cause a
tone of the corresponding word.
                                                                     758

 Table 1: Word density, and comprehension (Com) and                                               Comprehension and Production errors
 production (Pro) errors of L1 & L2 in the phonology                                              Novice learners of L2 will often encounter problems when
 (Phon) and semantic (Sem) maps. Results are based on                                             they use their second language. They may misunderstand
 the average of 5 trials.                                                                         unfamiliar L2 words, or may not get their words understood
                                                    Word Density              Error #             due to particular pronunciations. DevLex-II has been shown
                                                    Phon    Sem             Com       Pro         to be able to capture children’s error patterns in a
                                         L1         0.244 0.263             18.6     51.8         monolingual environment (Li et al., 2007). In the current
 Simultaneous                                                                                     study, we also found interesting patterns especially in our
                                         L2         0.236 0.218             36.4     29.8
                                         L1         0.174 0.168             10.0      4.4         network’s comprehension errors.
    Early L2                                                                                         First, very strong within-language interferences could be
                                         L2         0.382 0.430             46.8     34.8
                                         L1         0.135 0.135             10.4      4.2         found in the comprehension errors in all of the three
    Late L2                                                                                       bilingual learning scenarios. Such interference could be
                                         L2         0.999 0.998            140.2 186.4
                                                                                                  caused by the similarity either in sound or in meaning
high level of competition and a high rate of lexical                                              between two words in the same language. For example, an
confusion between lexical items during the speaker’s word                                         activation of the English word she on the input phonology
retrieval for production. These patterns may account for the                                      map caused the responding of see on the semantic map. This
empirically observed ‘deficit’ in lexical retrieval during                                        is an example of within-language interference due to sound
word naming in L2 (Craik & Bialystok, 2006). As seen in                                           similarity. Other examples include bump - jump; glass-grass;
Table 1, our model under the late L2 learning situation                                           pull-pool; qing3 (invite)-qin1 (kiss); zang1 (dirty) - zhang1
showed more comprehension and production errors for L2                                            (piece). Semantic similarity may also cause comprehension
words (140.2 and 186.4 on averages in 5 trials) than under                                        errors such as: kick-drop; cut-tear; and hei1(black)-
the other two learning situations. In addition, when L1 and                                       lv4(green); mi4feng1(bee)-ma3yi3(ant).
L2 errors were considered together, most errors happened to                                          Second, comprehension errors caused by between-
the L2 words. Word density was quite low for the L1 words                                         language interferences could also be found. Most of them
in general. They are more robust than words in high density                                       were caused by phonetic similarities (i.e., cross-language
areas and thus more resistant to competition or damage.                                           homophones): e2(goose)-a; tang2(sugar)-tongue; ye2ye
  Due to the influence of these different distribution and                                        (grandpa)-ear (see Li & Farkas, 2002, for similar errors);
word density patterns, lexical development may also be                                            fewer were caused by semantic similarities, Mao1(cat)-bear;
impacted by different L2 learning history. In Figure 3, we                                        shou3(hand)-toe. However, as in empirical studies
present the number of L2 words that can be successfully                                           summarized by Francis (2005), such interferences were not
produced by our network as a function of the L2 words                                             as common as within-language interferences, and in our
available to the network at different stages. Not surprisingly,                                   model it could be found only in the late L2 learning
the vocabulary sizes of the L2 words increased over time                                          situation. The absence of such interferences in the
under all the three learning situations. A regression analysis                                    simultaneous and early situations is probably due to the
indicated more rapid learning for the early than the late                                         distinct, less dense lexical representations in these situations
learning situation (see the slope function of the fitting line).                                  as compared to the late learning situation.
In fact, the pattern for early L2 learning is quite similar to                                       Another interesting finding is that the between-language
that for simultaneous learning. The empirical bases and                                           interference is unidirectional, that is, the comprehension of
implications of these findings, however, need to be further                                       L2 words was interfered by L1 knowledge only. There was
investigated.                                                                                     rare evidence of a reversed interference from L2 to L1 in
                                                                                                  our simulations. This also supports our earlier analysis that
                         500         Simultaneous Learning
                                                                                                  L2 representations are often parasitic on L1 representations
                                     Early L2 Learning                                            under late learning. Under this situation, L1 representations
                                     Late L2 learning
                         400                                         y=0.99X-51.5                 have been consolidated such that the processing of L2 word
     L2 words produced
                         300
                                         y=1.08X-70.1                                             tends to use existing structures and associative connections
                                                                                                  that are established by the L1 lexicon. This sometimes
                         200                                                                      causes unfamiliar L2 words to be wrongly projected to the
                                                                                                  regions of L1 words.
                         100
                                                      y=0.61X-15.4                                   As in monolingual simulations (see Li et al., 2007),
                           0                                                                      DevLex-II also showed lexical confusions, omissions,
                               0   100        200     300    400     500     600
                                                                                                  replacements, or incorrect sequencing of phonemes in
                                              Available L2 words                                  bilingual production. However, for the late L2 learning
                                                                                                  situation, many errors were caused by phonemes that are
Figure 3: Correctly produced words as a function of                                               unique to L2. For example, c ([ts']) and ch [t§'] are two
available L2 words at different stages. Error bars indicate                                       phonemes not found in L1 (English) and therefore they are
standard deviations, and the lines were fitted through                                            often confused in the map. Other examples include
regression analyses.                                                                              confusions of phonemes among j, q, x ( [tþ], [tþ'], [þ]), z
                                                                                            759

and zh ([ts], [t§]), s and sh ([s], [§]). In late L2 learning, the     French, R.M. (1999). Catastrophic forgetting in connection-
subtle differences between those phonemes are not highly                 ist networks. Trends in Cognitive Sciences, 3, 128–135.
distinguishable in a system that has already committed itself          French, R.M., & Jacquet, M. (2004). Understanding
to L1 phonemes. These simulated patterns match up well                   bilingual memory. Trends in Cognitive Science, 8, 87-93.
with empirically based hypotheses that early learners can              Flege, J.E. (1995). Second language speech learning:
create new phonetic categories more easily than late                     Theory, findings, and problems. In W. Strange, (Ed.),
learners, and that such differences are due to the                       Speech perception and linguistic experience (pp.233-
stabilization of the phonetic representation of L1 vs. L2 over           277). Timonium, MD: York Press Inc.
the lifespan of learning (see Flege, 1995).                            Hernandez, A., & Li, P. (2007). Age of acquisition: Its
                                                                         neural and computational mechanisms. Psychological
                         Conclusion                                      Bulletin, 133.
In this study we extended DevLex-II, a self-organizing                 Hernandez, A., Li, P., & MacWhinney, B. (2005). The
neural network model, to the simulation of bilingual lexical             emergence of competing modules in bilingualism. Trends
representation and development. The model has been                       in Cognitive Sciences, 9, 220-225.
modified to handle the plasticity-stability problem in L2              James, D., & Miikkulainen, R. (1995). SARDNET: A self-
learning. Our findings suggest that the nature of bilingual              organizing feature map for sequences. In G. Tesauro et
representations will depend on important developmental                   al., (Eds.), Advances in neural information processing
factors such as timing and history of learning. Comparing                systems 7 (pp.577-584). Cambridge, MA: MIT Press.
across three scenarios of learning, our model demonstrates             Kohonen, T. (2001). The self-organizing maps (3rd ed.).
how developmental patterns are determined by learning                    Berlin: Springer.
dynamics. In particular, when the learning of L2 is early              Kroll, J.F., & Tokowicz, N. (2005). Models of bilingual
relative to that of L1, functionally distinct lexical                    representation and processing: Looking back and to the
representations may be established for both languages;                   future. In J.F. Kroll & A.M.B. de Groot (Eds.), Handbook
when the learning of L2 is significantly delayed relative to             of bilingualism (pp.531-53). New York: Oxford
that of L1, the structural consolidation of the L1 lexicon will          University Press.
adversely impact the representation and retrieval of L2                Li, P., & Farkas, I. (2002). A self-organizing connectionist
words, resulting in parasitic L2 representation due to                   model of bilingual processing. In R. Heredia & J.
reduced plasticity in the structuring of a second language               Altarriba (Eds.), Bilingual sentence processing (pp.59-
(Hernandez et al., 2005; Hernandez & Li, 2007). In this                  85). North-Holland: Elsevier Science Publisher.
latter case, we can see how early learning leads to dedicated          Li, P., Farkas, I., & MacWhinney (2004). Early lexical
cognitive and neural structures that affect the shape and                development in a self-organizing neural network. Neural
outcome of later development. These findings point to a                  Networks. 17, 1345-1362.
highly dynamic process in which mechanisms of learning                 Li, P., & MacWhinney, B. (2002). PatPho: A phonological
interact with the timing and history of learning to determine            pattern generator for neural networks. Behavior Research
developmental trajectories. Connectionist models such as                 Methods, Instruments, and Computers, 34, 408-415.
DevLex and DevLex-II provide excellent computational                   Li, P., Zhao, X., & MacWhinney, B. (2007). Dynamic self-
accounts and mechanistic specifications for such interactive             organization and early lexical development in children.
dynamics in development.                                                 Cognitive Science. (in press)
                                                                       Markman, E. (1984) The acquisition and hierarchical
                     Acknowledgments                                     organization of categories by children. In C. Sophian
                                                                         (Ed.), The 18th annual Carneigie symposium on cognition
   This research was supported by a grant from the National              (pp.376-406). Hillsdale, HJ: Lawrence Erlbaum.
Science Foundation (BCS-0131829).                                      Mervis, C.B., & Bertrand, J. (1994). Acquisition of the
                                                                         novel name-nameless category (N3C) principle. Child
                         References                                      Development, 65, 1646-1663.
Bialystok, E. (2001). Bilingualism in development.                     Regier, T. (2005). The emergence of words: Attentional
   Cambridge, NY: Cambridge University Press.                            learning in form and meaning. Cognitive Science, 29, 819.
Craik, F., & Bialystok, E. (2006). Positive and negative               Tardif, T., Gelman, S.A., & Xu, F. (1999) Putting the “noun
   effects of bilingualism on cognitive aging. 47th Annual               bias” in context: a comparison of English and Mandarin.
   Meeting of the Psychonomic Society, Houston, TX.                      Child Development, 70, 620-635.
Dale, P.S., & Fenson, L. (1996). Lexical development                   Thomas, M.S.C. & Van Heuven, W. (2005). Computational
   norms for young children. Behavior Research Methods,                  models of bilingual comprehension. In J.F. Kroll &
   Instruments, & Computers, 28, 125-127.                                A.M.B. deGroot (Eds.) Handbook of bilingualism. New
Francis, W. S. (2005). Bilingual semantic and conceptual                 York: Oxford University Press.
   representation. In J.F. Kroll & A.M.B. De Groot (Eds.),             Wu, J. (1997). Language, play and general development for
   Handbook of bilingualism (pp. 251-267). New York:                     Chinese infant-toddlers. Unpublished Ph.D. dissertation,
   Oxford University Press.                                              University of Colorado at Boulder.
                                                                   760

