UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cognitive Robotics, Enactive Perception, and Learning in the Real World
Permalink
https://escholarship.org/uc/item/6t72608j
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Morse, Anthony F.
Ziemke, Tom
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

           Cognitive Robotics, Enactive Perception, and Learning in the Real World
                                            Anthony F. Morse (Anthony.Morse@his.se)
                                                 Tom Ziemke (Tom.Ziemke@his.se)
                                                      SCAI Lab, University of Skövde,
                                                   School of Humanities and Informatics,
                                                         SE-541 28 Skövde, Sweden
                               Abstract                                 claiming that the former was reasonably tight, in terms of
   Robotic cognitive modeling in the real world requires a level of
                                                                        theoretical explanation, while the latter left far too much
   integration and grounding rarely seen in more abstract               unspecified and unconstrained. In updating our interpretations
   modeling. However, like Newell we believe this is exactly the        of Newell’s first suggestion, even implemented simulations
   kind of integration needed to promote scientific cumulation in       leave much unspecified and unconstrained by comparison to
   the cognitive sciences. We present a neural model of learning        concrete robotic agents which must account for processing
   compatible with Noë’s account of enactive perception. We             from the sensory surface all the way to motor output, only
   highlight that accounts of enactive perception tend to               then can we claim to have a complete account of the
   oversimplify the problem of identifying contingent
   relationships and introduce a novel way to address the problem       phenomenon studied (cf. Brooks, 1989; Pfeifer & Scheier,
   of marginal regularities. Finally, we describe a general (non-       1999). That is not to claim that isolated or ungrounded
   task specific) model and present a number of real-world robotic      models cannot provide significant contributions to cognitive
   experiments demonstrating a wide range of integrated                 theories, rather that such models typically remain silent on
   psychological phenomena.                                             issues of integration and grounding. Hence, they are also at
   Keywords: Cognitive robotics; enactive perception; learning;         odds with the emerging paradigm of embodied cognition (e.g.
   cognitive modeling; association; reservoir systems; dynamic          Varela et al., 1991; Clark, 1997; Pfeifer & Scheier, 1999;
   liquid association; liquid state machine; echo state network.        Gibbs, 2005).
                                                                           Newell’s (1973) second and third suggestions were to
                                                                        “accept a single task and model all of it.” (ibid, p. 303), or “to
          Introduction: A Call for Integration                          stay with the diverse collection of small experimental tasks,
Although many of the pioneers of AI and cognitive science               as now, but to construct a single system to perform them all…
were very optimistic about the prospects of creating human-             [and crucially] …it must truly be a single system to provide
like general AI (Feigenbaum & Feldman, 1963; Simon,                     the integration that we seek.” (ibid, p. 305). Despite huge
1957), the field has not come even close to fulfilling such             progress in modeling techniques, convincing answers to
early promises. We believe that this is in part due to a lack of        Newell’s call for integration are very rare.
research directed specifically at the problem(s) of integration.           The natural way forward then for cognitive modeling, in
Newell (1973) claimed that this limited progress was, in part,          our opinion, is − still pretty much in the spirit of Allen
the result of using methods that do not support integrative and         Newell’s original view of cognitive modeling, although not
cumulative modeling: “Suppose that in the next thirty years             necessarily following his choice of symbolic modeling
we continued as we are now going. Another hundred                       approach – to aim for integrative and cumulative modeling. It
phenomena give or take a few dozen, will have been                      is here that we believe modeling with situated and embodied
discovered and explored. Another forty oppositions will have            agents is central, not only as real world modeling forces a
been posited and their resolution initiated. Will psychology            shift in our focus from ungrounded theories of isolated
then have come of age?” (ibid, pp. 287-288). Newell’s                   phenomena to grounded and integrated models accounting for
opinion at the time, and borne out over the following thirty            complete processing, but also for theoretical reasons in the
years, was that the answer must be no: “Far from providing              embodied cognition paradigm (Morse & Ziemke, In Press).
the rungs of a ladder by which psychology gradually climbs
to clarity, this form of conceptual structure leads rather to an             Perception, Action, and the Environment
ever increasing pile of issues, which we weary of or become             Real world robotic embodiment plays a wider role than
diverted from, but never really settle.” (ibid, p. 289). Clearly,       merely focusing our attention on matters of internal
Newell’s comments and suggestions are still relevant to all             integration. The unit of analysis that many cognitive scientists
forms of cognitive modeling from computational                          consider relevant to our understanding of cognition has
neuroscience to cognitive robotics, and are not limited solely          shifted from the view of cognition as purely internal
to the symbolic methods he pursued himself.                             computation that, at least to some degree, can be reduced to
   Newell made three specific suggestions for the future                mapping sensory input to motor output, to the view of
development of psychological theories and models; “The first            cognition as situated and embodied action that spans brain,
suggestion is to construct complete processing models rather            body and environment (Clark, 1997; Clark & Chalmers,
than the partial ones we now do.” (ibid, p. 301). He contrasted         1998; Hutchins, 1995; Suchman, 1987; Varela, Thompson, &
an implemented simulation with an abstract flow diagram,                Rosch, 1991). Thus embodiment calls our attention to the
                                                                    485

relationship between an agent or organism and its                    actions for evaluation, and recognizing categories in an agent
environment. One prominent example of this is the enactive           relative way.
approach (Noë, 2004; O'Regan & Noë, 2001) in which                      Initially the enactive theory of perception would appear
perception is thought to be both dependent upon, and                 open to computational / robotic modeling; acquiring and
constituted by our possession of sensorimotor knowledge, i.e.        representing sensorimotor profiles from experience would
“practical knowledge of the ways movement gives rise to              seem straight forward as they present contingent and hence
changes in stimulation.” (Noë, 2004). Thus sensorimotor              contextually consistent relationships between our actions and
knowledge is not simply factual knowledge about a domain             our sensory data. One possible method to use would be
but is intimately about the relationship between an agent and        statistical analysis from which consistent relationships in data
its environment.                                                     are supposed to emerge; however, there are at least two
   It is clear is that the strong dynamic relationship between       problems complicating the application of such methods in
the developing agent and its environment is co-determining           modeling enactive perception. Firstly, there is a temporal
and thus to better understand cognition, modeling in real            problem as the result of an action may not be immediate, and
environments with robotic/embodied agents is important.              may in fact result from a sequence of actions leading to a
Without refuting the importance of evolution, it seems               variation on the credit assignment problem (i.e. which subset
reasonably clear that much of our human world knowledge              of the actions performed is actually responsible for this
and general cognitive ability is either derived from, or heavily     sensory change). Secondly, and more problematically, there is
shaped by, life-time experiences. The models discussed in            the problem of marginal regularity. There are relatively few
this paper therefore address ontogenetic developmental               sensorimotor contingencies that emerge directly between our
models of human learning demonstrated on a real robot.               senses and actions, rather these contingencies lie between
   Models displaying cognitive abilities of one kind or another      patterns of relationships in sensory data and patterns of
typically capture either knowledge or skill in a limited             relationships in action. For example the regularities or
domain. In attempting to develop an integrative approach, and        affordances offered by a cup are not consistently between the
following Noë’s enactive view, we can first collapse these           same retinal pixels and the same muscular actions. Initially
two distinctions together; knowledge is skill, and skill is          this is worrying as by Noë’s theory it is the identification of
knowledge. Next, and still following Noë’s enactive view,            sensorimotor profiles that enables recognition of the objects
there is no special treatment of any particular modality or          in the first place. Acknowledging this problem turns Noë’s
domain of data, so as long as contingencies in the agent’s           account on its head; now it seems that you must have
interactions with its environment are captured, perception of,       persistent recognition of the object over time (allowing for
and hence skill within any domain should be forthcoming.             varying sensory contact) in order to perceive the
Our starting point for an integrated modeling approach then is       contingencies it affords to your action. The initial object
to model a form of learning compatible with Noë’s view of            recognition or tracking need not be a conscious perception in
enactive perception. This then provides means for a real             itself but achieving this prior recognition presents a serious
robotic agent to learn from its experience in noisy and              problem for computational / robotic modeling. As Kirsh
unstructured environments in a domain general way, thereby           (1992) put it, “what if so little of a regularity is present in the
integrating knowledge and skills from several domains of             data that for all intents and purposes it would be totally
interaction.                                                         serendipitous to strike upon it? It seems … that such a
                                                                     demonstration would constitute a form of the poverty of
 Enactive Perception and Marginal Regularities                       stimulus argument” (ibid, p. 317). Such marginal regularities
According to the enactive view, there are regularities in the        are present in the overwhelming majority of tasks requiring
world which produce stereotypical changes in sensory stimuli         any kind of categorization, recognition, or decision making
relative to actions performed. To use an example from (Noë,          process based in either real world or any other non-trivial data
2004) a plate may appear to us as elliptical from some               set (Clark & Thornton, 1997). In recent years the reservoir
viewpoints but we know it to be in fact round and perceive it        systems approach has been developed with the potential to
as such. This means that we know how it would look if we             alleviate both problems, as discussed in more detail in the
moved a little this way or a little that way, and we would be        next section.
surprised if we did move and found those expectations
contradicted. Our perception of a plate is to recognize that         Reservoir Systems
some part of our sensory input corresponds to a sensorimotor         Two primary forms of reservoir system are the biologically
profile typical of plates – how we would expect our sensory          derived Liquid State Machine (LSM) (Maass, Natschlager, &
input to change as a result of various actions. This is, Noë         Markram, 2002a, 2002b, 2002c) and the more
claims, how our perception gains content, though without an          computationally efficient Echo State Network (ESN) (Jaeger,
account of affect it is not clear how this content becomes           2001a, 2001b, 2002). Although descriptions of reservoir
meaningful. Despite this, it is clear that such knowledge could      systems can be quite complicated, what they all have in
be extremely useful to an embodied cognitive agent; for              common is a sparse randomly interconnected network of
example simulating or anticipating the effects of possible           artificial neurons in which activity coming into the system
                                                                     reverberates around the network, and would decay to a null
                                                                 486

state if the input were stopped. Reservoir systems implement          method from others both technically and theoretically.
a high dimensional space and cast the input data into it. To          Practically, this method does not require the kind of explicit
explain the role of the reservoir, Maass et al draw an analogy        training of readout units that both forces a localist
between the activity reverberating around a reservoir and the         interpretation and can be seen as fixing or providing the
ripples on a pond. Input to either system (e.g. dropping a            interpretations of those sensory states for which training is
stone into the water, or providing input to the reservoir)            provided. The relationships statistically captured are driven
causes activity (or ripples) which then reverberate around the        by contextual consistencies in the sensorimotor experience of
system, decaying over time. Just like the ripples on the pond,        the agent and therefore conform to the generation of enacted
this residual activity is far from random and can be used to          sensorimotor profiles. That is to say, sensorimotor
tell us something about the disturbance(s) that originally            contingencies between an agent and its environment will be
caused it, thus it carries information about those                    captured by the statistical analysis so long as the entities
disturbance(s).                                                       involved in the contingency are made separable by the
   Reservoir systems also have interesting temporal dynamics          reservoir. This is significantly more powerful than relying on
as a disturbance at time t will persist within the reservoir          the contingencies being between separable entities in the first
lasting at least as long as the decay period (the time taken to       place. Finally, the method remains uncommitted to any
reach a null state should input cease), and with feedback can         particular form of embodiment or sensory apparatus and
potentially last even longer.                                         should therefore be considered general purpose, requiring no
   Normally a reservoir system, although untrained, would             task or embodiment-specific knowledge in advance.
utilize trained perceptrons to act as readout units. These single        Using this method in modeling enactive perception, the two
layer perceptrons can only recover information from the               major problems highlighted in the previous section are
reservoir so long as it is linearly separable; however, this need     significantly alleviated. Firstly, the current state and trajectory
not be simple linear separation in the original input space but       of the reservoir are contingent not only on current events, but
rather in the transformed and dynamic state space of the              also recent events, thereby enabling contingencies between
reservoir. In this standard guise reservoir systems would seem        actions in the recent past and sensory changes, to be captured.
to tackle, at least in part, both of the problems identified with     Secondly, sensory input is continually transformed and
synthetically modeling Noë’s (2004) account of enactive               warped in the high-dimensional space of the reservoir such
perception, though they still require the explicit training of        that many of the marginal regularities are exposed. This is not
readout perceptrons.                                                  to claim that these problems have been solved, rather to re-
                                                                      iterate, they are alleviated to some degree, but should still be
               Dynamic Liquid Association                             considered as limitations to this model.
Readers less interested in the implementation details of the             At this point the original direction of Noë’s claims can be
model should pass over this section. The Dynamic Liquid               re-instated. Having begun forming sensorimotor profiles
Association (DLA) model (Morse, 2005a, 2005b, 2006) both              based on experienced contingencies between separable
removes the need for training readouts from the reservoir and         entities, such relationships can not only be used to predict the
implements an auto-associative network capturing multiple             sensory effects of various actions, but could also strengthen
psychological phenomena. We know that the basic limitation            the recognition / separation of these entities by feeding back
of any simple statistical or experience-based learning system         into the reservoir (Jaeger, 2001b).
to accurately capture relationships is that the entities those
relationships are between are linearly separable. Therefore if
it is possible to train a single layer perceptron to act as a         Auto-Association
readout unit to a reservoir, responding differentially to the         Following connectionist work on spreading activation
presence of a particular input feature, then, even without            models, a simple learning algorithm has been introduced for
doing so we know (given the limitations of single layer               the ongoing construction of Interactive Activation and
perceptrons) that that feature must be linearly separable             Competition (IAC) networks (Morse, 2003). Standard IAC
somewhere within the reservoir. By this logic the supervised          models (McClelland, Rumelhart, & Group, 1986; Page, 2000;
training of readout units only localizes responses but does not       Young & Burton, 1999) consist of a number of localist
provide any greater separation than is already present. Thus if       (independently interpretable) units connected via designed
we apply a context sensitive statistical or experience based          connectivity to other localist units, such that activity spreads
learning algorithm directly to the microcircuit, it should            between related feature units while incompatible features
behave as if all the features which could in principal be             compete. Unlike many architectures derived through
trained for identification by single layer perceptrons were           evolution or gradient descent supervision, these networks
explicitly represented anyway, i.e. the perceptron training           function in a manner introspectively similar to mental
becomes an unnecessary step. That means the limits imposed            activity, in that each locally represented thought, concept or
on statistical learning by requiring separation are extended to       idea primes related thoughts, concepts, and ideas as activity
include all those features of the sensory data stream which are       spreads between units via structured interconnections (Morse,
made linearly separable by the continual transformations of           2005a, 2005b; Young & Burton, 1999). To autonomously
the reservoir. This is an important step differentiating this         develop similar architectures in conjunction with a reservoir
                                                                  487

system, a unit sensitive to the current context is generated by        the behaviour emerging from the agent is significantly more
autonomous pattern recognition over the current state of the           complex than that of a Braitenberg vehicle (Braitenberg,
reservoir. In the models presented here this is achieved using         1984). Agents frequently approach obstacles, only turning or
Adaptive Resonance Theory (ART) networks (Carpenter &                  backing away at the very last moment. Some experienced
Grossberg, 1987) as they allow for the ongoing identification          agents 1hour+ were even able to perform extremely close
of consistent patterns in subsections of an otherwise varying          range movement without colliding.
input vector.
   The autonomously identified patters are then fully
connected to the reservoir and to motor action units by
connections initially weighted at 0, and subject to normalized
Hebbian and anti-Hebbian plasticity. It is these plastic
connections that provide a simple statistical analysis and are
intended to capture the contingencies present between actions
and sense data in the contexts in which each particular pattern
unit is active. As already discussed, the reservoir is intended
to provide separation between complex features in the
sensory data. Statistics directly between the reservoir and
actions would not be context sensitive as the same units are
involved in many different relationships. That is to say, the
statistical relationships are mediated by the autonomous
identification of sub-states of the reservoir such that different           Figure 1: 15 second time laps pictures showing (left) initial
sub-states can result in different statistical relationships               collisions form which the robot learned (right) to successfully
                                                                            navigate a real office environment without further collisions
between the transformed sensory data and actions.
           Experiments - Cognitive Robotics                            Classical Conditioning. Following Pavlov’s (1927)
                                                                       description of classical conditioning, a conditioned response
The DLA model described above is used as the control                   will be elicited by any stimulus that is conditioned by
system for a real robot such that input from three forward             repeated exposure to a pairing of that stimulus with one
facing infrared proximity sensors and six contact sensors              normally eliciting a reflex response. To demonstrate this with
(covering the front left and right, rear left and right, and left      complex sensory input, the DLA agent’s robotic embodiment
and right sides) provided input randomly but sparsely to the           is modified to include visual input from a pan-tilt camera, and
reservoir. In an additional set of experiments low-resolution          an additional input (a button press), which is directly
input from a camera was also fed via random connectivity               connected to the motor output so as to force the agent to
into the same reservoir. Four motor neurons were also set up           move forward. This hard-wired behavior can be considered
in a winner-takes-all relationship corresponding to                    analogous to a reflex response such as the salivation response
acceleration in the forward, backward, turn left, and turn right       elicited in the presence of food by Pavlov’s dogs. Thus, when
directions. Weak noise was used to initiate behaviour.                 the new input button is pressed, the robot necessarily (by
   Finally a motivation neuron was included, active whenever           hard-wired reflex) moves forward.
any of the contact sensors became active. This neuron had                 The initial random behaviour of the agents gradually
plastic reciprocal connections inverting the polarity of               became organized to produce obstacle avoidance as before.
incoming connections and amplifying their strengths. The               Following this, a large bold black arrow on a white card was
effect of this neuron is to inhibit units in positive relations to     held up in front of the moving camera pointing vertically up.
it, while amplifying those in negative relationships. The              The agent produced no particular response to the presence or
practical upshot of this is to prevent actions leading to activity     absence of the card in the visual input, and thus we have the
in the contact units, i.e. to prevent behavior expected to lead        same situation as in Stage 1 of Pavlov’s experiments (see
to a collision. For further details and full experimental              Figure 2). Presentation of the upward pointing arrow and the
analysis see Morse (2006).                                             button push, eliciting a move forwards reflex response, were
                                                                       then paired (made to co-occur while the agent remains in
Summary of Results                                                     open space, i.e. it is not forced to crash) providing the agent
Obstacle Avoidance. Placed in both simple and complex                  with experience of the visual arrow input whilst moving
environments, the robot, initially having no task-specific             forward, thus, mirroring the situation in Stage 2 of classical
knowledge wanders randomly around, occasionally colliding              conditioning. Given experience of this pairing (≈2-5 min,
with obstacles. Following a short period (≈5 min, ≈1000 time           ≈500 to 1000 time steps) the agent was then able to
steps) with occasional collisions, the agent’s behavior self-          consistently reproduce forward movement responses on
organizes to produce collision avoidance (see Figure 1). This          presentation of the upward pointing arrow alone (without the
result is not maintained when the reservoir is removed from            additional hard wired button press). This produces Stage 3 of
the architecture and statistical learning applied directly to the      classical conditioning where the reflex response has been
input and output streams. Although the task here is simple,
                                                                   488

successfully transferred to stimuli which previously elicited              unlike that produced by subsumption architectures (Brooks,
no discernable external response (see Figure 2).                           1989) in which more complex behaviours take over from
    The same method was repeated to condition a reverse                    simple behaviours; however, in this case the hierarchical
(backward) response to a downward pointing arrow.                          ordering of behaviour is a product of experience rather than
Following a further 500 – 1000 time steps (≈2-5 min)                       design.
experiencing the pairing the agent was found to be
differentially responsive to upward and downward pointing
arrows producing either forward or backward motion                                        Discussion and Conclusion
respectively. The agent was then conditioned for left and right            As an integrated model, the DLA robot readily reproduces
pointing arrows to produce left and right turns respectively.              multiple psychological phenomena without requiring the
The agent could then be driven by remote control simply by                 imparting of task-specific knowledge from the designer.
holding the arrow up in front of the camera and turning it to              Rather, by learning the sensorimotor contingencies of its
point in one of the four conditioned directions. This is not               experience, the agent is subsequently able to direct its
only a demonstration of conditioned learning but also a                    behavior in a manner informed by its past experiences.
demonstration of complex object recognition, in that the                   Although Noë claims that sensorimotor knowledge is not
differences between an upward pointing arrow, and a                        necessarily for the guiding of behavior, he readily admits that
downward pointing arrow, being both size and position                      “the knowledge in question is practical knowledge; it is
variant are non trivial.                                                   know-how. To perceive you must be in possession of
                                                                           sensorimotor bodily skill.” (Noë, 2004).
                                                                              To recapitulate the conditioning experiments in enactive
                                                                           terms, the agent first experiences contingencies between
                                                                           active contact sensors and high valued infrared sensor values.
                                                                           Subsequently, rising infrared values from one side of the
                                                                           robot paired with moving in that direction produces the
                                                                           expectation of contact sensor activation. Although not part of
                                                                           Noë’s account, placing a negative value on these expectations
                                                                           can guide the robot’s behaviour away from such situations,
                                                                           promoting the selection of actions which have different
                                                                           expectations. This has been demonstrated on a real robot in a
                                                                           real untailored environment, i.e. not only in tidy robot arenas
                                                                           with high contrast obstacles but further in unstructured
                                                                           environments with hand held visual cues and noisy sensors.
                                                                           The presentation of visual stimuli in contingent relationships
                                                                           with the agent’s movements provides further opportunities for
                                                                           perceiving the world. The agent expects to see appropriately
                                                                           oriented arrows as it moves, or vice versa, to move in
   Figure 2: The three stages of Classical Conditioning. Stage 1: an       directions appropriate to the orientation of visually
 unconditioned stimulus elicits an unconditioned response via a hard-      discriminated arrows. By Noë’s account, this is exactly the
       wired reflex connection; the conditioned stimulus elicits no        kind of knowledge required for enactive perception.
  particular response. Stage 2, conditioned and unconditioned stimuli         Following Newell’s (1973) suggestions for cognitive
    are repeatedly paired. In Stage 3, the conditioned stimulus now        modeling, integration can be considered paramount to
 elicits the conditioned response independently of the reflex-response     developing both cumulative models and theories. In the
                                stimulus.
                                                                           experiments briefly presented here (for further details see
                                                                           Morse, 2006) the focus has been on an embodied model of
Operant Conditioning. In operant conditioning (Skinner,                    learning, therefore classical and operant conditioning were
1938), the consequences of any behavior can result in                      primary psychological targets, being archetypal theories of
modifications to the production of that behavior. In the robot,            human and animal learning. Further to this, the inclusion of
this is demonstrated by changes in the behaviors leading to                numerous other psychological features such as; semantic and
obstacle avoidance. Controlling the movement of the robot by               repetition priming, overt and covert recognition, phobic
presenting arrow stimuli to the camera, initially has the                  acquisition, systematic desensitization, and sequence
potential to cause collisions; however, on being ‘driven’ into             learning, all detailed in Morse (2006), demonstrates a level of
obstacles the agent modifies its responses such that the                   integration rarely obtained by a single model. DLA is further
remote control will eventually only work in situations where               argued to be both compatible with Noë’s account of enactive
the visual ‘instruction’ will not cause a collision. If following          perception, and able to highlight difficulties in the application
the arrow is likely to cause a collision, the agent reverts to             of such accounts, such as the problem of marginal regularities
avoidance behaviors and then, once the collision has been                  here addressed by the inclusion of a reservoir system.
avoided, the agent reverts back to the behavior associated
with the presented arrow. This hierarchy of behaviour is not
                                                                       489

                   Acknowledgments                                 McClelland, J., Rumelhart, D., & Group, P. R. (1986).
                                                                    Parallel Distributed Processing: Explorations in the
This work has been supported by a European Commission
                                                                    Microstructure of Cognition. Volume 2: Psychological and
grant to the project “Integrating Cognition, Emotion and
                                                                    Biological Models. Cambridge, MA.: MIT Press.
Autonomy” (ICEA, IST-027819, www.iceaproject.eu) as part
                                                                   Morse, A. (2003). Autonomous Generation Of Burton’s IAC
of the European Cognitive Systems initiative.
                                                                    Cognitive Models. Paper presented at the European
                                                                    Conference of Cognitive Science 2003.
                         References                                Morse, A. (2005a). Psychological ALife: Bridging The Gap
Braitenberg, V. (1984). Vehicles: Experiments in Synthetic          Between Mind And Brain; Enactive Distributed
 Psychology: MIT Press.                                             Associationism & Transient Localism. In A. Cangelosi, G.
Brooks, R. A. (1989). How to build complete creatures rather        Bugmann & R. Borisyuk (Eds.), Modeling Language,
 than isolated cognitive simulators. In K. VanLehn (Ed.),           Cognition, and Action: Proceedings of the ninth conference
 Architectures for Intelligence (pp. 225-239). Hillsdale, NJ:       on neural computation and psychology (Vol. 16, pp. 403-
 Lawrence Erlbaum Associates.                                       407): World Scientific.
Carpenter, G., & Grossberg, S. (1987). A massively parallel        Morse, A. (2005b). Scale Invariant Associationism, Liquid
 architecture for a self-organizing neural pattern recognition      State Machines, & Ontogenetic Learning In Robotics. Paper
 machine. Computer Vision, Graphics, and Image                      presented at the Developmental Robotics (DevRob05).
 Processing, 37(1), 54-115.                                        Morse, A. (2006). Cortical Cognition: Associative Learning
Clark, A. (1997). Being there - putting brain, body and world       in the Real World: DPhil Thesis, Department of Informatics,
 together again: Cambridge, MA: MIT Press.                          University of Sussex, UK.
Clark, A., & Chalmers, D. J. (1998). The Extended Mind.            Morse, A., & Ziemke, T. (In Press). On the Role(s) of
 Analysis, 58, 10-23.                                               Synthetic Modelling in Cognitive Science. Journal of
Clark, A., & Thornton, C. (1997). Trading spaces:                   Pragmatics & Cognition, special issue on mechanism and
 Computation, representation, and the limits of uninformed          autonomy: what can robotics teach us about human
 learning. Behavioral and Brain Sciences, 20(01), 57-90.            cognition and action?
Feigenbaum, E., & Feldman, J. (1963). Computers and                Newell, A. (1973). You can’t play 20 questions with nature
 Thought. In: New York: McGrall Hill.                               and win: Projective comments on the papers of this
Hutchins, E. (1995). Cognition in the wild: Cambridge, MA:          symposium. Visual information processing, 135–183.
 MIT Press.                                                        Noë, A. (2004). Action in Perception: Cambridge, Mass.:
Jaeger, H. (2001a). The echo state approach to analysing and        MIT Press.
 training recurrent neural networks. GMD Report 148,               O'Regan, K., & Noë, A. (2001). A sensorimotor account of
 German National Institute for Computer Science.                    visual perception and consciousness. Behavioral and Brain
Jaeger, H. (2001b). Short term memory in echo state                 Sciences, 24, 939-1011.
 networks: GMD Report 152, German National Institute for           Page, M. (2000). Connectionist Modelling in Psychology: A
 Computer Science.                                                  Localist Manifesto. Behavioural and Brain Sciences, 23,
Jaeger, H. (2002). Adaptive Nonlinear System Identification         443-512.
 with Echo State Networks. Paper presented at the Neural           Pavlov, I. (1927). Conditioned Reflexes: An Investigation of
 Information Processing Systems (NIPS) 2002.                        the Physiological Activity of the Cerebral Cortex.
Kirsh, D. (1992). From Connectionist Theory to Practice. In         Translated by Anrep GV: London, Oxford University Press.
 Davis (Ed.), Connectionism: Theory and Practice. New              Simon, H. A. (1957). Models of Man: New York, NY: Wiley.
 York: O.U.P.                                                      Skinner, B. F. (1938). The Behaviour of Organizma: An
Maass, W., Natschlager, T., & Markram, H. (2002a).                  Experimental Analysis. New Jersey: Prentice Hall.
 Computational models for generic cortical microcircuits.          Suchman, L. A. (1987). Plans and Situated Action: The
 Computational Neuroscience: A Comprehensive Approach,              Problem of Human-Machine Communication: New York:
 CRC-Press.                                                         Cambridge University Press.
Maass, W., Natschlager, T., & Markram, H. (2002b). A model         Varela, F., Thompson, E., & Rosch, E. (1991). The embodied
 for real-time computation in generic neural microcircuits.         mind: Cognitive science and human experience: Cambridge,
 Paper presented at the Neural Information Processing               MA: MIT Press.
 Systems (NIPS) 2002.                                              Young, A., & Burton, A. (1999). Simulating Face
Maass, W., Natschlager, T., & Markram, H. (2002c). Real-            Recognition: Implications for Modelling Cogntion.
 Time Computing Without Stable States: A New Framework              Cognitive Neuropsychology, 16(1), 1-48.
 for Neural Computation Based on Perturbations. Neural
 Computation, 14(11), 2531-2560.
                                                               490

