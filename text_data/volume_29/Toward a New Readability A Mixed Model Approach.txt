UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Toward a New Readability: A Mixed Model Approach
Permalink
https://escholarship.org/uc/item/39r3d755
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Crossley, Scott A.
Dufty, David F.
McCarthy, Philip M.
et al.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                           Toward a New Readability: A Mixed Model Approach
                       Scott A. Crossley                                                    David F. Dufty
          (scrossley@mail.psyc.memphis.edu)                                            (ddufty@memphis.edu)
    Department of English, Mississippi State University                    Department of Psychology, University of Memphis
                      Starkville, MS 39759                                                 Memphis. TN 38152
                     Philip M. McCarthy                                                 Danielle S. McNamara
               (pmmccrth@memphis.edu)                                         (d.mcnamara@mail.psyc.memphis.edu)
     Department of Psychology, University of Memphis                       Department of Psychology, University of Memphis
                      Memphis. TN 38152                                                    Memphis. TN 38152
                              Abstract                                 Classic Readability
                                                                       Providing students with texts that are accessible and well
   This study is a preliminary examination into the use of
   Coh-Metrix, a computational tool that measures cohesion
                                                                       matched to reader abilities has always been a challenge
   and text difficulty at various levels of language, discourse,       for educators. A solution to this problem has been the
   and conceptual analysis, as a means of measuring English            creation and use of readability formulas. Since 1920 more
   text readability. The study uses 3 Coh-Metrix variables to          than 50 readability formulas have been produced in the
   analyze 32 academic reading texts and their corresponding           hopes of providing tools to measure text difficulty more
   readability scores. The results show that two indices, one          accurately and efficaciously. Additionally, it was hoped
   measuring lexical co-referentiality and one measuring word          these formulas would allow for a greater understanding of
   frequency, mixed with an estimate of syntactic complexity,          optimal text readability.
   yield a prediction of reading difficulty that is similar to            The majority of these readability formulas are based on
   traditional readability formulas. The study demonstrates
   that Coh-Metrix variables can contribute to a readability
                                                                       factors that represent two broad aspects of comprehension
   prediction that better reflects the psycholinguistic factors of     difficulty: lexical or semantic features and sentence or
   reading comprehension.                                              syntactic complexity (Chall & Dale, 1995). According to
                                                                       Chall and Dale (1995), formulas that depend on these
   Keywords: Readability; Corpus Linguistics; Cognitive                variables are successful because they are related to text
   Processing; Computational Linguistics; Discourse Analysis
                                                                       simplification. For instance, when a text is written for a
                                                                       beginning reading audience, the text generally contains
                         Introduction                                  more frequent words and shorter sentences. Thus,
This study is an exploratory examination into the use of               measuring the word frequency and sentence length of a
Coh-Metrix (Graesser, McNamara, Louwerse, & Cai,                       text should provide a basis for understanding how
2004) as an improved means of measuring text                           readable it is.
readability. While traditional readability formulas such as               However, traditional readability formulas are often not
Flesch Reading Ease (1948) and Flesch-Kincaid (1975)                   based on any theory of reading or reading comprehension,
have been widely accepted by the reading research                      but rather on empirical correlations. Therefore, their
community, they have also been widely criticized by                    soundness is strictly predictive and they are often accused
cognitive researchers for their inability to take into                 of having weak construct validity. Regardless, a number
account textbase processing, situation levels (Kintsch, et             of classic validation studies have found the formulas’
al., 1990; McNamara et al., 1996) and cohesion (Graesser               predictive validity to be consistently high, correlating
et al., 2004, McNamara et al., 1996). Coh-Metrix,                      with observed difficulty in the r = .8 range and above
however, offers the prospect of addressing the limitations             (Chall, 1958; Chall & Dale, 1995; Fry, 1989).
of conventional readability measures by providing                         While the predictive validity of these measures seems
detailed analyses of language by integrating lexicons,                 strong, they are generally based on traditional student
pattern classifiers, part-of-speech taggers, syntactic                 populations reading academic or instructional texts. This
parsers, shallow semantic interpreters, and other                      has led many proponents of readability formulas to
components that have been developed in the field of                    caution against their use with literary or technical texts, or
computational linguistics (Jurafsky & Martin, 2000). In                texts written to the formulas. However, the draw of
reference to cohesion indices, Coh-Metrix also analyzes                readability formulas’ simple, mechanical assessments has
co-referential cohesion, causal cohesion, density of                   led to their widespread use for assessing all sorts of texts
connectives, Latent Semantic Analysis metrics, and                     for a wide variety of readers and reading situations
syntactic complexity. Since Coh-Metrix considers                       beyond those for which the formulas were invented. The
textbase processing and cohesion, it is well suited to                 widespread use of traditional formulas in spite of
address many of the criticisms of traditional readability              restricted validity has inclined many researchers within
formulas.                                                              the field of discourse processing to regard them with
                                                                   197

reservation (Bruce, Rubin & Starr, 1981; Bruce & Rubin,           Corpus
1988; Davison & Kantor, 1982; Rubin, 1985; Smith,
                                                                  A corpus of reading texts was selected to test the
1988).
                                                                  hypothesis that linguistic variables related to cognitive
   The rise of cognitive models of reading has underscored
                                                                  processing and cohesion could predict text readability.
not only the limitations of the traditional formulas but
                                                                  The corpus we chose was the Bormuth (1971) passage set.
also the need for a measure that accounts for discourse-
                                                                  The Bormuth passage set is comprised of 32 academic
specific factors such as textbase and situation level
                                                                  passages that include corresponding readability scores.
processing (Kintsch et al., 1990; McNamara et al., 1996).
                                                                  The passage set includes texts taken from school
A more inclusive assessment of text comprehensibility
                                                                  instructional material and includes passages from biology,
must go deeper than surface readability features and
                                                                  chemistry, civics, current affairs, economics, geography,
explain how that learner interacts with a text (Kintsch,
                                                                  history, literature, mathematics, and physics. The
1994; McNamara et al., 1996; Miller & Kintsch, 1980).
                                                                  Bormuth readabiltity scores are based on the reading
Most importantly for the purpose of this study, such
                                                                  difficulty scores of 285 elementary and high school
assessment must include a measure of text cohesion,
                                                                  students from the grades of 3rd to 12th. Bormuth used
which is vital to text processing (Gernsbacher, 1997;
                                                                  cloze scoring procedures on his 32 academic passages to
McNamara, 2001; McNamara et al., 1996).
                                                                  test for reading difficulty. His cloze procedure deleted
   The limitations of classic readability formulas led to
                                                                  every 5th word of the text and the participants were
new readability theories based on cognitive and structural
                                                                  expected to correctly deduce the correct word (or
variables. Much of the ground work for this approach was
                                                                  synonym).
conducted by Kintsch and Vipond (1977), who were
                                                                     The selection of these passages as the foundation for
critical of classic readability formulas in that the formulas
                                                                  this study is based not only on the seminal work
were a-theoretical and based solely on text factors. In
                                                                  conducted by Bormuth (1971) with this passage set, but
suggesting new variables for testing readability based on
                                                                  also on the work done by Chall and Dale (1995) who
conceptuality, Kintsch and Vipond advocated the use of
                                                                  selected the Bormuth set to construct a new readability
propositions (defined as arguments attached to
                                                                  formula. The advantages of the Bormuth passages, as
predicates). Using propositional density along with classic
                                                                  stated by Chall and Dale (1995), are based primarily on
readability measures (word frequency and sentence
                                                                  Bormuth’s use of a cloze criterion as well as the fact that
length) Kintsch and Vipond reported a multiple
                                                                  the Bormuth passage set was constructed using variable
correlation of .97 between these variables and the reading
                                                                  text content and text difficulty. Additionally, the decision
difficulty scores of a limited data set. In later work
                                                                  by Chall and Dale (1995) to use Bormuth’s passages
(Kintsch et al., 1993), this approach was expanded to
                                                                  rather than other passage sets was made after extensive
relate propositions to coherence with the idea that as the
                                                                  evaluation and comparison of the passage characteristics
coherence of a text improved, so did the readability.
                                                                  and cross-validation of their readability scores to other
                                                                  passage sets (e.g. MacGinitie & Tretiak, 1971; Miller &
Coh-Metrix                                                        Coleman, 1967; Caylor et al., 1973).
Recent advances in various disciplines have made it
possible to computationally investigate various measures          Readability Formulas and the Bormuth Passages
of text and language comprehension that supercede
surface components of language and instead explore                Bormuth (1969) used the mean cloze scores from his
deeper, more global attributes of language. The various           passage sets to create a readability formula that was based
disciplines and approaches that have made this approach           on the number of letters per word, the number of Dale-
possible include computational linguistics, corpus                Chall words per total words (based on the 1948 Dale-
linguistics, information extraction, information retrieval,       Chall word list), and the number of words per sentence.
and discourse processing. Taken together, the                     Using Bormuth’s 1969 formula and an updated Dale word
improvements in these fields have allowed the analysis of         list (from 1983), a new multiple regression comparing the
many deep level factors of textual coherence to be                text features of the Bormuth passage set and its
automated, allowing for more accurate and detailed                corresponding reading difficulty scores reported a
analyses of language to take place (Graesser et al., 2004).       multiple correlation of .961 with an adjusted R2 of .915
   A synthesis of the advances in these areas has been            between the formula and the cloze scores.
achieved in Coh-Metrix, a computational tool developed               Chall and Dale (1995) also formulated a new
at the University of Memphis that measures cohesion and           readability formula based on the Bormuth passage set.
text difficulty at various levels of language, discourse, and     Their formula was designed using Dale’s updated word
conceptual analysis. This tool was designed with the goal         list (1983), the modification of rules for unfamiliar word
of improving reading comprehension in classrooms by               counts, and a simplified equation. Their final readability
providing a means to improve textbook writing and to              formula was based on three variables: number of frequent
more appropriately match textbooks to the intended                words (based on the 1983 Dale 3,000 words known by
students (Graesser et al., 2004).                                 students in grade 4), number of unfamiliar words (those
                                                                  words not in the Dale 3,000 words), and number of
                                                              198

sentences. These variables were rendered into a                  share common arguments (nouns, pronouns, and noun
readability formula based on semantic difficulty and             phrases).
syntactic difficulty. Using Chall and Dale’s readability
formula, a new multiple regression comparing the text            Word Frequency Coh-Metrix calculates word frequency
features of the Bormuth passage set and its corresponding        information through CELEX frequency scores. CELEX
reading difficulty scores reported a multiple correlation of     (Baayen, Piepenbrock, & Gulikers, 1995) is the primary
.956 with a corresponding adjusted R2 of .907.                   frequency count in Coh-Metrix and consists of
                                                                 frequencies taken from the early 1991 version of the
                          Purpose                                COBUILD corpus, a 17.9 million-word corpus. Word
                                                                 frequency is considered important to readability because
The purpose of this study is to analyze how well Coh-            frequent words are normally read more rapidly and
Metrix variables predict text readability. To accomplish         understood better than infrequent words (Haberlandt &
this goal, a readability formula based on Coh-Metrix             Graesser, 1985; Just & Carpenter, 1980). Additionally,
variables will be examined so that we can compare our            researchers argue that quick, accurate, and automatic
results to previous ones using traditional formulas. The         recognition of words help skilled readers in processing
number of passages available (the 32 passages of the             text (Silberstein, 1994).
Bormuth corpus in this case) limited the number of
variables that could be used without over-fitting the
                                                                 Statistical Analysis
model. At a minimum, 10 cases of data for each predictor
are considered sufficient (with conservative models using        To calculate the readability of the Bormuth passage set,
15 to 20). Accordingly, 3 independent variables from             the three selected variables were used as predictors in a
Coh-Metrix were selected to analyze the Bormuth                  training set and a multiple regression equation with the 32
passages. These indices were selected based on past              observed mean reading scores as the dependent variable
research pointing to syntactic complexity (Bormuth,              was conducted. The statistical analyses in this part of the
1969; Chall & Dale, 1995; Kintsch, 1979), word difficulty        study included descriptive statistics for the predictors and
(Haberlandt & Graesser, 1985; Just & Carpenter, 1980),           the dependent variable. To assess the assumption of
and co-referentiality (Kintsch & van Dijk, 1978; Rashotte        independent errors caused by outliers, Durbin-Watson
& Torgesen, 1985) as important for text difficulty and           statistics were conducted. In order to assess the
readability.                                                     assumption of multicollinearity, coefficient analyses were
                                                                 conducted.
Estimate of Syntactic Complexity In defining syntactic              In perfect circumstances, a researcher will have enough
complexity, we assume that sentences with difficult              data available to create separate training and testing sets
syntactic composition are structurally dense, syntactically      and use the training set to create predictors and the testing
ambiguous, or ungrammatical (Graesser et al., 2004). An          set to calculate how well those predictors function
estimate of syntactic complexity was included as a               independently. Historically, most readability studies have
predictor of readability because multiple reading theorists      been statistically imperfect in that they have based their
have affirmed its importance in text readability and most        findings on the results of a single training set (i.e.
readability formulas have included some measure of               Bormuth, 1971; Chall & Dale; 1995). While performance
syntactic complexity (e.g. Bormuth, 1969; Chall & Dale,          on a single training set allows conclusions regarding how
1995; Kintsch, 1979). Because longer sentences are a             well variables predict the difficulty of the texts in that set,
rough estimate of the number of propositions contained,          those conclusions may not be extendible to an
the variable number of words per sentence was selected           independent test set (Whitten & Frank, 2005). The
for this study.                                                  problem, of course, is the difficulty of creating
                                                                 sufficiently large data sets.
Co-referentiality Coh-Metrix currently measures four                With a limited data set, as in this study, the question
forms of lexical co-reference between sentences: noun            becomes how to make the most of the available data. To
overlap, argument overlap, stem overlap, and content             address this problem, this study considers three
word overlap. Lexical co-referentiality was chosen as a          approaches to cross-validation. The first two approaches
predictor of readability because overlapping vocabulary          are simple estimates of cross-validation: adjusted R2 data
has been found to be an important aspect in processing           is decided on. Once the number of folds has been decided,
texts and can lead to reading gains and faster reading rates     each is used for testing and training in turn. In n-fold
(Rashotte & Torgesen, 1985). It has been shown to aid in         cross-validation, which will be used in this study, the n
text comprehension and reading speed (Kintsch & van              refers to the number of instances in the data set. Each
Dijk, 1978). For this, argument overlap was chosen to            instance in turn is left out and the remaining instances are
represent lexical co-referentiality. Argument overlap was        used as the training set (in this case 31) and the accuracy
selected as it is the most robust measure of lexical co-         of the model is tested on the model’s ability to predict the
referentiality in that it measures how often two sentences       one remaining instance. In the case of the data at hand,
                                                             199

predictors were taken from the training set and used in a          together produce a multiple correlation .954 and a
regression analysis of the first 31 texts. The B values and        corresponding R2 of .910. This signifies that the
the constant from that analysis were used to predict the           combination of the three variables alone accounts for 91%
value of the 32nd text. This text then became the first in         of the variance in the performance of the students on the
our testing set. This process was repeated for all 32 texts,       32 cloze tests based on the Bormuth passages.
creating a testing set. The predicted values were then
correlated with the actual values (the mean cloze scores)                     Table 1:Descriptive Statistics
to test the model for performance on an independent
testing set. All of these models (adjusted R2, SURE
                                                                                                          Std.
estimate, and n-fold cross-validation) are important,
                                                                      Variable               Mean         Deviation    N
because if a model can be generalized, then it is likely
capable of accurately predicting the same outcome                     Predicted Mean
variable from the same set of predictors in a different text          Cloze Scores           458.209      54.699       32
group (Field, 2005).
                                                                      Predictor
                          Results                                     Words per Sentence       15.872      5.154       32
                                                                      CELEX Frequency           1.184      0.416       32
Pearson Correlations                                                  Argument Overlap          0.206      0.121       32
When comparing the three selected variables to the
Bormuth mean cloze scores, significant correlations were           Cross validation
reported for all indices. Correlations between the Bormuth
mean cloze scores and the number of words in a sentence            Two estimates of cross-validation were conducted. The
were significant (N = 32, r = -0.908, p < 0.001), as was           adjusted R2 for the regression analysis was .90 and the
the CELEX word frequency measures (N = 32, r = 0.826,              Stein’s Unbiased Risk Estimate (SURE) was .89.
p < 0.05) and the argument overlap measure (N = 32, r =            Considering that these two estimates are very similar to
0.686, p < 0.001).                                                 the observed R2 (.91), the estimates seem to support that
                                                                   the cross-validity of the model is good. As these are only
Multiple Regression Analysis                                       estimates, though, a n-fold cross-validation model was
                                                                   constructed. A correlation between the predicted values of
In order to estimate the degree to which the chosen                the testing set and the actual values revealed a significant
independent variables were collectively related to                 correlation (N = 32, r = 0.94, p < 0.001), demonstrating
predicting the difficulty of the Bormuth passages, the             that the predictors perform well on an independent testing
dependent and independent variables were investigated              set.
using a multiple regression analysis. Descriptive statistics
for the dependent and independent variables are presented
in Table 1, and results for the regression analysis are in                                 Discussion
Table 2. The variables were also checked for outliers and          A combination of three variables from Coh-Metrix
multicollinearity. For outliers, the Durbin-Watson statistic       predicted 91% of variance in cloze scores from the
was 2.672, which is less than 3 and greater than 1, implies        Bormuth (1971) dataset. Readability formulas based on
that there are no independent errors caused by residuals.          Chall and Dale (1995) and Bormuth (1969) achieved
Coefficients were checked for tolerance with all tolerance         similar results. Comparison of the adjusted R2 value
levels well beyond the .2 threshold, indicating that the           between this study and earlier studies seems unwise
model data did not suffer from multicollinearity.                  because of the very high correlations involved. The fact
   The results of the forced entry multiple regression             that diverse methods of measuring text difficulty all
analysis indicate that the combination of syntactic                achieve correlations of .9 or above indicate that a ceiling
complexity scores (words per sentence), CELEX                      effect is present. It seems to be the case that a variety of
frequency scores, and argument overlap scores taken                measures of text difficulty will achieve very high
                 Table 2: Regression Analysis of Three Independent Variables Predicting Reading Difficulty 2
                                            Unstandardized   Standardized           Standard
Variable                                    Coefficient      Coefficient            Error          T            P
Words per Sentence                          -5.896           -0.556                    .973         -6.061      0.000
Average Sentence Word Frequency             48.554            0.370                 10.381           4.677      0.000
Argument Overlap                            65.869            0.146                 33.854           1.946      0.062
                                                             200

correlations on this dataset. Because of this, we can               conventions. This may limit its generalizability as a
conclude that the measures used here are effective                  testbed for reading formulas, especially for less formal,
measures of text difficulty, as are readability measures            genres such as children's or adolescent fiction. To
such as the Dale-Chall readability score. We cannot,                determine which text measure is the best from several
however, conclusively determine which of these is more              competing measures (such as Coh-Metrix variables, the
effective: such a task would require a larger dataset with          Dale-Chall readability formula, etc.) a larger study would
less variability between texts.                                     need to be conducted, using more passages, and choosing
   Reading researchers have been arguing for some time              passages from genres more relevant to general reading. In
that measures of text difficulty are needed that directly           addition, the Bormuth passage set used cloze scores as its
take into account cognitive processing load, the individual         readability criteria. Cloze scoring, by its nature, appears
cognitive aptitude of the learner, and how that learner             connected to sentence length and word frequency because
interacts with a text (Kintsch, 1994; McNamara et al.,              excised frequent words would be easier to estimate and
1996; Miller & Kintsch, 1980; Gernsbacher, 1997;                    shorter sentences would allow for the inference of words
McNamara, 2001; McNamara & Kintsch, 1996). The                      based on limited part of speech likelihood. Thus passage
current study, which demonstrates that cognitively-                 difficulty based on cloze scoring likely correlates highly
inspired indices also provide effective measures of                 with readability formulas that measure these variables
reading difficulty, is a step in that direction. In particular,     such as Flesch Kincaid (1975) and Flesch Reading Ease
this study addresses two salient concerns about readability         (1948). Future studies that consider more robust cognitive
formulas raised by Chall and Dale (1995). First, the                variables would likely benefit from readability
formula relies on both traditional factors as well as               assessments based on recall or comprehension scores and
cognitive and structural factors, but not on one approach           not cloze scores. Future work should also consider
alone. Second, the formula is not difficult to apply or             participants’ background knowledge and account for how
more time consuming because it is automated.                        this knowledge interacts with text readability (McNamara
   While the foundations of this study were classic                 et al., 1996).
readability studies such as Bormuth’s (1971) and Chall                 While much work remains to be done, the current study
and Dale’s (1995), the approaches are dissimilar as they            contributes to the field of text readability by
are partially based on current theories of cognition. Using         demonstrating that a synthesis of traditional readability
Bormuth’s mean cloze scores, the three Coh-Metrix                   measures and indices of cohesion is a viable method for
variables, one employing lexical co-referentiality, one             evaluating text difficulty. This work has immediate
estimating syntactic complexity, and one measuring word             transfer potential in that it allows for more theoretically
frequency, yielded an accurate prediction of reading                grounded approaches to readability that are easily
difficulty of Bormuth’s classic passage. The results are            accessible and immediately applicable. As such, this
encouraging because the analysis incorporated variables             study provides educators with another tool from which to
that are directly related to cognitive processes of reading         select appropriate texts to match the needs of their
and show strong correlations to text readability using              students.
variables that are not all tied to superficial aspects of
reading, as past readability formulas have.                                            Acknowledgments
   Moreover, the readability formula presented here is
                                                                    The research was supported in part by the Institute for
exploratory and only considers three indices out of the
                                                                    Education Sciences (IES R305G020018-02). Any
hundred or so available through Coh-Metrix. These
                                                                    opinions, findings, and conclusions or recommendations
additional indices will allow future researchers options for        expressed in this material are those of the authors and do
incorporating measurements of cohesion such as                      not necessarily reflect the views of the IES.
anaphoric resolution, temporal and spatial information,
psycholinguistic measurement of word information, and
indices of causality, to name but a few. Traditional                                        References
readability formulas such as Bormuth’s and Dale and                 Baayen, R. H., Piepenbrock, R., & van Rijn, H. (Eds.)
Chall’s do not allow for such an extension nor the                     (1993). The CELEX Lexical Database (CD-ROM).
opportunity for deeper level analysis of text language                 Philadelphia,      Pennsylvania:      Linguistic   Data
features.                                                              Consortium.
                                                                    Bruce, B., & Rubin, A. (1988). Readability formulas:
                        Conclusion                                     Matching tool and task. In A. Davison & G. M. Green
                                                                       (Eds.), Linguistic complexity and text comprehension:
This study is limited by the small number of passages in               Readability issues reconsidered (pp. 5-22). Hillsdale,
the Bormuth dataset, and by the high correlations                      New Jersey: Erlbaum.
obtained using the dataset, which suggest a ceiling effect.         Bruce, B., Rubin, A., & Starr, K. (1981). Why readability
Furthermore, the passages are from the genre of academic               formulas fail. Reading Education Report No. 28.
writing. This genre has many unique characteristics, such
as the requirement for referencing, objectivity, and other
                                                                201

  Urbana: University of Illinois Center for the Study of          Technical Training, U. S. Naval Air Station, Memphis,
  Reading. (ERIC Doc. No. ED 205 915)                             TN
Bormuth, J. R. (1969). Development of readability               Kintsch, W. (1979). On Modeling Comprehension.
  analyses. Final Report, Project No. 7-0052, Contract            Educational Psychologist, 14, 3-14.
  No. 1, OEC-3-7-070052-0326. Washington, DC: U. S.             Kintsch, W. (1994). Text comprehension, memory, and
  Office of Education.                                            learning. American Psychologist , 49, 294-303.
Bormuth, J.R. (1971). Development of standards of               Kintsch, W., & Van Dijk, T. A. (1978). Toward a model
  readability: Toward a rational criterion of passage             of text comprehension and production. Psychological
  performance. Final report, U.S. Office of Education,            Review, 85, 363−394.
  Project No. 9-0237. Chicago: University of Chicago.           Kintsch, W., Britton, B.K., Fletcher, C.R., Mannes, S.M.,
Caylor, J.S., Sticht, T.G., Fox, L.C., & Ford, J.P. (1973).       Nathan, M.J. (1993). A comprehension-based approach
  Methodologies for determining reading requirements of           to learning and understanding. The psychology of
  military occupational specialties. Technical report No.         learning and motivation, 30, 165-214.
  73-5. Alexandria, Virginia: Human Resources Research          Kintsch, W. & Vipond, D. (1979). Reading
  Organization.                                                   comprehension and readability in educational practice
Chall, J. (1958). Readability: An appraisal of research and       and psychological theory. In LG. Nilsson (Ed.)
  applications. Columbus, Ohio: Ohio State University             Perspectives on Memory Research (pp. 329-366).
  Press                                                           Hillsdale, New Jersey: Erlbaum.
Chall, J. & Dale, E. (1995). Readability revisited: The         Kintsch, W., Welsch, D., Schmalhofer, F., & Zimny, S.
  New Dale-Chall Readability Formula. Cambridge,                  (1990). Sentence memory: A theoretical analysis.
  Massachusetts: Brookline Books.                                 Journal of Memory and Language, 29, 133–159.
Davison, A., & Kantor, R. (1982). On the failure of             MacGinitie, W. & Tretiak, R. (1971). Sentence depth
  readability formulas to define readable texts: A case           measures as predictors of reading difficulty. Reading
  study from adaptations. Reading Research Quarterly.             Research Quarterly, 6, 364-376.
  17, 187-209.                                                  McNamara, D. S. (2001). Reading both high-coherence
Field, A. (2005). Discovering Statistics Using SPSS.              and low-coherence texts: Effects of text sequence and
  London: Sage Publications, Ltd.                                 prior knowledge. Canadian Journal of Experimental
Flesch, R. (1948). A new readability yardstick. Journal of        Psychology, 55, 51-62.
  Applied Psychology, 32, 221-233.                              McNamara, D.S., Kintsch, E., Butler-Songer, N., &
Fry, E. (1989). Reading formulas: Maligned but valid.             Kintsch, W. (1996). Are good texts always better?
  Journal of Reading, 32, 292-297.                                Interactions of text coherence, background knowledge,
Gernsbacher, M. (1997). Coherence cues mapping during             and levels of understanding in learning from text.
  comprehension. In Costermans, J., and Fayol, M.,                Cognition and Instruction, 14, 1-43.
  (Eds.), Processing Interclausal Relationships. Studies        Miller, G.R. & Coleman, E. B. (1967). A set of thirty-six
  in the Production and Comprehension of Text (3-22).             prose passages calibrated for complexity. Journal of
  Mahwah, New Jersey: Erlbaum.                                    Verbal Learning and Verbal Behavior, 6, 851-854.
Graesser, A., McNamara, D., Louwerse, M., & Cai, Z.             Miller, J.R., & Kintsch,W. (1980). Readability and recall
  (2004). Coh-Metrix: Analysis of text on cohesion and            of short prose passages: A theoretical analysis. Journal
  language. Behavioral Research Methods, Instruments,             of Experimental Behavior: Human Learning and
  and Computers, 36, 193-202.                                     Memory, 6, 335-354.
Haberlandt, K. F., & Graesser, A. C. (1985). Component          Rashotte, C.A. & Torgesen, J.K. (1985). Repeated reading
  processes in text comprehension and some of their               and reading fluency in learning disabled children.
  interactions. Journal of Experimental Psychology:               Reading Research Quarterly, 20, 180-188.
  General, 114, 357-374.                                        Rubin, A. (1985). How useful are readability formulas? In
Jurafsky, D., & Martin, J.H. (2000). Speech and language          J. Osborn, P. T. Wilson, & R. C. Anderson (Eds.),
  processing: An introduction to natural language                 Reading education: Foundations for a literate America
  processing, computational linguistics, and speech               (pp. 61-77). Lexington, MA: Lexington Books.
  recognition. Upper Saddle River, NJ: Prentice-Hall.           Smith, F. (1988). Understanding reading: a
Just, M. A., & Carpenter, P. A. (1980). A theory of               psycholinguistic analysis of reading and learning to
  reading: From eye fixations to comprehension.                   read. Hillsdale, New Jersey: Erlbaum.
  Psychological Review, 87, 329-354.                            Silberstein, S. (1994). Techniques and resources in
Kincaid, J.P., Fishburne, R.P., Rogers, R. L., & Chissom,         teaching reading. New York: Oxford University Press.
  B.S. (1975). Derivation of new readability formulas           Whitten, I.A., & Frank, E. (2005). Data Mining. San
  (Automated Readability Index, Fog Count and Flesch              Francisco: Elsevier.
  Reading Ease Formula) for Navy enlisted personnel.
  Research Branch Report 8-75, Millington, TN: Naval
                                                            202

