UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Why Adult Language Learning is Harder: A Computational Model of the Consequences of
Cultural Selection for Learnability
Permalink
https://escholarship.org/uc/item/2zz7c15w
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Author
Nelson Jr., Robert N.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         Why Adult Language Learning is Harder: A Computational Model of the
                           Consequences of Cultural Selection for Learnability.
                                         Robert N. Nelson Jr. (rnnelson@purdue.edu)
                                               Department of English, Purdue University
                                                        West Lafayette, IN. 47906
                             Abstract                                   to an account of the structural imbalances observable in
                                                                        language phonotactics. Like Kirby (1996), however, this
  This paper reports on a limited model of language evolution
  that incorporates transmission noise and errorful learning as         model holds that adaptation occurs through iterations of
  sources of variation. The model illustrates how the adaptation        cultural transmission. To explore this hypothesis, an
  of language to the statistical learning mechanisms of infants         evolutionary model of errorful learning with noisy
  may be a factor in the apparent ceiling on adult second               intergenerational transmission was developed. While ease of
  language achievement. The model is limited in its focus to            articulation and discrimination are the primary forces that
  only phonotactics because the probabilistic imbalances that           shape phonotactics, this model assumes that for any two or
  have been found in phonotactics have been found to be                 more sequences that require near equal articulatory and
  effective cues in the very first language learning task, speech       discriminatory effort, the one that is most ‘learnable’ will be
  segmentation (Saffran & Theissen, 2003; Mattys & Jusczyk,
                                                                        selected.
  2001), and in the organization of lexical memory (Vitevitch,
  Luce, Pisoni & Auer, 1999). The argument that this model                  All languages exhibit regular phonotactic patterning.
  supports is that these probabilistic imbalances are the result of     While some of this structural imbalance is physiological in
  the cultural selection of more learnable variants across              origin, much of it is not, and constraints like vowel harmony
  generations of learners, and that this process has produced           in Finnish and Turkish or Czech word-final voiclessness,
  sequences that help the child learner while confounding the           which cannot be ascribed to articulatory pressures, must be
  adult learner. The child learner is aided by specific                 implicit knowledge that is culturally transmitted. Also not
  phonotactic cues that correlate with word and syllable                due to articulatory constraint are non-absolute, probabilistic
  boundaries (e.g. the English prohibition on word initial ‘-ng’        imbalances such as the pairing /uf/1 which occurs in
  and Czech word-final voicelessness). These cues are often
                                                                         English much more frequently than would be predicted by
  invisible or misleading to the adult learner (e.g. Broselow,
  Chen & Wang, 1998; Flege & MacKay, 2004), contributing to              the independent probabilities of either /u/ or /f/ (Kessler &
  errors in both perception and production.                              Treiman, 1997). Certain imbalances, like the prohibition on
                                                                         obstruents in Mandarin syllable codas, are believed to
  Keywords: Language Evolution; Critical Period Effect.                  influence both the production and perception of second
                                                                         languages (e.g. Broselow, Chen & Wang, 1998).
                           Background                                       The model presented here assumes that any phonotactic
                                                                         sequence that is easier to learn than a competitor sequence
    Most accounts of our maturational loss of linguistic
                                                                         will be selected for representation in lexical memory. And,
adaptability have focused on age-correlated changes in the
                                                                         while such selection is certainly influenced by the
learner. This report focuses on the object of learning,
                                                                         independent probabilities of the phonemes, true selective
language, and asks why language is harder for adults to
                                                                         advantage is the predictive efficiency of phones or
learn than for infants. The hypothesis that this project
                                                                         sequences of phones. This model shows that phonotactic
advances is that the adaptation of language to children is a
                                                                         imbalances may be the result of generations of language
factor in the age-associated decline in language learning
                                                                         learners selecting the most learnable forms of a language,
achievement. To this end, a model is presented which shows
                                                                         and that these patterns (1) make language easier for children
that, by integrating errors that occur during use and learning,
                                                                         to learn, (2) are partially responsible for the commonly
an artificial language that is initially only constrained by
                                                                         observed differences in outcomes between child and adult
articulatory considerations develops a more fine grained and
                                                                         learning, and (3) account for some of the distributional
informative structure whose distributional characteristics are
                                                                         characteristics of phonemes in natural languages.
highly similar to both natural language text and speech
samples. Importantly, the model also shows that networks,
when trained on one of the artificial languages evolved                                           The Model
through this process and then tested on another, display the                This is not a model of language evolution, but rather the
kind of cue blocking effect that held by Ellis (2006) to be              change through adaptation of a part of language. As Dell,
the source of ‘fragility’ in second language learning.                   Reed, Adams, and Meyer (2000) note, all languages have
  Unlike other models of the cultural selection of language,             patterns at many different levels, and all of these patterns
such as Kirby (1996), which are concerned with the
emergence of grammatical universals, this model is limited               1
                                                                           As in ‘stuff’.
                                                                    1337

are available and informative to the learner. It should be        variants). Ease of learning has been proposed as a selective
reasonable to assume, then, that to the degree that languages     feature in language evolution by William Labov (1994),
evolve at all, all of these different levels of systematicity     Morten Christiansen (1994), Terrence Deacon (1997), and
may be following individual (albeit mutually constraining)        Simon Kirby (1996). This model is different from those
trajectories through an evolutionary ‘design space’ (Dennett,     above, however, in that it identifies sources of variation
1995; Eigen & Winkler-Oswatitsch, 1992).                          (‘mutations’) that have strong correlates in the ‘real world’
                                                                  use of language. The sources of variation operationalized
The Population                                                    in this model are:
    The population that was exposed to learnability-based             1. Random bit-switching. Random bit-switching here
selection was comprised of words from the lexicon of an           represents types of variation that may enter a language
artificial language. The corpora showed structure at three        through inter-learner phenomena: contact between
levels. They were composed of 100-120 simple sentences            languages, dialects and/or idiolects. These mutations tend to
(‘NVN’). The lexicon was accordingly divided into two             be divergent, in that they increase the variety of forms
classes: N (67 words), and V (33 words). A pseudo-random          available to the learner.
number generator assigned words to slots in the sentences.            2. Integration of error. Integration of error is meant to
Words were strings of 3 to 11 ‘phones’, and were generated        operationalize types of variation that may enter a language
from a list of 15 phones that were each composed of 13            through intra-learner phenomena like the realization of the
features. There were 10 C (consonant) class phones and 5 V        past tense of ‘bring’ as ‘brang’ on analogy with other
(vowel) class phones. In accordance with the observation          present/past pairs. These errors tend to reduce the amount of
that words in natural languages are built from syllables that     variety available to the learner.
tend to adhere to an onset-rhyme-coda structure, a CV or              One reason to consider random mutation in a model of
CVC alternating structure was imposed on them. A finite           language change is that all transmission of information
state transducer (FST) generated 100 strings of a form such       implies noise. And it thus seems reasonable to adapt
that no more than two phones from the C (consonant) class         Shannon & Weaver’s (1949) original description—the
could occur before a phone from the V (vowel) class in any        stochastic ‘flipping’ of a bit as it passes through a noisy
string. Importantly, in any C or V position, any C- or V-         channel. This may seem to be an impossible simplification
class phone occurred with equal probability in the initial        of the human situation, which is concerned with the
lexicon. The phones were composed of thirteen features and        transmission of cultural meaning through language, but it
thus represented on a thirteen dimensional vector. Each           fits because when comprehending an utterance we select or
place on the vector stood for a real feature, so, for example,    construct the meanings of messages based on a sparse signal
the ‘phone’ /k/ was composed of the features +velar, +stop,       sent by an interlocutor through a noisy environment.
and –voice:                                                           Random bit-switching involved the switching of two
             {0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0} Æ /k/        positions on the feature vector if a random number between
   While the phone /a/ was composed of the features +voice,       0 and 1 was greater than a set threshold (0.99)2. For
+back, and +low:                                                  example, if the module took in the stop /k/ and then
             {0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1} Æ /a/        generated the number .991, /k/ could become the fricative
   Fifteen phones were generated for the initial ‘phone           /x/ with the switching of the bits in the sixth and seventh
inventory’, but during the operation of the model the             positions:
number of phones was extended by mutation to 21.                       a) {0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0} Æ /k/
                                                                       b) {0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0} Æ /x/
The Landscape                                                          The ‘mutated’ version of the phone would then replace
                                                                   one instance of the original in the corpus. After training,
    The landscape that shaped the population through
                                                                   network performance would be evaluated on both the
learnability-based selection was sequence learning. The            original and the mutated form. If the network performed
ability of Simple Recurrent Networks (SRN) to approximate
                                                                   better on the mutated form, it was passed into the lexicon,
a Bayesian analysis allowed them to function as the                replacing the previous form. Thus, for example, the word
landscape here. Predictive dependencies between phonemes
                                                                   /kekt/ became /kext/ in the sixth generation of the ‘L2’ run
in the stream of speech has been shown to be extremely             of the model. The model was limited to four types of switch
valuable for infants in the process of speech segmentation         so that only pronounceable phonemes were produced. Each
(Saffran & Theissen, 2003; Gómez & Gerken, 2000), and
                                                                   bit-switch was meant to represent exposure to a variant as
SRNs have been shown to model this data nicely (Elman,             the result of contact with a specific ‘dialect’ containing that
1990; Christiansen, Allen & Seidenberg, 1998;).
                                                                   variant:
                                                                      1. +PL Æ +FRIC. This mutation replaced stops with
Sources of Variation                                              homorganic fricatives.
   Elements of culture can accrue modifications during use,           2. +FRIC Æ +PL. This mutation replaced fricatives with
and these modifications can be transmitted to later               homorganic stops.
generations that improve the fitness of the enculturated
individual with respect to the environment or the fitness of
the culture with respect to the learner (Sperber, 1996,            2
                                                                     All random numbers were generated with the Mathematica
identifies this as an epidemiological feature of cultural         Random function, which uses the time of day at start-up as seed.
                                                              1338

   3. +FRNT Æ +BCK. This mutation moved the vocalic                   variants that can pass into the corpora. This parameter is
place of articulation.                                                intended to reflect the way that communicative requirements
   4. +BCK Æ +FRNT. This mutation moved the place of                  constrain language change in vivo. The second way that
articulation forward.                                                 change is modulated is through the interaction of the two
   The second method of introducing variation involved the            types of mutation (random bit-switching and integration of
inclusion of a network’s mistakes at one generation into the          error). Integration of error is compressive in that it tends to
corpus for the following generation. Since the task of the            collapse the language onto the most frequent phones and n-
network was predictive auto-association, the input and                grams. Random bit-switching brakes this compressive effect
teaching patterns were identical. However, the actual output          by providing low-frequency, high-information patterns that
was always close to the target (of the same C or V class, and         are resistant to change.
matching the +/-voice feature), but seldom ‘correct’3.
Integration of error was meant to instantiate types of                                           Results
variation that may enter a language through intra-learner               The results are presented in three sections. The first two
phenomena. These errors in learning are realized as                   describe tests of two artificial languages that were generated
overgeneralizations, not unlike the production of the past            by the same FST (‘L1’ and ‘L2’) and then subjected to 20
tense of ‘bring’ as ‘brang’ on analogy with present/past              generations of learnability-based selection. The third
pairs like ‘sing : sang’. The specific method was                     section examines the distributional characteristics of the
straightforward: after learning was stopped, a test corpus            ‘evolved’ corpora.
was presented to the network. Every vector produced by the
network in response was compared by its cosine with every             Section One The first measure compared the performance
possible target phone. The phone which showed the highest             of 10 pairs of SRNs (13-40-13) trained on both the 0th and
cosine with the actual output was considered to be the actual        20th generation of the ‘L1’ lexicon. The results are
output of the model. With a very low average probability             summarized in figure 1. The cosine averages on the y-axis
(p<=0.01), these highest cosine phones were substituted into         are for each respective entire corpus, and reflect the average
a temporary lexicon that could be tested against the original        similarity of the network output to the target of learning.
lexicon. Importantly, the level of network error (MSE) was
                                                                         0.75
interpreted as its confidence level and, accordingly, where
error was highest, the threshold for mutation was lowered.                0.7
So, while the average likelihood of any variant being passed             0.65
over to the lexicon was 0.01, the likelihood for the few                  0.6
phones showing the highest MSE was as high as 0.1. This                                                                          G20
                                                                         0.55                                                    G0
operationalizes the observation that the less well practiced a
                                                                          0.5
skill is, the more likely mistakes are to occur. The
temporary lexicon was then tested against training lexicon               0.45
and the winning patterns were passed onto the next                        0.4
generation. Integration of error produced the most winning                      1    5   10  50  100  500  1K  5K  10K 50K 100K 250K
                                                                        # of sweeps
variants, with 62% being passed on, versus 42% of the
random bit-switch variants.
                                                                                                  Figure 1.
   While the idea of variation has been important in the
evolutionary modeling of language (cf. Kirby, 1996), there
                                                                           This figure shows that 20 generations of selection for
has not been much discussion of the role of mutation in
                                                                     learnability had created, in the lexicon, enough
language evolution. This may partly be due to the sense of
                                                                     distributional, structural imbalance to increase the average
deliberateness in linguistic innovation that would seem to
                                                                     cosine of the network output and the target by 14.2%. The
make the models Lamarckian. Indeed, the difference
                                                                     exact nature of the structural imbalance will be discussed
between human and animal culture may be that human
                                                                     below, but it is generally due to the efficient ‘chunking’ of
cultural is deliberately cumulative with respect to
                                                                     initially random characters into high frequency bi- and tri-
modifications (e.g. ‘the ratchet effect’, Tomasello, 1999).
                                                                     grams (i.e. emergence of phonotactic patterns) and the
Edelman (1992) in fact holds that all cultural evolution is
                                                                     predictive value of low frequency phones (especially those
Lamarckian. Dennett (1995), however, has disagreed, noting
                                                                     recruited through mutations).
that this charge assumes the viewpoint of the holder of the
variant. A more rational viewpoint would be that of the
                                                                     Section Two For the second measure, networks were
variant, since it is the one ‘struggling’ for survival and
                                                                     trained on a corpus generated from L1G0 and L1G20. Then
unable to directly affect its own fitness.
                                                                     they were evaluated on their ability to process two new
   Nearly as important as the source of variation is the rate
                                                                     corpora: one generated from the L1G20 lexicon, and one
of mutation. There are two ways in which evolutionary
                                                                     generated from the L2G20 lexicon (i.e. the ‘L2’ lexicon that
change in this model is gated. First, by setting a parameter
                                                                     had undergone 20 generations of learnability based
that constrains language change by limiting the number of
                                                                     selection). The results are summarized in Figures 2 and 3.
3
                                                                     Note that, in Figure 1, the two data points at each number of
  An output was correct if its cosine with the actual target was     sweeps represent performance by the same network on two
higher than its cosine with any other possible target.
                                                                 1339

different data sets, whereas data points in Figures 2 and 3 at          weak cues in L1G20. These are statistical cues that, on their
the corresponding pairs represent performance of two                    own, possess very weak predictive value but become strong
different networks. Figure 2 shows that training networks on            predictors of patterns in the data when correlated with each
L1G0 does not increase or decrease their ability to predict             other. At 10,000 sweeps, networks begin to rely
sequences in L2G0. Figure 3 shows that that networks                    predominantly on these systems of weak correlations, thus
trained on the L1G20 found sequences from the L2G20                     performance on L2G20 and the Japanese data falls of
lexicon to be equally predictable in the early stages of                significantly in their respective groups of networks.
learning (the first 50 sweeps), but not so in later stages.                  0.8
                                                                            0.75
  0.65
                                                                             0.7
                                                                            0.65                                                          Jpns
   0.6
                                                                             0.6                                                          Eng
                                                               L1G0         0.55
  0.55
                                                               L2G0          0.5
                                                                            0.45
   0.5
                                                                             0.4
                                                                            0.35
  0.45                                                                    # sweeps 5    10   50   100  500  1k   5k   10k  50k 100k 250k 500k
   0.4
         5     10    50     100   500   1K   5K    10K  50K   100K                                      Figure 4.
                                                                              Section Three Cultural evolution of the type modeled
                              Figure 2.                                  here is driven by a ‘rich-get-richer’ effect that exploits
                                                                         statistical variations in (1) the initial random distribution of
   The y axis in figures 2 and 3 shows the mean cosine of                features and (2) the early rounds of mutation/selection. This
the network output with the target, while the x axis shows               type of effect has received a lot of attention recently as a
the number of sweeps through the training data.                          statistical mechanism behind the topography of Scale-Free
   0.75                                                                  Networks (e.g. Albert & Barabasi, 2002). However, in the
    0.7
                                                                         context of this model, it can be best understood as an
                                                                         instance of the Polya’s Urn contagion model4. If the
   0.65                                                      L1G20       mechanism posited in this model, integration of
                                                             L2G20
                                                                         transmission and learning errors, operates in real world, the
    0.6
                                                                         distributions that are the product of the model should look
   0.55                                                                  like the distributions we see in real life.
                                                                            Figure 5 shows a log-log plot of the frequency of
    0.5
                                                                         characters in three 100 sentence corpora alongside a
   0.45                                                                  frequency count of phonemes from a 750,000 phoneme
         5    10   50   100   500  1K  5K  10K  50K 100K 250K 500K       corpus of spoken British (RP) English (Fry, 1947). The
                                                                         second data set (‘TS’) is composed of the first 100 sentences
                                                                         of the second chapter of Mark Twain’s (1876) ‘Tom
                              Figure 3.                                  Sawyer’. The third data set (‘G20’) was generated from the
                                                                         L1G20 lexicon, the fourth data set is the G0 corpus. The
   Figure 3 shows that networks trained on L1 sequences                  process embodied by this model thus produces corpora
lose sensitivity to the underlying similarities of the L1 and            whose distributions are highly similar to both natural
L2 lexica while gaining sensitivity to finer-grained                     language text and speech samples.
dependencies in the L1. However, whether these patterns of                  In any word produced by the L1G0 FSA, all characters
network learning are meaningful depends partially on how                 are equally likely and the most compressed representation of
they hold over natural languages. Figure 4 shows the results             any word in the L1G0 lexicon would be the word itself.
of training similar networks (18-40-18 SRNs) on                          However, by the 20th generation, the lexicon includes
transcriptions of data from the Childes database                         several different recurring sequences. These sequences
(MacWhinney, 2000). Networks were trained on the                         reduce the entropy of the lexicon so any representation
Berenstein (English) data and then tested on the Miyata-Aki
(Japanese) data.
   Early in training, networks track each other because of (a)           4
                                                                           Notionally, Polya’s urn asks us to imagine a game played with an
the similar underlying structure of both languages (both Ls              urn that is filled with n red pebbles and n black pebbles. The game
are composed of CV and/or CCV sequences), and (b) since                  has one rule: if you first draw a red pebble, you have to put it back
half of all C-class phones are +voice while all of the V-class           and then also replace one of the black pebbles with a red one (or
phones are +voice, a good early ‘hypothesis’ for these                   vice-versa if a black pebble is selected first). The pebbles are then
networks is to always guess +voice (thus being right 66% of              remixed. It is now a little more likely that you will draw a red
the time). However, as learning proceeds from the 50th                   pebble the next time. Eventually, the urn will be filled with either
                                                                         only red or only black pebbles, the other color having been driven
sweep, networks become sensitive to multiply correlated                  out.
                                                                    1340

(magnetic, neural, etc.) of the L1G20 lexicon requires less          versa, occurred in the first and last three positions. These
information than a representation of the G0 lexicon                  class changes led to the emergence of a VV sequence, [ou],
                                                         RP          which occurred in the first and second phone positions of
  1000
                                                         TS          five words by 20th generation.
                                                         G0                                                    G20 C
                                                                        0.2
                                                                                                               G20 V
                                                         G20
                                                                                                               G0 C
    100
                                                                       0.15                                    G0 V
                                                                        0.1
     10
                                                                       0.05
      1                                                                   0
                                                                               1   2    3    4    5    6    7    8     9   10  11
        1                       10                       100
                                                                                                Figure7.
                            Figure 5.
   . Consider the by-order decline in entropy illustrated in
                                                                                              Discussion
Table 1. This figure shows that, while the imbalance in                 This simple model evinces an evolutionary process that is
frequencies of individual characters does reduce entropy,            very similar to the Polya’s Urn contagion model. The results
the greatest gain of informativeness in the lexicon is through       described in section one show that this simple winner-take-
character dependencies (2nd order entropy).                          all process increases the number of recurring sequences in
                                                                     the lexicon. This in turn increased the ability of the
                   Table 1: Entropy of L1G20                         networks to predict items in these sequences. Section two
                                                                     showed that change through iterations of learning produced
                                                                     lexica that were broadly similar but specifically highly
                0th Order    1st Order       2nd Order
                                                                     dissimilar. The broad similarities meant that networks’
        G0          4.3         3.88            3.23                 initial hypotheses about the data generalized well from one
        G20         4.3         3.76             2.4                 set to the other, while the specific dissimilarities meant that
                                                                     continued learning of the subtle cue correlations of the L1
     Adaptation in this model decreases entropy, and thus the        data produced a weight set that was less able to derive
amount of information a learner needs to construct a                 useful information from the L2 set. In a sense, continued
language, by creating high frequency ‘chunks’ that can               learning increased the overshadowing of cues and produced
become routinized, and lower frequency chunks that are               a blocking (of associative learning) effect (Kamin, 1969;
highly informative. Low frequency phones are created in              Rescorla & Wagner, 1972), which is hypothesized by Ellis
two ways in the model. The first way is by driving their             (2006) to be the source of ‘fragility’ in second language
numbers down though gradual replacement (the ‘rich-get-              learning.
richer’ effect). The second is when mutations recruit novel             This occurs because the evolutionary process embodied
combinations of features from the space of possible phones.          by the model produces distributions of features that are
The resulting distribution of high and low frequency phones          similar across languages. For example, the number of
and sequences of phones increase the learnability of the             voiced consonants in all artificial languages evolved in this
lexica. High frequency ‘chunks’ are not very predictive, yet         model is increased by 12 to 14.5% by the 20th generation.
occur so frequently that they are easy to predict (and thus          This means that early learning about general features of the
produce low error in the networks). On the other hand, very          distributional nature of the language will generalize well
low frequency characters that have high ‘suprisal’ (like ‘q-‘        from language to the next. However, while some features
in English orthography) are difficult to predict (i.e. produce       may be common across languages, their particular
high error) but, once they occur, are reliably predictive of         combinations are not. As learning continues and networks
the subsequent phone.                                                become sensitive to multiply correlated cues, their ability to
   Recall that the mutation rate increased when the network          generalize thus drops and the systems of cue correlations
was less confident of its output (i.e. the rate was sensitive to     learned for the L1 becomes maladaptive in the face of an
network error signal). As a result of this, positionally             L2.
constrained sequences of phones (like /N/ in English)                   This interpretation is in concert with a number of
emerged under the error-integration condition as a response          developmental studies (e.g. Dell et al., 2000; Mattys &
to the high prediction error associated with word                    Jusczyk, 2001), but especially Coady & Aslin, (2004) and
boundaries. Figure 7 shows the average relative                      Iverson, et al., (2003). Coady & Aslin, (2004) found that
probabilities for the V- and C-class phones for each possible        older children, but not younger ones, were sensitive to “fine-
phone position in every word. The graph shows that most              grained acoustic-phonetic information in the developing
of the category changes, from V-class to C-class and vice            lexicon” and that this sensitivity continued to develop over
                                                                 1341

time while Iverson et al. (2003) found that early language         Gaygen, D. (1997). The effects of probabilistic phonotactics
learning experience altered low level perceptual processes.           on the segmentation of conituous speech. State University
This acquired insensitivity partially grounds the critical            of New York at Buffalo, Buffalo, NY.
period effect as a predictable outcome of learning in parallel     Eigen, M., & Winkler-Oswatitsch, R. (1992). Steps towards
processing, representationally distributed, sub-symbolic              life : a perspective on evolution (P. Woolley, Trans.).
networks. It is also consistent with findings from the Second         New York: Oxford University Press.
Language Acquisition literature, in which L1 phonotactics is       Elman, J. L. (1990). Finding Structure in Time. Cognitive
shown to be sound predictor of difficulties with the                  Science, 14(1), 179-211.
production and perception of L2 phonology (Broselow,               Flege, J. E., & MacKay, I. R. A. (2004). Percieving vowels
Chen & Wang, 1998; Flege & MacKay, 2004).                             in a second language. Studies in Second Language
  In sum, cultural evolution by selection for learnability            Acquisition, 26(1), 1-34.
increases the learnability of evolved lexica while producing       Gomez, R. L., & Gerken, L. (2000). Infant artificial
a ‘critical period effect’ in agents that learn them. Results         language learning and language acquisition. Trends in
also show that the accumulation of adaptations results in a           Cognitive Science, 5(4).
lexicon that is rich in probabilistic information (i.e. entropy    Iverson, P., Kuhl, P. K., Akahane-Yamada, R., Diesch, E.,
is minimized), which, in turn, predicts the type of                   Tohkura, Y., Ketterman, A., et al. (2003). A perceptual
distribution of phonemes and graphemes in natural                     interference account of acquisition difficulties for non-
languages, as well as the same type of by-order decline in            native phonemes. Cognition, 87.
entropy found in English by Shannon & Weaver (1949).               Kamin, L. J. (1969). Selective association and conditioning.
Finally, the model also predicts the emergence of                     In S. Scarr, S. W. Scarr & L. J. Kamin (Eds.),
phontactics sensu stricto (typical sequences that have typical        Fundamental issues in associative learning. Halifax,
positions) as a response to increased uncertainty at word             Nova Scotia: Dalhousie University Press.
boundaries.                                                        Kauffman, S. A. (1993). The origins of order : self
                                                                      organization and selection in evolution. New York:
                          References                                  Oxford University Press.
Albert, R., & Barabasi, A. L. (2002). Statistical mechanics        Kessler, B., & Treiman, R. (1997). Syllable Structure and
  of complex networks. Reviews of Modern Physics, 74(1),              the Distribution of Phonemes in English Syllables.
  47-97.                                                              Journal of Memory and Language, 37(3), 295-311.
Carpenter, G. A., Cohen, M. A., & Grossberg, S. (1987).            Kirby, S. (1996). Function, Selection and Innateness: the
  Computing with Neural Networks. Science, 235(4793),                 Emergence of Language Universals. University of
  1226-1227.                                                          Edinburgh, Scotland.
Coady, J. A., & Aslin, R. N. (2003). Phonological                   Labov, W. (1994). Principles of linguistic change. Vol. 1:
  neighbourhoods in the developing lexicon. Journal of                Internal factors: Blackwell Ltd. Oxford.
  Child Language, 30, 441-469.                                      MacWhinney, B. (2000). The CHILDES project: Tools for
Broselow, E., Chen, S.-I., & Wang, C. (1998). The                     analyzing talk. Third Edition.: Mahwah, NJ: Lawrence
  Emergence of the Unmarked in Second Language                        Erlbaum Associates.
  Phonology Studies in Second Language Acquisition 20,              Rescorla, R. A., & Wagner, A. R. (1972). A theory of
  261-280.                                                            Pavlovian conditioning:The effectiveness of
Christiansen, M. H. (1994). Infinite Languages, Finite                reinforcement and non-reinforcement. In R. A. Rescorla,
  Minds: Connectionism, Learning and Linguistic                       A. R. Wagner, A. H. Black & W. F. Prokasy (Eds.),
  Structure. Unpublished PhD Dissertation, University of              Classical conditioning II: Current research and theory.
  Edinburgh, Scotland.                                                New Haven, CT.: Yale University Press.
Deacon, T. W. (1997). The Symbolic Species: The Co-                 Saffran, J. R., & Thiessen, E. D. (2003). Pattern induction
  evolution of Language and the Brain: W.W. Norton.                   by infant language learners. Developmental Psychology,
Dell, G. S., Reed, K. D., Adams, D. R., & Meyer, A. S.                39(3), 484-494.
  (2000). Speech errors, phonotactic constraints, and               Shannon, C. E. & Weaver, W. (1949). The Mathematical
  implicit learning: a study of the role of experience in             Theory of Communication. University of Illinois Press.
  language production. Journal of Experimental                        Urbana.
  Psychology: Learning, Memory and Cognition, 26(6),               Sperber, D. (1996). Explaining Culture: A Naturalistic
  1355-1367.                                                          Approach: Blackwell, Ltd. Oxford.
Dennett, D. (1995). Darwin's Dangerous Idea: Evolution             Tomasello, M. (1999). The Cultural Origins of Human
  and the Meanings of Life. New York: Simon & Schuster.               Cognition. Boston, MA.: Harvard University Press.
Edelman, G. M. (1992). Brilliant Air, Brilliant Fire: On the       Vitevitch, M. S., Luce, P. A., Pisoni, D. B., & Auer, E. T.
  Matter of the Mind. New York: Basic Books.                          (1999). Phonotactics, neighborhood activation, and lexical
Fry, D. B. (1947). The frequency of occurrence of speech              access for spoken words. Brain and Language, 68(1-2),
  sounds in Southern English. Archives Néerlandaises de               306-311.
  Phonétique Expérimentale, 20.
                                                               1342

