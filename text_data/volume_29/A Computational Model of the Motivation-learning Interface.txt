UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Model of the Motivation-learning Interface
Permalink
https://escholarship.org/uc/item/3709m22k
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Saggar, Manish
Markman, Arthur B.
Maddox, W. Todd
et al.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    A Computational Model of the Motivation-learning Interface
                                              Manish Saggar (mishu@cs.utexas.edu)
                                  Department of Computer Science, University of Texas at Austin,
                                                         Austin, TX 78705 USA
                                      Arthur B Markman (markman@psy.utexas.edu)
                                         W Todd Maddox (maddox@psy.utexas.edu)
                                      Department of Psychology, University of Texas at Austin,
                                                         Austin, TX 78705 USA
                                            Risto Miikkulainen (risto@cs.utexas.edu)
                                  Department of Computer Science, University of Texas at Austin,
                                                         Austin, TX 78705 USA
                             Abstract                                  computational models (Markman, Maddox and Baldwin,
  This paper presents a computational model of how motivation
                                                                       2005).
  influences learning, elaborating on the empirical study of               This paper presents a computational model for perceptual
  Markman, Baldwin and Maddox (2005). In a decision                    classification that incorporates motivation. The model is
  criterion learning task with unequal payoffs, the subjects were      based on simple perceptron learning (Rosenblatt, 1958) with
  more likely to maximize the reward when their motivation             modifications that instantiate the influence of motivation.
  was in line with the reward structure (i.e. when they were in a          The paper first describes theories of motivation, and then
  regulatory fit), whereas they were more likely to maximize           presents the details of the computational model. Followed
  accuracy when their motivation did not match the reward
  structure (i.e. when they were in a regulatory mismatch). The        by presentation of results from model simulations and
  model accurately replicates this pattern of results, and also        evaluation of how accurately the model fits to human data.
  accounts for the individual subject's behavior. In addition, the     Next, a new phenomenon predicted by the model has been
  model makes the novel prediction that regulatory-fit subjects        demonstrated and tested against the human data, followed
  who are near the reward threshold will shift their strategy          by analyses of model parameters. Finally, future directions
  toward maximizing accuracy, whereas regulatory-mismatch              for research are outlined.
  subjects who are far from the reward threshold will shift their
  strategy toward maximizing reward. When the original data
  was reanalyzed, this model-driven prediction was confirmed.                                   Background
  These results constitute a first computational step towards           This section reviews Regulatory Focus Theory (Higgins,
  understanding how motivation influences learning and                  2000), and a framework developed for investigating the
  cognition.                                                            influence of motivation on behavior (Maddox, et al. 2005).
  Keywords: Computational modeling, Motivation, Learning,
  Regulatory focus.                                                     Regulatory Focus Theory
                                                                           The motivation literature distinguishes between approach
                         Introduction                                   and avoidance goals (Carver & Scheier, 1998; Lewin, 1935;
Many of the tasks in our day-to-day life require us to choose           Markman & Brendl, 2000). Goals with positive states that
one option over another. Knowingly or unknowingly we                    one wishes to achieve are called approach goals, while
make decisions at every step and choose our behaviors from              goals with negative states that one wishes to avoid are called
a large repertoire of possibilities. Cognition plays an                 avoidance goals. Higgins (1987, 1997) extended this idea
important role in selection of these behaviors, but our                 by proposing regulatory focus theory, which suggests that -
motivational state to approach positive outcomes or avoid               orthogonal to approach and avoidance goals - there are
negative outcomes also affects which behaviors we select                psychological states of readiness or sensitivity for potential
(Maddox, Markman and Baldwin, 2005). Cognitive research                 gains/non-gains or losses/non-losses that tune the sensitivity
has focused on information processing and its effects on                of the motivational system. On this theory, a promotion
learning and behavior with little attention paid to                     focus is a state that focuses the motivational system on the
motivation. Recent research in social cognition and                     presence or absence of gains in the environment, and a
cognitive science has begun to bridge this gap (see Maddox,             prevention focus is a state that focuses the motivational
Markman and Baldwin, 2005, for a review). Although                      system on the presence or absence of losses.
there have been advances in the interface between                          Higgins and colleagues (Higgins, 1987, 1997; Higgins, et
motivation and learning, this work has been driven mostly               al. 1994) outlined three aspects of regulatory focus. First,
by experimental techniques that explore the operation of                chronic focus, is an a priori predisposition toward a
motivational systems indirectly, rather than by                         promotion or prevention focus. Higgins (1987) suggested
                                                                        that a promotion focus is associated with a person’s desire
                                                                   1439

to achieve ideal states (e.g., hopes, desires, or aspirations)     the categories, d’, was 1) in order to clearly show the effects
while a prevention focus is associated with a person’s desire      of motivational manipulations on learning.
to achieve ought states (e.g., duties, obligations etc.). Thus,       Three payoff matrices were devised to explore the
chronic focus could also describe a person’s attributes.           influence of regulatory fit on category learning through the
   Second, there is situational focus (also referred to as         associated payoff matrix (Table 1). In all cases, correct
incentive focus), which is induced by properties of current        responses yielded a higher payoff (or lower punishment) for
circumstances. Someone pursuing a potential gain, is placed        one category than the other, while incorrect responses were
in a state of readiness for gain and non-gain situations in        treated equally for both categories. In the mixed matrix,
general. Likewise, someone attempting to avoid a loss is           subjects were rewarded with points for correct responses
placed in a state of readiness for loss and non-loss situations    and penalized for incorrect responses. In the gain matrix,
in general. Situational focus can be manipulated                   subjects received points for both correct and incorrect
experimentally (e.g., Crowe and Higgins, 1997; Markman,            responses, though they received more points for a correct
Kim, & Brendl, 2005).                                              response than for an incorrect response. In the loss matrix,
   A third key aspect of regulatory focus is the idea of           subjects lost points for both correct and incorrect responses,
regulatory fit (Avnet & Higgins, 2003; Higgins, 2000;              though they lost fewer points for correct responses than for
Higgins, et al. 2003; Shah et al, 1998). A regulatory fit can      incorrect responses.
occur in a number of ways. This paper concentrates on a
match between the current regulatory focus and the reward
structure of the task (also referred to as goal attainment
means; Crowe & Higgins, 1997; Higgins, et al. 1994; Shah,
et al. 1998). For example, in many learning experiments,
people receive points for some responses and lose points for
others. One might try to maximize the number of points
obtained by focusing on gaining points or alternatively by
focusing on avoiding the loss of points. Situations in which
one can gain points involve a gain/non-gain reward
structure. Situations in which one can lose points involve a
loss/non-loss reward structure.                                     Figure 1: Category distributions and optimal decision
   The interaction between chronic focus, situational focus,        criteria. The two categories represented here are described
and the reward structure of the task has been studied               by one relevant dimension (position of a dot on a computer
extensively in the literature (Higgins & Spiegel, 2004).            screen). Category A is associated with a higher payoff, or
Subsets of these motivational factors have been found to            lower punishment, than category B. Consequently,
affect performance in a number of tasks including problem           maximizing reward requires selecting a decision criterion to
solving anagrams (Shah et al, 1998), decision making                the right of the criterion that maximizes accuracy.
recognition memory (Crowe & Higgins, 1997), and
consumer behavior (Markman, Kim, & Brendl, 2005). The                 These payoff matrices were all designed to have a signal
next section explains the motivational framework and the            detection decision criterion, β, of 3. Thus, the optimal
study of classification learning developed by Maddox, et al.        classifier would use the same decision criterion across
(2005) on which the computational model was based.                  matrices. For this task the stimuli were dots presented on a
                                                                    computer screen, and the two categories were defined by
Results on Classification Learning                                  location along an arbitrary dimension of 650 pixels. The
This section describes the research on motivation and               high-payoff category had a mean of 275 and a standard
learning done by Markman, Baldwin & Maddox (2005) to                deviation of 100, and the low-payoff category had a mean of
explore the effects of regulatory fit on people’s ability to        375 and a standard deviation of 100. Thus the optimal
acquire new categories.                                             accuracy criterion was at 325 pixels and the optimal reward
   The task used in this study was a simple one-dimensional         criterion was at 434.5 pixels.
classification task. Each stimulus is a dot that appears in a         Subjects performed three category-learning tasks, one
particular location on a computer screen. The categories had        with each of the matrices in Table 1. The regulatory focus
overlapping distributions, as shown in Figure 1. The bold           was manipulated using a situational manipulation derived
solid line indicates the decision rule that yields optimal          from previous experiments by Higgins and his colleagues
accuracy. To bias the reward structure of the task, one of the      (Higgins, 1997). In the promotion-focus condition,
categories (category A) had a higher payoff than the other,         participants were told that in each block, they would receive
but the payoffs for incorrect responses were the same for           an entry into a drawing to win $50 if their performance
both categories. Thus the decision rule that optimizes              exceeded some criterion. In the prevention-focus condition,
reward is shifted away from the center of the high payoff           an entry ticket for a $50 raffle was displayed on the
category (see Figure 1). Furthermore, the categories were           computer screen at the start of each block, and participants
made difficult to learn (signal detection discriminability of       were told that they could keep the ticket unless their
                                                               1440

performance fell below a criterion, in which case they                                 A single perceptron performs binary classification,
would lose that ticket. Thus the promotion-focus condition                         mapping its input x (a vector of type Real) to an output
framed the goal as an approach state, and the prevention-                          value ŷ (a scalar of type Real) calculated as:
focus condition framed the goal as an avoidance state. The
regulatory-fit view predicts that people’s performance will                                                              ,          (1)
be closest to optimal when their regulatory focus matches                          where w is a vector of real-valued weights for each input,
the structure of the payoff matrix.                                                 <.,.> denotes dot product and b is the ‘bias’ – a constant
                                                                                    term.
  Table 1: Payoff Matrices and Performance Criteria for the                            For binary classification, the sign of ŷ determines the
                         Three Payoff Conditions.                                   class. The bias can be thought of as offsetting the activation
               High-payoff Category        Low-payoff Category  Performance
                                                                                    function, or giving the output neuron a ‘base’ level of
   Matrix      Correct      Incorrect      Correct    Incorrect criterion           activity. Spatially, the bias alters the position (though not
              response      response      response    response  (threshold)         the orientation) of the decision boundary.
   Mixed            200           -100            0        -100          3,700         Learning in the perceptron is done by updating the
    Gain            400            100          200         100         33,700      weights with,
    Loss           -111           -411        -311         -411        -43,000
 Note: Subjects started each task with 0 points                                                                            ,        (2)
                                                                                    where wi denotes weight of the ith input xi, μ is the learning
                                                                                   rate and ti is the desired output. Thus, learning involves
                                                                                   adapting the weight vector after each iteration. The weights
                                                                                   change only if the output ŷi is different from the desired
                                                                                   output ti.
                                                                                    Figure 3: A single perceptron. The variables xi are the inputs
                                                                                    to this neuron, b is the bias and ŷ is the output of this
                                                                                    neuron.
Figure 2: Mean decision criteria of promotion- and
prevention-focus subjects as a function of the payoff matrix.
                                                                                       The single perceptron unit can be trained accordingly for
The data were analyzed by fitting a decision-criterion model
                                                                                    any set of two linearly separable classes (Rosenblatt, 1958).
to the data from each subject in each block using 100 trials
                                                                                    Given the classification task defined above, this perceptron
out of 150 (first and last 25 trials were discarded as noise).
                                                                                    predicts the decision bound to be at the optimal accuracy
                                                                                    criterion. However, to account for the regulatory fit the
   The data were consistent with the regulatory fit
                                                                                    simple perceptron was modified by adding an extra term to
hypothesis. Subject’s performance was closest to optimal
                                                                                    the equation that updates the weight of each input, as shown
when their regulatory focus fit the payoff structure of the
                                                                                    below
learning task. Subject with promotion focus had a decision
criterion closer to optimal than did people with prevention
focus when the payoff structure consisted of all gains.                                                                                        (3)
People with a prevention focus had a decision criterion
closer to optimal than did people with a promotion focus                            where, wacc is the weight on accuracy, wrew is the weight on
when the payoff structure consisted of all losses.                                 reward, μ is the learning rate for accuracy, α is the learning
Performance in the two regulatory-focus conditions was                             rate for reward, po and pe depict the parameters for
roughly equivalent when the payoff structure had both gains                        situational focus (promotion and prevention), g, l, and m
and losses.                                                                        depict payoff matrices (gains, losses, and mixed
   Based on this study the computational model was                                 respectively) and ri represents the reward that was attained
developed, as explained in the next section.                                        for previous decision. The value of po, pe g, and l is 1 or -1
                                                                                   depending upon the subject’s focus and pay-off matrix.
                       Computational Model                                         However, the value of m is either zero or one, depicting
                                                                                   whether the subject is in or not in the mixed condition.
   The building block of the computational model was
                                                                                       As represented in Eq. 3, the learning rule now consists of
perceptron (Rosenblatt, 1958) as shown in Figure 3. The
                                                                                   two parts: accuracy and reward. The accuracy part is the
perceptron is the simplest kind of feed-forward artificial
                                                                                   same as in Eq. 2 of perceptron learning, except for the new
neural network: a linear classifier.
                                                                               1441

weight wacc which accounts for accuracy criterion. However,
the reward part needs to be discussed in more detail. Let us                                                   ,
understand it with an example. Consider a subject given a
situational promotion focus who is doing the task with a
gain matrix. The parameter values for this person would be
                                                                                                                ,    (8)
po = 1, g = 1, l = -1, pe = -1, m = 0 and the Eq. 3 would
reduce to                                                             where, rt is the reward threshold (a constant defined in the
                                                                     beginning of the task). rp is the reward value at any present
                                                                      moment, ra is the assumed average reward, and q is the
                                                           (4)       number of trials left. Thus, if the reward threshold is
The change in weight in this case increases at a higher rate         achievable (i.e., the ratio of difference between the reward
in the direction of the optimal reward criterion compared to         threshold and the present reward and the number of trials
the optimal accuracy criterion. A similar pattern arises for a       left is lower than the assumed average reward) then θ = 1,
person with a prevention focus doing the task with a loss            and thus wacc increases and wrew decreases, thereby moving
matrix. In contrast, for a subject in a mismatch, i.e. a subject      towards the optimal accuracy criterion. However, if the
in a prevention focus and doing a task with gain matrix or in         reward threshold does not seem to be achievable (i.e., the
a promotion focus and doing a task with loss matrix, Eq 3             above ratio is higher than the assumed average reward) then
reduces to                                                            θ = -1, and thus wacc decreases and wrew increases, thereby
                                                                     moving towards the optimal reward criterion. Thus, the
                                                                     parameters θ and ra drive the model dynamically by
                                                           (5)        predicting rewards and making the model chose respective
                                                                      action (classification in this case). This dynamical nature of
Because of the negative sign between accuracy and reward              the model is very similar to the reinforcement learning
portion, in Eq 5, the change in weight is more in the                 behavior proposed by Sutton and Barto, 1998.
direction of the optimal accuracy criterion than the optimal            Thus, the modified model has the potential to replicate
reward criterion in a mismatch situation.                             and account for subject wise patterns of results shown by
   Further, in case of mixed pay-off matrix the factor                Markman et al. (2005).
(pog+lpe) would sum up to zero, independent of the
situational focus, since both g and l would be 1. So in mixed                                  Evaluation
condition the model would be tuned somewhere between
optimal accuracy and optimal reward criterion, similar to                The input to the model was similar to that used in the
what has been shown with the human subjects (Figure 2).              study by Markman, et al. (2005). The modified perceptron
   To model the data on a trial by trial basis, the weights,         had only one input: the location of pixel, with same means
wacc and wrew, must adapt after each trial during the duration       and optimal reward and accuracy criterion as in the original
of task. This dynamic adaptation takes place according to            study. The initial weight of this input was set randomly and
                                                                     the initial bias was random. However, these weights adapted
                                                          (6)        during the trial as defined by Eqs. 3 – 8.
                                                                         A total of 34 subjects out of 36 were modeled individually
                                                  (7)                (17 in prevention and 17 in promotion focus), by setting up
                                                                     perceptrons with different initial weights. The model was
where, θ represents prediction of rewards (explained in the          not able to fit 2 subjects in prevention focus. The ordering
next paragraph). Now, in case of a regulatory fit, i.e.,             of input was yoked to that given to the subject by Markman
subject with a promotion focus who is doing a task with              et al. (2005). The parameters po, pe g,l, m and ri were
gain matrix or subject with a prevention focus and doing a            initialized consistently with the condition of the study in
task with loss matrix, the change in wacc would be in the             which the subject was run. Values for the other model
negative direction and change in wrew would be in the                 parameters, like wacc (initial value only), wrew (initial value
positive direction (Eq 6 and 7) and vice versa for the               only), ra, μ, and α, were calculated by maximizing the
regulatory mismatch condition. Thus a subject in a fit                likelihood of the model to each subject’s final reward value
condition would go towards the optimal reward criterion               using a grid search of the parameter space. As shown in
while one with a mismatch condition would go towards                  Table 2, the model subjects matched each human subjects
accuracy.                                                             final reward value accurately.
   The parameter θ is particularly interesting. In the original          Analyses of these results lead to two interesting
empirical study each subject was shown a reward meter that            observations. First, the model shifted strategies over the
displayed the current number of points achieved and the               course of the study in a systematic way. When there was a
distance to the reward threshold. To mimic this aspect of             regulatory fit (promotion/Gain or prevention/Loss) and
the study, the θ variable was introduced in the                       equation 8 indicated that the reward threshold was likely to
computational model to represent a prediction that the                be reached, the model often shifted from a focus on the
reward would be obtained. It is defined as                            reward criterion to a focus on the accuracy criterion.
                                                                 1442

Similarly in a mismatch condition (promotion/Loss and              payoff matrix revealed a significant interaction
prevention/Gain), if equation 8 suggested that the reward          (F(1,34)=70.3, p<0.05). It is clear from the figure that the
threshold was unlikely to be reached, the model often              mean ra values for the loss payoff matrix are lower than the
shifted from an optimal accuracy criterion to an optimal           average rewards, thereby indicating that when people do
reward criterion. Motivated by this observation, the original      tasks with loss payoff matrix they tend to become cautious.
human subject data by Markman et al. (2005) was                    In contrast, in the gain payoff matrix the mean ra values are
reanalyzed and these shifts were indeed found in the data          higher than the average rewards, and subjects are less
(Table 3). This novel prediction would help in designing           cautious. This behavior could also provide a reason for the
new studies, which in turn could give an insight on the            variation (depending upon the condition) in shifting of
dynamics of motivational influences on learning.                   strategies during the task. Subjects who follow a cautious
                                                                   approach (or loss payoff matrix) should shift more in the
Table 2. Standardized error in predicting final reward             end compared to subjects with a less cautious approach (or
values for each human subject.                                     gain payoff matrix). Therefore, just based on the ra
         Regulatory Focus/Pay-                                    parameter of the model, it is possible to predict that if a
                                       Standardized Error         person is in a prevention or promotion regulatory focus, the
               Off Matrix
                                                                  chances of shifting are greater in the case of a loss payoff
             Prevention/Gain                 0.145
                                                                  matrix compared to a gain payoff matrix. This prediction
             Prevention/Loss                 0.177
            Prevention/Mixed                 0.112
                                                                  coincides with the human data (Table 3).
             Promotion/Gain                  0.225
             Promotion/Loss                  0.277
            Promotion/Mixed                  0.167
Table 3. Percentage accuracy of the model in predicting
shifts by human subjects, as well as the number of subjects
that shifted in each condition.
            Regulatory        Percentage        Number of
           Focus/Pay-Off       Accuracy          Subjects
               Matrix        (in predicting    Who Shifted
                                 shifts)
          Prevention/Gain        70.58               9
          Prevention/Loss        70.58              11
         Prevention/Mixed        64.70              11
          Promotion/Gain         64.70               6
          Promotion/Loss         64.70               8
         Promotion/Mixed         64.70               7             Figure 3. Mean weight on accuracy (wacc) for different
                                                                  conditions at the end of trial. The interaction in the model
Second, the parameter values of the model at various times        reflects the interaction found by Markman et al. (2005), i.e.
during the run provide interesting insights in to the             people in regulatory fit tend to move their decision criterion
motivation-learning interface. For example, consider the          towards the optimal reward criterion.
parameter wacc. The initial value for wacc was approximately
the same in all four conditions. However, at the end of the
trial, it was significantly higher in the mismatch conditions
as compared to the match conditions. A two-way ANOVA
on the weight parameter values by condition revealed a
significant interaction (F(1,34)=7.722, p<0.05). As shown
in Figure 3, the interaction in the model reflects the
interaction found by Markman et al. (2005), i.e. people in
regulatory fit tend to move their decision criterion towards
the optimal reward criterion.
   Additionally, the value of ra, which is used to predict the
future reward and achievability of the task, describes an
important characteristic of human behavior: reward/risk
analysis. If the value of ra for a given subject was higher
than the average value of rewards (based on payoff matrix),        Figure 4. Mean reward assumption (ra) for different
then that subject can be said to be careless. Conversely, if       conditions. The dashed lines indicate average reward values
the ra value was lower than the average then the subject was       (positive for gains and negative for losses).
cautious. Figure 4 shows the mean ra values for the six
different combinations. A two-way ANOVA on ra values by
                                                              1443

Finally, the learning rate for reward, α, was not significantly                             References
different in the four conditions. However the learning rate         Avnet, T., & Higgins, E. T. (2003). Locomotion,
for accuracy, μ, was significantly higher (two-way ANOVA              assessment, and regulatory fit: Value transfer from "how"
by condition, F(1,34)=6.22, p<0.05) for people in a                   to "what." Journal of Experimental Social Psychology.
regulatory fit than in a mismatch. When the subjects came          Carver, C. S., & Scheier, M. F. (1998). On the self-
to do the classification task they only knew that can perform         regulation of behavior. New York: Cambridge University
well if they accurately classify the instances. The                   Press.
manipulation of regulatory fit was completely unknown to            Crowe, E., & Higgins, E. T. (1997). Regulatory focus and
them. The high learning rate for accuracy shows that the              strategic inclinations: Promotion and     prevention     in
people in regulatory fit are more flexible than the ones in           decision-making. Organizational Behavior and Human
                                                                      Decision Processes.
regulatory mismatch, and that they are more prone to               Higgins, E. T. (1987). Self-discrepancy: A theory relating
shifting back to accuracy in the end. Figure 5 shows the              self and affect. Psychological Review.
mean learning rates for accuracy in different conditions.          Higgins, E. T., Roney, C. J., Crowe, E., & Hymes, C.
                                                                      (1994). Ideal versus ought predilections for approach and
                                                                      avoidance distinct self-regulatory systems. Journal of
                                                                      Personality & Social Psychology.
                                                                   Higgins, E. T. (1997). Beyond pleasure and pain. American
                                                                      Psychologist.
                                                                   Higgins, E. T. (2000). Making a good decision: Value from
                                                                      fit. American Psychologist.
                                                                   Higgins, E. T., Idson, L.C., Freitas, A. L., Spiegel, S., &
                                                                      Molden, D. C. (2003). Transfer of value from fit. Journal
                                                                      of Personality and Social Psychology.
                                                                   Higgins, E. T., & Spiegel, S. (2004). Promotion and
                                                                      prevention strategies for self-regulation: A motivated
                                                                      cognition perspective. In R. F. Baumeister & K. D. Vohs
                                                                      (Eds.), Handbook of self regulation: Research, theory and
                                                                      applications. New York: Guilford Press.
                                                                   Lewin, K. (1935). A dynamic theory of personality. New
                                                                      York: McGraw-Hill.
Figure 5. Mean learning rate of accuracy criterion (μ) for         Maddox, W. T., Baldwin, G. C., & Markman, A. B. (2005).
different conditions. High learning rate for accuracy shows           Regulatory focus effects on cognitive flexibility in rule-
that the people in regulatory fit are more flexible than the          based classification learning. Memory and Cognition.
ones in regulatory mismatch.                                       Maddox, W.T., Markman, A.B., & Baldwin, G.C. (2006).
                                                                      Using classification to understand the motivation-learning
                         Conclusion                                   interface. Psychology of Learning and Motivation.
                                                                   Markman, A. B., & Brendl, C. M. (2000). The influence of
The computational model presented in this paper elaborates            goals on value and choice. In D. L. Medin (Ed.), The
the motivation-learning interface observed by Markman et              Psychology of Learning and Motivation. San Diego, CA:
al. (2005). To our knowledge, this model is the first to              Academic Press.
incorporate the effects of regulatory focus on learning. The       Markman, A. B., Kim, K., & Brendl, C. M. (2005). The
model accurately fits the individual subject data, and                influence of goal activation on preference. Manuscript in
provides a detailed insight into the motivation-learning              preparation.
                                                                   Markman, A. B., Baldwin, G. C., & Maddox, W. T. (2005).
interface. The model led to the discovery of an unstudied             The interaction of payoff structure and regulatory focus in
phenomenon of shifting strategies across trials. These                classification. Psychological Science.
predictions were supported by a re-analysis of the original        Markman, A. B., Maddox, W. T., & Baldwin, G. C. (2005).
human subject data, thus elaborating and strengthening the            The implications of advances in research on motivation
theory proposed by Maddox et al. (2005). Furthermore, the             for cognitive models. Journal of Experimental and
evaluation of various parameters of the model not only                Theoretical Artificial Intelligence.
elaborates the underlying phenomenon but also suggests a           Rosenblatt, F.(1958). The perceptron: a probabilistic model
number of important avenues for future research that we               for information storage and organization in the brain.
plan to pursue. These results constitute a first computational        Psychological Review.
                                                                   Shah, J., Higgins, E. T., & Friedman, R. S. (1998).
step towards the understanding how motivational influences            Performance incentives and means: How regulatory focus
on learning and cognition.                                            influences goal attainment. Journal of Personality and
                                                                      Social Psychology.
                    Acknowledgments                                Sutton, Richard S.; Andrew G. Barto (1998). Reinforcement
This research was supported by AFOSR grant FA9550-06-                 Learning: An Introduction. MIT Press. ISBN 0-262-
                                                                      19398-1.
1-0204 to WTM and ABM, an IC2 Institute fellowship to
ABM, and NSF grant EIA-0303609 to RM.
                                                               1444

