UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Top-Down Modulation of Neural Responses in Visual Perception: A Computational
Exploration
Permalink
https://escholarship.org/uc/item/8918v3p8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Mozer, Micheal C.
Fan, Adrian
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                  Top-Down Modulation of Neural Responses in Visual Perception:
                                                A Computational Exploration
                                                   Michael C. Mozer and Adrian Fan
                                              {michael.mozer,adrian.fan}@colorado.edu
                                    Department of Computer Science and Institute of Cognitive Science
                                              University of Colorado, Boulder, CO 80309-0430
                               Abstract                                       These two contrasting perspectives are depicted in Fig-
                                                                           ure 1. We use the terms bottom up and top down to refer
    Visual perception is typically performed in the context of a task
    or goal. Nonetheless, visual processing has traditionally been         to the perspectives in which dynamics of visual processing
    conceptualized in terms of a fixed, task-independent hierarchy         is task independent or task dependent, respectively. Bottom
    of feature detectors. We explore the computational implica-            up simply implies that processing is guided from the outside
    tions of allowing early visual processing to be task modulated.
    Using artificial neural networks, we show that significant im-         world, and top down implies that processing is guided from
    provements in task accuracy can be obtained by allowing the            higher cortical regions. When we refer to ’bottom up’ and
    weights to be modulated by task. The primary benefits are ob-          ’top down’, refer only to processing dynamics, and not to
    tained under resource-limited processing. A relatively modest
    task-based modulation of weights and activities can lead to a          learning, which surely must have a top-down component; and
    large performance boost, suggesting an efficient means of in-          we do not deny that goal-independent processing might well
    creasing effective cortical capacity.                                  exploit some type of top-down feedback.
    Keywords: neural networks, top-down processing, visual per-               The vast majority of cognitive neuroscience models in vi-
    ception, control                                                       sion adopt an essentially bottom-up perspective. Although
                                                                           an exciting recent development has been to consider the role
                           Introduction                                    of top-down processing (e.g., Bar et al., 2006), “top down”
Individuals typically perceive the world around them with a                refers primarily to knowledge, expectations, and temporal
task or goal in mind. Despite the active nature of percep-                 and spatial context.
tion, the traditional theoretical perspective, exemplified by                 In this work, we focus specifically on top-down influence
the early work of Marr (1982), casts the visual system as                  of current goals and the task being performed, and we use
a static, passive sensory structure that constructs a veridical            “top down” as a synonym for task or goal dependent. We
representation of all facets of the environment, regardless of             investigate the continuum of possible models by varying the
immediate goals. The neural architecture that embodies this                strength of top-down modulation of visual processing based
perspective is a rigid hierarchy of feature detectors, which               on current goals and tasks. Surely, specializing an architec-
constructs a representation of the visual scene that can be                ture for a task at hand should facilitate processing—i.e., it
used by subsequent decision making and action systems.                     should yield more accurate results given a fixed amount of
    An alternative perspective is beginning to emerge that char-           neural hardware, or it should require less neural hardware to
acterizes visual information processing as dynamic, flexible,              achieve a given level of accuracy. Our exploratory study goes
and specialized to current goals. According to this perspec-               further and investigates the following issues: the magnitude
tive, these goals modulate the nature of the visual analysis               of the benefit of top-down modulation, the conditions under
that is performed, the flow of information within the visual               which a benefit is obtained, and the types of top-down modu-
system, and the resulting representations that are constructed.            lations that yield benefits. Our research aims to test the viabil-
                                                                           ity of the hypothesis that top-down cortical feedback serves to
    task
                                                                           tune the perceptual system to the task at hand.
                                                                           Evidence for top-down modulation
 visual          visual         scene          decision       response
  input       processing      description      making                      In this section, we review evidence from neuroscience, neu-
                                                                           roimaging, and psychology concerning the top-down modu-
                                                                           lation of visual processing.
                task
                                                                              Tasks and goals can influence processing in multiple ways.
                            visual processing                              On a slow time scale, practice on a task leads to learning of
             visual
              input                and             response                new representations. For example, Lee et al. (2002) recorded
                             decision making
                                                                           neural activity while a monkey performed visual search with
                                                                           shape-from-shading stimuli. V1 and V2 neurons show pop-
Figure 1: Two visual processing architectures: (a) bottom-up               out response to targets that increased with experience and
architecture in which visual processing is task independent;               skill. On a somewhat shorter time scale, Zemel et al. (2002)
(b) top-down architecture in which visual processing is task               demonstrated that human participants showed an immediate
dependent.                                                                 reorganization of perceptual grouping after being exposed to
                                                                       491

a set of novel shapes. These studies can be explained by                  (a)                                                         present/absent
                                                                                                                                           response
long-term perceptual learning, rather than a dynamic change
in neural response properties when the task changes.                                                                                                 hidden
   A dynamic case, occurring on a time scale of seconds, is
                                                                                                                                                        input
the influence of selective attention in the ventral pathway.
Attention to a stimulus attribute—location, orientation, di-              (b)                                                       (c)
rection of motion, etc.—raises the gain of neural responses                                                 task selection                                    task selection
(Kastner & Ungerleider, 2000). In V4, 25% of neurons show
                                                                                object 1   object 2     object 3         object n         task 1     task 2        task 3           task n
a statistically reliable difference in response depending on a
target orientation (Maunsell et al., 1991).
   Attentional modulation primarily yields greater sensitivity                                                     ...                                                      ...
without much change in selectivity (Maunsell, 2004). Some                                                                                                                   ...
                                                                                                 hidden                             hidden 1       hidden 2      hidden 3         hidden n
support has been documented for changes in selectivity. Us-
ing binocular rivalry displays, Logothetis and Schall (1989)                                          input                                                     input
found neurons in the superior temporal sulcus that reflected
the monkey’s perception, not the retinal stimulation. Crist,              Figure 2: (a) a generic single-task neural network architec-
Li, and Gilbert (2001) found an influence of contextual stim-             ture; (b) a bottom-up multitask architecture; (c) a top-down
uli placed outside the classical receptive field of V1 cells that         multitask architecture
was consistent with a trained discrimination, but only when
the monkey was performing the task.
   Evidence for task-based modulation is also found in hu-                or absence of a target in a single-item display. Each different
mans. PET studies show that the same retinal input can ac-                target corresponds to a task. For example, with single-digit
tivate different extrastriate areas, or even the dorsal versus            displays, one could define ten tasks, corresponding to: “Is a 0
the ventral stream, depending on whether the task being per-              present in the display?”, “Is a 1 present in the display?”, etc.
formed is detection or discrimination (Fias et al., 2002; Or-
                                                                             Figure 2a depicts a generic neural net to perform a spe-
ban et al., 1996). In a behavioral study, Schyns and Oliva
                                                                          cific task, i.e., answer a specific visual search question. The
(1991) found that the perceptual features extracted from im-
                                                                          input represents the visual field, and the output a binary
ages of faces depend on their diagnosticity for the task at
                                                                          present/absent decision. The hidden layer allows for a flexi-
hand: With hybrid stimuli combining images at two differ-
                                                                          ble task-appropriate re-representation of the input. This sim-
ent spatial scales, a primary discrimination task (gender, ex-
                                                                          ple model is not meant to have any isomorphism to the visual
pression, or identity) determines which scale is used to make
                                                                          system, but is only meant as a functional architecture that per-
secondary judgments.
                                                                          forms the same I/O mapping as the visual system (more on
   The high-density feedback projections found in each layer
                                                                          this topic in the Discussion section).
of the visual hierarchy are naturally interpreted as providing
a top-down signal. Beyond the projections to carry the sig-                  Figure 2b embeds the network of Figure 2a into a pure
nal, top-down modulation requires the ability to influence cell           bottom-up architecture. In this architecture, the input is clas-
response properties. Steriade (2004) has argued that slight               sified into one of n object categories, and following classifi-
changes to membrane potential can have dramatic effects: fir-             cation, task selection chooses the appropriate output unit to
ing patterns can transform a neuron from one response type                answer the present/absent question associated with the task.
(regular spiking, fast spiking, fast rhythmic bursting, intrinsi-         In contrast, the top-down architecture in Figure 2c switches
cally bursting) to another.                                               the processing that is performed on an input conditional on
                                                                          the task. In this Figure, the n hidden layers are a shorthand
Modeling top-down modulation of visual processing                         for the n task-specific analyses that could be performed on the
Having summarized the neuroscientific evidence indicating                 input. Essentially Figures 2b and 2c differ in that the bottom-
that tasks and goals influence visual information processing,             up architecture utilizes a hidden representation—specifically
we now discuss what we mean by “influence” in terms of                    the weights from the input to the hidden layer—that is task in-
computational models. We adopt the artificial neural net-                 dependent, whereas the top-down architecture utilizes a dif-
work (ANN) paradigm, because ANNs are arguably closer                     ferent hidden representation for each task, allowing for an
to the underlying neurobiology than are other machine learn-              extreme sort of task dependence.
ing models. We acknowledge that ANNs are still quite an                      The bottom-up and top-down architectures are endpoints of
abstraction from true neural architectures and dynamics, but              a continuum that represents the strength of top-down modu-
past research has been successful in using the ANN paradigm               lation. We explore the continuum by manipulating the degree
to draw inferences and make predictions concerning the oper-              to which hidden unit weights and activities can be modulated
ation of biological systems (e.g., Zipser & Anderson, 1988).              by task. No modulation leads to task-independent weights
   To provide a concrete framework for addressing task-based              and a bottom-up architecture; arbitrary modulation leads to
vision, we focus on visual search: determining the presence               task-dependent weights and a strong top-down architecture.
                                                                    492

    We use α to denote the parameter that controls the strength       3. What strength of top-down modulation is necessary to ob-
 of task modulation, where α = 0 and α = 1 correspond to                  tain a benefit over the pure bottom-up architecture? That
 the bottom-up and top-down architectures, respectively, and              is, for what value of α do we find a benefit? Because
 α plays the following role. In the bottom-up case, we have a             the neurobiological evidence suggests a limited modulation
 single set of input-to-hidden weights, denoted w̄. In the top-           due to top-down influences, one would have to question
 down case, we have a distinct set of weights for each task t,            whether top-down modulation played the role suggested
 denoted ŵt . Interpolating between these two cases obtains              by our framework if a benefit is obtained only for α values
 actual weights used for task t, wt , defined as:                         close to 1. In contrast, if an intermediate strength of top-
                                                                          down modulation (i.e., 0 < α < 1) outperforms the α = 0
                      wt = (1 − α)w̄ + αŵt ,                 (1)
                                                                          and α = 1 cases, it would provide a computational ratio-
 where w̄ = ∑u ŵu /n and n is the number of distinct tasks.              nale for the sort of weak top-down modulation observed in
    Just as the connectivity of the model is not intended to have         the brain.
 any neurobiological reality, neither is α. We are simply de-
 signing a model that has the necessary functional characteris-       4. How does the strength of top-down modulation (α) inter-
 tics: α allows us to manipulate the degree of top-down modu-             act with: (a) the amount of processing resources (hidden
 lation. Using an ANN model for this exploration allows us to             units) available, (b) the noise level in the input, and (c) the
 manipulate properties of the model—namely, activation and                amount of training data. All three of these variables in-
 weights—that at least have a rough correspondence to actual              fluence the difficulty of performing each task, and in these
 neural hardware.                                                         performance-limited cases, the benefit of top-down mod-
                                                                          ulation may be more apparent. Such a finding would be
 Research questions                                                       consistent with the neuroscientific finding that attentional
 Having proposed a simplistic but concrete architecture to ex-            modulations are larger when displays are cluttered or noisy
 amine the role of top-down modulation of information pro-                (e.g., Maunsell, 2004).
 cessing, we turn to questions we hope to answer with this line
 of research. In general, the questions concern the benefit of                                 Methodology
 top-down modulation. Although the neuroscientific and psy-            We studied four data sets, summarized in Table 1. Sets A,
 chological data mentioned earlier provide clear evidence of           C, and D are from the UCI Machine Learning Repository
 top-down modulation, cognitive neuroscience has little com-           (pendigits, letter-recognition, and isolet, respec-
 putational understanding of the magnitude of the benefit, the         tively), and Set B is derived from the MNIST database and
 conditions under which a benefit is obtained, and what types          available at yann.lecun.com/exdb/mnist/index.html.
 of top-down modulations yield benefits. Consider the follow-          Sets A-C are visual images, utilizing three different feature
 ing issues.                                                           representations: stroke based, pixel based, and statistical mo-
                                                                       ments and edge counts. Set D uses the 26 spoken letters of
1. Suppose the bottom-up architecture (Figure 2b) is given
                                                                       the alphabet. Because our modeling is at an abstract level, it
    the same number of free parameters (weights) as each of
                                                                       did not seem unreasonable to include a non-visual data set.
    the task-specific subnets of the top-down architecture (Fig-
                                                                       Our primary goal in picking data sets was to find a diverse
    ure 2c). This situation corresponds to the case in which
                                                                       collection using different representations.
    top-down modulation has the ability to arbitrarily rewire
                                                                          For any α, the training procedure involved a search in the
    the network connectivity. Because the top-down architec-
                                                                       model’s underlying parameter space, {ŵt }. These parame-
    ture benefits from an n-fold expansion in representational
                                                                       ters are translated into weights used in the activation dynam-
    and computing power, one would be surprised if it did not
                                                                       ics, {wt }, via Equation 1. The logic of this procedure is to
    win out.
                                                                       obtain weights whose strength of task-specific modulation is
2. Suppose the top-down and bottom-up architectures are                related to α. The training procedure and the {ŵt } are not
    matched on total number of free parameters (weights). By           meant to have any neurobiological reality; they simply pro-
    matching, we mean that a top-down architecture with h              vide a means of obtaining sets of weights with given func-
    hidden units is compared to a bottom-up architecture with          tional properties.
    roughly nh hidden units. Two early ANN studies offer con-             Training was performed via on-line steepest descent in the
    flicting predictions in this situation. Caruana (1997) stud-       underlying parameter space, {ŵt }, using a mean-squared-
    ied multitask learning in neural nets and found a benefit for      error objective function. For each training example on each
    sharing of hidden representations among tasks, as would            epoch, gradients were computed with respect to each task’s
    occur with the bottom-up architecture. Rueckl et al. (1989)        underlying parameters, and weights were updated. An adap-
    found that partitioning hidden units to handle specific tasks      tive learning rate was used, which increased by a small con-
    helped performance. The difference between these two               stant if the error dropped from one epoch to the next, and
    studies was the amount of similarity among tasks. Caru-            decreased by a constant of proportionality if the error rose.
    ana studied similar tasks, whereas Rueckl et al. studied           To ensure that the network was trained to a local minimum,
    tasks that appeared to have little overlap with one another.       we used a conservative criterion that terminated training only
                                                                  493

                                                    Table 1: Data sets used in simulations
                 label   description                      source   input dim            # tasks                 # examples                    evaluation                                      # hid
                 A       Pen-Based Handwritten Digits     UCI      256                  10                      10992                         70% train / 30% test                            2
                 B       Pixel-Based Handwritten Digits   MNIST    196                  10                      5000                          5-fold cross validation                         2
                 C       Distorted-Font Letters           UCI      16                   26                      20000                         3-fold cross validation                         15
                 D       ISOLET Spoken Letters            UCI      617                  26                      7797                          80% train / 20% test                            4
                                                                                                     1                                       1                                 1                                    1
when the epochwise mean squared-error dropped by less than
                                                                               Data Set A
1% over 100 epochs. For each value of α, each hidden-layer                                           .9                                      .9                                .9                                   .9
                                                                                              AROC
                                                                                                               α=1
                                                                                                     .8                                      .8                                .8                                   .8
size, and each train/test split, we performed 3-8 replications
                                                                                                     .7                                      .7                                .7                                   .7
of training with different random weight initializations. (The                                       .6
                                                                                                               α=0
                                                                                                                                             .6                                .6                                  .6
                                                                                                          4          8        12       16         0   .2   .4   .6   .8   1         0 .2 .4 .6 .8 1 1.2               0 .2 .4 .6 .8 1 1.2
number of replications was inversely related to the number of                                                  # Hidden Units                                   α                   rel. weight var. over tasks (Vw) rel. activity var. over tasks (Va)
                                                                                                     1                                       1                                 1                                    1
data splits, ensuring a roughly fixed number of total runs.)
                                                                               Data Set B
                                                                                                               α=1
                                                                                                    .95                                     .95                               .95                                 .95
   For each training run, an ROC curve was computed for the
                                                                                             AROC
                                                                                                     .9                                      .9                                .9                                   .9
                                                                                                    .85        α=0                          .85                               .85                                 .85
test/validation set, and the area under the ROC curve (AROC)
                                                                                                     .8                                      .8                                .8                                   .8
was determined. AROC is a measure of a model’s intrinsic                                            .75                                     .75                               .75                               .75
                                                                                                          2     4        6         8   10         0   .2   .4   .6   .8   1       0 .33 .67 1 1.33                  0 .33 .67 1 1.33
ability to perform a two-way discrimination—present versus                                           .9
                                                                                                               # Hidden Units
                                                                                                                                             .9
                                                                                                                                                                α
                                                                                                                                                                               .9
                                                                                                                                                                                  rel. weight var. over tasks (Vw) rel. activity var. over tasks (Va )
                                                                                                                                                                                                                 .9
                                                                               Data Set C
absent in the case of our tasks. The AROC measure ranges                                             .8                                      .8                                .8                                   .8
                                                                                              AROC
from 0.5, indicating chance discrimination, to 1.0, indicating                                       .7
                                                                                                               α=1
                                                                                                                                             .7                                .7                                   .7
perfect discrimination. An AROC score is obtained for each                                           .6                                      .6                                .6                                   .6
task, and we compute the mean AROC score across tasks.                                               .5
                                                                                                          10
                                                                                                               α=0
                                                                                                                    15        20       25
                                                                                                                                             .5
                                                                                                                                                  0   .2   .4   .6   .8   1
                                                                                                                                                                               .5
                                                                                                                                                                                    0 .2 .4 .6 .8 1
                                                                                                                                                                                                                   .5
                                                                                                                                                                                                                      0 .2 .4 .6 .8 1
                                                                                                               # Hidden Units                                   α                   rel. weight var. over tasks (Vw) rel. activity var. over tasks (Va)
                                                                                                     1                                       1                                 1                                    1
                                                                               Data Set D
                Results and Discussion                                                               .9                                      .9                                .9                                   .9
                                                                                              AROC
                                                                                                     .8        α=1                           .8                                .8                                   .8
Figure 3 shows results for data sets A-D, with one row per                                           .7                                      .7                                .7                                   .7
                                                                                                     .6                                      .6                                .6                                   .6
data set. The first column of the Figure plots AROC discrim-                                         .5
                                                                                                               α=0
                                                                                                                                             .5                                .5                                  .5
ination performance as a function of the size of the hidden                                               4              12
                                                                                                               # Hidden Units
                                                                                                                                       20         0   .2   .4   .6
                                                                                                                                                                α
                                                                                                                                                                     .8   1         0    .33 .67       1 1.33         0 .33 .67 1 1.33
                                                                                                                                                                                    rel. weight var. over tasks (Vw) rel. activity var. over tasks (Va )
layer, both for the pure bottom-up net (α = 0, dashed line) and
the strong top-down net (α = 1, solid line). The error bars in-                Figure 3: AROC performance on data sets A-D. The graphs
dicate +/- 1 standard error of the mean. AROC discrimination                   are explained in detail in the text. In the first column of
performance improves as the network size increases, at least                   graphs, the number of hidden units is varied. In columns 2-4,
for the range of network sizes we studied. The x-axis of the                   the number of hidden units is fixed, as described in the text.
graph indicates both the hidden layer size of the bottom-up
net, and the hidden layer size for each task in the top-down
net. Thus, comparing the bottom-up and top-down AROC                              The second column of Figure 3 plots the AROC as a func-
values for a given value on the x-axis allows a factor of n                    tion of training α. Individual runs—each with a different
more free parameters for the top-down net. This assumption                     weight initialization and/or train/test split—are marked with
is sensible if top-down modulation can completely rewire the                   an “x”. The data points are fit with a fourth or fifth or-
available hidden units for each task. At this extreme, it’s not                der polynomial to give a sense of the relationship. As the
surprising that the top-down net outperforms the bottom-up                     strength of top-down modulation of the weights (α) increases,
net.                                                                           so does performance. Interestingly, in three of the four data
   At the other extreme, when no rewiring can take place, the                  sets, an intermediate strength of top-down modulation, e.g.,
natural comparison is between nets matched on total hard-                      α = 0.5 yields reliably better performance than independence
ware: a top-down net with h units per task versus a bottom-                    of the weights across tasks, α = 1 (A: t(14) = 4.15, p < .001;
up net with nh units. The first column of Figure 3 implies—                    B: t(14) = 1.35, p > .10; C: t(14) = 4.62, p < .001; D:
assuming that performance remains at asymptote as the num-                     t(14) = 4.066, p < .002). And importantly, even weak top-
ber of hidden units is increased—little or no advantage for the                down modulation obtains performance improvements. We in-
top-down net in this case. Thus, the benefit of task-specific                  terpret these results as strong support for the computational
modulation of unit responses arises in conditions where hard-                  benefits of task-dependent modulation of unit responses.
ware resources are limited and can be effectively reused by                       We have treated α as if it controls the degree to which hid-
top-down modulation. For this reason, in all subsequent sim-                   den weights and responses are allowed to vary from one task
ulations, we selected a particular hidden layer size for each                  to the next. However, α is primarily a parameter of training,
data set, such that resource constraints arose. The size of the                because for α > 0, any arbitrary set of weights, {wt }, can be
hidden layer for each data set is shown in Table 1.                            obtained via Equation 1 and appropriate selection of {ŵt }.
                                                                         494

                                                                                                              0.86
Thus, it is necessary to assess the strength of task modulation
                                                                                                              0.85
in other ways.                                                                                                0.84
   One measure of task-specific modulation is how much in-                                                    0.83
dividual hidden-unit weights vary from one task to another.                                                   0.82
For some hidden unit i having weights wti for task t, the vari-                                        AROC   0.81
                                                                                                               0.8
ance is Et [|wti − Et 0 [wt 0 i ]|2 ]. We compute the expected vari-                                          0.79
ance over weights, and normalize this quantity with respect                                                   0.78
to the variance within a task, across hidden units:                                                           0.77
                                                                                                              0.76
                                                                                                                     none      bias       gain      bias+gain
                                                                                                                            task−based modulation
      Vw = Ei,t [|wti − Et 0 [wt 0 i ]|2 ]/Et,i [|wti − Ei0 [wt 0 i0 ]|2 ].   (2)
If Vw = 0, we have a pure bottom-up net in which the weights                              Figure 4: AROC performance on task B for different types
do not vary across tasks. If Vw = 1, a particular weight varies                           of constrained top-down modulation. Modulation of biases,
as much from one task to the next as the weights for a par-                               gains, or biases+gains led to only moderate improvements in
ticular task vary from one connection to another. The third                               performance. Error bars show one standard error of the mean.
column of Figure 3 plots the AROC value of each run as a
function of its corresponding Vw value. For data sets A, B,
and C, the best AROC value is obtained for Vw in the neigh-                               butions to the otherwise task-independent net input to a hid-
borhood of 0.5, 0.33, and 0.5, respectively. Thus, to achieve                             den unit. These constrained modulations correspond to a sub-
optimal performance, top-down modulation must vary the                                    class of responses observed in neural activity (e.g., Maunsell,
weights from task to task, but the amount of adjustment is                                2004).
far less than the variation one observes over different units.                               We found modest benefits for top-down modulation of bi-
   A second measure of task-specific modulation is analogous                              ases and gains. The largest effect was in data set A, where
to the first, but uses relative activation variance instead of                            AROC rose from .76 to .83 (t(28) = 1.99, p < .05). Effects of
weight variance. The measure Va , depicted in the fourth col-                             bias and gain modulation on data set B are shown in Figure 4.
umn of Figure 3, is the expected variance in the activity of                              The improvements are small relative to what we observed
a particular hidden unit across tasks, relative to the expected                           by allowing task modulation of individual connections. In
variance in a particular tasks across all hidden units. When                              biological neurons, bias and gain changes are observed in
Va = 0, we have a pure bottom-up net which yields no vari-                                the context of priming phenomena and attentional phenom-
ance in the hidden activations across tasks. When Va = 1, a                               ena, respectively. We speculate that the reason our simula-
particular hidden unit’s activity varies as much across tasks                             tions showed little benefit of these modulations is because our
as activity varies for a particular task across units. Similar to                         tasks did not involve sequential effects—in which case prim-
the Vw graphs, we find that a a relatively small task-dependent                           ing is useful—or multiple-object displays—in which case at-
modulation yields significant improvements in AROC; Va val-                               tentional selection is useful.
ues in the neighborhood of 0.5 yield optimal performance.                                    In a final set of simulations, we explored the interaction
   The α, Vw , and Va graphs all point to the same conclusion:                            between top-down modulation and input noise. During train-
any degree of top-down modulation of responses yields a sig-                              ing and testing, we added Gaussian noise to each input unit
nificantly increased discriminative ability of the ANN. Al-                               i with mean zero, and standard deviation λσi , where λ is a
though this conclusion is hardly startling, what is surprising                            noise level, and σi is the standard deviation of the input ac-
and interesting is (a) the slope of the curves, i.e., how sharply                         tivity in the training set. Figure 5 shows the outcome for
performance improves with even small modulations, and (b)                                 λ ∈ 0, 0.25, 0.5, 1 and data sets A and B. Noise had little im-
the magnitude of improvement that can be obtained by top-                                 pact on α = 0, most likely because the weights were con-
down modulation. The slopes on data set D are somewhat                                    strained by all tasks in parallel, and the fewer degrees of free-
shallower than on the other three data sets. This slope cannot                            dom led to less overfitting of the training data. Nonetheless,
be attributed to the number of tasks, because both C and D                                the benefits of top-down modulation over a pure bottom-up
involve 26 tasks. It might be attributed to the high input di-                            model net are obtained for most levels of noise. Even in data
mensionality of set D, which allows any degree of task modu-                              set A, where noise had a big impact, top-down modulation
lation to affect a large number of weights, consistent with the                           leads to a sort of noise robustness: its AROC value for λ = 0
finding that Set D’s Vw curve is shallower than its Va curve.                             and α = 0 is comparable to that for λ = 0.5 and α = 0.2.
   We performed additional simulations exploring con-
strained top-down influences of hidden unit activity involv-
                                                                                                     Conclusions and Future Work
ing only the gain or bias of a unit. That is, the net input to                            Our simulations show a clear benefit of top-down task-based
hidden unit j is defined as net j = gt (∑i w ji xi ) + bt , where x                       modulation of neural responses. Although the architectures
is the input vector, bt is a task-specific bias, and gt is a task-                        we studied had little of the structure of the human visual sys-
specific gain. We allowed either bt or gt to vary with task                               tem, and the ANN is a highly idealized neural network, we
during training, providing additive or multiplicative contri-                             are confident that the results apply to neurobiological sys-
                                                                                    495

       1
                     Data Set A                 1
                                                             Data Set B                                                      Acknowledgments
                                                                                 −.−.−λ = 0.00            This research was supported by NSF BCS 0339103 and
                                           .95
       .9                                                                        _____ λ = 0.25           NSF CSE-SMA 0509521. We thank Garrison Cottrells, Ben
AROC                                     AROC                                    ....... λ = 0.50         Pearre, Avleen Singh, Thomas Strohmann, and two anony-
                                            .9
       .8                                                                                                 mous reviewers for insightful comments on a draft of this
                                           .85                                   −−−−λ = 1.00
                                                                                                          manuscript.
       .7                                   .8
            0   .2    .4   .6   .8   1              0   .2    .4   .6   .8   1
                                                                                                                                  References
Figure 5: Performance on data sets A and B as a function of                                               Bar, M., Kassam, K. S., Ghuman, A. S., et al. (2006). Top-
α for various noise levels.                                                                                  down facilitation of visual recognition. PNAS, 103, 449–
                                                                                                             454.
                                                                                                          Caruana, R. (1997). Multitask learning. Machine Learning,
tems. If anything, our results are probably conservative be-                                                 28, 41–75.
cause the visual system is a multilayered hierarchy, and each                                             Crist, R. E., Li, W., & Gilbert, C. D. (2001). Learning to see:
layer introduces nonlinearities. As a result, small modula-                                                  experience and attention in primary visual cortex. Nature
                                                                                                             Neuroscience, 4, 519–525.
tions to the response of neurons in an early layer can amplify
                                                                                                          Fias, W., Dupont, P., Reynvoet, B., & Orban, G. A. (2002).
as they propagate forward.                                                                                   The quantitative nature of a visual task differentiates be-
    Top-down modulation increases the effective resources of                                                 tween ventral and dorsal stream. Journal of Cognitive Neu-
a neural architecture, and is therefore most useful to over-                                                 roscience, 14, 646–658.
come resource limitations. However, our simulations showed                                                Kastner, S., & Ungerleider, L. G. (2000). Mechanisms of vi-
that top-down modulation may also be useful in overcoming                                                    sual attention in the human cortex. Annual Rev. Neurosci.,
                                                                                                             23, 315–341.
some amount of input noise. We observed that a moderate
top-down modulation (e.g., α = 0.5) yielded better perfor-                                                Lee, T. S., Yang, C. F., Romero, R., & Mumford (2002). Neu-
                                                                                                             ral activity in early visual cortex reflects behavioral expe-
mance than a pure bottom-up (α = 0) or a strong top-down                                                     rience and higher-order perceptual saliency. Nature Neu-
model (α = 1). In a sense this result should not be terribly                                                 roscience, 5, 589–597.
surprising. The bottom-up model is ideal if the tasks share                                               Logothetis, N. K., & Schall, J. D. (1989). Neuronal correlates
strong similarities, and therefore internal representations of                                               of subjective visual perception. Science, 245, 761–767.
the input should be identical. The strong top-down model is                                               Marr, D. (1982). Vision. San Francisco, CA: W. H. Freeman.
ideal if the tasks are unrelated, allowing for flexible represen-                                         Maunsell, J.H.R. (2004) The role of attention in visual cere-
tations from task to task. Because the best performance in the                                               bral cortex. In L.M. Chalupa and J.S. Werner (Eds.), The
tasks we studied was obtained for an intermediate strength of                                                visual neurosciences (pp. 1538–1545). Cambridge, MA:
top-down modulation, we can infer that the tasks we studied                                                  MIT Press.
have an intermediate degree of similarity.                                                                Maunsell, J.H.R., Sclar, G., Nealey, T.A., DePriest, D.D.
                                                                                                             (1991) Extraretinal representations in area V4 in the
    A surprising and interesting finding of our simulations is                                               macaque monkey. Visual Neuroscience, 7, 561–573.
that even small task-based modulations yield significant per-                                             Orban, G.A., Dupont, P., Vogels, R., De Bruyn, B., Bormans,
formance improvements, as evidenced by the steep slopes of                                                   G., & Mortelmans, L. (1996). Task dependency of visual
our AROC curves for the α, Vw , and Va graphs. Because simi-                                                 processing in the human visual system. Behav. Brain Res.,
lar tasks should utilize similar representations, it makes sense                                             76, 215–223.
that not much modulation is required to achieve a perfor-                                                 Rueckl. J.G., Cave, K.R. & Kosslyn, S.M. (1989). Why are
mance boost. Our simulations provide a computational jus-                                                    “what” and “where” processed by separate cortical visual
tification for observed task-dependent modulation of neural                                                  systems? A computational investigation. Journal of Cog-
                                                                                                             nitive Neuroscience, 1, 171–186.
activity, and suggest that experimental studies should be even
                                                                                                          Schyns, P., G., & Oliva, A. (1999). Dr. Angry and Mr. Smile:
more sensitive to such modulations.                                                                          When categorization flexibly modifies the perception of
    Our simulations are limited by the number of data sets we                                                faces in rapid visual presentations. Cognition, 69, 243–
explored. We also did not have the opportunity to explore an-                                                265.
other possible benefit of top-down modulation: the ability to                                             Steriade, M. (2004). Neocortical cell classes are flexible en-
generalize to novel tasks (Caruana, 1997). For example, sup-                                                 tities. Nature Reviews Neuroscience, 5, 121–134.
pose one was asked to search for a target defined by a combi-                                             Zemel, R. S., Behrmann, M., Mozer, M. C., & Bavelier, D.
nation of color and shape. Previous experience with search-                                                  (2002). Experience-dependent perceptual grouping and
                                                                                                             object-based attention. Journal of Experimental Psychol-
ing for the color and/or the shape may facilitate search for                                                 ogy: Human Perception & Performance, 28, 202–217.
the novel combination via task-based modulation. Regardless
                                                                                                          Zipser, D., & Andersen, R. A. (1988). A back-propagation
of how such an exploration might turn out, we have demon-                                                    programmed network that simulates response properties of
strated how task-based modulation can increase the effective                                                 a subset of posterior parietal neurons. Nature (London),
processing and representational capacity of a hardware lim-                                                  331, 679–684.
ited system like the brain.
                                                                                                    496

