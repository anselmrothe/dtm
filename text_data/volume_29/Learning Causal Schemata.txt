UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Causal Schemata
Permalink
https://escholarship.org/uc/item/19v2r2ws
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Kemp, Charles
Goodman, Noah D.
Tenenbaum, Joshua B.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                                 Learning Causal Schemata
                                 Charles Kemp, Noah D. Goodman & Joshua B. Tenenbaum
                                                    {ckemp, ndg, jbt}@mit.edu
                                               Department of Brain and Cognitive Sciences
                                                   Massachusetts Institute of Technology
                               Abstract                                  causal powers, and the bottom-up approach emphasizes sta-
                                                                         tistical inferences that are based on patterns of covariation.
   Causal inferences about sparsely observed objects are often           As Cheng [2] and others have argued, these perspectives are
   supported by causal schemata, or systems of abstract causal
   knowledge. We present a hierarchical Bayesian framework               best regarded as complementary: top-down knowledge about
   that learns simple causal schemata given only raw data as in-         causal power plays a role in many inferences, and bottom-up
   put. Given a set of objects and observations of causal events in-     statistical learning can help to explain how this knowledge
   volving some of these objects, our framework simultaneously
   discovers the causal type of each object, the causal powers           is acquired. The apparent conflict between these perspec-
   of these types, the characteristic features of these types, and       tives may have developed in part because there is no well-
   the characteristic interactions between these types. Previous         established framework that accommodates them both. Kelley,
   behavioral studies confirm that humans are able to discover
   causal schemata, and we show that our framework accounts              for example, argued for both top-down [6] and bottom-up ap-
   for data collected by Lien and Cheng and Shanks and Darby.            proaches [7] to causal reasoning, but did not develop a single
                                                                         theoretical framework that properly unified his two proposals.
   Keywords: causal induction; intuitive theories; hierarchical          We will argue that a hierarchical Bayesian approach provides
   Bayesian models; categorization
                                                                         this missing theoretical framework, and will develop a model
                                                                         that shows how schemata support causal reasoning and how
                          Introduction                                   schemata can be acquired by statistical learning.
People often make accurate causal inferences based on very                  Part of our task is to formalize the notion of a causal
sparse data. Imagine, for instance, that you are travelling in           schema. Suppose that we are interested in a set of objects—
the tropics, and on your very first morning you take an anti-            for example, a set of pills. This paper works with schemata
malarial pill and wash it down with guava juice. Soon af-                that assign each object to a causal type, and specify the causal
terward you develop a headache and wonder what might have                powers and features of each type. Our pills, for instance, may
caused it. Suppose that you have very little direct information          represent four causal types—pills of type A cause headaches,
about the two potential causes—you have never before tasted              pills of type B relieve headaches, and pills of types C and D
guava juice or taken anti-malarial pills. Even so, you will              neither cause nor relieve headaches. A causal schema may
probably correctly attribute your headache to the pill rather            also specify how causal types interact. For instance, a C-pill
than the juice.                                                          and a D-pill may cause a headache when taken together, even
   Accurate inferences from sparse data often rely on the top-           though neither pill causes a headache on its own.
down influence of abstract knowledge. Even if you have                      The first section of this paper considers the well-studied
never come across anti-malarial pills or guava juice, you                problem (Fig. 1a) of learning a causal model that captures
probably know about the causal powers of pills in general                the relationship between a single object (e.g. a pill) and an
and juices in general—in particular, you know that pills tend            effect (e.g. a headache). Causal models for several objects
to cause headaches but that juices do not. Abstract causal be-           can be learned independently, but this approach ignores any
liefs of this sort are sometimes called causal schemata [6] or           information that might be shared across objects: for instance,
intuitive theories.                                                      two blood-pressure medications are likely to have similar side
   Two fundamental questions can be asked about causal                   effects, enabling us to predict that a new blood-pressure med-
schemata: how do these schemata support top-down in-                     ication will cause headaches if several others already have.
ferences given relatively sparse data, and how are these                 The second section introduces causal schemata that group
schemata acquired? This paper develops a hierarchical                    the objects into types, and specify the likely causal powers
Bayesian framework that provides a unified approach to both              of the objects belonging to each type (Fig. 1b). We show
questions. Griffiths [4] has previously shown that hierarchi-            how these schemata can be acquired in settings where learn-
cal Bayesian models help to explain how top-down inferences              ers must learn a schema at the same time as they are learning
can be guided by causal schemata. Here we focus on the ac-               causal models for many different objects.
quisition question, and show that hierarchical Bayesian mod-                By tracking the characteristic features of causal types,
els help to explain how causal schemata can be acquired by               learners can often make strong predictions about a novel ob-
bottom-up learning.                                                      ject before it is observed to participate in any causal interac-
   Top-down and bottom-up approaches to causal learning are              tions. For instance, predictions about a pill with a given color,
sometimes seen as competitors. The top-down approach [6,                 size, shape and imprint can be based on the effects produced
14] emphasizes inferences that are based on knowledge about              by previous pills which shared these features. The third sec-
                                                                     389

   (a)               (b)     Schema        (c)        Schema              e will be present even though o is absent, we assume that a
                                                                          generative background cause of strength b is always present
       Causal                Causal             Causal                    We specify the distribution P (e|o) by assuming that genera-
        Model                Models             Models
                                                                          tive and preventive causes combine according to a network of
        Event                 Event              Event    Feature         noisy-OR and noisy-AND-NOT gates.
        Data                  Data                Data      Data             Now that we have parameterized model M in terms of the
Figure 1: (a) A generative framework for discovering the                  triple (a, g, s) and the background strength b, we can rewrite
causal powers of a single object. (b) A generative framework              Equation 1 as
for learning a schema that guides inferences about multiple
objects. The schema organizes the objects into causal types,                  p(a, g, s, b|V ) ∝ P (V |a, g, s, b)P (a)P (g)p(s)p(b).       (2)
and specifies the causal powers of each type. (c) A generative            To complete our framework we must place prior distributions
framework for learning a schema that includes information                 on the four causal variables. We use uniform priors on the two
about the characteristic features of each type. Concrete ex-              binary variables (a and g), and assume that the two continu-
amples of each framework are shown in Figs. 2b, 2c, and 3.                ous variables (s and b) represent the logistic transformations
                                                                          of Gaussian variables drawn from conjugate priors.2 We set
tion extends the notion of a causal schema by including infor-            the hyperparameters of these conjugate priors to encourage b
mation about the characteristic features of each causal type              to be small and s to be large.
(Fig. 1c). Although we begin with cases where at most one
object is present at any time, the final section considers cases                      Learning multiple causal models
where multiple objects may be present. We extend the notion               Suppose now that we are interested in a set of objects {oi }
of a schema one more time by allowing interactions between                and a single effect e. We begin with the case where at most
different types (for instance, pills of type C may interfere with         one object is present at any time: for example, suppose that
pills of type D), and we show how these characteristic inter-             our patient takes many different pills, but at most one per day.
actions can be learned.                                                   Instead of learning a single causal model our goal is to learn
                                                                          a set {Mi } of causal models, one for each pill (Figs. 1b and
             Learning a single causal model                               2c). There is now a triple (ai , gi , si ) describing the causal
Suppose that we are interested in the relationship between a              model for each pill oi , and we collect these variables into
single object o and an effect e, and that we have observed a              three vectors, a, g and s. Let Ψ be the tuple (a, g, s, b) which
collection of event data V . Each observation in V represents             includes all the parameters of the causal models. As for the
a trial where the object o was either present or absent and               single object case, we assume that a generative background
the effect e either was or was not observed. For instance, if             cause of strength b is always present.
object o is a pill and effect e is a headache, each trial might              Instead of learning each causal model separately, we intro-
indicate whether or not a patient took a pill on a given day,             duce the notion of a schema. A schema specifies a grouping
and whether or not she subsequently experienced a headache.               of the objects into causal types, and indicates the causal pow-
To simplify our notation, o will refer both to the pill and to            ers of each of these types. The schema in Fig. 2c indicates
the event of the patient swallowing the pill.                             that there are two causal types: objects of type t1 tend to pre-
   We assume that the outcome of each trial is generated from             vent the effect, and objects of type t2 tend to cause the effect.
a causal model M that captures the causal relationship be-                Formally, let zi indicate the type of oi , and let ā, ḡ, and s̄ be
tween o and e (Figs. 1a and 2b). Having observed the event                schema-level analogues of a, g, and s: ā(t) is the probability
data V , our beliefs about the causal model can be summarized             that any given object of type t will be causally related to the
by the posterior distribution                                             effect, and ḡ(t) and s̄(t) are the expected polarity and causal
                                                                          strength for objects of type t. Even though ā and ḡ are vec-
                   P (M |V ) ∝ P (V |M )P (M ).                   (1)     tors of probabilities, Fig. 2c simplifies by showing each ā(t)
                                                                          and ḡ(t) as a binary variable.
We build on the approach of Griffiths and Tenenbaum [5] and                  To generate a causal model for each object, we assume
parameterize the causal model M using four causal variables               that each arrow variable ai is generated by tossing a coin
(Fig. 2a and 2b). Let a indicate whether there is an arrow                with weight ā(zi ), that each polarity gi is generated by toss-
joining o and e, and let g indicate the polarity of this causal           ing a coin with weight ḡ(zi ), and that each strength si is
relationship (g = 1 if o is a generative cause and g = 0 if o             drawn from the logistic transform of a Gaussian distribu-
is a preventive cause). Suppose that s is the strength of the             tion with mean s̄(zi ) and variance σ̄(zi ). Let Ψ̄ be the tuple
relationship between o and e.1 To capture the possibility that                2
                                                                                For instance, logit(s) is drawn from a Gaussian with mean µ
    1
      To simplify the later development of our model, we assume that      and variance σ 2 . σ 2 is drawn from an inverse gamma distribution
g and s are defined even if a = 0 and there is no causal relationship     with shape parameter a and scale parameter b, and µ is drawn from
between o and e. When a = 0, g and s can be interpreted as the            a Gaussian with mean m and variance vσ 2 . We set v = 10, a = 2
polarity and strength that the causal relationship between o and e        and b = 0.3 for all continuous variables. For strength variables, we
might have had if this relationship actually existed.                     set m = 1, and for the background variable we set m = −1.
                                                                      390

(a)                                                                (c)                                  t1                          t2
                  a=0                       a = 1, g = 1
                                                                                          z:       o1   o2   o3          o4     o5     o6    o7
          o                        o
                  o   e=1                  o           e=1           Schema                             t1                          t2
                 0     b                   0            b
                                                                                  ā, ḡ, s̄ :         −0.75                       +0.9
          e      1     b           e       1    1 − (1 − b)(1 − s)
                                                                                                         e                           e
                                                    ∅     o                                     ∅  o1   o2   o3          o4     o5     o6    o7
(b)                                      a, g, s :      +0.9
                                                                     Causal
                                                                                  a, g, s :       −0.8 −0.7 −0.75       +0.9 +0.94 +0.88 +0.9
           Causal Model (M )                                         Models
                                        b : +0.2     e    e                       b : +0.2      e   e    e    e           e      e      e     e
                                                    ∅     o                                     ∅  o1   o2   o3          o4     o5     o6    o7
           Event Data (V )                   e+ :  20    92          Event             e+ :    20   4    6    5          92     95     90     1
                                             e− :  80     8          Data              e− :    80  96   94   95           8      5     10     0
Figure 2: (a) Causal graphical models which capture two possible relationships between an object o and an effect e. a indicates
whether there is a causal relationship between o and e, g indicates whether this relationship is generative or preventive, and
s indicates the strength of this relationship. A generative background cause of strength b is always present. A third possible
model (a = 1, g = 0) is not shown. (b) Learning a causal model M from event data V (see Fig. 1a). The event data specify the
number of times the effect was (e+ ) and was not (e− ) observed when o was absent and when o was present. The model shown
has a = 1, g = 1, s = 0.9 and b = 0.2, and is an instance of the second model in (a). (c) Learning a schema and a set of causal
models (see Fig. 1b). z specifies a set of causal types, where objects belonging to the same type have similar causal powers,
and ā, ḡ, and s̄ specify the causal powers of each type. Note that the schema supports inferences about an object (o7 ) that is
very sparsely observed.
(ā, ḡ, s̄, σ̄). To complete the model, we specify prior distri-                Learning causal types given feature data
butions on z and Ψ̄. We use a prior P (z) that assigns some                Imagine that you are allergic to nuts, and that one day you
probability mass to all possible partitions but favors partitions          discover a small white sphere in your breakfast cereal—a
that use a small number of types.3                                         macadamia nut, although you do not know it. To discover
   Having defined a generative model, we can use it to learn               the causal powers of this novel object you could collect some
the type assignments z, the schema parameters Ψ̄ and the pa-               causal data—you could eat it and wait to see what happens.
rameters Ψ of the causal models that are most probable given               Probably, however, you will observe the features of the object
the event data V we have observed:                                         (its color, shape and texture) and decide to avoid it since it
                                                                           is similar to other allergy-producing foods you have encoun-
      p(z, Ψ̄, Ψ|V ) ∝ P (V |Ψ)P (Ψ|Ψ̄, z)p(Ψ̄|z)P (z).            (3)     tered.
                                                                              Our formal framework naturally handles the idea that in-
Fig. 2c shows how a schema and a set of causal models (top                 stances of a given causal type tend to have similar features
two rows) can be simultaneously learned from the event data                (Figs. 1c and 3). Suppose that we have a matrix F which
V in the bottom row. All of the variables in the figure have               captures many features of the pills in our study, including
been set to values with high posterior probability according to            their sizes, shapes, colors, and imprints. We assume that ob-
Equation 3: for instance, the partition z shown is the z with              jects belonging to the same type have similar features. For
maximum posterior probability. Note that learning a schema                 instance, the schema in Fig. 3 specifies that objects of type t1
supports confident inferences about object o7 , which is very              tend to have feature f7 but not f8 . Formally, let the schema
sparsely observed (see the underlined entries in Fig. 2c). On              parameters Ψ̄ include a matrix F̄ , where f¯j (t) specifies the
its own, a single trial might not be very informative about the            expected value of feature fj within causal type t.4 Building
causal powers of a novel object, but experience with previous              on previous models of categorization [1], we assume that the
objects allows our model to predict that o7 will produce the               value of fj for object oi is generated by tossing a coin with
effect as regularly as the other members of type t2 .                      bias f¯j (zi ). Our goal is now to use the features F along with
   To compute the predictions of our model we implemented                  the event data V to learn a schema and a set of causal models:
a Markov chain Monte Carlo scheme that samples from the
posterior distribution in Equation 3. Our implementation,                  p(z, Ψ̄, Ψ|V, F ) ∝ P (V |Ψ)P (F |Ψ̄, z)p(Ψ|Ψ̄, z)p(Ψ̄|z)P (z).
however, is not intended as a process model, and our pri-
                                                                              There are many previous models for discovering categories
mary contribution is the computational theory summarized by
                                                                           of objects with similar features [1], and feature-based catego-
Equation 3.
                                                                           rization is sometimes pitted against causal categorization [3].
    3
      We use a Chinese Restaurant Process prior on P (z), and set          Our framework works with the idea that real-world categories
the concentration parameter to 1. The entries in ā and ḡ are inde-       are often distinguished both by their characteristic features
pendently drawn from a Beta(0.1, 0.1) distribution, and the means
                                                                               4
and variances in s̄ and σ̄ are drawn from the conjugate prior already            The prior on F̄ assumes that all entries in this matrix are inde-
described.                                                                 pendent draws from a Beta(0.5, 0.5) distribution.
                                                                       391

    (a)                                      t1                              t2                          t1 t2
                                                                                                  f¯1 : .5 .4
                         z:        o1   o2      o3    o4       o9       o10     o11       o12
                                   o5   o6      o7    o8                o13     o14       o15     f¯2 : .5 .6
     Schema                                                                                       f¯3 : .3 .3
                                             t1                              t2                      .
                                                                                                     .
                                                                                                           .
                                                                                                           .
                                                                                                               .
                                                                                                               .
                 ā, ḡ, s̄ :              +0.7                                                   f¯7 : .9 .1
                                              e                               e                   f¯8. : .1. .9.
                                                                                                     .     .   .
                               ∅   o1   o2      ...   o8       o9 . . . o12     o13 . . . o15            o1 o2 o3 o4 o5 o6 o7 o8 o9 o10
     Causal                                                                                       f1 : 1      1    0   0   1   1  0   0   0   0 ···
                 a, g, s :        +0.7 +0.7          +0.7
                                                                                                  f2 : 0
     Models                                                                                                   0    1   1   0   0  1   1   1   1 ···
                b : +0.2        e   e    e             e        e        e       e         e      f3 : 1      0    0   0   1   0  0   0   0   0 ···
                                                                                                      .    .   .   .    .  .    .  .  .    .  .
                                                                                                      .    .   .   .    .  .    .  .  .    .  .
                               ∅   o1   o2      ...   o8       o9 . . . o12     o13 . . . o15     f7 : 1      1    1   1   1   1  1   1   0   0 ···
     Data             e+ :     2    8    8             8        2        2       0         0      f8 : 0      0    0   0   0   0  0   0   1   1
                      e− :
                                                                                                                                                ···
                               8    2    2             2        8        8       0         0          .
                                                                                                      .
                                                                                                           .
                                                                                                           .
                                                                                                               .
                                                                                                               .
                                                                                                                   .
                                                                                                                   .
                                                                                                                        .
                                                                                                                        .
                                                                                                                           .
                                                                                                                           .
                                                                                                                                .
                                                                                                                                .
                                                                                                                                   .
                                                                                                                                   .
                                                                                                                                      .
                                                                                                                                      .
                                                                                                                                           .
                                                                                                                                           .
                                                                                                                                              .
                                                                                                                                              .
               f1             f2
    (b)    f13 f3 f4 f5 f6
                                            (c)     Horizontal                Vertical         (d)               Preference for f1 -match
               o1 o2 o3 o4         f9               8    8 8  8            8   8    2      2                         condition    o13 o14 o15
                                       f7                                                                           horizontal     6 24 43
               o5 o6 o7 o8        f10               8    8 8  8            8   8    2      2            Human          vertical   73 90 98
           o13 o14         o9 o10 f11                      2  2                     2      2
                                                                                                                    horizontal     6    8    12
                          o11 o12 f12  f8                  2  2                     2      2            Model          vertical   61    68   75
               o15                f14
Figure 3: (a) Learning a schema and a set of causal models given event and feature data (see Fig. 1c). Objects belonging to the
same type have similar causal powers and similar features, and f¯i specifies the expected value of feature fi within each type.
The event and feature data shown are for the horizontal condition of the Lien and Cheng experiment. (b) A summary of the
feature matrix shown in (a). Feature f7 is shared by all and only the first eight objects, and f9 is shared only by the first four
objects. (c) Event data for two conditions. 10 trials were shown for each of the first 12 objects. In the horizontal condition, each
object with feature f7 produces the effect on 8 out of 10 trials. In the vertical condition, only objects with f1 regularly produce
the effect. (d) Predictions for the sorting task of Lien and Cheng [9]. The first two rows show the percentage of subjects who
grouped a novel object (o13 , o14 or o15 ) with the f1 -match (o1 ) rather than the f8 -match (o10 ). Only subjects in the vertical
condition tend to sort according to f1 . The model predictions represent the relative probability that each novel object belongs
to the same causal type as the f1 -match.
and their characteristic causal interactions. More often than                   the horizontal condition, each object with a cool color (f7 )
not, one kind of information will support the categories in-                    causes blooming on 8 out of 10 occasions, and the remaining
dicated by the other, but there will also be cases where the                    objects lead to blooming less often. In the vertical condition,
causal data and the feature data conflict. In cases like this, our              objects with irregular shapes (f1 ) are the only ones that tend
model may discover the feature-based categories, the causal                     to cause blooming. In both conditions, the model is shown
categories, or some combination of both—the categories pre-                     that blooming occurs on 2 out of 10 trials when no chemicals
ferred will depend on the relative weights of the statistical                   are applied.
information present in the two kinds of data.                                      We test our model by requiring it to reason about three
                                                                                objects (o13 , o14 and o15 ) for which no trials were observed
Behavioral data                                                                 (see the underlined entries in Fig. 3a). Object o13 has a novel
Lien and Cheng [9] ran several experiments that explore how                     shape, o15 has a novel color, and o14 is a novel combination of
perceptual features and causal observations can both inform                     a known shape and known color. Each novel object was pre-
causal judgments. Our framework can handle all of their                         sented as part of a trio that also included o1 and o10 , and we
tasks, but we focus here on a simplified version of their first                 computed whether the model preferred to group each novel
task. The effect of interest is whether a certain kind of plant                 object with the shape match (o1 ) or the color match (o10 ).5
blooms, and the potential causes are 15 chemicals (objects o1                   In the horizontal condition, the model prefers to sort each trio
through o15 ). Fig. 3b shows that the features of these objects                 according to color (f8 ), but in the vertical condition the model
(f1 through f14 ) support two systems of categorization. The                    sorts each trio according to shape (f1 ) (see Fig. 3d). Note
first is based on color: each object has a cool color (f7 ) or                  that the feature data and the causal data must be combined to
a warm color (f8 ), and the warm-colored objects are either                     produce this result: a model that relied on the features alone
yellow (f11 ), red (f12 ) or orange (f14 ). Similarly, each object              would predict no difference between the two conditions, and
has an irregular shape (f1 ) or a regular shape (f2 ) and there
                                                                                     5
are three kinds of irregular shapes (f13 , f3 and f4 ).                                We implemented this sorting task by computing the posterior
                                                                                distribution p(z|V, F ), and comparing the probability that the novel
   We show our model 10 trials for each of the first 12 ob-                     object and its color match belong to the same causal type with the
jects, and Fig. 3c summarizes the results of these trials. In                   probability that the novel object is grouped with the shape match.
                                                                          392

                                t1                       t2
                   o1       o2     o3   o4  o9       o10    o11 o12
                   o5       o6     o7   o8  o13      o14    o15 o16
Schema                          t1                       t2                         t1 +t1                                t2 +t2
                               +0.9                                                                                        +0.9
                                 e                        e                            e                                     e
                ∅  o1 . . . o6     o7   o8  o9 . . . o14    o15 o16 o1 +o2   o3 +o4      o5 +o6 o7 +o8  o9 +o10   o11 +o12   o13 +o14 o15 +o16
Causal            +0.9    +0.9    +0.9 +0.9                                                              +0.9       +0.9       +0.9     +0.9
Models
                e   e        e      e    e   e         e     e   e     e         e          e      e       e          e          e        e
                ∅  o1 . . . o6     o7   o8  o9 . . . o14    o15 o16 o1 +o2   o3 +o4      o5 +o6 o7 +o8  o9 +o10   o11 +o12   o13 +o14 o15 +o16
Data      e+ : 0   15       15      0    0   0         0     0   0     0         0          0      0       15        15          0       15
          e− : 15   0        0      0    0  15        15     0   0    15        15          0     15       0          0          0        0
Figure 4: Learning about interactions between objects. The schema specifies the causal powers of each type and of each com-
bination of types (the combination t1 +t2 ) is not shown. The collection of causal models includes a model for each combination
of objects. The event data are inspired by the experiment of Shanks and Darby [13]. The model groups the objects into two
types: objects belonging to type t1 cause the effect on their own but not when paired with each other, and objects belonging to
the type t2 cause the effect only when paired with each other.
a model that used only the causal data would be unable to                 sumptions. For instance, we assume that the causal power
make useful predictions about the three novel objects. Since              of a conjunction of objects is independent of the causal pow-
we have modeled a simplified version of the Lien and Cheng                ers that correspond to any subset of these objects. To accu-
task, the quantitative predictions of our model are not directly          rately capture human intuitions, it will be necessary to relax
comparable to their results, but Fig. 3d shows that our model             our simplifying assumptions, and to combine our framework
captures the main qualitative patterns in their data.6                    with a sophisticated approach to conjunctive causality [11].
                                                                          Here, however, we have aimed to provide the simplest possi-
  Discovering interactions between causal types                           ble example of how our framework can discover interactions
So far we have considered problems where at most one object               between causal types.
oi can be present at a time. Suppose now that multiple objects
                                                                          Behavioral data
can be present on any trial. For instance, consider the prob-
lem of discovering which drugs produce a certain allergy—                 Shanks and Darby [13] ran an experiment which suggests
two drugs which are innocuous on their own may produce the                that humans can acquire abstract knowledge about interac-
allergy when combined. Our goal is to discover a schema and               tions between causal types. These authors used a task where
a set of causal models that allow us to predict whether any               the potential causes were foods, and the effect of interest was
given combination of drugs is likely to produce an allergic               an allergic reaction. The data observed by participants in their
reaction. Formally, we would like to learn a causal model M               second experiment are shown in Fig. 4.7 When supplied with
for each possible combination of objects.                                 these data, our model discovers two causal types: foods of
   We assume that each combination of objects corresponds                 type t1 (o1 through o8 ) produce the allergy on their own, but
to a conjunctive cause that may be generative or preventive,              foods of type t2 (o9 through o16 ) do not. The model also dis-
and extend Ψ to include an arrow a, a polarity g and a strength           covers that two foods of type t2 will produce the allergy when
s for each combination of objects. We extend the schema in a              eaten together, but two foods of type t1 will not (Fig. 4).
similar fashion, and include schema parameters ā, ḡ, s̄ and σ̄             Shanks and Darby were primarily interested in predictions
for each combination of causal types. The causal model pa-                about cases which had never been observed in training—the
rameters for sets of objects are generated, as before, from the           cases underlined in Fig. 4. Their participants can be divided
schema parameters for the corresponding set of types. For                 into two groups according to their scores when tested on the
instance, Fig. 4 shows how the causal model for o13 +o14 is               training data. Learners in the high group (learners who scored
generated from the schema-level knowledge that pairs of ob-               well on the test) tended to make the same predictions as our
jects drawn from type t2 tend, in combination, to generate the            model: for instance, they tended to predict that o7 and o8 pro-
effect with strength 0.9. As before, we assume that a genera-             duce the allergy when eaten in isolation, that o15 and o16 do
tive background cause of strength b is always present.                    not, that the combination of o13 and o14 produces the allergy,
   There are several possible strategies for handling conjunc-            and that the combination of o5 and o6 does not. Learners in
tive causes and our approach makes several simplifying as-                the low group tended to make the opposite predictions: for
                                                                          instance, they tended to predict that o7 and o8 do not pro-
    6
      Lien and Cheng report that a handful of subjects did not group      duce the allergy when eaten in isolation. Since our compu-
the novel objects with either the shape match or the color match.
                                                                              7
These subjects were dropped before computing the percentages in                 Different subjects saw different amounts of training data, but
Fig. 3d.                                                                  we overlook this detail.
                                                                     393

tational framework does not suffer from memory limitations               is an acid, and acids turn litmus paper red.” Statements like
or lapses of attention, it is not surprising that it accounts only       these correspond to fragments of a causal schema, and future
for the predictions of learners who absorbed the information             experiments should explore how schemata are learned when
provided during training.                                                parts of these schemata are directly supplied.
                                                                            More often than not, competing accounts of a given phe-
                           Discussion                                    nomenon both capture some element of the truth. Where
We described a hierarchical Bayesian framework (Fig. 1c) for             possible, cases like these should be handled by building uni-
learning causal schemata. Our hierarchical framework sup-                fied accounts that subsume the two competing views. We
ports several kinds of inferences. We focused on bottom-up               have developed a hierarchical Bayesian model that attempts
learning and showed that the model helps to explain how a                to unify top-down and bottom-up approaches to causal rea-
causal schema and a set of specific causal models can be si-             soning. Similar conflicts between top-down and bottom-up
multaneously learned given event data and feature data. If               approaches are found in other areas of cognitive science, and
the causal schema is known in advance, then the framework                the hierarchical Bayesian approach may be useful for resolv-
serves as a computational theory of top-down causal learning,            ing these conflicts wherever they occur.
and explains how inferences about a set of causal models can
                                                                         Acknowledgments Supported by the William Asbjornsen
simultaneously draw on low-level event data and top-down
                                                                         Albert memorial fellowship (CK), the James S. McDonnell
knowledge.
                                                                         Foundation Causal Learning Collaborative Initiative (NDG,
   Our work exploits the fact that probabilistic approaches              JBT) and the Paul E. Newton chair (JBT).
are modular and can be composed to build integrated mod-
els of inductive reasoning. The model in Fig. 1c can be cre-
ated by combining three models: probabilistic causal mod-                                            References
els [12] specify how the event data are generated given a set            [1] Anderson, J. R. (1991). The adaptive nature of human catego-
                                                                            rization. Psychological Review, 98(3):409–429.
of causal models, the infinite relational model [8] specifies            [2] Cheng, P. W. (1993). Separating causal laws from casual facts:
how the causal models are generated, and Anderson’s ratio-                  Pressing the limits of statistical relevance. In The psychology of
nal approach to categorization [1] specifies how the features               learning and motivation, volume 30, pages 215–264. Academic
                                                                            Press, San Diego.
are generated. Since all three models work with probabili-
                                                                         [3] Gopnik, A. and Sobel, D. (2000). Detecting blickets: How
ties it is straightforward to combine them to create a single               young children use information about novel causal powers in cat-
integrated framework for causal reasoning.                                  egorization and induction. Child Development, 71:1205–1222.
   We showed that our framework helps to explain some as-                [4] Griffiths, T. L. (2005). Causes, coincidences, and theories. PhD
                                                                            thesis, Stanford University.
pects of the data collected by Lien and Cheng [9] and Shanks
                                                                         [5] Griffiths, T. L. and Tenenbaum, J. B. (2005). Structure and
and Darby [13], and it also accounts for several other results              strength in causal induction. Cognitive Psychology, 51:354–384.
in the literature. Waldmann and Hagmayer [16] showed that a              [6] Kelley, H. H. (1972). Causal schemata and the attribution pro-
known set of categories can influence future causal learning,               cess. In Jones, E. E., Kanouse, D. E., Kelley, H. H., Nisbett,
and our approach predicts a similar result if we fix the causal             R. S., Valins, S., and Weiner, B., editors, Attribution: Perceiving
                                                                            the causes of behavior, pages 151–174, Morristown, NJ. General
types z then use our framework to discover a set of causal                  Learning Press.
models given event data. Our framework can also model ex-                [7] Kelley, H. H. (1973). The processes of causal attribution. Amer-
periments carried out using the blicket detector [3] or causal              ican Psychologist, 28:107–128.
blocks world [15] paradigms. Many aspects of these exper-                [8] Kemp, C., Tenenbaum, J. B., Griffiths, T. L., Yamada, T., and
                                                                            Ueda, N. (2006). Learning systems of concepts with an infinite
iments have been previously modeled, but our framework                      relational model. In AAAI 06.
captures phenomena that are not addressed by most existing               [9] Lien, Y. and Cheng, P. W. (2000). Distinguishing genuine from
models. For instance, our model suggests why two identi-                    spurious causes: A coherence hypothesis. Cognitive Psychology,
cal looking blocks might both be categorized as blickets even               40:87–137.
                                                                         [10] Mansinghka, V. K., Kemp, C., Tenenbaum, J. B., and Griffiths,
though a handful of observations suggest that they have dif-                T. L. (2006). Structured priors for structure learning. In UAI 06.
ferent effects on a blicket detector [3].                                [11] Novick, L. R. and Cheng, P. W. (2004). Assessing interactive
   Several extensions of our approach may be worth explor-                  causal inference. Psychological Review, 111:455–485.
ing. We restricted ourselves to problems where the distinc-              [12] Pearl, J. (2000). Causality: Models, reasoning and inference.
                                                                            Cambridge University Press, Cambridge, UK.
tion between a set of potential causes and a set of effects 8
                                                                         [13] Shanks, D. R. and Darby, R. J. (1998). Feature- and rule-based
is known in advance, but in some cases this distinction might               generalization in human associative learning. Journal of Experi-
need to be learned [10]. A second limitation is that we fo-                 mental Psychology: Animal Behavior Processes, 24(4):405–415.
cused on cases where feature data and contingency data rep-              [14] Shultz, T. R. (1982). Rules of causal attribution. Monographs
resent the only input to our model. Human learners are some-                of the Society for Research in Child Development, 47(1):1–51.
                                                                         [15] Tenenbaum, J. B. and Niyogi, S. (2003). Learning causal laws.
times directly supplied with abstract causal knowledge—for                  In Proceedings of the 25th Annual Meeting of the Cognitive Sci-
example, a science student might be told that “pineapple juice              ence Society.
                                                                         [16] Waldmann, M. R. and Hagmayer, Y. (2006). Categories and
    8
      This paper has focused on problems where there is a single ef-        causality: the neglected direction. Cognitive Psychology, 53:27–
fect, but our approach also handles problems with multiple effects.         58.
                                                                     394

