UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Characterizing Motherese: On the Computational Structure of Child-Directed Language
Permalink
https://escholarship.org/uc/item/54k371nk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Brodsky, Peter
Waterfall, Heidi
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                          Characterizing Motherese:
          On the Computational Structure of Child-Directed Language
             Peter Brodsky (pb86@cornell.edu)                     Heidi Waterfall (he32@cornell.edu)1
                                        Shimon Edelman (se37@cornell.edu)
                                        Department of Psychology, Cornell University
                                                     Ithaca, NY 14853 USA
                          Abstract                                partial self-repetitions — variation sets — when speak-
   We report a quantitative analysis of the cross-utterance       ing to young children acquiring language (Furrow, Nel-
   coordination observed in child-directed language, where        son, & Benedict, 1979; Kavanaugh & Jirovsky, 1982;
   successive utterances often overlap in a manner that           Kaye, 1980; Snow, 1972; Hoff-Ginsberg, 1985, 1986,
   makes their constituent structure more prominent, and
   describe the application of a recently published unsuper-      1990; Küntay & Slobin, 1996; Waterfall, 2006).
   vised algorithm for grammar induction to the largest
   available corpus of such language, producing a gram-           Variation sets
   mar capable of accepting and generating novel well-            Hoff-Ginsberg (1985) conducted one of the initial ex-
   formed sentences. We also introduce a new corpus-based
   method for assessing the precision and recall of an auto-      aminations of the effect of maternal self-repetitions on
   matically acquired generative grammar without recourse         children’s progress in language acquisition. She showed
   to human judgment. The present work sets the stage             that alternations in maternal self-repetitions that con-
   for the eventual development of more powerful unsuper-
   vised algorithms for language acquisition, which would         formed to major constituent boundaries were related
   make use of the coordination structures present in nat-        to growth in children’s verb use, while those repeti-
   ural child-directed speech.                                    tions that altered material within a phrasal constituent
   Keywords: Language acquisition; grammar inference;             aided in noun-phrase growth. In a subsequent study,
   computational linguistics.
                                                                  Hoff-Ginsberg (1986) found that the frequency of self-
                      Introduction                                repetitions and expansions was positively correlated with
                                                                  child verb phrase development. Similarly, Hoff-Ginsberg
Does child-directed speech — what Newport, Gleitman,
                                                                  (1990) confirmed that maternal self-repetitions and ex-
and Gleitman (1977) called “Motherese” — possess spe-
                                                                  pansions were positively correlated with the average
cial characteristics that make it easier to learn from?
                                                                  number of verbs per utterance in child speech.
In this paper, we present two kinds of corpus-based ev-
                                                                     Hoff-Ginsberg’s analyses, however, concentrated on
idence that should be useful in addressing this ques-
                                                                  the corpus as a whole and did not examine the contin-
tion. First, we report a quantitative analysis of the
                                                                  gent nature of clusters of such repetitions. Küntay and
cross-utterance coordination observed in child-directed
                                                                  Slobin (1996) pioneered the research into variation sets,
language, where successive utterances often overlap in
                                                                  conducting the first longitudinal study specifically ana-
a manner that makes their constituent structure more
                                                                  lyzing the effect of local clusters of partial repetitions in
prominent. Second, we describe the application of a re-
                                                                  child-directed speech on language development. Focus-
cently published unsupervised algorithm for grammar in-
                                                                  ing on the acquisition of Turkish, they found that vari-
duction to the largest available corpus of child-directed
                                                                  ation sets made up approximately 20% of child-directed
language, and the performance of the resulting grammar
                                                                  speech. The use of variation sets was positively associ-
in accepting and generating novel well-formed sentences.
                                                                  ated with children’s acquisition of specific verbs.
This work sets the stage for the development of more
                                                                     In sum, variation sets seem to be ideal environments
powerful unsupervised algorithms for language acquisi-
                                                                  for learning lexical items and constituent structures. By
tion, which would make use of the coordinated structures
                                                                  holding most of the utterance constant, while altering it
present in natural child-directed speech.
                                                                  slightly (see Table 1 for an example), parents may allow
         Cross-utterance coordination in                          children to discover lexical items, syntactic constituents,
                                                                  and their place in the syntax, vis-à-vis comparison and
                        Motherese                                 contrast, as envisaged (in the context of the discovery of
There is a great deal of evidence suggesting that par-            grammar by linguists) by Zellig Harris (1946).
ents produce structured dialogues when talking with                  Waterfall (2006) conducted the first longitudinal study
very young children. Parents’ speech to young chil-               of variation sets in English. We briefly mention here
dren is highly repetitive and often includes clusters of          some of her findings (Waterfall, 2007). The participants
    1
      Also with the Department of Psychology, University of       were twelve parent-child dyads (ages 14-30 months). The
Chicago, Chicago, IL 60637 USA.                                   subjects were balanced for child gender, child birth or-
                                                              833

                                                                   of the verb). We note that it may be possible to rephrase
Table 1: A variation set addressed to a 14 month old.
                                                                   “obligatory” in linguistic terminology as “there is a very
      You got to push them to school.
                                                                   high probability that two elements will co-occur in the
      Push them.
                                                                   data.” Thus, it may be the case that children use statis-
      Push them to school.
                                                                   tical information when acquiring constituents — a notion
      Take them to school.
                                                                   that is compatible with the computational approach of
      You got to take them to school.
                                                                   Solan, Horn, Ruppin, and Edelman (2005).
der, and for maternal educational level as a measure of            Finding variation sets
socio-economic status.2 The subjects were videotaped in            The search for variation sets in a corpus can be easily au-
their homes for 90 minutes every four months starting              tomated. The program we wrote for that purpose scans
when the child was approximately 14 months old and                 the corpus, opening a new variation set record when a
continuing to 30 months. There were five observations              non-stoplisted4 word appears for a second time on the
in total. The data for (Waterfall, 2007) come from tran-           working set queue. The first sentence of the variation
scripts made from those videotapes.                                set is the one in which the repeated word first occurs.
   To determine whether or not variation sets foster               The variation set is closed with the last sentence that
the acquisition of syntactic constituents, child-directed          contained a word also contained by any of the other sen-
speech was analyzed for the manipulation of multi-word             tences in the candidate set, so long as the first penul-
constituents in variation sets (e.g., You can sit [on              timate occurrence of the repeating word is also on still
this]. You can sit [up here].). Children’s speech                  on the queue.5 The simplest case results in a variation
was then examined for the use of those structures.                 set consisting of two sentences, both of which share at
Lastly, children’s production of a constituent (e.g., di-          least one word in common. Interleaved variation sets are
rect objects) was correlated with the manipulation of              also possible — sentences sharing words with other, non-
that constituent in variation sets.                                adjacent sentences.6 The variation sets detected in the
                                                                   corpus are then displayed to the user, along with their
Table 2: Correlation results for variation set use and             main computational characteristics, computed according
children’s constituent structure production (reproduced            to methods explained below.
from Waterfall, 2007). Significance levels: * – p < .05;
** – p < .01; *** – p < .0001.                                     Diameter of variation sets
          Prepositional Phrase Adjuncts       .58*                 One key computational characteristic of a variation set
          Entire clause                       .67**                is its diameter, or equivalently the maximal dissimilar-
          Subjects                            .68**                ity between utterances that comprise it. We define dis-
          Direct objects                      .91***               similarity between two strings of words in terms of the
                                                                   Levenshtein (edit) distance: the smallest number of in-
                                                                   dividually weighted elementary edit operations (inser-
   When examining multi-word constituents,3 Waterfall
                                                                   tions, deletions, and substitutions on a per word basis)
(2006) found that children’s production of a structure
                                                                   that transform one string into another. The mean values
is highly correlated with parents’ manipulation of that
                                                                   of variation set diameter for four corpora are shown in
structure in variation sets. The results form a fairly nat-
                                                                   Figure 1.
ural scale. Variation sets are most beneficial for con-
stituent structures that are typically considered obliga-          Prevalence of variation sets
tory (e.g., direct objects) and are less so for those items
                                                                   How surprised should one be to find a variation set in
that are typically considered optional (e.g., prepositional
                                                                   a corpus? To estimate the significance of a series of ut-
phrase adjuncts). Constituents that are obligatory in
                                                                   terances forming a variation set, we would need to know
some cases but that can also be omitted or not used in
                                                                   the probability distribution over utterances, which is, of
others fall somewhere in the middle (e.g., subjects can
                                                                   course, unavailable. We can, however, try to approxi-
be omitted in commands or conjoined clauses; an entire
                                                                   mate that distribution using a statistical language model
subordinate clause can be an adjunct or a complement
                                                                   derived from the available corpus. Given a sequence
   2
     The data mentioned here are a subset of a larger, unre-           4
lated, longitudinal study conducted by Goldin-Meadow, Hut-               Words that are to be excluded from consideration, such
tenlocher, & Levine, under NIH Grant # PO1 HD40605,                as the or and, are put on a stop list.
                                                                       5
2002-2007.                                                               The working set queue is bounded by two limits: the
   3                                                               number of words and the number of lines. When either is
     For some single word constituents (e.g. wh-items) and for
manipulations that occur within a constituent (e.g. manip-         reached, words are taken off the head of the queue until nei-
ulation of a definite article within a noun phrase), variation     ther limit is exceeded.
                                                                       6
set use is not significantly correlated with production. For             An example of an interleaved variation set addressed to a
a detailed explanation of why this might be the case, see          14-month old: Piggies / You want to read that? / Oh
(Waterfall, 2006).                                                 that is piggies. / You want to read this one?
                                                               834

                                                                   the sentence ID sets from every element in the n-gram.
                                                                   Each sentence ID is then used to access the right-linked
                                                                   list hash table. If a node is recovered, it is added to a
                                                                   counted collection, from which a node is drawn at ran-
                                                                   dom to produce the next element of the generated utter-
                                                                   ance.8
Figure 1: Mean edit-distance diameters of variation
sets from four sources: a 42, 530-utterance corpus
of children-directed language (mean words per utter-
ance WPU=4.32) from Waterfall (2006), the 300, 000-
utterance English CHILDES collection (MacWhinney,
2000), and bi- and tri-gram level statistical models of the
CHILDES corpus, generated by an algorithm described                Figure 2: Percentage of words in variation sets in the
below.                                                             (Waterfall, 2006) and CHILDES data (left two bars)
                                                                   and in artificial corpora generated by language models
of words that form a partial utterance w1 , w2 , . . . , wk ,
                                                                   matching the bi- and trigram statistics of the Waterfall
a language model (Goodman, 2001) assigns to each of
                                     (n)                           corpus (right two bars).
its n possible continuations wk+1 — that is, to each of
the words that may appear in the next place in a well-                Figure 2 shows a comparison of the prevalence of vari-
formed utterance in the given language — a probability             ation sets in two natural corpora, and in two artificially
P (wk+1 |w1 , w2 , . . . , wk ). Once “trained” on a corpus, a     generated ones that match the bi- and trigram statistics
language model can be used to estimate the probability             of (Waterfall, 2006). Variation sets are seen to occur
of given utterances, or to generate new ones according             more often in natural corpora (where they also have a
to the probability distribution it embodies, the latter use        lower raw Levenshtein-distance diameter and a higher
being related to the bootstrap methods in mathematical             informational value; not plotted), indicating that this
statistics (Efron & Tibshirani, 1993).                             hallmark of Motherese cannot be due simply to its bi- or
   We estimated the significance of variation sets in the          trigram statistics.
Waterfall (2006) and CHILDES data, by (1) generating
artificial corpora with simple bi- and trigram language            Informativeness of variation sets
models,7 and (2) comparing the prevalence of variation             How useful is a variation set for the learner? A pair of
sets in those corpora and in real data. Our stochastic             utterances that have nothing in common (a fact repre-
algorithm for reproducing n-gram distributions from the            sented by some arbitrary maximal value of edit distance)
training corpus while generating novel utterances uses             is not informative, and neither is a pair of identical ut-
the adios graph data structure (Solan et al., 2005), an-           terances. An optimally informative pair would therefore
notated with the probabilities of the various arcs (as             balance overlap and change; we denote the normalized
estimated from a training corpus). Given a new sen-                distance between members of such a pair by 0 < β < 1.
tence, the algorithm instantiates each word as a node in           To compute the average informational value of an en-
a double-ended queue (deque), one per sentence. Each               tire variation set, every utterance in the variation set is
deque is assigned a unique ID, which is added to its               compared to every other utterance (pairs that are iden-
node’s ID set. Because each distinct word has one and              tical or share no non-stoplisted words are not compared;
only one node associated with it in the graph, the num-            this prevents interleaved variation sets from artificially
ber of sentence IDs in the nodes’ ID sets increases during         depressing the average informational content of the vari-
training. The links between nodes are stored in a hash             ation set sample; is also prevents highly repetitive vari-
table where the key is the sentence ID and the value               ation sets from generating outliers).
is the node. When generating sentences, an n-gram of                  Following this line of reasoning, we define the
arbitrary length is used to produce an intersection of             information-theoretic similarity between two utterances
   7                                                                   8
     An n-gram language model conditions the probability of              This approach does not handle loops – recurring nodes
a word on n preceding words in the utterance.                      in the same path. This option will be added in the future.
                                                               835

within a variation set to be: 1 − |L(~u1 ,~βu2 )−β| , where L     corpora, using adios (Automatic DIstillation Of Struc-
takes two utterances (with stoplisted elements, such as           ture), a batch algorithm that learns phrase structure
closed-class words, removed) and returns their Leven-             rules from raw corpus data by recursively aligning utter-
shtein distance normalized to lie between 0 and 1, and β          ances while abstracting any patterns (Solan et al., 2005).
is a baseline reference value between 0 and 1 which turns         As customary in computational linguistics, we describe
the distance into an information-theoretic measure.               the performance of the learned grammar in terms of re-
   In a preliminary study, we found that the mean infor-          call (defined as the proportion of the sentences in a with-
mational value of the maternal speech corpus (Waterfall,          held test corpus that can be generated by the grammar),
2006) on a variation set by variation set basis correlates        and precision (the proportion of the sentences generated
with the child’s vocabulary size (Figure 3). A value of β         by it that are acceptable).
(“bias” or baseline, explained above) of 0.487 yields the
strongest correlation (R2 = 0.21). These data suggest             Recall and precision on CHILDES
that a fine balance between change and overlap between            Because of the greedy nature of the adios algorithm,
sentences in variation sets (about 50% overlap and 50%            the learned grammar depends on the order of the sen-
new material, with a slight preference towards the latter)        tences in the corpus, which is why the results from sev-
may be the most conducive to vocabulary growth.                   eral learners trained on permuted versions of the corpus
                                                                  are usually pooled. We have trained 30 learners on per-
                                                                  mutations of most of the English portion of CHILDES
                                                                  (approximately 300, 000 sentences), reserving 500 sen-
                                                                  tences for testing recall performance; the recall level was
                                                                  0.50. To test precision, we had each of 10 learners gener-
                                                                  ate 100 sentences, which were then manually judged as
                                                                  grammatical or not; the precision level was 0.63.9
                                                                     These levels of recall and precision are much higher
                                                                  than those achieved by the adios algorithm on the Wall
                                                                  Street Journal corpus used, e.g., by Pullum and Scholz
                                                                  (2002) in their assessment of the “poverty of the stimu-
                                                                  lus” argument. This, of course, merely confirms that the
                                                                  language of CHILDES is structurally simpler than that
                                                                  of the WSJ. More generally, the present results exceed
                                                                  the performance of other unsupervised algorithms that
                                                                  can learn from raw text, but fall somewhat short of the
                                                                  parsing performance achieved by algorithms that work
                                                                  with hand-tagged part of speech data (Klein & Manning,
                                                                  2002).
                                                                     It should be noted that no other method has to our
                                                                  knowledge been tested extensively on CHILDES. More-
                                                                  over, grammars learned by the algorithms that rely on
Figure 3: Information value of variation sets in the cor-         POS tags tend to result in low precision when the POS
pus of Waterfall (2006). The mean information value               symbols in the generated sentences are substituted with
of the maternal variation sets is most correlated with            actual words. In comparison, the level of precision at-
the size of child’s productive vocabulary (R2 = 0.21) for         tained by adios (0.63) can be safely taken at face value.
β = 0.487. For points with vocabulary size > 25, the              Some examples of incorrect and correct sentences it gen-
regression is more pronounced (R2 = 0.40).                        erates appear below:
   Language acquisition from Motherese                            I doesn’t notice it if that’s in your eye.
                                                                  Out jump the tomato.
Very little work has been carried out to date on the              Mumma break it.
acquisition of a generative grammar from real child-
                                                                      9
directed language (Solan et al., 2005; in comparison, the               We also tested the algorithm on the adult speech portions
CHILDES data are often used to test algorithms that ad-           of the only two Hanja/Mandarin corpora from CHILDES:
                                                                  Chang and Zhou (2, 000 and 8, 000 sentences; in each case,
dress specific problems in language acquisition, such as          500 were reserved for testing). Single-learner recall was 0.31
word segmentation or auxiliary fronting in forming po-            and 0.32, respectively (comparable to that obtained for the
lar interrogatives in English). In this section, we report        much larger pooled English CHILDES corpus of 300, 000 sen-
                                                                  tences). Five native speakers rated a sample of Zhou sen-
the first quantitative results on learning a highly pro-          tences at 0.93 precision, compared to 0.54 for novel adios-
ductive construction-like grammar from the CHILDES                generated sentences.
                                                              836

 Wanna put some on your dress?                                   that part. Every generated sentence that matches an
 Shall we add another one like this?                             utterance in either part A or part B is discarded; only
 It didn’t make any noise.                                       novel (unique) sentences are retained. We note that the
                                                                 proportion of sentences produced by the generator that
 A new method for estimating precision                           are found in part A is a pessimistic estimate of the gener-
 The development of generative language models capable           ator’s precision. For part A to be effective in “catching”
 of learning from large, complex, real-life corpora such as      most well-formed generated sentences, it is important
 CHILDES is hampered by the difficulty of estimating the         that it be much larger than part B. When the number
 precision of the models. To calculate precision — that is,      of unique sentences generated is equal to the number of
 the proportion of generated sentences that are acceptable       sentences in part B (or when no new sentences can be
 — one needs either a reliable parser for the target gram-       created), the process is halted and the novel sentences,
 mar (which does not exist for realistic natural language        which for the above reason are more likely than the av-
 data) or access to human subjects who would judge the           erage generated sentence to be ill-formed, are placed in
 acceptability of the generated sentences (an infeasible         part C.
 requirement in the development of large-scale learning             The processor is trained on part A; given a new sen-
 models, where precision needs to be assessed repeatedly         tence, it returns a score between 0 and 1 indicating its
 for thousands of sentences in each cycle).                      normalized probability. Computing the average score
    We describe a novel method for estimating recall and         for sentences in part B would yield the processor’s re-
 precision, which bypasses these limitations. It relies          call. However, by testing it on both parts B and C
 on the observation that two highly constrained models           as described below, we can also estimate its precision.
 trained on disjoint corpora are very unlikely to agree co-      For every sentence in the union of B and C, the score
 incidentally about the acceptability of a given test sen-       is binned; a value of 0 is placed in the bin if the sen-
 tence (operationalized as its probability given the gram-       tence comes from part C, and a value of 1 if it is from
 mar). Thus, any such agreement supports the hypothe-            part B. The processor’s precision is high insofar as the
 sis that the score given to a sentence is indeed valid. A       average score for sentences from part C (which, as ex-
 precision-testing scheme based on this observation (see         plained above, are likely to be ill-formed) is low, and
 Figure 4) requires:                                             in particular significantly lower than that for sentences
                                                                 from part B. Figure 5 shows that this is indeed the case
1. A language model, called the processor, which is
                                                                 for two models trained on CHILDES: adios interpolated
    trained on a part of the available corpus, and for which
                                                                 with a bigram model (shaded bars) and a trigram model
    the precision needs to be estimated;
                                                                 (open bars). A Fisher Exact test indicated that the dif-
2. An auxiliary language model, called the generator,            ference between B and C average scores was highly sig-
    which is trained on another part of the corpus, and          nificant for both models: t = 1158.2 (p = 0.0000) and
    then used to generate sentences that have a high like-       t = 136.8 (p = 0.0000) respectively. A Friedman test
    lihood of being ill-formed.                                  of the difference between the distributions of scores gen-
                                                                 erated by the two models showed the adios+bigrams
                                                                 model to be significantly better: χ2 = 17.8 (p < 0.001).
                                                                    It is important to note that the generator and the
                                                                 processor are not trained on the same or even overlap-
                                                                 ping parts of the corpus. Training the generator on the
                                                                 same segment as the processor would create doubt as to
                                                                 whether the outcome is characteristic of the corpus in
                                                                 general or is specific to the common segment. By us-
                                                                 ing disjoint training sets, we ensure that the only path
                                                                 to agreement between the two models is via the more
                                                                 abstract, general characteristics of the corpus. A large-
                                                                 scale Monte Carlo simulation study designed to validate
                                                                 this approach to precision estimation is currently under
 Figure 4: A scheme for testing precision without a parser       way. It involves artificial corpora generated by context-
 or a human evaluator (see text for explanation).                free grammars (allowing us to obtain the ground truth
                                                                 for precision using parsers for those grammars).
 The training corpus must be large enough so that less
 than half of it suffices to train both the processor and                              Conclusions
 the generator. This corpus is split into two parts, A and
 B. The generator is trained on part B, and is used to           In this short paper, we described an initial quantita-
 produce sentences that follow the WPU distribution of           tive investigation of a key characteristic of child-directed
                                                             837

                                                               Harris, Z. (1946). From morpheme to utterance. Lan-
                                                                 guage, 22, 161-183.
                                                               Hoff-Ginsberg, E. (1985). Relations between discourse
                                                                 properties of mothers’ speech and their children’s syn-
                                                                 tactic growth. Journal of Child Language, 12, 367-385.
                                                               Hoff-Ginsberg, E. (1986). Function and structure in ma-
                                                                 ternal speech: their relation to the child’s development
                                                                 of syntax. Developmental Psychology, 22, 155-163.
                                                               Hoff-Ginsberg, E. (1990). Maternal speech and the
                                                                 child’s development of syntax: A further look. Journal
                                                                 of Child Language, 17, 85-99.
                                                               Kavanaugh, R., & Jirovsky, A. (1982). Parental speech
                                                                 to young children: A longitudinal analysis. Merrill-
                                                                 Palmer Quarterly, 28, 297-311.
                                                               Kaye, K. (1980). Why we don’t talk “baby talk” to
Figure 5: A large-scale estimate of the precision of two         babies. Journal of Child Language, 7, 498-507.
language models trained on the English CHILDES cor-            Klein, D., & Manning, C. D. (2002). Natural lan-
pus. The plot shows the probabilities assigned by an             guage grammar induction using a constituent-context
interpolation of an adios model with a bigram model              model. In T. G. Dietterich, S. Becker, & Z. Ghahra-
(shaded bars) and a trigram model (open bars) to ill-            mani (Eds.), Advances in neural information process-
formed test sentences newly generated by an auxiliary            ing systems 14 (p. 35-42). Cambridge, MA: MIT
mechanism (left), and to withheld test sentences (right).        Press.
As explained in the text, this result indicates that it        Küntay, A., & Slobin, D. (1996). Listening to a Turkish
is possible to estimate precision without recourse to a          mother: Some puzzles for acquisition. In D. Slobin &
parser (which is not available for real natural language)        J. Gerhardt (Eds.), Social interaction, social context,
or to human acceptability judgments.                             and language: Essays in honor of Susan Ervin-Tripp
                                                                 (p. 265-286). Hillsdale, NJ: Lawrence Erlbaum Asso-
language — its variation set structure — and demon-              ciates.
strated that our current algorithm for language acquisi-       MacWhinney, B. (2000). The CHILDES project: Tools
tion, adios, can learn a precise, relatively high-coverage       for analyzing talk. Mahwah, NJ: Erlbaum. (Volume
generative grammar from the CHILDES corpus. We                   1: Transcription format and programs. Volume 2: The
are presently working on developing a next version of            Database.)
the adios algorithm, which will incorporate the insights       Newport, E. L., Gleitman, H., & Gleitman, L. (1977).
from variation set studies, and thereby serve as a better        Mother, I’d rather do it myself: Some effects and non-
model of human performance in language acquisition.              effects of maternal speech style. In C. E. Snow & C. A.
                                                                 Ferguson (Eds.), Talking to children: Language input
                 Acknowledgments                                 and acquisition (p. 109-150). Cambridge: Cambridge
                                                                 University Press.
HRW’s dissertation work was supported by NIH Grant
                                                               Pullum, G. K., & Scholz, B. (2002). Empirical assess-
# PO1 HD40605 to Susan Goldin-Meadow and Janellen
                                                                 ment of poverty of the stimulus arguments. The Lin-
Huttenlocher at the University of Chicago. The present
                                                                 guistic Review, 19, 9-50.
project was supported in part by a seed grant from the
                                                               Snow, C. E. (1972). Mothers’ speech to children learning
Cornell Institute for the Social Sciences. The English
                                                                 language. Child Development, 43, 549-565.
CHILDES precision and recall data were generated by
                                                               Solan, Z., Horn, D., Ruppin, E., & Edelman, S. (2005).
Morgan Ulinski. The Mandarin CHILDES data were
                                                                 Unsupervised learning of natural languages. Proceed-
generated by Shane Sniffen and Andrew Carr.
                                                                 ings of the National Academy of Science, 102, 11629-
                                                                 11634.
                      References
                                                               Waterfall, H. R. (2006). A little change is a good
Efron, B., & Tibshirani, R. (1993). An introduction to           thing: Feature theory, language acquisition and varia-
   the bootstrap. London: Chapman and Hall.                      tion sets. Unpublished doctoral dissertation, Univer-
Furrow, D., Nelson, K., & Benedict, H. (1979). Mothers’          sity of Chicago.
   speech to children and syntactic development: Some          Waterfall, H. R. (2007). The role of variation sets in
   simple relationships. Journal of Child Language, 6,           verb learning. (In preparation.)
   423-442.
Goodman, J. T. (2001). A bit of progress in language
   modeling. Computer Speech and Language, 403-434.
                                                           838

