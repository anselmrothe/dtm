UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
NIMBLE: A Kernel Density Model of Saccade-Based Visual Memory
Permalink
https://escholarship.org/uc/item/2hn4v6q3
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Barrington, Luke
Marks, Tim K.
Cottrell, Garrison W.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            NIMBLE: A Kernel Density Model of Saccade-Based Visual Memory
                                     Luke Barrington* , Tim K. Marks‡ and Garrison W. Cottrell‡
               ? Electrical and Computer Engineering Department, ‡ Computer Science and Engineering Department
                                                      University of California, San Diego
                                                                La Jolla, CA 92093
                                                {lbarrington, tkmarks, gary}@ucsd.edu
                               Abstract                                      uses naı̈ve Bayes to combine the likelihood estimates from
                                                                             individual fragments. We further extend the model to multi-
   We present a Bayesian version of Lacroix et al.’s natural in-
   put memory (NIM) model of saccadic visual memory (Lacroix,                class visual memory tasks, and to use a variety of kernels
   Murre, & Postma, 2006). Our model uses a cognitively plau-                for density estimation. Our model, which we call NIMBLE
   sible image sampling technique that provides a foveated repre-            (for NIM with Bayesian Likelihood Estimation), achieves hu-
   sentation of image patches. We conceive of these memorized
   image fragments as samples from image class distributions and             man levels of performance on a standard face recognition task
   model the memory of these fragments using kernel density                  and can also successfully perform multi-class face and object
   estimation. Using these models, we derive class-conditional               identification tasks. Bayesian combination of individual frag-
   probabilities of new image fragments and integrate individ-
   ual fragment probabilities to classify images. Our Bayesian               ment likelihoods outperforms the combination method from
   formulation of the model extends easily to handle multi-class             the NIM model in most cases and the new kernels far outper-
   problems. We validate our model by demonstrating human lev-               form those used in NIM.
   els of performance on a face recognition memory task and high
   accuracy on multi-category face and object identification.                   We begin by describing our biologically-motivated image
                                                                             sampling and transformation procedure. We then describe
                                                                             the NIM model. Next, we explain our Bayesian version of
Keywords: Cognitive model; saccade-based vision; kernel                      the model, NIMBLE, including a variety of extensions. We
density estimate                                                             present human and model performance on visual memory
                                                                             tasks and conclude the paper with a discussion.
                          Introduction
                                                                                              Visual Input Simulation
Human visual perception begins with saccades, a small num-
ber of local, foveated patches sampled from a visual scene.                  Fixation Point Selection
In order to perceive all parts of a visual scene with great acu-             Given a current fixation point, the choice of where to sac-
ity as well as to maintain neural activation in the visual cor-              cade to next is driven by a number of external cues including
tex, we repeatedly foveate different areas of the scene, con-                motion, peripheral complexity and non-visual stimuli (e.g.
centrating fixations on the parts that are most salient or task-             sound) as well as top down task-dependent directives such
relevant (Yarbus, 1967). Not only is our sampling of visual                  as attention and expectation. Though many computer mod-
objects fragmented in space and time, the sequence of sac-                   els (Wolfe, 1994; Mozer, Shettel, & Vecera, 2005; Zelinsky,
cades (scan path) we follow is unlikely to be repeated in fu-                Zhang, B. Yu, & Samaras, 2005) have been proposed for how
ture exposures to the same object or object class (Henderson,                to integrate top-down and bottom-up cues, in this work we
Williams, & Falk, 2005). Hence, simple exemplar matching                     concentrate only on bottom-up salience of static images. We
of information from new saccades to stored memories can-                     model the fixation selection process using an interest opera-
not be relied upon to account for human capacities for object                tor for determining the scan paths (Yamada & Cottrell, 1995).
recognition.                                                                 This simplified model uses the rotational variance of eight
   Lacroix et al. (Lacroix, Murre, Postma, & Herik, 2004;                    low-resolution Gabor filter responses to construct a distribu-
Lacroix et al., 2006) have proposed the Natural Input Mem-                   tion of the contour complexity (salience) over all pixels in a
ory (NIM) model to account for humans’ ability to recognize                  given image:
faces.1 The model is in the mathematical psychology tradi-
tion, but is unusual for this sort of model in that (a) it uses                                         1 8
actual facial images as input, and (b) it is based on the idea of
                                                                                      Salience(i, j) =    ∑ (G (i, j, θ) − µG (i, j))2
                                                                                                        8 n=1
storing saccade-based face fragments, rather than whole face
exemplars. The model’s memory is reminiscent of a kernel                     where G (i, j, θ) is the response of a Gabor filter with orien-
density estimator, but differs in important details in the way               tation θ centered at pixel (i, j) and µG (i, j) is the mean re-
the estimates from individual fragments are combined. In this                sponse across all orientations. A similar technique developed
paper, we present a Bayesian version of the NIM model that                   by (Renninger, Coughlan, Verghese, & Malik, 2004) defines
                                                                             salience as the entropy, rather than the variance, of local im-
    1 Face recognition refers to the ability to discriminate previously
                                                                             age contours.
seen faces from novel faces, based on a study list. In contrast, face
identification or person identification refers to the ability to identify       We convert this salience map into a probability distribution
face images as particular individuals.                                       using the softmax function (Bishop, 1995). A fixation point
                                                                          77

is then chosen randomly according to this distribution. Fig-
ure 1 shows a salience map generated in this manner as well
as a sample distribution of fixation points. After each fixa-
tion point is chosen, we reduce the salience around the fixated
point by subtracting a univariate Gaussian, centered at the fix-
ation point, from the salience distribution and renormalizing.
This inhibits repeated fixations of the same location.
   Despite the simplicity of this purely bottom-up model, the
resulting scan paths for the face recognition task qualitatively
approximate those observed in humans (Yamada & Cottrell,
1995). The model satisfies three of the five criteria identified
by (Itti & Koch, 2001) for a computational model of visual
attention: it derives perceptual saliency of a fixation point                       (a)                              (b)
from the surrounding context, it creates a salience distribu-
tion over the visual scene, and it inhibits return to previously     Figure 1: (a) An image from the FERET database with 10
attended locations. In this paper, we ignore the remaining two       sample fixation points. (b) The corresponding salience map
criteria, which concern top-down influences on fixation point        generated using the technique of (Yamada & Cottrell, 1995).
selection. In future work, we intend to incorporate top-down         Fixations tend to cluster around highly salient areas but relax-
feedback to direct eye movements, by extending the results           ation of sampled points enforces an even distribution across
of (Nelson & Cottrell, 2007) to determine the fixations that         the image.
would be most useful in enhancing performance on the cur-
rent visual task.
   We have tested NIMBLE using various alternative mech-             extra-foveal information, corresponding to the low-resolution
anisms for computing visual salience. The salience operator          data from the retinal periphery.
of (Itti & Koch, 2001) results in roughly the same face recog-          The size of the extracted patch of filter responses and the
nition performance as that of (Yamada & Cottrell, 1995), but         number of patches that the model may examine for each im-
the latter uses the same mechanism for computing salience            age are experimental parameters that correspond, in human
(Gabor filters) as for processing images (see next section).         vision, to the distance of the eye from the image (and thus the
Purely random selection of fixations reduces performance by          size of the foveated area) and the time spent studying the im-
30%. Sampling fixations from the Canny edge map of the im-           age (determining the number of saccades made). For a patch
age reduces performance by 20%. We also tested NIMBLE                size of 35x35 pixels (corresponding to a visual angle of 1.5◦
using the actual locations of human fixations, which were            for a subject about 75cm from a 256µm-pixel computer moni-
recorded from the same face images using an eye-tracker, and         tor, an approximation of the human studies discussed below),
found the resulting memory performance to be comparable to           the model’s input feature vector has 35 x 35 pixels x 8 ori-
using the salience operator described.                               entations x 4 frequencies = 39200 dimensions. For efficiency
                                                                     and good generalization, we use principal components analy-
Retinal / Cortical Image Transform                                   sis (PCA) to reduce the size of this vector to 80 components,
A fixated patch of an input image undergoes many stages              retaining about 90% of the variance depending on the dataset
of neural processing before being stored as a pattern of ac-         (see NIMBLE Results below). This feature extraction pro-
tivation in high-level visual cortex. Our biologically-inspired      cedure of wavelet-based image decomposition followed by
model of the processing in primary visual cortex (V1) uses the       PCA is a standard approximation for biologically motivated
magnitude responses of Gabor filters at 8 orientations and 4         vision models (Dailey, Cottrell, Padgett, & Adolphs, 2002;
frequencies (Jones & Palmer, 1987). We transform an image            Palmeri & Gauthier, 2004; Lacroix et al., 2006).
into the Gabor-filtered domain by calculating the response of
each of these 32 filters at every image pixel. We use Gabor fil-                  Natural Input Memory (NIM)
ter frequencies of 16 , 12 , 8 and 14 cycles/pixel (corresponding
                     1 1 1
                                                                     The inspiration for our model of saccade-based vision comes
         2
to 8, 10 3 , 16 and 32 cycles/face).                                 from the work of (Lacroix et al., 2004, 2006). Their Nat-
   Square patches extracted from these Gabor response im-            ural Input Memory (NIM) model is so-called since it takes
ages constitute our foveated representation of the fixated           saccade-like samples from a studied image as input. Their
point. The highest-spatial-frequency filter responses corre-         sampling method differs slightly from ours in that they sam-
spond to the high-resolution foveated area centered at the fix-      ple from the contours of an image, determined by Canny
ation point. The low-frequency filter responses at a given           edge-detection, and then process the sampled patches with
pixel within the square patch are computed from an image             the steerable pyramid transform, a multi-scale wavelet-based
area with spatial context that extends beyond the borders            transform that is similar to Gabor filtering. They apply PCA
of the patch. Thus this patch-based representation includes          to these features before storage in the memory.
                                                                  78

   Following the lead of many cognitive memory models                familiar or unfamiliar. Our extension of NIM, described in
(Hintzman, 1984; Nosofsky & Palmeri, 1997; Dailey, Cot-              the next section, stores class labels with each exemplar, and
trell, & Busey, 1998), the NIM model’s memory process                can return explicit posterior probabilities for each class given
stores the feature-transformed representation of fixated image       the image fragments, permitting multi-class and hierarchical
fragments as vectors in a high-dimensional memory space.             memory tasks in addition to the familiar / unfamiliar recogni-
Memories are compared to each other as well as to new im-            tion memory task in (Lacroix et al., 2006).
age fragments by comparing the Euclidean distance between
their vector representations in the memory space. The NIM                          A More NIMBLE Approach
model computes the familiarity of a new fragment by calcu-           Having sampled and processed a new image as described
lating the proportion of previously stored memories that lie         above, we want to evaluate the probability of the resulting set
within a radius r (a model parameter) of the new fragment            of N fragments, F = { f1 , ..., fN }, under the models for each
in the memory space. Averaging these familiarities over all          of a number of image classes (e.g., familiar/unfamiliar faces,
samples from a new image produces an estimate of the prob-           Alice/Bob/Carol/Dan/unknown, dogs/not dogs). For a class,
ability that the image is from the class known to the mem-           c, we use Bayes rule to compute the posterior distribution:
ory. The memory space introduced by the NIM model has
                                                                                                     P(F |c)P(c)
been shown to achieve the best known correlation with human                              P(c|F ) =                  .
judgements of perceptual similarity (Lacroix et al., 2006),                                               P(F )
and the retrieval methods exhibit human performance effects          In this case, P(F |c) is the likelihood of the set of image frag-
(such as list length and list strength) on face recognition mem-     ments under the density model for class c, and P(c) is the
ory tasks (Lacroix et al., 2004).                                    class prior which may be learned from experience with train-
   The NIM memory retrieval method (Lacroix et al., 2006)            ing data.
determines the familiarity of a newly examined fragment by              We compute the likelihood of the set of image fragments,
counting how many of the stored memories, {m1 , ..., mM }, lie       P(F |c), by combining the likelihoods of each individual frag-
within a radius r of the new image fragment. Thus the famil-         ment, P( fi |c). We compute these class-conditional fragment
iarity of the new fragment, f , is defined by:                       likelihoods using kernel density estimation (see below).
                                M
                                                                     Naı̈ve Bayes Fragment Combination
                  f am( f ) =  ∑ Ir (||m j − f ||2 ),         (1)
                               j=1                                   In the NIMBLE model, we can consider the naı̈ve Bayes
                                                                     assumption of conditional independence between each frag-
where                        (                                       ment fi ∈ F , given the class, and take the product of the indi-
                                1, x ≤ r                             vidual fragment likelihoods to get an estimate of the overall
                    Ir (x) =
                                0, otherwise.                        likelihood function:
                                                                                                        N
NIM Combination of Fragment Familiarities                                                  P(F |c) = ∏ P( fi |c).                  (3)
An     image is represented as a set of fragments                                                      i=1
F = { f1 , ..., fN }. In the NIM model, (Lacroix et al.,             By integrating fragment likelihoods using the naı̈ve Bayes
2006) define the familiarity of an image as the mean of the
                                                                     combination (3), we can obtain a parameter-free estimate of
familiarities of all N patches taken from that image:
                                                                     the posterior probability of each class given the image.
                                                                        In contrast, if we consider the familiarity of image patches
                                  1 N
                    f am(F ) =       ∑ f am( fi ).
                                  N i=1
                                                              (2)    in the NIM model to be fragment likelihoods, we can think
                                                                     of NIM’s fragment integration method as defining the likeli-
                                                                     hood of an image to be the mean of its fragment likelihoods:
 They use a logistic function to transform this mean familiar-
ity value into a probability:                                                                         1 N
                                                                                         P(F |c) =       ∑ P( fi |c).              (4)
                                             1                                                       N i=1
             P(familiar image) =                        ,
                                      1 + βe−θ f am(F )              However, it is difficult to interpret this formulation’s implicit
                                                                     assumptions about dependence between fragments.
where β and θ are parameters of the model used to fit the
performance to human data.                                           Bayesian Classification
   The NIM model formulation (Lacroix et al., 2006) only             The classification decision is made by comparing the log ratio
attempts to make judgements about the familiarity of a stud-         of the class and non-class posteriors:
ied image by comparing a set of fragments extracted from
it to all previously stored memories. Since these memories                 P(c|F )         P(F |c)P(c)           P(F |c)       P(c)
                                                                       log           = log                = log          + log      .
are stored without labels, the resulting familiarity value must            P(c|F )         P(F |c)P(c)           P(F |c)       P(c)
be compared to a threshold to decide whether the image is                                                                          (5)
                                                                  79

The first term on the right-hand side of Equation (5) com-         Table 1: Model ROC area for face recognition memory. Im-
pares the relative likelihoods of the observed fragments under     age likelihoods are determined by combining the familiarities
the class and non-class models. The second term controls the       of image fragments using either naı̈ve Bayes (3) or the mean
bias or prior weight that the model or subject puts on seeing      of the fragment familiarities (4). The likelihood of an image,
images from class c versus all other images. The Bayes de-         given the distractor class is found using a background model
cision rule classifies the image as coming from class c when       with either 10 or 80 dimensions. Standard errors of the mean
Equation (5) is positive and from class c otherwise. In the        are computed over 5 random trials.
multi-class framework, the Bayes-optimal rule is to chose the                                                    ROC area
class with the largest posterior probability:                           Kernel    Fragment Combination
                                                                                                           10-D BG 80-D BG
                                                                      Gaussian         Naı̈ve Bayes        0.94±.03 0.58±.02
                      c∗ = argmax P(F |c).                  (6)       (σ = 1)        Mean familiarity      0.97±.02 0.62±.13
                                 c                                    kNN              Naı̈ve Bayes        0.93±.05 0.97±.02
Kernel Density Estimation                                             (k = 1)        Mean familiarity      0.96±.02 0.96±.01
Kernel density estimation places a kernel function at the point
in memory space corresponding to every memorized frag-
ment and computes the probability density of the new point                             NIMBLE Results
 f under each of these kernels. The sum of these probabil-         In our simulations of memory tasks below, we consider both
ities forms the overall estimation for the likelihood of the       face and object datasets. For facial memory tasks, we use
new fragment, P( f |c). The choice of kernel function and the      as input 128x192 pixel grayscale images from the FERET
parameters that control its shape are design features of the       database (Phillips, Wechsler, Huang, & Rauss, 1998). Images
model, which we will consider below.                               of 95 male and female Caucasian faces without facial hair or
   We may interpret the NIM (Lacroix et al., 2006) measure of      glasses were chosen and the images were centered and nor-
a new fragment’s familiarity (1) as a kernel density estimate      malized to have common eye positions and equal contrast.
that centers a hypersphere of radius r, with uniform density,      An example may be seen in Figure 1(a). For object memory
at the location of each stored exemplar in memory space. The       tasks, we use 128 × 128 pixel grayscale images of 20 objects
familiarity of a new fragment, f , can be viewed as summing        from the COIL-100 data set (Nene, Nayar, & Murase, 1996).
its density under all of these uniform kernels.
   By casting the problem of memory retrieval as a kernel          Face Recognition
density estimation task we can explore the model’s perfor-         The first experiment used to test memory performance is a
mance under a variety of kernel functions beyond the hyper-        simple face recognition task. We follow the formulation of
sphere in (1). Indeed, this kernel prohibits using the naı̈ve      (Duchaine & Nakayama, 2005) who used this method to eval-
Bayes combination of fragment likelihoods (3) since, if a test     uate the face and object memory performance of normal and
fragment f were to find no stored points within radius r, it       prosopagnosic human subjects. The study phase of their task
would be assigned zero likelihood. In that case, even if all       presented subjects a sequence of 10 target images, each dis-
other fragments were strongly predictive of the class, the re-     played for 3 seconds. This target list was repeated for a to-
sulting product of fragment likelihoods would be P(F |c) = 0.      tal of 20 image viewings. In the test phase, subjects were
   We implement the NIMBLE model using two alternative             presented with 50 images where 10 were the original targets
kernel functions. The first is a Gaussian kernel:                  (again, shown twice) and 30 were novel distractors, the lures.
                                   |Mc |                           The subjects’ task was to classify each image in the study
                               1
                P( f |c) =
                            |Mc |   ∑ N ( f , m j , σ)      (7)    phase as old or new. When tested on face image categories,
                                    j=1
                                                                   normal human subjects achieved receiver operating charac-
(here N (x, µ, σ) represents the normal distribution of x with     teristic (ROC) curve areas in the range 0.9 to 1.0 for this task.
mean µ and variance σ). The second is a k-nearest-neighbor            In the study phase of our simulations, we extract N = 10
(kNN) kernel:                                                      fragments from each of the target faces, approximating the
                                         kc                        number of saccades a human makes in 3 seconds. We sam-
                         P( f |c) ∝         ,               (8)
                                     |Mc |V                        ple each of the 10 target faces twice and store the resulting
where V is the minimum volume centered at f that contains          200 fragments in the model’s memory space. During the test-
kc of the |Mc | memories from class c.                             ing phase, we extract a new set of N fragments from the test
                                                                   faces. Given the stochastic nature of our interest operator,
   NIMBLE’s Bayesian framework can accommodate both                the exact fragments extracted from previously viewed target
naı̈ve Bayes combination of fragment likelihoods (3) and           images are unlikely to be seen again. As (Henderson et al.,
NIM’s averaging method of combining fragment likelihoods           2005) demonstrated, human scan paths are not repeated in
(4). In Tables 1 and 2, we refer to these two methods for ob-      facial memory encoding and retrieval, and so simple exem-
taining an overall image likelihood from fragment likelihoods      plar matching may not perform well. In our experiments, the
as Naı̈ve Bayes and Mean familiarity, respectively. We also        mean distance from a point sampled from a test face to the
indicate the best parameter setting for each kernel.               nearest study point from the same face was 8.8 pixels.
                                                                80

Table 2: Model accuracy for identity recognition memory tasks. Face ID uses 29 identities from FERET, Object ID uses 20
classes from COIL-100. (Optimal gaussian variance for object ID is 10-times greater than for face ID). Standard errors of the
mean are computed over 5 random trials.
                                                    Face ID Accuracy (%)                Object ID Accuracy (%)
                              Kernel          Naı̈ve Bayes Mean familiarity       Naı̈ve Bayes Mean familiarity
                       Gaussian (σ = 1, 10)      85.6±2           72.2±2               87±1            73.7±2
                       kNN (k = 1)               89.2±.6          85.8±2             92.7±.7            87±.4
   Since we do not restrict our model to discrete kernel func-        images (with different lighting, expressions or orientations)
tions such as (1), in which only a subset of the stored mem-          from 29 different FERET face identities or 20 COIL-100 ob-
ories contribute to the old/new decision, all stored memories         ject classes, and tested on 3 unseen images from each of these
from a given class contribute to the estimate of the posterior        classes. Unlike in the recognition task, the model must now
probability of the class. In order to apply the Bayes decision        learn to identify images it has never seen before. The out-
rule (5) to the one-class recognition task described above, we        put of the model is the posterior probability for each class,
recast it as a two-class classification task. Training image          and the classification decision is made using (6). For this
fragments are stored with a class label that indicates they have      multi-class problem, we assign equal prior probability to each
been seen in the study phase.                                         of the classes and evaluate performance as the average ac-
   We need to be able to estimate the likelihood that an im-          curacy over all classes. Note that the optimal parameter,
age fragment was generated by the lure (distractor) class,            σ, for the Gaussian kernel depends on the class of images
P( f |c). To estimate this probability, we use a multivariate         to be identified since the within-class variance of patches
Gaussian whose variance in each feature dimension is set              taken from rotating objects (COIL-100) is much higher than
equal to the principal component (eigenvalue) obtained by             the variance between patches sampled from aligned faces
performing PCA on fragments extracted from 55 face images             (FERET). Identification task results are shown in Table 2.
not used in the study or test phases. We used this method be-         Our model demonstrates high performance on these multi-
cause it approximates storing a large number of face patches          class tasks. For example, our best object recognition model
that a subject might see over her lifetime but is computation-        (kNN with Naı̈ve Bayes) approaches state-of-the-art com-
ally faster than explicitly sampling from an extra set of non-        puter vision models for object recognition; (Belongie, Malik,
task images. We compared the effect of using two different            & Puzicha, 2002) report 97.6% accuracy on the same task.
background models to estimate P( f |c): a low-dimensional
background model using the first 10 principal component di-
mensions, and a high-dimensional background model using                  We use this multi-class task to demonstrate the advantage
the first 80 principal component dimensions. In Table 1, we           of using the naı̈ve Bayes method for combination of fragment
refer to these as 10-D BG and 80-D BG, respectively. The              likelihoods (3) over the mean familiarity method (4) used in
Gaussian kernel suffers a drop in performance when using              (Lacroix et al., 2006). For certain images, a given fragment
the high-D background model since the extra dimensions of             may be either diagnostic of its true class or useful in exclud-
the 80-dimensional background model (which account for the            ing another class. In both cases, adding this fragment’s likeli-
least variance in the data) are quite susceptible to noise. When      hood to a running average over fragments (4) provides less
categorizing a new input, the kNN model (k = 1) uses only             useful modification to the ultimate posterior than does the
one data point, unlike the Gaussian model which takes input           probabilistically valid naı̈ve Bayes updating method of mul-
from every point in memory. Thus, the kNN model is less               tiplication (3). This scenario is illustrated in Figure 2 for the
affected by noise.                                                    mean posterior probability of the correct class in the facial
   For each set of test fragments, we compute the posterior           identification task, averaged over all 29 facial identities. We
probability that these image fragments were generated by the          use an online version of NIMBLE to update the posterior,
target and lure distributions. By varying the prior values for        P(c|F ), as each fragment is added to F . With more informa-
each class, P(c) and P(c), we can generate receiver operating         tion, the posterior for the correct class with naı̈ve Bayes likeli-
characteristic (ROC) curves for the recognition memory task.          hood combination (3) rises towards 1, while the posterior cal-
The area under the ROC curve is computed and results are              culated using mean familiarity (4) remains roughly constant.
shown in Table 1. Normal human performance for face recog-            The posterior probabilities of the 28 incorrect classes are not
nition results from (Duchaine & Nakayama, 2005) show ROC              shown but, since the sum over all 29 classes must equal unity,
areas between 0.9 and 1.0, and NIMBLE performs similarly.             it is clear that each incorrect class has very low probability
                                                                      and that the Bayes decision rule in Equation 5 almost always
Image Identification                                                  results in correct classification. Random guessing would set
Having extended NIM to allow memories to be stored with               P(c|F ) = 29 1
                                                                                      . Note that these results make the prediction that,
class labels, we now apply NIMBLE to multi-class mem-                 on average, a single saccade is enough to correctly identify a
ory tasks. In this paradigm, the model is trained using 3             face!
                                                                  81

             1
                                                                                 pressions. Journal of Cognitive Neuroscience. 14,
           0.9                                                                   1158-1173.
                                                                         Duchaine, B., & Nakayama, K. (2005). Dissociations of
           0.8
                                                                                 face and object recognition in developmental prosopag-
           0.7                                                                   nosia. Journal of Cognitive Neuroscience, 17, 249-261.
                                                                         Henderson, J., Williams, C., & Falk, R. (2005). Eye move-
           0.6
                                                                                 ments are functional during face learning. Memory &
   P (c|F)                                                                       Cognition, 33, 98-106.
           0.5
                                                                         Hintzman, D. (1984). Minerva 2: A simulation model of hu-
           0.4
                                                                                 man memory. Behavior research methods, instruments
           0.3                                                                   and computers, 16, 96-101.
                                                                         Itti, L., & Koch, C. (2001). Computational modeling of visual
           0.2
                                                                                 attention. Nature Reviews Neuroscience, 2, No. 3, 194-
           0.1
                                                    Naive Bayes
                                                                                 203.
                                                    Mean Familiarity     Jones, J., & Palmer, L. (1987). An evaluation of the
             0
              1  2     3     4    5      6     7     8      9      10            two-dimensional gabor filter model of simple receptive
                           number of fragments in F
                                                                                 fields in cat striate cortex. Journal of Neurophysiology,
                                                                                 58(6) 1233-1258.
Figure 2: NIMBLE’s posterior probability of the correct face             Lacroix, J., Murre, J., & Postma, E. (2006). Modeling recog-
class vs. number of fixations in the 29-class face identifica-                   nition memory using the similarity structure of natural
tion task. Posteriors are computed using both naı̈ve Bayes                       input. Cognitive Science, 30, 121-145.
combination of fragment likelihoods (3) and mean familiar-               Lacroix, J., Murre, J., Postma, E., & Herik, H. J. V. den.
ity combination of fragment likelihoods (4). The very low                        (2004). The natural input memory model. Proc. of the
probabilities of the 28 incorrect classes are not shown.                         26th annual meeting of the Cognitive Science Society.
                                                                         Mozer, M., Shettel, M., & Vecera, S. (2005). Top-down
                          Discussion                                             control of visual attention- a rational account. Neural
Using the NIM model (Lacroix et al., 2006) as our start-                         Information Processing Systems.
ing point, we developed NIMBLE, a biologically-inspired,                 Nelson, J., & Cottrell, G. (2007). A probabilistic model of eye
saccade-based Bayesian model of face and object recogni-                         movements in concept formation. Neurocomputing.
tion. We have demonstrated that NIMBLE performance is                    Nene, S., Nayar, S. K., & Murase, H. (1996). Columbia
comparable to human performance on a standard recogni-                           object image library (coil-100) (Tech. Rep.).
tion memory task and that this biologically-inspired model               Nosofsky, R., & Palmeri, T. (1997). An exemplar-based ran-
approaches the best machine vision results. In addition, the                     dom walk model of speeded classification. Psycholog-
online version of NIMBLE demonstrates that, like humans,                         ical Review, 104, 2, 266-300.
our system can achieve correct identification and recognition            Palmeri, T., & Gauthier, I. (2004). Visual object understand-
of faces and objects after a very small number of fixations.                     ing. Nature Reviews Neuroscience, 5, 291-303.
   We plan to integrate top-down feedback into the system                Phillips, J., Wechsler, H., Huang, J., & Rauss, P. (1998).
to direct fixations to sample from image locations with top-                     The feret database and evaluation procedure for face-
down interest as well as bottom-up salience. Because NIM-                        recognition algorithms. Image & Vision Computing,
BLE is a fully probabilistic model, it will be straightforward                   16, 5, 295-306.
to integrate the existing model into more complex systems.               Renninger, L., Coughlan, J., Verghese, P., & Malik, J. (2004).
                                                                                 An information maximization model of eye move-
                    Acknowledgements                                             ments. Neural Information Processing Systems.
This work is supported by NIMH grant MH57075 to GWC.                     Wolfe, J. (1994). Guided search 2.0: A revised model of
                                                                                 visual search. Psychonomic Bulletin & Review, 1, 2,
                          References                                             202-238.
Belongie, S., Malik, J., & Puzicha, J. (2002). Shape matching            Yamada, K., & Cottrell, G. (1995). A model of scan paths
        and object recognition using shape contexts. Pattern                     applied to face recognition. Proc. of the 17th Annual
        Analysis and Machine Intelligence, 24-4, 509-522.                        Cognitive Science Conference 55-60.
Bishop, C. (1995). Neural networks for pattern recognition.              Yarbus, A. (1967). Eye movements and vision. Plenum Press,
        Oxford University Press.                                                 New York.
Dailey, M., Cottrell, G., & Busey, T. (1998). Facial memory is           Zelinsky, G., Zhang, W., B. Yu, X. C., & Samaras, D. (2005).
        kernel density estimation (almost). Neural Information                   The role of top-down and bottom-up processes in guid-
        Processing Systems.                                                      ing eye movements during visual search. Neural Infor-
Dailey, M., Cottrell, G., Padgett, C., & Adolphs, R. (2002).                     mation Processing Systems.
        Empath: a neural network that categorizes facial ex-
                                                                      82

