UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Links Between Implicit Learning of Sequential Patterns and Spoken Language Processing

Permalink
https://escholarship.org/uc/item/4x895491

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)

Authors
Conway, Christopher M.
Pisoni, David B.

Publication Date
2007-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Links Between Implicit Learning of Sequential Patterns
and Spoken Language Processing
Christopher M. Conway (cmconway@indiana.edu)
David B. Pisoni (pisoni@indiana.edu)
Department of Psychological & Brain Sciences, 1101 E. 10th Street
Bloomington, IN 47405 USA
Abstract

the perception of spoken materials in noise; the more
predictable a sentence is, the easier it is to perceive it
(Kalikow et al., 1977). Therefore, the ability to extract
probabilistic or statistical patterns in the speech stream may
be a factor that is important for language learning and
spoken language processing: the better able one is at
implicitly learning the sequential patterns in language, the
better one should be at processing upcoming spoken
materials in an utterance, especially under highly degraded
listening conditions.
In this paper, we examine the hypothesis that a domaingeneral ability to implicitly encode complex sequential
patterns underlies aspects of spoken language processing.
This kind of incidental, probabilistic sequence learning has
been investigated in some depth over the last few years
under the rubrics of “implicit”, “procedural”, or “statistical”
learning (Cleeremans, Destrebecqz, & Boyer, 1998;
Conway & Christiansen, 2006; Saffran, Aslin, & Newport,
1996; Stadler & Frensch, 1998). To help elucidate the link
between implicit learning and language processing, we used
a new experimental methodology that was developed to
assess sequence memory and learning based on Milton
Bradley’s Simon memory game (e.g., Pisoni & Cleary,
2004). In this task, participants see sequences of colored
lights and/or sounds and are required to simply reproduce
each sequence by pressing colored response panels in
correct order.
Not only can the Simon memory game task be used to
assess learning and memory of fixed sequences, but it can
also be used to measure implicit sequence learning of more
complex rule-governed or probabilistic patterns (Karpicke
& Pisoni, 2004). In the present experiment, we used a
version of the Simon memory game that incorporates visualonly stimuli that contained structural regularities, and
correlated participants’ performance on the implicit learning
task with their ability to perceive spoken sentences that
varied in terms of the final word’s predictability, under
degraded listening conditions. Before describing the study
in full, we first briefly review previous evidence related to
implicit learning and language processing.

Spoken language consists of a complex, time-varying signal
that contains sequential patterns that can be described in
terms of statistical relations among language units. Previous
research has suggested that a domain-general ability to learn
structured sequential patterns may underlie language
acquisition. To test this prediction, we examined the extent to
which implicit sequence learning of probabilisticallystructured patterns in normal-hearing adults is correlated with
performance on a spoken sentence perception task under
degraded listening conditions. Our data revealed that
performance on the sentence perception task correlated with
implicit sequence learning, but only when the sequences were
composed of stimuli that were easy to encode verbally. The
evidence is consistent with the hypothesis that implicit
learning of phonological sequences is an important cognitive
ability that contributes to spoken language processing
abilities.
Keywords: Implicit learning, artificial grammar learning,
sequence learning, speech perception, language.

Introduction
It has long been recognized that language comprehension
involves the coding and manipulation of sequential patterns
(Lashley, 1951; see also Conway & Christiansen, 2001).
Spoken language can be thought of as patterns of sound
symbols occurring in a sequential stream. Many of the
sequential patterns of language are fixed, that is, they occur
in a consistent, regular order (e.g., words are fixed
sequences of phonemes). Thus, being able to encode and
store in memory fixed sequences of sounds would appear to
be a key aspect of language learning. Empirical work with
normal-hearing adults and children supports this view,
showing a strong link between sequence memory, word
learning, and vocabulary development (for a review, see
Baddeley, 2003).
Although short-term verbal memory is undoubtedly
important for learning fixed sequences in language, such as
words or idioms, the learning of more complex, highly
variable patterns in language may require a different kind of
cognitive mechanism altogether (Conway & Christiansen,
2001). For instance, in addition to fixed sequential patterns
of sounds, spoken language also contains sequences that can
be described in terms of complex statistical relations among
language units. Rarely is a spoken utterance perfectly
predictable; most often, the next word in a sentence can only
be partially predicted based on the preceding context
(Rubenstein, 1973). It is known that sensitivity to such
probabilistic information in the speech stream can improve

Implicit Sequence Learning and Language
Implicit learning involves automatic, unconscious
learning mechanisms that extract regularities and patterns
that are present across a set of exemplars, typically without
direct awareness of what has been learned. Many
researchers believe that implicit learning is one of the

191

primary mechanisms through which children learn language
(Cleeremans et al., 1998; Conway & Christiansen, 2001;
Dominey, Hoen, Blanc, & Lelekov-Boissard, 2003; Ulman,
2004): language acquisition, like implicit learning, also
involves the incidental, unconscious learning of complex
sequential patterns. This perspective on language
development is supported by recent findings showing that
infants engage implicit learning processes to extract the
underlying statistical patterns in language-like stimuli
(Gómez & Gerken, 2000; Saffran et al., 1996).
Although it is a common assumption that implicit learning
is important for language processing, the evidence directly
linking the two processes is mixed. One approach is to
assess language-impaired individuals on a putatively nonlinguistic implicit learning task; if the group shows a deficit
on the implicit learning task, this result is taken as support
for a close link between the two cognitive processes. Using
this approach, some researchers have found an implicit
sequence learning deficit in dyslexics (Howard, Howard,
Japikse, & Eden, 2006; Menghini, Hagberg, Caltagirone,
Petrosini, & Vicari, 2006; Vicari, Marotta, Menghini,
Molinari, & Petrosini, 2003) while others have found no
connection between implicit learning, reading abilities, and
dyslexia (Kelly, Griffiths, & Frith, 2002; Rüsseler, Gerth, &
Münte, 2006; Waber et al., 2003). At least with regard to
reading and dyslexia, the role of implicit learning is not
clear (also see Grunow, Spaulding, Gómez, & Plante, 2006).
One complication with establishing an empirical link
between implicit learning and language processing is that
implicit learning itself may involve multiple subsystems that
each handle different types of input (e.g., Conway &
Christiansen, 2006; Goschke, Friederici, Kotz, & van
Kampen, 2001). For instance, Conway and Christiansen
(2006) used a novel modification of the artificial grammar
learning paradigm (Reber, 1967), with participants exposed
to sequential patterns from two grammars interleaved with
one another. Participants learned both grammars well when
the stimuli were in two different sense modalities (vision
and audition) or were in two different perceptual dimensions
within the same sense modality (colors and shapes or tones
and nonsense words). However, when the grammars were
instantiated using the same perceptual dimension (two sets
of shapes or two sets of nonsense words), participants
demonstrated much worse implicit learning performance.
These results suggest the possible existence of multiple
learning mechanisms that operate in parallel, each over a
specific kind of input (tones, speech-like material, shapes,
etc.).
A similar conclusion was reached by Goschke et al.
(2001). They found that aphasics were impaired on the
learning of phoneme sequences but not visual sequences,
suggesting the involvement of dissociable domain-specific
learning systems. The existence of multiple implicit learning
systems may help explain why some studies have
demonstrated a link between implicit learning and language
and other studies have not: some implicit learning systems
(e.g., perhaps those handling phonological patterns) may be

more closely involved with language acquisition and
processing than others.
The empirical study described below was designed to
elucidate some of the complex issues regarding the nature of
implicit sequence learning and its involvement in spoken
language processing. In the present experiment, we used
two versions of the Simon game task – one using color
patterns and the other using non-color spatial patterns -- in
order to examine possible differences in visual stimuli that
can be easily or not easily encoded verbally. We also used a
spoken language task under degraded listening conditions.
In this way, we were able to assess whether implicit
sequence learning that is or is not phonologically-mediated
is correlated with spoken language perception under
degraded listening conditions. Our hypothesis was that
performance on the Simon implicit sequence learning task
would be significantly and strongly correlated with
performance on the spoken sentence perception task, but
only when the Simon task uses stimuli that are easy to
encode verbally.

Method
Participants
Twenty undergraduate students (age 18-36 years old) at
Indiana University received either monetary compensation
or course credit for their participation. All subjects were
native speakers of English and reported no history of a
hearing loss or speech impairment.

Apparatus
A Magic Touch® touch-sensitive monitor displayed visual
sequences for the two implicit learning tasks and recorded
participant responses.

Stimulus Materials
Spoken sentence perception task For the language
perception task, we used English “SPIN” sentences created
by Kalikow et al. (1977) and subsequently modified by
Clopper and Pisoni (2006). The sentences varied in terms of
the final word’s predictability. Three types of sentences
were used, 25 of each type: high-predictability (HP), lowpredictability (LP), and anomalous (AN). All sentences
were 5 to 8 words in length and were balanced in terms of
phoneme frequency. HP sentences have a final target word
that is predictable given the semantic context of the sentence
(e.g., “Her entry should win first prize”); LP sentences have
a target word that is not predictable given the semantic
context of the sentence (e.g., “The man spoke about the
clue”). On the other hand, AN sentences follow the same
syntactic form and use the same carefully constructed set of
phonetically balanced words as the HP and LP sentences,
but the content words have been placed randomly (e.g.,
“The coat is talking about six frogs”).
All 75 sentences were spoken by a single male speaker, a
life-time resident of the “midland” region of the United
States, whose spoken recordings were chosen from amongst

192

a set of recordings taken from multiple speakers developed
as part of the “Nationwide Speech Project” (see Clopper &
Pisoni, 2006). The sentences were then degraded by
processing
them
with
a
sinewave
vocoder
(www.tigerspeech.com) that simulates listening conditions
for a user of a cochlear implant with 6 spectral channels. All
sentences were leveled at 64 dB RMS.

engaged in each of these three tasks varied according to
random assignment, but in all cases the SSP task always
occurred as the middle of the three tasks.
Spoken sentence perception task In the SSP task,
participants were told they would listen to sentences that
were distorted by a computer, making them difficult to
perceive. Their task was to identify the last word in each
sentence and write the word down on a sheet of paper
provided to them. Sentences were presented over
headphones using a self-paced format. The 75 sentences
described above were presented in a different random order
for each subject. A written response was scored as correct if
the written word matched the intended spoken target word;
misspellings (e.g., “valt” instead of “vault”) were counted as
correct responses.

Implicit sequence learning tasks For the sequence learning
tasks, we used three different artificial grammars to generate
the sequences. Grammar A was taken from Karpicke and
Pisoni (2004) while Grammars B and C were from
Knowlton and Squire (1996). An artificial grammar is a
Markovian finite-state machine that consists of a series of
nodes connected by various transitions (see Figure 1). The
grammars can generate sequences of various lengths that
obey certain rules that specify the order that sequence
elements can occur. To use the grammar to generate a
sequence, one begins at the arrow marked “start”, and
traverses through the various states to determine the
elements of the sequence, until reaching the “end” arrow.
For example, by passing through the nodes S1, S2, S5, S7,
S10, Grammar A generates the sequence: 3-4-3-1.

Implicit sequence learning tasks For the two sequence
learning tasks, Color-Seq and Non-Color-Seq, we used a
touchscreen version of the Simon game device. Participants
were told that they would see visual sequences on the
computer screen and then after each one, they were required
to reproduce what they saw using the response panels on the
touch screen. Unbeknownst to participants, the sequences
were generated according to one of the three artificial
grammars previously described. Each sequence learning
task consisted of two parts, a Learning Phase and a Test
Phase. The procedures for both phases were identical and in
fact from the perspective of the subject, there was no
indication of separate phases at all. The only difference
between the two phases was which sequences were used. In
the Learning Phase, the 22 Learning Sequences were
presented randomly, two times each. After completing the
sequence reproduction task for all of the learning sequences,
the experiment seamlessly transitioned to the Test Phase,
which used the 20 novel grammatical (G) and 20
ungrammatical (U) Test Sequences.
Sequence presentation consisted of colored (for ColorSeq) or black (for Non-Color-Seq) squares appearing one at
a time, in one of four possible positions on the screen (upper
left, upper right, lower left, lower right). Each square
appeared on the screen for a duration of 700 msec, with a
500 msec ISI. For Color-Seq, the four elements (1-4) of
each grammar were randomly mapped onto each of the four
screen locations as well as four possible colors (red, blue,
yellow, green). The assignment of grammar element to
position/color was randomly determined for each subject;
however, for each subject, the mapping remained consistent
across all trials. Likewise, for Non-Color-Seq, the four
elements of each grammar were mapped onto each of the
four screen locations, randomly determined for each subject.
The spatial mapping in this condition also remained
invariant for a given subject.
After an element appeared for 700 msec, the screen was
blank for 500 msec, and then the next element of the
sequence appeared. After the entire sequence had been
presented, there was a 2000 msec delay and then five panels
appeared on the touch screen. Four of those panels were the

Figure 1: One of three artificial grammars used to generate
sequences for the implicit learning tasks.
We used each grammar to generate 22 unique exemplars
(2 exemplars of length 3, and 4 exemplars each of lengths 48) that were used for the Learning Phase of the task. Twenty
additional exemplars were also generated by each grammar
(4 exemplars each of lengths 4-8), for use in the Test Phase.
Twenty ungrammatical sequences were also generated for
the Test Phase. Ungrammatical sequences were created by
taking each grammatical sequence and randomly shuffling
the elements that comprise it. For example, the
ungrammatical sequence 2-2-3-3 is a randomized version of
the Grammar A grammatical sequence 3-2-2-3. Using this
method, ungrammatical sequences differ from grammatical
sequences only in terms of the order of elements within a
sequence, not in terms of the actual elements themselves.

Procedure
All participants engaged in three tasks: a spoken sentence
perception (SSP) task which occurred under degraded
listening conditions; and two visual sequence learning tasks,
“Colored-Sequence” (Color-Seq) and “Non-ColoredSequence” (Non-Color-Seq). The order that participants

193

same-sized and same-colored as the four locations that were
used to display each sequence. The squares were
appropriately colored (red, green, blue, and yellow for
Color-Seq and all black for Non-Color-Seq). The fifth panel
was a long horizontal bar placed at the bottom of the screen,
which acted as the equivalent of the “Enter” button. The
subject’s task was to watch a sequence presentation and then
to reproduce the sequence they saw by pressing the
appropriate buttons in the correct order as dictated by the
sequence. When they were finished with their response, they
were instructed to press the long black bar at the bottom,
and then the next sequence was presented after a 2-sec
delay.
Participants were not told that there was an underlying
grammar for any of the Learning or Test sequences, nor that
there were two 2 types of sequences in the Test phase. From
the standpoint of the participant, the task in Color-Seq and
Non-Color-Seq was solely one of observing and then
reproducing a series of unrelated sequences.
Finally, following the experiment, all participants filled
out a debrief form that asked whether they used a verbal
strategy when doing the Non-Color-Seq task, such as
verbally coding the four different locations in terms of
numbers “one”, “two”, etc.

Table 1: Weighted span scores for grammatical (G) and
ungrammatical (U) sequences, as well as the difference
between the two (LRN)

Sequence Task
Color-Seq
Non-Color-Seq

Sequence Type
G
U
LRN
M
SE
M
SE M
SE
64.9

5.13

56.4

5.77

8.55

4.62

55.3

5.70

43.9

4.35

11.5

3.08

For each subject, we also calculated the difference
between G and U on each task, which served as a measure
of sequence learning (LRN; see Table 1). To confirm that
learning occurred in both tasks, we compared the LRN
scores to chance levels using one-tailed t-tests. Both
comparisons were statistically significant [Color-Seq: t(19)
= 1.85, p < .05; Non-Color-Seq: t(19) = 3.72, p < .001],
indicating that participants in both tasks on average showed
implicit learning for the grammatical regularities of the
sequences, demonstrated by having better memory spans for
test sequences that were consistent with the grammars used
during the learning phase. Finally, we compared the two
LRN scores between tasks and found no differences
between them, t(19) = .60, p = .56.
We next investigated the size of the learning effect for
individual subjects. Although on average, subjects showed a
learning effect, there was wide variation in LRN scores
across these two tasks (Seq-Color: -18 to 71; Non-ColorSeq: -14 to 33). Because of the variability in the scores, it is
possible to determine to what extent individual differences
in implicit learning abilities for sequential patterns
correlates with spoken sentence perception under degraded
listening conditions.
To assess the relations between implicit sequence learning
and spoken language perception, we computed correlations
among the following dependent measures: HP, LP, AN,
Color-Seq grammatical (C-G), Color-Seq ungrammatical
(C-U), Color-Seq LRN (C-LRN), Non-Color-Seq
grammatical (NC-G), Non-Color-Seq ungrammatical (NCU), and Non-Color-Seq LRN (NC-LRN). If probabilistic
sequence learning is an important underlying source of
variance that contributes to spoken language perception, we
would expect that the LRN scores will be strongly
correlated with the spoken sentence perception scores.
The correlation analyses, shown in Table 2, revealed
several interesting patterns. None of the G and U scores
correlated significantly with the SSP scores. However, as
expected, the LRN scores, which measure implicit learning
of the underlying sequence patterns, revealed a different
pattern altogether. The results showed that LRN for ColorSeq correlated significantly with HP (r = .48, p < .05) and
LP (r = .56, p < .01) but not with AN (r = .36, p = .12),
whereas LRN for Non-Color-Seq did not correlate
significantly with any of the SSP measures (r’s < .38).

Results
For the SSP task, subjects accurately perceived target words
in HP sentences (M=18.2) significantly more often than LP
or AN sentences (M=12.9 and 13.3, respectively): HP vs.
LP, t(19) = 10.8, p < .001; HP vs. AN, t(19) = 7.1, p < .001.
For Color-Seq and Non-Color-Seq, a sequence was scored
correct if the participant correctly reproduced the sequence
in its entirety. Span scores were calculated using a weighted
method, in which the total number of correct sequences at a
given length was multiplied by the length, and then scores
for all lengths added together. We calculated separate span
scores for grammatical and ungrammatical test sequences
for each subject. Performance on the two sequence learning
tasks are shown in Table 1, which depicts weighted span
scores for grammatical (G) and ungrammatical (U)
sequences.
A 2x2 ANOVA contrasting Task (Color-Seq vs. NonColor-Seq) and Sequence Type (grammatical vs.
ungrammatical) revealed a main effect of Task [F(1, 76) =
4.4, p < .05] and a marginal main effect of Sequence Type
[F(1, 76) = 3.6, p = .061] and no significant interaction.
These results indicate that overall, participants span scores
were better for the Color-Seq task, which is not surprising
considering that the Color-Seq task has an extra cue (color)
over and beyond the spatio-temporal cues available in the
Non-Color-Seq task. The marginal effect of Sequence Type
indicates that participants had higher span scores for the
grammatical sequences and thus suggests that overall,
participants showed implicit learning of the underlying
grammatical regularities in the sequence patterns.

194

Moreover, neither of the two LRN scores correlated
significantly with one another (r = .26, p = .28)1.
Additionally, we ran a principal component analysis
(PCA) on all nine measures to reduce the data set to a
smaller set of components. The results of the analysis
revealed two components that explained 69% of the total
variance. Interestingly, the second component (31.4% of
total variance) includes HP, LP, and Color-Seq LRN,
whereas the first component (37.6% of total variance)
includes the six other DV’s.

sequence learning and language tasks involved stimuli in
two different sensory modalities (vision and audition,
respectively).
A few observations are important to highlight. First,
performance on the SSP task was not correlated with span
scores for G or U sequences. That is, the contribution to
language processing that we have demonstrated is not due
merely to serial recall abilities. It was only when we
assessed how much memory span improved for
grammatically-consistent sequences did we find a
significant correlation. Thus, it is the ability to extract
knowledge about structured sequential patterns over a set of
sequences that is important, not just the ability to encode
and recall a sequence of items from memory.
A second point to make is that the Color-Seq task
correlated much more strongly with the high (HP) and low
(LP) predictable sentences compared to the anomalous (AN)
sentences. To do the HP (and to a lesser extent, LP)
sentence perception tasks successfully, the listener needs to
use the context of the preceding material in the sentences to
help predict and identify the final target word. This
sequential context is not available for the AN sentences
because they were semantically anomalous. In turn,
successful performance on the Color-Seq task also requires
sensitivity to sequential, probabilistic context. That is, the
greater one’s sensitivity to sequential structure in the
grammatical sequences, the better chance one has of
correctly recalling a novel grammatical sequence that
contains the same kind of probabilistic structure. Thus, we
believe we have identified a key link between implicit
sequence learning and spoken language perception: both
require the ability to acquire and use probabilistic
information distributed across temporal patterns.
Third, we note that only the Color-Seq task, not the NonColor-Seq task, was correlated with SSP. From a procedural
standpoint, the only difference between Color-Seq and NonColor-Seq was that the Color-Seq task included not only
spatiotemporal information, but also the presence of color
cues. One account of these differences is that the sequences
from the Color-Seq task are very readily verbalizable and
codable into phonological form (e.g., “Red-Blue-YellowRed”) whereas those from the Non-Color-Seq task are not.
Thus, Color-Seq but not Non-Color-Seq might involve
implicit learning of phonological representations, and it
could be this basic learning ability that contributes to
success on the SSP task.
To examine this prediction further, we used the postexperiment debriefing questionnaire to identify 12
participants (“phonological coders”) who attempted to
encode sequences in the Non-Color-Seq task using some
kind of verbal code, such as labeling each of the four spatial
positions with a digit (1-4). The remaining 8 subjects (“nonphonological-coders”) indicated they did not use a verbal
code during the task. We assessed correlations between
these two groups’ LRN scores and SSP measures and found
that although none of the correlations quite reached
statistical significance (presumably due to a lack of

Table 2: Correlations between dependent measures for the
sentence processing and implicit sequence learning tasks
(see above text for abbreviations). Significant correlations at
p < .05 are in bold; those at p < .01 are also underlined.
Measure

1

2

3

4

5

6

7

8

9

1.HP
2.LP
3.AN
4.C-G
5.C-U
6.C-LRN
7.NC-G
8.NC-U
9.NC-LRN

--

.83
--

.60
.39
--

.26
.29
.37
--

-.2
-.2
.01
.65
--

.48
.56
.36
.30
-.5
--

.01
.03
.30
.61
.52
.03
--

-.2
-.2
.13
.42
.49
-.1
.85
--

.33
.28
.38
.53
.27
.26
.66
.15
--

In sum, the results can be summarized as follows. First,
participants on average showed implicit learning in both the
Color-Seq and Non-Color-Seq task, as demonstrated by the
LRN scores being statistically greater than zero. Second,
only LRN for Color-Seq, but not Non-Color Seq, was
significantly correlated with the high (HP) and low
probability (LP) sentences in the SSP task; neither LRN
socres were correlated with the anomalous (AN) sentences.
Finally, a PCA analysis showed that HP, LP, and LRN for
Color-Seq all loaded on a common component. These data
suggest a strong link between visual implicit sequence
learning and spoken language processing abilities.

Discussion
Our hypothesis was that participants’ abilities on a visual,
implicit sequence learning task, especially one that
incorporated stimuli that could be easily encoded verbally,
would be correlated with their performance on a spoken
sentence perception task under degraded listening
conditions. Building on previous empirical and theoretical
work suggesting that spoken language processing depends
upon domain-general implicit sequential learning skills, our
results provide the first empirical demonstration of
individual variability in implicit learning performance
correlating with language processing in typically-developing
subjects. The results are particularly striking given that the
1

With a sample size of n=20, there is only enough power to
identify “large” correlation/effect sizes (Cohen, 1988); thus, a nonsignificant correlation in this data may not signify no correlation at
all, but it does suggest that if a correlation exists, it is substantially
weaker than the significant effects reported here.

195

statistical power), the difference in the correlations between
the two groups was quite striking: phonological coders’
performance on the sequence task correlated with HP (r =
.43), LP (r = .28), and AN (r = .44) whereas the correlations
for non-coders were r = -.31 for HP, r = -.17 for LP, and r =
.14 for AN.
Thus, for those participants who explicitly used a
phonological-coding strategy on the Non-Color-Seq task,
their performance was positively correlated with SSP task
performance, whereas for participants who did not use such
a strategy, their performance was much less or even
negatively correlated with SSP task performance. Although
statistically non-significant at this time, this pattern of
results for the Non-Color-Seq task may suggest that a
crucial aspect of implicit sequence learning that contributes
to spoken language processing is the learning of structured
patterns from sequences that can be easily represented using
a verbal code.
To summarize, we believe the evidence points to an
important factor underlying spoken language processing: the
ability to implicitly learn complex sequential patterns, and
perhaps especially those that can be represented
phonologically. Using a visual implicit sequence learning
task, we found that sequence learning performance
correlated with performance on a spoken sentence
perception task requiring one to capitalize on sequential
context. These results suggest a strong link between implicit
sequence learning and spoken language processing and not
only provide important new theoretical insights, but also
have practical implications regarding the nature of language
processing in both typical and clinical populations.

Gómez, R.L. & Gerken, L.A. (2000). Infant artificial language
learning and language acquisition. Trends in Cognitive Sciences,
4, 178-186.
Goschke, T., Friederici, A. D., Kotz, S. A., & van Kampen, A.
(2001). Procedural learning in broca's aphasia: Dissociation
between the implicit acquisition of spatio-motor and phoneme
sequences. Journal of Cognitive Neuroscience, 13(3), 370-388.
Grunow, H., Spaulding, T.J., Gómez, R.L., & Plante, E. (2006).
The effects of variation on learning word order rules by adults
with and without language-based learning disabilities. Journal of
Communication Disorders, 39, 158-170.
Howard, J.H., Jr., Howard, D.V., Japikse, K.C., & Eden, G.F.
(2006). Dyslexics are impaired on implicit higher-order
sequence learning, but not on implicit spatial context learning.
Neuropsychologia, 44, 1131-1144.
Kalikow, D.N., Stevens, K.N., & Elliott, L.L. (1977). Development
of a test of speech intelligibility in noise using sentence
materials with controlled word predictability. Journal of the
Acoustical Society of America, 61, 1337-1351.
Karpicke, J. D., & Pisoni, D. B. (2004). Using immediate memory
span to measure implicit learning. Memory & Cognition, 32(6),
956-964.
Kelly, S.W., Griffiths, S., & Frith, U. (2002). Evidence for implicit
sequence learning in dyslexia. Dyslexia, 8, 43-52.
Knowlton, B.J. & Squire, L.R. (1996). Artificial grammar learning
depends on implicit acquisition of both abstract and exemplarspecific information. Journal of Experimental Psychology:
Learning, Memory, & Cognition, 22, 169-181.
Lashley, K.S. (1951). The problem of serial order in behavior. In
L.A. Jeffress (Ed.), Cerebral mechanisms in behavior (pp. 112146). New York: Wiley.
Menghini, D., Hagberg, G.E., Caltagirone, C., Petrosini, L., &
Vicari, S. (2006). Implicit learning deficits in dyslexic adults:
An fMRI study. Neuroimage, 33, 1218-1226.
Pisoni, D.B. & Cleary, M. (2004). Learning, memory, and
cognitive processes in deaf children following cochlear
implantation. In F.G. Zeng, A.N. Popper & R.R. Fay (Eds.),
Springer handbook of auditory research: Auditory prosthesis,
SHAR Volume X (pp. 377-426).
Reber, A.S. (1967). Implicit learning of artificial grammars.
Journal of Verbal Learning and Behavior, 6, 855-863.
Rubenstein, H. (1973). Language and probability. In G.A. Miller
(Ed.), Communication, language, and meaning: Psychological
perspectives (pp. 185-195). New York: Basic Books, Inc.
Rüsseler, J., Gerth, I., & Münte, T.F. (2006). Implicit learning is
instact in developmental dyslexic readers: Evidence from the
serial reaction time task and artificial grammar learning. Journal
of Clinical and Experimental Neuropsychology, 28, 808-827.
Saffran, J.R., Aslin, R.N., & Newport, E.L. (1996). Statistical
learning by 8-month-old infants. Science, 274, 1926-1928.
Stadler, M.A. & Frensch, P.A. (Eds.) (1998). The handbook of
implicit learning. London: Sage Publications.
Ullman, M. T. (2004). Contributions of memory circuits to
language: The declarative/procedural model. Cognition, 92, 231270.
Vicari, , S., Marotta, , L., Menghini, D., Molinari, M., & Petrosini,
L. (2003). Implicit learning deficit in children with
developmental dyslexia. Neuropsychologia, 41, 108-114.
Waber, D. P., Marcus, D. J., Forbes, P. W., Bellinger, D. C.,
Weiler, M. D., Sorensen, L. G., et al. (2003). Motor sequence
learning and reading ability: Is poor reading associated with
sequencing deficits? Journal of Experimental Child Psychology,
84, 338-354.

Acknowledgments
We wish to thank Luis Hernandez and Jennifer Karpicke for
their invaluable assistance on this project. This work was
supported by NIH DC00012.

References
Baddeley, A.D. (2003). Working memory and language: An
overview. Journal of Communication Disorders, 36, 189-208.
Cleeremans, A., Destrebecqz, A., & Boyer, M. (1998). Implicit
learning: News from the front. Trends in Cognitive Sciences, 2,
406-416.
Clopper, C.G. & Pisoni, D.B. (2006). The Nationwide Speech
Project: A new corpus of American English dialects. Speech
Communication, 48, 633-644.
Cohen, J. (1988). Statistical power analysis for the behavioral
sciences. Hillsdale, NJ: Erlbaum.
Conway, C.M. & Christiansen, M.H. (2006). Statistical learning
within and between modalities: Pitting abstract against stimulusspecific representations. Psychological Science, 17, 905-912.
Conway, C.M., & Christiansen, M.H. (2001). Sequential learning
in non-human primates. Trends in Cognitive Sciences, 5, 529546.
Dominey, P.F., Hoen, M., Blanc, J.-M., & Lelekov-Boissard, T.
(2003). Neurological basis of language and sequential cognition:
Evidence from simulation, aphasia, and ERP studies. Brain and
Language, 86, 207-225.

196

