UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Seeing is Believing: Priors, Trust, and Base Rate Neglect
Permalink
https://escholarship.org/uc/item/2fn2q8fp
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Welsh, Matthew B.
Navarro, Daniel J.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

                      Seeing is Believing: Priors, Trust, and Base Rate Neglect
                                     Matthew B. Welsh (matthew.welsh@adelaide.edu.au)
                       Australian School of Petroleum, University of Adelaide, Adelaide SA 5005, Australia
                                      Daniel J. Navarro (daniel.navarro@adelaide.edu.au)
                             School of Psychology, University of Adelaide, Adelaide SA 5005, Australia
                              Abstract                                    and, secondly, that people are therefore suboptimal or bi-
                                                                          ased in their judgments, and may be taken to be acting ir-
   Tversky and Kahneman (1974) described an effect they called            rationally. Note, however, that there are two distinct claims
   `insensitivity to prior probability of outcomes', better known         here. Clearly, underweighting the base rate information will
   as base rate neglect (Bar-Hillel, 1980). This describes peo-           lead people to make judgments that differ from those pro-
   ple's tendency to underweight prior information in favor of
   new data. Probability theory requires these prior probabilities        vided by a simplistic application of Equation 1. However,
   to be taken into account, via Bayes' theorem, when deter-              the charge of irrationality is a stronger claim, and a more
   mining an event's posterior probability. The fact that most            questionable one.
   people fail to do so has been taken as evidence of human ir-              Traditional approaches to the study of human decision
   rationality and, by other authors, of a mismatch between our
   cognitive processes and the questions being asked (Cosmides            making have tended to assume that rational behavior is best
   & Tooby, 1996; Gigerenzer & Hoffrage, 1995). In contrast to            operationalized in terms of strict adherence to an externally-
   both views, we suggest that simplistic Bayesian updating us-           provided optimality criterion, such as expected utility. Any
   ing given base rates is not always a rational strategy. Instead,       deviations from these criteria are deemed to be irrational.
   we reconsider Bar-Hillel's original relevance theory, and ar-          However, this approach has been criticized for the assump-
   gue that, since base rates differ in their perceived degree of
   trustworthiness they are, accordingly, rationally discounted by        tion that it is always rational to conduct exhaustive calcula-
   people.                                                                tions, rather than to make a far swifter decision that leads
   Keywords: base rate neglect; Bayesian updating; cognitive              to a satisfactory outcome (Todd & Gigerenzer, 2000); and
   bias; decision-making                                                  though the critique is based on Simon's (1956) notion of
                                                                          bounded rationality, much of the framework can be recon-
                                                                          ciled very neatly with the classical Bayesian view (e.g., Lee
   In the closing remarks to A Philosophical Essay on Proba-              & Cummins, 2004). In this spirit, this paper discusses the
bilities, Laplace (1814/1951) argues that \the theory of prob-            question of how one might appropriately weight base rates
abilities is at bottom only common sense reduced to calculus;             and novel information in order to make predictions in real
it makes us appreciate with exactitude that which exact minds             environments.
feel by a sort of instinct without being able ofttimes to give a
reason for it". Using probability theory, Bayes' rule provides
the mechanism by which a set of prior beliefs can be updated
                                                                                   The Existence of Base Rate Neglect
in light of evidence, as follows: given a hypothesis, h, which            The research on base rate neglect is heavily polarized. The
we believe has some prior probability of being correct p(h),              `heuristics and biases' school of thought argues that base
if we then observed some data, x, Bayes' theorem tells us                 rate neglect is robust { resulting from people's inability to
how to find p(h|x), the posterior probability that h is true              update in a Bayesian manner (Kahneman & Tversky, 1996)
given that we have now seen x.                                            { while their opponents argue that the effect disappears un-
                                                                          der experimental conditions better suited to human cognition
                    p(h|x) = p(x|h)p(h)/p(x)                      (1)     (Cosmides & Tooby, 1996; Gigerenzer, 1996). In particular,
                                                                          it is suggested that questions phrased in a frequency format
As to whether Laplace's claim provides a plausible account                rather than in terms of probabilities are more easily dealt
of human reasoning, one of the principal sources of dis-                  with by people and thus less susceptible to base rate neglect.
cussion is base rate neglect, a phenomenon that seems to                  The reasoning behind this argument is the claim that fre-
contradict the assertion that analytic probabilities are merely           quencies of events are easily observed whereas the probabil-
formalized versions of people's intuitions about chance. The              ity of a single event is intrinsically unobservable (Cosmides
general finding is that, when people are provided with prior              & Tooby, 1996). Thus people would be expected to have
information (in the form of a base rate) along with new ev-               cognitive abilities suited to counting events and comparing
idence, they typically weight the evidence provided by data               these absolute frequencies rather than determining one-off
far more heavily than the base rates (Tversky & Kahneman,                 probabilities.
1974). This tendency to downgrade the value of the prior rel-                Initial support for this was found by a number of re-
ative to the likelihood is taken to imply that: firstly, Bayes'           searchers (Cosmides & Tooby, 1996; Gigerenzer & Hoffrage,
theorem does not provide a complete account of the rea-                   1995) but subsequent research has found that relative fre-
soning employed by people (Villejoubert & Mandel, 2002);                  quencies, such as percentages, give an equal or greater reduc-
                                                                      701

tion in base rate neglect (Harries & Harvey, 2000; Sloman,          Rationally, however, you are aware that there is such a thing
Over, Slovak, & Stibel, 2003). Sloman et al. further argue          as regional variation and that your observations from Europe
that, rather than a difference in the underlying cognition, the     are less likely to be predictive in Australia. Accordingly, a
effect described by earlier work results from nesting proba-        belief in regional variation provides a strong justification for
bilities to make it clear to participants which values need to      a decision to neglect the base rate.
be compared and that the same benefit can be achieved in               When deciding how much faith to place in a base rate, at
probability formats if the data are presented equivalently.         least four environmental factors would appear to be relevant.
   Even accepting that the method works, however, base rate         • Location. Even if you genuinely believed that 99.9%
neglect is generally reduced by using frequency formats, not           was the true, world-wide base rate of white swans, the
eliminated. Even where people are given direct experience              existence of regional variations implies that the single
of a sample, rather than merely summary statistics, base rate          black swan observed in Australia should be more highly
neglect persists (e.g., Goodie & Fantino, 1999; Gluck &                weighted. Therefore, when changing from one location to
Bower 1988) and an analogous effect has been observed in               another, a rational person will discount prior observations
pigeons (Zentall & Clement, 2002), suggesting that the effect          against current ones { that is, they will neglect the base
is not simply an artifact of experimental design.                      rate in favor of new data.
                   Unstable Base Rates                              • Age. Old data are less likely to be relevant to a new pre-
In some respects, this debate seems somewhat confusing.                diction than more current data as base rates change over
As the proponents of bounded rationality, Gigerenzer and               time. Consider, for example, the proportion of land preda-
Todd (1999; Todd & Gigerenzer, 2003) have argued that we               tors that are dinosaurs. If you were relying on base rates
should seek to understand cognitive processes in light of the          incorporating data from the last 170 million years, you
environments in which they are designed to operate. Given              might predict a fairly high proportion of observations. A
the preponderance of data illustrating the robustness of the           more current analysis, however, would yield a lower fig-
effect (e.g., Kahneman & Tversky, 1996), rather than attempt           ure. While this is a deliberately extreme example, this
to force the effect to disappear, it seems more productive             \information aging" effect is observed in library curves
to consider the ecological reasons that might suggest that             that track the frequency with which books are borrowed
neglecting base rates is the right thing to do.                        as a function of age, which have a similar shape to human
   The tendency within the literature has been to treat base           forgetting curves, suggesting that disregarding old infor-
rates as eternal and unchanging truths given unto people and           mation is a rational adaptation to changing environments
which, therefore, it is irrational to ignore. This is not, how-        (Anderson & Schooler, 1991).
ever, generally the case. The value of base rate data is lim-       • Source. In general, people trust the evidence of their own
ited, or bounded, in a number of important ways. Goodie                senses to a greater extent than they do that of another
and Fantino (1999) touch on this, arguing that people need             person. Thus, a sample that a person has collected them-
to be sensitive not just to base rates but also to the how base        selves is likely to be weighted more heavily than data
rates change. In the classic \taxicab" problem they argue that         given to that same person from an outside source. This
the base rates given for taxicab colors and eyewitness relia-          is, of course, quite rational in that, with outside data, the
bility are specific to one place at one time and thus subject          degree of certainty over its veracity and how it was col-
to change. Indeed, in advocating a relevance-based account             lected will tend to be lower than that regarding one's own
for the base rate neglect effect, Bar-Hillel (1980) examined           observations.
variants of the taxicab problem in which the source of infor-
mation for the base rate is varied, and notes corresponding         • Quantity. Sample size must also be considered for both
effects on the strength of the phenomenon.                             the prior and current samples. The former is often ignored
   In this paper, we expand on the perceived-relevance view            in base rate neglect experiments but must be considered
of base rate neglect. Our approach can be motivated by con-            as sample size partially determines a base rate's reliabil-
sidering the following example, adapted from one commonly              ity. Empirically, a \base rate" can only be discovered via
used by philosophers and originating in the work of David              observation: in the real world, base rates are simply prior
Hume (1739/1898).                                                      samples. As a consequence, the decision-maker should
                                                                       consider how much data contributes to the base rate itself.
   Imagine that you have been calculating the proportion
   (base rate) of white swans amongst the general swan                                     Experiment 1
   population. You have been across Europe and observed             As an initial examination, we consider the impact of varying
   999 swans { all of which were white. You then take a             the location, age, source and quantity of the data that pro-
   plane to Australia and continue your survey. Your first          vides a base rate. The approach is similar to, but more sys-
   observation is of a black swan. You have now observed            tematic than, the variations considered by Bar-Hillel (1980).
   one thousand swans and have a base rate of 99.9% for
   white swans. As you plan to continue your survey, what           Method
   is the probability that the next swan you observe will           Participants. Participants were twenty university students
   be white?                                                        and members of the general public, 10 males and 10 females,
                                                                    with a mean age of 30.4 (SD = 12.1). Each was paid for
In a naive statistical sense, one would expect the next swan to     their participation with a $10 bookstore voucher.
be white with a 99.9% probability, as the base rate indicates.
                                                                702

Experimental Design. The scenarios used in our experi-               sample.1 So, for instance, in the example given in the method
ment were designed to maximize the extent to which people            section, the observer might specify a Beta(50,150) prior. In
recognize a need to combine two sources of information, by           general, if n0 denotes the number of observations that make
explicitly placing the base rate data on a scale commensurate        up this prior and x0 is the number of those observations
with a second source of evidence. To do so, both sources             that meet the criterion, then the prior is Beta(x0, n0 − x0 ),
of evidence are described as samples of data (prior sample           and the expected prior value for θ is given by the base rate,
and new sample) that need to be taken into account. In this          E[θ|x0, n0] = x0/n0 = r0. In the event that the new data
experiment we chose to examine the effect of varying sample          are assumed to have exactly the same distribution as the
size, while combining the source, age and location variables         prior data, then x1|n1 ∼ Binomial(θ, n1 ). Given this, the
into a general cover story. Under the \high trust" cover story,      posterior distribution over θ is Beta(x0 + x1 , n0 + n1 −
the prior sample was described as recent data, collected by          x0 − x1), and the observer would report the obvious choice,
the participant, in the same location. Under the \low trust"         E[θ|x0, x1, n0, n1] = (x0 + x1 )/(n0 + n1 ).2
cover story, the data was old, collected by someone else, and           This model assumes that the observer assigns equal weight
in a different location. Sample sizes were varied for both the       to all data. However, this is highly unlikely. Firstly, the sce-
prior data (20 or 200 data points) and for the new data (4,          narios encourage participants to assume that the prior sample
8 or 12 data points). Moreover, the implied base rate could          may be less closely related to the quantity of interest θ than
be either 25% or 75% (with the new data implying the alter-          the new data. Accordingly, if each prior datum is \worth"
nate). With all factors fully crossed, this gave 24 (2x3x2x2)        only t new data, then a natural description of the prior is
conditions in total.                                                 a Beta(tx0, tn0 − tx0).3 Updating in the usual manner, we
   All of the scenarios used variations on the same cover            might expect the participant to report the value,
story: that the participant was part of a survey team exploring
an alien planet and reporting on the proportion of some native                                                  tr0 n0 + r1n1
                                                                                 E[θ|r0, r1, n0, n1, t] =                        ,       (2)
life form or natural event that met a particular criterion. In                                                     tn0 + n1
every case, the participant was given a prior sample and then
told what they had observed. Finally they were asked for an          where r0 = x0/n0 denotes the base rate, and r1 = x1 /n1
estimate combining both sets of information to be included           denotes the sample rate. In this experiment, we vary the
in their report. For example:                                        way people weight r0 against r1 in two distinct ways. By
                                                                     altering the description applied to the prior sample, we expect
                                                                     to see a change in the value of t. This is a direct \cover
   You are currently classifying predators according to              story" manipulation, and is expected to result in some explicit
   whether they pose a threat to humans. Your team, work-            downgrading of the usefulness of prior sample.
   ing at this location recently collected 200 observations             The second manipulation involves sample size, and is
   and found that 50 (25%) of them met this criterion. This          somewhat more complex, since sample size is already built
   week, you have made another 4 observations, of which              into the naive model predictions. By altering the ratio n0/n1 ,
   3 (75%) met the above criterion. What proportion of               we would expect some reweighting of the two estimates.
   predators in the area do you estimate pose a threat to            However, in view of the widely studied \insensitivity to sam-
   humans?                                                           ple size" effect (e.g., Kahneman & Tversky, 1974), the sub-
                                                                     jective \value" of a particular sample size is unlikely to be the
This example shows a prior sample size of 200 with a base            same as its actual value. Nevertheless, following Sedlmeier
rate of 25%. The current sample has a size of 4 and a rate of        and Gigerenzer (1997), we might reasonably expect that peo-
75%. The prior is trustworthy in that it is described as recent,     ple's behavior will accord with Bernoulli's (1713) statement
local and self-collected. Twenty-four scenarios were created         of the so-called empirical law of large numbers: \even the
so each participant would see a scenario in each condition.          stupidest of men, by himself and without any instruction
                                                                     (which is a remarkable thing), is convinced that the more
Procedure. All scenarios were incorporated into a GUI and            observations have been made, the less danger there is of
presented in random order. Participants sat at the computer          wandering from one's goal" (see Stigler, 1986, p.65). For
and read the introductory cover story before proceeding to the       the moment, then, we make the assumption that the sub-
first randomly determined scenario. During each scenario, all        jective value ñ is related to the objective value n via some
of the information remained visible on the screen until the          unknown monotonic increasing function ñ = f(n). Given
participant had entered a predicted rate of future occurrence.       this, we model the participants' judgments by assuming that
No time limit was imposed and most participants completed            they will report the value of θ to be expected when one ap-
the 24 scenarios within an hour.                                     plies Bayes' theorem to the subjective sample values, with
Descriptive Model. To analyze the data, we will adopt                    1
                                                                           This is equivalent to starting with a non-informative Haldane
a heavily simplified model for how a \rational" decision-            prior over θ, assuming that x0 |n0 ∼ Binomial(θ, n0 ), and then
maker might solve this kind of induction problem. Suppose            updating belief about θ via Bayes' theorem (see Jaynes, 2003).
                                                                         2
the participant (implicitly) makes the assumption that the                 For people of a less Bayesian persuasion, it is worth noting that
                                                                     this is also equivalent to a decision-maker reporting the maximum
observed data reflect some unknown Bernoulli probability             likelihood estimate for a pooled sample.
θ, and reports the expected value for θ given the data. In               3
                                                                           The statistical model in this case involves a trivial generaliza-
this situation, a straightforward choice of prior might be a         tion of the Binomial distribution, straightforward to derive but not
Beta distribution with parameters estimated from the prior           discussed here for space considerations.
                                                                 703

some constant effect expected to arise due to the cover story:
                                                                                           75   n = 20                                  75   n = 200
                                                                                                 0                                            0
                                       tr0ñ0 + r1 ñ1
          E[θ|r0, r1, ñ0, ñ1, t] =                   .     (3)
                                         tñ0 + ñ1
                                                                          Estimated Rate                               Estimated Rate
   In order to fit the data from the 24 conditions, we fit 4                               50                                           50
values for t (high and low trust for both base rates), and 4 val-
ues for subjective sample size. Assuming that f(20) = 20,
we estimate the values for ñ that correspond to f(4), f(8),
f(12) and f(200), which are expected to be more-or-less                                    25                                           25
invariant across experimental conditions. Note that, since 8                                    4      8          12                         4      8          12
parameters are used to fit 24 data points, there is a sense                                     New Sample Size (n )
                                                                                                                 1
                                                                                                                                             New Sample Size (n )
                                                                                                                                                              1
in which this model is more descriptive than explanatory.
                                                                          Figure 1: Participants estimated rates for the various con-
However, it will transpire that f(·) has a very regular form,
allowing these parameters to be fixed in a sensible fashion,              ditions in which the base rate was 25%. Triangles denote
and leaving only the explicit trust parameter t as truly `free'.          data from conditions involving the \high trust" cover story,
                                                                          and the circles show the \low trust" condition data. The
Results                                                                   thin lines are standard error bars. The dashed lines show the
Since the simplified framework discussed here makes no pro-               predictions of the naive Bayesian model (Equation 2), while
vision for extrapolation (i.e., participants perceiving a trend),         the solid lines show the predictions made by the descriptive
only those 14 participants whose data show no evidence of                 model.
extrapolation (i.e., all 24 judgments lie in the range [25, 75])
are considered in this initial investigation. Figures 1 and 2
show the mean estimates for the underlying probability given                               75                                           75
by these participants in all 24 conditions. The triangles show
empirical data for the \high trust" cover story, and the circles
                                                                          Estimated Rate                               Estimated Rate
show data for the \low trust" cover story. The dashed line
shows the predictions made by the simplistic Bayesian solu-                                50                                           50
tion (Equation 2). Overall, there is a clear base rate neglect
effect: the empirical predictions tend to be shifted away from
the Bayesian solution towards the current rate (i.e., above it                             25   n0 = 20                                 25   n0 = 200
in Figure 1 and below it in Figure 2). In total, data for 23
of the 24 conditions are shifted in this direction (one-tailed                                  4      8          12
                                                                                                New Sample Size (n )
                                                                                                                                             4      8          12
                                                                                                                                             New Sample Size (n )
sign test gives p ≈ 1.5 × 10−6). More important, however,                                                        1                                            1
is the fact that trustworthiness is having a clear effect. In             Figure 2: Participants estimated rates for the various condi-
all 12 cases, the mean predictions made by participants in                tions in which the base rate was 75%. The format of the
high trust scenarios are closer to the Bayesian solution than             plot is the same as for Figure 1.
estimates made in otherwise equivalent low trust scenarios
(one-tailed sign test gives p ≈ 2.4 × 10−4).
   A finer grain of analysis is possible by fitting the model.            the 75% base rate and high trust is odd, since it implies that
Parameter estimates for t and ñ were obtained by minimizing              a prior subjective datum is treated as being worth more than
sum squared errors. Figure 3 shows the recovered parameter                one subjective new datum. This observation, and the fact
estimates for the subjective sample size parameters, ñ. Com-             that the corresponding empirical data for these conditions
parison with the solid line makes clear that ñ ∝ log n: in this          (solid line at the top left of Figure 2) do not show strong
task, subjective impressions of sample size rise logarithmi-              evidence of base rate neglect, suggests that this case may be
cally with the actual sample size. This logarithmic relation-             somewhat different to the others.
ship is in agreement with both the classic Weber-Fechner
law, and with other data suggesting that the mental repre-                Discussion
sentation of magnitude is approximately logarithmic (e.g.,
Shepard, Kilpatric & Cunningham 1975; Dehaene 2003).                      The results paint a relatively clear and somewhat intriguing
   The implied trust statistics t for the cover story, shown in           view of base rate neglect. To a large extent, the base rates
Table 1, are more complex. Most importantly but not sur-                  implied by larger samples are weighted more heavily than for
prisingly, in both the 25% base rate conditions and the 75%               small samples, in keeping with the so-called empirical law of
base rate conditions, the estimated value for t is much higher            large numbers (Sedlmeier & Gigerenzer, 1997). In that sense,
when the cover story suggests high trust as opposed to low                people can be seen to adapt to the trustworthiness of the data
trust. Parameter estimates for low trust suggest that a prior             in a very sensible fashion. That said, a kind of \insensitivity"
datum is worth only 1/4 of a new datum, in subjective (i.e.,              to sample size is observed, since the subjective value rises
log) terms. When the base rate is 25%, the high trust pa-                 nearly logarithmically with sample size, rather than linearly.
rameter is approximately 1, suggesting that the only effect in            Altering the cover story to devalue the base rate has a large
this condition is the logarithmic scaling of subjective sample            effect on trust, lowering the subjective value of the base rate
size effect shown in Figure 3. The inferred value of 1.4 for              by three quarters in both the 25% and 75% conditions.
                                                                    704

                                            40                                                                             75
          Inferred Subjective Sample Size
                                            35
                                                                                                   Estimated Proportions
                                            30
                                            25
                                            20                                                                             50
                                            15
                                            10
                                             5
                                             0                                                                             25
                                                 4     8 12 20               200                                                    0          1          2           3
                                                     Empirical Sample Size                                                              Number of Reasons to Distrust
Figure 3: Subjective sample sizes inferred from participants'                            Figure 4: Actual and predicted values for participants' es-
probability judgments follow an approximately logarithmic                                timates for the underlying rate in experiment 2. Empirical
function.                                                                                values are shown by white circles with standard error bars
                                                                                         shown. Model predictions are shown with crosses.
Table 1: Estimated trust statistics for the low and high trust-
worthiness conditions, as a function of the underlying base                              Table 2: Estimated effect on trust for each element of the
rate.                                                                                    cover story.
                      high trust story low trust story                                                                                  location      age      source
      25% base rate         0.94                0.25                                                                            t         0.34        0.63      0.62
      75% base rate         1.41                0.23
                                                                                         those with 75% base rate, prior sample of 20 and current
                                                 Experiment 2                            of 4): if all parameter values are multiplied by 1.41 (the
Method                                                                                   high trust value found for these conditions in Experiment 1),
Experiment 2 aimed to expand on the three factors that con-                              we obtain ñ = 6.61 for the subjective sample size, which
tributed to the cover story in Experiment 1. The design of                               is fairly close to the value of 7.82 found in Experiment 1.
the experiment was the same as for Experiment 1, and was                                 Similarly, the low trust value of 0.23 from Experiment 1 is
in fact conducted simultaneously with the first experiment                               close to prediction from Experiment 2 of: 1.41 × 0.34 ×
using the same 20 participants, with the various conditions                              0.63 × 0.62 = 0.18.
intermixed with those used in the first study. In this case, the
\base rate" was fixed at 75% using a sample of size 20 (i.e.,
                                                                                         Discussion
15 hits), and the new data are based on a sample size of 4                               It is clear that all three elements of the cover story affect
with a single hit, suggesting a rate of 25%. An independent                              the trust that people assign to data in reasonable ways. For
effect model takes the same format as Equation 3, but with                               example, location has a stronger effect than time or source,
separate terms for the effect of location tl , age of data ta                            corresponding with natural expectations - specifically, that
and source of the data ts . For reasons that will become clear                           a change in continent will alter the value of a dataset more
shortly, we fix the high value for trust at 1 in each case (e.g.,                        than it being 100 years old or collected by someone else.
when you collect the data yourself), and simply estimate the                             Moreover, the results of Experiment 2 provide insight into
low value. Similarly, we again extract ñ from the raw data.                             the unexpected value t = 1.4 from the high trust, 75% base
                                                                                         rate conditions of Experiment 1. The fact that participants
Results                                                                                  in Experiment 2 showed near perfect calibration in terms of
The basic pattern of results is shown in Figure 4. As more                               sample size suggests that, in situations with high trust and
reasons to distrust the prior data (distant location, old data,                          small, easily-added samples, people are able to weight sam-
collected by someone else) are added to the cover story, par-                            ples in an exact (linear) fashion rather than logarithmically.
ticipants' ratings move away from the base rate and closer                               Examining the results for n1 = 4 in the left-hand plot of
to the new data. Moreover, a model that assumes that each                                Figure 2 (corresponding to Experiment 2's conditions) one
manipulation has a constant effect on trust provides a very                              sees that the calculated value t = 1.4 likely results from the
close fit to the data. As shown in Table 2, each manipulation                            model assuming logarithmic weighting of sample sizes when,
has a substantial effect. Changing the age or source of the                              under such conditions, participants updated their beliefs in
data lowers trust to 2/3, while changing the location lowered                            accordance with Bayes' Theorem.
trust to 1/3. Fitting the subjective value of the new data, we
obtained ñ = 4.72, suggesting that in this case participants'                                                                      General Discussion
subjective understanding of sample size was almost perfectly                             Together, the experiments provide an interesting perspective
calibrated.                                                                              on base rate neglect; overwhelmingly supporting the view
   The overall pattern of results is highly consistent with                              that, although the base rate neglect effect is genuine, it is
results from corresponding conditions in Experiment 1 (i.e.,                             not that people simply fail to take into account all of the
                                                                                   705

available information. On the contrary, there is evidence to           References
suggest that people are, in fact, discounting prior informa-           Anderson, J. R. & Schooler, L. J. (1991). Reflections of the envi-
tion as less relevant than current information. Four distinct             ronment in memory. Psychological Science, 2, 396-408.
factors are shown to influence the extent to which people              Bar-Hillel, M. (1980). The base-rate fallacy in probability judg-
devalue prior information: geographic distance, age of the                ments. Acta Psychologica, 44, 211-233.
data, the source of the information, and the amount of data            Bernoulli, J. (1713). Ars Conjectandi, Basilea: Thurnisius.
                                                                       Cosmides, L. & Tooby, J. (1996). Are humans good intuitive statis-
upon which the base rate is constructed. Sample size, the last            ticians after all? Rethinking some conclusions from the literature
of the four factors, was investigated in some detail, and the             on judgment under uncertainty. Cognition, 58, 1-73.
results suggest that people are sensitive to changes in sample         Dehaene, S. (2003). The neural basis of the Weber-Fechner law: a
size. This is particularly interesting in that, quite incidentally        logarithmic mental number line. Trends in Cognitive Sciences,
                                                                          7(4),145-147.
to the overall goals for the study, it suggests that many of           Gigerenzer, G. (1996). On narrow norms and vague heuristics: A
the results pertaining to \insensitivity to sample size" might            reply to Kahneman and Tversky (1996). Psychological Review,
be best explained by supposing that people use an internal                103(3), 592-596.
logarithmic representation to scale sample size, in agreement          Gigerenzer, G., & Hoffrage, U. (1995). How to improve Bayesian
with other studies that have looked at the psychological rep-             reasoning without instruction: Frequency formats. Psychologi-
                                                                          cal Review, 102(4), 684-704.
resentation of magnitude.                                              Gigerenzer, G., & Todd, P. M. (1999). Simple Heuristics That
   An intriguing possibility is that the proposed logarithmic             Make Us Smart. New York: Oxford University Press.
law for subjective sample size may not apply in all cases. As          Gluck, M. A. & Bower, G. H. (1988). From conditioning to cate-
indicated, the parameter estimates for the two Experiments                gory learning: An adaptive network model. Journal of Experi-
lead to similar predictions. However, while most conditions               mental Psychology: General, 117, 227-247.
                                                                       Goodie, A. S., & Fantino, E. (1999). What does and does not
in Experiment 1 involve logarithmic scaling (leading to Fig-              alleviate base-rate neglect under direct experience. Journal of
ure 3) this appear not to be the case for the more constrained            Behavioral Decision Making, 12, 307-335.
case in Experiment 2. One explanation for the disparity may            Harries, C. & Harvey, N. (2000). Are absolute frequencies, rela-
be that in some situations (with high trust and easily manip-             tive frequencies, or both effective in reducing cognitive biases.
ulated numbers), people mentally represent the data in terms              Journal of Behavioral Decision Making, 13, 431-444.
                                                                       Hume, D. (1739/1898). A Treatise of Human Nature. London:
of a single pooled sample, rather than as two distinct sam-               Ward Lock.
ples. In this pooled case, the relative weight of the prior            Jaynes, E. T. (2003). Probability Theory: The Logic of Science.
data and new samples would combine linearly. It is possible               Cambridge: Cambridge University Press
that this distinction between \pooling" and \comparing" data           Kahneman, D., Slovic, P. & Tversky, A. (1982). Judgment Under
                                                                          Uncertainty. Cambridge, UK: Cambridge University Press.
sets could explain the effect, but without further data it is          Kahneman, D. & Tversky, A. (1996). On the reality of cognitive
difficult to do more than speculate.                                      illusions. Psychological Review, 103(3), 582-591.
   Three final caveats are in order. Firstly, the proposed ac-         Laplace, P. S. (1814/1951). Essai Philosophique sur les Proba-
count only covers the weighting of two data sources. A                    bilites (F. W. Truscott & F. L. Emory, Trans.). New York: Dover
complete account should extend the approach to deal with                  Publications.
                                                                       Lee, M. D., & Cummins, T. D. R. (2004). Evidence accumulation
extrapolation. Secondly, no claim is made that discounting                in decision making: Unifying the `take the best' and `rational'
is always conscious: people may very well have an intuitive               models. Psychonomic Bulletin & Review, 11(2), 343-352.
preference to rely on more recent data, for instance, but still        Sedlmeier, P. & Gigerenzer, G. (1997). Intuitions about sample
be willing to admit (post-experiment) that they \should" have             size: The empirical law of large numbers. Journal of Behavioral
used Bayes' theorem. An intuitive (and appropriate) distrust              Decision Making, 10, 33-51.
                                                                       Shepard, R. N., Kilpatric, D. W. & Cunningham, J. P. (1975). The
of base rates not being inconsistent with the ability to follow           internal representation of numbers. Cognitive Psychology, 7, 82-
the logic of Bayesian updating. Finally, it should be noted               138.
that since our experimental design used within-subject com-            Simon, H. A. (1956). Rational choice and the structure of environ-
parisons, it is heavy-handed in terms of the extent to which              ments. Psychological Review, 63, 129-138.
participants are made aware of the potential variations in reli-       Sloman, S. A., Over, D., Slovak, L. & Stibel, J. M. (2003). Fre-
                                                                          quency illusions and other fallacies. Organizational Behavior
ability for different sources of data. Thus, although it is clear         and Human Decision Processes, 91, 296-309.
that there are situations in which people are extremely good           Stigler, S. M. (1986) The History of Statistics Cambridge, MA:
at incorporating or discounting prior data in a sensible fash-            Harvard University Press.
ion, it is not as clear how generally this holds. In particular,       Todd, P. M. & Gigerenzer, G. (2000). Simple heuristics that make
further research is required to determine whether examples                us smart. Behavioral and Brain Sciences, 23(5), 727-741.
                                                                       Todd, P. M. & Gigerenzer, G. (2003). Bounding rationality to the
without any markers of trustworthiness, such as traditional               world. Journal of Economic Psychology, 24, 143-165.
base rate neglect experiments, lead people to trust or distrust        Tversky, A. & Kahneman, D. (1974). Judgment under uncertainty:
the presented base rates. Until this question has been re-                heuristics and biases. Science, 185, 1124-1131.
solved, however, it seems premature to base any charge of              Tversky, A. & Kahneman, D. (1982). Evidential impact of base
                                                                          rates. In D. Kahneman, P. Slovic & A. Tversky (Eds.), Judgment
human irrationality on previous base rate findings.                       Under Uncertainty: Heuristics and Biases. Cambridge, UK:
                                                                          Cambridge University Press.
Acknowledgments                                                        Villejoubert, G. & Mandel, D. R. (2002). The inverse fallacy: an
MBW was supported by ExxonMobil and Santos, through the CIBP              account of deviations from Bayes Theorem and the additivity
                                                                          principle. Memory and Cognition, 30(2), 171-178.
at the Australian School of Petroleum. DJN was supported by an
Australian Research Fellowship (ARC grant DP-0773794). We              Zentall, T. R., & Clement, T. S. (2002). Memory mechanisms in
                                                                          pigeons: evidence of base-rate neglect. Journal of Experimental
thank Anastasia Ejova for collecting the data and Steve Begg,             Psychology: Animal Behavior Processes, 28(1), 111-115.
Nancy Briggs and three anonymous reviewers for their comments.
                                                                   706

