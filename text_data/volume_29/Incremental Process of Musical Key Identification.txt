UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Incremental Process of Musical Key Identification
Permalink
https://escholarship.org/uc/item/9nr5c65k
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Matsunaga, Rie
Abe, Jun-ichi
Publication Date
2007-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                              Incremental Process of Musical Key Identification
                                     Rie Matsunaga (matunaga@psych.let.hokudai.ac.jp)
                                               Japan Society for the Promotion of Science
                                           Jun-ichi Abe (abe@psych.let.hokudai.ac.jp)
                                 Department of Psychology, Hokkaido University, N10 W7, Kita-ku
                                                       Sapporo, 060-0810, JAPAN
                              Abstract                                  2004). The underlying idea in this approach posits that
                                                                        listeners interpret the most commonly occurring pitch class
   Pitch set is a primary cue for key perception. However, pitch        within a melody as its tonal center. However, evidence
   set alone cannot account for the phenomenon that listeners           favoring this approach is often correlational, meaning that
   perceive different keys for melodies that consist of the same
                                                                        inferences about the causal relationship between the
   pitch set but exhibit different temporal arrangements.
   Contrary to previous results, a recent study demonstrated that
                                                                        frequency of a pitch class and the perception of it as a tonal
   additional cues based on sequence properties (e.g., the              center remain tentative. In other words, pitch distributional
   augmented fourth, a pitch class in the final position of a           properties (e.g., relative frequency) may not provide cues
   melody, etc.) did not contribute to key perception. To explain       for key identification.
   this phenomenon, we traced how listeners developed a sense                The third approach stresses that “a local property”, not
   of key as melodies (with the same pitch set differing in pitch       a global property, in a melody. For example, Butler and
   sequence) unfolded over time. In each melody, listeners              Brown proposed rare intervals (i.e., the augmented fourth or
   identified the key following the presentation of a segment of        the diminished fifth) as cues (e.g., Butler & Brown, 1994).
   pitches where the number of tones within a segment increased
                                                                        Others have suggested that different local property cues
   with successive presentations. Results suggested that listeners
   gradually established the sense of key. Throughout the
                                                                        (other than rare intervals) function in this capacity; thus,
   progress of melodies, the listeners’ key responses were              proposed cues include the inclusion of a perfect fifth and
   governed by a set of pitches within a segment provided a             either the major third or the minor third (e.g., Huovinen,
   given point in time. These findings suggest that key                 2002), an ascending fourth or a descending fifth in the
   identification is derived from the incremental changes of the        opening (e.g., Vos, 1999), the pitch class of the final tone
   pitch set with unfolding of a melody.                                (e.g., Creel & Newport, 2002), or the opening pitch class in
                                                                        conjunction with the final pitch class (e.g., Cuddy, Cohen &
   Keywords: Music perception; Tonal organization; Musical              Mewhort, 1981). Finally, however, on this question there
   key identification
                                                                        appears to be little current consensus, across these various
                                                                        studies.
                          Introduction                                       It is clear that, in spite of research on these three
      Musical key identification plays a fundamental role in            proposals, the particular properties that contribute to reliable
music perception. Empirical evidence suggests that key                  key identification remain open to question. Consider the two
identification results from the organization of a tone                  melodies shown in Figure 1. Although both are composed of
sequence into a hierarchical system of tonality according to            the same set of six pitches, they differ in the sequential
a listener’s internal schema (e.g., Abe & Hoshino, 1990;                arrangement of these pitches. If pitch set alone serves as a
Krumhansl, 1990). What kind of a property in an arbitrary               cue to key, then listeners should identify these two melodies
melody functions as a cue for key identification?                       to have the same key. But they do not. In fact, listeners
      There are three approaches to this issue. The first               generally interpret Melody 1 as being in C major and
approach stresses “pitch set (the collection of pitch classes           Melody 2 as being in G major.
in a melody, regardless of their order)”, which is a global                  Matsunaga and Abe (2005) explored possible
property in a melody. Many studies have shown that pitch                determinants of this phenomenon. They required musically
set indeed functions as a primary cue for key identification            trained listeners and untrained listeners to identify a key (or
(e.g., Abe & Hoshino, 1990; Balzano, 1982; Longut-
Higgins, 1987). More specifically, these studies suggest that
listeners, who are familiar with Western music, perceive a
melody to be in a given key when the constituent pitches of
this melody are all interpretable as scale tones of a certain
diatonic scale.
      A second approach emphasizes “the distribution of
pitch classes” which is also a global property in a melody
(e.g., Krumhansl, 1990; Oram & Cuddy, 1995; Temperley,
                                                                   1277

a tonal center) for melodies consisting of the same pitch set
but differing in temporal arrangements of pitches. They
found that, regardless of their musical training, listeners’
key identifications were governed not only by the pitch set
but also by certain other melodic properties.
      In pursuing the latter, Matsunaga and Abe (2007)
investigated whether certain local sequence properties might
be responsible for different key identifications. The
experimental design of Matsunaga and Abe differed from
those of previous studies in that they examined what local
property have more influence than any other local property
on key identification. Using linear discriminant analyses,
they evaluated relative contributions of as many different
local sequence properties as possible (e.g., the augmented               Figure 2: The experimental procedure of the present study.
fourth, the perfect fifth, a pitch class in the final position,
etc.). Their listeners were asked to provide key
                                                                      the first three tones of each sequence (State 3) and identified
identifications for a variety of different intact melodies that
                                                                      keys. This procedure was continued until key response
comprised the same pitch set but differed in temporal
                                                                      distributions were obtained for sequences of Stages 2
arrangements of pitches. The results led to the conclusion
                                                                      through 6.
that none of the local sequence properties examined
                                                                            Our task required listeners to directly name the key of a
contributed significantly to key identification. Such findings
                                                                      presented sequence. Although this is simplest and most
appear to undermine hypotheses about key identification
                                                                      direct means of measuring key identification, it does require
that rest on specific local sequence properties, although they
                                                                      that listeners are capable of key naming. For this reason we
do not rule out the possibility that as yet unexamined local
                                                                      employed musically trained listeners (referred to as
properties function as critical cues to key. In sum, the
                                                                      musicians) with absolute pitch as participants; musically
research of Matsunaga and Abe (2005, 2007) has shown that
                                                                      untrained listeners (i.e., non-musicians) cannot perform this
the previous approaches to key identification fall short in
                                                                      task. In addition, musicians are typically less influenced by
explaining how listeners arrive at different keys of melodies
                                                                      unexpected factors and bias. Note, however, that these
      The purpose of the present study is to examine certain
                                                                      differences between musicians and non-musicians does not
other melodic properties that might lead listeners to perceive
                                                                      imply that only musicians can respond to specialized
different keys for melodies that comprise the same pitch set
                                                                      perceptual cues. Many previous studies indicate that
but differ in temporal arrangements of pitches. These
                                                                      musicians and non-musicians make similar distinctions
melodies share a set of all constituent pitches in a whole
                                                                      between melodic and jumbled sequences (e.g., Hoshino &
melody; that is, pitch full-set is common to the melodies. On
                                                                      Abe, 1981), are similarly sensitive to tonal hierarchies (e.g.,
the other hand, the melodies do not share a set of pitches
                                                                      Hèbert, Peretz, & Gagnon, 1995), and basically identify the
within each of the melody segments which start at the first
                                                                      same tonal center (e.g., Matsunaga & Abe, 2005). Such
pitch and increase by one pitch. That is, pitch subset is
                                                                      findings suggest that perceptual cues for key identification
uncommon to the melodies. For example, Melodies 1 and 2
                                                                      are common to all listeners that share a common cultural
(Figure 1) share the pitch full-set [C, D, E, G, A, B], while
                                                                      exposure to music, regardless of their musical training and
they have different pitch subsets within a segment that
                                                                      absolute pitch abilities.
consists of the first two pitches (i.e., [C, G] in Melody 1 and
[D, B] in Melody 2). Likewise, they differ in pitch subsets
within a segment that consists of first three pitches (i.e., [C,
E, G] in Melody 1 and [C, D, B] in Melody 2), first four                                          Method
pitches (i.e., [C, E, G, A] and [C, D, G, B]), or first five
pitches (i.e., [C, D, E, G, A] and [C, D, E, G, B]). Such             Participants
differences in pitch subsets among melodies may, in turn,               The participants were 15 undergraduate students (range =
contribute to corresponding differences in key identification.        18-22 years), who were familiar with Western music. All
Accordingly, our hypothesis is that unfolding pitch subsets           reported that they possessed absolute pitch. They had an
(i.e., as presented at successive points in time) will govern         average of 15.3 (range = 12-17) years of musical training.
the time course of key identification                                 Musical instruments that they routinely played were the
   To assess this hypothesis, we enlisted the experimental            piano for 10 participants, and the electronic organ for five
tracking procedure outlined in Figure 2. Here, although each          participants.
stimulus tone sequences consisted of six pitches, initially
listeners heard the first two tones of each sequence (Stage 2)        Materials and apparatus
and then identified keys. Following this, the listeners heard           Thirty-nine sequences of six tones were used as musical
                                                                      stimuli. All comprised the same pitch full-set, but they
                                                                 1278

differed in the temporal arrangement of the constituent                switch responses, namely those responses that reflected a
pitches. The 39 tone sequences were chosen from the                    change in key from one presentation (e.g., Stage n) to the
stimulus sequences used in the Matsunaga and Abe (2007).               next (e.g., Stage n+1). After Stage 3-4, the average
The pitch full-set employed was [C, D, E, G, A, B]. All                percentage of key switch responses decreased as tone
constituent tones of this pitch full-set can be interpreted as         sequences progressed (Stages 2-3 = 48%, Stages 3-4 = 51%,
scale tones of the following four keys: C major, G major, E            Stages 4-5 = 44%, and Stage 5-6 = 43%). A one-way
minor, and A minor. To create as many kinds of intervals as            ANOVA revealed a significant main effect of the stages, F
possible within the pitch full-set, we generated two pitch             (3, 42) = 2.97, p = .043. No comparisons between the stages
full-sets: [C4, D4, E4, G4, A4, B4] (Pitch Full-Set I) and [D4,        were significant (all ps > .10). Next, we examined
E4, G4, A4, B4, C5] (Pitch Full-Set II). There were 20                 confidence ratings. The confidence ratings provided by each
possible intervals between two pitches in the two pitch full-          listener were averaged for each of the five stages (Stages 2-
sets: (±1)1, (±2), (±3), (±4), (±5), (±7), (±8), (±9), (±10), and      6). A one-way ANOVA revealed that confidence increased
(±11) in semitone. Of the 39 tone sequences, 13 originated             significantly over stage (M = 3.7, 3.8, 3.9, 4.0, 4.6 for
from Pitch Full-Set I and 26 came from II.                             Stages 2-6, respectively) with F (4, 56) = 10.72, p < .001.
   All the tone sequences were monophonic isochronous                  However, the only significant pair-wise differences were
melodies whose tones were contiguous and did not overlap.              between Stage 6 and each of the remaining four stages (all
All sequences were presented at the same tempo; the                    ps < .01), suggesting that the main effect was responsible
duration of each tone was equal (i.e., 0.6 s), for a total of 3.6      for confidence ratings in Stage 6. It may not be all that
s per tone sequence. The timbre of each pitch was that of an           surprising that the confidence of key identification was the
acoustic grand piano. The tone sequences were created as               highest at the end of each sequence, because the listeners
MIDI files using sequencing software (Roland “Cakewalk”                knew that it was the end of each sequence.
software) installed on a Windows PC.                                     These results showed that the listeners vacillated among a
                                                                       few key categories in their key identifications but that these
Procedure                                                              vacillations attenuated and confidence increased as a
   Each listener (i.e., participant) was seated in front of two        sequence progressed. Consistent with the results of previous
speakers. Each listener was given a response sheet listing 12          studies (Krumhansl & Kessler, 1982), our findings suggest
major and 12 minor key categories plus an atonal category.             that listeners’ key identifications are unlikely to be
Each sequence was played in the following fashion: First,              stabilized abruptly in a particular location; but rather
only the opening two pitches of the sequence (Stage 2) were            listeners gradually establish the sense of key.
presented; next, the first three pitches (Stage 3) were
presented, and so on until the presentation ended with the             Contributions of pitch subsets to key responses
whole tone sequence (Stage 6). After each presentation,                  Results of key identification responses appear in Table 1.
listeners were asked to identify the most plausible key and            In each of the stages, from Stage 2 through 5, participants
to rate their subjective confidence in their key identification        tended to limit their key responses to C major, G major, and
on a 7-point scale (7 = full confidence to 1 = poor                    A minor. Responses to remaining keys were relatively
confidence). The presentations were self-paced; participants           infrequent. These three keys contain all constituent tones of
indicated their readiness for the next presentation by                 all the pitch subsets as diatonic scale tones. Some of the
conveying verbally. After three practice trials, the 39                tone sequences in each stage elicited response agreement
experimental trials were presented in randomized order                 among the majority of the listeners for C major, or G major,
across the listeners.                                                  or A minor. This suggested that the listeners systematically
                                                                       selected a key from these three keys.
                  Results and Discussion                                 In order to determine whether pitch subsets led the
                                                                       listeners to distinguish among C major, G major, and A
Transitions of key responses and confidence ratings                    minor responses, we performed Multiple Discriminant
                                                                       Analyses (MDA) with dummy variables separately for each
   Distributions of key responses for the two pitch full-sets
were highly similar. Therefore, the data were pooled across            of the four stages. If MDA shows that pitch subsets satisfied
the pitch full-sets.                                                   the following two criteria, then we may infer that such
   To examine how the listeners developed the sense of a key         Table 1
while tone sequences unfolded over time, we analyzed the             Percent of each of the three key responses and the number of tone sequences that
data for key identification responses and confidence ratings         elicited response agreement among majority of the participants (eight or more of
                                                                     the15 participants) in each of the three keys.
separately. The first analysis examined percentages of key
                                                                                       Percent of key responses (%)        Number of tone sequences
                                                                                     C major     G major      A minor    C major     G major    A minor
1
  In this paper, intervals were denoted by positive integers for         Stage 2       39.7       24.6         12.5         12          5          3
ascending intervals and by negative integers for descending              Stage 3       35.9       25.6         14.2          9          5          3
intervals (one unit = a semitone). For example, the ascending            Stage 4       31.5       33.0         16.2          5          7          2
                                                                         Stage 5       32.1       36.6         15.7          6          6          1
major third and the descending major third were denoted as (+4)
                                                                         Stage 6       40.5       38.1         11.6         15          11         0
and (-4) respectively.
                                                                  1279

  subsets made significant contributions to key responses: (1)                significant discriminant functions, we assigned the label “C
  a pitch subset was associated with one key response (e.g., C                major-like” and “G major-like” to the positive and negative
  major) but it was not associated with another key response                  directions of Function 2 respectively, and “A minor-like” to
  (e.g., G major); and (2) pitch subsets associated with each of              the positive direction of Function 1 (Figure 3A). If the
  the key responses were transpositionally equivalent -- for                  structure coefficient near ±0.30 or higher of independent
  different absolute pitches with the same tonal functions (e.g.,             variable has the same sign in the discriminant function as
  tonic, dominant).                                                           the group centroid of a group, this indicates that the
    It is necessary to distinguish between the major and minor                independent variable contributes positively to defining this
  modes because the two modes differ in the sequence of                       group (cf. Hair, Anderson, Tatham, & Black, 1998). Visual
  intervals (in semitones) between adjacent tones. Due to this                inspection of Figure 3B shows that [C, E], [E, G], and [C,
  difference, tonal functions of intervals in major keys are not              G] are associated with “C major-like”, while [D, B], [G, B],
  always equivalent to those in minor keys even though                        and [D, G] are associated with the “G major–like”.
  intervals of major keys and minor keys are the same. Here,                    In the analysis presented in Figure 3, the pitch subsets of
  we performed MDAs using the C major, G major, and A                         [C, E], [E, G], [C, G] may be interpreted as [tonic, mediant],
  minor groups as dependent variable groups, while we                         [mediant, dominant], and [tonic, dominant] in C major,
  decided to focus mainly on listeners’ ability to differentiate              respectively. On the other hand, [D, B], [G, B], and [D, G]
  the two major keys (C and G majors).                                        are interpretable as [dominant, mediant], [tonic, mediant],
    Figures 3-6 present the results of MDAs for key                           and [dominant, tonic] in G major, respectively. These
  identification responses in Stage 2-5 respectively. We begin                relationships between pitch subsets of C major and those of
  with the results of MDA for Stage 2, which involve first-                   G major indicated that the three separate pairs of the pitch
  pitch subsets comprising two tones (Figure 3). The                          subsets for each key differed in pitch classes but they
  dependent variable groups of the MDA was three-group key                    nonetheless shared comparable tonal functions. The [C, E]
  identification (C major, G major, and A minor groups),                      and [G, B] include (±4) or (±8); [E, G] and [D, B] include
  while independent variables were 14 types of the two-pitch                  (±3) or (±9); [C, G] and [D, G] include (±7) or (±5). The
  subsets (e.g., [C, D], [C, E], etc). The sample observations                results suggest that pitch subsets with (±4) or (±8), those
  were 449 responses, which consisted 232 of responses of C                   with (±3) or (±9), and those with (±7) or (±5) made
  major, 144 of G major, 73 of A minor. On the basis of                       significant contributions to distinction of the major keys.
  locations of group centroids in a space defined by the                      Finally, this MDA also reveals listeners’ sensitivity to key
                                                                              information associated with A minor -- A minor was
                                                                              associated with [E, A], which is interpretable as [dominant,
                                                                              tonic] in A minor.
                                                                                The results for MDA in Stage 3, which involve pitch
                                                                              subsets that include the first three tones, appear in Figure 4.
                                                                              Dependent variables were a three-group key identification,
                                                                              while independent variables were 17 types of the three-pitch
                                                                              subsets (e.g., [C, D, E], [C, E, G], etc.). The sample
                                                                              observations were 442 responses. The correspondences of
                                                                              [C, E, G] and [D, E, G] with positive direction of Function 1
                                                                              reflect their associations with “C major-like”, while the
                                                                              correspondence of [D, G, B] and [G, A, B] with the negative
                                                                              direction of Function 2 reflect their associations with “ G
                                                                              major–like.” The pitch sets of [C, E, G] and [D, E, G] are
                                                                              interpretable as [tonic, mediant, dominant] and [supertonic,
                                                                              mediant, dominant] in C major, respectively. [D, G, B] and
                                                                              [G, A, B] are interpretable as [dominant, tonic, mediant] and
                                                                              [tonic, supertonic, mediant] in G major, respectively. The [C,
                                                                              E, G] of C major and [D, G, B] of G major differed in pitch
                                                                              classes but shared tonal functions. The [C, E, G] and [D, G,
                                                                              B] subsets include intervals [(±4), (±3), (±7)], [(±8), (±3),
                                                                              (±5)], or [(±9), (±4), (±5)], because there were two kinds of
                                                                              C (i.e., C4 and C5) in the used tone sequence. This result of
                                                                              the major keys was consistent with that of A minor -- A
                                                                              minor was associated with [C, E, A], which is interpretable
Figure 3: Results of MDA on Stage 2. 3A represents group centroids            as [mediant, dominant, tonic] in A minor.
for C major, G major, and A minor groups. 3B represents pitch subsets           The results for MDA in Stage 4, which involves the first
in a space defined by the two structure coefficients. Pitch subsets           pitch subset containing four tones, is shown in Figure 5.
having ±.20 or higher on either discriminant function 1 or function 2 are     Independent variables were 12 types of the four-pitch
represented in the 3B.
                                                                         1280

         Figure 4: Results of MDA on Stage 3. The                            Figure 5: Results of MDA on Stage 4. The representations
         representations of the table and the figure are the same            of the table and the figure are the same as those in Figure
         as those in Figure 3.                                               3.
subsets (e.g., [C, D, E, G] etc.). The sample observations
were 472 responses. The correspondences of [C, E, G, B]
and [C, D, E, G] with positive direction of Function 1 reflect
their associations with “C major-like”, while the
correspondence of [D, G, A, B] with the negative direction
of Function 2 reflects its association with “ G major–like.”
The [C, E, G, B] and [C, D, E, G] subsets are interpretable
as [tonic, mediant, dominant, leading-tone] and [tonic,
supertonic, mediant, dominant] in C major respectively. The
[D, G, A, B] subset is interpretable as [dominant, tonic,
supertonic, mediant] in G major. Thus, [C, D, E, G] subset
of C major and [D, G, A, B] of G major differed in pitch
classes but shared tonal functions, and these pitch subsets
include a set of intervals [(±2), (±3), (±4), (±5), (±7)], [(±2),
(±3), (±5), (±8), (±10)], or [(±2), (±4), (±5), (±7), (±9)].
Again, this analysis reveals listeners’ sensitivity to A minor
-- A minor was associated with [C, E, A, B], which is
interpretable as [mediant, dominant, tonic, supertonic] in A
minor.
     Finally, MDA in Stage 5, which involves the first-five-
pitch subsets, showed that none of the pitch subsets made
significant contributions to key identification. The result
might reflect the fact that combinations of five pitches (of
six pitches) were highly similar.
  In summary, the results of MDAs revealed that the pitch
                                                                       Figure 6: Results of MDA on Stage 5. The representations of
subsets that figured in Stages 2-4 made reliable
                                                                       the table and the figure are the same as those in Figure 3.
contributions to key identification responses. Across these
three stages, the significant pitch subsets shared (±7) and its
inversion (±5), (±4) and its inversion (±8), and (±3) and its
inversion (±9). In other words, these pitch intervals
                                                                  1281

correspond to intervals that consist of the “tonic triad” of a       Butler, D., & Brown, H. (1994). Describing the mental
diatonic scale. Thus, in each stage, the choice of a key                representation of tonality in music. In R. Aiello (Ed.), Musical
response is likely to be based on those pitch subsets that              perceptions (pp. 191-212). New York: Oxford University
include constituent intervals of the tonic triad.                       Press.
                                                                     Creel, S. C., & Newport, E. J. (2002). Tonal profiles of
                                                                        artificial scales: Implications for music learning. In C.
                   General Discussion                                   Stevens, D. Burnham, G. McPherson, E. Schubert, & J.
                                                                        Renwick (Eds.), Proceedings of the 7the International
  The present experiment indicates that the listener                    Conference on Music Perception and Cognition, (pp.
gradually established the sense of key as melodies unfolded.            281-284). Adelaide, Australia: Causal Productions.
The MDAs, across the first successive few stages, revealed           Cuddy, L. L., Cohen, A. J., & Mewhort, D. J. K. (1981).
that only a small number of pitch subsets provided in each              Perception of structure in short melodic sequences.
stage made significant contributions to the key identification          Journal of Experimental Psychology: Human Perception
responses. Specifically, the results suggested that in a given          and Performance, 7, 869-883.
stage, key identifications were determined from pitch                Hair, J. F., Anderson, E. R., Tatham R., & Black, W. C.
subsets that offered constituent intervals of a tonic triad of a        (1998). Multivariate data analysis (5th ed.). NJ:
diatonic scale. This is consistent with other evidence that             Prentice Hall.
the tonic triad of a diatonic scale facilitates key                  Hèbert, S., Peretz, I., & Gagnon, L. (1995). Perceiving the
identification for listeners familiarized with Western music            tonal ending of tune excerpts: The roles of pre-existing
(e.g., Abe, 1987; Krumhansl & Kessler, 1982). The present               representation and musical expertise. Canadian Journal
results suggest that, throughout progress of a tone sequence,           of Experimental Psychology, 49, 193-209.
the sense of key is governed by pitch subsets provided at            Hoshino, E., & Abe, J. (1981). Tonality and the coherence
each point in time. In other words, key identification                  in melody cognition. (Hokkaido Behavioral Science
emerged gradually on a pitch subset by pitch subset basis.              Report Series P No. 23). Sapporo, Japan: Hokkaido
  As mentioned in Introduction, our previous studies                    University, Department of Psychology. (In Japanese.)
(Matsunaga & Abe, 2005, 2007) showed that neither the                Huovinen, E. (2002). Pitch class constellations: Studies in
original pitch set approach (e.g., Longuet-Higgins, 1987)               the perception of tonal centricity. Turku, Finland:
nor the local property approach (e.g., Butler & Brown,                  Suomen Musiikkitieteellinen Seura.
1994; Huovinen, 2002; Vos, 1999) explain the phenomenon              Krumhansl, C. L. (1990). Cognitive foundations of musical
that listeners identified different keys for melodies that              pitch. New York: Oxford University Press.
comprised the same pitch set but differing in the temporal           Krumhansl, C. L., & Kessler, E. J. (1982). Tracing the
arrangement of pitches. By tracing listeners’ development of            dynamic changes in perceived tonal organization in a
a sense of key, the present study found that identification of          spatial representation of musical keys. Psychological
different keys for the melodies is due to pitch subsets’                Review, 89, 334-368.
contributions that are dynamically accumulated throughout            Longuet-Higgins, H. C. (1987). Mental processes: studies
the course of musical passages. This implies that tonal                 in cognitive science. London: MIT Press.
organization is based on incremental changes of pitch set as         Matsunaga, R., & Abe, J. (2005). Cues for key perception
a melody unfolds over time.                                             of a melody: Pitch set alone? Music Perception, 23,
                                                                        153-164.
                         References                                  Matsunaga, R., & Abe, J. (2007). What kinds of local
                                                                        sequence properties function as cues for musical key
                                                                        perception? Manuscript submitted for publication.
Abe, J. (1987). How is a melody processed? In G. Hatano
                                                                     Oram, N., & Cuddy, L. L. (1995). Responsiveness of
      (Ed.), Music and cognition (pp. 41-68). Tokyo: Tokyo
                                                                        Western adults to pitch-distributional information in
      University Press. (In Japanese.)
                                                                        melodic sequences. Psychological Research, 57, 103-
Abe, J., & Hoshino, E. (1990). Schema driven properties in
                                                                        118.
      melody cognition: Experiments on final tone
                                                                     Temperley, D. (2004). The cognition of basic musical
      extrapolation by music experts. Psychomusicology, 9,
                                                                        structures. Cambridge, MA: MIT Press.
      161-172.
                                                                     Vos, P. G. (1999). Key implications of ascending forth and
Balzano, J. G. (1982). The pitch set as a level of description
                                                                        descending fifth openings. Psychology of Music, 27, 4-
      for studying musical pitch perception. In M. Clynes,
                                                                        18.
      (Ed.), Music, Mind, and Brain. New York: Plenum
      Press.
                                                                 1282

