UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Account of the Development of the Generalization of Shape Information
Permalink
https://escholarship.org/uc/item/4734v20m
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)
Authors
Doumas, Leonidas A.A.
Hummel, John E.
Publication Date
2007-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       A Computational Account of the Development of the Generalization of Shape
                                                            Information
                                        Leonidas A. A. Doumas (adoumas@indiana.edu)
                                Department of Psychological and Brain Science, 1101 E. Tenth Street
                                                          Bloomington, IN 47405
                                     John E. Hummel (jehummel@cyrus.psych.uiuc.edu)
                                             Department of Psychology, 603 E. Daniel Street
                                                           Champaign, IL 61820
                               Abstract                                curved shape. That is, to adults and older children, the two
                                                                       curved shapes are more alike than the slightly curved shape
   Abecassis, Sera, Yonas, and Schwade (2001) have shown that          and the straight shape. Presumably the two curved shapes
   young children represent shapes more metrically, and perhaps        are more similar because they share the visual invariant
   more holistically, than do older children and adults. How does
                                                                       “curved”. By contrast younger children are more likely to
   a child transition from representing objects and events as
   undifferentiated wholes to representing them explicitly in
                                                                       say the slightly curved shape is like the straight shape,
   terms of their attributes—including invariant aspects of            presumably because it is metrically closer and they are
   objects’ shapes—and the relations among those attributes?           insensitive (or less sensitive) to the visual invariants
   According to recognition-by-components theory objects are           “curved” and “straight”. There is evidence for an analogous
   represented as collections of arranged geons. We propose that       “relational shift” in cognitive development, in which young
   the transition from more holistic to more categorical shape         children appear to process objects and events rather
   processing is a function of the development of geon-like            holistically but, as they develop and learn, gradually come
   representations. We present a model, DORA, that was                 to represent them in terms of independent objects, relations
   originally proposed to solve the problem of discovering
                                                                       and properties (see e.g., Gentner & Rattermann, 1991;
   relations, but can also learn representations of single geons
   from representations of multi-geon objects. We demonstrate
                                                                       Smith, 1989).
   that DORA follows the same trajectory humans do, originally            How does a child transition from representing objects and
   generalizing shape more holistically and eventually, after          events as undifferentiated wholes to representing them
   more learning, generalizing categorically.                          explicitly in terms of their attributes—including invariant
                                                                       aspects of objects’ shapes—and the relations among those
   Keywords: Shape bias, relation learning, relation discovery,
                                                                       attributes? This question is really two questions. The first
   development, computational modeling.
                                                                       is the question of how the invariant properties (e.g.,
                           Introduction                                “straight” vs. “curved” regardless of the degree of
                                                                       curvature) come to be detected from the holistic early visual
   Numerous studies have shown that both children and                  input (e.g., as in V1) in the first place. The second is the
adults apply similar labels to objects with similar shapes             question of how the child comes to notice that these
(e.g., Imai & Gentner, 1997; Landau, Smith, & Jones, 1988,             invariants remain constant across separate objects. That is,
1992; Smith, 1995; Woodward & Markman, 1998). This                     how does the child discover that the “straightness” of one
phenomenon is often referred to as the shape bias. There is            shape is, in some sense the same as the “straightness” of
considerable debate about the origins of the shape bias (see           another? In other words, how does the child predicate
e.g., Jones & Smith, 1993; Landau, Smith, & Jones, 1988,               straightness as an explicit property that retains its identity
1992; Woodward & Markman, 1998), but there are also                    across different instances? We argue that these processes,
questions about how children and adults can and do see two             discovery and predication, are necessary precursors to the
shapes as similar in the first place.                                  shift from reliance on metric representations of shape to
   Abecassis, Sera, Yonas, and Schwade (2001) have shown               representations based more on abstract visual invariants.
that young children represent shapes more metrically, and                 We present our early efforts at understanding the answer
perhaps more holistically, than do older children and adults.          to the second of these two questions. We present a model
For example, presented with a slightly curved shape, a much            that relies on the processes of analogical mapping and
more curved shape and a straight shape (i.e., where the                intersection discovery to highlight shared abstract properties
metric difference in curvature is smaller between the                  between separate systems (e.g., separate shapes) and
slightly curved shape and the straight shape than between              subsequently predicates these similarities as explicit (i.e.,
the slightly curved shape and the more curved shape), adults           symbolic) properties of the systems. Simulations suggest
and older children tend to choose the more curved shape,               that these basic processes may permit the discovery and
rather than the straight shape, as more like the slightly              predication of geon like representations from examples
                                                                  221

containing multiple goens. In addition, learning more                    relations we transition from more holistic to more
refined representations of geons leads to the more                       categorical shape generalization.
categorical (i.e., adult) processing of shapes observed by
Abecassis et al. (2001).                                                                     The DORA Model
                                                                            DORA (Doumas & Hummel, 2005; Doumas, Hummel &
               Recognition by components                                 Sandhofer, submitted) is a symbolic connectionist network
   As noted by Abecassis et al. (2001) the problem of                    that learns structured representations of relations from
learning to generalize shapes (i.e., understanding that two              unstructured inputs. DORA dynamically binds distributed
shapes are similar and so the same name should be applied                (i.e., connectionist) representations of relational roles and
to both) is similar to the problem of recognizing objects in             objects into explicitly relational (i.e., symbolic) structures.
the world.                                                               The resulting representations enjoy the advantages of both
   According to Biederman’s (1987; Hummel & Biederman,                   connectionist and traditional symbolic approaches to
1992) Recognition-by-Components (RBC) theory of object                   knowledge representation, while suffering the limitations of
recognition, adults visually represent objects in terms of a             neither (see Doumas & Hummel, 2005).
structural description that specifies the categorical relations             DORA was developed as a model of the discovery of
among an object’s parts. For example, a coffee mug would                 relational concepts. It has been used to simulate a wide
be represented as a curved cylinder (the handle) side-                   range of cognitive phenomena including the discovery of
attached to a vertical cylinder (the body). A bucket would               novel relational concepts, the trajectory of children’s
be represented as a curved top-attached to a vertical cylinder           relation learning, the idiosyncrasies of early relational
or truncated cone. The parts, in turn, are represented as                concepts the progressive-alignment effect, and adult relation
geons: classes of generalized cylinders1 that can be                     learning (see Doumas & Hummel, 2005; Doumas et al.,
discriminated from one another based on categorical                      submitted). In this paper we use DORA to simulate the
contrasts in their 3-D shape (which, in turn, can be detected            discovery of simple geons from multi-geon objects and the
based on non-accidental categorical contrasts in the object’s            development of the shape-bias in children and adults.
2-D image). For example, a cylinder has a curved cross                      DORA uses a hierarchy of distributed and localist codes
section, parallel sides and a straight major axis; a cone has a          to represent relational structures. This hierarchy is adapted
curved cross section, nonparallel sides and a straight major             from Hummel & Holyoak’s (1997, 2003) LISA model. At
axis; and a curved brick has a straight cross section, parallel          the bottom, “semantic” units represent the features of
sides and a curved major axis. Each geon is represented in               objects and roles in a distributed fashion. At the next level,
terms of its general aspect ratio (i.e., degree of elongation:           these distributed representations are connected to localist
very squat [e.g., like the lid of a jar]; somewhat squat [like a         units (POs) representing individual objects and relational
tuna can]; neither squat nor elongated [like a cube or ball];            roles. Localist role-binding units (RBs) link object and
somewhat elongated [like a soup can] or very elongated                   relational roles units into specific role-filler bindings. At the
[like a lamp post]), but importantly, a geon’s metric                    top of the hierarchy, localist P units link RBs into whole
properties (such as the precise degree of curvature of its               relational propositions (see Figure 1).
major axis or the precise shape of its cross section) are
otherwise completely left out of the description. The
resulting categorical structural descriptions are naturally
robust to variations in viewpoint and variations in an
object’s precise 3-D shape and thus provide a natural basis
for recognizing objects in novel viewpoints and for
recognizing different exemplars as members of the same
basic-level category (e.g., a Toyota Camry and a Mazda 626
have identical geon-based descriptions).
   If what allows us to recognize two objects as members of
the same category is our ability to process and represent the
geons that compose those objects, it follows that as we
develop more refined representations of geons and their                       Figure 1. Example of a proposition in DORA. Triangles
                                                                            are used to denote roles and circles to denote objects for
1
                                                                           clarity. In DORA, the same types of units code both roles
   A generalized cylinder is the 3-dimensional (3-D) volume                                        and objects.
produced by sweeping a 2-D shape (the cross-section) along an
axis in the third dimension. For example, sweeping a circle along
                                                                            At the most basic level, DORA uses analogical mapping
a straight axis produces a cylinder; sweeping the same cylinder
along the same axis while linearly reducing its size produces either     to isolate shared properties of objects and to represent them
a cone (if the circle eventually disappears into a point) or a           as explicit structures. When DORA maps one object or
truncated cone (if he circle never completely disappears); and           structure onto another, corresponding elements of the two
sweeping a rectangle along a curved axis results in a curved brick-      representations fire in synchrony. For example, if DORA
like shape.
                                                                     222

compares a mouse and a hummingbird, then the nodes                    3a). However, because only the essential “small” feature is
representing the mouse will fire in synchrony with those              common to both representations of “small”. When the two
representing the hummingbird (Figure 2). Consequently,                representations are compared the features they share will
any semantic features that are shared by both compared                become most active (Figure 3b). When a new PO learns
objects (i.e., features common to both the hummingbird and            connections to the active features (as described above) it is
the mouse) receive twice as much input as features                    most strongly connected to the feature “small” (the feature
connected to one but not the other. The network uses this             shared by both “small” representations) and less strongly
firing pattern to recruit a new PO unit that learns                   connected to the features idiosyncratic to either particular
connections to active semantics in proportion to their                representation (Figure 3c). In short, through a series of
activation via simple Hebbian learning (i.e., DORA learns             progressive comparisons DORA preserves what remains
stronger connections to more active units; Figure 2b). The            invariant across examples and discards everything else.
new PO thus becomes an explicit representation of the
featural overlap of the compared hummingbird and mouse.
So, in the case of comparing a hummingbird and a mouse,
the network might form an explicit predicate representing
“small” (and any other features they share, for example,
“animal”) due to their semantic overlap (Figure 2).
Importantly, this new PO acts as an explicit predicate
representation of the property small that can be dynamically
bound to fillers.2
                                                                        Figure 3. DORA learns a refined representation of “small”
                                                                       by comparing a two “dirty” representations of “small”. (a)
                                                                      When DORA compares a the two representations of “small”
                                                                        the units representing both become active simultaneously.
                                                                        (b) Feature units shared by both representations of “small”
                                                                            become more active (darker grey). (c) A new unit is
                                                                       recruited and learns connections to features in proportion to
                                                                          their activation (solid lines indicate stronger connection
                                                                         weights). The new unit codes the featural over-lap of the
     Figure 2. DORA learns a representation of “small” by              compared representations, or a more refined representation
  comparing a hummingbird and a mouse. (a) When DORA                                               of “small”.
         compares a hummingbird and a mouse the units
      representing both become active simultaneously. (b)                In the previous example DORA learned and refined an
   Feature units shared by both the hummingbird and mouse             explicit representation of the property small. In the example
      become most active (darker grey). (c) A new unit is             we used a single semantic unit to code the feature “small” in
 recruited and learns connections to features in proportion to        order to make the example easier to follow. However, what
    their activation (solid lines indicate stronger connection        is important about DORA’s operation is not what each
       weights). The new unit codes the featural over-lap             specific semantic unit codes, but that DORA’s learning
    hummingbird and mouse, or a “dirty” representation of             algorithm isolates and forms explicit representations of any
                              “small”.                                features shared by compared representations, whatever those
                                                                      features may be. Whether “small” is coded by a single
    Although the new predicates DORA learns are initially             feature unit or by a set of units, when DORA compares
“dirty” in that they contain extraneous features (e.g., in the        small things it will isolate and represent the features that are
previous example the representation of “small” also contains          invariant in small things (i.e., whatever is integral to being
the feature “animal”) through repeated iterations of the same         small) and discard other features. In other words through
learning process, DORA forms progressively more refined               progressive comparisons of examples of a concept, DORA
representations. For example, consider what happens when              will isolate the properties that are invariant across those
DORA compares the “dirty representation of “small” it                 examples and represent those properties with an explicit
learned in the previous example to another representation of          predicate that can take arguments. Given that there are
“small” it learned, say, by comparing a matchbook to a                invariant properties in the world and the human cognitive
playing card. Both representations of “small” contain the             system can detect them, DORA provides a means to learn
essential feature “small” and an extraneous feature (Figure           explicit structured representations of these properties.
                                                                                                Simulations
2
   DORA uses systematic asynchrony of firing to bind roles to
                                                                         We ran two simulations with DORA. In the first we
fillers (see Doumas & Hummel, 2005; Doumas et al., submitted).
As this is not important for the simulations reported here, we do
                                                                      simulated the development of representations of single
not discuss binding further in this paper.                            geons from representations of multi-geon objects. In the
                                                                  223

second we simulated the findings of Abecassis et al. (2001).          could discover which features define geons simply by
In these simulations we make a key assumption: We assume              observing examples of multi-geon objects.                 More
that metric and categorical attributes are represented by the         concretely, could DORA discover that the features straight
visual system independently of one another. That is, we               cross section, straight axis and parallel sides define bricks
assume that the visual system is capable of detecting                 and that curved cross section, straight axis and non-parallel
properties such as curved cross sections, straight cross-             sides define cones, simply by comparing objects composed
sections and parallel and non-parallel lines, and that these          of bricks, cones and other geons.
properties are represented independently of metric                       We then allowed three sets of comparisons. During the
properties like location in the visual field. This assumption         first set of comparisons (CS 1), we allowed DORA to
was predicted in the computational models of Hummel (e.g.,            compare multi-geon objects. Each set of multi-geon objects
Hummel & Biederman, 1992) and has been supported by                   that DORA compared contained at least one of the same
psychophysical experimentation (e.g., Stankiewicz, 2002).             geons. For example, DORA might compare the cone and
                                                                      brick in Figure 4a to the wedge and brick in Figure 4b.
Simulation 1                                                          When DORA compared these two objects it learned a
   To simulate the development of geon representations we             representation of what they had in common, namely, those
created 160 multi-geon objects. These objects consisted of            features essential to bricks (along with some extraneous
at 2 geons selected randomly from a pool of 7 geons                   features the two objects shared by chance). That is, the first
(including straight brick, curved brick, straight cone,               set of comparisons produced “dirty” representations of the
straight wedge, curved wedge, straight cylinder, and curved           geons.
cylinder; see Biederman, 1987). Examples of these stimuli                After CS 1 we began the second set of comparisons (CS
are presented in Figure 4. Each multi-geon object was                 2), during which we allowed DORA to compare the “dirty”
represented in DORA as a PO unit attached to 12 features.             representations of geons it had learned during CS 1 to other
Half of these features described invariant categorical                “dirty” representations of the same geon. For example,
properties of the geons that composed the object (e.g.,               DORA might compare one “dirty” representation of a brick
straight cross-section, parallel sides, curved axis-of-               to another “dirty” representation of a brick. This produced
symmetry, etc.). So, for example, the object consisting of            more refined representations of the geons.
the cone and the brick was attached to the categorical                   Finally, after CS 2 we began the third set of comparisons
features of a brick (e.g., straight cross-section, straight axis-     (CS 3) during which we allowed DORA to compare the
of-symmetry, parallel sides) and the categorical features of a        more refined representations of geons it had learned during
cone (e.g., curved cross-section, straight axis-of-symmetry,          CS 2 to other refined representations of the same geon. For
non-parallel sides). In addition, each object was also                example, DORA might compare one representation of a
attached to 6 features describing metric properties that were         cone it had learned during CS 2 to another representation of
chosen at random (i.e., the object’s location in the visual           a cone it had learned during CS 2. This produced even more
field or the degree of curvature).                                    refined representations of the individual geons.
                                                                         After each set of comparisons we tested the
                                                                      representations of individual geons that DORA had learned
                                                                      using a selectivity metric (SM). The SM was calculated for
                                                                      each object as the mean weight between that object and the
                                                                      features essential to the geon it represented (e.g., for a cone
                                                                      curved cross-section, straight axis-of-symmetry, non-
                                                                      parallel sides) divided by 1 + the mean weight between that
                                                                      object and all irrelevant features to which it was connected.3
                                                                      In short, the SM provided a metric of the refinement of the
                                                                      representation. The higher the SM of a representation of a
Figure 4. Examples of some multi-geon objects used during
                                                                      geon the more strongly that representation is connected to
                          simulation 1
                                                                      relevant features and the less strongly it is connected to
                                                                      irrelevant features.
   Importantly the features we use to code categorical and
                                                                         The SM results for the representations learned during
metric properties are features that can be detected by JIM
                                                                      each set of comparisons are presented in Table 1. During
from V1-like representations of objects. For example, JIM
                                                                      each set of comparisons DORA learned progressively more
can detect categorical features like “curved cross-section”
                                                                      refined representations of the six geons. Although this is,
and metric features like “x-coordinate=5”. However, JIM
                                                                      admittedly, a simplified case of learning, the simulation
does not learn which shape attributes are view-invariant,
                                                                      demonstrated that DORA’s learning algorithm designed for
and thus form the “definition” of a geon (e.g., that straight
                                                                      learning relations from examples is sufficient to learn
vs. curved major axis matters, whereas the exact degree of
                                                                      representations of individual geons from objects containing
axis curvature does not); rather this information was hand-
coded into the model’s operation.            As such in this          3
                                                                         One was added to the denominator to keep the SM a ratio
simulation we tested whether DORA’s learning algorithm
                                                                      between 0 and 1.
                                                                  224

multiple geons. With this in mind we proceeded to simulate       had learned during CS 1 of the previous simulation. So, for
the results of Abecassis et al. (2001).                          example, to represent the exemplar from the middle row
                                                                 middle column of Figure 5 we used the representation above
    Table 1. Simulation 1 results (SM = selectivity metric)      (curvedBrick1, curvedBrick2) where curvedBrick1 and
                                              SM                 curvedBrick2 were geons learned during simulation 1. To
     Initial representations                    .5               simulate adults we did the same thing only we constructed
           After CS 1                          .64               the exemplars using the geons that DORA had learned
           After CS 2                          .72               during CS 3 of simulation 1. In short, to simulate children
           After CS 3                          .84               we used messier representations of geons (those learned by
                                                                 DORA after less experience) and to simulate adults we used
                                                                 more refined representations of geons (those learned by
Simulation 2                                                     DORA after more experience. To simulate children we
                                                                 placed 6 representations of the sample items constructed
   In Experiment 2 of Abecassis et al. (2001) 4 year-old
                                                                 using CS 1 geons and 6 representations of random geons in
children and adults were presented with objects like those
                                                                 random configurations into LTM. To simulate adults we
depicted in the middle row of Figure 5a. These sample
                                                                 placed 6 representations of the sample items constructed
exemplars were given a novel label, for example “wug”.
                                                                 using CS 3 geons and 6 representions of random geons in
The participants were then given the other objects from
                                                                 random configurations into LTM.
Figure 5 one at a time and asked if these too were “wugs”.
                                                                    We ran 12 simulations each with 6 trials (the three bottom
While the objects in the bottom row where, on the whole,
                                                                 row trials and the three top row trials). On each trial we
more similar to the objects in the middle row in terms of
                                                                 allowed DORA used its representation of the test exemplar
metric properties, they differed on important categorical
                                                                 to retrieve previously viewed exemplars from its LTM.
features: The items in the middle row had curved axes of
                                                                 During retrieval the representation of the test exemplar
symmetry while those in the bottom row did not. On the
                                                                 became active and passed activation to representations in
other hand, the objects in the top row while less similar in
                                                                 LTM. As representations in LTM became active DORA
terms of metric properties to the objects in the middle row,
                                                                 used the Luce choice axiom to retrieve active LTM
but were more categorically similar in that they shared
                                                                 representations into working memory (WM). After two or
categorical features such as curved axis of symmetry.
                                                                 three exemplars had been retrieved into WM DORA attempt
                                                                 to map the representation of the test exemplar to the
                                                                 representations of the retrieved exemplars. During mapping
                                                                 the representation of the exemplar becomes active and
                                                                 passes activation to the representations of the retrieved
                                                                 exemplars which compete (via lateral inhibition) to become
                                                                 active. If one of the retrieved representations matches the
                                                                 test items better than the others (i.e., shares a higher
                                                                 proportion of its semantic units with the test exemplar) then
                                                                 it will become most active and DORA will map the two
                                                                 representations.      If DORA found a strong mapping
                                                                 correspondence, the test item was labeled a “wug”,
                                                                 otherwise (i.e., if DORA found no strong mapping) the test
                                                                 item was not labeled a “wug”.
                                                                    The results from Abecassis et al. (2001) and our
 Figure 5. Example of the stimuli used in the experiment by      simulation are presented in Figure 6. Like the children in
                      Abecassi et al. (2001).                    Abecassis et al.’s study, DORA with messier geon
                                                                 representations tended to generalize the name “wug”
   As noted previously, children generalized the name of the     roughly equally often to both exemplars from the top and
sample exemplars to the test exemplars in both the bottom        the bottom row. On the other hand, with more refined
row and the top row of Figure 5. Adults, on the other hand,      representations, DORA generalized the name “wug” much
generalized the name given to the sample exemplars much          more often to items from the top row than those from the
more frequently to the test exemplars from the top row. The      bottom. In short, with more experience DORA tended to
authors concluded that as children get older they become         generalize a name to more categorically similar objects than
more sensitive to invariant predictive properties (e.g.,         to more holistically similar objects, as people do. These
curvature) and less sensitive to over-all similarity.            simulation run using exactly the same settings and
   We simulated the adults and children in the above             parameters that we used to simulate several other finding in
experiment by varying the composition of the experimental        the literature (e.g., Dixon & Banart, 2003; Gentner & Namy,
stimuli presented to DORA. To simulate children we               1999; Kotovsky & Gentner, 1996; Smith (1984); Smith et
created all nine “wug” exemplars using the geons DORA
                                                             225

al., 1988; see Doumas et al., submitted). We did no                Dixon, J. A., & Bangert, A. S. (2004). On the spontaneous
parameter fitting and these results reflect DORA’s first run.        discovery of a mathematical relation during problem
                                                                     solving. Cognitive Science, 28, 433-449.
                                                                   Doumas, L. A. A., & Hummel, J. E. (2005). A symbolic-
                                                                     connectionist model of relation discovery. In B. G. Bara,
                                                                     L. Barsalou, & M. Bucciarelli (Eds.), Proceedings of the
                                                                     Twenty-Third Annual Conference of the Cognitive Science
                                                                     Society, 606-611. Mahwah NJ: LEA.
                                                                   Doumas, L. A. A., Hummel, J. E., & Sandhofer, C. M.
                                                                     (submitted). A theory of the discovery and predication of
                                                                     relational concepts.
                                                                   Gentner, D., & Namy, L. (1999). Comparison in the
                                                                     development of categories. Cognitive Development, 14,
                                                                     487-513.
                                                                   Hummel, J. E., & Biederman, I. (1992). Dynamic binding
                                                                     in a neural network for shape recognition. Psychological
                                                                     Review, 99, 480-517.
                                                                   Hummel, J. E., & Holyoak, K. J. (1997). Distributed
Figure 6. The experimental data from children and adults in          representations of structure: A theory of analogical access
           Abecassis et al. (2001) and from DORA.                    and mapping. Psychological Review, 104, 427-466.
                                                                   Hummel, J. E., & Holyoak, K. J. (2003) . A symbolic-
                          Discussion                                 connectionist theory of relational inference and
                                                                     generalization. Psychological Review, 110, 220-264.
   Through a process of iterative comparison, DORA                 Imai, M., & Gentner, D. (1997). A cross-linguistic study of
gradually comes to discover features that remain invariant           early word meaning: Univerasl ontology and linguistic
over instances of an object category (or concept). This              influence. Cognition, 62, 169-200.
process allows it to discover invariant object attributes and,     Jones, S. , & Smith, L.B. (1993). The place of perception in
to form representations of geon like structures. The                 children’s concepts. Cognitive Development, 8, 113-139.
resulting representations provide a natural account of the         Kotovsky, L., & Gentner, D. (1996). Comparison and
developmental shift in the shape bias described by                   categorization in the development of relational similarity.
Abecassis et al. (2001). This process may also provide a             Child Development, 67, 2797-2822.
basis for understanding how geons—clusters of co-occuring          Landau, B., Smith, L., & Jones, S. (1988). The importance
invariant features—are discovered by exposure to multi-              of shape in early lexical learning.              Cognitive
geon objects.                                                        Development, 3, 299-321.
   An important implication of the DORA model is that              Landau, B., Smith, L., & Jones, S. (1992). Syntactic
comparison is central to the development of representations          content and the shape bias in children’s and adult’s lexical
of geons and the transition from holistic to categorical             learning. Journal of Memory and Language, 31, 807-825.
representations of shape.       Thus, DORA predicts that           Smith, L. B. (1984). Young children’s understanding of
situations that invite comparison will provide rich contexts         attributes and dimensions. Child Development, 55, 363-
for developing categorical representations of shape. Such            380.
situations might include when two items share the same             Smith, L. B. (1989). From global similarities to kinds of
label, when the child is directed by an adult to compare, or         similarities: The construction of dimensions in
when items are in close spacial proximity.                           development. In S. Vosniadou and A. Ortoney (Eds.),
                                                                     Similarity and analogical reasoning (pp. 147-177).
                         References                                  Cambridge: Cambridge University Press.
                                                                   Smith, L. B. (1995). Self-organizing processes in learning
Abecassis, M., Sera, M. D., Yonas, A., & Schwade, J.                 to learn words: Development is not induction. In The
   (2001) What's in a Shape? Children represent shape                Minnesota Symposium of Child Psychology, Vol. 28,
   variability differently than adults when naming objects.          Basic and applied perspectives on learning, cognition, and
   Journal of Experimental Child Psychology, 78, 303-326.            development, 1-32. Mahwah, NJ: Erlbaum
Biederman, I. (1987).         Recognition-by-components: A         Smith, L. B., Rattermann, M. J., & Sera, M. (1988).
   theory of human image understanding. Psychological                “Higher” and “lower”: Comaprative interpretations by
   Review, 94 (2), 115-147.                                          children. Cognitive Development, 3, 341-357.
                                                               226

