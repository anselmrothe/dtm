A fine-grained understanding of emotions: Young children match within-valence
emotional expressions to their causes
Yang Wu (yangwu@mit.edu)1, Paul Muentener (Paul.Muentener@tufts.edu)2
Laura E. Schulz (lschulz@mit.edu)1
1

Department of Brain and Cognitive Sciences, MIT
77 Massachusetts Avenue, Cambridge, MA 02139 USA
2
Department of Psychology, Tufts University
490 Boston Avenue, Medford, MA 02155 USA
Abstract
Previous research suggests that the ability to make finegrained distinctions among emotions emerges gradually over
development. However, such studies have looked primarily at
children‚Äôs first-person responses to emotional expressions or
at whether children can match emotion labels to emotional
expressions. Relatively little work has looked at children‚Äôs
ability to link emotional responses to their probable causes.
Here we ask two, three, and four year-old children and adults
to identify the causes of vocal expressions. Because we were
interested in the ability to make nuanced distinctions, we
looked within a single valence and asked whether children
could distinguish expressions elicited by exciting, delicious,
adorable, funny, and sympathetic events. Our results suggest
both an early emerging ability to distinguish within-valence
emotions and rapid development; by four, children‚Äôs
performance mirrored that of the adults. This suggests that
very early in development, children have a rich representation
of emotions that allows them to link distinct positively
valenced emotional expressions to their probable causes.
Keywords: emotion understanding; causal reasoning; vocal
expressions; toddlers; preschoolers

Introduction
‚ÄúI recognize terror as the finest emotion and so I will try to
terrorize the reader. But if I find that I cannot terrify, I will
try to horrify, and if I find that I cannot horrify, I'll go for
the gross-out. I'm not proud.‚Äù -- Stephen King
‚Äúairy, amused, animated, beatific, blissful, blithe, bright,
brisk, buoyant, cheerful, cheery, comfortable, contented ‚Ä¶‚Äù
-- The beginning of a list of words for happiness, from:
//www.derose.net/steve/resources/emotionwords/ewords.ht
ml
Human beings have a sophisticated understanding of
emotions. Sufficiently sophisticated that English-speaking
adults in our culture can appreciate the distinction between
terror, horror, and disgust, and, more salubriously, the
distinction between feeling airy, amused, and animated. To
the degree that we make these distinctions, we represent not
only the meaning of these emotion words, but also the
expressions and vocalizations that might accompany them,
and the causes and contexts that might elicit them.
However, relatively little is known about the
development of this rich understanding of emotion. Studies

in infancy have focused primarily on babies‚Äô distinct
responses to positive and negative emotions. Thus for
instance infants have an augmented startle response when a
sudden noise is paired with an angry (versus neutral) face
and a reduced startle when it is paired with a happy face
(Balaban, 1995). Similarly social referencing studies show
that infants will approach novel toys and visual cliffs if their
caregiver displays a positive, encouraging expression but
withdraw if their caregiver displays a frightened, negative
expression (e.g. Klinnert, 1984; Kinnert, Emde, Butterfield,
& Campos, 1986; Mumme & Fernald, 2003; Mumme,
Fernald, & Herrera, 1996; Sorce, Emde, Campos, &
Klinnert, 1985). More recent work has shown that infants
expect an agent who has succeeded at its goal to express a
positive emotion rather than a negative emotion (Skerry &
Spelke 2014). By 18-months, children will use a recipient‚Äôs
emotional responses to food (i.e. happy or disgusted) to
offer the food she likes (Repacholi & Gopnik, 1997). These
suggest that infants distinguish positively and negatively
valenced emotion and that these representations are
structurally connected with their representations of goals
and desires in ways that allow them both to use emotions to
inform their own actions, and to use others‚Äô actions to
predict their emotions.
Other studies have attempted to tease apart infants‚Äô
responses to more subtle distinctions, including withinvalence emotions. However, the evidence for fine-grained
distinctions among emotions early in development is
relatively weak. Although some work on social referencing
suggests that infants are slightly more likely to cross the
visual cliff given if the parent displays a sad face than a
fearful or angry one (Sorce, Emde, Campos, & Killnert,
1985), this difference could be explained by the arousal
values of these emotions; sadness may be lower in arousal
than fear or anger, and thus its deterrent effect may be
weaker. Other studies have shown (in looking time studies
and in coding infants‚Äô own responses to the stimuli) that
infants can discriminate facial expressions including anger,
fear, and sadness (e.g., Haviland & Lelwica, 1987; Serrano,
Iglesias, & Loeches, 1992). Similar distinctions have been
shown for positive facial expressions (e.g., pure happiness
and happiness mixed with surprise; Ludemann, 1991).
Studies have also shown that infants can distinguish
congruent and incongruent pairings of emotional faces and
voices, and by 7-months, can discriminate emotions in

2685

either modality (e.g. Flom & Bahrick, 2007; Grossman,
Striano, & Friederici, 2006; Walker-Andrews, 1986). Neural
measures have also found for instance that infants generate
different EEG responses to angry and fearful faces (Hoehel
& Striano, 2008). However, although these methods speak
to infants‚Äô ability to distinguish cues to different emotions,
they fall short of telling us whether infants discriminate
emotions as such.
Stronger evidence that infants have rich internal
representations of emotions comes from studies of infants‚Äô
and toddlers‚Äô production of emotion (see Camras, Malatesta,
& Izard, 1991; Malatesta, Culver, Tesman, & Shepard, 1989
for reviews). However, infants‚Äô and toddlers‚Äô ability to
generate rich emotional responses in ways that adults
interpret as contextually appropriate may be distinct from
their ability to understand the kinds of events that elicit
different emotions.
Even studies in older children suggest a relatively
protracted development of emotion understanding. When
asked to label prototypical facial expressions with basic
emotion labels (i.e. happiness, sadness, fear, anger, surprise,
disgust; Ekman, 1992), two-year-olds generally use no
labels; over the next four years, children gradually add the
six basic emotion labels to their vocabulary (see Widen,
2013 for a review). This slow and gradual development has
also been found cross-culturally (Kayyal, Widen, & Russell,
2012). Other studies have found that children fail to
understand the relationship between beliefs and emotion
even well beyond the age at which children explicitly
understand false beliefs. For instance, children who are
capable of recognizing that Little Red Riding Hood falsely
believes her grandmother (rather than a wolf) is in the bed,
nonetheless inaccurately infer that Red Riding Hood is
scared (Bradmetz & Schneider, 1999). Findings like these
have led researchers to propose that early in childhood,
children begin with a very coarse model of emotion
(distinguishing only valence and arousal) and only gradually
infer a more elaborate, differentiated understanding (Widen
& Russell, 2008a; 2008b).
However the evidence for the relatively slow
development of children‚Äôs fine-grained distinctions in
emotions comes primarily from verbal tasks where children
are asked to match the meaning of words with emotional
faces or stories, or draw inferences that depend on relatively
advanced language facilities. In many domains of social
cognition, children have evinced sophisticated abilities
much earlier when tasks have depended less on verbal input.
Given recent evidence suggesting that in infancy and early
childhood, children evaluate prosocial and antisocial actions,
understand fair and unfair distributions of resources,
collaborate on joint goals, evaluate agents‚Äô competence and
incompetence, and expect members of social groups to
behave alike (e.g., Geraci & Surian, 2011; Hamlin, Wynn,
& Bloom, 2007; 2011; Hamlin, Ullman, Goodman,
Tenenbaum, & Baker, 2013; Jara-Ettinger, Tenenbaum, &
Schulz, in press; Powell & Spelke, 2013; Sloane,

Baillargeon, & Premack, 2012; Warneken, Lohse, Mellis, &
Tomasello, 2011), it would be surprising if young children
genuinely had no ability to make any nuanced distinction
within emotional valences.
How can we evaluate children‚Äôs sensitivity to fine-grained
distinctions among emotions? Asking children to
discriminate emotional expressions (as in many infancy
studies) is revealing about infants‚Äô ability to distinguish
emotions but not about their ability to understand them.
However, asking children to connect emotion words to
emotional expressions or emotional stories (as in many
studies with preschoolers) may tax children‚Äôs verbal
competence and underestimate their actual comprehension.
Here we introduce a new paradigm for assessing children‚Äôs
representations of emotions in early childhood. The
paradigm draws on the intuition that there are probabilistic
causal relationships between particular events and particular
emotional responses. Spoiled food generates a disgust
reaction; harm directed at an innocent victim generates
anger; precarious heights generate fear. By the same token,
fireworks generate excitement; cute babies generate
affection; and breathtaking landscapes generate awe. The
causal relationships are only true in probability; there may
be variability in individuals‚Äô responses. However, given
abundant research suggesting that very young children are
sensitive to evidence for causal relationships in other
domains (see Gopnik & Wellman, 2012; Schulz, 2012 for
review) it seems possible that children would also have
learned causal relationships between specific kinds of events
and specific emotional responses. Here we ask whether very
young children can connect emotional expressions to their
probable causes. We hypothesize that given a non-verbal
assessment of their emotion understanding, even young
children will make nuanced within-valence discriminations
much more accurately than previous research would suggest.
We presented the generative candidate causes of the
emotions pictorially; to avoid confusion, we therefore
elected to have the emotional responses be vocal
expressions rather than facial expressions. We anticipated
that children would have no difficulty registering the
different vocalizations since studies suggest that children are
proficient at distinguishing emotional cues in vocal
expressions (Flom & Bahrick, 2007; Grossman, Striano, &
Friederici, 2006; Sauter, Panattoni, & Happe, 2013; WalkerAndrews, 1986).
For the eliciting causes we chose five kinds of scenes.
These were chosen arbitrarily, constrained by three criteria:
a) all scenes had to elicit positively valenced emotions (to
avoid distressing the children); b) each kind of scene should
elicit what an adult would perceive as an emotional response
distinct from that elicited by any of the other four kinds, c)
the eliciting scenes had to be easy to portray and easy for
young children to recognize. From these criteria we
developed stimuli corresponding to funny, exciting,
adorable, sympathetic, and delicious events. (See Figure 1.)

2686

To ensure that the stimuli did indeed elicit natural and
distinctive emotional vocalizations, we asked two female
adults to look at each scene and respond as spontaneously as
possible, out loud, but without any words. (See Methods.)
Their vocalizations were recorded. We then paired each
vocal expression with two candidate causes (only one of
which was actually used to elicit the vocalization) and
looked at whether children (ages two to four) and adults
could link the vocalization with the eliciting cause of the
emotion. We predicted that, contradictory to previous
research, even young children could discriminate withinvalence emotional expressions and identify their causes.

Methods
Participants
Forty-eight children (mean age: 3.4, range: 2.0-4.9 years)
were recruited at a children‚Äôs museum: 16 were two-yearolds (mean age: 2.5, range: 2.0-2.9); 16 were three-year-olds
(mean age: 3.4, range: 3.0-3.9); and 16 were four-years-olds
(mean age: 4.5, range: 4.1-4.9). Although most of the
children were White and middle class, a range of ethnicities
and socioeconomic backgrounds reflecting the diversity of
the local population were represented. An additional eight
children were recruited but not included in the final sample
due to: (1) location biases (i.e. pointing to the left (or right)
pictures throughout the experiment; n=5); (2) refusal to
point (n=2); (3) getting distracted (i.e. playing with the
keyboard; n=1).
Fifty-eight adult participants were recruited on Amazon
Mechanical Turk (MTurk), a marketplace for online
workers. A range of ethnicities and socioeconomic
backgrounds reflecting the diversity of the marketplace were
represented. Each MTurk worker received $0.2 for
participating in this study.

Materials
Eliciting cause stimuli For each of the five kinds of
candidate causes we chose four pictures to create a full
stimulus set. For funny stimuli we chose children making
silly faces; for exciting stimuli we chose light-up toys; for
adorable stimuli we chose cute babies; for sympathetic
stimuli we chose crying babies, and for delicious stimuli we
chose desserts. All pictures were found online in Google
Image and cropped to the same image size. See Figure 1.
As noted, our primary selection criteria were that the stimuli
be easily recognizable by children and likely to generate
distinct positively valenced emotional responses in adults,.
Additionally however, to ensure that any observed effect
was relatively general, we wanted to include both objects
and people. We also wanted to ensure that any responses to
agents could not be explained as mimicry or emotional
contagion. The inclusion of crying babies was thus
particularly interesting because it would require children to
map a negative eliciting cause to a positive comforting
response. To the degree that children can do this, it would
suggest that children do not merely process the valence of

Figure 1 Eliciting cause stimuli. See text for details.

salient stimuli, but represent emotions within a causal
framework where they can link emotional responses to
probable causes, even across valence boundaries. Two
pictures that did not belong to any of the five target
categories (and that differed in valence from each other)
were used for a Warm-Up Trial: a picture of a beautiful
beach and a picture of a dying flower. See Figure 1.
Emotional Vocalization stimuli The set of twenty test
pictures and the two warm-up pictures were combined and
presented in random order to two female adults. The adults
were told that they could not use words, but that they should
look at each picture and vocalize their response. They
recorded their responses individually in a private room. We
selected one vocal response for each picture, using half the
vocalizations from one adult and half from the other. This
resulted in 20 test audio clips corresponding to the 20 test
pictures and 2 warm-up clips corresponding to the 2 warmup pictures (see http://web.mit.edu/yangwu/www/VocRes/).
Each vocal response was cropped to a two-second audio clip.
Stimulus Presentation Both the pictures and the vocal
responses were presented using Matlab and PsychToolbox
on a 15-inch laptop. A doll (height: 37 cm) and a white
cylinder-shaped speaker (diameter: 10 cm; height: 17 cm)
were also used. The speaker was connected to the laptop and
the doll was placed on the speaker so that when a vocal
response was played, it looked like the doll made the sound.
Each child saw one warm-up trial and 20 test trials. In
each test trial, a Matlab script was used to a) randomly
select two of the five categories; b) randomly choose one
picture from each of the two selected categories, and c)
randomly choose the vocal expression elicited by one of the
two pictures. The script also specified that each picture
would be presented in exactly two test trials: once as the
target and once as the distractor and each vocal expression
would be played on only a single test trial.
On each trial, the two pictures (13 cm √ó 9 cm) were
presented in both sides of the screen. The timing of the
presentation of the pictures and vocal expression was
triggered by pressing a button on the keyboard.
The presentation for adults used the same materials but a
slightly different script due to the technical constraints of
running online experiments with full picture-sound
randomization. There was no warm-up trial for adults and
adults had 10 test trials rather than 20. For the test-trials we

2687

Procedure
Children were tested individually in a private room at the
children‚Äôs museum. The laptop used for presenting the
stimuli was placed on a table. The laptop screen was about
40 cm from the child. The speaker was put in front of the
laptop, 8 cm from the child.
The experimenter first introduced the doll to the child:
‚ÄúHi, this is Sally! Today we‚Äôll play a game with Sally!‚Äù The
experimenter then placed the doll on the speaker, facing the
laptop screen.
Warm-up Trial The experimenter presented one picture on
the left side of the screen and said: ‚ÄúThis is a picture of a
beautiful beach. When Sally looks at it, she makes this
sound.‚Äù The experimenter surreptitiously pushed a button on
the keyboard and the sound actually recorded by the actor
on viewing the scene came from the speaker, where Sally
sat, so that it seemed that Sally produced the sound. The
experimenter then made the left picture disappear, and
presented a picture on the right side of the screen. The
experimenter said: ‚ÄúThis is another picture. It‚Äôs a dying
flower. When Sally looks at it, she makes this sound.‚Äù The
experimenter activated the other sound. The first sound was
a positive ‚ÄúOoh!‚Äù; the second, a negative ‚ÄúOhh.‚Äù (See Audio
File: Ooh & Ohh.) The experimenter then displayed both
pictures and introduced the game: ‚ÄúIn this game I will show
you two pictures. Sally will look at one of them and make a
sound. We will need to guess which picture Sally is looking
at. OK? I'll play the game first!‚Äù The experimenter played
the positive sound again, pointed to the picture of the beach,
and said: ‚ÄúWhen Sally makes this sound, I think she is
looking at the picture of a beautiful beach.‚Äù Then she played
the sad sound, pointed to the dying flower, and said: ‚ÄúWhen
Sally makes this sound, I think she is looking at this dying
flower.‚Äù During the entire warm-up phase, if the child
looked puzzled, got distracted, or asked to repeat any part of
the trial (e.g. to play the sound again), we repeated the part
of the presentation that the child may have missed, in order
to make sure that the child understood the procedure. Lastly,
the experimenter said: ‚ÄúNow it‚Äôs your turn to play the game!‚Äù
and started the test trials.
Test Trial On each test trial, the experimenter pushed a
button on the keyboard to trigger the presentation of two
pictures and said: ‚ÄúHere are two new pictures, and Sally
makes this sound.‚Äù Then she pushed a button on the
keyboard to trigger the vocalization. (The timing was
controlled by the experimenter but the choice of stimuli was
controlled by the Matlab script; see Stimulus Presentation.)
She asked the child: ‚ÄúWhich picture do you think Sally is
looking at?‚Äù If the child made no response, the experimenter

played the sound again and said, ‚ÄúDo you think Sally is
looking at this picture [pointing to the left picture] or this
picture [pointing to the right picture]? Do you want to
point?‚Äù If the child still made no response after a subsequent
prompt, the experimenter skipped that trial and moved on to
the next trial. If the child skipped three trials successively,
or asked to stop, we terminated the experiment. On average,
two year-olds completed 15.1 trials; three-year-olds
completed 18.4 trials and four-year-olds completed 19.0
trials. The three groups differed significantly in the number
of trials completed (F(2)=3.898, p=.027). Two-year-olds
completed fewer trials than four-year-olds (Tukey‚Äôs HSD
tests, p=.033); two-year-olds and three-year-olds did not
differ from each other (p=.085); three-year-olds and fouryear-olds did not differ from each other (p=.908). The
percentage of correct responses for each child was
computed only for the completed trials. The entire
experiment took less than three minutes.
The adult participants were tested online. Adults were
told that the vocal expression in each trial was someone‚Äôs
response when looking at one of the pictures and their task
was to guess which picture the person was looking at when
she made the sound. Participants were also told that they
could replay the sound as often as needed on each trial by
clicking a button.

Results
Participants correctly matched the vocal expression to its
causes significantly above chance in all age groups (twoyear-olds: M=.60, SD=.142, 95% CI [.52, .67], t(15)=2.745,
p=.015, d=.10; three-year-olds: M=.68, SD=.194, 95% CI
[.57, .78], t(15)=3.637, p=.002, d=.18; four-year-olds:
M=.90, SD=.055, 95% CI [.88, .93], t(15)=29.589, p<.001,
d=.40; adults: M=.87, SD=.177, 95% CI [.82, .91],
t(57)=15.704, p<.001, d=.37; One-Sample T Test, twotailed). See Figure 2.

Accuracy

randomly sampled two pictures from each of the five
categories and used these to generate a randomly ordered set
of 10 picture pairs. Half the adults were given the vocal
expression corresponding to one picture in each pair in the
set; the other half of the adults were shown the same set of
pictures but given the vocal expression corresponding to the
other picture in each pair.

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
2 year-olds 3 year-olds 4 year-olds

Adults

Figure 2 Response accuracy in each age group. Error bars indicate SEM.

A 4√ó5 mixed-design analysis of variance was conducted
on participants‚Äô responses with the age group as the
between-subjects factor and the emotion category as the
within-subjects factor. Only the effect of age was significant
(F(3,102)=15.794, p<.001, ùúÇùëù2 =.32); there was no main
effect of category (F(4, 408)=2.116, p=.078, ùúÇùëù2 =.02) or
interaction (F(12, 408)=1.025, p=.424, ùúÇùëù2 =.03). The
performance of two and three-year-olds did not differ from
each other (Tukey‚Äôs HSD tests, p=.525), but both age
groups differed from four-year-olds and adults (all ps<.001).

2688

Accuracy

Four-year-olds performance was comparable to adults
(p=.831). See Figure 3.
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Funny

Exciting

2 year-olds

Adorable

3 year-olds

Sympathetic

Delicious

4 year-olds

Adults

Figure 3 Response accuracy by category in each age group. Error
bars indicate SEM.

Accuracy

The effect of age is apparent in looking at the
performance of individual children: 12.5% of two-year-olds,
31.3% of three-year-olds, 100% of four-year-olds performed
above chance. See Figure 4.
These results suggest that some sensitivity to relatively
fine-grained distinctions among positive emotional
expressions emerges as early as two and three. However, as
evident in Figure 4, children also undergo rapid
developmental change. By four, children achieve adult-like
performance on this task. Overall, children‚Äôs performance
was not specific to any set or subset of these stimuli;
children succeeded whether the eliciting causes were
animate or inanimate, and succeeded even when they had to
map a stimulus expressing negative emotion to a positive
response.
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1.5

2

2.5

3

3.5

Age (years)

4

4.5

5

5.5

Figure 4 The response accuracy of each child as a function of age.
Error bars indicate SEM.

Discussion
We found that children as young as two and three had an
emerging ability to discriminate within-valence emotional
expressions, and, at least in the context of a simple twovariable forced choice task, use these expressions to identify
their probable causes. By four, children‚Äôs performance on
our task had already reached adult levels.
As noted, even infants discriminate emotional facial
expressions (e.g. Serrano, Iglesias, & Loeches, 1992), match
emotional facial and vocal expressions (e.g. Flom &
Bahrick, 2007) and exhibit different behavioral responses to
different emotional expressions (e.g. Klinnert, 1984).
However, although these abilities might serve as bases for
understanding emotions, the results themselves do not rule

out low-level explanations for infants‚Äô performance. Infants
might detect differences at the level of facial features, or
learn behavioral responses to characteristic expressions
without any understanding or representation of the
underlying emotions. In our task, however, the underlying
emotion is the only link between the vocal expressions and
the elicitors. There are probabilistic causal relationships, but
no surface cues that conjoin an exciting toy to an expression
of delight or a crying baby to an expression of sympathy.
Our finding that children not only distinguish relatively
subtle gradations in emotions within valence but also map
them onto probable causes is however, consistent with more
recent research suggesting that even infants can match
emotions appropriately to eliciting causes (i.e., anticipating
positive responses for goal completion; Skerry & Spelke,
2014). Future research might look at whether the ability to
draw more nuanced distinctions within valences emerges in
younger toddlers and infants.
Future studies could also investigate the underlying
mechanisms supporting this ability. One possibility is that
children themselves experience an emotional response to the
elicitors, simulate the emotional expression they would
make, and compare this simulation with the vocal
expression they hear in order to identify the appropriate
mapping between the candidate cause and the vocalization.
A second possibility is that children have observed others
responding to similar cues in similar ways in the past and
have learned stable associations between the events. We
refer to causes rather than ‚Äúassociations‚Äù throughout
because a wealth of research suggests that children readily
infer causal relationships from data when they see evidence
for plausible causal relationships (see Gopnik & Wellman,
2012, Schulz, 2012, and Tenenbaum, Kemp, Griffiths, &
Goodman, 2011, for reviews); here however the point is
only that children might originally learn the mappings from
statistical input in their environment. A final possibility is
that children have an abstract representation of the kinds of
stimuli and events that elicit emotions and the kinds of
emotional expressions linked to those emotions. For
example, they might represent that humorous events
generate amusement and amusement generates characteristic
vocalizations. Given that studies in other domains (e.g.,
intuitive physics) suggest that mental simulation, statistical
associations, and abstract causal theories mutually inform
each other to support commonsense judgment (Battaglia,
Hamrick, & Tenenbaum, 2013), these accounts may not be
mutually exclusive. Critically however for our purposes, all
of these accounts require children to draw relatively finegrained distinctions between emotional responses.
If
children collapsed across different positive emotions, or
responded only to the valence and arousal of emotional
expressions, they could not reliably make nuanced
mappings either for themselves or for others.
Finally, we realize that there may be some dispute about
the degree to which we want to think of the response to any
of these eliciting causes as an emotional response per se. We
might say we feel ‚Äúexcited‚Äù on seeing the light-up toy or

2689

‚Äúamused‚Äù when we see the silly faces, but there is no simple
emotion label that captures what we feel when we see a cute
baby (endeared? affectionate?), a crying baby (sympathetic?
tender?), or delicious food (delighted? anticipatory?). We
believe this speaks more to the impoverished nature of our
emotion labels than to the absence of emotional responses to
our stimuli. Patently, people often have strong emotional
responses both to babies (adorable or distressed) and to food.
Although, as our opening quotations illustrate, there are
myriad emotion words in English, the proliferation of
emotion words is not a cross-cultural universal (e.g., Lutz,
1982) and the words that we have may fail to capture
anything like the full richness of human emotional
experience. However, the current results suggest that some
of that richness can be captured non-verbally and may be
accessible, even to very young children.

Acknowledgments
This material is based upon work supported by the Center for Minds,
Brains and Machines (CBMM), funded by NSF STC award CCF-1231216.

References
Balaban, M. T. (1995). Affective Influences on Startle in Five‚ÄêMonth‚ÄêOld
Infants: Reactions to Facial Expressions of Emotion. Child
Development, 66(1), 28-36.
Battaglia, P. W., Hamrick, J. B., & Tenenbaum, J. B. (2013). Simulation as
an engine of physical scene understanding. Proceedings of the
National Academy of Sciences, 110(45), 18327-18332.
Bradmetz, J., & Schneider, R. (1999). Is Little Red Riding Hood afraid of
her grandmother? Cognitive vs. emotional response to a false belief.
British Journal of Developmental Psychology, 17(4), 501-514.
Camras, L. A., Malatesta, C., & Izard, C. E. (1991). The development of
facial expressions in infancy. Fundamentals of nonverbal behavior, 1,
73-105.
Ekman, P. (1992). An argument for basic emotions. Cognition & emotion,
6(3-4), 169-200.
Flom, R., & Bahrick, L. E. (2007). The development of infant
discrimination of affect in multimodal and unimodal stimulation: The
role of intersensory redundancy. Developmental psychology, 43(1),
238.
Geraci, A., & Surian, L. (2011). The developmental roots of fairness:
Infants‚Äô reactions to equal and unequal distributions of resources.
Developmental science, 14(5), 1012-1020.
Gopnik, A., & Wellman, H. M. (2012). Reconstructing constructivism:
Causal models, Bayesian learning mechanisms, and the theory theory.
Psychological bulletin, 138(6), 1085.
Grossmann, T., Striano, T., & Friederici, A. D. (2006). Crossmodal
integration of emotional information from face and voice in the infant
brain. Developmental Science, 9(3), 309-315.
Hamlin, J.K, Ullman, T., Tenenbaum, J., Goodman, N., & Baker, C. (2013).
The mentalistic basis of core social cognition: experiments in preverbal
infants and a computational model. Developmental science, 16(2), 209226.
Hamlin, J. K., Wynn, K., & Bloom, P. (2007). Social evaluation by
preverbal infants. Nature, 450(7169), 557-559.
Hamlin, J. K., Wynn, K., Bloom, P., & Mahajan, N. (2011). How infants
and toddlers react to antisocial others. Proceedings of the national
academy of sciences, 108(50), 19931-19936.
Haviland, J. M., & Lelwica, M. (1987). The induced affect response: 10week-old infants' responses to three emotion expressions.
Developmental Psychology, 23(1), 97.
Hoehl, S., & Striano, T. (2008). Neural Processing of Eye Gaze and
Threat‚ÄêRelated Emotional Facial Expressions in Infancy. Child
development, 79(6), 1752-1760.

Jara-Ettinger, J., Tenenbaum, J. B., & Schulz, L. E. (in press). Not so
innocent: Toddlers' reasoning about costs, competence, and culpability.
Psychological Science.
Kayyal, M. H., Widen, S. C., & Russell, J. A. (2012). Palestinian and
American children‚Äôs understanding of facial expressions of emotion.
Manuscript in preparation.
Klinnert, M. D. (1984). The regulation of infant behavior by maternal facial
expression. Infant Behavior and Development, 7(4), 447-465.
Klinnert, M. D., Emde, R. N., Butterfield, P., & Campos, J. J. (1986).
Social referencing: The infant's use of emotional signals from a
friendly adult with mother present. Developmental Psychology, 22(4),
427.
Ludemann, P. M. (1991). Generalized Discrimination of Positive Facial
Expressions by Seven‚Äêand Ten‚ÄêMonth‚ÄêOld Infants. Child
Development, 62(1), 55-67.
Lutz, C. (1982). The domain of emotion words on Ifaluk. American
ethnologist, 9(1), 113-128.
Malatesta, C. Z., Culver, C., Tesman, J. R., Shepard, B., Fogel, A., Reimers,
M., & Zivin, G. (1989). The development of emotion expression
during the first two years of life. Monographs of the Society for
Research in Child Development, i-136.
Mumme, D. L., & Fernald, A. (2003). The infant as onlooker: Learning
from emotional reactions observed in a television scenario. Child
development, 74(1), 221-237.
Mumme, D. L., Fernald, A., & Herrera, C. (1996). Infants' responses to
facial and vocal emotional signals in a social referencing paradigm.
Child Development, 67(6), 3219-3237.
Powell, L. J., & Spelke, E. S. (2013). Preverbal infants expect members of
social groups to act alike. Proceedings of the National Academy of
Sciences, 110(41), E3965-E3972.
Repacholi, B. M., & Gopnik, A. (1997). Early reasoning about desires:
evidence from 14-and 18-month-olds. Developmental psychology,
33(1), 12.
Sauter, D. A., Panattoni, C., & Happ√©, F. (2013). Children's recognition of
emotions from vocal cues. British Journal of Developmental
Psychology, 31(1), 97-113.
Schulz, L. (2012). The origins of inquiry: Inductive inference and
exploration in early childhood. Trends in cognitive sciences, 16(7),
382-389.
Serrano, J. M., Iglesias, J., & Loeches, A. (1992). Visual discrimination
and recognition of facial expressions of anger, fear, and surprise in 4‚Äê
to 6‚Äêmonth‚Äêold infants. Developmental Psychobiology, 25(6), 411425.
Skerry, A. E., & Spelke, E. S. (2014). Preverbal infants identify emotional
reactions that are incongruent with goal outcomes. Cognition, 130(2),
204-216.
Sloane, S., Baillargeon, R., & Premack, D. (2012). Do infants have a sense
of fairness?. Psychological science, 0956797611422072.
Sorce, J. F., Emde, R. N., Campos, J. J., & Klinnert, M. D. (1985).
Maternal emotional signaling: Its effect on the visual cliff behavior of
1-year-olds. Developmental psychology, 21(1), 195.
Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman, N. D. (2011).
How to grow a mind: Statistics, structure, and abstraction. science,
331(6022), 1279-1285.
Walker-Andrews, A. S. (1986). Intermodal perception of expressive
behaviors: Relation of eye and voice?. Developmental Psychology,
22(3), 373.
Warneken, F., Lohse, K., Melis, A. P., & Tomasello, M. (2011). Young
children share the spoils after collaboration. Psychological Science,
22(2), 267-273.
Widen, S. C. (2013). Children‚Äôs interpretation of facial expressions: The
long path from valence-based to specific discrete categories. Emotion
Review, 5(1), 72-77.
Widen, S. C., & Russell, J. A. (2008a). Young children‚Äôs understanding of
other‚Äôs emotions. In M. Lewis & J. M. Haviland-Jones (Eds.),
Handbook of emotions (pp. 348‚Äì363). New York, NY: Guilford.
Widen, S. C., & Russell, J. A. (2008b). Children acquire emotion
categories gradually. Cognitive Development, 23, 291‚Äì312. doi:
10.1016/j.cogdev.2008.01.002

2690

