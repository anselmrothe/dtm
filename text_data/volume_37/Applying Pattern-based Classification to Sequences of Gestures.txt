                  Applying Pattern-based Classification to Sequences of Gestures
                                          Suzanne Aussems (s.aussems@warwick.ac.uk)
                                            Department of Psychology, University of Warwick
                                          University Road, Coventry CV4 7AL, United Kingdom
                                               Mingyuan Chu (mingyuan.chu@mpi.nl)
                                                 Max Planck Institute for Psycholinguistics
                                            PO Box 310, 6500 SH Nijmegen, the Netherlands
                                                 Sotaro Kita (s.kita@warwick.ac.uk)
                                            Department of Psychology, University of Warwick
                                          University Road, Coventry CV4 7AL, United Kingdom
                                     Menno van Zaanen (mvzaanen@tilburguniversity.edu)
                                 Tilburg center for Cognition and Communication, Tilburg University
                                             PO Box 90153, 5000 LE Tilburg, the Netherlands
                              Abstract                                  though the frequency of gestures might be the same among
   The pattern-based sequence classification system (PBSC)
                                                                        people with different levels of empathy, these people may or-
   identifies regularly occurring patterns in collections of se-        der different types of gestures, most notably interactive ges-
   quences and uses these patterns to predict meta-information.         tures (i.e., conduit and palm-revealing gestures) in different
   This automated system has been proven useful in identifying          ways. That is, in some situations more information might be
   patterns in written language and musical notations. To illus-
   trate the wide applicability of this approach, we classify sym-      hidden in frequencies of gesture sequences than in frequen-
   bolic representations of speech-accompanying gestures pro-           cies of single gestures.
   duced by adults in order to predict their level of empathy. Pre-
   vious research that focused on isolated gestures has shown              Previous studies on cross-linguistic differences in speech-
   that the frequency and salience with which individuals pro-          accompanying gestures (see Kita (2009) for a review) sug-
   duce certain speech-accompanying gestures are related to em-         gested that looking at gesture sequences may be fruitful.
   pathy. The current research extends these analyses of sin-
   gle gestures by investigating the relationship between the fre-      For instance, in verb-framed languages such as Turkish and
   quency of multi-gesture sequences of speech-accompanying             Japanese, path information is expressed in one clause and
   gestures and empathy. The results show that patterns found in        manner information in another clause, in contrast to English,
   multi-gesture sequences prove to be more useful for predict-
   ing empathy levels in adults than patterns found in single ges-      in which manner and path are expressed in a single clause.
   tures. This paper thus demonstrates that sequences of gestures       The verb “rolling down” is expressed in one clause in En-
   contain additional information compared to gestures in isola-        glish, but it takes two clauses (e.g., “rolling/spinning” and
   tion, suggesting that empathic people structure their gestural
   sequences differently than less empathic people. More impor-         “descending/downwards path”) to express this verb in Turk-
   tantly, this study introduces PBSC as an innovative, effective       ish and Japanese. Research has shown that such linguistic
   method to incorporate time as an extra dimension in gestural         structures influence the ways in which gestural communica-
   communication, which can be extended to a wide range of se-
   quential modalities.                                                 tion is structured (Özyürek & Kita, 1999; Kita & Özyürek,
                                                                        2003). Whereas Turkish and Japanese speakers tend to use
   Keywords: Grammatical inference; speech-accompanying
   gestures; empathy; pattern-based sequence classification.            one gesture to depict the rolling movement, and one gesture
                                                                        to depict its downward path, English speakers tend to depict
                                                                        manner and path in a single gesture. These studies suggest
                           Introduction                                 that in some languages, multi-gesture sequences depict one
People naturally accompany their speech with gestures. Sev-             event, and accordingly, that the order in which people pro-
eral studies have reported results indicating that gesture type,        duce gestures alongside their speech may follow particular
frequency, and salience are related to personality traits, cogni-       patterns.
tive abilities, and empathy levels (Hostetter & Alibali, 2006;             There may be other sequential regularities present in
Chu & Kita, 2011; Hostetter & Potthoff, 2012; Chu, Meyer,               speech-accompanying gestures. For example, different types
Foulkes, & Kita, 2014). For example, Chu et al. (2014) found            of gestures represent different types of information in nar-
that empathy (i.e., how much people think about other peo-              rative, and these gestures may be ordered in a systematic
ple’s thoughts and feelings) predicts the frequency of ges-             way. Representational gestures often accompany speech with
tures with an interactive function, that is, conduit and palm-          “narrative-level” information, which is about events and situ-
revealing gestures. Whereas previous studies mainly looked              ations in the story (e.g, “A cat is looking at a canary bird in
at the frequency of isolated gestures, the current research             a cage.”). Beat gestures often accompany speech with “meta-
aims to extend these analyses to sequences of gestures. Even            narrative-level” information (McNeill, 1992) which refers to
                                                                    124

the structure of the story (e.g., “The cat tries to catch the ca-            Pattern-Based Sequence Classification
nary bird in different ways, but he never succeeds.”). Interac-       Pattern-based sequence classification (henceforth PBSC) is
tive gestures (Bavelas, Chovil, Lawrie, & Wade, 1992) often           an approach that aims to identify patterns in longer sequences
accompany speech with “para-narrative-level” information,             of symbols. The patterns describe regularities found in se-
which refers to the interactive exchange between the speaker          quences that come from the same class. Given a sequence,
and the listener (e.g., “Do you know one of these American            PBSC uses the identified patterns to assign the sequence to
cartoons?”). These types of information may be ordered in             the class it belongs to. This approach stems from the field of
a particular way in narrative; for example, a cluster of meta-        grammatical inference, which addresses the task of building
narrative utterances may be followed by a long sequence of            a compact representation of a class given a subset of sample
narrative utterances. This would in turn lead to systematic           sequences from that class (van Zaanen & Gaustad, 2010). In
patterns in sequences of gestures. Manually annotating such           contrast to other grammatical inference systems, PBSC aims
regularities in gestural communication is very time consum-           to learn a representation that describes the boundaries be-
ing and inefficient, which is why it is important to investigate      tween multiple classes (corresponding to the number of em-
if such regularities can be identified automatically.                 pathy levels in the current study), allowing for the classifica-
   In this paper we propose a pattern-based classification ap-        tion of sequences into their corresponding class. This is done
proach to extend the analyses of single gestures to multi-            by extracting patterns in the shape of sub-sequences, i.e., con-
gesture sequences. In order to demonstrate the applicability          secutive symbols, from the sequences in the training dataset.
of the system, we use empathy scores as meta-information to           For practical purposes, patterns have a predetermined, fixed
classify the gesture sequences. Empathy may be related to             length (although combinations of different pattern lengths are
the ways in which people structure information during con-            possible as well) which coincides with the notion of n-grams,
versation (people with high empathy levels may order in-              where n defines the length of the pattern (Heaps, 1978). The
formation in ways that are more helpful to the listener than          system only retains and uses patterns that are deemed use-
people with low empathy levels), which may result into par-           ful according to some “usefulness” measure or scoring met-
ticular sequences of gestures. To our knowledge, this is the          ric. A sequence can then be classified into a class based on
first study that uses a pattern-based learning system to iden-        which patterns are found in the sequence and the scores of the
tify regularly produced sequences of speech-accompanying              matching patterns.
gestures and relates these to empathy. We hypothesize that
                                                                      System Walk-Through
multi-gesture patterns predict empathy levels in adults better
than information extracted from isolated gestures.                    PBSC, like other supervised classification systems, involves
                                                                      a training and a testing phase. During training, the system
   Our classification approach is based on an existing pattern-
                                                                      receives a collection of sequences that are labeled with its
based learning system (van Zaanen & Gaustad, 2010). This
                                                                      underlying class. First, from these sequences, all possible n-
system has proven to be useful in identifying patterns in sev-
                                                                      gram patterns (n consecutive symbols) are extracted and for
eral sequential modalities, including semantics in written lan-
                                                                      each pattern the scoring metric is calculated indicating how
guage (van Zaanen & van de Loo, 2012) and musical nota-
                                                                      well the pattern fits each of the possible classes. This results
tions (van Zaanen, Gaustad, & Feijen, 2011). Our main aim
                                                                      in a set of patterns with a score for each class. These patterns
is to demonstrate the wide applicability of the PBSC system.
                                                                      can be seen as vectors in a multi-dimensional space with one
In this paper, we show the effectiveness of the system in the
                                                                      dimension per class. Summing pattern vectors for each oc-
context of gestural communication.
                                                                      currence in a sequence results in a vector that describes the
   The methodology we use is similar to that of Schmid,               sequence in the vector space. Second, based on the patterns,
Siebers, Seuß, Kunz, and Lautenbacher (2012), who use a               all training sequences are inserted in the vector space (and
pattern-based sequence classifier to predict pain levels with         their correct class is known).
patterns in action units that describe facial expressions. Their         During testing, the system needs to assign a class to a new,
approach requires manual tuning of the learned patterns and           unseen sequence. First, the system builds a vector for the
can only make a distinction between two classes (pain or no           sequence using the patterns. Next, it identifies the vector (of
pain). In contrast, our system can be applied without man-            the training sequences) that has the lowest cosine distance to
ual intervention and can make distinctions between any pre-           the vector of the test sequence. The class belonging to the
selected number of classes, which correspond to different lev-        training vector is returned. This corresponds to a k-nearest
els of empathy in the current study. Classifying into only            neighbor approach (Cover & Hart, 1967) with k = 1.
two classes (high and low empathy) may be insufficient, be-
cause it leads to greater variability in people’s empathy levels      Scoring Metric
within a class. Our system’s ability to increase the number of        During training, the system aims to identify patterns that are
classes results in more specific information about the empa-          maximally discriminative between classes. Patterns that oc-
thy level of a person, which utilizes the uniqueness in gesture       cur frequently in a class are assigned a high score for that
sequences that people produce. We proceed by describing our           class compared to patterns occurring less frequently in that
system in more detail in the next section.                            class, because frequent patterns describe sequences from that
                                                                  125

class better than less frequent patterns. Additionally, pat-                                        Data
terns that occur only in sequences in a particular class are          We used the dataset developed by Chu et al. (2014), which
more discriminative compared to sequences occurring in all            represents a sample of 122 English native speakers (71 fe-
classes. The combination of these properties are described            male, 51 male) with a mean age of 19.41 years (SD = 4.85).
in a well-known scoring metric taken from the field of infor-         This dataset contains a total of 11,032 annotated speech-
mation retrieval: tf*idf (Sparck Jones, 1972). This measure,          accompanying gestures elicited by description tasks (for more
which is extended to handle patterns (van Zaanen & Gaus-              information see Chu et al. (2014). In addition, participants
tad, 2010), consists of two components: term frequency (tf )          were tested on several cognitive abilities and their level of
which measures the relative frequency of the pattern and in-          empathy. Here, we focus on the relationship between the ges-
verse document frequency (idf ) which measures the discrim-           tures participants produced alongside their speech and their
inative power of the pattern over all classes. The tf is defined      level of empathy.
as the relative frequency of the pattern with respect to the to-
tal number of patterns found in the sequences belonging to            Empathy Quotient
that class. The idf is the logarithm of the total number of           In the study by Chu et al. (2014), the Empathy Quotient ques-
classes divided by the number of classes containing the pat-          tionnaire (Baron-Cohen & Wheelwright, 2004) was used to
tern. Thus, tf*idf provides a score describing the discrimina-        measure the empathy levels of adult participants. This in-
tive power of the pattern with respect to each class.                 strument comprises 40 questions related to empathy (e.g., “In
                                                                      a conversation, I tend to focus on my own thoughts than on
                                       ni, j
                           tf i, j =                                  what my listener might be thinking”) and 20 filler questions
                                     ∑k nk, j                         unrelated to empathy (“I prefer animals to humans”). Par-
                                                                      ticipants were instructed to rate how strongly they agreed or
                                           |C|                        disagreed with each statement (agree strongly, agree slightly,
                   idf i = log
                                  |{c ∈ C : ti ∈ c}|                  disagree slightly, or disagree strongly). On each item of the
                                                                      task, participants scored 2 points if the response reflected
                       tf*idf i, j = tf i, j × idf i                  empathy strongly, 1 point if the response showed empathy
                                                                      slightly, or 0 points if the response did not show empathy at
   Here, ni, j describes the number of occurrences of pattern ti      all. A total score was computed to indicate the level of empa-
in class c j and C denotes the set of classes under considera-        thy of each participant, with a maximum score of 80.
tion.
   Note that a pattern that occurs frequently in a particular         Data Representation
class has a higher tf score compared to the classes in which          In the dataset, each gesture was annotated with information
the pattern occurs less frequently. However, the tf score of          about its semantics, salience, and handedness. For the in-
a pattern is weighted by the idf component. Patterns occur-           put of our PBSC system, we extracted this information and
ring in all classes will have a zero idf value, in contrast to        converted it into three distinct datasets of symbolic gesture
patterns occurring in fewer classes, which will have higher           sequences. First, the semantics of the gestures was denoted
idf values. Patterns that have a tf*idf score of zero for all         by seven unique symbols that provided information about the
classes (because they occur in all classes) are not retained, as      different types of gestures, such as representational gestures,
they are useless for classification purposes. Note that when          beat gestures, and palm-revealing gestures, unclear represen-
no matching patterns are found, the system falls back on a            tational gestures, representational gestures specifically used
majority class baseline. This baseline measurement leads the          for indexing the listener, unclear gestures in general, and ges-
system to classify a sequence into the class that occurs most         tures that did not belong to the mentioned categories. Sec-
frequently in the training data.                                      ond, the level of salience of the gestures was denoted by four
   The length of the patterns has impact on the tf*idf scores as      symbols indicating the part of the arm that was used to pro-
well as their practical usefulness in classification. In general,     duce the gesture (finger, forearm, hand, or whole arm). Third,
short patterns occur more frequently in both training and test-       handedness was represented by three symbols that included
ing data. On the one hand, during training, very short patterns       information about whether speakers gestured with their right
are likely to occur in all classes, leading to zero scores. On        or left hand, or with both hands. In addition to the denotations
the other hand, it is more likely to find a short pattern (with       of the latter two gesture representations, we also incorporated
non-zero tf*idf score) in the test data compared to a very long       information (five unique symbols) about gestures that were
pattern (corresponding to a very specific sequence of sym-            produced with the arm only, feet, legs, torso, and head.
bols). This means that (depending on the amount of training
data available), there is a sweet spot in which a specific pat-       Classification Tasks
tern length performs best. Previous research has shown that           The PBSC system assigns participants to an empathy level
the best results are often found with pattern lengths of three        class based on pattern occurrences in the (sequences of) ges-
or four symbols (van Zaanen & Gaustad, 2010; van Zaanen               tures they produce. Having a partition of two classes cor-
et al., 2011).                                                        responds to classifying into high or low empathy classes,
                                                                  126

whereas three classes corresponds to low, mid, or high em-             performance was not affected by the symbolic representation
pathy classes. To define empathy-level classes, we first di-           of the gestures.
vided the range of empathy scores from all participants by                In Figure 1, horizontal lines represent the classification
the number of classes to obtain the size of sub-range of em-           accuracy when the system used information extracted from
pathy scores for each class, and then classified participants          single gestures (n = 1). The other lines illustrate the clas-
into the different empathy-level classes. For example, when            sification accuracy when the system used gesture sequences
the class size was two, participants who scored anywhere be-           (n = 2, 3, 4, 5, or 6). As can be seen, increasing the number
tween the minimum and the minimum + (maximum – min-                    of classes to classify into (illustrated in the different panels)
imum) / 2 were classified into the low-empathy level class,            leads to lower accuracy scores overall, which is an artifact of
and the rest, into the high-empathy level class. The gesture           the system.
sequences produced by participants with empathy scores be-                The ANOVA revealed a significant interaction effect be-
longing to the same class were considered example sequences            tween pattern length and classification task on classification
from that class. We varied the number of classes in the par-           accuracy, F(20) = 7.901, p < .001. Tukey’s HSD compar-
tition from two to six, which resulted in five classification          isons indicated that when the system classified participants
tasks. During testing, gesture sequences produced per par-             into two or three classes of empathy, varying pattern lengths
ticipant were classified and the performance of the system             did not affect classification accuracy significantly. This is due
was measured by classification accuracy (percentage of par-            to the fact that the idf has limited impact in these situations.
ticipants classified in the correct empathy level class based          In fact, when classifying into two classes, the system often
on their gesture sequences). Note that it is expected that the         falls back on the majority class baseline. When participants
overall system performance will decrease as the number of              were assigned to four classes, the PBSC system that used se-
classes increases, because increasing the number of classes            quences of three or more gestures to predict adults’ empathy
has an impact on the number of class boundaries that PBSC              levels outperformed the PBSC system that used single ges-
should learn, which makes the classification task harder. At           tures (p < .001). Additionally, the classification accuracy of
the same time, relatively less training data is available per          the system was significantly higher when using sequences of
class when the number of classes is increased (as the partici-         three or more gestures than when extracting information from
pants are divided over the classes available). In contrast, the        sequences of two gestures (p = .009 for n=3, p < .001 for
idf factor in the scoring metric performs better with a high           all other pattern lengths). This indicates that long patterns
number of classes (with two classes, only one non-zero idf             lead to higher classification accuracy than short patterns. Pat-
value is available, with six classes, five distinct idf values are     tern lengths had an effect when participants were classified
available).                                                            into five classes: the system that used sequences of two or
                                                                       more gestures to predict empathy outperformed the system
Comparison of Results                                                  that used single gestures (p < .001). It is not surprising that
In order to show that sequences of gestures provide more in-           a significant pattern length effect was found for these classi-
formation about empathy levels than single gestures, we need           fication tasks. With a high number of classes to classify into,
to compare the performance of the PBSC system using longer             the idf weight is more useful (for all pattern lengths), allow-
patterns (n = 2, 3, 4, 5, or 6) with the performance of the            ing for a more fine-grained weighing of the corresponding tf
PBSC system using single gestures (n = 1). Thus, our analy-            score. Increasing the number of classes even more, leads to
sis includes six pattern lengths.                                      a decrease in amount of training (and testing) data per class,
    The accuracy of the system was measured through 10-fold            which is why we found no interaction effect when partici-
cross-validation. This procedure involves randomly breaking            pants were classified into six classes of empathy. When the
up the dataset into ten folds of equal size and subsequently           number of classes is higher than five, the amount of training
training the system based on nine of these folds to test on the        data per class becomes too small to accurately find patterns
tenth (unseen) fold. This process is then repeated until all ten       in sequences of gestures. With the amount of data available
folds have been tested once and a mean accuracy is computed            from the dataset developed by Chu et al. (2014), the sweet
for the system’s performance.                                          spot seems to lie around four or five empathy-level classes
                                                                       and sequences of three or more gestures. When more data
                            Results                                    is available, we expect that a higher number of classes and
                                                                       longer pattern lengths lead to even better classification re-
The accuracy of classification by the PBSC (0–100%) was                sults.
entered in a 3 (gesture representation) x 5 (classification
task) x 6 (pattern length) ANOVA. The results revealed no                             Conclusion & Future Work
main effect of gesture representation on system performance,
F(2) = 0.251, p = .778. Moreover, gesture representation did           PBSC is a pattern-based classification approach, which has
not significantly interact with the other two variables in the         proven to be useful in predicting meta-information in a range
design. Thus, it did not matter if a gesture was described             of sequential modalities (e.g., written language, musical no-
based on its semantics, salience, or handedness; the system            tations). To contribute to the wide applicability of the PBSC,
                                                                   127

                                                             Symbol types       Semantics           Salience       Handedness
                                         2                      3                           4                            5                      6
                            80
  Classification accuracy
                            60
                            40
                            20
                                 2   3   4   5   6   2   3      4   5       6   2     3     4   5      6       2    3    4      5   6   2   3   4   5   6
                                                                                    Pattern length
Figure 1: Accuracy of classifying participants into empathy-level classes based on their gesture sequences (y-axis), using 10-
fold cross-validation. The analyses were split based on the different gesture representations (symbol types), pattern length
(x-axis), and classification tasks (different panels). Horizontal lines represent classification accuracy with single gestures.
we demonstrate that the approach can also be successfully                                   sults indicated that they are related to each other in time. The
used in the context of gestural communication. As a practi-                                 PBSC identified this information and successfully used it to
cal example, we examined the relationship between patterns                                  predict empathy levels in adults.
in sequences of speech-accompanying gestures produced by                                       Previous research has shown that gestures are shaped in
adults and their level of empathy.                                                          part by speakers’ desire to communicate information clearly
   We found that patterns describing sequences of gestures                                  to their listeners (Hostetter, Alibali, & Schrager, 2011). Em-
provide more discriminative power compared to patterns de-                                  pathy levels may be related to the ways in which people struc-
scribing single gestures when predicting empathy levels of                                  ture information in conversation. Speech-accompanying ges-
gesturing participants. That is, the relative frequency of                                  tures are related to information threads in the flow of the con-
multi-gesture patterns predicted participants’ empathy scores                               versation. Speakers with a high empathy level may think
better than the relative frequencies of gestures in isolation.                              more about how well the listener can follow the conversa-
This was the case for all three symbolic gesture representa-                                tion and structure the order of information, accordingly. This
tions: semantics, salience, and handedness. We found evi-                                   may lead to specific patterns gesture sequences because dif-
dence for this when comparing symbol patterns consisting of                                 ferent types of gestures are associated with different types
one symbol with longer patterns. The differences lie within                                 of utterances (e.g., representational gestures with narrative
the tasks in which participants were classified into four or                                utterances and beat gestures with meta-narrative utterances
five empathy classes, because these classification tasks pro-                               (McNeill, 1992)). Our results suggest that empathic people
vided the system with enough training data in each class to                                 structure their gestural communication at the discourse level
allow for optimal discriminative power of the idf component                                 in ways that are different from less empathic people.
of our scoring metric. This, in turn, led to more pronounced                                   Several directions for future work may be considered.
differences between the patterns. When classifying into four                                First, an in-depth, qualitative analysis of the patterns may be
classes, we found additional evidence that long patterns con-                               carried out to investigate, for instance, whether differences
tain more information than short patterns, as patterns of two                               are caused by clustering of certain types of gestures at vari-
symbols were outperformed by longer patterns. We conclude                                   ous points in narrative and/or systematicities in the use of in-
that gestures are not produced in isolation; in fact, our re-                               teractive gestures alongside speech. The most discriminative
                                                                                      128

patterns between the classes could provide insight into which        Hostetter, A. B., & Alibali, M. W. (2006). Raise your hand if
gesture sequences are typical for a particular empathy level.          you’re spatial: Relations between verbal and spatial skills
Second, PBSC allows for alternative gesture representations,           and gesture production. Gesture, 7(1), 73-95.
for instance, combining representations of different aspects         Hostetter, A. B., Alibali, M. W., & Schrager, S. M. (2011).
of a gesture into one complex symbol. This can be used to              If you don’t already know, I’m certainly not going to show
investigate the relative importance of different aspects of ges-       you! Motivation to communicate affects gesture produc-
tures. Third, a cross-linguistic comparison may be interest-           tion. In G. Stam & M. Ishino (Eds.), Integrating gestures:
ing. Information provided in multi-pattern gesture sequences           The interdisciplinary nature of gesture. Amsterdam, The
might become more pronounced in, for instance, Turkish and             Netherlands: Benjamins.
Japanese conversations, because in these languages certain           Hostetter, A. B., & Potthoff, A. L. (2012). Effects of person-
aspects of motion events in gesture are more often sequential-         ality and social situation on representational gesture pro-
ized than in English. Fourth, the relationship between multi-          duction. Gesture, 12(1), 62-83.
gesture sequences and other personality traits than empathy          Kita, S.     (2009).     Cross-cultural variation of speech-
or particular cognitive abilities can also be investigated. Fi-        accompanying gesture: A review. Language and Cognitive
nally, we believe that the PBSC approach can be applied to             Processes, 24(2), 145-167.
many other situations that deal with the classification of sym-      Kita, S., & Özyürek, A. (2003). What does cross-linguistic
bolic sequences (e.g., the visual, auditory, and motor sensory         variation in semantic co-ordination of speech and gesture
domains).                                                              reveal? Evidence for an interface representation of spatial
                                                                       thinking and speaking. Journal of Memory and Language,
                    Acknowledgments                                    48(1), 16-32.
This research was supported by an Economic and Social Re-            McNeill, D. (1992). Hand and mind. Chicago: University of
search Council Grant RES-062-23-2002 granted to Sotaro                 Chicago Press.
Kita and Antje Meyer. We thank Antje Meyer for allow-                Özyürek, A., & Kita, S. (1999). Expressing manner and path
ing the use of the dataset. Our gratitude goes to Farzana              in English and Turkish: Differences in speech, gesture, and
Bhaiyat, Christina Chelioti, Dayal Dhiman, Lucy Foulkes,               conceptualization. In M. Hahn & S. Stoness (Eds.), Pro-
Rachel Furness, Alicia Griffiths, Beatrice Hannah, Sagar               ceedings of the 21st Annual Conference of the Cognitive
Jilka, Johnny King Lau, Valentina Lee, Zeshu Shao, Callie              Science Society (p. 507-512). Mahwah, NJ: Erlbaum.
Steadman, and Laura Torney for their help with data col-             Schmid, U., Siebers, M., Seuß, D., Kunz, M., & Lauten-
lection and coding. We thank Birmingham City University,               bacher, S. (2012). Applying grammar inference to iden-
Bishop Vesey’s Grammar School, City College Birmingham,                tify generalized patterns of facial expressions of pain. In
CTC Kingshurst Academy, and University College Birming-                J. Heinz, C. de la Higuera, & T. Oates (Eds.), Proceedings
ham for their participation in our research.                           of the 11th International Conference on Grammatical In-
                                                                       ference. Heidelberg: Springer.
                          References                                 Sparck Jones, K. (1972). A statistical interpretation of term
Baron-Cohen, S., & Wheelwright, S. (2004). The Empathy                 specifity and its application in retrieval. Journal of Docu-
   Quotient: An investigation of adults with Asperger syn-             mentation, 28(1), 11-21.
   drome or high functioning autism, and normal sex differ-          van Zaanen, M. (2000). ABL:Alignment-Based Learn-
   ences. Journal of Autism and Developmental Disorders,               ing. In Proceedings of the 18th International Confer-
   34(2), 163-175.                                                     ence on Computational Linguistics (COLING) (p. 961-
Bavelas, J. B., Chovil, N., Lawrie, D. A., & Wade, A. (1992).          967). Saarbrücken, Germany.
   Interactive gestures. Discourse Processes, 15(4), 469-489.        van Zaanen, M., & Gaustad, T. (2010). Grammatical In-
Chu, M., & Kita, S. (2011). The nature of gestures’ beneficial         ference as Class Discrimination. In J. Sempere & P. Gar-
   role in spatial problem solving. Journal of Experimental            cia (Eds.), Grammatical Inference: Theoretical Results and
   Psychology: General, 140(1), 102-116.                               Applications. Berlin/Heidelberg: Springer.
Chu, M., Meyer, A., Foulkes, L., & Kita, S. (2014). In-              van Zaanen, M., Gaustad, T., & Feijen, J. (2011). Influ-
   dividual differences in frequency and saliency of speech-           ence of Size on Pattern-based Sequence Classification. In
   accompanying gestures: The role of cognitive abilities and          P. van der Putten, C. Veenman, J. Vanschoren, M. Israel,
   empathy. Journal of Experimental Psychology, 143(2),                & H. Blockeel (Eds.), Proceedings of the 20th Dutch Con-
   694-709.                                                            ference on Machine Learning (p. 53-60). The Hague, The
Cover, T., & Hart, P. (1967). Nearest neighbor pattern classi-         Netherlands.
   fication. IEEE Transactions on Information Theory, 13(1),         van Zaanen, M., & van de Loo, J. (2012). Learning Interpre-
   21-27.                                                              tations Using Sequence Classification. In J. Heinz, C. de la
Heaps, H. (1978). Information Retrieval: Computational and             Higuera, & T. Oates (Eds.), Proceedings of the Eleventh In-
   Theoretical Aspects. Orlando, FL: Academic Press.                   ternational Conference on Grammatical Inference (p. 220-
Hostetter, A. B. (2011). When Do Gestures Communicate? A               223). Washington, DC.
   Meta-Analysis. Psychological Bulletin, 137(2), 297-315.
                                                                 129

