    Active learning as a means to distinguish among prominent decision strategies
                Paula Parpart (paula.parpart.10@ucl.ac.uk), Eric Schulz (eric.schulz.13@ucl.ac.uk),
            Maarten Speekenbrink (m.speekenbrink@ucl.ac.uk) & Bradley C. Love (b.love@ucl.ac.uk)
                    Department of Experimental Psychology, University College London, London, WC1H 0AP
                              Abstract                                cues to make decisions, as the most powerful cue Ck can out-
   A long-standing debate in decision making has been whether
                                                                      weigh any combination of the subsequent cues Ck+1 , . . . ,Ck+n
   people rely on very little information for making choices, or      (Gigerenzer & Goldstein, 1999). Both strategies are known
   weigh and add all available information. We propose a new          to perform best in matching environments that have the same
   method to determine whether a non-compensatory (Take-The-          properties, i.e., WADD performs best in a compensatory envi-
   Best) or compensatory strategy (Logistic Regression) is more
   psychologically plausible: by looking at peoples active learn-     ronment and TTB in a non-compensatory environment (Mar-
   ing queries. This method goes beyond traditional model selec-      tignon & Hoffrage, 1999).
   tion techniques as it reveals the information people choose to
   learn early on, which subsequently drives their decisions. We      Traditional model testing approaches
   developed active learning algorithms for both Take-The-Best
   and Logistic Regression, and designed an active learning ex-       The dispute over the two model classes is about their psycho-
   periment to distinguish between these models. By letting both      logical plausibility as models for human decision making. A
   models and humans actively learn, we could compare their           repeated argument has been that non-compensatory strategies
   queries, and found that people follow a rank-based learning
   strategy in non-compensatory environments, but prefer more         are simpler and require less computational capacity and are
   certainty-based queries in compensatory environments. We           therefore more plausible (Todd & Gigerenzer, 2000). Yet,
   argue that active learning studies provide a promising new         the most common method of pitting compensatory and
   methodology to distinguish among decision models.
   Keywords: Decision Making, Heuristics, Active Learning,            non-compenastory strategies against each other have been
   Take-The-Best                                                      statistical simulations, showing that one outperforms the
                                                                      other in artificial environments. For example, multiple
                          Introduction                                studies show that the simpler TTB can outperform the
How do we decide between two alternatives? This question              compensatory linear regression (Czerlinski et al., 1999) in
is as fundamental to research in judgment and decision mak-           various datasets. In contrast, other studies show that there is
ing as its answer is controversial (Todd & Gigerenzer, 2000).         no strong reason to prefer TTB over other cognitive models
Whereas some cognitive scientists believe that people only            as it does not perform noticeably better (Chater et al., 2003;
require a few pieces of information to come up with good              Schulz et al., 2014).
decisions (Marewski et al., 2010), others have described hu-          All of these studies argue about the predictive accuracy of
mans as integrating all the evidence for both alternatives to         cognitive models; nevertheless - just because one class of
make a decision (Arkes et al., 1986) . One of the core ques-          models can beat another with better predictions, it does not
tions in this debate concerns the way in which people look up         follow that this class is necessarily a better psychological
and integrate information.                                            representation of what people actually do. Although whole
Imagine you have to decide between two restaurants to go for          research paradigms are dedicated to solving the question
lunch. Both restaurants differ on several binary cues (for ex-        about whether people rely on simpler non-compensatory
ample, one is in walkable distance, the other is not). One            heuristics or complex integrative mechanisms, different
decision strategy you could apply is to weigh the cues by             methodologies currently in use to answer this question are
their importance and add them up; this is called a weighted           scarce and homogeneous. Another method has been probing
additive linear model (Payne et al., 1993, WADD). For each            whether participants look up additional information (Newell
restaurant, WADD would compute a weighted sum, and the                et al., 2003). This is only a limited approach to the problem
restaurant with the larger sum is chosen. Alternatively, peo-         at hand since it is only ever possible to check for k + 1
ple might prefer a simpler strategy and base their decision           look-ups given Ck cues presented so far and it has been
only on one cue. This is what the Take-The-Best heuris-               argued that people look up additional information but do not
tic (Gigerenzer & Goldstein, 1996, TTB) does: it creates a            use it (Marewski & Mehlhorn, 2011).
ranking order of the cues according to their validities, and
chooses the restaurant that is preferred by the highest ranked           We propose active learning as a novel method to solve the
cue. If that cue does not discriminate between restaurants,           dilemma of discriminating among compensatory and non-
then the second cue is considered, and so forth. WADD is a            compensatory strategies as psychologically plausible deci-
compensatory strategy, whereas TTB is a non-compensatory              sion models. What most of the previous studies have in com-
strategy. Compensatory strategies have the property that a            mon is that they study peoples decision making in static, pas-
cue can be compensated for by combinations of subsequent              sive and highly controlled experiments. In order to answer the
cues and regression is a typical examples thereof. In contrast,       crucial question about what information people hold in mem-
the non-compensatory Take-The-Best heuristic ignores most             ory and how they look up knowledge when making decisions,
                                                                  1829

we believe one has to look at an earlier stage in the process        to the queries made by participants in an active learning task
–at the stage of learning the relevant information in the first      with pairwise comparisons. By letting people freely choose
place. We argue that stronger evidence for peoples use of ei-        among pairwise comparisons, we can investigate whether
ther TTB or a WADD strategy comes from the way people                people pick information such that they learn about cue or-
actively acquire information, i.e. cue weights and cue orders,       ders, or instead learn cue weights directly as proposed by the
in the respective environments. If a cognitive agent has evolu-      active WADD strategy.
tionarily developed to prefer a certain class of models as her
means to learn a cognitive representation in a particular en-                         Active learning algorithms
vironment, then the way she sequentially selects information         Both active learning algorithms essentially rely on a one-step
should (at least partially) reflect this representation. For ex-     ahead greedy entropy minimization of their posterior esti-
ample, if an agent has come to apply TTB, then -intuitively-         mates. Greedy algorithms always choose as the next observa-
she should try to find the most important cue first as this will     tion that which currently promises to reduce the uncertainty
decrease her uncertainty maximally, and so forth. Using this         about the learning model maximally.
way of re-creating the structure of a cognitive mechanism,
it becomes possible to set up active learning algorithms for         Take-The-Best
many different cognitive models over time.                           The active learning algorithm for the Take-The-Best heuris-
                                                                     tic is based on a entropy reduction method that considers a
Active Learning: Do people learn with respect to                     distribution over all possible cue orders. Therefore, we gen-
cue weights or cue orders?                                           erated all possible cue orders given the features, including
The main idea of psychological theories of active learning           those where some cues are unimportant or negatively corre-
is to describe a learning agent as optimally designing exper-        lated with the outcome1 . Afterwards, we put a uniform prior
iments (Chaloner & Larntz, 1989). That is, given that one            over the cue orders via pseudo counts. Pseudo counts here
has to find the true hypothesis out of many potential explana-       can be seen as urns, where the number of balls represents
tions as fast as possible, an agent assigns prior probabilities      the current probability of a given order. The way we assess
to each hypothesis according to some objective criterion such        (Shannon’s) entropy is by standardizing the balls per cue or-
as the available frequency data or according to the subjec-          der via the sum of all balls. Using the resulting values as a
tively judged plausibility of each hypothesis. Each possible         probability density distribution, our algorithm predicts new
outcome of any possible experiment can thus be considered,           cases by generating a TTB output for each of the cue orders
and a “preposterior analysis” (Raiffa & Schlaifer, 1961) of          and then estimating the overall mean, weighted by every cue
the ways in which each possible experimental outcome could           order’s current probability. Using this approach, we can eas-
modify beliefs about the hypothesis, can be conducted. The           ily estimate the probability for a new test item to be a win or
proposals for optimal experimental design (OED) work in              a loss and calculate the expected reduction in entropy over all
an information gain-driven fashion and maximize an infor-            cues given a new training item. Entropy can be reduced via
mational utility, which is typically a measure of how much           some cue orders generating correct predictions and thereby
beliefs have changed or how large the uncertainty reduction          getting more counts on their pseudocounts. This is possible
is. There has been a great deal of interest in both norma-           as our model updates all cue orders that made correct pred-
tive and descriptive questions surrounding human informa-            citions at time point t by adding one more ball to their urns
tion acquisition. In a probabilistic framework, many OED             at time point t + 1. The addition of balls will –over time–
models have been used to model human behavior on cogni-              put more and more probability mass on the true cue order and
tive tasks such as feature learning (Griffiths & Austerweil,         thereby gradually reduce uncertainty. The used distribution
2009), reward-specific information search (Meder & Nelson,           over all possible cue orders can also be seen as a distribu-
2012), and to assess the trade-off between exploration and ex-       tion over the whole hypothesis space. The way our algorithm
ploitation (Knox et al., 2011).                                      then works is by the attempt to drive down the uncertainty
In this current study, we want to assess to what extent dif-         of this hypothesis space as quickly as possible, an approach
ferent OED models match participants’ behavior in an ac-             that is close to optimal in a Bayesian active learning context
tive learning experiment, but with the goal of distinguishing        (Golovin et al., 2010)2 .
among decision models. We specifically designed the per-
fect environments for both model classes, i.e., a fully non-         Logistic Regression
compensatory environment for TTB, and a fully compen-                Logistic regression is set up as a competing compensatory
satory environment for logistic regression (WADD strategy),          model to the non-compensatory TTB model. We use a
and several environments in between these extremes. As there         Bayesian version of logistic regression based on a random
are no active learning counterparts to the two decision mod-         walk Metropolis MCMC algorithm. Again, the way the algo-
els yet, we focus on qualitative predictions. Consequently, we       rithm works is by maximizing the expected information gain
developed two entropy-minimizing learning algorithms, one                1 This results in a very complex hypothesis space that increases
for a cue-ranking strategy and one for a cue-weighing strat-         exponentially with the number of features.
egy. Next, we compare the models’ a priori search queries                2 A technical description can be found in the appendix online.
                                                                 1830

for each trial. However, as a logistic regression does not learn                            Used Compensatoriness
cue orders, the expected information gain is approximated by                   10.0   ●
the combined variance of all weights, the β-estimates. This
means that a Bayesian logistic regression is fitted to all past                       ●
observations and the current variance for all βs is calculated                  7.5
and then compared to the variances that could be expected                             ●
from a newly fit model given a new input. This uncertainty
sampling-based algorithm provides us with a compensatory
                                                                           w    5.0
active learning algorithm for the scenarios at hand. Instead of                       ●
trying to drive down the hypothesis space as quickly as possi-
ble, this algorithm tries to learn about the weights as precisely
as possible in order to make good compensatory judgments.                       2.5   ●         ●
                                                                                                ●
                                                                                                              ●             ●
                                                                                                              ●
            Degrees of Compensatoriness                                                         ●
                                                                                                              ●
                                                                                                                            ●
                                                                                                                            ●
                                                                                                              ●
                                                                                0.0             ●             ●             ●
We are interested in the performance of the two proposed ac-
                                                                                      1         2             3             4
tive learning models in environments with different “compen-                                          Wn
satoriness”. Note that a non-compensatory environment can
be defined as a WADD environment in which the β weights
                                                                     Figure 1: Compensatoriness for five different levels of θ. The
are exponentially decreasing. In order to create different de-
                                                                     x-axis represents four different cues and the y-axis displays
grees of “compensatoriness”, we make use of a mathematical
                                                                     the weight magnitudes.
trick that allows us to rely on a single parameter to smoothly
vary from compensatory to non-compensatory environments
through a “stick breaking process”. The generation would be          by the active Take-The-Best algorithm, while logistic regres-
of a set of 4 weights β4k=1 through:                                 sion would better match their choices in the compensatory
                                                                     environments.
                         β0k ∼ Beta(1, θ)                     (1)    Participants
                    Define   {β0k }4k=1   as:                 (2)    Two hundred and sixty-four (N = 264) participants (M = 35.4
                                   k−1                               years) were recruited via Amazon Mechanical Turk to take
                         βk = β0k ∏ (1 − β0i )                (3)    part in the “Alien Olympics” study. Participants were paid
                                   i=1                               $0.50 for participation plus an additional bonus between $0
                                                               α
                                                                     and $0.5 depending on their performance.
As the expectation of the Beta-distribution is defined as α+θ    ,
a perfect Take-The-Best environment corresponds to setting           Materials and Stimuli
θ to 1 or greater as this would lead to a perfectly non-             On each trial, participants had to choose a pair of Aliens
compensatory weight structure. Given the strict boarder of           to compete against each other, in order to learn about their
θ = 1 that separates compensatory from non-compensatory              strengths. The Aliens varied on four different features, which
strategies, we will use θ = [ 0, 0.5, 1, 2, ∞] for all the upcom-    are displayed in Figure 2. The features were designed to be
ing scenarios as this generates degrees of compensatoriness          helpful in fights, e.g., wings enabled an Alien to fly which
starting from uniform weights (θ = 0) all the way to an envi-        helps in attacking enemies, while camouflage is useful for
ronment where only one cue matters (θ = ∞). Figure 1 shows           defense. The features were explained to participants at the
the weighting structures that result from simulating different       start and they were told that the different characteristics might
levels of compensatoriness for four cues by increasing θ.            not all be of equal importance for an Alien’s strength in a
                                                                     fight. As there are four features, we generated all possi-
                        Experiment                                   ble feature combinations which results in 16 different Alien
The experiment was designed to find out whether people               types. On each trial, participants were presented with four
are more likely to follow a rank-based or a weight based             random Aliens on the screen, and had to choose two of these
active learning algorithm. The outcome has strong impli-             to compete against each other. After selecting a pair, they
cations for either decision mechanism as plausible decision          received feedback about which Alien had won the compe-
strategies. We hypothesized that people are sensitive to the         tition. They were also told that sometimes a weaker Alien
structure of the environment (the degree of compensatori-            could win against a stronger competitor as in any sport, which
ness) in their choice of learning algorithms. We assigned            reflects the probabilistic generation of the actual outcomes.
people randomly to one of the five above-mentioned com-              The underlying weights of the four features that people could
pensatoriness conditions. We expected participants in the            learn depended on the compensatoriness condition a partici-
more non-compensatory environments to be better matched              pant was in. Importantly, we emphasized that people should
                                                                 1831

pick their Aliens wisely by selecting informative comparisons        Results
out of the presented Aliens, as the goal was to learn how the        Participants’ performance at identifying the stronger Aliens
different features influenced an Aliens chances to win. Partic-      during the test stage was highly above chance; the aver-
ipants were informed that they would need this feature knowl-        age percentage of correct choices made was 74% (t(263) =
edge later in the experiment for an assessment task. The ac-         27.44, p < 0.001) with a range of (30%,97%). Performance
tual outcomes observed in feedback were generated by using           varied as a function of the compensatoriness condition that
the weights from the respective compensatoriness conditions          participants were in. Figure 3 represents the average score as
(standardized to always add up to 10) and applying logistic          a function of compensatoriness: as the environmental struc-
regression in order to determine an Alien’s strength, or likeli-     ture gets more non-compensatory (i.e. more weight on just
hood of winning against another Alien.                               a few cues), the average performance drops. This intuitively
                                                                     makes sense as there is less information to be learned when
Procedure
                                                                     a cue dominates all others, which makes draws more likely
The experiment was divided into a learning phase and a test          and informative comparisons less likely. However, peak per-
phase. The learning phase consisted of participants actively         formance was observed for an environment not completely
choosing Alien pairs to fight against each other on 30 trials.       compensatory (θ = 0), but slightly compensatory.
The test phase was designed to assess what people learned
and was structured as follows: On each trial, participants
were presented with only 2 different Aliens that were again
randomly drawn from the Alien database. We told partici-
pants that these Aliens were the candidates for their Olympic
Team, and it was their task to choose the Alien they consid-
ered to be stronger based on what they had learned about the
characteristics. This assessment phase consisted of 10 binary
choices. Participants were reminded that a bonus payment
would depend on their performance in this test phase.
                                                                     Figure 3: Average test performance across participants by
                                                                     compensatoriness conditions.
                                                                         Next, we demonstrate the model fits of the regular Take-
                                                                     The-Best heuristic and Logistic Regression to participants’
                                                                     choices at test. These were generated by fitting both models
                                                                     to the set of Aliens participants had selected, and using the
                                                                     fitted models to predict choices in the test set. Figure 4
                                                                     presents the model fits as a function of the compensatoriness.
                                                                     It can be seen that Take-The-Best was better at predicting
                                                                     people’s behavior in the highly non-compensatory condi-
                                                                     tions, whereas in the more compensatory conditions no
                                                                     significant difference between the models could be found.
                                                                     This demonstrates again that purely behavioral model fits
                                                                     are limited in their ability to distinguish between common
                                                                     decision models, even in a prediction-based test. Therefore,
                                                                     we focus on the active learning results next.
Figure 2: Aliens varied on 4 different features (A-D): Anten-
nae, Wings, Diamonds, and Camouflage. E: Alien without               Active Learning Results We categorized all possible pair-
features, F: Alien with all features.                                wise comparisons people could choose on each trial into the
                                                                     8 possible subtypes that can be seen on the x-axis of Figure 5.
                                                                 1832

                                                                                                           Frequency of selected queries
                                                                                       20
                                                                                       15
                                                                         Frequency
                                                                                       10
                                                                                       5
Figure 4: Behavioral model fits of the Take-the-Best Heuristic                         0
and Logistic Regression. The y-axis represents the percent-
                                                                                             WDDD   WLDD    WWDD   WWLD   WWLL   WWWD      WWWL   WWWW
age of correct predictions with respect to people’s choices at
test.                                                                                                                Queries
WDDD for example signifies a comparison of two Aliens                    Figure 5: The 8 subtypes of active learning choices that par-
with 3 similar features (D for draw), where one of the Aliens            ticipants made and the a priori model choices.
had one more feature than the other (W for Win). A WLDD
comparison compares two Aliens with an equal direction of
two features but differing in two others (W for Win, L for
Loss), i.e., this might test whether the feature Wings are more
important than Camouflage for the outcome. People rarely
chose comparisons where it is unclear what feature was re-
sponsible for an outcome, e.g., a comparison of an Alien with
3 or 4 more features than its competitor (WWWD, WWWW).
Instead, the most common comparisons were simpler and
controlled, such as the WLDD, which test for the relative ef-
fect of one feature in comparison to another, i.e. searching for
orders among features. Although participants were told in the
instructions that all features are helpful in fights, the most fre-
quent comparison was the WDDD query, assessing whether
a feature improves the outcome. The fact that people pre-
ferred these simple queries could reflect a preference to per-
form confirmatory tests (Markant & Gureckis, 2012). Finally,
we compared queries selected by the two learning algorithms
against queries chosen by participants. We let both the TTB
and Logistic Regression algorithms learn in the same com-
pensatory and non-compensatory environment as the partic-
ipants, by creating as many simulated participant profiles as
there were participants in each compensatoriness condition.
Then, we let the models learn over time. As a result, the fre-
                                                                         Figure 6: Frequency of queries by active learning algorithms
quencies of selections executed at each run by the algorithms
                                                                         matched to participants’ queries. Lower panel: y-axis shows
were matched with those by humans and an overall correla-
                                                                         the variance explained. Upper panel: y-axis displays correla-
tion between the frequencies was calculated. Figure 6 shows
                                                                         tions.
in the lower panel how well the selection frequency predicted,
and in the upper panel how well the selection frequencies by
the models correlated with participants’ frequencies.
                                                                                     These results demonstrate that participants in different con-
                                                                      1833

ditions differed in terms of which active learning algorithm          shed more light onto how people actually learn in different
best described their queries (lower panel, Figure 6). With            tasks. We hope to utilize this new approach for more process-
an increase in non-compensatoriness, the Active Take-The-             based comparisons between different learning and decision
Best model explained more variance and Logistic Regression            making models in the near future.
less, in line with our prediction. This is also reflected in the
number of noncompensatory tests performed (e.g., WWLD),                                     Acknowledgements
which increased in more non-compensatory conditions. The              PP and ES contributed equally. They are both supported by
                                                                      the UK Centre for Doctoral Training in Financial Comput-
underlying correlations between the models’ and peoples’ se-          ing & Analytics. This work is partly supported by the Lev-
lections (upper panel, Figure 6) reveal a similar picture for the     erhulme Trust grant RPG-2014-075 to BCL. An appendix
TTB learning algorithm - with more non-compensatoriness,              explaining the computational models in more detail can be
                                                                      found at: https://github.com/ericschulz/activemodeltest.
the TTB algorithm’s queries better matched what queries peo-
ple were choosing. However, as the environment becomes                                            References
more and more compensatory, participants tend to select ob-           Arkes, H. R., Dawes, R. M., & Christensen, C. (1986). Factors influ-
servations that do not reduce uncertainty maximally with re-             encing the use of a decision rule in a probabilistic task. Organiza-
                                                                         tional Behavior and Human Decision Processes, 37(1), 93–110.
spect to the weight-based logistic regression algorithm, and
                                                                      Chaloner, K., & Larntz, K. (1989). Optimal bayesian design applied
instead select comparisons that are more certain which could             to logistic regression experiments. Journal of Statistical Planning
reflect more confirmatory hypothesis testing. This finding               and Inference, 21(2), 191–208.
also remained the same when we used predictive uncertainty            Chater, N., Oaksford, M., Nakisa, R., & Redington, M. (2003). Fast,
                                                                         frugal, and rational: How rational norms explain behavior. Orga-
instead of information gain, showing that -as environments               nizational behavior and human decision processes, 90(1), 63–86.
get more compensatory- participants tend to select queries            Czerlinski, J., Gigerenzer, G., & Goldstein, D. G. (1999). How good
where they already know the outcome better. Overall, the                 are simple heuristics?
Take-The-Best active learning algorithm which minimizes               Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the fast and
                                                                         frugal way: models of bounded rationality. Psychological review,
uncertainty with respect to cue orders was a better descrip-             103(4), 650.
tion of how people learn in our experiment.                           Gigerenzer, G., & Goldstein, D. G. (1999). Betting on one good
                                                                         reason: take the best and its relatives. Simple Heuristics that
                                                                         Make Us Smart. Oxford University Press, New York, (pp. 75–95).
               Discussion and Conclusion                              Golovin, D., Krause, A., & Ray, D. (2010). Near-optimal bayesian
                                                                         active learning with noisy observations. In Advances in Neural
Results demonstrated that–at least in more non-compensatory              Information Processing Systems, (pp. 766–774).
environments– people learn more like an order-based strat-            Griffiths, T. L., & Austerweil, J. L. (2009). Analyzing human feature
egy, which lends support to the Take-The-Best heuristic                  learning as nonparametric bayesian inference. In Advances in
                                                                         neural information processing systems, (pp. 97–104).
as a plausible decision mechanism in these environments.              Knox, W. B., Otto, A. R., Stone, P., & Love, B. C. (2011). The nature
This finding represents more processing-based evidence than              of belief-directed exploratory choice in human decision-making.
the usual predictive accuracy findings or descriptive model              Frontiers in psychology, 2.
                                                                      Marewski, J. N., Gaissmaier, W., & Gigerenzer, G. (2010). Good
fits. Furthermore, people do seem to be adaptive in their                judgments do not require complex cognition. Cognitive process-
choice of active learning strategies to the structure of the             ing, 11(2), 103–121.
environment: the more non-compensatory the environment                Marewski, J. N., & Mehlhorn, K. (2011). Using the act-r architec-
was, the more choices people made in accordance with the                 ture to specify 39 quantitative process models of decision making.
                                                                         Judgment and Decision Making, 6(6), 439–519.
TTB active algorithm. People were not well-described by               Markant, D., & Gureckis, T. M. (2012). One piece at a time: Learn-
the weight-based logistic regression algorithm, and for very             ing complex rules through self-directed sampling. In Proceedings
compensatory environments they even seemed to pick the                   of the 34th Annual Conference of the Cognitive Science Society.
                                                                         Austin, TX: Cognitive Science Society.
opposite choices to the uncertainty reducing algorithm, i.e.,         Martignon, L., & Hoffrage, U. (1999). Why does one-reason de-
they chose more certain queries. This could in turn be due               cision making work. Simple heuristics that make us smart, (pp.
to the fact that –when all cues are equally important– people            119–140).
notice they cannot learn any cue rank orders, and so they             Meder, B., & Nelson, J. D. (2012). Information search with
                                                                         situation-specific reward functions. Judgment and Decision Mak-
might apply another strategy that is compensatory but not                ing, 7(2), 119–148.
captured by logistic regression, for example a tallying strat-        Newell, B. R., Weston, N. J., & Shanks, D. R. (2003). Empirical
egy. This is a question we plan to address in a follow up study.         tests of a fast-and-frugal heuristic: Not everyone takes-the-best.
                                                                         Organizational Behavior and Human Decision Processes, 91(1),
                                                                         82–96.
   The current experiment demonstrates that active learning           Payne, J. W., Bettman, J. R., & Johnson, E. J. (1993). The adaptive
experiments can be used to distinguish among prominent de-               decision maker. Cambridge University Press.
                                                                      Raiffa, H., & Schlaifer, R. (1961). Applied statistical decision the-
cision strategies. Our results revealed a more informative pic-          ory. Division of Research, Harvard Business School, Boston, MA.
ture than the traditional passive model fitting procedures. We        Schulz, E., Speekenbrink, M., & Shanks, D. R. (2014). Predict
believe that the application of active learning algorithms as            choice: A comparison of 21 mathematical models. Cognitive
a means to distinguish among decision algorithms is a novel              Science Society.
                                                                      Todd, P. M., & Gigerenzer, G. (2000). Précis of simple heuristics
and promising approach. Creating active versions of classic              that make us smart. Behavioral and brain sciences, 23(05), 727–
decision models and testing them in related experiments will             741.
                                                                  1834

