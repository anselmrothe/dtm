Cognitive Consequences of Interactivity
Nan Renner (nrenner@ucsd.edu)
UCSD CREATE
Center for Research on Educational Equity, Assessment & Teaching Excellence
La Jolla, CA 92093

Abstract
When children encounter objects, design constrains and
affords action and cognition. An observational study in the
wild revealed how manipulable objects afforded greater
complexity of cognitive outcomes, including testing causeand-effect and expressing abstract ideas about phenomena in
the natural world. Evidence comes from video analysis of
children’s speech, gesture, and action when using a wide
range of natural history exhibits. In the museum—an
environment expressly designed for learning—children
sought information with their moving bodies, eyes and hands.
They explored sensorimotor contingencies, looking while
touching, pushing, and pulling; they probed the perceptual
affordances of different types of museum media, including
graphic panels, specimens, models, and interactive exhibits.
Children spoke more about the museum’s content when they
touched the exhibits, but the content of their speech changed
depending on the object’s affordances for interaction. With
static specimens and models, children most often referred to
objects’ concrete properties. With interactive exhibits,
children’s speech involved references to dynamic relations
among exhibit elements. Use of abstract speech and iconic
gestures also suggests that they perceived interactive exhibits
as representations of objects and phenomena beyond the hereand-now. In summary, when children used interactive
exhibits, the content of their speech was relational,
representational, and at times, both representational and
relational; they employed modes of conceptualization not
seen when using non-interactive exhibits.
Keywords: Distributed cognition; embodied cognition;
situated cognition; interactivity; perceptual and cognitive
affordances; representation; design; learning; museums

Introduction
What kinds of thinking does interaction make possible?
This observational study takes a deep dive into one thin
slice of everyday cognition—outside the laboratory, in the
wild—in a natural history museum. While contributing to a
compendium of human cognitive accomplishments in the
wild, describing cognitive consequences of interactivity can
inform design of learning technologies.
Museum professionals call manipulable exhibits
“interactive.” Interactive exhibits allow for reciprocity;
when a user takes action, the exhibit responds in some
perceivable way (McLean, 1996).
To understand the cognitive nature of interactivity
requires examination of the cognitive ecosystem, and what
people, objects, and social and cultural practices all
contribute to accomplishing a cognitive task.

From the perspective of distributed cognition, the
organization of mind—both in development and in
operation—is an emergent property of interactions among
internal and external resources. In this view, the human body
and the material world take on central rather than peripheral
roles. (Hollan, Hutchins & Kirsh, 2000).

Cognitive resources internal to individuals include the
functions enabled by human bodies, broadly speaking,
perception, action, and other forms of cognition
accomplished by brains (e.g. object recognition, memory,
imagination). Cognitive resources external to individuals
include artifacts, constructed environments, other people’s
actions, social organizations, norms, and cultural practices
which shape behavior and thought (Ibid; Clark, 2010;
Hutchins, 2000). We look for organization of intelligent
activity in the coordination of internal and external
resources (Ibid).
Touch is a primary mode for interaction with the physical
world. The complexity of the human tactile system, in
tandem with proprioception, allows for rich uptake of
information. Touching enables knowing about object
properties—in gestalt and in details—such as size, shape,
texture, material, spatial location and adjacencies (Hatwell,
2003). Perception informs action, e.g. sight of a hand tool
activates premotor regions in the brain, readying the body
for action (Grafton, Fadiga, Arbib, Rizzolatti, 1997). Action
serves perception, e.g. eyes and hands move over objects to
drive sensory input. The structures of human sensorimotor
systems—evolved for survival in a material world and tuned
through lived experience—subserve the functions of actionperception loops. In museums and elsewhere, we use these
biological
endowments
for
aesthetic
enjoyment,
conceptualization, learning, and more.
Grounded cognition theories assert that embodied
experience and situated action provide the building blocks
for modal simulation and the perceptual symbol systems,
proposed as underlying all cognition (Barsalou 2008;
Barsalou, 1998). During infancy, interaction with objects in
space may enable the development of abstract image
schemas, which act as conceptual primitives that provide the
foundation for categorization and abstract thought (Mandler,
2004). For crawling babies and pilots in their cockpits,
interaction with objects changes what is available for
perception, with consequences for memory, problem
solving, and action (Hutchins, 1995b). Through the
placement and arrangement of objects in space, humans can
create conceptual relationships among categories of objects
and organize their world for preferred types of action
(Kirsh, 1995; Tversky, 2011.)

1961

People use “epistemic action” when they manipulate
objects to produce knowledge in order to solve problems;
they don’t just solve problems “in their heads” (Kirsh &
Maglio, 1994). Objects in the environment can provide
structure for thought by serving as material anchors for
conceptualization, e.g. the systematic arrangement of
numbers and moving hands on a clock face supports the
conception of episodes and passages of time (Hutchins,
2005). Tools change the composition of functional cognitive
systems and the nature of cognitive tasks by changing the
distribution of cognitive labor (Cole & Griffin, 1980;
Hutchins, 1995a,b). As an example, compare mental
multiplication of two very large numbers to computing the
product with pencil and paper, or with a calculator.
Museum exhibits can serve as tools for exploring and
representing ideas. External representations permit inference
making by sharing the cognitive load with sensory systems
(Kirsh & Maglio, 1994). They can provide a substrate on
which one might “project” imagined structure (Kirsh, 2009),
as when eyes trace a path on a map. Additionally, when
objects can be manipulated, their representational potential
expands by changing what is available for both perception
and imaginary projection. Alignment of structure between
aspects of perceptual experience and mental content may
provide the basis for analogical reasoning and conceptual
understanding (Gentner, 2010). Research has shown how
interaction with external representations—in particular,
diagrams and gesture—serves critical functions in achieving
insight through processes that engage perception,
juxtaposition of elements, imagination, and representation
through abstraction (Nersessian, 2012; Bechtel, 2013;
Becvar, Hollan & Hutchins, 2005; Hutchins & Palen, 1998).
Learning scientists and educational researchers have
stated the need to more deeply explore the cognitive
constraints and affordances of interactive museum exhibits
(Rennie, Feher, Dierking & Falk, 2003). Some researchers
have articulated strategies for designers to focus users’
attention, limit sensory overload and frustration, and
promote understanding (Allen, 2004; Allen & Gutwill,
2004). Indeed, museum exhibits can be powerful tools to
promote learning and to study how learning happens (Feher,
1990). Researchers working in the realm of embodied
mathematics learning are exploring exhibits as mathematical
“instruments” for the development of perceptuomotor
attunement, fueling mathematical imagination, merging
action and conceptualization (Nemirovsky, Kelton, &
Rhodehamel, 2013). There is widespread acknowledgement
that interaction with objects provides the means for
important cognitive work in learning enviornments (Bell,
Lewenstein, Shouse & Feder, 2009). A growing research
community conducts microanalytic ethnographies of
interaction in environments designed for learning (Norris,
2004), yet we have not exhaustively documented the
cognitive consequences of interactivity.

Methods and Analysis
Observing individuals and groups engaged with social
and physical environments, we see how sequences of action
enact and embody trains of thought (Alac & Hutchins,
2004). Translating distributed cognition theory into
methods, we use cognitive ethnography (Williams, 2006),
an evolving methodology that bounds units of analysis
based on cognitive tasks (Hollan, Hutchins & Kirsh, 2000).
Cognitive ethnography focuses on interaction among
elements in cognitive ecosystems, both human and
environmental. Qualitative and quantitative methods used
are multimodal, multiparty, multiscalar (Johnson, 2010).
For this research, primary data were comprised of video
recordings of six bilingual fourth-grade children, each
spending approximately 40 minutes in a natural history
exhibition focused on geology and paleontology. Video
recordings involved hand-held cameras following children
as they moved through the museum. In addition, headmounted cameras worn by children captured their literal
point of view in an attempt to get inside the activity,
deliberately taking an endogenous perspective (Stevens,
2010). Qualitative, descriptive analyses derive from the
video recordings. Coding and annotation of the video
generated secondary data, used for quantitative analyses
related to abundance, diversity, distribution, sequences, and
co-occurrences of cognitive events. The coding scheme,
developed during the exploratory phases of this study,
involved codes informed by theories of Distributed and
Embodied Cognition, as well as emergent codes in the
tradition of Grounded Theory related to the consequences of
action and cognitive function (Charmaz, 2000).
Children’s behaviors determined the parsing of activity in
the museum. The video was annotated to mark engagement
of perceptual and expressive modalities, i.e. when children
looked, touched, talked, and gestured with exhibits. The
coding scheme also specified how behaviors were coupled
with the environment, as different targets of touch have
different qualities and affordances (e.g. they touched
smooth graphic panels, irregularly-shaped and textured
touchable specimens, and manipulable interactive exhibits).
Speech was coded in multiple ways, related to the presence
or absence of the referent, and to differentiate exhibitrelated from non-exhibit-related speech. Coding enabled
categorization of utterances as exhibit-related and concrete,
abstract, or a blend of concrete and abstract (Figure 1). In
addition, use of parts of speech referring to objects and
actions supported interpretations of the cognitive functions
of speech (to name, describe, evaluate, direct attention, ask a
question, etc.). The gesture codes simultaneously indicate
form and function (indexical and iconic).
This study draws from video data of six children’s
activity in four of six galleries, totaling 166 minutes,
including 194 events defined by a participant’s sustained
visual attention on an exhibit, with some of that time in
proximity close enough to touch. The video data has 30
frames per second; a frame-by-frame analysis allows for
coding of behavior at a resolution of 33 milliseconds.

1962

Figure 1. Coding scheme for exhibitrelated speech.
With training and a great deal of patience, research
assistants coded video, focusing on observable behaviors
such as: Look, Touch, Manipulate, Talk, Gesture, Read.
Definitions of behaviors in an ethogram and a decision tree
for types of talk (Figure 1) guided their judgments. Studying
the complexity of cognition in the wild requires perception
tuned by knowledge and experience, what Goodwin calls
“professional vision” (Goodwin, 1994). Consequently, the
lead researcher confirmed the accuracy of the coding done
by assistants.
The cognitive ethnography approach aligns with
Multimodal Interaction Analysis, informed by strategies and
orientations from Conversational Analysis, Multimodal
Discourse Analysis, and Interaction Analysis (Norris,
2004). The cognitive task defines the unit of analysis in
cognitive ethnography. In this case, the cognitive task for
the children was to make sense of the novel museum
environment, so the analysis involved the children and
objects in the environment. The video and annotation data
allow purchase on the question: What are cognitive
consequences of interactivity for children in a museum?
Study participants attended a special museum immersion
program. One girl and one boy from each of three classes
were purposefully selected by the researcher with no prior
knowledge of their personal or academic history. Results
from this study derive from six participants, all bilingual, (5
English/Spanish bilinguals, 1 English/Vietnamese), during
fall of their fourth-grade year. This study sits within a larger
research agenda with the goal to describe a unique cognitive
ecosystem at the intersection of formal and informal
education in a natural history museum. The larger
ethnography included observations and recordings of the
three classes, attending adults, interviews with teachers and
museum educators, subsequent museum observations, and
classroom conversations.

Results
Allocation of attention influences other forms of
cognition. Actions of the eyes and hands serve as a proxy
for attention. When in the museum galleries, children
looked at exhibits 90-95% of the total time, and touched
exhibits 25-60% of the total time. Among the 194 events
defined by sustained visual attention on a singular exhibit

within arm’s reach, the vast majority (79%) involved
touching. Forms of touch differed with the targets for touch
and their affordances for engagement. Children touched the
smooth surfaces of exhibit cases and graphic panels in 53%
of all manual events (384 total across six children); they
touched irregularly shaped specimens and models in 25% of
manual events; they manipulated exhibits in 22% of manual
events. The percentages of look-only, touchable, and
manipulable exhibits, relative to the overall number of
exhibits, is equivalent. However the amount of time spent at
interactive exhibits, relative to overall time, is greater than
the percentage of interactive exhibits relative all exhibits.
Children often watched others while waiting in line to take
their turn with an interactive exhibit.
Of all the speech events uttered by children while in the
galleries (n=496), 69% related to exhibit content (e.g.
“That’s a starfish”); the remaining 31% involved social
coordination, such as “I’m going to take you over here,” and
“We gotta go.” Touch and talk tend to co-occur. When
children touched exhibits, they simultaneously talked about
half the time. When children talked about exhibits, they
simultaneously touched 70% of the time.
The content of children’s speech changed depending on
the object’s affordances for interaction. Children commonly
used speech related to concrete objects on display and
concrete actions (67% of all exhibit-related speech events).
With static specimens and models, children most often
referred to concrete objects’ properties, naming, describing,
and evaluating, using nouns, pronouns, adjectives, and
indexical gestures.

Figure 2. “That’s where we are,”
representational speech with indexical gesture.
Children infrequently talked about representational
content; 19% of multimodal utterances were coded as
representational, i.e. they made reference to a museum
object that was present and perceivable and also something
physically absent, blending abstract and concrete speech.
Examples include when a child pointed to a dynamic world
map with moving continents and said “That’s where we are”
(Figure 2) or pointed to a geologic model, saying “That’s
lava.” Although representational utterances were less
common overall, when the children engaged with interactive
exhibits, they were much more likely to use
concrete/abstract representational speech. Two-thirds of 55

1963

instances of concrete/abstract representational speech
occurred while children manipulated or watched another
child manipulate an interactive exhibit. Concrete speech is
three times more abundant than representational speech.
Yet, speech describing relations among exhibit elements
was three times more abundant in representational than
concrete speech, always occurring with interactive exhibits.
Referring to dynamic cause-and-effect relations among
exhibit elements, the children used verbs, adverbs, and
prepositions in addition to other parts of speech. Their use
of abstract speech and iconic gestures suggests that they
perceived interactive exhibits as representations of objects
and phenomena beyond the here-and-now.

Discussion
When museum exhibits afford interaction, they yield
consequences for attention and conceptualization. When
children manipulated interactive exhibits in the museum—
opportunities that they actively sought—they achieved feats
of cognitive complexity. With non-interactive exhibits,
children tended to focus on questions related to concrete
objects. With interactive exhibits, they went beyond naming
the concrete objects. They explored opportunities for taking
action and expressed representational meanings of museum
objects in speech and gesture. Additionally, interactive
exhibits seem to attract and hold the attention of children for
longer time periods, a finding consistent with many museum
studies (Serrell, 1998). This longer “stay time” may
influence outcomes for speech and cognition.
Various lines of research assert that language use can
bootstrap cognitive development (Spaepen, Coppola,
Spelke, Carey, Goldin-Meadow, 2011; Balcomb,
Newcombe, Ferrara, 2011; Carey, 2011). At multiple levels,
whether behavioral associations or purported neural
connections, talking about experience can form and
strengthen linkages between percepts and concepts (Gentner
& Boroditsky, 2001; Ayoub & Fischer, 2006). Different
forms of talk involve different cognitive functions. Naming
a concrete object involves perception, recognition, and
mental linkage with a verbal label. Naming that which an
object represents involves both seeing the object, and seeing
as, invoking the imagination to form a representation
(Goodwin & Goodwin, 1996; Alac & Hutchins, 2004). This
seeing as, marked by the use of representational speech and
gesture, happened more frequently with exhibits that had
opportunities for interaction.
Especially when interactive, the exhibits served as tools,
as pivots for the imagination (Vygotsky, 1934), and as
material anchors for conceptual blends (Hutchins, 2005), a
purported process by which humans weave together ideas
from two distinct yet related mental spaces (Fauconnier,
1994). As material anchors for conceptual blends, museum
exhibits instantiate a physical analogy for a set of concepts.
The imagination links what is present with what is not
present, creating representational relationships. When
children used concrete/abstract speech and iconic gesture as
vehicles of expression, they made these representational

relationships available for observation, for themselves and
others.
With exhibits as tools, children can give form to their
imaginations. Among the children, iconic representational
gestures were rare and not evenly distributed throughout the
exhibition. The majority of iconic gestures occurred at a
plate tectonics exhibit, designed to represent a subduction
zone. The design of the exhibit strongly evoked
representation of volcanoes among the children, yet the
physical design left out a critical conceptual component—
the eruption of lava from the Earth’s surface. With iconic
gestures, the children gave form to imagination and, with
their hands accompanied by sound effects, they filled a gap
in the physical design by enacting eruptions and explosions
(Figure 3).

Figure 3. Enacting a volcanic gesture
coupled with subduction exhibit.
Children expressed the representational potential of
exhibits by coordinating their resources for actionperception-cognition with the material resources of the
exhibits, asynchronously collaborating with the designers
who deployed strategies of visual-spatial abstraction and
temporal-spatial compression. Interactive exhibits can
instantiate analogies for phenomena, objects, and processes,
but people create representations, sometime observable in
speech and gesture.
When children manipulated exhibits, they experienced
contingent relationships between the actions of their hands
and changes in their visual field. Speech and gesture that
accompanied manipulation served specific cognitive
functions, i.e. making reference to analogical and dynamic
relations using abstract nouns, verbs, prepositions, and
representational gestures, resulting in greater cognitive
complexity. Talk that accompanied touching static objects,
not involving manipulation, had simpler cognitive
outcomes: naming, describing, evaluating, using concrete
nouns, adjectives, the verb “to be,” and indexical pointing
gestures.
When exhibits can be manipulated, this seems to motivate
their inclusion in a category endemic to museums, a
category of objects that are supposed to be representational.
A child expressed this expectation of representation when
he approached an interactive model and asked, not the most

1964

common question “What is it?,” rather “What’s this
supposed to be?”
The richness of this cognitive accomplishment—using
exhibits to create representations, personally meaningful
and publicly shared—involves a distribution and integration
of cognitive labor. A child’s eyes focus on an exhibit,
supporting visual perception while the line of sight can
serve as a pointer for others’ attention. The hands
manipulate an interactive exhibit, creating movement that
changes the visual field, highlighting how the elements
relate to each other and demonstrating how action causes
effects. Speech can label the objects and express how they
relate, and gesture can locate those objects in space and
express dynamics of phenomena in concrete and/or abstract
terms. And multiple parties can get involved, watching,
moving, talking, gesturing—collaborating to create
representations in the museum.
When opportunities for multimodal and multiparty
engagement expand the potential for cognitive complexity,
coherence or confusion can result. To increase the
probability of perceptual-conceptual coherence and reduce
the probability of confusion, the results of this research
suggest implications for design.
To accomplish the cognitive achievement of perceiving
and expressing representational content, museum exhibits
should instantiate a direct isomorphic mapping between
concrete objects and abstract concepts—“structural
alignment” (Gentner, 2010) enhances the probability of
achieving intersubjective agreement on the representational
content. If multiple conceptual steps are required to achieve
correspondence between the object and concept, intellectual
scaffolding (ideally in material form) must support making
those steps, and sufficiently hold attention to complete the
conceptual journey.
Physical aspects of exhibits channel attention and focus
perception. With interactive displays, manipulation of an
exhibit changes what is available for perception, and
movement highlights specific features. Interactive exhibits
instantiate dynamic relationships of cause-and-effect, and
through analogical reasoning, can represent abstract, more
generalizable, relationships. With affordances of
manipulation and interaction, exhibits can serve as
technologies for exploration and imagination, rather than
solely as media for transmitting information.
Hands—these uniquely human, extraordinarily flexible
tools—can be put to good use in museums, schools, and
other learning environments. Children will touch whatever
is available. In many museums, the most abundant
touchable resources—graphic panels—offer the least tactile
information. The least abundant resources—interactive
exhibits—offer the most multisensory information and
potential for cognitive complexity. Touching and
manipulating objects compels the allocation of both
individual and joint attention, influencing what and how
children see, and the ideas they activate through speech and
gesture. Educators and designers may take stock of their
investment in these different learning resources and assess

their potential for engagement involving perception/action/
cognition.
Interactive exhibits enhance the potential for
conceptualization that is relational, representational, and a
combination of relational and representational. When
children engage multiple perceptual and expressive
modalities, interacting with objects and coordinating with
the actions of others, an opportunistic distribution of
cognitive labor results, offering great potential for cognitive
complexity and richness of meaning-making.

Acknowledgments
This paper results from dissertation research conducted
under the supervision of Edwin Hutchins, with advice from
James Hollan, Michael Cole, Christine Johnson, David
Kirsh, Marta Kutas, and Jay Lemke, with funding from the
University of California San Diego Predoctoral Humanities
Fellowship. Special thanks to Tyler Marghetis, Hugh
Mehan, Alba Basurto, Gina Bello, Richard Caballero,
Jordan Davison, Divya Krishnakumar, Mandy Wong, and
the San Diego Natural History Museum.

References
Alac, M., Hutchins, E. (2004). I see what you are saying:
Action as cognition in fMRI brain mapping practice. Journal
of Cognition and Culture, 4.3.
Allen, S. (2004). Designs for Learning: Studying Science
Museum Exhibits That Do More Than Entertain. Published
online in Wiley InterScience (www.interscience.wiley.com).
Allen, S., Gutwill, J. (2004). Designing with multiple
interactives: Five common pitfalls. Curator 47(2): 199–212.
Ayoub, C. C., & Fischer, K. W. (2006). Developmental
pathways and intersections among domains of development.
In K. McCartney & D. Phillips (Eds.), Handbook of Early
Child Development, 62–82. Oxford, U.K.: Blackwell.
Balcomb, F., Newcombe, N.S., Ferrara, K. (2011). Finding
where and saying where: Developmental relationships
between place learning and language in the second
year. Journal of Cognition and Development, Vol. 12, No. 3:
315–331.	  	  
Barsalou, L. (1999). Perceptual symbol systems. Brain and
Behavioral Sciences, 22: 577–660.
Barsalou, L. (2008). Grounded cognition. The Annual Review
of Psychology, 59:617–45.
Bechtel, W. (2013). Understanding biological mechanisms:
Using illustrations from circadian rhythm research. In
Kampourakis, K. (Ed.) Philosophical issues in biology
education. New York, NY: Springer.
Becvar, L.A., Hollan, J., Hutchins, E. (2005). Hands as
molecules: Representational gestures as cognitive artifacts
for developing theory in a scientific laboratory. Semiotica,
156-1/4: 89–112.
Bell, P., Lewenstein, B., Shouse, A., Feder, M. (2009).
Learning Science in Informal Environments: People, Places,
and Pursuits. Committee on Learning Science in Informal
Environments, National Research Council. Washington, DC:
The National Academies Press.

1965

Carey, S. (2011). The Origin of Concepts: A précis. Behavioral
and Brain Sciences, 34, 113–167.
Charmaz, K. (2000). Grounded theory: Objectivist and
constructivist methods. In N.K. Denzin & Y.S. Lincoln
(Eds.), Handbook of qualitative research (2nd ed., pp. 509–
535). Thousand Oaks, CA: Sage.
Clark, A. (2011). Supersizing the Mind: Embodiment, Action,
and Cognitive Extension. New York, NY: Oxford University
Press.
Cole, M., Griffin, P. (1980). Cultural amplifiers reconsidered.
In D. Olson (Ed.), Social Foundations of Language and
Thought. New York: W. W. Norton.
Fauconnier, G. (1994). Mental Spaces: Aspects of Meaning
Construction in Natural Language. New York, NY:
Cambridge University Press.
Feher, E. (1990). Interactive museum exhibits as tools for
learning: explorations with light. International Journal of
Science Education,12(1):35-49.
Gentner, D. (2010). Bootstrapping the mind: Analogical
processes and symbol systems. Cognitive Science, 34: 752–
775.
Gentner, D., Boroditsky, L. (2001). Individuation, relativity
and early word learning. In M. Bowerman & S. Levinson
(Eds.), Language Acquisition and Conceptual Development,
215–256. Cambridge, UK: Cambridge University Press.
Goodwin, C. (1994). Professional vision. American
Anthropologist, 96(3): 606–633.
Goodwin, C., Goodwin, M.H. (1996). Seeing as a Situated
Activity: Formulating Planes. In Yrjö Engeström and David
Middleton (Eds.) Cognition and Communication at Work,
61–95. Cambridge, MA: Cambridge University Press.
Grafton, S.T., Fadiga, L., Arbib, M.A., Rizzolatti, G. (1997).
Premotor cortex activation during observation and naming of
familiar tools. NeuroImage, Volume 6, Issue 4, 231-236.
Hatwell, Y. (2003). Touch and cognition. In Y. Hatwell, A.
Streri, E. Gentaz (Eds.) Touching for Knowing: Cognitive
Pyschology of Haptic Manual Perception. Philadephia, PA:
John Benjamins.
Hollan, J., Hutchins, E. & Kirsh, D. (2000). Distributed
cognition: Toward a new foundation for human-computer
interaction research. ACM Transations on Computer-Human
Interaction, 7(2), pp. 174–196.
Hutchins, E. (1995a). Cognition in the Wild. Cambridge, MA:
The MIT Press.
Hutchins E. (1995b). How a cockpit remembers its speeds.
Cognitive Science, 19, 265-288.
Hutchins, E. (2000). Distributed Cognition. IESBS Distributed
Cognition. San Diego, CA: University of California, San
Diego.
Hutchins, E. (2005). Material anchors for conceptual blends.
Journal of Pragmatics, 37: 1555–1577.
Hutchins, E., Palen, L. (1998). Constructing meaning from
space, gesture and speech. In L. B. Resnick, R. Saljo, C.
Pontecorvo, and B. Burge (Eds.) Discourse, Tools, and
Reasoning: Situated Cognition and Technologically
Supported Environments. Verlag, Germany: Springer.
Johnson, C. (2010). Observing cognitive complexity in
primates and cetaceans. International Journal of
Comparative Psychology, 23: 587-624.

Kirsh D. (1995). The intelligent use of space. Artificial
Intelligence 73:31-68.
Kirsh, D. (2009). Interaction, external representations and sense
making. In N. A. Taatgen & H. van Rijn (Eds.), Proceedings
of the 31st Annual Conference of the Cognitive Science
Society (1103-1108). Amsterdam: Cognitive Science
Society.
Kirsh, D. and Maglio, P. (1994). On distinguishing epistemic
from pragmatic action. Cognitive Science, 18: 513–549.
Mandler, J.M. (2004). The Foundations of Mind: The Origins
of Conceptual Thought. New York, NY: Oxford University
Press.
McLean, K. (1993). Planning for People in Museum
Exhibitions. Washington DC: Association of Science &
Technology Centers.
Nemirovsky, R., Kelton, M., Rhodehamel, B. (2013). Playing
mathematical instruments: Perceptuomotor integration with
an interactive mathematics exhibit. Journal for Research in
Mathematics Education. 44(2):372-415.
Nersessian, N. J. (2012): Modeling practices in conceptual
innovation: An ethnographic study of a neural engineering
research laboratory. In U. Feest & F. Steinle (Eds.) Scientific
Concepts and Investigative Practice, 245–269. Berlin,
Germany: DeGruyter.
Norris, S. (2011). Discourse in Action: Introducing Mediated
Discourse Analysis. Studies in Multimodality : Multimodality
in Practice : Investigating Theory-in-Practice-throughMethodology. Florence, KY: Routledge.
Rennie, L., Feher, E., Dierking, L., Falk, J. (2002). Toward an
agenda for advancing research on science learning in out-ofschool settings. Journal of Research in Science Teaching.
40(2): 112–120.
Serrell, B. (1998). Paying Attention: Visitors and Museum
Exhibitions. Washington DC: American Association of
Museums.
Spaepen, E., Coppola, M., Spelke, E.S., Carey, S.E., GoldinMeadow, S. (2011). Number without a language model.
PNAS, Vol. 108, N. 8, 3163–3168.
Stevens, R. (2010). Learning as a members’ phenomenon, in
National Society for the Study of Education, Volume 109,
Issue 1, (82–97). New York, NY: National Society for the
Study of Education, Columbia University.
Tversky, B. (2011). Visualizing thought. Topics in Cognitive
Science, Volume 3, Issue 3, 499–535.	  	  
Vygotsky, L.S. (1934/1986). Thought and Language. Kozulin
(Ed.), Hanfmann & Vakar (Trans.). Cambridge, MA: The
MIT Press.
Williams, R. (2006). Using cognitive ethnography to study
instruction. Proceedings of the 7th international conference
on learning sciences, 838–844.

1966

