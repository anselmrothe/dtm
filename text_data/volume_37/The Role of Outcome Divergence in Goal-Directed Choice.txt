                                      The Role of Outcome Divergence in Goal-Directed Choice
                            Prachi Mistry (prachim@uci.edu), Mimi Liljeholm (m.liljeholm@uci.edu)
                                                Department of Cognitive Sciences, UC Irvine
                                                                Irvine, CA 92697
                              Abstract                                     probability distributions, can be used to prune searches of
   We assessed the influence of instrumental outcome                       the cognitive map.
   divergence – the extent to which actions differ in terms of
   their outcome probability distributions – on behavioral
   preference in a two-alternative forced choice task. We found                         a)
   that participants preferred a pair of available actions with high
   divergence to a pair with low divergence. The effect of
   outcome divergence, dissociated here from that of other
   motivational and information theoretic factors, potentially
   reveals the value of flexible control.                                                                               A2
                                                                                                                     A1
   Keywords: Instrumental Outcome Divergence; Flexible                                        O1      O2     O3
   Control; Goal-Directedness, Choice Preference
                                                                                        b)
                          Introduction
Goal-directed decisions are supported by a “cognitive map”
of state transition probabilities that are flexibly combined                                                           A2
                                                                                                                    A1
with subjective utilities in order to generate action values,                                O1      O2     O3
the basis of choice (Tolman, 1948; Balleine and Dickinson,
1998; Doya et al., 2002; Daw et al., 2005). Although                            Figure 1: Probability distributions over three
computationally expensive, the dynamic binding of utilities                     possible outcomes, O1, O2 and O3, for two
and probabilities offers adaptive advantage over more                           available actions, A1 and A2.
automatic, habitual, action selection, which uses cached
values based on reinforcement history (e.g., Daw et al.,                      Now consider the scenario in Figure 1b, in which the
2005).       There are, however, situations in which the                   probability distribution of A2 has been reversed across the
processing cost of goal-directed computations does not yield               three outcomes. Note that, if the utilities of O1 and O3 are
the return of flexible control. Here, we introduce a novel                 the same, the two actions still have the same value.
decision variable – instrumental outcome divergence – that                 Likewise, the outcome entropies – that is, the uncertainty
serves as a measure of flexible control, and assess its                    about which outcome will be obtained given performance of
influence on behavioral preference.                                        an action – is the same across the two actions. And yet, the
   Consider the scenario illustrated in Figure 1a, which                   two actions clearly differ. To appreciate the significance of
shows two available actions, A1 and A2, where the bars                     this difference, imagine that O1 and O3 represent food and
represent the transition probabilities of each action into                 water respectively, and that you just had a large delicious
three potential outcome states, O1, O2 and O3. Here, the                   meal but without a drop to drink. Chances are that your
goal-directed approach prescribes that the agent retrieves                 desire for O3 is greater than for O1 at that particular
each transition probability, estimates the current subjective              moment. However, a few hours later, you may be hungry
utility of each outcome, computes the product of each utility              again and, having had all the water you want, now have a
and associated transition probability, sums across the                     preference for O1. Unlike the scenario illustrated in Figure
resulting value distribution for each action and, finally,                 1a, that in Figure 1b allows you to produce the currently
compares the two action values (e.g., Doya et al., 2002;                   desired outcome as preferences change, by switching
Daw et al., 2005). Of course, given equivalent costs, actions              between actions. Thus, instrumental divergence can serve
that yield identical outcome states will inevitably have the               as a measure of agency – the greater the divergence between
same value, and thus need not be contrasted further in terms               available actions, the greater the agent’s flexible control
of the utilities of their outcomes. Consequently, the extent               over the environment.
to which actions differ in terms of their relationships to                    Scanning human participants with functional magnetic
future states, that is, the divergence of their outcome                    resonance imaging (fMRI) as they performed a simple
                                                                           decision-making task, Liljeholm et al., (Liljeholm et al.,
                                                                       1601

2013) found that activity in the inferior parietal lobule, an      Method
area previously implicated in several aspects of goal-             Participants Twenty undergraduates at the University of
directed processing, including the computation of                  California, Irvine (12 females; mean age = 20.20 ± 4.81)
instrumental contingencies (Seo et al., 2009; Liljeholm et         participated in the study for course credit. All participants
al., 2011) the attribution of intent (den Ouden et al., 2005),     gave informed consent and the Institutional Review Board
and awareness of agency (Chaminade and Decety, 2002;               of the University of California, Irvine, approved the study.
Farrer et al., 2008; Sperduti et al., 2011), scaled with the
instrumental divergence of available actions. However, the         Decision Variables We defined the expected value of each
task used by Liljeholm et al. did not allow them to assess         available action as the sum of the products of its transition
the influence of divergence on behavioral preference. Here,        probabilities and token utilities: thus, if the values of the
to behaviorally assess the value of control, we used a novel       green, blue and red tokens are $1, $2 and $3 respectively,
experimental task (see Figure 2 and Methods for details) in        and an action produces the three tokens with probabilities of
which participants chose between pairs of actions with             0.7, 0.0 and 0.3 respectively, the expected value of that
different levels of instrumental divergence. Specifically,         action is $1.6. Another important decision variable
participants were required to choose between a high and low        frequently shown to influence instrumental choice is the
divergence action pair at the beginning of each block and,         variability, or entropy, of outcome states (Erev and Barron,
on subsequent trials in that block, choose only between the        2005; Weber and Huettel, 2008; Abler et al., 2009), which is
actions within the selected pair.                                  greatest when the probability distribution over outcomes is
                                                                   uniform (i.e., all outcomes are equally likely) and smallest
                                                                   when the probability of a particular outcome is 1. We
                                                                   computed the Shannon entropy of the outcome variable X
            Press ! to select         Press " to select
                                                                   conditional on a particular action Y, defined as:
                                  OR                                                                    p(y)
            Room 1: A1 v. A2          Room 2: A1 v. A3
                                                                    H (X | Y ) =    ∑      p(x, y)log
                                                                                                       p(x, y)
                                                                                  x∈X,y∈Y
                                                                   To rule this variable out as a source of behavioral
                                ...                                preference, we kept it constant across all actions throughout
                                                                   the study.
                    A1     A2       A3   A4                           Finally, we formalize instrumental divergence as the
                                                                   Jensen-Shannon (JS) divergence of the outcome probability
                                $3                                 distributions for the actions in a given pair. A finite and
                                                                   symmetrized version of the Kullback-Leiber divergence, JS
                            $1       $2                            divergence specifies the distance between probability
                                                                   distributions M and N as:
      Figure 2: Task illustration showing the choice
      screen at the beginning of a block (top), and the                    1         !M $        1      !N $
      choice screen on a trial within the block (bottom).
                                                                    JSD =
                                                                           2
                                                                             ∑  i
                                                                                  ln # i & M i + ∑ ln # i & N i
                                                                                     " Pi %      2   i
                                                                                                        " Pi %
      On each trial, once an action (e.g., A3) was                 where
      selected, a feedback screen showed that action
                                                                         1
      inside a selection square, together with the                  P=     (M + N )
      particular token (e.g., red) delivered on that trial.              2
   We predicted that, all other things being equal,                   Task & Procedure The task is illustrated in Figure 2. At
participants would prefer action pairs with high divergence,       the start of the experiment, participants were instructed that
as these yield the highest level of flexible control. Flexible     they would assume the role of a gambler in a casino, playing
control is particularly important in a dynamic environment,        a set of four slot machines (i.e., actions, respectively labeled
where the subjective utilities of outcome states change            A1, A2, A3, and A4) that yielded three different colored
frequently. With primary rewards, this is generally the case       tokens (blue, green and red), each worth a particular amount
due to sensory-specific satiety (e.g., Balleine and Dickinson,     of money, with different probabilities. They were further
1998). Here, to simulate the subjective utility of primary         told that, in each of several blocks, they would be required
rewards, we used colored tokens as outcomes, and                   to first select a room in which only two slot-machines were
reassigned values to tokens across conditions.                     available, and that they could only choose between the two
                                                                   machines in the selected room on subsequent trials in that
                                                               1602

block. Finally, participants were instructed that, while the       sequence was repeated once, followed by a final set of four
outcome probabilities would remain constant throughout the         v1 blocks, yielding 9 sets of 4 blocks for a total of 36
study, the values of the tokens would change at various            blocks.1 Each v2 and v3 set contained two blocks in which
times, and these changes might occur after the participant         expected value differed in the same direction as divergence
had already committed to a particular pair of machines in a        and two blocks for which expected value differed in the
given block. Consequently, although changes in value were          opposite direction of divergence. The order of v2 and v3 sets
explicitly announced, and the current values of tokens were        was counterbalanced across participants and the order of
always printed on their surface (to facilitate the computation     blocks within each set was random. Finally, each block
of expected values), a participant might find themselves in a      consisted of 6 trials on which participants choose between
room in which the values of the two available actions had          the two actions in the selected pair, for a total of 216 trials.
suddenly been altered.                                                           Before starting the gambling task participants were given
   Two distinct probability distributions over the three           a practice session in order to learn the probabilities with
possible token outcomes were used: 0.7, 0.0, 0.3 and 0.0,          which each action produced the different colored tokens. To
0.7, 0.3. The assignment of outcome distributions to actions       avoid biasing participants towards any particular reward
was such that two of the actions (either A1 and A2 or A1           distribution, no values were printed on the tokens in the
and A3, counterbalanced across subjects) always shared one         practice session. During practice, to ensure equal sampling,
distribution, while the other two actions shared the other         each action was presented on 10 consecutive trials with only
distribution. This yielded a low (zero) outcome divergence         that action being available, and with tokens occurring
for pairs in which the two actions shared the same                 exactly according to their programmed probabilities (i.e., if
probability distribution (as in Figure 1a), and a high (0.49)      the action produced green tokens with a probability of 0.2,
outcome divergence for pairs in which actions had different        the green token would be delivered on exactly 2 of the 10
outcome probability distribution (as in Figure 1b). The            trials).
unpredictability (i.e., Shannon entropy) of outcomes given a                     Following 10 trials with a given action, participants rated
particular action was held constant at 0.61 for all actions.       the probability with which that action produced each
The four actions were combined into six pairs, which were          colored token before proceeding to the next action. Once all
in turn combined into 15 two-alternative choice scenarios          actions had been practiced, the four actions were presented
(see top screen in Figure 2). For 8 of these scenarios,            in random order and participants again rated the outcome
divergence differed across the two action pairs, while for the     probabilities of each. If a participants’ estimate of any
remaining 7 scenarios, all decision variables, including           given probability deviated by more than 0.2 from the
divergence, where the same for both available pairs.               programmed probability, they were returned to the
   We were primarily interested in assessing preference for        beginning of the practice phase, and this continued until all
high- over low-divergence pairs when expected value was            rated probabilities were within 0.2 points of programmed
held constant across pairs. Consequently, in the majority of       probabilities. At the end of the study, after the gambling
blocks, the values assigned to the blue, green and red token       phase, participants again provided estimates of the action-
respectively were $2, $2 and $1, yielding identical expected       token probabilities.
values for all actions. However, to simulate a dynamic                           Importantly, all monetary amounts were fictive, and
environment, in a subset of blocks, the token values were          participants were instructed at the beginning of the
changed to $2, $1 and $3 respectively, and in yet another          experiment that they would not receive any actual money
subset they were changed to $1, $2 and $3: For these two           upon completing the study.                                                                                                                                                                                            Nonetheless, given the
subsets of blocks, the expected value of the low-divergence        previously demonstrated correspondence between real and
action pair was either higher ($2.30) or lower ($1.60) than        fictive monetary rewards, in both behavioral choice and
that of the high-divergence pair ($1.95), depending on             neural correlates (Bowman and Turnbull, 2003; Bickel et
which outcome probability distribution was shared by the           al., 2009; Miyapuram et al., 2012), we predicted that
two actions in the low-divergence pair.                            participants would select pairs with the highest expected
   Changes between the three distinct value assignments            value whenever expected value differed across pairs,
described in the previous paragraph (henceforth v1, v2 and         regardless of differences in divergence.                                                                                                                                                                                            We also
v3), although explicitly announced and apparent based on           hypothesized, however, that participants would choose
the numbers printed on tokens, were unpredictable in that          according to divergence whenever expected values were
they always occurred after a participant had already
committed to a particular pair of actions in a given block.
The order of value assignments was such that four
                                                                   	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  	  
                                                                   1
                                                                           For completeness, the 7 choice scenarios in which all decision
consecutive v1 blocks were followed by a set of four               variables were held constant across the two available pairs were
consecutive v2 blocks, followed by another set of four v1          randomly distributed throughout the sequence of 36 blocks. These
blocks, followed by a set of four v3 blocks. This entire           7 blocks were not analyzed and will not be discussed further.
                                                               1603

  held constant across pairs, reflecting the postulated value of     differed in the opposite direction of divergence, 33% (SD =
  control.                                                           26%), p<0.001. The percentage of high divergence choices
                                                                     was also significantly greater when expected value was held
                                                                     constant across pairs, 66% (SD = 23%), than when
  Results                                                            expected value differed in the opposite direction of
     Participants required on average 1.9 (SD=1.2) cycles of         divergence, p<0.001. Although the percentage of high
  practice on the action-token probabilities. Mean probability       divergence choices was apparently greater when expected
  ratings, obtained right before and right after the gambling        value differed in the same direction as divergence than when
  phase, are shown in Table 1.                                       expected value was held constant, this difference did not
                                                                     reach significance, p=0.09.
!      Table 1: Mean probability ratings with standard
       deviations. Programmed probabilities are shown in
       the top row. Mean ratings, obtained before and                                          Discussion
       after the gambling task, are averaged across actions             We assessed the influence of instrumental outcome
       and outcomes, yielding three unique outcome                   divergence – the extent to which actions differ in terms of
       probabilities.                                                their outcome probability distributions – on behavioral
                                                                     preference in a simple gambling task. In each round of
                       0.7         0.0         0.3                   gambling, participants chose between two pairs of actions,
            Before 0.70 ± 0.02 0.00 ± 0.01 0.30 ± 0.02               knowing that they would be restricted to choosing between
             After 0.65 ± 0.17 0.04± 0.12 0.31 ± 0.07
                                                                     actions in the selected pair on subsequent trials in that
                                                                     round. One pair of actions had high outcome divergence
                                                                     while the other pair had zero outcome divergence. We found
     Consistent with our primary hypothesis, we found that,
                                                                     that, when other decision variables, such as expected value
  when divergence differed across the two available action
  pairs while expected value and outcome entropy were held           and outcome predictability, were held constant, participant
  constant, there was a preference for high over low                 chose the pair with high divergence significantly more often
  divergence, such that participants selected the high               than that with zero divergence.
  divergence pair 66% (SD = 23%) of the time. A planned                 As noted, actions with high outcome divergence afford an
  comparison revealed that this was significantly greater than       agent flexible control over the environment: a commodity
  chance performance, t(19) = 3.20, p < 0.005.                       that is particularly valuable when the utilities of states are
     To assess how preferences for divergence was modulated          dynamically changing, as in the current task. We interpret
  by expected value, blocks were divided into 3 expected             the preference for high divergence demonstrated here as
  value conditions: In the first condition, expected value was       reflecting the intrinsic value of flexible control.
  held constant across the high and low divergence pair, in the      Alternatively, however, participant’s choices may reflect a
  second condition, expected value differed across pairs in the      previously demonstrated tendency to increase diversity,
  same direction as divergence, and in the third condition           motivated by a desire to minimize risk in uncertain
  expected value differed in the opposite direction of               environments (Hedesstrom et al., 2006; Ayal and Zakay,
  divergence. We entered the percentage of high divergence           2009). Although highly related, in that greater outcome
  choices by each participant into a 3 (expected value) x 2          divergence allows for greater diversity, as is the case in the
  (order) x 2 (probability) mixed analysis of variance, with         present study, the flexible control afforded by divergence
  “expected value” as a repeated measure and with “order”            does not necessarily follow from diversity.
  and “probability”, respectively indicating the order of v2 and        To illustrate the distinction between diversity and
  v3 sets and the assignment of probability distributions to         instrumental divergence, imagine that you are allowed to
  actions (see methods), as between-subjects factors.
                                                                     choose between the two scenarios illustrated in Figure 1a
     There was a significant main effect of expected value,
                                                                     and 1b respectively, but that once you make your selection,
  F(2,32)=21.86, p<0.001. There was no significant effect of
                                                                     a computer algorithm chooses between A1 and A2 with a
  the order in which changes in value assignments (i.e., v2 and
  v3 sets) occurred within the sequence of blocks,                   probability of 0.5. While selecting the high-divergence
  F(1,16)=1.14, p=0.30, nor any significant effect of which          scenario in Figure 1b would yield the highest diversity, it
  two of the four actions shared a particular outcome                would not allow you to avoid a particular outcome (e.g., O1)
  probability distribution, F(1,16)=2.62, p=0.13. There were         should this outcome suddenly lose its utility. On the other
  no significant interactions (smallest p=0.13).                     hand, if you were permitted to choose between A1 and A2
     Bonferroni adjusted pairwise comparisons revealed that          yourself, selecting the high-divergence scenario would
  the percentage of high divergence choices was significantly        allow you to completely avoid O1. Alternatively, imagine
  greater when expected value differed in the same direction         that the two outcome probability distributions in Figure 1a
  as divergence, 81% (SD = 24 %), than when expected value           were uniform, such that all outcomes were equally likely:
                                                                 1604

this would yield maximum diversity, but zero instrumental            outcome divergence allows for a potential extension of such
divergence. Further work is needed to discriminate between           effects to the case of multiple probabilistic outcomes.
preferences for diversity versus instrumental divergence in             Finally, outcome divergence may have a modulatory
goal-directed choice.                                                influence on “sense of agency” – a conscious experience of
   On several gambling rounds in the current study, expected         ones capacity to impact the external world commonly
value differed across action pairs, in either the same or            measured as a compression of the perceived time interval
opposite direction of divergence. Participants’ choices were         between voluntary actions and their consequences (Haggard
in accordance with expected value on these rounds, such              et al., 2002; Haggard and Cole, 2007). Intriguingly, a recent
that the percentage of high divergence choices was                   study showed that the degree of temporal compression
significantly greater when expected value differed in the            increased with the number of available actions such that, the
same than in the opposite direction. Indeed, the high                greater the number of action alternatives, the smaller the
divergence pair was only selected on 33% of rounds in                perceived temporal interval (Barlas and Obhi, 2013). A
which expected value differed in the opposite direction.             distinct possibility is that not only the number of available
Although this preference for monetary reward over                    actions but also the divergence of their outcome
divergence would likely have been even more marked if                distributions plays a role in this effect. Notably, since
actual, rather than fictive, monetary amounts had been used,         schizophrenic individuals have been shown to have a
it is also possible that there are relative magnitudes of            dysregulated sense of agency (Haggard et al., 2003; Voss et
currency and divergence at which the value of control                al., 2010), the influence of outcome divergence on this
exceeds that of monetary gain: a breaking point in the trade-        measure may prove to be a useful diagnostic tool in the
off between motivational and information theoretic decision          early detection of thought disorders.
variables.                                                              In summary, we have introduced a novel decision variable
   Model-based reinforcement learning (RL) represents                – instrumental outcome divergence – and demonstrated its
knowledge about action-outcome contingencies as a matrix             influence, dissociable from that of other motivational and
of state-transition probabilities (e.g., Doya et al., 2002; Daw      information theoretic factors, on behavioral preference. Our
et al., 2005). In this framework, on each learning trial,            results complement previous work on the controllability of
leaving one state and arriving in the next contingent on             outcomes (McClure et al., 2001; Haggard et al., 2003;
performing a particular action, the agent computes a state           Teodorescu and Erev, 2014) and contribute towards a fuller
prediction-error, which is then used to update transition            characterization of goal-directed cognition and action.
probabilities. In our previous work (Liljeholm et al., 2013)
we computed instrumental outcome divergence based on                                     Acknowledgements
such trial-by-trial changes in transition probabilities, derived
                                                                     This work was supported by a start-up fund from the
by fitting an RL model to behavioral choices. In the present
                                                                     University of California, Irvine to M.L. The authors thank
study, since participants were trained to criterion on
                                                                     Daniel McNamee for helpful discussion.
outcome probabilities prior to the gambling task, we instead
computed divergence based on two predefined outcome
probability distributions. Future work may consider a more
fine-grained analysis of preference for high divergence                                        References
under conditions of trial-and-error learning.                        Abler B, Herrnberger B, Gron G, Spitzer M (2009) From
   Another interesting consideration is the potential role of           uncertainty to reward: BOLD characteristics differentiate
outcome divergence in stimulus generalization. If two cues              signaling pathways. BMC neuroscience 10:154.
signal identical future states, the cost of discriminating           Ayal S, Zakay D (2009) The perceived diversity heuristic:
between them does not yield a return of improved                        the case of pseudodiversity. Journal of personality and
predictability and, consequently, is likely not worth the               social psychology 96:559-573.
effort. Indeed, it is well known that pairing distinct cues          Balleine BW, Dickinson A (1998) Goal-directed
                                                                        instrumental action: contingency and incentive learning
with the same outcome enhances subsequent generalization
                                                                        and their cortical substrates. Neuropharmacology 37:407-
between those cues, a phenomenon known as acquired
                                                                        419.
equivalence (Honey and Hall, 1989; Liljeholm and Balleine,
                                                                     Barlas Z, Obhi SS (2013) Freedom, choice, and the sense of
2010). Analogously, in acquired distinctiveness, the pairing            agency. Frontiers in human neuroscience 7:514.
of cues with different outcomes decreases subsequent                 Bickel WK, Pitcock JA, Yi R, Angtuaco EJ (2009)
generalization (Bonardi et al., 2005). Thus far, equivalence            Congruence of BOLD response across intertemporal
and distinctiveness effects have, to our knowledge, been                choice conditions: fictive and real money gains and
limited to cases with two distinct outcome states and                   losses. J Neurosci 29:8839-8846.
deterministic cue-outcome relationships. The use of                  Bonardi C, Graham S, Hall G, Mitchell C (2005) Acquired
                                                                        distinctiveness and equivalence in human discrimination
                                                                 1605

  learning: evidence for an attentional process.                Seo H, Barraclough DJ, Lee D (2009) Lateral intraparietal
  Psychonomic bulletin & review 12:88-92.                         cortex and reinforcement learning during a mixed-strategy
Bowman CH, Turnbull OH (2003) Real versus facsimile               game. J Neurosci 29:7278-7289.
  reinforcers on the Iowa Gambling Task. Brain and              Sperduti M, Delaveau P, Fossati P, Nadel J (2011) Different
  cognition 53:207-210.                                           brain structures related to self- and external-agency
Chaminade T, Decety J (2002) Leader or follower?                  attribution: a brief review and meta-analysis. Brain
  Involvement of the inferior parietal lobule in agency.          structure & function 216:151-157.
  Neuroreport 13:1975-1978.                                     Teodorescu K, Erev I (2014) Learned helplessness and
Daw ND, Niv Y, Dayan P (2005) Uncertainty-based                   learned prevalence: exploring the causal relations among
  competition between prefrontal and dorsolateral striatal        perceived controllability, reward prevalence, and
  systems for behavioral control. Nature neuroscience             exploration. Psychological science 25:1861-1869.
  8:1704-1711.                                                  Tolman EC (1948) Cognitive maps in rats and men.
den Ouden HM, Frith U, Frith C, S.J. B (2005) Thinking            Psychological review 55:189-208.
  about intentions. NeuroImage 28:787-796.                      Voss M, Moore J, Hauser M, Gallinat J, Heinz A, Haggard
Doya K, Samejima K, Katagiri K, Kawato M (2002)                   P (2010) Altered awareness of action in schizophrenia: a
  Multiple model-based reinforcement learning. Neural             specific deficit in predicting action consequences. Brain :
  computation 14:1347-1369.                                       a journal of neurology 133:3104-3112.
Erev I, Barron G (2005) On adaptation, maximization, and        Weber BJ, Huettel SA (2008) The neural substrates of
  reinforcement learning among cognitive strategies.              probabilistic and intertemporal decision making. Brain
  Psychological review 112:912-931.                               research 1234:104-115.
Farrer C, Frey SH, Van Horn JD, Tunik E, Turk D, Inati S,
  Grafton ST (2008) The angular gyrus computes action
  awareness representations. Cereb Cortex 18:254-261.
Haggard P, Cole J (2007) Intention, attention and the
  temporal experience of action. Consciousness and
  cognition 16:211-220.
Haggard P, Clark S, Kalogeras J (2002) Voluntary action
  and conscious awareness. Nature neuroscience 5:382-385.
Haggard P, Martin F, Taylor-Clarke M, Jeannerod M,
  Franck N (2003) Awareness of action in schizophrenia.
  Neuroreport 14:1081-1085.
Hedesstrom TM, Svedsater H, Garling T (2006) Covariation
  neglect among novice investors. J Exp Psychol-Appl
  12:155-165.
Honey RC, Hall G (1989) Acquired equivalence and
  distinctiveness of cues. Journal of experimental
  psychology Animal behavior processes 15:338-346.
Liljeholm M, Balleine BW (2010) Extracting functional
  equivalence from reversing contingencies. Journal of
  experimental psychology Animal behavior processes
  36:165-171.
Liljeholm M, Tricomi E, O'Doherty JP, Balleine BW (2011)
  Neural correlates of instrumental contingency learning:
  differential effects of action-reward conjunction and
  disjunction. J Neurosci 31:2474-2480.
Liljeholm M, Wang S, Zhang J, O'Doherty JP (2013) Neural
  correlates of the divergence of instrumental probability
  distributions. J Neurosci 33:12519-12527.
McClure J, Densley L, Liu JH, Allen M (2001) Constraints
  on equifinality: goals are good explanations only for
  controllable outcomes. The British journal of social
  psychology / the British Psychological Society 40:99-115.
Miyapuram KP, Tobler PN, Gregorios-Pippas L, Schultz W
  (2012) BOLD responses in reward regions to hypothetical
  and imaginary monetary rewards. Neuroimage 59:1692-
  1699.
                                                            1606

