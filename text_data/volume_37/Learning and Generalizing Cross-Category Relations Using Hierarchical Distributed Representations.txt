                            Learning and Generalizing Cross-Category Relations
                                 Using Hierarchical Distributed Representations
                                                    Dawn Chen1 (sdchen@ucla.edu)
                                                 Hongjing Lu1, 2 (hongjing@ucla.edu)
                                           Keith J. Holyoak1 (holyoak@lifesci.ucla.edu)
                                                 Departments of Psychology1 and Statistics2
                                                    University of California, Los Angeles
                                                         Los Angeles, CA 90095 USA
                               Abstract                                     A few models based on neural-network architectures
                                                                         (Doumas, Hummel & Sandhofer, 2008; Smith, Gasser &
   Recent work has begun to investigate how structured relations
   can be learned from non-relational and distributed input              Sandhofer, 1997) have had some success in modeling
   representations. A difficult challenge is to capture the human        bottom-up relation learning. However, it is difficult to fully
   ability to evaluate relations between items drawn from distinct       evaluate the adequacy of proposed models of relation
   categories (e.g., deciding whether a truck is larger than a           learning without first controlling the nature of the
   horse), given that different features may be relevant to              elementary inputs on which learning is based. A well-known
   assessing the relation for different categories. We describe an       limitation of models of analogy (for which relational
   extension of Bayesian Analogy with Relational
   Transformations (BART; Lu, Chen & Holyoak, 2012) that
                                                                         knowledge is central) is that modelers typically create their
   can learn cross-category comparative relations from                   own “toy” input representations, which may be tailored
   autonomously-generated and distributed input representations.         (perhaps inadvertently) so as to reduce task difficulty
   BART first learns separate representations of a relation for          (Chalmers, French & Hofstadter, 1992). In modeling basic
   different categories and creates second-order features based          relation learning, it is critical to ensure that the non-
   on these category-specific representations. BART then learns          relational inputs on which learning operates are
   weights on these second-order features, resulting in a                autonomously created (rather than hand-coded by the
   category-general representation of the relation. This
   hierarchical learning model successfully generalizes the              modeler), and are of realistic complexity. When a model of
   relation to novel pairs of items (including items from different      relation learning is forced to operate on realistic inputs,
   categories), outperforming a flat version of the learning             theoretical issues that might have gone unnoticed with
   model.                                                                simpler inputs are brought to the fore.
   Keywords: relation learning; generalization; distributed                 Here we address one key issue that arises in learning
   representations; Bayesian models                                      relations from non-relational and realistically complex
                                                                         inputs: How can a learned relation be generalized to novel
                           Introduction                                  items, which have representations dissimilar to the items
                                                                         used to train the system? We first describe the basic model
Learning Relations from Non-relational Inputs                            that served as our starting point, and then demonstrate how
                                                                         it could be extended to overcome apparent limits on its
A hallmark of human intelligence is the ability to learn and
                                                                         capacity to generalize.
make inferences based on relations between entities, rather
than solely on features of individual entities (for a review
                                                                         Bayesian Model of Relation Learning
see Holyoak, 2012). A challenge for cognitive science is to
explain how relations can be acquired. Some approaches to                Recently, discriminative Bayesian models have been used to
relation learning postulate some sort of grammar that                    learn relations in a bottom-up fashion. A key idea is that an
generates possible relations, tacitly assuming that the origin           n-ary relation can be represented as a function that takes an
of relational concepts is top-down (e.g., Tenenbaum, Kemp,               ordered set of n objects as its input and outputs the
Griffiths & Goodman, 2011). Doubtless some relations are                 probability that these objects instantiate the relation. The
constructed in a top-down fashion, but there is strong                   model learns a representation of the relation from labeled
evidence that at least some relations are formed by bottom-              examples, and then applies the learned representation to
up processes (Mandler, 1992). For example, children seem                 determine whether the relation holds for novel examples. A
to acquire comparative relations such as larger than in                  second key idea is that relation learning can be facilitated by
stages, first learning features of individual objects, then              incorporating empirical priors, which are derived using
extracting specific attributes of individual objects (e.g., a            some simpler learning task that can serve as a precursor to
size value), and eventually linking attributes of paired                 the relation learning task (Silva, Heller & Ghahramani,
objects to form a binary relation (Smith, 1989). Thus a basic            2007).
problem for cognitive science is: How can relations be                      These ideas were incorporated into Bayesian Analogy
acquired from non-relational inputs?                                     with Relational Transformations (BART), a discriminative
                                                                     339

model that can learn comparative relations from non-                      BART’s learned relations support generalization to new
relational inputs (Lu, Chen & Holyoak, 2012). Given                    animal pairs. After receiving 100 training pairs represented
independently-generated feature vectors representing pairs             using topic feature vectors, the model discriminates between
of animals that exemplify a relation, the model acquires               novel pairs that instantiate a relation and those that do not
representations of first-order comparative relations (e.g.,            with about 70-80% accuracy. The model yields the classic
larger, faster) as weight distributions over the features. The         symbolic distance effect (Moyer & Bayer, 1976), as
richest and most complex feature representations we have               discrimination accuracy increases monotonically with the
used are derived by applying the topic model (Griffiths,               magnitude difference between items in a pair. Moreover,
Steyvers, & Tenenbaum, 2007) to the English Wikipedia                  BART’s learned weight distributions can be systematically
corpus. The output of the topic model is used to create a              transformed to solve analogies based on higher-order
real-valued feature vector for each word. The simulations              relations between the learned first-order relations (e.g.,
presented here are based on topic vectors.                             opposite). A simpler version of the model can predict
   BART represents a relation using a joint distribution of            magnitude values (based on human ratings) for individual
weights, w, over object features. A relation is learned by             objects (Chen et al., 2014), and an extension can use its
estimating the probability distribution P( w | XS , RS ), where        learned relational representations to generate novel items
                                                                       instantiating the relation (Chen, Lu & Holyoak, 2013).
 X S represents the feature vectors for object pairs in the
training set, the subscript S indicates the set of training            Relations Linking Distinct Categories
examples, and R S is a set of binary indicators, each of               BART has thus demonstrated the promise of using a
which (denoted by R) indicates whether a particular object             bottom-up approach to bootstrap relation learning.
(or pair of objects) instantiates the relation or not. The             However, after being trained on animal pairs, the initial
multivariate distribution of weights, w, constitutes the               model failed on tests requiring generalization to inanimate
learned relational representation, which can be interpreted            objects (e.g., deciding if a toaster is larger than a shoe),
as quantifying the influence of the corresponding feature              performing only slightly above chance (about 57%
dimensions in X on judging whether the relation applies.               accuracy).
The weight distribution can be updated based on examples                  This failure illustrates the importance of using realistic,
of ordered pairs that instantiate the relation. Formally, the          independently-generated inputs. It would have been easy to
posterior distribution of weights can be computed by                   hand-code a local feature representing a discriminative
applying Bayes’ rule using the likelihood of the training              dimension (e.g., a size value) into the representations of all
data and the prior distribution of w (which we assume to be            physical entities, in which case the model would readily
independent of the object-pair features in the training set,           generalize a relation learned from pairs within a specific
 XS ) :                                                                domain (e.g., animal pairs) to all pairs of entities. But topic
                                P  R S | w, X S  P  w              inputs do not provide such discriminative features. As a
           P  w | XS , RS                                 . (1)     consequence, each relation acquired by BART is
                                P R
                                w
                                        S | w, X S  P  w            represented by a highly distributed pattern of weights across
   The likelihood is defined as a logistic function for                many feature dimensions. The pattern acquired using one
computing the probability that a pair of objects instantiates          subset of entities (animals) may not match the pattern
the relation, given the weights and feature vector:                    needed to make relational discriminations for a different
                                             1                         subset (inanimate objects). It is easy to imagine features that
                    P( R  1| w, x)            T .            (2)     would impact a relational discrimination very differently for
                                       1  e w x                      different classes of entities. For example, the feature “is
   The prior, P(w), is a Gaussian distribution and is                  from Africa” might predict that an animal is relatively large,
constructed using a bottom-up approach in which initial                but that a building is relatively small. Similarly, a topic
learning of simple concepts provides empirical priors that             feature of “found in nature” might be associated with certain
guide subsequent learning of more complex concepts.                    large objects (e.g., mountain, ocean), but have weak
Specifically, BART extracts empirical priors from weight               predictive power for the sizes of most animals.
distributions for one-place predicates such as large to guide             Semantic hierarchies are built out of disjunctions of
the acquisition of two-place relations such as larger. Lu et           different categories (Hampton, 1988), and more general
al. (2012) trained BART on the eight one-place predicates              categories are typically more difficult to learn than specific
(e.g., large, small, fierce, meek) that can be formed using            ones (e.g., Horton & Markman, 1980). Ecologically, it
the extreme animals at each end of the four relevant                   seems very likely that comparative relations most
continua (size, speed, ferocity, and intelligence). When               commonly are learned using pairs of entities drawn from a
learning a two-place relation, BART automatically chooses              relatively specific category (e.g., a dog is larger than a cat; a
the most relevant one-place predicate based on the training            bowl is larger than a glass). Nonetheless, adults are quite
pairs for the relation, from which the empirical prior weight          accurate in judging relative sizes of dissimilar entities they
distribution is derived. For additional details on the                 may never have previously considered together (e.g., a
operation of the model, see Lu et al. (2012).                          toaster is larger than a sparrow; Holyoak, Dumais & Moyer,
                                                                   340

1979). Thus, comparative relations can be evaluated not                   Domain and Inputs
only for items drawn from a single specific category, but                 Although in principle our model could learn any
also for items drawn from different categories. Here we                   comparative relation that encompasses multiple categories,
describe a hierarchical extension of the BART model that                  here we focus on the larger and smaller relations between
addresses generalization across different categories, and                 animals and inanimate objects. To establish the “ground
report tests comparing its performance with a “flat” (non-                truth” of whether various pairs of entities instantiate these
hierarchical) version of the same model.                                  relations, we used a set of human ratings of size for a mixed
                                                                          set of animals and objects (Holyoak et al., 1979). After
      Hierarchical Model of Relation Learning                             ambiguous words (e.g., “match”) were removed, there were
                                                                          32 animals and 111 inanimate objects for which topic
Overview                                                                  representations were available.
The computational goal is to learn comparative relations,                    To obtain topic feature vectors, we ran the topic model on
such as larger, that span multiple categories (animals and                Wikipedia corpus to obtain 300 topics. Note that deriving a
inanimate objects), from mostly within-category examples                  higher number of topics would take a very long time on
(animal-animal pairs and object-object pairs) and a small                 such a large corpus. The algorithm was used to generate a
number of cross-category examples (animal-object and                      Markov chain. The first sample was taken after 1,000
object-animal pairs). We have developed a two-layer model                 iterations, and sampling was repeated once every 100
for this task, illustrated in Figure 1. The bottom layer                  iterations until eight samples were produced. Each sample
contains the raw input features, which we term first-order                yielded a matrix in which the (i, j)th entry is the number of
features. Based on within-category examples described by                  times that word i has been assigned to topic j. From this
first-order features, the model first learns a separate,                  matrix, we derived a vector for each word based on the
specialized representation of the relation for each category.             conditional probability of each topic given that word. We
From         these      initial    category-specific     relational       averaged the word vectors created from different samples of
representations, the model derives a small number of more                 the Markov chain because they contained very similar topics
abstract features (second-order features), which comprise                 (determined by examining the most probable words for each
the model’s second layer of features. These second-order                  topic).
features have similar interpretations across different                       Finally, we reduced the dimensionality of the topic
categories, abstracting away differences among the                        vectors by automatically choosing 50 effective features
categories in how their first-order features influence                    (those for which learning is enabled) for animals and objects
relational judgment. The model then learns a second layer of              separately. These were simply the features most associated
weights that operate on second-order features to predict                  with the items in each category (i.e., those with the highest
whether a pair of entities (possibly from different                       values summed across the items). Thus, animals and objects
categories) instantiates the comparative relation. These                  are represented by different (but possibly overlapping) sets
second-order weights can be learned from cross-category as                of effective features. As we will see, the hierarchical model
well as within-category examples. We use a small number                   allows entities from different categories to be represented by
of cross-category examples in most of our simulations, but                different sets of effective features. Figure 2 provides a
we also experiment with using only within-category                        visualization of the topic vectors (reduced to 10 features) for
examples.                                                                 10 animals and 10 objects. Note that the topic vector for
                                                                          each word is not constrained to be a probability distribution
                                                                          over topics.
                                                                 Relation
                                                               (e.g., larger)
                                       second-order
                                         weights
     second-order features
     first-order weights                                                                                         first-order weights
     for animals                                                                                                 for objects
     first-order features                    …                    …                       …                    …
                                animal 1             animal 2                 object 1             object 2
 Figure 1: Illustration of the hierarchical model of relation learning with an example in which an animal occupies the first role
 and an object occupies the second role (e.g., whale-ocean). The first-order relational weights for animals are highlighted in
 light blue and the weights for objects are highlighted in purple. Features and weights for the second relational role are
 indicated with dashed lines. Each second-order feature is distinguished by a different color.
                                                                     341

Table 1: The top 10 words associated with some example                            for the first role and positive for the second role, associated
topics found by the topic model using the Wikipedia corpus.                       with features that predict smallness (the con cluster); and (3)
                                                                                  around zero for both roles (with a few weights that are
Topic                                  Top 10 words                               positive or negative for both roles), corresponding to
                                                                                  features that are uncorrelated with size (the neutral cluster).
   1      fish marine fishing sea species water waters ocean shark whale
                                                                                  These patterns were indeed the three clusters that the k-
   2      food rice meat made milk foods served cuisine cooking eating            means algorithm typically found for the learned weights, as
                                                                                  illustrated by the example in Figure 3. (The choice of k = 3
   3      wear worn wearing hair dress wore made fashion clothing black
                                                                                  is further justified by a plot of the sum of all within-cluster
          disease virus infection cases infected HIV diseases spread human        point-to-centroid distances as a function of k, in which an
   4
          AIDS
                                                                                  “elbow” occurs at k = 3.)
   5      animals animal harry potter wild bear hunting lion horn sheep
   6      forest species plant tree plants trees wood forests native found                               Animals       Objects
                                                                                                      Role 1 Role 2  Role 1 Role 2
          land agricultural farm farmers food farming agriculture crops rural
   7
          production
                                                                                      Pro cluster:                                    Pro cluster:
   8      park hill creek mount parks area mountain trail located rock               Includes topics                                 Includes topics
                                                                                         5 and 7                                         1 and 8
                    Animals                                 Objects
                      topic                                   topic                   Con cluster:
                                                                                    Includes topic 4
          1 2 4 5 7 11 12 13 15 16                  1 2 3 6 8 9 10 11 14 16                                                           Con cluster:
  whale                                     ocean                                                                                    Includes topics
    cow                                  mountain                                                                                        2 and 3
 donkey                                       pond
      pig                                      tree
penguin                                        bed
     dog                                      sock
   duck                                        egg                                  Neutral cluster:
 mouse                                       acorn                                   Includes topics
minnow                                     earring                                       1 and 2                                         Neutral
                                               pea                                                                                       cluster:
     flea
                                                                                                                                    Includes topic 6
Figure 2: Illustration of topic vectors (reduced to 10 features
to conserve space) for some example animals and objects,
which are sorted by their sizes. The cell intensities represent
feature values (dark indicates high values and light indicates                                         -1   0   1   -1     0    1
low values).
                                                                                  Figure 3: Illustration of the first-order weights that BART
Operation of the Model                                                            learned for each category and the three clusters found by the
                                                                                  k-means algorithm for one run of the model. Each row
Learning First-Order Weights In order to learn the initial
                                                                                  within each set of weights represents a single topic
category-specific relational representations, the original
                                                                                  dimension. See Table 1 for interpretation of some of the
BART model is trained separately on 40 animal-animal
                                                                                  topics in each cluster. Note that corresponding clusters for
pairs and 40 object-object pairs that instantiate larger (or
                                                                                  the two categories include different features.
smaller; we will use the larger relation to illustrate the
operation of the model in the rest of this paper). This phase
                                                                                      A single second-order feature is derived from each
of learning yields two weight distributions: one that
                                                                                  cluster. For a given pair of entities, each second-order
represents the larger relation for animals and one for
                                                                                  feature is computed by taking the dot product between the
objects.
                                                                                  first-order feature values in the corresponding cluster and
Deriving Second-Order Features For each category, the                             the learned first-order weight means on those features. As
model uses k-means clustering to separate the input features                      illustrated in Figure 1, the weights for the appropriate item
into three clusters, based on the pattern of learned first-order                  category and relational role are used. For example, given the
weights across the two relational roles (i.e., larger-object                      pair whale-ocean, the role-1 weights for animals are used to
and smaller-object). We chose k = 3 because we                                    calculate the second-order features for whale, and the role-2
hypothesized that the weights for comparative relations                           weights for inanimate objects are used for ocean. Since
would generally follow three distinct patterns: (1) positive                      there are three clusters for each role, a total of six second-
for the first role and negative for the second role, associated                   order features are calculated for each pair of entities.
with features that predict largeness for the particular                           Critically, the second-order features are indifferent to the
category, animals or objects (the pro cluster); (2) negative                      identity and number of the first-order features included in
                                                                                  each cluster.
                                                                              342

Learning Second-Order Weights We use the original                                  mean accuracy on the larger relation across ten runs for the
BART model with an uninformative prior (zero means and                             two models on each type of test pair (the results for smaller
identity covariance matrix) to learn the weights on the                            were similar). The hierarchical model outperformed the
second-order features from a small number (10 or fewer) of                         baseline model by about 19 percentage points across the
cross-category pairs that instantiate larger. In our                               three types of test pairs. In subsequent tests, we focus on
simulations, we experiment with using different numbers of                         cross-category test pairs, which are the most interesting type
such training pairs.                                                               because the models must consider items from different
                                                                                   categories together (the type that occurs least frequently in
Baseline Model                                                                     the training set).
We compare the hierarchical model to a “flat” model that
does not include second-order features and weights. This is                        Number of Cross-Category Training Examples
simply the original BART model, given 40 within-category                           We varied the number of cross-category training examples
examples of each type and 10 cross-category examples. For                          while keeping constant the number of within-category
this model, entities from different categories must be                             examples of each type (40), and tested the models on 100
represented by the same set of effective features. We use the                      novel cross-category pairs. Figure 5 shows the mean
union of the two sets of 50 features selected for animals and                      accuracy on larger across ten runs for the two models as a
objects, resulting in a set of 79 features.                                        function of the number of cross-category training pairs
                                                                                   (ranging from 0 to 10). (Once again, the results for smaller
                          Simulation Results                                       were similar.) The hierarchical model performed at chance
We evaluated the models by running them on ten different                           level when no cross-category examples were provided,
sets of training pairs and novel test pairs. These pairs were                      because its second-order weights had not been learned and
randomly chosen from the set of all possible pairs that                            were simply the prior (zero means and identity covariance
instantiate a specific relation. Each model calculates the                         matrix). The baseline model was insensitive to the number
probability of instantiating the relation for each test pair                       of cross-category training pairs, whereas accuracy for the
(e.g., penguin-flower) and its reverse (flower-penguin), so                        hierarchical model increased with the number of cross-
the test set contains an equal number of positive and                              category pairs, besting the baseline model after just four
negative examples of the relation. The model is considered                         examples.
to be correct on a test pair if the pair instantiates the relation
and its predicted probability is greater than .5, or if the pair                                              Generalization for larger
does not instantiate the relation and its predicted probability                                 1
                                                                                                                                          Model
is less than .5. Results are averaged over the ten runs. Here                                  0.9
we report the results of several tests of the generalization                                                                              Hierarchical
                                                                                    Accuracy
                                                                                               0.8
ability of each model.
                                                                                               0.7                                        Baseline
Testing on Pairs of Each Type                                                                  0.6
In the first test, we trained each model on 40 animal-animal                                   0.5
pairs, 40 object-object pairs, and 10 cross-category pairs.                                    0.4
We then tested each model on 100 novel animal-animal,                                                0   2     4     6    8    10    12
object-object, or cross-category pairs. Figure 4 shows the
                                                                                                     Number of Cross-Category Examples
                          Generalization for larger
                                                               Model               Figure 5: Learning curves for the two models: mean
            1
                                                                                   accuracy of models on a generalization test for larger across
           0.8                                                Hierarchical         10 runs as a function of number of cross-category training
                                                                                   pairs. Error bars indicate 1 standard deviation.
Accuracy
           0.6                                                Baseline
                                                                                   Type of Examples for Second-Order Weights
           0.4
                                                                                   The hierarchical model’s second-order weights apply
           0.2                                                                     equally to pairs drawn from the same or different categories
                                                                                   because they operate on the same set of second-order
            0                                                                      features for each category. Thus, the hierarchical model
                 animal-animal object-object cross-category
                                                                                   improves performance on all pair types (see Figure 4). It
                            Type of Test Pairs                                     follows that the model should perform well on cross-
                                                                                   category test pairs even when its second-order weights are
Figure 4: The models’ mean accuracy on a generalization                            learned from within-category examples only. We again
test for larger across ten runs for different types of test                        trained the first-order weights using 40 animal-animal and
pairs. Error bars indicate 1 standard deviation.                                   40 object-object pairs. We then trained the model’s second-
                                                                             343

order weights on 10 additional pairs: either 10 animal-                critique of artificial intelligence methodology. Journal of
animal pairs, 10 object-object pairs, 5 within-category pairs          Experimental and Theoretical Artificial Intelligence, 4,
of each type, or 10 cross-category pairs. Finally, we tested           185–211.
the model on 100 novel cross-category pairs. The model               Chen, D., Lu, H., & Holyoak, K. J. (2013). Generative
achieved accuracies of 91%, 92%, and 91% on larger when                inferences based on a discriminative Bayesian model of
trained respectively on 10 animal-animal pairs, 10 object-             relation learning. In M. Knauf, M. Pauven, N. Sebanz, &
object pairs, and 5 within-category pairs of each type. In             I. Wachsmuth (Eds.), Proceedings of the 35th Annual
comparison, accuracy was 93% when the model’s second-                  Conference of the Cognitive Science Society (pp. 2028-
order weights were learned from 10 cross-category                      2033). Austin, TX: Cognitive Science Society.
examples. Thus, the hierarchical model can learn to make             Chen, D., Lu, H., & Holyoak, K. J. (2014). The discovery
relational judgments for cross-category pairs without ever             and comparison of symbolic magnitudes. Cognitive
encountering a single example of such pairs.                           Psychology, 71, 27-54.
                                                                     Doumas, L. A. A., Hummel, J. E., & Sandhofer, C. M.
                   General Discussion                                  (2008). A theory of the discovery and predication of
We have demonstrated that a hierarchical extension of the              relational concepts. Psychological Review, 115, 1-43.
BART model can learn and generalize comparative relations            Griffiths, T. L., Steyvers, M., & Tenenbaum, J. B. (2007).
across dissimilar categories, using non-relational topic               Topics in semantic representation. Psychological Review,
vectors as inputs. The key to the model’s performance is its           114, 211-244.
creation of higher-order features based on patterns of               Hampton, J. A. (1988). Disjunction of natural concepts.
category-specific first-order weights applied to primitive             Memory & Cognition, 16, 579-591.
features representing individual entities.                           Holyoak, K. J. (2012). Analogy and relational reasoning. In
   Insight into the superior performance of the hierarchical           K. J. Holyoak & R. G. Morrison (Eds.), The Oxford
model can be provided by examining the topic dimensions                handbook of thinking and reasoning (pp. 234-259). New
from which the model created each second-order feature.                York: Oxford University Press.
One topic that appears in the feature representations of both        Holyoak, K. J., Dumais, S. T., & Moyer, R. S. (1979).
animals and objects involves fish and the sea (topic 1; see            Semantic association effects in a mental comparison task.
Table 1). For objects, this topic was a part of the pro feature        Memory & Cognition, 7, 303-313.
for larger (objects related to the sea tend to be large, such as     Horton, M. S., & Markman, E.M. (1980). Developmental
ocean, pond, and boat), whereas for animals it was a part of           differences in the acquisition of basic and superordinate
the neutral feature (marine animals span the full range of             categories. Child Development, 51, 708-719.
sizes). Another feature shared by animals and objects is a           Lu, H., Chen, D., & Holyoak, K. J. (2012). Bayesian
topic related to food (topic 2 in Table 1). This feature was a         analogy with relational transformations. Psychological
part of the con feature for objects (food items and objects            Review, 119, 617-648.
related to cooking tend to be small), but a part of the neutral      Mandler, J. M. (1992). How to build a baby: II. Conceptual
feature for animals (animals of various sizes are eaten).              primitives. Psychological Review, 99(4), 587.
   As we expected, first-order features impacted relational          Moyer, R. S., & Bayer, R. H. (1976). Mental comparison
judgments differently for different categories of entities. For        and the symbolic distance effect. Cognitive Psychology, 8,
each of the topic dimensions mentioned above, the baseline             228–246.
model is forced to learn a single weight that applies to both        Silva, R., Heller, K., & Ghahramani, Z. (2007). Analogical
animals and objects, and therefore cannot capture these                reasoning with relational Bayesian sets. In M. Mella & X.
differences between categories. In contrast, the hierarchical          Shen (Eds.), Proceedings of the Eleventh International
model accommodates these differences by assigning each                 Conference on Artificial Intelligence and Statistics.
topic dimension to the cluster corresponding to the most             Smith, L. B. (1989). From global similarities to kinds of
appropriate second-order feature (pro, con, or neutral),               similarities: The construction of dimensions in
which may differ for each category. These second-order                 development. In S. Vosniadou & A. Ortony (Eds.),
features have similar interpretations across different                 Similarity and analogical reasoning (pp. 147-177).
categories, and hence simplify the complex and distributed             Cambridge, UK: Cambridge University Press.
input representations from which relations can be acquired.          Smith, L. B., Gasser, M., & Sandhofer, C. M. (1997).
                                                                       Learning to talk about the properties of objects: A
                                                                       network model of the development of dimensions. In R.
                    Acknowledgments
                                                                       L. Goldstone, D. L. Medin & P. G. Schyns (Eds.),
Preparation of this paper was supported by a grant from the            Advances in the psychology of learning and motivation,
National Science Foundation (BCS-135331).                              Vol. 36: Perceptual learning (pp. 219-255). San Diego,
                                                                       CA: Academic Press.
                         References                                  Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman,
Chalmers, D. J., French, R. M., & Hofstadter, D. R. (1992).            N. D. (2011). How to grow a mind: Statistics, structure,
   High-level perception, representation, and analogy: A               and abstraction. Science, 331, 1279-1285.
                                                                 344

