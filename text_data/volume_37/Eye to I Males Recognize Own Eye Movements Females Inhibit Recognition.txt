       Eye to I: Males Recognize Own Eye Movements, Females Inhibit Recognition
  Sanjay Chandrasekharan, Geetanjali Date, Prajakt Pande, Jeenath Rahaman, Rafikh Shaikh, Anveshna
       Srivastava, Nisheeth Srivastava, Harshit Agrawal (sanjay, geet, prajaktp, jeenatr, rafikh, anveshna
                       @hbcse.tifr.res.in, nisheeths@gmail.com, harshitagrawal.iitr@gmail.com)
                       The Learning Sciences Research Group, Homi Bhabha Centre for Science Education,
                                                  Tata Institute of Fundamental Research,
                                                           Mumbai, 400088, India
                              Abstract                                   of light, and their own clapping from a set of recordings of
   Studies show that people can recognize their own movements,
                                                                         clapping (Flach, Knoblich & Prinz, 2004). Similarly,
   such as their own walking (presented in silhouette using point        pianists can pick out their own rendition of a piece from a
   lights), their own drawing (presented as a moving point light),       set of recordings of the same piece (Repp & Knoblich,
   own clapping, and their own piano playing. We extend this             2004). People can also recognize their own manipulation of
   result to proprioceptive control, showing that people can             a puppet (Mazalek et al., 2009), as well as virtual avatars
   recognize their own eye movements, when presented as just a           that encode their own movements (Mazalek et al., 2010).
   point moving against a black background. Eye movements                   This type of self-recognition is explained by the theory of
   were recorded using a wearable eye tracking glass, while
   participants executed four tasks. A week later, participants          common coding (Prinz, 1992; 1997; Hommel et al., 2001),
   were shown these videos, alongside another person's videos,           which postulates that execution, perception and imagination
   for each task, and asked to recognize their own movements.            of movements share a common code at the neural level. This
   Males recognized their own eye movements significantly                code leads to the automatic, but covert, activation of the
   above chance, but only for tasks with large and familiar body         motor system when perceiving biological movements. This
   movements. Females performed below chance in these tasks.             covert activation of the motor system (or simulation) allows
   We argue that the standard common coding/motor simulation
                                                                         the participant to judge which encountered movement is
   model does not account for this result, and propose an
   extension where eye movements and body movements are                  more familiar, and this familiar movement is then identified
   strongly coupled. In this model, eye movements automatically          as one's own movement.
   trigger covert motor activation, and thus participate directly in        In the study reported here, we extend this line of research
   motor planning, simulations and the sense of agency.                  in two ways. One, we investigated whether the self-
   Keywords: Self-recognition, Eye movements, Common                     recognition effect holds for proprioceptive control
   coding, Motor simulation, Oculo-motor coupling, Agency                (Donaldson, 2000), by examining recognition of own eye-
                                                                         movements when presented in a format similar to the point
                          Introduction                                   light walker, where the eye movements made during tasks is
                                                                         displayed using a red dot moving in a dark background.
   The ability to recognize oneself is a central component of
                                                                         Results show that people can recognize their own eye
self-awareness. Many studies have examined the
                                                                         movements, but the recognition response is different for
evolutionary and developmental origins of self-recognition,
                                                                         males and females. Second, we argue that the common
particularly the ability to recognize oneself in a mirror,
                                                                         coding/simulation account is insufficient to explain our
which has been studied in the case of different animals
                                                                         results, and propose a related model, where overt eye
(Gallup, Anderson & Shillito, 2002) as well as human
                                                                         movements trigger covert body movements.
babies (Bertenthal & Fischer, 1978; Lewis & Brooks-Gunn,
1979). Another approach to understanding self-recognition
involves studying the way people recognize their own faces
                                                                                            Experiment Design
(Tsakiris, 2008), particularly the neural mechanisms                        Briefly, we recorded eye movements of participants using
involved in this process (Devue et al., 2007).                           a wearable eye tracking glass (Tobii), while they executed
   A third approach to study self-recognition is based on                four actions. Two of the actions were familiar (walking,
recording people's movements, and presenting sparse                      climbing) and involved systematic eye movements in
versions of these movements, to examine whether people                   relation to whole body movements. The other two actions
can recognize their own movements, when presented next to                (walking with one leg tied to another person's leg, shading
others' movements (Loula et al., 2005). An influential                   different sized circles in a sequence) were chosen to
experiment (Johansson, 1973) created 'point light walkers'               minimize the systematic connection between eye movement
by attaching lights to participants' joints, and filming their           and whole-body movement. These tasks were chosen based
walking in a dark room. When presented sets of such point                on pilot testing, where participants were shown actual scene
light videos, with one encoding their own movements and                  videos (i.e. the world as seen by the wearer of the eye
another encoding someone else's movements, participants                  tracking glass) generated by the tracker software. The eye
could recognize their own movements. Extending this                      movements were superimposed in this video scene as a
approach, Knoblich and Prinz (2001) showed that people                   moving red dot. Participants could identify their own eye
can recognize their own handwriting traced by a moving dot               movements, as well as others' movements, in these scene
                                                                     327

videos. Interviews suggested that this was achieved by               very difficult for participants to refer to and track any
identifying the walking style of the participant in these            markers to identify their own eye movements.
videos, particularly the head movement patterns, which are              In the test block, run after a week, each participant was
encoded in the way the scene moves ('bounces') in these              first shown a demo, where two videos were shown, and the
videos, as the external world moves in tandem with the head          experimenter showed how to select a video using keyboard
movements. To remove these body movement cues, we                    input (Q for left video, P for right video). Participants were
superimposed the eye movements on a black background,                instructed that their task was to select the video that showed
thus removing all scene movement information. These                  their own movement. Once a participant indicated
videos minimize head movement cues. However, it was felt             understanding of the setup, we showed them 8 recordings (4
that some systematic body movement may still be                      tasks x 2 instruction conditions) of their eye movements
embedded in the eye movement patterns, and this implicit             alongside those of another participant randomly selected
body movement could be used as a cue for recognizing one's           from our participant pool (a new contrast participant picked
own movement. Two tasks (3-leg, drawing) were developed              for each of the 8 trials). The relative position of the videos
as controls to address this issue, as these tasks                    was selected as the outcome of a Bernoulli trial (p = 0.5).
disrupt/minimize the connection to full body movement.               Videos recorded without instruction were shown first in the
  A week after recording the videos using the eye tracking           block, followed by videos recorded with instruction.
glass, participants did a 2-alternative forced choice task,
where two black background videos were displayed side by
side in each trial (one showing their own eye movements,
the other showing another person's eye movements).
Participants had to identify their own eye movements.
                Materials and Methods
The design of the study followed the standard format of the
earlier self-recognition studies (Knoblich & Prinz, 2001,
Mazalek et al., 2009; 2010). All participants individually
completed two separate protocols, a recording block and a
test block, with an intervening interval of 7-12 days. In the
recording block, they completed a set of four actions:
     (1) walking in a corridor (walk)                                            Figure 1: Screenshot of the choice task
     (2) climbing four flights of stairs (climb)
     (3) walking in a corridor, with one leg tied to an                The videos participants saw were generated with a C
          experimenter's leg (3-leg)                                 program, using screen coordinates of gaze-points detected
     (4) shading differentially sized circles on an A3 sheet         by the tracker. The program determined where on the screen
          with a pencil (draw)                                       a circle sized 20 pixels would be drawn across a series of
The primary recording was done without any instruction on            frames. We sampled the frame rate of the videos to
the details of the experiment. After completing the four             synchronize with the 30 fps rate of the tracker, to ensure that
actions once without any instruction, participants were              the eye movements retained their original timing in the
selected randomly to receive one of two instructions:                video. Videos were looped indefinitely until the participant
  (A) be aware of how your eyes are moving as you                    was ready to make a choice. (see videos at this link:
perform these tasks                                                  http://gnowledge.org/~sanjay/LSR/Cogsci_2014/)
  (B) next week, we will ask you to try and pick out your               The study was run in two phases, an exploratory phase,
eye movements from two sequences of eye movements                    and a testing phase. In the exploratory phase, we ran 20
Participants given instruction (B) were also shown a demo            participants (10 males, 10 females), and analysed the data.
of the recognition task performed in the test block (Figure          This analysis identified a clear gender difference in self
1). After receiving one of the instructions, participants were       recognition. The testing phase, with another 22 participants
asked to complete all four tasks again, remaining mindful of         (11 males, 11 females), was run to test the robustness of this
the instructions they had received.                                  effect. We report the combined data from the two phases, as
   This condition explored the role of instruction, if any, in       the results were similar for both phases. We also combine
identifying one's own eye movements. Knowing about the               the instruction and no-instruction data, as there was no
recognition task in advance provided participants the option         significant difference between the two conditions.
of laying down eye movement markers if they wished, and
then do the recognition explicitly, based on these markers. If       Participants
such an explicit strategy is used, and it is effective, accuracy     Across the two phases, we recruited 21 males (mean age
in self recognition would be very high for the videos                23.6, S.D. 6.5 years) and 21 females (mean age 22.7, S.D.
recorded with instruction. However, given the absence of             4.9 years), with uncorrected normal vision. Informed
scene elements in the black background videos, it would be           consent was obtained from all participants. During testing,
                                                                 328

one of the female participants reported physical discomfort          fitting the data. One way to disambiguate would be to
and withdrew consent for participating in the experiment.            identify discriminative features of these hypothesized sub-
Another participated in part 1 of the experiment (video              populations. When we tried to do so, we immediately
recording), but could not participate in the second part             encountered a strong gender effect in our data.
(recognition). Thus, our final sample contained 40
participants (20 males, 20 females). The response time data
for two participants was lost due to a computer problem, so
this data is reported only for 38 participants. All participants
were volunteers, and were students or staff members of our
institute. All were originally naive as to the purpose of the
study, and with no previous experience with eye tracking.
Apparatus
For recording eye-tracking data, we used the Tobii Glasses
system, which is a lightweight (75 gms) wearable eye-
tracker (Figure 2). Participants performed the recognition
task on a custom application designed using UNIX shell
scripts (Figure 1) running on a 15” screen laptop. Data
collection and analysis was done using GNU Octave.
                                                                     Figure 3: Deviation of the performance of our participant
                                                                     sample from random behavior predicted by the null
                                                                     hypothesis. We plot a histogram of the number of
                                                                     participants getting different number of trials right (max =
                                                                     8) against a plot showing the baseline binomial distribution
                                                                     we would obtain from 1000 repetitions of 40 Bernoulli
                                                                     trials. Error bars are 2 SD across.
                                                                        As Table 1 shows, males recognize themselves in the
                                                                     walk and climb tasks (actions involving a close connection
                                                                     between eye movements and whole-body movement) at
                                                                     rates significantly better than chance. Females perform
                                                                     below chance, significantly for the climb and 3-leg task, and
   Figure 2: Tobii Eyetracking Glasses, used to record eye           at trend level in the walk task.
          movements in the study (Source: Tobii.com)                    Males took more time than females overall in making the
                                                                     recognition decisions (p=0.03), but this difference was not
                Data collection and analysis                         significant for individual tasks.
                                                                            80
We recorded accuracy and response time data for each of
the eight recognition trials. To ensure reliability, response               70
time was recorded using UNIX system calls.
  Statistical significance for testing whether a particular                 60
sample performed better than chance on any subset of the
                                                                            50
tasks was assessed against a binomial distribution generated
using an identical number of trials as the sample size. Chi-                40
square proportion testing was used to differentiate
performance between pairs of samples.                                       30
                                                                            20
                           Results
Our overall sample performs almost exactly as by chance                     10
(accuracy mean % = 48.1). However, the histogram of
performance quality is not binomially distributed as one                     0
                                                                                         Female                 Male
would expect from a random outcome (see Figure 3).
 The true distribution of outcomes we obtained suggested a
                                                                       Figure 4: The gender effect in the recognition task. Males
bimodal generative process, viz., there might be two
                                                                          clearly outperform females (p<0.005), and a random
subpopulations in our sample, one of which is able to
                                                                      baseline, in identifying themselves from prior recordings of
recognize their gaze data, and the other not. Such an
                                                                            their eye movements. Error bars are 2 SD across.
inference, however, is susceptible to the possibility of over-
                                                                 329

As Figure 4 shows, males significantly outperform females           movements in the eye movement videos. The inability of
(p<0.005) in recognizing their own eye movements. The               male participants to identify themselves in these tasks
difference in these two populations accounts largely for the        suggests that information about body movement,
deviation from chance behavior seen in Figure 3.                    particularly head movement, is used, implicitly, while
                                                                    recognizing one's own eye movements in the walk and
  Table 1: Average accuracy for male and female cohorts in          climb conditions. This means a mechanism that can access
                      the recognition task                          body movements from eye movements is required to
         Tasks                 Male                Female           account for our results.
                                                                       A good candidate mechanism is common coding (Prinz,
         Walk                65.00%*              #37.50%           1992; 1997; Hommel et al., 2001), which postulates a
         Climb              67.50%**              *30.00%           common representation at the neural level, connecting
                                                                    execution, perception and imagination of movements. Self-
         3-leg                42.50%             **30.00%           recognition effects are explained by the covert activation of
         Draw                 47.50%               55.00%           familiar (one's own) motor patterns, which are triggered, via
                                                                    common coding, by the perception of movement.
                           * p=0.013             * p=0.04              In all the cases of self-recognition where common coding
                         ** p= 0.0008          ** p= 0.03           is provided as the explanation (Knoblich & Prinz, 2001;
                                                # p= 0.14           Flach, Knoblich, & Prinz, 2004; Repp & Knoblich, 2004;
                                                                    Mazalek et al., 2009; 2010), the choice task involves
                         Discussion                                 perceiving a biological movement. In our case, the
Our results show that:                                              perception also leads to the actuator (the eye) moving
   1) Males recognize their own eye movements                       overtly, in patterns similar to the movements originally
significantly above chance in the walk and climb tasks.             executed during the recording phase. The motor activation is
   2) The same participants cannot recognize their own eye          overt, but this overt replay of executed eye movements is
movements in the 3-leg and drawing tasks.                           not enough for males to identify one's own eye movement in
   3) Females perform below chance, significantly in the            every case, as the recognition happens only in the walking
climb and 3-leg tasks, and at trend level in the walk task.         and climbing tasks, where the eye movements occur with
   4) Females take less time than males to make a decision.         systematic body movements. This suggests full body
   We will first discuss results 1 and 2. One possible account      movements are accessed, and they may even be required, to
for this pattern of results would be a strictly localist model,     identify one's own eye movements.
where the eye is treated as a standalone movement system,              How could full body movements be accessed via the overt
and proprioception of the eye muscles (Donaldson, 2000) is          activation of eye movements? Common coding theory does
the possible mechanism involved in the self/other judgment.         not provide an account of such a mechanism. To extend
In this view, the eye moves in specific patterns while              common coding theory to include such a mechanism, we
executing the actions during the recording session. When            propose that this is achieved by a two-way oculo-motor
the gaze-point data is played back as a video in the choice         coupling, where overt eye movements trigger covert motor
task, similar eye movement patterns are overtly activated           plans, and, in the other direction, planned motor movements
while watching each gaze point video, as watching the gaze          trigger compatible eye movements. In this view, body
point move recruits smooth pursuit. One of the overt eye            movements in response to dynamic environmental stimuli
movement patterns activated by the gaze point videos                (such as catching a suddenly thrown ball) are eye
appear familiar to the participant, based on previous               movements 'writ large', so to speak, as the pattern of eye
proprioceptive experience. This video is then identified as         movement (such as smooth pursuit) generated by the
one's own movement. Note that this account does not                 dynamic stimuli provides real-time, precise, often scaled,
assume common coding, and the associated covert                     information for the motor plan. In the other direction,
activation of the motor system, as eye movements are                planned motor movements (such as inserting a door key)
overtly executed during the choice task, and the familiarity        lead to 'orienting' eye movements, which can act as forward
judgment is based on this overt movement.                           models that help plan and execute fine motor movements.
   However, in this account, participants would be expected            A crude analogy for this two-way coupling could be a
to recognize their own eye movements in the three-leg and           pantograph, which allows a small figure traced using a pen
the drawing tasks as well, because the eye would move in            to be automatically converted to a large figure traced using
familiar patterns for their own video, for all the tasks. Since     another pen, coupled to the first pen using a parallelogram
our results show recognition above chance for males only in         structure (Figure 5). The pantograph can convert large
the walking and climbing tasks, and not in the 3-leg and            drawings to small ones as well. This system only provides
drawing tasks, this account does not explain our results.           scaling, and is thus not a good analogy for complex control.
   Remember that the latter two tasks (3-leg, drawing)              A more sophisticated analogy for the coupling between
minimize systematic head movement patterns, and were                body movements and eye movements would be Watt's
developed as controls to address the issue of embedded head         Centrifugal Governor (van Gelder, 1997), a dynamic control
                                                                330

system that mechanically regulates the speed of the steam           the other person's movements. This lowers familiarity for
engine. van Gelder (1997) proposed the Watt Governor as a           the own video, leading to chance performance.
model of the mind, arguing for a dynamic systems approach              In the drawing case, minimal body movement is
to cognition. Our proposal is inspired by this model, but           generated, as the task is shading a sequence of circles. The
combines it with the imagery and representation possibilities       triggered body movement is thus limited to hand movement
of common coding, which are based on covert and off-line            with a standard pattern – the eye just moves to and fro, in
activation of the common code. The overt eye movements              tandem with the hand movement. This movement would not
thus work as an embodied emulator (Grush, 2004).                    activate the motor system fully, and thus the covert motor
                                                                    movement would be similar for both own and other videos.
                                                                    This makes either both videos appear familiar, or both
                                                                    appear unfamiliar, making the choice random.
                                                                       Why do females perform below chance, significantly in
                                                                    the climb and 3-leg tasks, and at trend level in the walk
                                                                    task? In the eye-as-micro-simulator account, they would be
         Figure 5: A pantograph (Source: Wikipedia)                 expected to do well in the walk and climb cases, as the
                                                                    proposed two-way oculo-motor coupling is a basic psycho-
    In our proposal, the eye functions as a physical micro-         physical process, and would be similar in females.
simulator that is coupled to the external world in real-time,          We propose that the automatic covert activation of the
similar to the Watt Governor. The state of the world                motor system by eye movements happens for females as
activates the eye overtly, and this movement provides               well, for both videos. However, only for the self video,
precise and real-time parameters to the motor system for            further activation of the covert process is blocked, and not
environment-driven motor plans. For intended actions, i.e.          allowed to proceed, by an inhibition signal. This inhibition
actions driven by the self and not by the environment, the          of the covert body movement leads to zero motor system
eye again moves overtly, but in micro-simulator mode,               response for the self video, but some from the other video,
providing forward models (Wolpert & Kawato, 1998).                  which leads to the other video being consistently chosen.
  These overt forward models allow more precise and                 This explains the consistent below chance performance in
detailed predictions than imagined models of movement. It           the climb and walk cases. Interestingly, this also explains
is possible that some of the parameters of the imagined             the significant below chance performance in the 3-leg case:
movement are set using the parameters of the overt eye              here also both the videos lead to covert motor activation,
movements. Other parameters could be set by optical flow            and the patchy covert activation from one's own video
(Gibson, 1950), which is also modulated by eye movements.           (modulated by another person's movement) is blocked,
   The eye-as-micro-simulator model extends the common              leading to zero motor activation for this video. This leads to
coding proposal, by outlining one specific mechanism,               the other video being chosen consistently. As the
where visual pursuit of movement triggers motor activation.         comparison between no-motor-response and some-motor-
In the other direction, the model predicts that imagination of      response would be faster, this mechanism account also
movement, required for intended actions, would be                   explains the lower response time for females.
accompanied by eye movement patterns similar to                        Why do females block the motor activation for one's own
execution/perception of movements. There is significant             movements from proceeding further? We propose that this is
evidence for eye movement during imagination (Johansson,            because of a strong bias to control full-fledged mimicry
Holsanova & Holmqvist, 2006; Johansson & Johansson,                 (Wang & Hamilton, 2012), and other signals of affiliation --
2014). Performance in insight problem-solving improves              i.e. a bias towards not letting the body display signs of
when participants are made to implicitly generate eye               interest. The activation of the motor system by one's own
movements related to a solution (Thomas & Lleras, 2007).            eye movement possibly moves the motor activation too
Related work shows that making eye movements influence              close to overt display, and this could be one reason why
aesthetic judgments (Topolinski, 2010), and the eye pupil           motor activation is blocked. A related reason could be eye
adjusts to imagined light (Laeng & Sulutvedt, 2014).                movements activating the self (Baltazar et al., 2014), which
   The eye-as-micro-simulator account explains our results          could independently lead to the blocking, as situations
well. In the walking and climbing tasks, watching the videos        where the self is activated would require caution. A parallel
trigger overt eye movement patterns, which automatically            case is the lack of emotional arousal for recognized faces,
generate covert body movements. As the covert motor                 which underlies the Capgras delusion (Ramachandran &
activations proceed over time, the body movement triggered          Blakeslee, 1999), where a close relative or friend is replaced
by one of the videos appear familiar to participants, and this      by an imposter. Interestingly, Capgras delusion occurs more
video is chosen as one's own eye movement.                          frequently in females (Todd, Dewhurst & Wallis, 1981).
   In the three-leg task as well, motor activation is generated        This account leads to a specific prediction about neural
by both the videos. But as the activations proceed, the             activation in our task: a continuing motor area activation for
familiar motor pattern doesn't rise up consistently, as the eye     males, and a short activation and then inhibition of the
movements in this case are patchy, as they are influenced by        motor area for females. This prediction is best tested using
                                                                331

an electro-physiology study using the same recognition               movements during mental imagery, both in light and in
paradigm. We are currently developing such an experiment.            complete darkness. Cognitive Science, 30(6), 1053-1079.
   It is possible that the inhibition response we report for       Knoblich, G., & Prinz, W. (2001). Recognition of self-
females is specific to our study population, as the study was        generated actions from kinematic displays of drawing.
done in a cultural milieu where overt physical signaling by          Journal of Experimental Psychology: human perception
females is discouraged. Cross-cultural studies are needed to         and performance, 27(2), 456.
test whether the effect is specific to cultural environments       Laeng, B. & Sulutvedt, U. (2014). The eye pupil adjusts to
where females are cautious about overt physical responses.           imaginary light. Psychological Science, 25(1), 188-197.
If yes, this specificty would provide a window to explore          Lewis, M. & Brooks-Gunn, J. (1979). Social cognition and
how the oculo-motor coupling is tuned by cultural norms.             the acquisition of self. New York: Plenum Press.
                                                                   Loula, F., Prasad, S., Harber, K. & Shiffrar, M. (2005).
                    Acknowledgments                                  Recognizing people from their movement. Journal of
We gratefully acknowledge the support of Department of               Experimental Psychology: Human Perception and
Science and Technology, Government of India, through a               Performance, 31(1), 210.
Cognitive Science Initiative grant (SR/CSI/186/2012). We           Mazalek, A., Chandrasekharan, S., Nitsche, M., Welsh, T.,
thank our participants for volunteering for the study.               Thomas, G., Sanka, T. & Clifton, P. (2009). Giving your
                                                                     self to the game: transferring a player's own movements
                                                                     to avatars using tangible interfaces. In Proceedings of the
                         References                                  2009 ACM SIGGRAPH Symposium on Video Games (pp.
Baltazar, M., Hazem, N., Vilarem, E., Beaucousin, V., Picq,          161-168). ACM Press.
   J. L., & Conty, L. (2014). Eye contact elicits bodily self-     Mazalek, A., Nitsche, M., Chandrasekharan, S., Welsh, T.,
   awareness in human adults. Cognition, 133(1), 120-127.            Clifton, P., Quitmeyer, A., Peer, F. & Kirschner, F. (2010).
Bertenthal, B. I. & Fischer, K. W. (1978). Development of            Recognizing self in puppet controlled virtual avatars. In
   self-recognition in the infant. Developmental Psychology,         Proceedings of the 3rd International Conference on Fun
   14(1), 44.                                                        and Games (pp. 66-73). ACM Press.
Devue, C., Collette, F., Balteau, E., Degueldre, C., Luxen,        Prinz, W. (1992). Why don’t we perceive our brain states?
   A., Maquet, P. & Brédart, S. (2007). Here I am: the               European Journal of Cognitive Psychology, 4, 1–20.
   cortical correlates of visual self-recognition. Brain           Prinz, W. (1997). Perception and action planning. European
   Research, 1143, 169-182.                                          Journal of Cognitive Psychology, 9, 129-154.
Donaldson, I.M.L. (2000). The functions of the                     Ramachandran, V.S. & Blakeslee, S. (1999). Phantoms in
   proprioceptors of the eye muscles. Philosophical                  the Brain: Human Nature and the Architecture of the
   Transactions of the Royal Society, Series B: Biological           Mind. London: Fourth Estate.
   Sciences, 355.1404, 1685-1754.                                  Repp, B. H. & Knoblich, G. (2004). Perceiving Action
Flach, R., Knoblich, G., & Prinz, W. (2004). Recognizing             Identity How Pianists Recognize Their Own
   one’s own clapping: The role of temporal cues.                    Performances. Psychological Science, 15(9), 604-609.
   Psychological Research, 69(1-2), 147-156.                       Thomas, L. E. & Lleras, A. (2007). Moving eyes and
Gallup, G.G., Jr., Anderson, J.L. & Shillito, D.P. (2002). The       moving thought: On the spatial compatibility between eye
   mirror test. In The Cognitive Animal: Empirical and               movements and cognition. Psychonomic Bulletin &
   Theoretical Perspectives on Animal Cognition, ed. M.              Review, 14(4), 663-668.
   Bekoff, C. Allen and G.M. Burghardt, University of              Todd, J., Dewhurst, K., Wallis, G. (1981). The syndrome of
   Chicago Press.                                                    Capgras. British Journal of Psychiatry, 139, 319–27.
Gibson, J.J. (1950). The Perception of the Visual World.           Topolinski, S. (2010). Moving the Eye of the Beholder:
   Houghton Mifflin.                                                 Motor Components in Vision Determine Aesthetic
Grush, R. (2004). The emulation theory of representation:            Preference. Psychological Science, 21(9), 1220-1224.
   Motor control, imagery, and perception, Behavioral and          Tsakiris, M. (2008). Looking for myself: current
   Brain Sciences, 27, 377–442                                       multisensory input alters self-face recognition. PloS one,
Hommel, B., Müsseler, J., Aschersleben, G. & Prinz,W.                3(12), e4040.
   (2001). The theory of event coding (TEC): A framework           van Gelder, T. (1997). Dynamics and Cognition. In Mind
   for perception and action planning. Behavioral and Brain          Design: Philosophy, Psychology, Artificial Intelligence.
   Sciences, 24, 849–878.                                            Ed. J. Haugeland, Cambridge, Mass.: MIT Press, 421-450
Johansson, G. (1973). Visual perception of biological              Wang, Y., & Hamilton, A. F. D. C. (2012). Social top-down
   motion and a model for its analysis. Perception &                 response modulation (STORM): a model of the control of
   Psychophysics, 14, 201–211.                                       mimicry in social interaction. Frontiers in human
Johansson, R., & Johansson, M. (2014). Look here, eye                neuroscience, 6.
   movements play a functional role in memory retrieval.           Wolpert, D. M., & Kawato, M. (1998). Multiple paired
   Psychological Science, 25(1), 236-242.                            forward and inverse models for motor control. Neural
Johansson, R., Holsanova, J. & Holmqvist, K. (2006).                 Networks, 11(7), 1317-1329.
   Pictures and spoken descriptions elicit similar eye
                                                               332

