            A diffusion model account of the transfer-of-training effect
  Colin Kupitz1 (ckupitz@uci.edu), Martin Buschkuehl2 (mbuschkuehl@mindresearch.org),
            Susanne Jaeggi1,3 (smjaeggi@uci.edu), John Jonides4 (jjonides@umich.edu),
        Priti Shah4 (priti@umich.edu), and Joachim Vandekerckhove1,5 (joachim@uci.edu)
     1
       Department of Cognitive Sciences, University of California, Irvine; 2 MIND Research Institute, Irvine, CA;
      3
        School of Education, University of California, Irvine; 4 Department of Psychology, University of Michigan;
                                 5
                                   Institute for Mathematical Behavioral Sciences, Irvine, CA
                          Abstract                               We favor such a modeling approach because, while tradi-
                                                                 tional analyses can sometimes provide interesting conclu-
   We revisit a transfer-of-training study and analyze its
   data using a cognitive modeling approach. Fitting a           sions, they lack the ability to distinguish between qual-
   diffusion model to participant behavior over sessions al-     itatively different sources of variability in the way that
   lows conclusions as to the underlying causes of behav-        cognitive process models do. For example, if in a train-
   ioral changes—be they changes in cognitive strategies,
   adaptation to the paradigm, increasing familiarity with       ing paradigm participants respond more quickly in the
   the stimuli, or speed of information processing. Our dif-     last session than the first, this may be because they be-
   fusion model analysis revealed that participants simul-       came more adept at processing the information needed
   taneously adapt speed-accuracy trade-off, increase their
   non-decisional response speed, and increase their speed       for the task, but they might also have become more ef-
   of information processing. All three of these adaptations     ficient at the perceptual or motor component of the re-
   transferred to a similar, non-trained outcome task.           sponse process, or they may have cognitively adapted
   Keywords: transfer of training; diffusion model; cog-         to the task and act with less caution (either by shifting
   nitive psychometrics                                          criterion or a change in speed-accuracy tradeoff). This
                                                                 lack of interpretability of simple summary statistics is
                       Introduction                              an issue in and of itself, and further, averaging artefacts
As a research topic, working memory (WM) training                can produce inferential errors and/or biased estimates
has grown in both interest and controversy in recent             (Heathcote, Brown, & Mewhort, 2000; see also Clark,
years (e.g., Jaeggi, Buschkuehl, Shah, & Jonides, 2014;          1973). Thus, we believe generating a model to describe
Morrison & Chein, 2011; Oberauer, Süß, Wilhelm, &               the underlying processes of WM tasks is especially im-
Wittman, 2003; Rode, Robson, Purviance, Geary, &                 portant: not only does it provide a novel way of inter-
Mayr, 2014). The ideal goal of WM training is to im-             preting WM training and transfer, but it will addition-
prove the underlying cognitive process(es) that is (are)         ally allow us to make stronger and more concrete claims
shared across other non-trained tasks. It is assumed             as to the effect and efficacy of WM training tasks on
that, if these basic underlying processes can be improved,       cognitive processes, which might allow us to make pre-
the improvement will not only be observed in the trained         dictions about near and far transfer depending on which
task but will generalize to non-trained tasks that rely          cognitive process(es) improved during training. In this
at least partially on the trained cognitive ability (e.g.,       paper, we present a reinterpretation of WM training and
WM).                                                             transfer data in the context of a cognitive model, as a
   In the current study, we focus on the change-detection        proof of concept that cognitive modeling is a useful tool
paradigm (e.g., Luck & Vogel, 1997)—a WM task that               in the study of WM tasks, especially in relation to train-
has been used for more than a century. In a typical              ing and transfer.
example of this paradigm, the participant is briefly pre-
sented with an array and, following a short delay, is asked                                 Data
to judge if a second presented stimulus array is identical       We will revisit data by Buschkuehl, Jaeggi, Mueller,
to the first or not. Despite the prevalence of the change-       Shah, and Jonides (2014). Here we describe only the
detection paradigm in WM literature, the effect of train-        subset of data that we will use. Other measures are de-
ing on task performance—and especially on transfer task          scribed in Buschkuehl et al. (2014).
performance—has not been investigated thoroughly. In
fact, it has been argued that performance in the change          Participants
detection paradigm is relatively fixed (Rouder et al.,           A total of 45 participants were recruited for the study
2008; Zhang & Luck, 2011).                                       from two university communities, and were randomly
   While measurement in the WM literature has tradi-             assigned to one of two interventions. Four of the par-
tionally focused on measures of accuracy, speed, and/or          ticipants withdrew from the study following the pre-test
capacity, some researchers have successfully applied cog-        session. Five participants were excluded from the anal-
nitive models to WM tasks (e.g., van Vugt & Jha, 2011).          yses due to irregularites in their training schedules, and
                                                             1219

two participants were excluded for failing to complete          by a 1,000ms blank screen. The entire array was shown
all of the pre- and post-test tasks, leaving a total of 17      again on the test portion of the trial, with the shape
participants in each of the two training groups.                to be judged indicated by a black circle. Participants
                                                                were asked to indicate if the encircled shape was the
Procedure and tasks                                             same as it was in the initial array presentation. The
Participants were tested on the two criterion tasks (“sim-      next trial began immediately after the participant made
ple” and “complex”) and then randomly assigned to ei-           a judgement.
ther the easy or hard training group (test and training            Easy Training Task. The easy training task was
tasks are described below). The first session of train-         similar to the simple criterion task described above with
ing was completed in the laboratory in order to give            three main differences. First, no mask was presented.
participants the opportunity to ask any questions they          Second, rather than only displaying the square to be
might have about the training task or the procedure.            judged, the entire array of squares was redisplayed with
The training program was then installed on the personal         the square to be judged encircled. Third, feedback was
computers of the participants, and the remainder of the         provided at the end of each trial. The additional smaller
training took place on those computers. In order to en-         alterations made included that the initial array was pre-
sure compliance, participants were required to send the         sented for 250ms followed by a 1,000ms blank screen,
training data generated after each session via email to         which was followed by the test display lasting until the
the laboratory. Participants were asked to complete ten         participant responded.
training sessions (no more than two per day, which was             Each training session consisted of 15 blocks of 20 trials.
only allowed immediately following a missed day) within         Participants started with a set size of two in their first
14 days. Following the training period, participants were       training session. After each block, performance was eval-
tested again in the laboratory on the criterion tasks in        uated and if accuracy was higher than 85%, the set size
order to evaluate the impact of the intervention.               was increased by one; similarly, if the accuracy dropped
   Simple Criterion Task. Each trial of the easy crite-         below 70%, set size was reduced by one. Otherwise set
rion task began with a fixation cross presented in the cen-
ter of the screen for 1,000ms. Then, an array of colored
squares (possible colors: blue, red, yellow, purple, green,                    initial     blank             test
                                                                              display     or mask          display
black, white) was presented on a screen with a dark grey
background for 250ms, immediately followed by a 200ms
blank screen. Next, a set of masks was displayed for
700ms, directly covering the colored square display loca-
tions. Each mask consisted of a colored striped square,
with each mask being newly generated at each trial from
the colors used within the colored squares of that trial.
Subsequently a 100ms blank screen was presented, and
then one of the squares from the initial array was pre-
sented again until a change or no-change judgement was
                                                                                                                     feedback
made by the participant. A new trial began 1,000ms
after the previous trial ended.
   Participants were given task instructions through the
computer program and went through ten practice trials.
During the practice phase, the stimulus set size (i.e.,
the number of colored squares) was either two, four, or
six, and accuracy feedback was given. After the practice
trials, there were 150 test trials: 15 change trials and
                                                                                                    time
15 no-change trials for each of the possible set sizes, 2,
4, 6, 8, and 10. The order of test trials was randomly
determined by the computer, and no feedback was given           Figure 1: Example trials for each of the four tasks. The
on test trials.                                                 simple and the complex criterion tasks differ in the type
                                                                of stimulus (color squares vs. shapes), the presence of
  Complex Criterion Task. The complex criterion
                                                                masks, and the number of items remaining in the test
task was similar to the simple criterion task described
                                                                display. The easy and hard training tasks differ only in
above with small alterations. Instead of colored squares,
                                                                the the presence of masks, the number of items remain-
random black shapes were used (identical to those in
                                                                ing, and the presence of feedback. Note that the hard
Jaeggi et al., 2003, but black in color and smaller in size).
                                                                training task and simple criterion task are the same.
The stimulus array was presented for 500ms and followed
                                                            1220

                                                                                  µα
                                                                                   k      µβk   µτk    µδk
         τ                                       "same"
   α
              δ                                                  σα              αkip                                 γiα
αβ                              sample path
                                                                 σβ                      βkip                         γiβ
   0
                                                                 στ                            τkip                   γiτ
                                           "different"
                                                                 σδ                                    δkip           γiδ
Figure 2: A graphical representation of the Wiener dif-
fusion model. The accumulation process begins at evi-
dence value αβ and unfolds with an average increase of δ
per second until a boundary at α or 0 is reached. τ is an                          ykipt
additive time constant for nondecisional processes. The
shaded area is the model-predicted probability density                              trials t
function over response and response time, W(α, β, τ, δ).                                      participants p
                                                                                                                 sessions i
                                                                                                    set sizes k
size remained unchanged. The set size of the first block
of subsequent training sessions was determined by sub-         Figure 3: A graphical representation of our exploratory
tracting two from the set size of the last block in the        hierarchical diffusion model. Parameters µ indicate the
previous training session (as ‘warm-up time’). The pro-        set-size-specific population mean of each parameter; pa-
gram had a maximum set size of 20, but no participants         rameters γ indicate the effect of session on each parame-
reached a set size higher than 16.                             ter; and parameters σ indicate the between-person vari-
   Hard Training Task. The hard training task was              ability in each parameter. Node ykipt is the tth choice re-
identical to the simple criterion task described above.        sponse time data point for participant p in session i with
Thus it differed from the easy training task in that there     set size k. For example, the supposed distribution of δkip
was no feedback provided, there was a mask presented,          is normal with mean µδk + γiδ and standard deviation σ δ ,
and only one of the squares was shown in the test display      and the distribution of ykipt is the Wiener distribution
(to preclude any context or configuration effects).            with unit diffusion coefficient. The figure displays only
                                                               part of the model, which was fit to the training and cri-
   Data preprocessing. We did minimal data prepro-
                                                               terion behavior simultaneously, with the same set-size
cessing. Beyond the data from excluded participants,
                                                               parameters but freely estimated session offsets.
we discarded only data from trials in which the response
time was clearly too fast (less than 200ms) or too slow
to be a one-shot response process (more than 2000ms).
                                                               sponse; and δ, the “drift rate” or rate of information
                   Diffusion model                             accumulation within a trial. Importantly, this parame-
Our modeling analysis uses an hierarchical diffusion           terization gives us a representation of skill at the task
model for two-choice reaction times introduced by              (in the form of the drift rate variable, δ), while simul-
Vandekerckhove, Tuerlinckx, and Lee (2011), which is           taneously accounting for non-skill based changes in task
an extension of a model first described by Stone (1960).       performance and speed.
   In the diffusion model, it is assumed that participants        In our model, we will decompose the observed param-
make task decisions through a process of sequential accu-      eters into constituent components. For all parameters,
mulation of information, executing a response when suf-        we will assume a fixed effect of set size, so that each set
ficient information is garnered. Figure 2 illustrates the      size has its own mean value for each parameter (e.g., µτ4
process. The parameters of interest are α, the amount          is the average nondecision time for trials with set size
of information required before a decision is made (which       4). We additionally assume an average fixed offset for
captures the speed-accuracy trade-off); β, the a-priori        each parameter in each session (e.g., γ5β is the average
bias that a participant might have towards one or the          offset in a-priori bias β in session 5), relative to the first
other response; τ , the non-decision time including time       training session (so γ1 = 0 for all parameters). Finally,
for encoding the stimulus and executing the motor re-          we assume a random participant effect, so that each par-
                                                           1221

ticipant gets an additional term to indicate their unique        “easy training” participant groups. The results were
level of each parameter relative to the group mean. This         qualitatively similar between the two groups, with the
term will be a draw from a normal distribution with              exception that the learning effect on drift rate was
mean 0. Taken together, the model is fully described by          smaller in the “easy training” group (p(ζeasy < 0|y) ≈
the set of structural equations                                  0.071, MAPE ζ̂easy ≈ .010) than in the “hard training”
                  θkip   =   µθk + γiθ + εθp                     group (p(ζhard < 0|y) ≈ 0.008, MAPE ζ̂hard ≈ .015).
                    εθp      N 0, σ θ ,
                                      
                         ∼                                          The right panels in Figure 4 show the mean of each
                                                                 parameter per set size. These results are not important
for each diffusion model parameter θ, and the likelihood         to our discussion, save for knowing that the parameters
function ykipt ∼ W(α, β, τ, δ). The likelihood function is       behave in expected ways (most stay relatively constant,
defined as the first passage time distribution of a Wiener       except for drift rate, which decreases as expected with
process with constant boundaries.                                increasing task difficulty), and underscoring that set size
   We fit this model simultaneously to the training data         was taken into account in our analyses.
and the criterion tasks, allowing for different session off-
sets for each parameter in each of the criterion sessions.
   We implemented the model in an hierarchical Bayesian
framework, as in Vandekerckhove et al. (2011). Figure 3                        session effect (γ)         pop. mean (µ)
gives a graphical model representation of the model we              0.2                                                      2
used. In this graph, variables are represented by nodes.                 α
Downstream (i.e., “receiving”) nodes are probabilisti-                0                                                      1
cally dependent on upstream nodes, shaded nodes are
observed variables, and unshaded nodes unobserved vari-            −0.2                                                      0
ables. Plates indicate ‘loops’ over sets of similar nodes.                   2     4    6      8   10       5     10     15
                                                                   0.05                                                      1
   We drew eight chains of 1000 samples from the joint                   β
posterior distribution of all parameters of the hierarchi-            0                                                      0.5
cal diffusion model using a freely available extension of
the Bayesian computation program JAGS (Wabersich &               −0.05                                                       0
Vandekerckhove, 2014). Convergence of the Monte Carlo                        2     4    6      8   10       5     10     15
                                                                    0.1                                                      1
chains was confirmed with the typical R̂ < 1.1 criterion.                τ
                  Modeling results                                    0                                                      0.5
Training                                                           −0.1                                                      0
Posterior distributions of the parameters are displayed                      2     4    6      8   10       5     10     15
                                                                    0.5                                                      4
in Figure 4. The left panels in the figure show the pro-                 δ
gression of the parameter over sessions. The first session
                                                                      0                                                      2
is used as a reference point. The pattern of behavior
is clear for each parameter. Over sessions, boundary               −0.5                                                      0
separation α decreases as participants begin to trade ac-                    2     4    6      8   10       5     10     15
curacy for speed. The a-priori bias level β stays con-                            session (i)               set size (k)
stant and around 0.5, as induced by the experimental
paradigm. Nondecision time τ steadily decreases over             Figure 4: Right panels: Posterior distributions of the
sessions. Drift rate δ shows a slight decrease going from        population means µk of the four diffusion model param-
the first to the second session (presumably due to the           eters as a function of set size k. Posterior uncertainty,
change in context from the laboratory to the partici-            indicated by the 99% credibility interval, is larger for the
pant’s home) but rapidly stabilizes. A slight upward             highest set sizes because few participants reached that
trend is visible.                                                level of difficulty. The panels show little systematic ef-
   In a second analysis, the increase of drift rate over         fects, except for a marked decrease in drift rate from
sessions two through ten was modeled as a linear func-           set size 2 to 5. This shows that task difficulty increases
tion: δpik = µδk + ζ(i − 6) + εδp , with set-size mean µδk ,     with set size, but levels off around 5. Left panels: Pos-
                                                                 terior distributions of the session-specific offset terms γi
person-specific error term εδp , regression weight ζ, and i
                                                                 as a function of sessions i. The leftmost marker is the
the session number. In this model, the posterior of re-
                                                                 first session, which is singled out because it was the only
gression weight p(ζ < 0|y) ≈ 0.007, indicating a positive
                                                                 training session held in the lab. Ignoring the first session,
trend with mean a posteriori estimate (MAPE) ζ̂ ≈ .011.
                                                                 we observe a decrease in boundary separation α and in
   We conducted a third analysis in which we took into
                                                                 nondecision time τ , and a slight increase in drift rate δ.
account the difference between the “hard training” and
                                                             1222

            caution (α)              a−priori bias (β)
                                                                                                                 Interaction
    0.5                       0.05                                                                      α       Session ME
                                                                                                                   Task ME
                                                                                                                 Interaction
      0                          0                                                                      β       Session ME
                                                                                                                   Task ME
                                                                   Interaction
  −0.5                       −0.05
                                                                  Session ME
                                                                     Task ME
                                                                                δ                                  0.78
           pre      post               pre        post                                                           Interaction
        nondecision time (τ)             ability (δ)
                                                                                                        τ       Session ME
                                                                                                                   Task ME
    0.1                        0.5
                                                                   −0.2 −0.1        0    0.1 0.2        0.3   0.4       0.5
                                 0                                                     effect size
      0
                              −0.5                             Figure 6: Posterior distributions of effect size estimates
                                                               corresponding to the training effects in Fig. 5. The Ses-
  −0.1                          −1                             sion main effect (ME) is the parameter in the second
           pre      post               pre        post         session minus that in the first. The Task ME is the per-
                                                               formance in the easy task minus the hard. All effect sizes
Figure 5: Diffusion model parameter estimates, with            are expressed in the parameter’s original units. Circles
99% credibility intervals, from the transfer tasks. Ses-       represent mean effect size and thick and thin bars the
sion is given on the horizontal axes. Circles represent        95% and 99% credibility intervals, respectively. Consis-
the simple criterion task; Squares represent the complex       tent learning effects are seen in caution α, nondecision
criterion task. Top left: αs are seen to start above the       time τ and drift rate δ, while bias β is the most stable
reference level in the pre-training test and to end below      parameter. An interaction effect indicates that the abil-
it in the post-training test. Top right: βs start slightly     ity parameter δ increases more for the easy transfer task
above the reference level in the pre-training for the sim-     than for the hard transfer task (which is less similar to
ple criterion task and below it for the complex criterion      the training tasks).
task, with the former decreasing and the latter stable.
Bottom left: τ s start level with the reference point but
decreases markedly after training. Bottom right: δ for         changes in cognitive strategy (the amount of information
the easy criterion task starts below the reference level       required to make a decision), motor and encoding time
in the pre-training test and ends above it in the post-        (nondecision time), and—to a lesser degree—task abil-
training test. This is expected because this task is very      ity (drift rate). Given that drift rate has been associated
similar to the training task. Interestingly, for the com-      with fluid intelligence (Ratcliff, Schmiedek, & McKoon,
plex criterion task—which is less similar—δ increases af-      2008; van Ravenzwaaij, Brown, & Wagenmakers, 2011),
ter training as well, indicating transfer of training.         this strikes us as the most practically significant find-
                                                               ing. This finding is also in line with previous results
                                                               from cognitive models of practice and learning (Dutilh,
Transfer                                                       Vandekerckhove, Tuerlinckx, & Wagenmakers, 2009).
Figures 5 and 6 show similar results for the criterion            More importantly, the transfer of training effect is
tasks. When we compare the pre- and post-test data for         seen in the parameters of the diffusion model. On the
the simple (circles) and complex (diamonds) criterion          one hand, we see changes in the boundary separation
tasks, we find the same changes in boundary separation         parameter and the non-decision time. These two pa-
α and non-decision time τ . Additionally, we also see          rameters are typically interpreted as cognitive strategy
a stronger increase in drift rate δ. This is particularly      (speed/accuracy tradeoff), and speed of stimulus prepro-
interesting given that δ is most readily interpreted as a      cessing and motor response, respectively. In the latter
higher-level “ability” (e.g., Vandekerckhove, Verheyen,        parameter, we expect to see transfer of training to closely
& Tuerlinckx, 2010; Pe, Vandekerckhove, & Kuppens,             related tasks (i.e., tasks that rely on similar stimulus
2013) which should be less sensitive to specific properties    configurations that require similar perceptual encoding),
of the task.                                                   with diminishing effect the more unrelated the tasks be-
                                                               come. On the other hand, we also observe an increase
                       Discussion                              in drift rate parameter from the first testing occasion to
Two findings are of note. First, the diffusion model           the last. This parameter is commonly interpreted as a
analysis indicates that the improvement seen during the        higher level cognitive ability, more distant from superfi-
training phase of the experiment is a multicomponen-           cial task properties. Hence, training in this parameter is
tial effect: The practice effect consists of simultanous       expected to transfer more easily to “distant” tasks (i.e.,
                                                           1223

tasks that rely on different stimulus configurations), rel-          ory: Storage, processing, supervision, and coordi-
ative to the other parameters of the diffusion model. In             nation. Intelligence, 31 (2), 167 – 193.
future studies, we will explicitly manipulate the distance     Pe, M., Vandekerckhove, J., & Kuppens, P. (2013). A
between tasks to test this hypothesis.                               diffusion model account of the relationship between
   Finally, we should point out that this type of conclu-            the emotional flanker task and depression and ru-
sion was made possible through the use of a cognitive                mination. Emotion, 13 , 739–747.
psychometric model. Future work will include the ap-           Ratcliff, R., Schmiedek, F., & McKoon, G. (2008). A
plication of a more sophisticated cognitive-psychometric             diffusion model explanation of the worst perfor-
model in which individual differences in training effect             mance rule for reaction time and IQ. Intelligence,
size will be used to forecast transfer effect size.                  36 , 10–17.
                                                               Rode, C., Robson, R., Purviance, A., Geary, D. C., &
                                                                     Mayr, U. (2014). Is working memory training ef-
                      References                                     fective? A study in a school setting. PloS one,
Buschkuehl, M., Jaeggi, S., Mueller, S., Shah, P., &                 9 (8), e104796.
      Jonides, J. (under review). Training change de-          Rouder, J. N., Morey, R. D., Cowan, N., Zwilling, C. E.,
      tection leads to substantial task-specific improve-            Morey, C. C., & Pratte, M. S. (2008). An as-
      ment.                                                          sessment of fixed-capacity models of visual work-
Buschkuehl, M., Jaeggi, S. M., Mueller, S. T., Shah, P.,             ing memory. Proceedings of the National Academy
      & Jonides, J. (2014). Training on change detection             of Sciences, 105 (16), 5975–5979.
      leads to substantial task-specific improvements. In      Stone, M. (1960). Models for choice–reaction time. Psy-
      Poster presented at the 26th annual convention of              chometrika, 25 , 251–260.
      the association for psychological science, san fran-     van Ravenzwaaij, D., Brown, S., & Wagenmakers, E.-J.
      cisco, ca.                                                     (2011). An integrated perspective on the relation
Clark, H. H. (1973). The language–as–fixed–effect fal-               between response speed and intelligence. Cogni-
      lacy: A critique of language statistics in psycho-             tion, 119 (3), 381–393.
      logical research. Journal of Verbal Learning and         van Vugt, M. K., & Jha, A. P. (2011). Investigating
      Verbal Behavior , 12 , 335–359.                                the impact of mindfulness meditation training on
                                                                     working memory: A mathematical modeling ap-
Dutilh, G., Vandekerckhove, J., Tuerlinckx, F., & Wa-
                                                                     proach. Cognitive, Affective, & Behavioral Neuro-
      genmakers, E.-J. (2009). A diffusion model de-
                                                                     science, 11 (3), 344–353.
      composition of the practice effect. Psychonomic
                                                               Vandekerckhove, J., Tuerlinckx, F., & Lee, M. D. (2011).
      Bulletin & Review , 16 , 1026–1036.
                                                                     Hierarchical diffusion models for two–choice re-
Heathcote, A., Brown, S., & Mewhort, D. J. K. (2000).
                                                                     sponse times. Psychological Methods, 16 , 44–62.
      The power law repealed: The case for an expo-
                                                               Vandekerckhove, J., Verheyen, S., & Tuerlinckx, F.
      nential law of practice. Psychonomic Bulletin &
                                                                     (2010). A crossed random effects diffusion model
      Review , 7 , 185–207.
                                                                     for speeded semantic categorization data. Acta
Jaeggi, S. M., Buschkuehl, M., Shah, P., & Jonides, J.               Psychologica, 133 , 269–282.
      (2014). The role of individual differences in cogni-     Wabersich, D., & Vandekerckhove, J. (2014). Extending
      tive training and transfer. Memory & Cognition,                JAGS: A tutorial on adding custom distributions
      42 (3), 464–480.                                               to JAGS (with a diffusion model example). Behav-
Jaeggi, S. M., Seewer, R., Nirkko, A. C., Eckstein, D.,              ior Research Methods, 46 , 15–28.
      Schroth, G., Groner, R., et al. (2003). Does exces-      Zhang, W., & Luck, S. J. (2011). The number and qual-
      sive memory load attenuate activation in the pre-              ity of representations in working memory. Psycho-
      frontal cortex? Load-dependent processing in sin-              logical Science, 22 (11), 1434–1441.
      gle and dual tasks: functional magnetic resonance
      imaging study. NeuroImage, 19 (2), 210–225.                                  Authors’ Note
Luck, S. J., & Vogel, E. K. (1997). The capacity of
                                                               We report how we determined our sample size, all data
      visual working memory for features and conjunc-
                                                               exclusions (if any), all manipulations, and all measures
      tions. Nature, 390 (6657), 279–281.
                                                               in the study. Greater detail can be found in Buschkuehl,
Morrison, A. B., & Chein, J. M. (2011). Does work-
                                                               Jaeggi, Mueller, Shah, and Jonides (under review). This
      ing memory training work? The promise and chal-
                                                               project was partly supported by grants #1230118 from
      lenges of enhancing cognition by training working
                                                               NSF’s Methods, Measurements, and Statistics panel and
      memory. Psychonomic Bulletin & Review , 18 (1),
                                                               #48192 from the John Templeton Foundation to JV.
      46–60.
Oberauer, K., Süß, H.-M., Wilhelm, O., & Wittman,
      W. W. (2003). The multiple faces of working mem-
                                                           1224

