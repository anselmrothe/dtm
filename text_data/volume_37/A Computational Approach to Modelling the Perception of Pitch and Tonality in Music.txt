      Harmonics co-occurrences bootstrap pitch and tonality perception in music:
                        Evidence from a statistical unsupervised learning model
                                              Kat Agres (kathleen.agres@qmul.ac.uk)
                                                     Queen Mary, University of London
                                     Department of Electronic Engineering and Computer Science
                                                            London E1 4NS, UK
                   Carlos Cancino, Maarten Grachten, Stefan Lattner (firstname.lastname@ofai.at)
                                      Austrian Research Institute for Artificial Intelligence (OFAI)
                                                   Freyung 6/6, A-1010 Vienna, Austria
                              Abstract                                 clustering or categorization. These abstracted representations
                                                                       may also model human perception (Hinton, 2007; Bartlett,
   The ability to extract meaningful relationships from sequences
   is crucial to many aspects of perception and cognition, such        2001; Grachten & Krebs, 2014).
   as speech and music. This paper explores how leading                   In music, unsupervised learning techniques have been used
   computational techniques may be used to model how hu-               effectively to learn feature representations for the harmonic
   mans learn abstract musical relationships, namely, tonality         relationships between keys (Leman, 1995) and tonal pitch
   and octave equivalence. Rather than hard-coding musical
   rules, this model uses an unsupervised learning approach to         relationships within a key (Cancino, Lattner, & Grachten,
   glean tonal relationships from a musical corpus. We de-             2014). The model proposed by Cancino et al. (2014) suc-
   velop and test a novel input representation technique, using a      cessfully replicates certain aspects of pitch perception, but
   perceptually-inspired harmonics-based representation, to boot-
   strap the model’s learning of tonal structure. The results are      fails to replicate others, such as the perception of octave sim-
   compared with behavioral data from listeners’ performance on        ilarity (the perceptual similarity of tones one octave apart)
   a standard music perception task: the model effectively en-         displayed by musicians. This is likely due to the symbolic
   codes tonal relationships from musical data, simulating expert
   performance on the listening task. Lastly, the results are con-     pitch input representation used, which fails to capture har-
   trasted with previous findings from a computational model that      monic relationship between tones. The current work uses a
   uses a more simple symbolic input representation of pitch.          novel harmonics-based input representation inspired by hu-
   Keywords: Music perception; tonality; unsupervised learning;        man pitch perception, with the hypothesis that the additional
   Restricted Boltzman Machines                                        information provided from lower resolved harmonics will
                                                                       bootstrap both the perception of tonal relationships and oc-
                          Introduction                                 tave similarity. The present research investigates this topic
Learning the rules and structure of sequential information is          through the use of unsupervised statistical learning, and tests
of fundamental importance to human perception and cogni-               the extent to which these methods are capable of modelling
tion, yet the process by which this occurs is still debated            the perception of tonality, through the use of this more rich
and widely investigated across domains. In language, for ex-           input representation.
ample, linguistic nativists posit that innate, domain-specific
mechanisms are responsible for grammar learning (e.g.,                 Pitch Perception in Listeners
Berwick, Pietroski, Yankama, & Chomsky, 2011; Pinker,                  Arguably, the statistical properties of music (such as pitch
1994), while others argue that more general, statistical learn-        occurrences and transitional probabilities between tones or
ing mechanisms underlie the induction of grammatical rules             chords) enable its structure to be learned from exposure.
(Chater & Manning, 2006; Saffran & Wilson, 2003; Gomez                 For example, the transitional probabilities between musical
& Gerken, 1999). This debate has spread to other domains,              events, and the frequency of occurrence of pitches in tonal
such as the perception of tonal music, which, like language,           music, contribute to listeners perception of the hierarchical
is highly structured, and is governed by a set of grammatical          relationship of pitches within a key (Smith & Schmuckler,
rules that can be described in music-theoretic terms (Lerdahl          2004). This is known as the “tonal hierarchy”, a phrase
& Jackendoff, 1983). Indeed, listeners’ ability to implicitly          that highlights the relative stability or importance of certain
extract statistical regularities and knowledge of tonal rela-          pitches in a musical key. In other words, due to the predom-
tionships has received much attention in recent years (Pearce,         inance of some notes over others within a tonality (such as
2005; Saffran, Johnson, Aslin, & Newport, 1999).                       the tonic and fifth scale degree), certain notes are perceived
   In an effort to model mechanisms for learning statisti-             as belonging more or less to the key than others, and are con-
cal structure, unsupervised learning methods and Restricted            sequently perceived as having different functional roles in the
Boltzman Machines (RBMs) have garnered enthusiastic sup-               tonality. In the case of C Major, for example, the notes C and
port for examining questions of learning, feature represen-            G (the tonic and fifth scale degree) have greater stability than
tations, and the probabilistic structure of (big) data. Once           the leading tone (B, the seventh in the scale), or chromatic
an RBM has learned the properties of the given data, its la-           pitches not in the key (e.g., F sharp).
tent (learned) feature spaces may be explored, and used for               Discovery of the tonal hierarchy was the result of seminal
                                                                    42

studies by Krumhansl and colleagues (Krumhansl, 1990) us-             of musical-phrase boundaries. Although this data-driven ap-
ing a “probe tone paradigm”. In this task, listeners hear a mu-       proach has been fairly successful, many statistical approaches
sical context that clearly establishes a key (such as an ascend-      lack robustness (e.g., they do not capture an entire conditional
ing or descending scale), but is left incomplete (e.g., without       probability distribution), resistance to noise, and flexibility
the final note of the scale). After this context, a subsequent        regarding different prior contexts. To circumvent these is-
“probe tone” is played, and listeners rate how well the tone          sues, an unsupervised RBM model is presently used to learn
completes the prior context, usually on a scale from 1 (“very         the probabilistic structure of tonal music through repeated ex-
bad”) to 7 (“very good”) (Krumhansl & Shepard, 1979). The             posure to a musical corpus.
results of probe tone tasks have repeatedly shown that dif-              An advantage of RBMs over the Self-Organizing Maps
ferent pitches have different functions in the key. There is          (SOMs) used in prior computational modeling approaches to
historical precedence for using human probe tone results as           the perception of tonality (Leman, 1995; Tillmann, Bharucha,
a measure of model performance in music, and our computa-             & Bigand, 2000) is that the learned representation space in
tional model follows this tradition.                                  SOMs is typically 2- or 3-dimensional, whereas RBMs can
   In addition to the statistical properties of music, the charac-    learn spaces of arbitrary dimensionality. Low-dimensional
teristics of the acoustic signal also impact pitch and tonality       space is convenient for visualization, but there are few
perception (McDermott & Oxenham, 2008; De Cheveigne,                  biologically-motivated reasons for enforcing learned repre-
2005). Pitch, the psychological perception of frequency, is           sentations to be low-dimensional. Although RBMs are not
perceived in logarithmic relation to frequency. Whereas oc-           claimed to be plausible models of neural structures, stacked
taves on the linear frequency spectrum become farther apart           RBMs have been shown capable of learning biologically real-
the higher the absolute pitch, octaves are equally-spaced on          istic receptive fields in vision (Lee, Ekanadham, & Ng, 2008).
the mel scale (such that doubling a frequency creates the per-
                                                                      Perception-Based Input Representation Applications of
ception of a pitch one octave higher). There is some evidence
                                                                      neural networks to music often start from symbolic rep-
that the perceptual similarity of pitches an octave apart is uni-
                                                                      resentations of music, midi notes, or piano roll notation
versal and innate (Demany & Armand, 1984), and nearly all
                                                                      (Cancino et al., 2014; Grachten & Krebs, 2014; Boulanger-
cultures base their musical scale on a one-octave range.
                                                                      Lewandowski, Bengio, & Vincent, 2012). This usually im-
   From a developmental perspective, given that most voices           plies that pitch (octave-specific note name, e.g., ‘G4’) or
and instruments produce tones in which the fundamental                pitch chroma (octave-invariant note name, e.g., ‘G’) are used,
pitch (F0) is much stronger than the partials, listeners may          but this approach means losing potentially useful information
gradually build up pitch and tonal perception from weak indi-         from harmonics that can ain in the extraction of tonal relation-
vidual harmonics. Empirical studies show that adults tend to          ships. For example, human listeners perceive co-occurring
be more sensitive to tonal relationships and less influenced by       harmonics for pitches that are an octave or a fifth apart; this
pitch proximity than children (Cuddy & Badertscher, 1987).            consonance may help listeners develop abilities such as oc-
If greater perception of individual harmonics is gained over          tave similarity perception and relative pitch. Therefore, we
the developmental trajectory, models using F0 as input may            developed an input representation that could enable the RBM
better simulate children and novice listeners, while models           to use harmonics to bootstrap tonal learning.
using harmonics information may reflect more experienced                 A harmonics representation provides the model with
listeners.                                                            richer input than using only note-names or fundamental
   Because both low-level acoustic information and implicit           pitches. Other computational approaches have represented
statistical learning mechanisms contribute to tonal perception        even lower-level information; for example, autocorrelation
in listeners, the present research sought to model how the hi-        temporal models (Licklider, 1951; van Noorden, 1982; Med-
erarchical perception of tonality may be learned through ex-          dis & Hewitt, 1991; Cariani, 2001) have shown that neural in-
posure to music, utilizing an input representation inspired by        terspike interval representations and their subharmonic repre-
the perception of pitch.                                              sentations may potentially underlie the perception of pitch as
                                                                      well as some basic aspects of tonality. Complementary to this
Computational approaches                                              tradition, we endeavored to test whether resolved harmon-
Hard-coded, rule-based models can describe various cog-               ics within the range of the piano (which covers the range of
nitive phenomena with notable accuracy, possibly captur-              musical tonality) were sufficient to simulate listeners’ perfor-
ing some of the innate structure that constrains bottom-up,           mance on a music perception task addressing the tonal func-
domain-general cognitive processing. Nevertheless, percep-            tion of pitches within a key. While innate properties of the
tion reflects, to a substantial degree, what is learned based         auditory system (e.g., neural spiking activity) may subserve
on experience. Accordingly, an emphasis has recently been             representations of tonality, tonal perception is likely mediated
placed on investigating how features of data are learned              by experience. We were therefore interested in whether dif-
from exposure. The development of such systems allows                 ferent input representations (harmonics vs F0s) would better
researchers to model perception without requiring user in-            simulate listeners with varying degrees of musical expertise.
put or the pre-specification of rules. To this end, statistical          When examining the perception of tonal structure, our har-
and probabilistic approaches have elucidated aspects of mu-           monics representation has the advantage over audio-based
sic perception, such as tonal relationships and the perception        representations (such as acoustic spectra computed from
                                                                   43

tones) that it allows us to focus solely on the effect of coincid-       Chain Monte Carlo technique that is well suited for energy
ing resolved harmonics between tones. When working with                  based models such as RBMs (Hinton, 2002).
acoustic spectra, this effect is blurred by phenomena like in-              For this paper, we train a model with 100 hidden units for
harmonicity, and tone quality (timbre). It is beyond the scope           200 epochs, using a single Gibbs sampling step and a mini-
of this article to account for the effect of these phenomena             batch size of 100. Different model parameters were explored,
on the perception of tonal structure. Thus, the following ap-            such as the size of hidden layer and the amount of train-
proach employs an abstract representation based on human                 ing epochs. All hyperparameters (learning rate, momentum,
pitch perception, with the hypothesis that co-occurring har-             number of steps of Gibbs sampling) were selected according
monics may scaffold the development of relative pitch and                to the guidelines proposed by Hinton in (Hinton, 2012).
octave affinity found in musically-trained listeners.
                                                                         Harmonics input representation
                             Method                                      A distributed binary input vector was computed for every
Restricted Boltzman Machine model                                        pitch of the piano keyboard, from A0 to C8, tuned in equal
The present research implemented a Restricted Boltzmann                  temperament. For each pitch the first four harmonics were
Machine, a generative stochastic neural network (Hinton,                 represented, comprising the fundamental frequency and three
2002). This model consists of a layer of visible units v ∈ Rn ,          successive harmonics for each pitch. The harmonic series was
which represent the observed data, and a layer of binary hid-            computed by multiplying the pitch’s F0 by integer values (2
den units h ∈ {0, 1}l . Both layers form a bipartite graph, i.e.         for the second harmonic, 3 for the third harmonic, etc). The
there are no connections between units from each layer. The              four harmonics encoded represent the F0, an octave interval
joint probability distribution of v and h described by the RBM           above the F0 (second harmonic), a fifth above the second har-
is given by                                                              monic (third harmonic), and two octaves above the F0 (fourth
                                                                         harmonic). The harmonics for all 88 piano tones formed a
                             1                                           total of 112 frequency bins, which served as the 112 visi-
                 p(v, h) =     exp (−E(v, h | θ)) ,                      ble input nodes for the model. The binary input vector (visi-
                             Z
                                                                         ble units) for each pitch encoded that pitch’s harmonics, i.e.,
where Z is a normalization term, and E(·) is an energy func-             there were four “on” nodes in each input vector.
tion, usually a quadratic function of the visible and hid-
den units. This energy function is proportional to the log-              Training corpus
likelihood function of the model parameters θ given the vis-             Our training corpus consisted of the entire set of 48 fugues
ible and hidden units, and its name was inspired by the Ising            from J.S. Bachs Well-Tempered Clavier, regarded as one of
model from statistical thermodynamics. For the standard                  the most seminal works of classical music. Previous com-
Bernoulli-Bernoulli RBM1 , the energy function is                        putational modeling shows that the representations derived
                                                                         from this corpus reflect the “Circle of Fifths”; in other words,
           E(v, h | W, a, b) = −vT a − hT b − vT Wb,
                                                                         the statistics of this corpus yield meaningful relationships be-
where θ = {W, a, b}, with W ∈ Rn×l a weight matrix, a ∈ Rn               tween the musical keys (Cancino et al., 2014). Because the
a bias vector for the visible units, and b ∈ Rl a bias vector for        fugues span every key and therefore have different distribu-
the hidden units.                                                        tions of pitch occurrences, they were all transposed to the
   The free energy (FE), denoted by F (v), is a measure of               key of C. Transposing or otherwise accounting for key (e.g.,
the expectancy of an input (visible) configuration, since it is          by representing scale degree and pitch interval) is common
proportional to the expected value of the conditional proba-             practice for training computational models on tonal corpora
bility of the visible units given all possible configurations of         that span different keys. Without transposition, the statistics
the hidden units, i.e.                                                   defining tonal relationships from different keys will provide
                                                                         conflicting information to a model that uses absolute pitch
                  F (v) ∝ − log (E {p(v | h)}) .                         representation. Each fugue was decomposed into its con-
                                                                         stituent voices (two to five per fugue), where “voices” refers
Model training                                                           to the number of parts in the musical score. Voices in the bass
                                                                         register were moved to the C3 to C6 range to enable their
The model parameters θ are optimized to maximize the ex-                 tonal information to be used and integrated by the model.
pected log-likelihood of the observed data. In the machine               This yielded a total of 166 voices used for training, and each
learning literature, this optimization process for neural net-           voice was considered as a single monophonic melody in the
works is known as training (Bishop, 1995). The standard                  corpus.
method for training RBMs is known as Contrastive Diver-
                                                                            The set of voices were converted from their original MIDI
gence, proposed in (Hinton, 2002). In this gradient-descent-
                                                                         format into the harmonics representation described above (ev-
like algorithm, the gradient of the log-likelihood of the ob-
                                                                         ery pitch was replaced by its binary harmonics vector). The
served data is approximated using Gibbs sampling, a Markov
                                                                         RBM was then trained on n-grams of these harmonics vec-
    1 For more details on the derivation of energy functions for sev-    tors, where an n-gram is defined as a successive set of n tones
eral RBM architectures see (Cancino, Lattner, & Grachten, 2015)          in the corpus. N-grams were each eight notes long, and were
                                                                      44

created by means of a sliding window (e.g., for a particular         rience. The model results were therefore compared to highly
melody, notes 1-8 formed the first n-gram, followed by notes         trained musicians (experts) and musically-untrained listeners
2-9 for the second n-gram, etc). This n-gram length was cho-         (novices). We refer the reader to this paper for further details
sen to allow for the presentation of a seven tone stimulus plus      regarding the study.
a single probe tone to the model, as is necessary for compari-
son with human ratings on a probe tone test (see the next sec-                         Results and Discussion
tion on Model Evaluation). Moreover, Cancino et al. (2014)           The performance of the model, as assessed by the FEs of the
found that a minimum of eight notes in an n-gram was nec-            probe test stimuli, was compared with average probe tone rat-
essary for optimal categorization of the n-gram in terms of          ings by expert and novice listeners (Krumhansl & Shepard,
tonal key. The 8-grams were presented in randomized order            1979). We were interested in comparing the model with the
to provide more robust training for the model. Note that the         pattern (or profile) of human responses across probe tones,
RBM computes the probabilities of the elements in each in-           but the original variance data of listeners’ responses is no
put vector (the set of visible nodes that encode the input, in       longer available, which precludes statistical significance test-
our case, the set of eight pitches), not the probability of a se-    ing. Therefore, to compare the patterns of results, we cal-
quence of n-grams. As such, there is no temporal aspect with         culated the Kullback-Leibler (KL) divergence (Kullback &
regard to the order of training instances themselves; rather,        Leibler, 1951) between the two sets of data, which measures
each n-gram is treated as another time-invariant training in-        the distance between two discrete distributions, p(1) and p(2) .
stance. The RBM extracts meaningful relationships between            KL divergence was then used as the kernel for a distance-
the pitches within, and not between, each training n-gram.           based Similarity measure (Shepard, 1987) that is used to
                                                                     quantify the similarity between the two distributions:
Model evaluation
                                                                                                                            
After training the RBM, the model’s internalization of the                Similarity p(1) | p(2) = exp −DKL p(1) | p(2) .
tonal pitch hierarchy was tested. To this end, we implemented
a Krumhansl-style probe tone test: The model was given ei-              This similarity measure has the property of being exactly
ther an ascending scale (the octave from C3 to C4) or a de-          one if both distributions are identical, and tends asymptoti-
scending (from C6 to C5), without the final C to complete the        cally to zero if the KL divergence between both distributions
octave. This musical context was immediately followed by             goes to infinity. Similarity (e−KL ) values and Pearson cor-
a probe tone which was selected from the chromatic pitches           relations between model and human ratings are provided in
between C4 and C5 (see Figure 1).                                    Table 1 for an RBM tested on probe stimuli with ascending
                                                                     scale and descending scale contexts.
              Ascending                     Descending               Table 1: Comparison of expert and novice listeners’ probe
                                                                     tone ratings (for ascending or descending stimuli) with an
                                                                     RBM model tested on ascending or descending scale con-
                           Probe tones                               texts. The highest Similarity values are in bold for both of
                                                                     the model test conditions.
Figure 1: Ascending and descending C major scale context,
and the set of possible chromatic probe tones.                                           Asc model context   Desc model context
                                                                       Expertise          R      Similarity   R       Similarity
                                                                       Expert (Asc)      0.82      0.88      0.72        0.57
   To provide these stimuli to the model for testing, we con-          Expert (Desc)     0.83      0.84      0.83        0.88
structed n-grams of length 8, each of which contained the              Novice (Asc)      0.59      0.75      0.00        0.42
seven pitches from the ascending or descending scale, fol-             Novice (Desc)     0.54      0.52      0.75        0.54
lowed by a probe tone. This yielded a test set of 26 stimuli.
The Free Energy (FE) was calculated for each of these probe             Given the model’s results for ascending test stimuli, the KL
test stimuli, and then normalized and scaled for comparison          divergence is lowest (i.e., the distributions were least differ-
with human ratings.                                                  ent), and the Similarity is greatest, for Expert listeners’ rat-
   The model’s performance was compared with that of lis-            ings of ascending probe stimuli. In other words, the model
teners for both ascending and descending scale stimuli, as re-       reflects expert listeners’ behavioral results for this set of stim-
ported in Krumhansl and Shepard (1979). This classic study           uli. The RBM results are most highly correlated with expert
was chosen because 1) the probe tone context featured scales         listeners for both ascending and descending stimuli.
rather than chords, 2) tones containing harmonics were used             These findings are mirrored by the descending stimuli re-
(as opposed to pure tones, or Shepard tones as in Krumhansl          sults. For these test stimuli, the KL divergence is lowest and
and Kessler (1982)), and 3) listeners with different levels of       the Similarity is highest for Expert listeners who rated de-
training were tested. This last point enabled us to test the         scending probe stimuli. The RBM results are most highly cor-
hypothesis that this richer input representation will allow the      related with descending ratings from Expert listeners. Once
model to better simulate listeners with greater musical expe-        again, the model best reflects expert listeners’ results when
                                                                  45

the two are compared on the same set of stimuli, and further                   on learning the probabilistic structure of sequential informa-
demonstrates the stimulus-specific response of the RBM.                        tion, contribute to the acquisition of abstract, high-level rela-
    The comparisons between RBM Free Energy results and                        tionships in music.
expert listeners’ ratings are plotted in Figure 2 for visualiza-                  Our novel representation of musical input was inspired by
tion. These graphs illustrate that the RBM was able to model                   how human listeners process pitch, and this method takes our
the hierarchical tonal relationships exhibited by listeners: The               model one step closer to an embodied approach to modeling
model learned the privileged role of diatonic pitches in the C                 music cognition. Future work will investigate using the en-
major scale, and exhibits a degree of octave similarity.                       tire frequency spectrum of every tone (e.g., as sampled from
                                                                               audio recordings). The full spectrum of pitch information
                                    Ascending
 7
                                                                               may result in even better model performance on pitch-related
                    RBM free energy        Expert listener rating
 6
                                                                               tasks, especially with regard to octave equivalence.
 5                                                                                As hypothesized, a harmonics-based representation assists
 4                                                                             the model in learning the tonal hierarchy and octave similarity
 3                                                                             from pitches that share harmonics. The model best simulated
 2                                                                             expert listeners, which can be taken as evidence that trained
 1
                                                                               musicians likely take advantage of the harmonic spectrum of
   C4 C#4  D4   D#4   E4      F4    F#4   G4    G#4        A4     A#4 B4 C5
                                                                               musical pitches in order to (implicitly) perceptually organize
                                   Descending
                                                                               the pitches within a key. Our findings may also support the
 7                  RBM free energy        Expert listener rating
 6
                                                                               claim that novice listeners focus more on fundamental fre-
 5
                                                                               quency and pitch proximity than harmonics. More generally,
 4                                                                             these findings highlight how the choice of representation can
 3                                                                             have a notable impact on learned features, and that alternative
 2                                                                             representations may be used to simulate different populations.
 1
                                                                                  An extension of this work will consider using representa-
   C4 C#4  D4   D#4   E4      F4    F#4   G4    G#4        A4     A#4 B4 C5
                                                                               tions based on subharmonic patterns, as these are consistent
                                                                               with temporal models of pitch perception (Cariani, 2001)).
Figure 2: RBM Free Energy results compared with average                        In addition, superior model performance may result from us-
probe tone ratings by expert listeners for ascending and de-                   ing stacked RBMs, a method currently popular in the area of
scending scale contexts.                                                       deep learning, as additional layers (model depth) may allow
                                                                               the model to learn increasingly abstract features of tonal rela-
    These results were also compared to a version of the RBM                   tionships.
model that was instead trained on MIDI pitch with no har-
monics, as reported in Cancino et al. (2014), which was                                            Acknowledgments
configured to have the same parameters and hyperparame-                        This research was made possible through support from the
ters as the model discussed above. This pitch-only model,                      European Commission. The Lrn2Cre8 and PROSECCO
trained to the same number of epochs, yielded worse perfor-                    projects acknowledge the financial support of the Future and
mance when compared with listeners. The highest Similarity                     Emerging Technologies (FET) programme within the Sev-
value for ascending contexts was 0.58 (for non-expert listen-                  enth Framework Programme for Research of the European
ers rating descending stimuli). The highest Similarity value                   Commission, under FET grant number 610859 (Lrn2Cre8)
for descending contexts was 0.76 (with novice listeners rating                 and FET grant number 600653 (PROSECCO).
descending stimuli). The greater similarity to untrained lis-
teners rating descending contexts may reflect the prevalence                                            References
of C4 over C3 in the corpus. Compared to an RBM model
using only a local binary pitch representation, the harmon-                    Bartlett, M. S. (2001). Face image analysis by unsupervised
ics representation yields better overall results. Also, whereas                   learning. Springer Science & Business Media.
the harmonics representation best models expert listeners, the                 Berwick, R. C., Pietroski, P., Yankama, B., & Chomsky, N.
pitch-only representation reflects less experienced listeners.                    (2011). Poverty of the stimulus revisited. Cognitive Sci-
                                                                                  ence, 35(7), 1207–1242.
                             Conclusion                                        Bishop, C. M. (1995). Neural networks for patter recogni-
In this paper, we use unsupervised learning techniques to train                   tion. Claredon Press, Oxford.
a computational model on pitch relationships from a corpus                     Boulanger-Lewandowski, N., Bengio, Y., & Vincent, P.
of fugues from Bach’s Well Tempered Clavier. Our approach                         (2012).     Modeling temporal dependencies in high-
allows the RBM to learn musical structure (i.e., tonal rela-                      dimensional sequences: Application to polyphonic music
tionships) from a training corpus without having to hard-code                     generation and transcription. In Proceedings of the 29th
tonal rules into the model. In fact, the high correlations be-                    international conference on machine learning.
tween the model and listeners’ performance lend support to                     Cancino, C., Lattner, S., & Grachten, M. (2014). Devel-
the claim that domain general processing mechanisms, based                        oping tonal perception through unsupervised learning. In
                                                                            46

  Proceedings of the 15th international society for music in-     Kullback, S., & Leibler, R. A. (1951). On information and
  formation retrieval conference.                                   sufficiency. The Annals of Mathematical Statistics, 22(1),
Cancino, C., Lattner, S., & Grachten, M. (2015). Deriva-            79-86.
  tions of the free energy of restricted boltzmann machines       Lee, H., Ekanadham, C., & Ng, A. Y. (2008). Sparse deep
  (Technical Report). Austrian Research Institute for Artifi-       belief net model for visual area V2. In Advances in neural
  cial Intelligence.                                                information processing systems 20 (pp. 873–880).
Cariani, P. (2001). Temporal codes, timing nets, and music        Leman, M. (1995). A model of retroactive tone-center per-
  perception. Journal of New Music Research, 30(2), 107–            ception. Music Perception.
  135.                                                            Lerdahl, F., & Jackendoff, R. (1983). A generative theory of
Chalnick, A., & Billman, D. (1988). Unsupervised learning           tonal music. MIT Press.
  of correlational structure. In Proceedings of the tenth an-     Licklider, J. (1951). A duplex theory of pitch perception.
  nual conference of the cognitive science society (pp. 510–        The Journal of the Acoustical Society of America, 23(1),
  516). Hillsdale, NJ: Lawrence Erlbaum Associates.                 147–147.
Chater, N., & Manning, C. D. (2006). Probabilistic models         Matlock, T. (2001). How real is fictive motion? Doctoral
  of language processing and acquisition. Trends in cognitive       dissertation, Psychology Department, University of Cali-
  sciences, 10(7), 335–344.                                         fornia, Santa Cruz.
Cuddy, L. L., & Badertscher, B. (1987). Recovery of the           McDermott, J. H., & Oxenham, A. J. (2008). Music per-
  tonal hierarchy: Some comparisons across age and levels           ception, pitch, and the auditory system. Current opinion in
  of musical experience. Perception & Psychophysics, 41(6),         neurobiology, 18(4), 452–463.
  609–620.                                                        Meddis, R., & Hewitt, M. J. (1991). Virtual pitch and phase
De Cheveigne, A. (2005). Pitch perception models. In Pitch          sensitivity of a computer model of the auditory periphery. i:
  (pp. 169–233). Springer.                                          Pitch identification. The Journal of the Acoustical Society
Demany, L., & Armand, F. (1984). The perceptual reality of          of America, 89(6), 2866–2882.
  tone chroma in early infancy. The journal of the Acoustical     Newell, A., & Simon, H. A. (1972). Human problem solving.
  Society of America, 76(1), 57–66.                                 Englewood Cliffs, NJ: Prentice-Hall.
Feigenbaum, E. A. (1963). The simulation of verbal learn-         Ohlsson, S., & Langley, P. (1985). Identifying solution paths
  ing behavior. In E. A. Feigenbaum & J. Feldman (Eds.),            in cognitive diagnosis (Tech. Rep. No. CMU-RI-TR-85-2).
  Computers and thought. New York: McGraw-Hill.                     Pittsburgh, PA: Carnegie Mellon University.
                                                                  Pearce, M. T. (2005). The construction and evaluation of
Gomez, R. L., & Gerken, L. (1999). Artificial grammar learn-
                                                                    statistical models of melodic structure in music perception
  ing by 1-year-olds leads to specific and abstract knowledge.
                                                                    and composition. Unpublished doctoral dissertation, City
  Cognition, 70(2), 109–135.
                                                                    University London.
Grachten, M., & Krebs, F. (2014). An assessment of learned
                                                                  Pinker, S. (1994). The language instinct: The new science of
  score features for modeling expressive dynamics in music.
                                                                    language and mind (Vol. 7529). Penguin UK.
  IEEE.
                                                                  Saffran, J. R., Johnson, E. K., Aslin, R. N., & Newport, E. L.
Hill, J. A. C. (1983). A computational model of language ac-
                                                                    (1999). Statistical learning of tone sequences by human
  quisition in the two-year old. Cognition and Brain Theory,
                                                                    infants and adults. Cognition, 70(1), 27–52.
  6, 287–317.
                                                                  Saffran, J. R., & Wilson, D. P. (2003). From syllables to syn-
Hinton, G. E. (2002, July). Training products of experts by         tax: Multilevel statistical learning by 12-month-old infants.
  minimizing contrastive divergence. Neural Computation,            Infancy, 4(2), 273–284.
  14(8), 1771–1800.                                               Shepard, R. N. (1987). Toward a universal law of generaliza-
Hinton, G. E. (2007). Learning multiple layers of represen-         tion for psychological science. Science, 237, 1317-1323.
  tation. Trends in cognitive sciences, 11(10), 428–434.          Shrager, J., & Langley, P. (Eds.). (1990). Computational
Hinton, G. E. (2012). A practical guide to training re-             models of scientific discovery and theory formation. San
  stricted boltzmann machines. Neural Networks: Tricks of           Mateo, CA: Morgan Kaufmann.
  the Trade.                                                      Smith, N. A., & Schmuckler, M. A. (2004). The perception of
Krumhansl, C. L. (1990). Cognitive foundations of musical           tonal structure through the differentiation and organization
  pitch (Vol. 17). Oxford University Press New York.                of pitches. Journal of experimental psychology: human
Krumhansl, C. L., & Kessler, E. J. (1982). Tracing the dy-          perception and performance, 30(2), 268.
  namic changes in perceived tonal organization in a spa-         Tillmann, B., Bharucha, J., & Bigand, E. (2000). Implicit
  tial representation of musical keys. Psychological review,        learning of tonality: a self-organizing approach. Psychol.
  89(4), 334.                                                       Rev., 107, 885.
Krumhansl, C. L., & Shepard, R. N. (1979). Quantification         van Noorden, L. (1982). Two channel pitch perception. In
  of the hierarchy of tonal functions within a diatonic con-        Music, mind, and brain (pp. 251–269). Springer.
  text. Journal of experimental psychology: Human Percep-
  tion and Performance, 5(4), 579.
                                                               47

