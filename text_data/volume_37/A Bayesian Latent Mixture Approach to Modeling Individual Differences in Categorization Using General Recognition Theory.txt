         A Bayesian Latent Mixture Approach to Modeling Individual Differences
                           in Categorization Using General Recognition Theory
                                                  Irina Danileiko (idanilei@uci.edu)
                                                   Michael D. Lee (mdlee@uci.edu)
                                   Department of Cognitive Sciences, University of California, Irvine
                                                            Irvine, CA 92617 USA
                                                Michael L. Kalish (mlkalish@syr.edu)
                                               Psychology Department, Syracuse University
                                                           Syracuse, NY 13244 USA
                              Abstract                                    gregated or averaged over people. Other applications apply
                                                                          models at the level of individual participants (e.g., Nosof-
   Decision-bound models of categorization like General Recog-
   nition Theory (GRT: Ashby & Townsend, 1986) assume that                sky, 1986). Most recently, there have been some attempts
   people divide a stimulus space into different response regions,        to extend categorization models to include models of individ-
   associated with different categorization decisions. These mod-         ual differences (e.g., Bartlema, Lee, Wetzels, & Vanpaemel,
   els have traditionally been applied to empirical data using stan-
   dard model-fitting methods like maximum likelihood estima-             2014), using Bayesian methods, but these are restricted to ex-
   tion. We implement the GRT as a Bayesian latent mixture                emplar and prototype models.
   model to infer both qualitative individual differences in the
   types of decision bounds people use, and quantitative differ-             For decision-bound models, one important potential source
   ences in where they place the bounds. We apply this approach           of individual differences relates to the use of unidimensional
   to a previous data set with two category structures tested under       versus multidimensional boundaries. A working hypothe-
   different cognitive loads. Our results show that different partic-
   ipants categorize by applying diagonal, vertical, or horizontal        sis in the decision bound literature is that simple category
   decision bounds. Various types of contaminant behavior are             structures that separate stimuli based on a single dimension
   also found, depending on the category structures and presence          are amenable to simple explicit rules that can be verbal-
   or absence of load. We argue that our Bayesian latent mixture
   framework offers a powerful approach to studying individual            ized, whereas more complicated category structures that re-
   differences in categorization.                                         quire integration across the dimensions need associatively
   Keywords: category learning; decision bound models; Gen-               learned boundaries that are more implicit. As a result, one fo-
   eral Recognition Theory; Bayesian inference; latent mixture            cus of modeling individual differences using GRT is to infer
   model
                                                                          whether people use a simple horizontal or vertical bound that
                           Introduction                                   partitions stimuli along one stimulus dimension, or a more
                                                                          general linear (diagonal) decision bound that is sensitive to
Categorization is a fundamental cognitive capability, form-               both dimensions (e.g., Ell & Ashby, 2012). This modeling
ing a basis for structuring mental representations to capture             often also considers the possibility of some form of random
meaning and enable prediction. Understanding and modeling                 responding, to identify contaminant participants.
how people make categorization decisions is a key challenge
for cognitive science. One prominent and successful class of                 Methodologically, GRT models that incorporate the pos-
models, known as General Recognition Theory (GRT: Ashby                   sibility of individual differences (e.g., Ell & Ashby, 2012;
& Townsend, 1986), assumes that categorization decisions                  Soto, Vucovich, Musgrave, & Ashby, in press) rely on maxi-
are made based on decision bounds. For example, in a cat-                 mum likelihood methods for parameter estimation, and model
egorization task in which a person places a stimulus into one             selection criteria like the Bayesian Information Criterion.
of two categories on each trial, GRT assumes decisions are                While useful, these methods are limited. Maximum likeli-
based on a boundary that splits the stimulus space into two               hood estimation does not allow for the uncertainty in where a
response regions. The decision-bound modeling approach is                 person places a decision bound to be inferred, even though
naturally contrasted with exemplar models of categorization,              there will always be uncertainty remaining after observing
which assume that people remember all instances of a cate-                their performance on a limited number of trials. Informa-
gory and keep them in memory for comparison to novel stim-                tion criteria attempt to correct for the complexity of differ-
uli to make categorization decisions (e.g., Nosofsky, 1986).              ent possible decisions strategies, but do so in an approximate
   An important issue for any model of categorization relates             way that equates model complexity with counts of parame-
to the possibility of individual differences. Different people            ters. Using Bayesian methods automatically overcomes both
may categorize differently, perhaps as a result of different              of these limitations.
starting knowledge, different training or learning experiences,              Accordingly, our goal in this paper is to demonstrate a
different learning strategies, or different decision strategies.          Bayesian latent mixture approach to modeling individual dif-
Many applications of category learning models ignore indi-                ferences within the GRT framework. The structure of this
vidual differences, and deal with behavioral data that are ag-            paper is as follows. We first describe the experimental data
                                                                      501

                                                                    Table 1: Number and percentage of participants inferred to
      Unidimensional                  Information Integration
                                                                    use vertical, diagonal, or other strategies in each condition.
                                                                                Condition                 Vertical Diagonal Other
                                                                             Unidimensional no load      34 (68%) 6 (12%) 10 (20%)
                                                                                Unidimensional load      23 (46%) 7 (14%) 20 (40%)
                                                                    Information integration no load      15 (30%) 25 (50%) 11 (20%)
                                                                        Information integration load     17 (34%) 17 (34%) 16 (32%)
Figure 1: The unidimensional and information integration
category structures.                                                Modeling Assumptions
                                                                    The model we develop is tailored to the Zeithamova and Mad-
                                                                    dox (2006) experiment. It includes six categorization strate-
set that we re-analyze. We then describe our formulation of         gies that could be applied to the categorization structures in
a model, with six possible categorization strategies, in latent     the experiment. The latent mixture modeling methods we
mixture terms to allow for individual differences, and its im-      use, however, are general, and could naturally be extended or
plementation as a graphical model to allow for fully Bayesian       modified to incorporate different assumptions about individ-
inference. We examine the inferences this model makes about         ual differences in categorization strategies or types of stimuli.
individual differences in the decision strategies and decision         The most obvious categorization strategies to include, in
bounds for the four experimental conditions in the data set.        the context of GRT, are vertical boundaries, which are appli-
Finally, we discuss the benefits, as well as possible refine-       cable to the unidimensional category structure, and general
ments and extensions of our modeling approach.                      linear (diagonal) decision boundaries, which are applicable
                                                                    to the information integration structure. We also decided to
  Zeithamova and Maddox (2006) Experiment                           include a horizontal boundary strategy for completeness.
                                                                       The other three categorization strategies we consider cor-
Zeithamova and Maddox (2006) conducted a category learn-            respond to contaminant models. In the latent mixture ap-
ing experiment with four conditions, involving a total of 170       proach, with its focus on generative modeling of observed
participants in a between-participants design. Each condition       behavior, contaminants are not “removed” by processing the
consisted of five 80-trial blocks, during which each stimu-         data on the basis of accuracy or other summary criteria, but
lus was presented once with corrective feedback. The stim-          by modeling the contaminant behavior itself (Zeigenfuse &
uli consisted of Gabor patches, varying in the dimensions of        Lee, 2010). We allow for three different types of contaminant
spatial frequency and spatial orientation. The two category         behavior. One corresponds to guessing, in which the partici-
structures used are shown in Figure 1, with stimuli in Cat-         pant is equally likely to categorize any stimulus as belonging
egory A shown in black, and stimuli in Category B shown             to Category A as Category B, and the other two assume that
in white. The unidimensional structure on the left involves a       all, or almost all, of the stimuli are repeatedly placed in either
single dimension that separates the categories, while the in-       Category A or Category B.
formation integration category structure on the right involves
both dimensions. Both of the category structures were pre-          Graphical Model Implementation
sented with and without an additional memory load task, to          We formalize the latent mixture of these six strategies as
give the total of four conditions. These category structures        a graphical model, which is a common way of formalizing
and load conditions provide important tests of theories con-        probabilistic cognitive models (Lee & Wagenmakers, 2013).
trasting verbal and implicit category learning systems, and         Graphical models have the conceptual advantage of providing
have been replicated and re-analyzed by Newell, Dunn, and           an intuitive visualization of the generative process assumed to
Kalish (2010).                                                      produce data, and its dependence on psychological variables
                                                                    represented by parameters. They have a practical advantage
         Individual Differences GRT Model                           of making it straightforward to do fully Bayesian inference
                                                                    using computational sampling methods.
Latent mixture models assume that observed data arise from             In a graphical model, nodes represent the data, parameters,
a number of different sources, which combine or mix to pro-         and other variables of interest, and their dependencies are in-
duce the overall data. In the case of individual differences        dicated by the graph structure. Latent parameters are shown
in categorization, the different sources correspond to the dif-     as unshaded nodes while the observed parameters and the
ferent categorization strategies used by different people. The      data are shown as shaded nodes. Discrete variables are repre-
latent nature of the mixture means which strategy each indi-        sented with square nodes while continuous variables are rep-
vidual uses is not known, but rather there are latent parame-       resented with circular nodes. Stochastic variables are shown
ters assigning people to strategies that need to be inferred.       as single-bordered nodes while deterministic ones are shown
                                                                502

                                                                            αDi ∼ Uniform(− π2 , π2 )
                                    zi
                                                                  βi , βi , βiD
                                                                    H    V      ∼ Uniform(− 12 , 12 )
                                                                             σi ∼ Uniform(0, 1)
                         αD
                          i     βiD      βiH  βiV                            λi ∼ Uniform(0, 10)
                                                                            ǫij ∼ Gaussian(0, σ12 )
                  σi     λi                                                                        i
                                                                                  Categorical( 61 , . . . , 16 )
                                                                             zi ∼ 
                                                                                    1
                                                                                  
                                                                                    2                                          if zi   =1
                                                                                  
                                                                                  
                                                                                  
                                                                                    0.01                                       if zi   =2
                  ǫij               θij                  pj                       
                                                                                  
                                                                                  
                                                                                  
                                                                                   0.99                                        if zi   =3
                                                                            θij =
                                                                                  
                                                                                    Φ([pj1 − βiV + ǫij ]/λi )                  if zi   =4
                                                                                  
                                                                                  
                                                                                  
                                                                                                 H
                                    yij                                            Φ([pj2 − βi + ǫij ]/λi)
                                                                                                                               if zi   =5
                                                                                  
                                                                                       pj2 −tan αD           D
                                                                                  
                                                                                   Φ([            i pj1 −βi
                j stimuli                                                                    tan2 αD +1
                                                                                                                   + ǫij ]/λi ) if zi = 6
                                                                                                     i
              i subjects                                                    yij ∼ Bernoulli(θij )
     Figure 2: Graphical model representation of our model for inferring individual differences in categorization using GRT.
as double-bordered nodes. The rectangular plates show inde-                The general linear (diagonal) decision bound when zi = 6 is
pendent replications of the graph structure within the model.           parameterized by the angle of the slope αD              i and intercept βi .
                                                                                                                                                       D
    Figure 2 shows the graphical model representation of our            Using standard geometric results giving the distance from a
latent mixture model. The discrete parameter zi acts as strat-          point to a line parameterized this way gives
egy selection variables, indicating which of the six possible
decision strategies is used by the ith participant. This deter-                               p j2 − tan αD    i p j1 − βi
                                                                                                                            D                 
                                                                                  θi j = φ [                   D
                                                                                                                               +   εi j ]/λ i  .
mines how θi j , the probability that the ith participant cate-                                       tan2 αi + 1
gorizes the jth stimulus into Category A, is calculated. If
zi = 1, indicating the guessing strategy, then θi j = 21 . For the         Since αDi is an angle, it is natural to make its prior               uniform
repeated-choice contaminant models, with zi = 2 and zi = 3,             over all possibilities, so that αD          ∼                −   π π
                                                                                                                                          ,
                                                                                                                 i     Uniform           2 2 . To sim-
θi j is assumed to be 0.01 and 0.99, respectively.                      plify the setting of priors, we normalized the coordinate loca-
    The other three strategies involve decision bounds, and are         tions of the stimuli to lie in a square of unit length, centered
parameterized. If zi = 4, then a vertical decision bound is             on the origin. This makes βV                   H H                          1 1
                                                                                                                 i , βi , βi ∼ Uniform − 2 , 2
used with x-axis value βV     i . The jth stimulus, with coordinate     reasonable vague assumptions. We also use vague uniform
location p j = (p j1 , p j2 ) is more likely to be in Category A if     priors on the noise standard deviation                of probit scaling
                                                                                                                                                   pa-
it lies to the right of this boundary. Following GRT, we as-            rameters, with σi ∼ Uniform 0, 1 , λi ∼ Uniform 0, 10 , and
sume the difference between the boundary and the location               give each of the possible categorization           strategies equal prior
of the stimulus on the relevant dimension is corrupted by ad-           probability zi ∼ Categorical 16 , . . . , 61
ditive Gaussian noise, and use a probit function to map noisy
distances to response probabilities. Formally, this gives                                     Modeling Results
                                                                       We implemented the graphical model in Figure 2 in JAGS
                   θi j = Φ [p j1 − βV   i + εi j ]/λi
                                                                        (Plummer, 2003), and applied to to the data from the final
for the vertical         boundary strategy, where εi j ∼               block of trials for every participant in all four conditions of
Gaussian 0, σ12 is the noise term, parameterized by the                 Zeithamova and Maddox (2006). Our results are based on 6
                i
standard deviation of the noise σi for the ith participant, and         independent chains with 10,000 samples each, collected after
λi scales the probit transfer function, controlling how cate-           discarding the first 50,000 burn-in samples from each chain,
gorization probabilities for the ith participant vary with the          and thinning by collecting only every 5th sample. The chains
distance of a stimulus from the decision bound. By applying             were inspected visually for convergence, and using the stan-
the noise term directly to the distance, we conceive of it              dard R̂ statistic. In a few cases, individual chains that had
combining both the variability in the perceptual information            clearly failed to mix were discarded.
provided by the stimulus, and variability in memory for the                Table 1 summarizes the overall results, listing how many
decision bound (Maddox & Ashby, 1993). The horizontal                   participants are inferred as using the vertical, diagonal, or
strategy when zi = 5 is formalized analogously, in terms of a           other categorization strategy—grouping the contaminant and
y-axis value βH i as
                                                                        horizontal strategies as “other” strategies, since they do not
                                                                       allow for accurate categorization behavior—for all four ex-
                  θi j = Φ [p j2 − βH   i + εi j ]/λi .                 perimental conditions. Individual-level results are shown in
                                                                    503

                                             Unidimensional Without Load
                 100V              100V              100V                99V              85V 15D            59V 41D
            1                  2                3                  4                   5                 6
               55V 35D             100D              100D              53D 45V             100R           38G 36V 19D
            7                  8                9                 10                  11                 12
                                                                                         Repeat              Guess
                                              Unidimensional With Load
                100V                99V              97V           58V 19D 17G         44V 28G 19D          49H 45D
            1                 2                 3                 4                   5                 6
                100D               100D            58D 42V              100R           40G 29V 21D     39G 26D 24V 12H
            7                 8                 9                 10                 11                 12
                                                                      Repeat             Guess             Guess
Figure 3: Inferences about catergorization strategies and decision bounds for 12 representative participants in the unidimen-
sional with no load (top two rows) and unidimensional with load (bottom two rows) conditions.
Figures 3 and 4 for the unidimensional and information in-          ferred decision boundary for the participant. This is based on
tegration category structures. Each panel corresponds to a          the maximum a posteriori (MAP) strategy—that is, the one
participant, and a total of 12 representative participants are      with the greatest posterior probability—and shows the poste-
shown for each condition. Results for all participants in all       rior of each boundary by shading, with darker shades indicat-
conditions are available at https://osf.io/dmjs7.                   ing more likely boundaries. For those participants inferred to
   Each panel shows the categorization decisions made by            be contaminants, the label “Repeat” or “Guess” is shown.
the participant, with stimuli placed in Category A shown               The first 7 participants shown for unidimensional without
as black circles, and stimuli placed in Category B shown            load condition in Figure 3 are inferred to be using a verti-
as white squares. The label above the panel summarizes              cal decision boundary, the next 3 are inferred to use diago-
the posterior of the zi indicator variable, using the abbre-        nal boundaries, and the last two participants are inferred to be
viations D=Diagonal, V=Vertical, H=Horizontal, G=Guess,             contaminants. The inferred locations of these boundaries vary
R=Repeat. Any strategy with more than 10% posterior mass            across the participants with, for example, the vertical bound-
is included so that, for example, “38G 36V 19D” means the           ary for the 3rd participant much further to the left than the
posterior probabilities were 0.38 for the guessing strategy,        vertical boundary for the 5th participant. These inferences are
0.36 for the vertical bound strategy, and 0.19 for the general      consistent with the different categorization decisions made by
linear (diagonal) strategy, with the small remaining posterior      the participants since, for example, the 3rd participant makes
mass distributed among the other strategies.                        Category A decisions for stimuli much further to the left.
   Each panel also shows the posterior distribution for the in-        There are different levels of uncertainty in the inferences
                                                                504

                                         Information Integration Without Load
                  100D              100D               100D                 98D              86D 10V           52D 47V
             1                  2                 3                   4                   5                  6
                  100V             88V 12D            74V 26D             70V 30D          44V 27G 22D           100R
             7                  8                 9                  10                  11                 12
                                                                                                               Repeat
                                           Information Integration With Load
                  100D              100D               100D                 95D             78D 12V             100V
             1                  2                3                   4                   5                  6
                   95V           62V 19D 14H         46V 42D          52V 25G 18D      35G 27V 26D 12H 31G 29V 26D 14H
             7                  8                9                   10                 11                 12
                                                                                            Guess              Guess
Figure 4: Inferences about categorization strategies and decision bounds for 12 representative participants in the information
integration with no load (top two rows) and information integration with load (bottom two rows) conditions.
about the boundaries participants use. The vertical boundary           fects of cognitive load.
for the seventh participant, for example, is much more uncer-             A similar pattern of modeling results is found for the in-
tain than the vertical boundaries inferred for the first 6 partic-     formation integration conditions in Figure 4. The first 6 rep-
ipants. It is also relatively uncertain whether this participant       resentative participants in the no load condition are inferred
used a vertical or diagonal decision bound, with their poste-          to use diagonal decision boundaries, but there are significant
rior probabilities of 0.55 and 0.35 respectively. The complete         individual differences in where these boundaries are placed,
representation of uncertainty about inferences, at both the            and the certainty of the inferences about these locations. The
level of which categorization strategy a participant used, and         next 5 representative participants are inferred to use a sim-
where they placed their decision boundaries for these strate-          pler vertical decision bound categorization strategy, while the
gies, is an important advantage of the Bayesian approach.              12th participant is inferred to be a repeat contaminant.
   The representative participants chosen for the unidimen-               The 5th and 6th participants in this condition—with signif-
sional with load condition in Figure 3 show the greater vari-          icant posterior uncertainty between the diagonal and vertical
ability in the categorization strategies inferred to be used in        categorization strategies—highlight a powerful property of
this condition. There are more contaminant participants, and           the latent mixture approach. One way to conceive of the latent
less consistent use of vertical boundaries. More participants          mixture in cases like this is not as an inference between two
are inferred to use diagonal and even horizontal boundaries,           incommensurable possibilities, but as a single general model
and the uncertainty in the location of these boundaries is             with a theoretically rich prior. Since a vertical boundary is
greater. These differences are naturally attributed to the ef-         a special case of a diagonal boundary, the 5th participant’s
                                                                   505

posterior uncertainty of 0.86 for diagonal and 0.10 for verti-        contaminant behavior. We focused on linear decision bounds
cal boundaries could be interpreted as a diagonal boundary            from GRT, but other more general decision bounds like bi-
with 86% of the overall posterior coming from the slope and           linear or quadratic bounds, or different categorization models
intercept, and an additional 10% coming from the posterior            such as exemplar models, could be incorporated in the graph-
for the vertical boundary. This corresponds to inferring only         ical modeling framework. It is also straightforward to extend
a diagonal boundary, but with a prior that places significant         our account of individual differences to include hierarchi-
prior density on boundaries with infinite slope.                      cal structure, allowing both variability in classification strate-
   The 11th participant in the information integration without        gies and parameterizations of those strategies to be modeled
load condition shows significant uncertainty about the cat-           (Bartlema et al., 2014). These possibilities provide a natural
egorization strategy. Their decisions are somewhat consis-            direction for future research in understanding the individual
tent with a vertical boundary towards the middle-left of the          differences in how people learn and use category structures.
stimuli, but also appear somewhat consistent with guessing.
The posterior uncertainty in their zi model indicator parame-                              Acknowledgments
ter shows that none of the categorization strategies assumed          This work was supported by NSF Award 1431635.
in modeling provide a good account of their behavior, and
suggests the need for further model development. One possi-                                    References
bility in cases like this is that the participant changed strate-     Ashby, F. G., & Townsend, J. T. (1986). Varieties of percep-
gies during the trial block, and some sort of more complicated           tual independence. Psychological Review, 93, 154–79.
multi-strategy model is required.                                     Bartlema, A., Lee, M., Wetzels, R., & Vanpaemel, W. (2014).
   The representative participants shown for the information             A Bayesian hierarchical mixture approach to individual dif-
integration with load condition are inferred to use both diago-          ferences: Case studies in selective attention and represen-
nal and vertical decision bounds, but there is more use of the           tation in category learning. Journal of Mathematical Psy-
simpler vertical strategy, and more contaminant behavior. Ex-            chology, 59, 132–150.
amples like the 7th participant, who is confidently inferred to       Ell, S. W., & Ashby, F. G. (2012). The impact of category
use a vertical bound near the far right of the stimulus space,           separation on unsupervised categorization. Attention, Per-
highlight the possibility of improving the current model us-             ception & Psychophysics, 74, 466–475.
ing more informative priors. The current inference is that the        Lee, M. D., & Wagenmakers, E.-J. (2013). Bayesian Cogni-
participant places a near-degenerate decision bound to distin-           tive Modeling: A Practical Course. Cambridge University
guish just one or two stimuli from the others. It is debatable           Press.
whether this use is consistent with the theoretical motivations       Maddox, W. T., & Ashby, F. G. (1993). Comparing decision
of decision bound models, which usually expect significant               bound and exemplar models of categorization. Perception
number of stimuli to be separated. One way to include this               and Psychophysics, 53, 49–70.
theoretical assumption, only possible in a Bayesian approach,         Newell, B. R., Dunn, J. C., & Kalish, M. L. (2010). The di-
is to change the prior on βV                                             mensionality of perceptual category learning: A state-trace
                            i to capture the expectation that the
vertical boundary will be close to the middle of the stimulus            analysis. Memory & Cognition, 38, 563–581.
space (Vanpaemel & Lee, 2012).                                        Nosofsky, R. M. (1986). Attention, similarity and the
                                                                         idenitification-categorization relationship. Journal of Ex-
                          Conclusion                                     perimental psychology: General, 115, 39–57.
                                                                      Plummer, M. (2003). JAGS: A program for analysis of
Latent mixture modeling is a general framework for model-                Bayesian graphical models using Gibbs sampling. In
ing individual differences in human behavior. In this paper,             K. Hornik, F. Leisch, & A. Zeileis (Eds.), Proceedings of
we applied the approach to the challenge of understanding                the 3rd International Workshop on Distributed Statistical
the different decision bounds people might use to categorize             Computing. Vienna, Austria.
stimuli, consistent with previous theorizing and modeling ap-         Soto, F. A., Vucovich, L., Musgrave, R., & Ashby, F. G. (in
plying General Recognition Theory. We developed a latent                 press). General recognition theory with individual differ-
mixture with six possible categorization strategies, and ap-             ences: A new method for examining perceptual and deci-
plied it to previously modeled data reported by Zeithamova               sional interactions with an application to face perception.
and Maddox (2006).                                                       Psychonomic Bulletin & Review..
   Our results highlight a number of powerful features of the         Vanpaemel, W., & Lee, M. D. (2012). Using priors to formal-
Bayesian approach. It represents uncertainty about model use             ize theory: Optimal attention and the Generalized Context
and the parameterization of those models, in contrast to tradi-          Model. Psychonomic Bulletin & Review, 19, 1047–1056.
tional inference methods like maximum likelihood estimation           Zeigenfuse, M. D., & Lee, M. D. (2010). Finding the features
or least-squares fitting. This means inferences are sensitive to         that represent stimuli. Acta Psychologica, 133, 283–295.
all aspects of the complexity of the various possible catego-         Zeithamova, D., & Maddox, W. T. (2006). Dual task interfer-
rization strategies. Importantly, it is possible to propose any          ence in perceptual category learning. Memory & Cognition,
sort of categorization strategy, including explicit models of            34, 387–398.
                                                                  506

