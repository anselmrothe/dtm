         What is Lost in Translation from Visual Graphics to Text for Accessibility
                                            Peter Coppin (pcoppin@faculty.ocadu.ca)
               Dept. of Industrial Design, Faculty of Design, OCAD University, Toronto, ON M5T 1W1 CANADA
           Dept. of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON M5S 3G8 CANADA
                             Abstract
  Many blind and low-vision individuals are unable to access
  digital media visually. Currently, the solution to this
  accessibility problem is to produce text descriptions of visual
  graphics, which are then translated via text-to-speech screen
  reader technology. However, if a text description can
  accurately convey the meaning intended by an author of a
  visualization, then why did the author create the visualization
  in the first place? This essay critically examines this problem
  by comparing the so-called graphic–linguistic distinction to
  similar distinctions between the properties of sound and
  speech. It also presents a provisional model for identifying
  visual properties of graphics that are not conveyed via text-to-
  speech translations, with the goal of informing the design of
  more effective sonic translations of visual graphics.
        Graphics Without Visual Perception
Consider the experience of a blind or low-vision individual
who uses a screen reader to access pictures, diagrams,
charts, and graphs. Unlike a user who accesses graphical                   Figure 1. The chart (a) is composed of visually perceived
media through visual perception, the screen reader user                shape contours (b) and text labels (c). Accessibility practices
usually accesses these graphics via text-to-speech                      translate b–c to text (d), with shapes described via text (e).1
“descriptions,” essentially interpretations of what was
deemed most relevant by the person who produced the text                  Many scholars have explored the differences between
descriptions of the author’s intended meaning. For example,            graphics and text, often referred to as the so-called
Figure 1a presents a financial chart with rising and falling           “graphic–linguistic distinction” (Shimojima, 1999). In
stock prices over time, where time is shown on the                     addition, researchers have investigated how so-called “non-
horizontal axis and monetary value is shown on the vertical            linguistic sonification” can be employed to make charts and
axis. Figure 1d presents a text description of the chart               graphs more accessible (e.g., Hermann, Hunt, & Neuhoff,
compliant with the Web Content Accessibility Guidelines                2011; Mauney & Walker, 2004). This essay examines the
(WCAG), using text to describe the rising and falling                  graphic–linguistic distinction in order to better understand
monetary values over time. The next sections compare and               how it could correspond to a similar distinction between
contrast how these presentations are experienced.                      properties of non-linguistic sonification compared to speech
  In a text description of a visual graphic (Figure 1d), all of        to provide a means to identify what is lost when graphics are
the information is conveyed via text (or text-to-speech,               translated to text-to-speech. An increased understanding
when conveyed via screen reader technology). But in the                could inform the design of new approaches for conveying
original chart (Figure 1a), only some of the information is            properties of graphically represented shapes via sound.
conveyed via text, predominantly numerical values and
labels (Figure 1c); the shape of the shaded contour                            The Graphic–Linguistic Distinction:
(Figure 1b) is not conveyed via text: the visually perceived                 Implications for Sonic Interface Design
shapes are picked up “more directly” and the features of               The graphic–linguistic distinction has been described in
shapes are translated to text descriptions. However,                   various ways: analogical versus Fregean; analog versus
important properties of visually perceived shape information           propositional;      graphical       versus   sentential;    and
(Figure 1b) are lost in translation and are instead conveyed           diagrammatical versus linguistic (Shimojima, 1999).
via text (Figure 1e). This shape information is needed to
provide the unique affordances that are often associated
                                                                          1
with “visual” representations relative to text.                             Adapted from “Web Accessibility Best Practices: Graphs” by
                                                                       Campus Information Technologies and Educational Services
                                                                       (CITES) and Disability Resources and Educational Services
                                                                       (DRES), University of Illinois at Urbana/Champaign. Copyright
                                                                       2005 by University of Illinois at Urbana/Champaign.
                                                                   447

2D Versus Sequential                                                 can alter the pitch of the sound if “scrubbed” to different
According to Larkin and Simon (1987), diagrammatic                   points on the x-axis, so that higher pitches correspond to
representations “preserve explicitly the information about           points that intersect with the cursor at higher elevations
the topographical and geometric relations among the                  (Figure 2, right) and lower pitches correspond to points that
components of the problem.” More specifically, Larkin and            intersect with the cursor at lower elevations, thereby
Simon defined a diagram as “a data structure in which                allowing blind or low-vision users to perceive the contours
elements appear in a single sequence” whereas a                      of the graph (cf. Brown, Brewster, Ramloll, Burton, &
diagrammatic representation is a “data structure in which            Riedel, 2003).
information is indexed by two-dimensional location.” For
the purposes of this essay, the text description in Figure 1e
                                                                     Relation Symbols and Object Symbols
is classified as sentential because the text is composed of          According to Russell (1923), in sentences “words which
marks arranged in a linear sequence and the marks are taken          mean relations are not themselves relations,” whereas in
to refer to words with linguistic meanings (linguistically           graphical representations like maps, “a relation is
conveyed elements). In contrast, Figure 1a is classified as a        represented by a relation.” An example of the latter is the
diagram because the financial values are indicated via               financial chart (e.g., Figure 1a), where higher monetary
(textually) labeled points or lines (elements) that are              values are conveyed via marks at higher elevations of the
indexed to a graphical grid. The visually processed spatial          graphic, whereas lower monetary values are conveyed via
relations among these labeled marks yield powerful                   marks at lower elevations. This convention allows the
affordances, because by processing the contours of lines or          visually perceived spatial relationships among the marks to
the relative positions of marks scattered across the two-            represent relationships among monetary values over time.
dimensional graphical surface, the viewer can infer values
and trends that are not explicitly conveyed via labels (cf.          Implications for sonic charts and graphs
Barwise & Etchemendy, 1990).                                         Graphical relations could be conveyed sonically. Consider
                                                                     two tones with different pitches: Tone A and Tone B
Implications for sonic charts and graphs                             (Figure 2, right). If Tone A is at a lower frequency than
Sonic sentential properties. Text-to-speech (the current             Tone B, then the sonic relation between the two tones is the
standard for WCAG accessibility) would seem to be the                perceptible difference in pitch between the tones. For
obvious candidate for the sonic version of what Larkin and           example, if Tone A refers to a stock price at an earlier point
Simon referred to as a sentential structure, where elements          in time, and Tone B refers to a stock price at a later point in
are arranged in a linear sequence. In the case of visually           time, then the perceptible difference between the pitches of
processed written sentences composed of word forms                   the tones can convey the difference in price over time.
printed on a page, the sequential properties result from the         Moving the sonic cursor from left to right would correspondPitch
linear arrangement of characters and word forms on the               to a change (increase) in pitch, conveying the change in         Stereo
printed surface. In the case of sonic sentential structures, the     stock price over time via a sonic relation.
sequential properties are temporal, presented as a sequence                     “A is lower than B and
                                                                                B is to the right of A”
of sounds that are perceptually processed as words that refer
to intended meanings. Larkin and Simon did not define what                                                               Pitch
                                                                                                  D
the elements (that are arranged in sequence) are composed                                 B
                                                                                                                         Increases
                                                                                 Pitch
of. For the purpose of this subsection, let us assume that the                                 C
                                                                                        A           E
elements are some combination of properties that, when
sequentially processed as words, refer to intended items.                                   Stereo
                                                                                                            Cursor Moves
   Sonic diagrammatic properties. To present diagrammatic                                                     to Right
properties in a way that can be perceived aurally, designers
                                                                          Figure 2. By scrubbing a “sonic cursor” along an axis,
would need to exploit properties of sound that can convey
topological and geometric relations. People use stereo, echo,        audiences could access sonically conveyed relations through
and the Doppler effect to determine the spatial locations of                           changes in pitch and via stereo.
sound-producing objects in physical environments (cf. Nasir
                                                                     Analog Versus Digital
& Roberts, 2007). Designers could exploit these cues to
convey geometric and topological relations among elements            The classic distinction between analog versus digital, where
that are indexed to a 2D plane (cf. Brown, Brewster,                 analog refers to visual properties of a graphic and digital
Ramloll, Burton, & Riedel, 2003; Hermann, Hunt, &                    refers to linguistic properties, is most commonly associated
Neuhoff, 2011). Figure 2 shows how left and right arrow              with Goodman (1968). Shimojima (1999) illustrated this
keys could move an “audio cursor” to different positions on          distinction using the example of a speedometer dial. The
an x-axis of a computationally generated 2D space. The               analog aspect of the dial is the perceived orientation of the
position of the sonically conveyed cursor on the x-axis could        needle relative to the numerically labeled marks on the dial.
be indicated via stereo (cf. Zhao, Plaisant, Shneiderman, &          The digital aspect is the numerical magnitude (speed)
Lazar, 2008). For a simple spark line graph, the sonic cursor
                                                                 448

determined by comparing the needle’s position to the marks         both A and C.” Each text description conveys a different
representing numerical values.                                     interpretation of what is shown visually and therefore
                                                                   affords different inferences. In contrast, a diagram can
Implications for sonic charts and graphs                           convey many other relationships because of how it conveys
The analog versus digital distinction appears to involve two       topological and geometric information through visual
interrelated capabilities: lower-level perceptual capabilities     perception: Barwise and Etchemendy referred to this as a
to process geometric and topological properties (e.g., those       diagram’s ability to present “countless facts.”
shown on the speedometer dial); and higher-level                      In translating a visual diagram into a sonic diagram, one
capabilities to process, filter, and interpret how those           is essentially translating a spatial structure from one set of
perceptually processed features fall into conceptual               modality-specific perceptual features into another. Loomis
categories (e.g., the numerically represented velocity)            et al. (2013) have argued that regardless of the stimulus
(Mandler, 2006; Figure 3). A financial chart is composed of        modality, what is generated is ultimately an amodal “spatial
both analog (lines that vary along the Cartesian plane) and        image”. Thus in principle it should be possible to convey
digital (text that conveys monetary values relative to time)       the same underlying spatial representation with the unique
properties. The current text-to-speech approach only               affordances of diagrams using sonification.
exploits the digital properties of language (words with
symbolic meaning) – but designers could produce effective          Implications for sonic charts and graphs
visual-to-audio translations by recruiting features of sound       When Barwise and Etchemendy (1990) referred to diagrams
such as pitch, echo, stereo, and timbre to convey properties       as “physical situations,” they were referring to the properties
of     graphics      that    vary     in    analog      space.     (and affordances) of diagrams that emerge through
                                                                   interaction via a human visual perception system. The
                                                                   challenge for designers who seek to extend the affordances
                                                                   of visual diagrams to the sonic domain is to identify
                                                                   properties or dimensions of sound that similarly (i.e., using
                                                                   human perceptual processing of sound) make use of
                                                                   “physical situations” to present “countless facts.”
                                                                      Thus, a hybrid stereo–varying frequency interface (see
                                                                   Figure 3) should enable a user to “hear the shape” of a
                                                                   contour. Indexing text-to-speech labels to contours should
                                                                   allow users to form multiple sentences (countless facts)
                                                                   about the geometric and/or topological relations among the
                                                                   labeled elements.
                                                                   Extending the Graphic–Linguistic Distinction into
    Figure 3. A perception–reaction system is hierarchically       the Sonic Domain
  organized to process lower-level perceptual structures and
   categorize them into higher-level conceptual categories.        Let us now extend on the various graphic–linguistic
                                                                   distinctions to consider sonic versions of visual charts and
Intrinsic Versus Extrinsic Constraints                             graphs.
                                                                      1. Extending on the diagrammatic versus sentential
For brevity, the following discussion will use the classic         distinction, text-to-speech can be considered a sonic version
characterization provided by Barwise and Etchemendy                of what Larkin and Simon referred to as a sentential
(1990) because it is compact and intuitive:                        structure and is the current WCAG approach to web
   Diagrams are physical situations. They must be, since we        accessibility. In contrast, spatial sound can be exploited to
can see them. As such, they obey their own set of constraints      convey 2D sonic diagrammatic external representations.
. . . By choosing a representational scheme appropriately,            2. Extending on the analog versus digital distinction, text-
so that the constraints on the diagrams have a good match          to-speech uses language to convey digital properties
with the constraints on the described situation, the diagram       sonically. The analog properties of sound, such as tone,
can generate a lot of information that the user never need         timbre, stereo, and echo could afford the communication of
infer. Rather, the user can simply read off facts from the         spatial, geometric, or topological information.
diagram as needed. This situation is in stark contrast to             3. Extending on the distinction between relation symbols
sentential inference, where even the most trivial                  and object symbols, the current text-to-speech approach
consequence needs to be inferred explicitly.                       uses words to convey relations. Because relations among
   To illustrate how “diagrams are physical situations,”           elements represented by analog and spatial properties of
consider the illustration shown in Figure 2 (left). A text (or     sound are themselves relations, analog and spatial properties
text-to-speech) description might go as follows: “A is below       of sound could be recruited to map numerical values to
B and both A and B are to the left of C.” Another textual          perceptual dimensions.
description might read: “B is between A and C and is above
                                                               449

   4. Extending on the distinction between intrinsic and             under perceptual categories, At higher-level association
extrinsic constraints, producing sonic versions of visual            areas (see Figure 3, right), conjunctive neurons converge in
graphics would require identifying “physical situations” that        zones across multiple sensory modes. These “convergence
naturally emerge during human perceptual processing of               zones” (Damasio, 1989; Simmons & Barsalou, 2003) enable
sound to present “countless facts.”                                  simulated prototypes of possible perception–reactions that
                                                                     are not as easily described in terms of a specific perceptual
 Perceptual and Conceptual Graphic Relations                         mode or a reenactment of a specific prior perception–action.
This section integrates these extensions and proposes how            Instead, these simulated prototypes fall under more general
the graphic–linguistic distinction could be extended to sonic        categories of possible perception–actions (Barsalou, 2003).
external representations. First, let us recruit and expand on        These are not only more amodal, but have been described as
the distinction between lower-level perceptually processed           more filtered, interpreted (Pylyshyn, 1973), conceptual
topological and geometric features of an environment versus          (Barsalou, 2003, 2005), or abstract (Barsalou, 2003). For
the      recognition,     categorization,    and      linguistic     example, a child who takes a bite out of what turns out to be
communication of those features.                                     a rotten apple might later reenact this experience when she
   Visual and aural sentential structures and relations are          perceives another rotten apple with common properties.
detected and perceptually processed via lower-level sensory          Over time, she will develop an understanding of ‘rotten’ as a
receptors and perceptual categories (Figure 3, left). In             category that can include apples, as well as many other
written text or text-to-speech, what is most relevant is the         objects and experiences.
higher-level conceptual category (Figure 3, right) that a
given feature (such as perceptually processed printed text on           Back to charts and graphs. In a financial chart (and
a page or text-to-speech) is taken to fall under. What is            many other kinds of diagrams), relations are conveyed via
needed is a way to convey topological and geometric                  lower-level perceptual processing of the geometrical and
relations among elements by exploiting lower-level                   topological properties of the marked physical surface
perceptually processed features of a visual graphic or sonic         (Table 1). In contrast, in text descriptions (sentential
structure (Figure 3, left). Let us refer to these perceptually       structures), relations are conceptual (and conveyed
processed features as perceptual properties. Let us refer to         linguistically; see Table 2); although visual properties of
these perceptually processed relations among elements as             printed text or aural properties of text-to-speech are also
perceptual relations. Let us refer to relations that are             picked up by sensory receptors, what is meaningful about
communicated via text as text-described relations.                   them is the conceptual relation that is conveyed
                                                                     linguistically.
Perceptual Relations vs. Text-Described Relations
                                                                      Table 1. Diagrams are composed of perceptually processed
We are now ready to build on previous work by Coppin
                                                                      relations among linguistically conveyed conceptual objects;
(2014) to provide a theoretical foundation for distinguishing
                                                                           sentences are composed of linguistically conveyed
perceptual relations versus text-described relations.
                                                                           conceptual relations among linguistically conveyed
   The model is based on the idea that an individual’s
                                                                            conceptual objects (adapted from Coppin, 2014).
perception–reaction loop (cf. Gibson, 1986) enables survival
                                                                                            Diagrammatic         Sentential
and prosperity within a dynamic environment composed of
                                                                     Relations              Perceptual           Conceptual
change and variation. This requires capabilities to predict,
                                                                     Objects or Items Conceptual                 Conceptual
anticipate, and simulate (Barsalou, 1999) dynamic change
and variation. For example, reaching for and grasping an
item such as a cup requires capabilities to perceptually
process features from the proximal surface of the item and
                                                                     Perceptual Specificity is Lost in Translation
also to predict, anticipate, and simulate features of the distal     The idea of “specificity” is central to understanding what is
surface of the item.                                                 lost in translation, so let us begin by clarifying what is
   These simulations are constructed from the memory                 meant by “more or less specific” in this context. Consider
traces of past perception–reactions (conjunctive neurons), so        the line shown in Figure 4b. Relative to the line of Figure
simulation involves many of the same neural systems used             4c, we have more knowledge about the location of a point in
during perception (Kosslyn, Ganis, & Thompson, 2001).                a one-dimensional space, due to the shaded red marker. This
For example, as I perceive the cup, I am also informing              means we have more certainty (or more information) about
potential action (reaching for and grasping the proximal and         the specified location of the point in Figure 4b than we do
distal sides of the cup). Thus, perception and simulation are        about the location of the point in Figure 4c.
integrated aspects of perception–reaction within a physical
environment, and each act of perception–reaction leaves
memory traces in the form of conjunctive neurons across
lower-level association areas (Figure 3).
    At lower-level association areas, which are more tightly
coupled with sensory receptors, simulated prototypes fall
                                                                 450

                                                                      translation and how what is lost could be conveyed via non-
                                                                      linguistic sound. In the text description (Figure 1d), the
                                                                      problem is that all content is conveyed conceptually (via
                                                                      text-to-speech) whereas the original visual graphic that the
                                                                      text description is based on conveys much of the content
                                                                      (the contour of the shape) perceptually: Perceptual relations
                                                                      are lost and replaced by conceptual relations, generating
 Figure 4. The left vertical line (b) refers to the limited range     perceptual ambiguity. If the objective is to present Figure 1a
  of perceptual structures conveyed via a given graphic. The          sonically, how can a designer decide which aspects should
right line (c) refers to the wider range of possible conceptual       be conveyed via conceptual properties (text-to-speech) and
   categories that the perceptual structures could fall under.        which aspects should be conveyed via perceptual sonic
 The model predicts that when perceptual specificity is high          properties (such as spatial sound)?
              (b) conceptual specificity is low (c).                     Recall the perceptual distinction, where perceptual
                                                                      properties are predicted to afford the communication of
   Extending the line example to discuss perceptual                   concrete structures more effectively compared with
relations, Figure 4b refers to intentionally configured marks         conceptual properties, and an aspect of a graphic can be
or sounds from an author to cause intended audience                   identified as “more concrete” if it produces a perceptual
percepts (the diagram in Figure 4a). However, the                     structure that corresponds to what could be picked up and
perceptual relations of Figure 4a can be processed, filtered,         perceptually processed from a physical environment. In this
and interpreted to fall under a range of possible relational          account, the graphically represented shape contour
categories (that can be text-described), indicated by the             (Figure 1b) is primarily perceptual, and is therefore more
highlighted segment of the right line in Figure 4c (as shown          appropriate for translation to sonic properties that can use
in Figure 4d: “A is below B and both A and B are to the left          spatial sound to convey geometric and topological relations
of C” or “B is between A and C and is above both A and                among conceptually conveyed objects.
C”). In other words, although perceptual specificity is high,            To determine which aspects of a graphic should be
conceptual specificity of the intended relation is low                conveyed via text-to-speech, recall the conceptual
because the perceptual relations can fall under numerous              distinction: text is predicted to afford the communication of
conceptual categories. However, the reverse is also true and          abstract conceptual categories more effectively compared
this reversal exposes the heart of what is lost during the            with perceptual properties, and a concept can be identified
translation process.                                                  as more abstract if it is less tied to a specific perceptual
                                                                      mode). In other words, it is less easily mapped back to a
Conceptual Specificity is Perceptually Ambiguous                      structure that could be picked up and perceptually processed
Extending the line example to discuss the perceptual                  from a physical environment. Under this account, the
ambiguity of text-described (conceptual) relations, the right         numbers that label increments on the x and y axes (Figure
highlighted line in Figure 5c refers to a specific (sentential)       1a) are more conceptual because they cannot be mapped
text description authored to convey intended conceptual               back to a perceptual structure that could be picked up from a
relations (Figure 5d). However, numerous perceptual                   physical environment.
relations (Figure 5a) can fall under the text-described
conceptual relations, indicated by the highlighted segment                                     Conclusion
of the left line in Figure 5b. In other words, although               This essay proposes a provisional model to underpin the
conceptual specificity is high, perceptual specificity of the         various accounts of the graphic–linguistic distinction
intended relations is low, because numerous perceptual                described in the literature as a means to extend the graphic-
relations can fall under the text-described conceptual                linguistic distinction into aural domains. The model makes
relations.                                                            the distinction in terms of lower level perceptual capabilities
                                                                      that enable perceivers to perceptually process concrete
                                                                      structures (e.g., geometric and topological features) on the
                                                                      one hand, and higher level capabilities that enable
                                                                      perceivers to process and interpret how those perceptually
                                                                      processed structures fall under more abstract conceptual
                                                                      categories on the other.
                                                                         Due to these distinctions, the model predicts that
      Figure 5. The model predicts that when conceptual               perceptual relations (conveyed via graphics or non-linguistic
    specificity is high (c) perceptual specificity is low (b).        sonification) afford the communication of concrete relations
                                                                      (conveyed via text or text-to-speech) more effectively
Application to an Example Design Problem                              compared to conceptual relations conveyed via text or text-
Let us now return to the WCAG text description example                to-speech. In addition, the model predicts that conceptual
from Figure 1 in order to demonstrate what is lost in                 relations (conveyed via text or text-to-speech) afford the
                                                                  451

communication of abstract relations more effectively                Damasio, A. R. (1989). The brain binds entities and events
compared to perceptual relations conveyed via graphics or             by multiregional activation from convergence zones.
non-linguistic sonification.                                          Neural Computation, 1(1), 123–132.
   In addition, the model streamlines accounts that                 Gibson, J. J. (1986). The ecological approach to visual
distinguish diagrammatic from sentential structures to                perception. Hillsdale, NJ: Lawrence Erlbaum.
(1) characterize sentential structures as composed of               Goodman, N. (1968). Languages of art: An approach to a
conceptual relations among conceptual objects on the one              theory of symbols. Indianapolis, IN: Bobbs-Merrill
hand, and (2) diagrammatic structures as perceptually                 Company.
represented relations among conceptual objects on the other.        Hermann, T., & Hunt, A. (2011). The sonification
Under this account, (3) a sonic diagram is conceptualized as          handbook. Berlin: Logos Verlag.
sonically conveyed relations among linguistically conveyed          Kosslyn, S. M., Ganis, G., and Thompson, W. L. (2001).
(via text-to-speech) objects.                                         Neural foundations of imagery. Nature Reviews
   This model may be applied by researchers and designers             Neuroscience, 2(9), 635–642. doi:10.1038/35090055
to generate testable predictions. For example comparing             Larkin, J. H., & Simon, H. A. (1987). Why a diagram is
recognition performance of a visual data set communicated             (sometimes) worth ten thousand words. Cognitive
either through sonification or text-description. This is useful       Science, 11, 65–99. doi:10.1111/j.1551-6708.1987
within a design context because designers lack guidelines             .tb00863.x
for converting visual graphics into non-visual perceptual           Loomis, J. M., Klatzky, R. L., & Giudice, N. A. (2013).
modes.                                                                Representing 3Dspace in working memory: Spatial
                                                                      images from vision, touch, hearing, and language. In S.
                   Acknowledgements                                   Lacey & R. Lawson (Eds), Multisensory Imagery:
This research was supported in part by grants from the                Theory & Applications (pp. 131-156). New York:
Centre for Innovation in Data-Driven Design and the                   Springer.
Graphics Animation and New Media Centre for Excellence.             Mandler, J. M. (2006). Categorization, development of. In
I would like to thank Research Assistants Ambrose Li and              Encyclopedia of Cognitive Science. doi:10.1002
Michael Carnevale as well as Dr. David Steinman.                      /0470018860.s00516
                                                                    Mauney, B.S. & Walker, B.N. (2004, July). Creating
                         References                                   functional and livable soundscapes for peripheral
                                                                      monitoring of dynamic data. In 10th International
                                                                      Conference on Auditory Display (ICAD 2004). (pp. 6-9).
Barsalou, L. W. (1999). Perceptual symbol systems.                  Nasir, T., & Roberts, J. C. (2007, June). Sonification of
   Behavioral & Brain Sciences, 22, 577–660.                          spatial data. In 13th International Conference on Auditory
Barsalou, L. W. (2003). Abstraction in perceptual symbol              Display (ICAD 2007) (pp. 112–119). ICAD.
   systems. Philosophical Transactions of the Royal Society         Palmer, S. E. (1978). Fundamental aspects of cognitive
   of London. Series B: Biological Sciences, 358(1435),               representation. In E. Rosch & B. B. Llyod (Eds.)
   1177–1187. doi:10.1098/rstb.2003.1319                              Cognition and Categorization, 259–303. Hillsdale, NJ:
Barsalou, L. W. (2005). Abstraction as dynamic interpret-             Lawrence Erlbaum Associates, Publishers.
   ation in perceptual symbol systems. In L. Gershkoff-             Pylyshyn, Z. W. (1973). What the mind’s eye tells the
   Stowe & D. Rakison (Eds.), Carnegie Symposium Series:              mind’s brain: A critique of mental imagery. Psychological
   Building object categories (pp. 389–431). Majwah, NJ:              Bulletin, 80(1), 1.
   Erlbaum.                                                         Russell, B. (1923). Vagueness. Australasian Journal of
Barsalou, L. W. (2009). Simulation, situated conceptual-              Psychology and Philosophy, 1(2), 84–92. doi:10.1080
   ization, and prediction. Philosophical Transactions of the         /00048402308540623
   Royal Society of London. Series B: Biological Sciences,          Shimojima, A. (1999). The graphic-linguistic distinction:
   364(1521): 1281–1289. doi:10.1098/rstb.2008.0319                   Exploring alternatives. Artificial Intelligence Review,
Barwise, J., & Etchemendy, J. (1990). Visual information              13(4), 313–335.
   and valid reasoning. In W. Zimmerman (Ed.), Visualiz-            Simmons, W. K., & Barsalou, L. W. (2003). The similarity-
   ation in mathematics (pp. 8–23). Washington, DC:                   in-topography principle: reconciling theories of concept-
   Mathematical Association of America.                               ual deficits. Cognitive neuropsychology, 20, 451–486.
Brown, L. M., Brewster, S. A., Ramloll, S. A., Burton, R.,          Spence, C. (2011). Crossmodal correspondences: A tutorial
   & Riedel, B. (2003). Design guidelines for audio                   review. Attention, Perception, & Psychophysics, 73(4),
   presentation of graphs and tables. International                   971–995. doi:10.3758/s13414-010-0073-7
   Conference on Auditory Display.                                  Zhao, H., Plaisant, C., Shneiderman, B., & Lazar, J. (2008).
Coppin, P. W. (2014). Perceptual-cognitive properties of              Data sonification for users with visual impairment: a case
   pictures, diagrams, and sentences: Toward a science of             study with georeferenced data. ACM Transactions on
   visual information design (Doctoral dissertation, Univers-         Computer-Human Interaction (TOCHI), 15(1), 4.
   ity of Toronto, Toronto, Canada). Retrieved from https://
   tspace.library.utoronto.ca/handle/1807/44108
                                                                452

