   Exploring Complexity in Decisions from Experience: Same Minds, Same Strategy
Emmanouil Konstantinidis (em.konstantinidis@gmail.com), Nathaniel J. S. Ashby (nathaniel.js.ashby@gmail.com),
                                                  & Cleotilde Gonzalez (coty@cmu.edu)
                                                   Department of Social & Decision Sciences
                                            Carnegie Mellon University, Pittsburgh, PA 15213, USA
                                 Abstract                                    Ashby et al. (2015) investigated whether the less-than-
                                                                          optimal rates of maximization found in DFE and continued
     One frequent piece of advice is not to “put all our eggs in          variability in choice are more likely the result of diversifica-
     one basket” and opt for multiple alternatives in order to min-
     imize risk and uncertainty in our decisions. In a behavioral         tion in choice, or whether it more likely reflects noise (un-
     study involving decisions-from-experience, Ashby, Konstan-           clear preferences) or strategies such as win-stay-lose-shift or
     tinidis, and Gonzalez (2015) showed that participants follow         hot-stove effects (e.g., Biele, Erev, & Ert, 2009). The di-
     an “irrational” strategy in choice selection which departs from
     maximization. As structural complexity (number of avail-             versity hypothesis suggests that participants distribute their
     able options) increased, participants diversified their choices      choices in a quasi-normative way, choosing from options pro-
     more, proportional to rank ordering options based on their ex-       portional to their experienced EVs (e.g., through probability
     pected value. The current work explores the underlying cogni-
     tive mechanisms through a reinforcement-learning model and           matching). This hypothesis was tested using an experimental
     shows that people’s choices can be explained by a singular           design where the structural complexity of a typical decisions-
     strategy (diversification in choice), which originates from sim-     from-feedback (DFF) paradigm was manipulated by increas-
     ilar cognitive processes regardless of structural complexity.
                                                                          ing the number of options available to choose from. Ashby
     Keywords: Decisions from Experience; Diversification; Com-           et al. found support for the diversity hypothesis across all
     putational Modeling; Probability Matching
                                                                          levels of complexity (see Behavioral Results in the current
                                                                          manuscript).
                             Introduction                                    The purpose of the present work is to examine this ef-
  People are often confronted with many real-life situations in           fect and decompose its underlying cognitive and psycholog-
  which they have to make decisions among a number of op-                 ical underpinnings by using computational modeling analy-
  tions such as investments programs, medical plans, and re-              sis. Cognitive models can be used to assess latent psycho-
  tirement options. One “safe” approach in choosing among                 logical factors that affect behavior in a task and to quantify
  multiple investment programs, for example, is not to “put all           these processes via model parameters. The main hypothesis
  the eggs in one basket”, but instead select several investments         is that diversification in choice originates from similar cog-
  in order to minimize the risk of losing everything (Ayal &              nitive processes; in other words, model parameters will be
  Zakay, 2009). This approach is non-optimal given normative              similar across conditions and levels of structural complexity.
  accounts of decision-making under risk and uncertainty such
  as expected value (EV) maximization.                                                               Method
     In experience-based decision-making, people make deci-               Participants
  sions between options that carry monetary payoffs in the                We tested a total of 722 participants, recruited from Ama-
  absence of explicit information about the payoffs and asso-             zon Mechanical Turk. Participants who did not complete
  ciated probabilities (Barron & Erev, 2003; Hertwig et al.,              the study and failed to pass an attention check test (click on
  2004). On each trial, they receive feedback from their se-              the corner of the screen instead of clicking continue) were
  lections and their goal is to maximize overall winnings. This           removed from analysis. Four-hundred and five participants
  is usually achieved by first exploring the environment (i.e.,           fulfilled our inclusion criteria (Mage = 33.46, 47% female).
  the available options) and then exploiting the most rewarding           Participants received $1.25 for their participation and an ad-
  options (Gonzalez & Dutt, 2011). Often, in decisions-from-              ditional amount dependent on their performance in the task
  experience (DFE), people prefer options with higher EVs                 (Mearnings = $4.45).
  (e.g., Hills, Noguchi, & Gibbert, 2013; Jessup, Bishara, &
  Busemeyer, 2008). While more choices are made from the                  Task
  most advantageous option, perhaps indicating a shift from               A typical DFF paradigm was employed (Barron & Erev,
  exploration to exploitation, some degree of variability in              2003). Participants had to make 200 consequential choices
  choice remains even after a great deal of experience (Ashby &           in one of four conditions: choices involving 2 (C2: N = 99),
  Rakow, in press). Such variability might suggest that while             4 (C4: N = 100), 8 (C8: N = 100), or 16 options (C16: N =
  individuals generally drift towards the EV maximizing op-               106). Different options were labeled alphabetically (“Option
  tion, they might also (incorrectly) see some value in diver-            A” to “Option P”) and appeared as buttons on the computer
  sifying their choices across available options; such contin-            screen in random order. In each condition, there was an equal
  ued variation might represent strategies such as probability            number of safe (two moderate outcomes with equal probabil-
  matching (see Shanks, Tunney, & McCarthy, 2002).                        ity) and risky (low probability of a high outcome, but higher
                                                                      1177

probability of a low outcome) options (see Table 1). For ex-                    preference of spreading selections across choices is not ran-
ample, in the two option condition (C2), gambles S1 (a safe                     dom, but rather it follows a quasi-normative approach. This
high EV option) and R1 (a risky low EV option) were ran-                        EV matching strategy is also consistent with other strategies
domly assigned to “Option A” and “Option B”. The C4, C8,                        such as probability matching. For instance, recent studies in
and C16 conditions included gambles S1 and R1 along with                        DFE and multi-armed bandit tasks have shown that partici-
additional gambles shown in Table 1. The maximizing option                      pants’ choice strategies may be best explained by a probabil-
(i.e., the option with the highest EV) was option S1 across                     ity matching heuristic (Schulz, Konstantinidis, & Speeken-
conditions. After each choice, participants received feedback                   brink, 2015; Speekenbrink & Konstantinidis, in press).
about the outcome of their decision.
Table 1: Safe (S) and risky (R) gamble pairs outcomes in points
(OS1-OS2 and OR1-OR2), probabilities (50%-50% and 20%-80%),                                                 1.00
                                                                                                                                             0.06 (26)   0.04 (26)
and expected values in points (EVS and EVR ) in all experimental                                                               0.12 (38)                 0.04 (27)
                                                                                                                   0.15 (44)
conditions (C2, C4, C8, C16).                                                                                                                0.07 (32)   0.03 (29)
                                                                                                                                                         0.05 (35)
                                                                                                                               0.12 (44)     0.09 (38)   0.04 (32)
      Conditions                   Safe                      Risky                                                                                       0.04 (41)
                                                                                                            0.75                             0.07 (44)
 C2   C4   C8      C16   OS1-0.5   OS2-0.5   EVS   OR1-0.2   OR2-0.8   EVR                                                                               0.05 (38)
                                                                                    Proportion of Choices
                                                                                                                               0.14 (60)                 0.05 (44)
 X    X    X        X      70        60       65    100        30       44                                                                   0.08 (55)
                                                                                                                                                         0.04 (53)
      X    X        X      65        55       60    110        20       38
           X        X      60        50       55    120        10       32                                                                   0.09 (55)   0.07 (55)
           X        X      55        55       55    130         0       26                                                                               0.04 (55)
                                                                                                            0.50                                         0.04 (56)
                    X      67        57       62    105        25       41                                                                   0.12 (60)
                                                                                                                                                         0.05 (59)
                    X      64        54       59    115        15       35                                         0.85 (65)
                    X      61        51       56    125         5       29                                                                               0.08 (60)
                    X      58        48       53    135         0       27
                                                                                                                               0.62 (65)
                                                                                                                                                         0.1 (62)
                                                                                                            0.25
                                                                                                                                             0.41 (65)
Procedure
                                                                                                                                                         0.23 (65)
Participants provided informed consent and answered demo-
graphic questions. They were informed that they would be                                                    0.00
presented with either 2, 4, 8, or 16 options (between sub-
                                                                                                                     C2          C4               C8      C16
jects), and that they would have to play the options in order
to learn what outcomes were possible as their outcomes and                                                                            Condition
probabilities would not be provided. They were told that their                  Figure 1: Proportion of choices from each option across conditions.
goal was to earn as many points as possible, as points would                    Numbers in parentheses indicate each option’s EV.
be converted to money (40 points = $0.01). After participants
made their 200 decisions, they were informed of their total                        A possible explanation of this effect is that it may be driven
earnings and thanked for their time.                                            by initial exploration of the environment and thus diminishes
                                                                                towards the end of the experiment. Put differently, the ten-
                         Behavioral Results                                     dency to spread choices might be a result of extended explo-
The first step in our analysis was to examine the pattern of                    ration in the first blocks of the experiment and participants
choice selections across conditions. According to the diver-                    select more frequently the maximizing option in the last tri-
sity hypothesis, we would expect participants’ strategies to                    als of the task. In order to examine this possibility, we tested
depart from maximization (i.e., select consistently the option                  whether the experienced outcome from each option (first 160
with the highest EV) and to rather show a pattern where they                    trials) is a significant determinant of choice selection in the
allocate their choices based on the EV of each option. In other                 last trials of the experiment (40 trials).
words, the option with the highest EV attains the highest pro-                     We conducted a mixed-effects multiple regression predict-
portion of choices, followed by the option with the second                      ing the proportion of choices for each option in the last 40
highest EV, and so on.                                                          trials by the average experienced outcome up to trial 160.
   Figure 1 shows this pattern of results. While the maxi-                      The analysis showed that each option’s average experienced
mizing option (red bar) has the greatest proportion of choices                  outcome significantly predicts choice proportions in the last
in each condition, indicating that participants learn to select                 40 trials, b = .01, z = 23.80, p < .001. The effect is also
more frequently from this option, the option with the sec-                      present when we examine each of the four conditions seper-
ond highest EV in each option set receives the second highest                   ately (zs > 9, ps < .001). This result suggests that participants
proportion, and so on. In fact, there is a direct mapping be-                   allocate their choices according to each option’s EV even in
tween the rank ordering of options based on their EV and                        the later stages of the experiment and after extended feedback
the proportion of choices each of them receives. Thus, the                      and interaction with the task.
                                                                             1178

             Modeling Structural Complexity                                   probabilities match the formed expectancies. When θ ap-
Inspection of choice strategies across conditions suggested a                 proaches zero, choice between options is random (P[G(t +
close link between each option’s EV and the proportion of                     1) = j] = 1/k, where k is the number of available options)
selections it received. We utilised a computational model-                    allowing for exploration behavior. On the other hand, large
ing analysis in order to examine whether the psychological                    values of θ indicate that options with high expectancies will
and cognitive processes underlying choice behavior are simi-                  be selected more often (exploitation). In this model instantia-
lar across conditions.                                                        tion, θ is independent of time (i.e., trial number; see Yechiam
                                                                              & Ert, 2007):
The model                                                                                                   θ = 3c − 1,                            (4)
We employed a reinforcement-learning (RL) model (see Ahn
et al., 2008; Daw et al., 2006; Sutton & Barto, 1998), which                  where c ranges between 0 and 5, with values close to 0
incorporates three basic assumptions regarding the decision                   indicating random choice and values close to 5 suggesting
process in DFE. These assumptions reflect psychological and                   deterministic-exploitative choice1 .
cognitive processes whose interaction is responsible for ob-                  Model Evaluation Parameters were estimated for each in-
served performance (e.g., Busemeyer & Stout, 2002). The                       dividual using maximum likelihood estimation (MLE). The
first assumption relates to the subjective evaluation of re-                  procedure was a combination of grid-search (60 different
ceived feedback in each trial after selecting an option by a                  starting points for each set of parameters) and Nelder-Mead
utility function. This transformation is achieved by using a                  simplex search methods which identified the parameter val-
utility function similar to the value function of Prospect The-               ues that maximized the following log likelihood criterion:
ory (Kahneman & Tversky, 1979):
                                                                                          t−1 k
                             u(t) = x(t)α ,                            (1)        LLi = ∑      ∑ ln(P[G j (t + 1) | Xi (t),Yi (t)]) · δ j (t + 1). (5)
                                                                                          t=1 j=1
where u(t) represents the subjective utility of payoff x on trial
t. The free parameter α (0 ≤ α ≤ 1) determines the shape of                   The model is assessed on how accurately it can predict choice
the utility function. When α equals 1, the subjective utility                 on the next trial, P[G j (t + 1)], given an individual’s history of
matches the received payoff, whereas values less than 1 result                choices, Xi (t), and associated payoffs, Yi (t), up to and includ-
in a curved utility function.                                                 ing trial t (also known as one-step-ahead prediction method).
    The second assumption refers to the formation of expectan-                The dummy variable δ j indicates whether an option is se-
cies, E, about the values of each option j on trial t. Specifi-               lected on trial t + 1.
cally, the momentary utility u j (t) serves as input to a learning
rule which updates these expectancies. In this model, we used                                         Modeling Results
a delta learning rule. This rule updates only the expectancy
E of the selected option j on trial t, whereas the expectancies               Model Fitting
of the unselected options remain unchanged:                                   The first step in our analysis was to ensure that the model
                                                                              we employed provides a good fit to the data and an accurate
        E j (t) = E j (t − 1) + A · δ j (t) · [u j (t) − E j (t − 1)]. (2)    representation of the participants’ choices. The RL model
                                                                              was compared against a random pick model which assumes
The dummy variable δ j (t) determines whether an option is
                                                                              random choice on every trial (P[G(t + 1 = j) = 1/k, where k
selected on trial t (δ j = 1) or not (δ j = 0). The free param-
                                                                              the number of options) and a statistical mean-tracking model
eter A (0 ≤ A ≤ 1) indicates how much the old expectancy,
                                                                              which assumes choice is based on the relative strength of each
E j (t − 1), is modified by the prediction error, [u j (t) − E j (t −
                                                                              option’s mean observed payoff in each trial. In order to assess
1)]. Large values of A reflect rapid forgetting and strong re-
                                                                              the fit of the models, we computed the Schwartz Bayesian
cency effects, whereas smaller values of A indicate weak and
                                                                              information criterion (BIC) for each individual that takes into
recency effects and long associative memories (Busemeyer &
                                                                              account the number of free parameters of each model2 .
Stout, 2002).
                                                                                 Table 2 includes the mean BIC (µBIC) and the number of
    Finally, a choice, which is a probabilistic function of the
                                                                              participants best fit by each model (nBIC). It is evident that
relative strength of each option (i.e., its expectancy compared
                                                                              the cognitive RL model outperforms its competitors in both
to the expectancies of the other options; third assumption),
                                                                              fit measures across all conditions. In other words, predic-
is made. This is achieved by employing a softmax selection
                                                                              tions regarding choice performance improve if we use the RL
rule:
                                              eθ ·E j (t)                     model.
                 P[G(t + 1) = j] = k                       ,           (3)
                                          ∑k=1 eθ ·Ek (t)                         1 We also tried a trial-dependent version of θ parameter of the
                                                                              form θ (t) = (t/10)c , but it produced almost identical model fits.
which defines the probability of selecting option G on the                        2 BIC is defined as follows: BIC = −2 · LL + m · ln(N), where
                                                                                                                      i          i
next trial, t + 1. The free parameter θ (sensitivity or inverse               m is the number of parameters and N the number of observations (in
“temperature” parameter) controls the degree to which choice                  this case, it is the number of trials).
                                                                          1179

Table 2: Model fitting results: Values of mean BIC (µBIC; lower values indicate better fit) and total number of participants best fit by each
model (nBIC) across complexity conditions.
                                                            C2                  C4                                      C8                          C16
                                         Model        µBIC         nBIC    µBIC       nBIC                        µBIC        nBIC          µBIC          nBIC
                                         RL          139.19          87   343.75        91                       588.61         93          836.6           85
                                         Mean        154.17           6   393.33         0                       721.03          0        1068.44            1
                                         Random      275.87           6   551.75         9                       827.62          7        1103.49           20
   Figure 2 shows the observed mean proportion of choices                                options based on their EV. If this hypothesis stands true, then
from each option across 200 trials (Data) and model’s predic-                            model parameters should not differ across conditions, reflect-
tions (Model). The model accurately predicts the rank order                              ing similar underlying psychological processes.
of each option; that is, the option with the highest EV is se-
lected more often, followed by the option with the second
highest EV and so on. In addition, the model’s predictions                                                                               C2                                  C4
                                                                                                                 1.00
for the overall proportion of choices are also very close to                                                                 0.15 (44)        0.15 (44)          0.12 (38)         0.12 (38)
the observed ones (see Figure 3). The accuracy of the model                                                                                                      0.12 (44)         0.16 (44)
(both overall and across trials) provides further support that                                                   0.75
                                                                                                                                                                 0.14 (60)
the model we employed is a good representation of the fac-                                                                                                                         0.11 (60)
tors responsible for observed behavior.
                                                                                                                 0.50
                                                                                                                             0.85 (65)        0.85 (65)
                                                                                                                                                                 0.62 (65)         0.61 (65)
                                                                                         Proportion of Choices
                                        C2                           C4                                          0.25
                        0.75
                                                                                                                 0.00
                        0.50                                                                                                             C8                                  C16
                                                                                                                 1.00        0.06 (26)        0.05 (26)          0.04 (26)         0.03 (26)
                                                                                                                                                                 0.04 (27)         0.05 (27)
                                                                                                                                                                 0.03 (29)
Proportion of Choices
                                                                                                                             0.07 (32)        0.09 (32)                            0.03 (29)
                        0.25                                                                                                                                     0.05 (35)         0.05 (35)
                                                                                                                             0.09 (38)        0.07 (38)          0.04 (32)         0.04 (32)
                                                                                                                                                                 0.04 (41)         0.06 (41)
                                                                                                                 0.75        0.07 (44)        0.1 (44)           0.05 (38)         0.04 (38)
                                                                                                                                                                 0.05 (44)
                        0.00                                                                                                 0.08 (55)        0.08 (55)          0.04 (53)         0.11 (44)
                                                                                                                                                                 0.07 (55)
                                        C8                          C16                                                      0.09 (55)
                                                                                                                                              0.14 (55)          0.04 (55)
                                                                                                                                                                                   0.03 (53)
                                                                                                                                                                                   0.05 (55)
                                                                                                                 0.50        0.12 (60)
                                                                                                                                                                 0.04 (56)         0.04 (55)
                                                                                                                                              0.08 (60)          0.05 (59)         0.07 (56)
                                                                                                                                                                 0.08 (60)         0.05 (59)
                        0.75
                                                                                                                                                                 0.1 (62)          0.09 (60)
                                                                                                                 0.25                                                              0.05 (62)
                                                                                                                             0.41 (65)        0.39 (65)
                        0.50                                                                                                                                     0.23 (65)         0.21 (65)
                                                                                                                 0.00
                        0.25
                                                                                                                              Data            Model               Data             Model
                        0.00
                               0   50   100   150   200 0     50    100   150   200
                                                                                         Figure 3: Overall observed proportion of choices from each op-
                                                    Trial                                tion (Data) and overall predicted choice probabilities (Model) across
                                                                                         conditions. Numbers in parentheses indicate each option’s EV.
Figure 2: Mean proportion of observed choices (Data: Solid line)
and mean predicted choice probabilities (Model: Dashed line) for
each option across conditions (C2, C4, C8, and C16). Lines are                              Table 3 shows the mean and median values of the model
smoothed by a moving window of 7 trials.                                                 parameters. We tested whether individual parameters differ
                                                                                         across conditions. Three non-parametric between-subjects
                                                                                         ANOVAs (Kruskall-Wallis test), one for each parameter, re-
Model Parameters                                                                         vealed significant effects of condition in α, K(3) = 14.84, p =
According to the diversity hypothesis, people manifest a                                 .002, and A parameters, K(3) = 18.96, p < .001, whereas
quasi-normative approach to choice allocation in experience-                             there were no differences in c parameter, K(3) = 4.95, p =
based decision-making by choosing options proportional to                                .18. Pairwise comparisons (Mann-Whitney tests; p values ad-
their EV. In other words, they do not maximize their overall                             justed for multiple comparisons using the Holm-Bonferroni
winnings by consistently selecting the most profitable option,                           method) showed that differences across conditions found in
but they prefer to distribute their choices by rank ordering the                         parameters α and A are mainly because of condition C2 being
                                                                                      1180

significantly different from the remaining conditions. No dif-         The relative strength of the maximizing option is higher in the
ferences were observed between the remaining comparisons               C2 condition which would explain the maximization rate of
(conditions C4, C8, and C16).                                          70%.
Table 3: Mean (M) and median (Md) values of model parameters                                     Discussion
across conditions.
                                                                       The main objective of the current work was to investigate
                                  Parameters                           choice preferences and strategies in a setting where the struc-
    Condition           α              A                c              tural complexity of a typical DFF paradigm was manipulated
                                                                       across experimental conditions. Examination of participants’
                     M     Md       M      Md        M     Md          decisions revealed two main theoretical and practical implica-
    C2             0.87   0.99    0.30    0.13    1.17    0.57         tions for theories of experience-based decision-making. First,
    C4             0.68   0.99    0.12    0.05    1.30    0.77         behavioral results suggest that participants showed a tendency
    C8             0.70   0.99    0.12    0.05    1.31    0.73         to distribute and diversify choices, despite the fact that they
                                                                       would move away from the optimal EV maximization option:
    C16            0.72   0.99    0.13    0.07    1.21    0.67
                                                                       choice proportions follow the rank ordering of options based
                                                                       on their EV, in a way that the option with the highest EV is
   The main question from the previous analysis relates to the         selected more often, followed by the option with the second
difference found between condition C2 and the rest of the              highest EV, and so on. In other words, people do not solely
conditions. Participants exhibit similar patterns of behaviour         select the maximizing option, but they spread their choices
across conditions, which is consistent with the diversity hy-          even after prolonged exposure to the task.
pothesis (see Figure 3). However, computational modelling                 The previous finding bolsters recent observations in
analysis showed that condition C2 is different with partici-           decisions-from-experience literature which have shown that
pants showing higher updating rates (parameter A) compared             people’s choice strategies in multi-armed bandit tasks may
to the other conditions. In other words, participants in C2            be best described by a probability matching heuristic.
condition rely more on newly received payoffs and thus show,           Speekenbrink and Konstantinidis (in press) found that a
on average, stronger recency effects and rapid forgetting of           computational model that utilises probability matching (by
the previously formed expectancies compared to participants            a means of a sampling-choice procedure which is called
in the remaining conditions. In addition, conditions differ in         Thompson sampling; see May et al., 2012) provides the best
parameter α but a closer look at the median value indicates            account of participants’ behavior in a dynamic (restless) DFF
that this may be due to some extreme cases.                            paradigm. Probability matching can be seen as a different
   While the interpretation may seem reasonable when look-             manifestation of the EV matching heuristic observed in our
ing at the parameter values, this may not represent the way            study.
people behave in different levels of structural complexity.               The second implication comes from computational model-
Figure 2 suggests that differences in parameter A between              ing analysis. One would assume that people employ different
conditions is the result of a different pattern of behavior in         strategies to cope with the increased uncertainty in the envi-
the first 50 trials. Specifically, participants in condition C2        ronment as they have to track the value of multiple options
learn to pick the maximizing option faster than participants           in order to make advantageous decisions. Figure 1 suggests
in other conditions: The choice curves are steeper (i.e., dif-         that participants’ maximization rates (red bar) are different
ferent slopes) in the first 50 trials in the C2 condition, in-         across conditions. This fact alone would indicate that deci-
dicating that participants discover the best option easier and         sion strategies are different, inconsistent with our EV match-
faster. The 0.30 value of A represents the average updating            ing hypothesis. However, inspection of model parameters
rate across 200 trials, including the first 50 trials. Hence, this     across conditions suggests that the underlying psychological
value does not necessarily mean that participants in the C2            processes responsible for observed behaviour are essentially
condition update more, with their choices being based more             identical across different levels of structural complexity. Dif-
on recent payoffs than in other conditions. As Figure 2 shows,         ferences in maximization rates cannot be attributed to differ-
participants’ choice behavior stabilizes after the initial explo-      ences in the underlying cognitive mechanisms responsible for
ration phase and they do not update the expectancies of the            participants’ choices. On the contrary, the underlying minds
options.                                                               are seemingly identical, following an EV matching strategy.
   Another important consideration is the fact that expectan-             A potential limitation of the computational modeling anal-
cies initiate with a value of 0. Before any feedback is re-            ysis is that the parameter estimates across conditions come
ceived, the model assumes that there is no prior informa-              from different participants and, thus, do not represent stable
tion (negative or positive) regarding the task. The latter indi-       latent psychological processes, but rather individual differ-
cates that, assuming constant sensitivity (c) across conditions,       ences and variation (or lack thereof) not attributable to the
higher updating rate in the first 50 trials would explain the al-      experimental design. Future research can overcome this lim-
most abrupt switch to the maximizing option in condition C2.           itation by employing within-subjects designs or by using a
                                                                   1181

Hierarchical Bayesian Estimation (HBE; Steingroever, Wet-            Ayal, S., & Zakay, D. (2009). The perceived diversity heuris-
zels, & Wagenmakers, 2014). HBE allows for individual dif-             tic: The case of pseudodiversity. Journal of Personality and
ferences in parameter estimates, which come from a group               Social Psychology, 96, 559–573.
or population level distribution, and are more reliable (uncer-      Barron, G., & Erev, I. (2003). Small feedback-based deci-
tainty in parameter estimates is also taken into account). Test-       sions and their limited correspondence to description-based
ing our hypothesis using HBE would require model fitting               decisions. Journal of Behavioral Decision Making, 16,
to be conducted twice: first, by pooling all subjects from all         215–233.
experimental conditions together and thus assuming identi-           Biele, G., Erev, I., & Ert, E. (2009). Learning, risk atti-
cal group-level distributions for each parameter and secondly,         tude and hot stoves in restless bandit problems. Journal of
assuming separate posterior parameter distributions for each           Mathematical Psychology, 53, 155–167.
condition. Comparison of the two fittings (i.e., posterior dis-      Busemeyer, J. R., & Stout, J. C. (2002). A contribution of
tributions of parameters estimates) could potentially provide          cognitive decision models to clinical assessment: Decom-
a more definitive answer as to whether the underlying psy-             posing performance on the Bechara gambling task. Psy-
chological mechanisms are similar across conditions.                   chological Assessment, 14, 253–262.
   In addition, the RL model we used was compared against            Daw, N. D., O’Doherty, J. P., Dayan, P., Seymour, B., &
two rather “weak” and cognitive-free statistical models. This          Dolan, R. J. (2006). Cortical substrates for exploratory
suggests that other cognitive models may be more appropri-             decisions in humans. Nature, 441, 876–879.
ate to account for the observed behavioral patterns and could        Gonzalez, C., & Dutt, V. (2011). Instance-based learning: In-
provide deeper insights into the processes that govern choice          tegrating sampling and repeated decisions from experience.
allocation. Future research can test alternative models and as-        Psychological Review, 118, 523–551.
sumptions regarding learning (e.g., decay and instance-based         Hertwig, R., Barron, G., Weber, E. U., & Erev, I. (2004).
learning rules) and choice (e.g., different choice rules such as       Decisions from experience and the effect of rare events in
greedy, ε-greedy, and softmax with exploration bonus).                 risky choice. Psychological Science, 15, 534–539.
   Overall, the present work sought to answer whether an             Hills, T. T., Noguchi, T., & Gibbert, M. (2013). Information
observed tendency to spread choices and favor diversity in             overload or search-amplified risk? Set size and order ef-
decisions-from-experience is characterized by similar cogni-           fects on decisions from experience. Psychonomic Bulletin
tive mechanisms across different levels of structural complex-         & Review, 20, 1023–1031.
ity. Future research should delve into the mechanisms and            Jessup, R. K., Bishara, A. J., & Busemeyer, J. R. (2008).
identify determinants of this preference for choice allocation         Feedback produces divergence from prospect theory in de-
as it may be more pronounced than previously believed.                 scriptive choice. Psychological Science, 19, 1015–1022.
                                                                     Kahneman, D., & Tversky, A. (1979). Prospect theory: An
                    Acknowledgments                                    analysis of decision under risk. Econometrica, 47, 263–
                                                                       291.
This work was supported by the Army Research Labora-
                                                                     May, B. C., Korda, N., Lee, A., & Leslie, D. S. (2012).
tory under Cooperative Agreement, Number: W911NF-13-
                                                                       Optimistic Bayesian sampling in contextual-bandit prob-
2-0045 (ARL Cyber Security CRA) and the National Science
                                                                       lems. The Journal of Machine Learning Research, 13,
Foundation Award, Number: 1154012. The views and con-
                                                                       2069–2106.
clusions contained in this document are those of the authors
                                                                     Schulz, E., Konstantinidis, E., & Speekenbrink, M. (2015).
and should not be interpreted as representing the official poli-
                                                                       Exploration-exploitation in a contextual multi-armed ban-
cies, either expressed or implied, of the Army Research Lab-
                                                                       dit task. Manuscript in preparation.
oratory or the U.S. Government. The U.S. Government is au-
                                                                     Shanks, D. R., Tunney, R., & McCarthy, J. (2002). A re-
thorized to reproduce and distribute reprints for Government
                                                                       examination of probability matching and rational choice.
purposes notwithstanding any copyright notation here on.
                                                                       Journal of Behavioral Decision Making, 15, 233–250.
                                                                     Speekenbrink, M., & Konstantinidis, E. (in press). Uncer-
                         References
                                                                       tainty and exploration in a restless bandit problem. Topics
Ahn, W.-Y., Busemeyer, J. R., Wagenmakers, E.-J., & Stout,             in Cognitive Science.
   J. C. (2008). Comparison of decision learning models using        Steingroever, H., Wetzels, R., & Wagenmakers, E.-J. (2014).
   the generalization criterion method. Cognitive Science, 32,         Absolute performance of reinforcement-learning models
   1376–1402.                                                          for the Iowa gambling task. Decision, 1, 161–183.
Ashby, N. J. S., Konstantinidis, E., & Gonzalez, C. (2015).          Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning:
   Too many baskets: A misguided preference for diversity in           An introduction. Cambridge, MA: The MIT Press.
   decisions-from-experience. Manuscript in preparation.             Yechiam, E., & Ert, E. (2007). Evaluating the reliance on
Ashby, N. J. S., & Rakow, T. (in press). Eyes on the prize?            past choices in adaptive learning models. Journal of Math-
   Evidence of diminishing attention to experienced and fore-          ematical Psychology, 51, 75–84.
   gone outcomes in repeated experiential choice. Journal of
   Behavioral Decision Making.
                                                                 1182

