           Reconstructing the Bayesian Adaptive Toolbox: Challenges of a dynamic
                               environment and partial information acquisition
                                              Percy K. Mistry (pkmistry@uci.edu)
                                           Jennifer S. Trueblood (jstruebl@uci.edu)
                  Department of Cognitive Sciences, University of California Irvine, Irvine, CA 92697-5100 USA
                             Abstract                                 forced choice paradigm where the environmental conditions
   We show how dynamic (changing) environments can affect
                                                                      can change over the course of trials, and where it is possible
   choice behavior, and highlight the challenges that recent          for participants to acquire only a partial subset of the cue
   models face in explaining the learning and selection of            information available.
   heuristic strategies under such conditions, especially when
   decisions are made using only a small subset of the available                              Experiment
   information. We propose an enhanced modeling framework
   that includes a trial-by-trial implementation of a Bayesian        We use a MCPL paradigm where participants had to make
   adaptive toolbox, redefinition of heuristic strategies, and        repeated forced choices between one of three options on the
   incorporation of intricate learning rate mechanisms into a         basis of a set of underlying cues. This paradigm was similar
   strategy learning model. We use data from a new empirical          to that used by Bröder & Schiffer (2006) with changes in the
   study to show how this improves the quality of inference.          conditions and relationships between cues and options.
   Keywords: Learning; Bayesian graphical models; strategy
   selection; heuristics; adaptive toolbox; Bayesian inference;       Methods
   dynamic environments; reinforcement learning
                                                                      34 University of California, Irvine undergraduates
                                                                      participated in the experiment for course credit. The cover
                          Introduction                                story for the choice task was a hypothetical stock market
We investigate the strategy selection problem in multiple             game, in which participants had to choose between three
cue probability learning (MCPL) tasks by applying                     financial stock options, based on four possible binary cue
Bayesian inferential approaches to the question of how                attributes that included past profit growth, sales growth, and
strategy selection and learning can be investigated.                  recommendations from two independent advisors. The cue
Scheibehenne, Rieskamp, & Wagenmakers (2013)                          values were instantiated as High / Low for the two financial
introduced a Bayesian adaptive toolbox where the                      indicators, and as Buy / Sell for the two advisory cues.
probability of using each strategy is inferred across all trials      Participants could acquire any of the twelve (four attributes
rather than on a trial-by-trial basis.                                x three options) cue values in any order, at a cost of 5% of
   We implement a similar toolbox approach on a trial-by-             the total gross reward obtained for that trial, for each cue
trial basis, and augment this with a hierarchical learning            acquired. Once a participant selected a cue attribute, it
mechanism (strategy selection and learning (SSL),                     remained visible throughout the trial. Each participant made
Rieskamp & Otto, 2006) that governs the shift in use of               choices for 120 trials split into four blocks of 30 trials each.
strategies over trials. This allows us to capture adaptive            Each block was associated with either a compensatory (C-
behavior under dynamic environmental conditions where                 Block) or non-compensatory (N-Block) environment, which
people demonstrate substantial learning effects. Next, we             differed in the relationship between the cue values (c1 to c4,
show how the standard definition of heuristic strategies is           encoded as +1 or -1) and the associated reward outcomes
ineffective in accounting for behavior in the unique class of         (R), such that gross rewards ranged from –150 to +150:
experimental paradigms we have selected. To tackle this, we           R(C) = 40c1 + 37c2 + 34c3 + 31c4 + noise(-8, 8)
propose that such standard heuristic strategies be redefined          R(N) = 78c1 + 7c2 - 21c3 - 36c4 + noise(-8, 8)
at the level of their elementary building blocks (Gigerenzer             The objective of the task was to maximize the rewards
and Gaissmaier, 2011) and incorporate Bayesian inference              remaining after any cue acquisition related costs. In our
based belief updating1 into the learning mechanism. Finally,          task, a take-the-best (TTB) strategy always provided a
we adapt the SSL model to incorporate more elaborate                  higher net payoff in N-blocks and a weighted average
learning rate mechanisms such as variable learning rates,             (WADD) strategy in C-blocks. The actual cue weights,
item-specific learning, random-effects, volatility dependent          order of importance or validity of the weights, or the type of
learning, and counterfactual learning.                                environment for each block was not known to the
   We first describe a new empirical study that we use to             participants (this was to be learned as part of the decision
subsequently show how our model can provide greater                   process), but they were told that the underlying environment
insight into adaptive behavior. Our study focuses on a                and relationships between cues and options could change
                                                                      between blocks, but remained constant within a block. The
   1                                                                  start and end of each block was clearly indicated. The cue
     The learning mechanism is not changed to Bayesian learning,
just the process by which the modeler determines what strategy is
                                                                      weights included negative values (this design was
to be reinforced is mechanized as a Bayesian inference process        implemented to nudge participants towards a more
                                                                  1595

deliberative cognitive effort as opposed to focusing on the             starting C have a coefficient of +0.03, and -0.03 when
salience of the positive valued cues), and while the cue                interacting with starting N; alternative routines are exactly
weights and order were not disclosed, participants were told            the other way around. Starting conditions alone have a
that it was possible for cues to be negatively related to the           coefficient of +0.03 (C) and -0.03 (N), reflecting initial bias.
options (brief examples of how this could be justified within
the paradigm were included). After each trial, feedback was                   Table 1: Pairwise Bayesian t-test between conditions
provided on the reward associated with all the three options.
   The block size was designed to be small (30 trials each) to                                    Performance         Cue Acquisition
                                                                              Difference
manipulate the possible effects of routinization of decision                                    Log(BF) Delta        Log(BF) Delta
strategies (see Bröder & Schiffer, 2006; Bröder et al, 2013).            CNCN vs CCNN             15.8      -0.26      10.6      -0.22
The experiment consisted of a factorial design with four                 CNCN vs NCNC               -3       na          2.8     -0.15
conditions (2 conditions starting either with a C-Block or N-            CNCN vs NNCC              3.2      0.16       13.8      -0.26
Block x 2 conditions where the routine was manipulated by                CCNN vs NCNC             15.3      0.27        -2.2       na
either alternating or placing similar blocks consecutively).             CCNN vs NNCC             43.8      0.43        -2.7       na
Thus, the four blocks under the four conditions could be                 NCNC vs NNCC              2.2      0.15        -1.1       na
represented as CNCN, CCNN, NCNC and NNCC. We
wanted to measure the interaction between routine length                   Table 2: Bayesian ANOVA test for factors contributing to
and starting conditions, manifested as the extent of                                  the standardized performance score
maladaptive routinization, initial bias and response to
different levels of volatility that the changing environment                    Model vs Baseline (Intercept only)          Log(BF)
represented, assess the potential inadequacies of existing                   Routine (Consecutive vs Alternate)                 -2.1
models to explain underlying behavior, and demonstrate                       Routine + Routine:Starting4                        15.1
how these models could be suitably improved.                                 Routine + Starting                                 16.2
                                                                             Routine:Starting4                                  17.4
Results                                                                      Starting Condition (N vs C)                        18.2
Table 1 shows the result of Bayesian t-tests2 for pairwise                   Routine + Starting + Routine:Starting4             33.5
differences in the number of cues acquired, and the                          Starting + Routine:Starting4                       36.1
performance (standardized reward scores3), between
conditions. This shows a hierarchy of performance levels,                  We also test for differences within and between block
with significant evidence for higher performance in the                 types (see Table 3). There is strong evidence for within
CCNN condition, no significant difference between the two               block improvement in performance between the first (HB1)
alternating conditions (CNCN and NCNC) as the t-test                    and second (HB2) half of each block. This is true for both
comparing these yields a BF in favor of the null, and                   environmental conditions, but the effect size and
reasonably strong evidence for a lower performance in the               significance is much higher in N-blocks vs C-blocks.
NNCC condition. The mean performance score reflects this
trend (CCNN 0.86, CNCN & NCNC 0.78 and NNCC 0.73).                             Table 3: Bayesian t-test (within & between blocks)
   A Bayesian ANOVA test (Table 2) reveals that the
routine type alone (consecutive vs alternating blocks) is not                                     Performance         Cue Acquisition
                                                                              Difference
a significant factor, and the best model that explains the                                      Log(BF) delta        Log(BF) Delta
variance is based on the starting condition (C vs N) and a               HB2 vs HB1 (C)             39      0.15         3.2     -0.11
strong interaction between the starting condition and the                HB2 vs HB1 (N)            193      0.32       74.6      -0.41
routine type. Analyzing the coefficients for the factors under           C vs N (overall)         -1.2       na        51.1       0.23
this model reveal an interesting relationship where the                  C vs N (HB1)              2.2      0.10         1.3      0.09
routine types have an asymmetric impact depending on the                 C vs N (HB2)             -3.2       na        72.0       0.39
starting condition. Consecutive routines interacting with                C2 vs C1 (all)            9.1      0.16       0.16      -0.08
                                                                         N2 vs N1 (all)             57      0.35       44.3      -0.31
   2
     Results are summarized as the log(Bayes factor) in favor of a
difference vs the null (zero difference), based on a JZS t-test, and       The overall performance of N-blocks and C-blocks
the standardized mean difference (Delta) which shows the effect         however is not different (significance test yields a BF in
size. A log(BF) with absolute value < 1 can be considered               favor of the null; overall accuracy for C is 82.3% and for N
inconclusive. Log(BF) > 1 indicates evidence in favor of the            is 82.9% and standardized performance score for C is 0.80
difference, and log(BF) < -1 in favor of the null. Larger log(BF)       and N is 0.78). Rather, a half-block comparison between C
values imply greater evidence of a difference. Very large               and N blocks shows that first half performance in C-blocks
differences are highlighted in bold.                                    is marginally better than in N-blocks (log(BF)=2.2 in favor
   3
     We measured effective performance by normalizing rewards
                                                                           4
from 0 to 1 based on the maximum and minimum possible gross                  ‘Routine:Starting’ indicates the interaction effect between
rewards on each trial.                                                  routine and starting conditions
                                                                    1596

of a difference). This leads to the conclusion that                   where I(si,t) is an indicator function based on response
performance starts at a lower level in N-blocks, perhaps              matching or response matching and minimum cue
reflecting an initial bias, but seems adaptive enough to reach        acquisition, that indicates whether a strategy was used on a
overall C-block levels. This adaptivity is also reflected in          particular trial. The initial q-values depend on an initial
the cue acquisition levels, (average cue acquisition is C             association parameter (K), initial strategy preference (β) and
33%, N 28%), where a t-test is not really conclusive for the          the maximum possible reward on any trial (Q(si,1) = βi * K
first half of C and N blocks, but shows a very significant            * Rmax). We propose modifying the q-value calculation for
(log(BF) = 72) and strong effect size for higher cue                  each strategy to Q(si,t) = Q(si,t-1) + p(si,t|co,u) * r(c,t-1),
acquisition levels in the second half for C-blocks vs N-              where we define p(si,t|co,u) as the Bayesian posterior
blocks, a significant (log(BF) = 74.6) and strong reduction           probability of the participant having utilized a specific
in cue acquisition between the first and second half within           strategy (si) on trial (t), based on the observed choice (co)
N-blocks, and a significant increase in performance between           and the pattern of cues acquired (u):
the first and second encountered blocks of the same type,             p(si,t|co,u) = p(co,t|u,si) p(u,t|si) p(si,t)
with a stronger effect for N-blocks. Our modeling efforts                                  p(co,t|u) p (u,t)
attempt to capture this behavior via inference on the                    Here, p(si,t) is the prior probability of utilizing a strategy
underlying latent heuristic strategies utilized by participants,      (si) on trial (t) as predicted by the cognitive model. The
how these strategies change with changing environmental               remaining probabilities, p(u,t|si), the probability of acquiring
types, and the differences between conditions.                        the specific cue pattern given the application of a specific
                                                                      strategy, and p(co,t|u,si), the probability of making a specific
     Modeling Challenges and Enhancements                             choice given the particular strategy being used and the cue
                                                                      pattern acquired, need to be specified. We propose that these
                                                                      probabilities be defined as the information search and
What to reinforce? A Bayesian solution
                                                                      decision rule building blocks of the heuristic strategy.
Most learning algorithms update beliefs about a set of items
under consideration. If the locus of learning is a choice             Redefining heuristic strategies
option, learning can be explicitly modeled since the selected
choice option is always known. When the locus of learning             Similar to traditionally defined strategies (TS), p(co|u,s) is
is a latent process (in our case, a heuristic or strategy that        simply a decision rule that combines all the cue information
cannot be directly observed), the modeling process needs to           in exactly the same way, but taking into account only the
infer which latent item was utilized and hence needs to be            cue values that have actually been acquired on each trial. If
reinforced or updated by the learning algorithm on each               the decision rule applied to the partially observed cues can
trial. Existing approaches to identify such latent strategies         discriminate between all options, this probability is either 0
include response matching (strategy prediction matches the            or 1 for each option (c), otherwise it is distributed across the
actual response observed; see Rieskamp, 2008) or an                   non-discriminable options. We call these strategies
additional criterion of minimum cue acquisition (minimum              observed-cue strategies (OS), to differentiate the level at
cues required to implement the strategy have to be acquired;          which the decision rule is applied. On the other hand,
see Rieskamp & Otto, 2006).                                           defining p(u|s) at the level of a heuristic strategy is quite
   In paradigms, like ours, which allow partial information           different from the traditional cue search rules. We propose
utilization and where the cue acquisition density is very low,        that the cognitive act of cue acquisition can be envisaged as
response matching alone is unrealistic, since the number of           a sampling process, and the heuristic defines the probability
cues acquired are rarely adequate (e.g. in our study, average         distribution of cue acquisition patterns from which the
cue acquisition levels were 31%, with over 50% of cues                individual is sampling. To implement this, we categorize
being acquired on only about 12% of the trials) to                    each possible pattern into one of a number of ordered subset
implement standard heuristic strategies (e.g. TTB, WADD,              categories on the basis of identified classifiers. The extreme
tallying, and so on). Including a criterion for minimum cue           categories define a pair of complementary approaches to cue
acquisition makes most of the updates ineffective, since              acquisition, and the ordered categories are defined to
none of the strategies would be updated on a large number             represent a log-odds ratio between the two complementary
of trials (e.g. in our study, updates on 90% of the trials            approaches (i.e. extreme categories include cue acquisition
become ineffective since they do not meet the cue                     patterns that have extreme log-odds ratios and those in the
acquisition criteria for any commonly defined strategy). To           middle reflect patterns that are equally likely under the two
counter these issues we propose a possible solution,                  acquisition approaches). The log-odds for each ordered
partially redefining what is considered a ‘strategy’, as part         category are derived from the classifiers by calculating an
of an adaptive toolbox of strategies. The existing SSL model          index score for each category. For our study, we categorized
calculates the probability of using each strategy (si) on each        all possible (4096) cue acquisition patterns by using a
trial (t) based on the underlying value assigned to each              simple classification scheme with three classifiers: (1) the
strategy, called q-values (p(si,t) = Q(si,t) / Σj Q(sj,t)). The q-    number of unique cue attributes where at least one cue value
values are updated based on the observed choice (co) and              was selected (higher value indicates a compensatory
associated reward (Q(si,t) = Q(si,t-1) + I(si,t-1)*r(co,t-1)),        approach), (2) the cue acquisition density within this subset
                                                                  1597

of attributes (lower indicated a greater propensity to                 propose that the conflict between probabilities of using
compare cues across attributes, thus compatible with a                 different strategies generated by the cognitive model can be
compensatory approach), and (3) an assumption of                       interpreted as a possible proxy measure of the volatility. We
sensitivity to costs (this redistributed the probabilities for         implement a version of the model that modulates the
each approach towards patterns with lower cue acquisition              learning rate on a trial-by-trial basis based on a moving
density). Using these classifiers we could obtain a formulaic          average of recent entropy. Higher entropy reflects greater
characterization of different cue acquisition patterns                 uncertainty in the environment and hence increases learning
yielding a score of 0 to 1 for each5, which was then scaled to         rates. Entropy (for ‘n’ strategies in a toolbox) is calculated
reflect the log-odds, and transformed to a probability using           based on the strategy probabilities generated by the model:
the inverse logit function. We could thus define a pair of             Entropy(t,n)= - (1/loge n)*Σi=1:n{p(si,t)*loge(p(si,t)}
heuristic approaches (approximated as compensatory and
non-compensatory) with complementary probability                       Random effects (SSL-R): Since learning rate may be
distributions over all possible cue patterns, defining two sets        subject to individual (participant) effects, item effects
of ‘p(u|s)’. While further details of this mechanism are               (individual strategies, type of environment – compensatory
beyond the scope of this paper, we highlight that the                  or non-compensatory) as well as the experimental
classifiers used were not exhaustive, but an illustrative              conditions, we propose a model where these 4 main effects
instantiation of a working model for our toolbox.                      are broken down as random effects and combine additively
                                                                       on a probit scale (see Rouder & Lu, 2005 for Bayesian
Modeling Learning Rates                                                modeling of crossed random effects). We develop a version
Previous implementations of SSL usually assume a constant              of our model assuming independent random effects, and
learning rate across all trials, often parameterized as an             each of these (L_ind, L_strat, L_env, L_cond) are modeled
initial association level (but see Gluth, Rieskamp, & Buchel,          hierarchically with a scaled normal prior and a
2014 for a fixed learning rate implementation). However,               hyperparameter for the effect standard deviation. The
learning rates might be influence by a number of different             posterior distribution of the standard deviation indicates the
factors. Thus, we explore four different learning rate                 level of heterogeneity arising from each effect.
mechanisms: (1) variable, (2) entropy-based learning rates,            L_probit = L_mean + L_ind + L_strat + L_env + L_cond
(3) random effects, and (4) counterfactual learning.                   Lr(si,b) = Scaling Factor * Φ (L_probit)
Variable Learning Rates (SSL-V): Studies have shown                    Counterfactual Learning (SSL-C): Counterfactual
that flexible and variable learning rates within RL based              learning of choice options is commonly studied, however
mechanisms can improve predictions and also produce                    incorporating it into a task paradigm with low cue
results comparable to Bayesian learning (Payzan-                       acquisition density and a latent locus of learning can get
LeNestoury & Bossaertsz, 2014; Speekenbrink, &                         tricky, as counterfactual implications of traditionally defined
Konstantinidis, 2014). We re-parameterize the SSL model                compensatory strategies when actual behavior is non-
to include a flexible learning rate that can depend on the             compensatory cannot be easily evaluated. We can however
environmental condition (i.e. change between experimental              implement counterfactual learning successfully using our
blocks) and can also be strategy-dependent. The latter                 approach to defining heuristics based on observed cues, as
formulation can be interpreted as responses to different               below, where Iij is an indicator function that reflects whether
levels of ‘surprise’ to the same reward outcome that                   a particular strategy predicts choice ‘cj’, given the observed
different strategies generate. The learning rate for each              cues, and CF is a free parameter [0, 1] indicating the relative
block type (b) and strategy (si), L(si,b), is modeled using a          strength of counterfactual learning.
hierarchical prior, and the initial association parameter (K)          Q(si,t) = Q(si,t-1) + Σj { Iij * r(cj,t-1) * L(si) *
is no longer required. The revised q-value calculation is                                           [p(si,t|cj,u)+(1-p(si,t|cj,u))* CF] }
Q(si,t) = Q(si,t-1) + p(si,t|co,u) * r(co,t-1) * L(si,b).
                                                                       Bayesian inference framework
Entropy-based Learning Rates (SSL-E): Allowing the
learning rate to vary between blocks and strategies still              The learning model is implemented in a Bayesian inference
enforces a fixed learning rate within blocks. Assessment of            framework that allows hierarchical estimation of the
environmental volatility and detection of environmental                parameters. The calculated strategy probabilities are
changes have been implicated in the modulation of learning             converted to choice probabilities for each choice option ‘j’,
rates (Pearson & Platt 2013; Behrens et al, 2007). We                  and include an application error rate (AER), ϵi, defined
                                                                       independently for each strategy ‘i’.
   5                                                                   p(cj) = Σi { p(cj|si)(1- ϵi) + (1-p(cj|si)) ϵi / (N -1) }
     For instance, selecting all 3 cue values corresponding to the
three options from a single attribute, representing a non-                Here, N is the number of different choice options. The
compensatory approach, resulted in a raw score of 0.08, whereas        AER captures variability in the decision rule but cannot
selecting 3 cue values, each from a unique attribute-option pair,      account for variability in the cue acquisition process. To
thus representing a compensatory approach, resulted in a raw score     ensure that the sum of posterior probabilities inferred in the
of 0.75.
                                                                   1598

Bayesian inference for belief updating sum to one over all           acquisition was unable to account for any of the standard
strategies, we propose the inclusion of a guessing strategy,         strategies on most trials, and 90% of the updates were
which defines an equal probability distribution over all             ineffective. This is reflected in the lack of coherence
choices and cue acquisition patterns, and is reinforced with         between the high probability (> 80%) of CS predicted by
a probability 1 –Σi p(si,t|co,u). This allows the model to           this model and CS being updated by the learning model for
capture variability in cue acquisition behavior that cannot be       only 0.5% of the trials. Differences between conditions are
reasonably explained by any of the strategies.                       explained via minor differences in the probability of
                                                                     guessing, with no insight into differences between blocks.
                       Modeling Results                                 Next, we assessed the static toolbox without learning
Table 4 summarizes the comparative performance of models             using the observed-cue decision rules (OS) and found that
including a static toolbox and an unchanged SSL model                this outperformed the previous models considered in terms
based on traditional strategies (TS), response matching and          of accuracy and DIC. This also provided more realistic
minimum cue acquisition (CA), and our proposed model                 application error (AER) rates (NS dropped from 28% to
based on observed strategies (OS), Bayesian updating (BU)            10%, CS fell from 9% to 0.5%), and a more balanced view
and four models with alternate learning rate structures (SSL-        of the average strategy usage (55% CS, 35% NS). It also
V, SSL-E, SSL-R, SSL-C). All models were built including             infers that condition NNCC has the lowest usage of CS
a compensatory (CS), non-compensatory (NS) and guessing              (possibly implying some form of routinization) and the
strategy. We use the human data from the described                   highest guessing rate (22%), with the CCNN and NCNC
experiment to generate a posterior distribution of the               both having similar high rates of CS and lowest rate of
parameter values and a posterior predictive distribution of          guessing (2-3%), and CNCN lying in between these.
the data. The posterior predictive distribution reveals the             Implementing our revised learning model (SSL-V)
distribution over all possible data points that the model            provided inference on average strategy usage similar to the
predicts based on the inferred posterior distribution of the         static mode, but improved accuracy and DIC even further.
parameters after having seen the data. All of the following          Inferences from the entropy (SSL-E), counterfactual (SSL-
analysis is thus based on Bayesian inference on the observed         C), and measurement of individual differences and random
human data using the above described cognitive models.               effects (SSL-R) models provided similar estimates, although
Our framework (OS / BU / modified learning rates) provide            only SSL-C model improved fit compared to the SSL-V
higher accuracy (Acc) of the posterior predictive (thus, the         model. In all of these models, the ineffective updates
best account of the observed human data), improved (lower)           reduced from 90% to only about 15%, which contributes
deviance information criteria (DIC), and better qualitative          significantly to the improved performance of the models.
insights compared to existing approaches (Static / TS / CA)          The updates for individual (NS and CS) strategies are now
as we demonstrate in the subsequent commentary.                      also coherent, being in the range of the strategy use
                                                                     predicted by the model (unlike the CA implementation).
                    Table 4: Model Comparison                           Most importantly, these models now provided a dynamic
                                                                     account of how strategy use shifted on a trial-to-trial basis,
                                                                     within and between blocks, and between conditions. All the
               Strategy                     Insight Insight
 Learning                                                            OS-based SSL adaptations provide a similar insight into the
                type /      Acc      DIC      b/w        b/w
    Rate                                                             dynamics of strategy use across blocks. Figure 1 shows the
               Update                        conds blocks
                                                                     strategy usage inferred on a trial-by-trial level from one of
 Static      TS      -      72%     4379    Limited       No
                                                                     these models. In the CNCN condition, usage of CS strategy
 SSL         TS      CA     72%     4413    Limited       No
                                                                     is well-tuned to the advent of C-blocks, but there is a
 Static      OS -           77%     3277    Limited       No
                                                                     considerable amount of guessing in the N-blocks. While the
 SSL-V       OS BU          80%     2786      Yes        Yes
                                                                     participants seem to be picking up on the differences in the
 SSL-E       OS BU          80%     2950      Yes        Yes
                                                                     alternating blocks, finding the right NS seems to be harder.
 SSL-R6      OS BU          80%     2915      Yes        Yes
                                                                        In the CCNN condition, participants seem to recognize
 SSL-C       OS BU          82%     2745      Yes        Yes
                                                                     the change in the first N block which is quite volatile in
                                                                     terms of use of strategies, but interestingly, they revert back
   The static (no learning) toolbox model using traditional          to the previously routinized CS strategy within this block
strategies (TS) predicted an 85% use of CS and practically           itself, and implement it even more strongly in the last N-
no usage of NS. Incorporating an SSL mechanism using                 block. Once again, this shows change detection at the advent
response matching and minimum cue acquisition (CA)                   of the N-block, and a similar difficulty in finding the right
worsened the DIC even further, primarily because cue                 NS. But it seems that the higher routinization of CS makes
                                                                     participants revert back to CS rather than adopt a guessing
   6
     Bayesian inference was carried out using MCMC sampling.         strategy, which is rarely used in this condition, hence
MCMC chain convergence was good (R<1.1) across parameters            leading to the best overall performance. In the contrasting
for all models considered, except SSL-R, where a few individual      NNCC condition, participants again start with an initial
parameters showed poor convergence (R>1.1). We restrict analysis     preference for CS, but this not seem to be strongly
primarily to the models where convergence was not an issue.
                                                                 1599

reinforced and is replaced with a higher usage of a guessing        strategy type effects. This ties in nicely with the empirical
strategy, until the advent of the first C-block. In the NCNC        observations on differences in adaptivity within N-blocks
condition however, participants do not revert to guessing in        being higher than for C-blocks. It also explains the higher
the first block and their use of a CS strategy is positively        volatility of probabilities of strategies within N-blocks.
reinforced, resulting a stable preference across blocks.
Comparing performance in N1 between NNCC and NCNC                                            Conclusion
conditions reveals that the better reinforcement of CS in           We implemented an experimental design to identify
NCNC is a result of the cue patterns selected, resulting in         behavioral patterns in a paradigm where the environmental
the best option being selected 80% of the time, vs 65% in           conditions change and the information costs push
NNCC. Relating this to our redefined strategies, future             participants towards partial information acquisition. We
analysis could consider comparing these conditions with             demonstrated how otherwise successful models may be
different distributions from which cue patterns are sampled.        rendered inadequate, and successfully built a computational
                                                                    framework to reconstruct a Bayesian adaptive toolbox,
                                                                    improving our ability to account for observed behavior.
                                                                                              References
                                                                    Behrens, T. E., Woolrich, M. W., Walton, M. E., &
                                                                       Rushworth, M. F. (2007). Learning the value of
                                                                       information in an uncertain world. Nature neuroscience,
                                                                       10(9), 1214-1221.
                                                                    Bröder, A., Glöckner, A., Betsch, T., Link, D., & Ettlin, F.
                                                                       (2013). Do people learn option or strategy routines in
                                                                       multi-attribute decisions? The answer depends on subtle
                                                                       factors. Acta psychologica, 143(2), 200-209.
                                                                    Bröder, A., & Schiffer, S. (2006). Adaptive flexibility and
     Figure 1: SSL-V model: Mean probabilities of strategy             maladaptive routines in selecting fast and frugal decision
 use across trials (B1 to B4 are four blocks of 30 trials each)        strategies. Journal of Experimental Psychology:
                                                                       Learning, Memory, and Cognition, 32(4), 904–918.
   Also interesting were the learning rates inferred by these       Gigerenzer, G., & Gaissmaier, W. (2011). Heuristic decision
models. The SSL in its original form was modeled using the             making. Annual review of psychology, 62, 451-482.
initial association parameter, which can be interpreted as the      Gluth, S., Rieskamp, J., & Buchel, C. (2014). Neural
inverse of the learning rate (but not exactly equivalent).             Evidence for Adaptive Strategy Selection in Value-Based
Implementing SSL using only response matching (RM)                     Decision-Making. Cerebral Cortex, 24(8), 2009–2021.
inferred a low initial association of 20 (previous studies          Payzan-LeNestour, E., & Bossaerts, P. (2014). Learning
have yielded best fit parameters in the range of 50-100),              about unstable, publicly unobservable payoffs. Review of
whereas a more realistic implementation incorporating                  Financial Studies, hhu069.
minimum cue acquisition as well inferred an extremely high          Pearson, J. M., & Platt, M. L. (2013). Change detection,
value of 1047, thus inferring almost no learning (since 90%            multiple controllers, and dynamic environments: Insights
of the trials were ineffective learning updates).                      from the brain. Journal of the Experimental Analysis of
Implementing our revised models using a re-parameterized               Behavior, 99(1), 74–84.
learning rate yielded an average learning rate of 1.3 (SSL-         Rieskamp, J., & Otto, P. E. (2006). SSL: a theory of how
V), 0.4 (SSL-C), 0.5 (SSL-E), and 2.1 (SSL-R). The                     people learn to select strategies. Journal of Experimental
counterfactual model (SSL-C) includes a larger breadth of              Psychology: General, 135(2), 207.
learning, and the entropy model (SSL-E) typically predicts          Rieskamp, J. (2008). The importance of learning when
frontloading of the learning rate, which gradually drops and           making inferences. Judgment and Decision Making, 3(3),
settles to lower levels as entropy is resolved. SSL-C also             261–277.
infers that the extent of counterfactual learning (inferred         Rouder, J. N., & Lu, J. (2005). An introduction to Bayesian
parameter CF) is lower in the NNCC (0.36) condition as                 hierarchical models with an application in the theory of
compared to the remaining conditions (average 0.49).                   signal detection. Psychonomic Bulletin & Review, 12(4),
   Interestingly, while the SSL-V model shows a higher                 573-604.
learning rate for CS as compared to NS, segregating these           Scheibehenne, B., Rieskamp, J., & Wagenmakers, E. J.
effects as random effects in the SSL-R model reveals a more            (2013). Testing adaptive toolbox models: A Bayesian
intricate pattern. It reveals that N-blocks and NS strategies          hierarchical approach. Psychological Review, 120(1), 39.
contribute to higher learning rate effects than C-blocks and        Speekenbrink, M., & Konstantinidis, E. (2014). Uncertainty
CS strategies respectively, and also that maximal                      and exploration in a restless bandit task. Cognitive
heterogeneity is observed in individual participant and                Science Society.
                                                                1600

