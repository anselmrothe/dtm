                                    The Antecedents of Moments of Learning
                                            Gregory R. Moore (grm13@my.fsu.edu)
                                             College of Education, Florida State University
                                           1114 W. Call Street, Tallahassee, FL 32306, USA
                                   Ryan S. Baker (baker2@exchange.tc.comlumbia.edu)
                                                Teachers College, Columbia University
                                            525 West 120th St., New York, NY 10027, USA
                                            Sujith M. Gowda (mgsujith@gmail.com)
                                                               Metacog, Inc.
                                              55 Linden St., Worcester, MA 01609, USA
                              Abstract                                 Weisbuch, Rutchick, Newman, & Ambady, 2010), and how
                                                                       increased cognitive load can disrupt insight (De Dreu,
  In this paper, we study the antecedents of moments of                Nijstad, Baas, Wolsink, & Roskes, 2012).
  particularly successful learning while students use a Cognitive         A criticism of this literature, however, is that insight
  Tutor for geometry. Students used the Cognitive Tutor as part        problems in laboratory settings may not be representative of
  of their regular classroom activities and data was collected         how “eureka moments” manifest in authentic learning
  automatically. Learning moments were operationalized as
  when the probability that the student just learned was
                                                                       situations (Bowden, Jung-Beeman, Fleck, & Kounios,
  extremely high, as determined by a probabilistic model: the          2005). The focus on laboratory research on insight problems
  moment-by-moment learning model. The results indicate that           allows for greater control and facilitates research, given that
  while self-explanation is weakly predictive of learning              eureka moments are relatively rare during real-world
  moments, contextual guessing and several other factors are           learning situations. However, if the properties of insight in
  even better predictors of learning moments. These results            authentic learning are different—if real-world insight
  suggest that unexpected events in student behavior may be            involves problems substantially different than “insight
  good predictors of changes in knowledge.                             problems”, and if problem-solving manifests differently in
                                                                       real-world contexts, where help and various types of
  Keywords: Moment-by-Moment Learning; Intelligent
  Tutoring System; Educational Data Mining; Robust Learning
                                                                       learning support are often available—then the findings of
                                                                       laboratory insight research may not translate to
In the process of learning a skill, a learner goes from not            understanding real-world insight during learning (Bowden
knowing the skill, and being unable to demonstrate it, to              et al., 2005).
knowing the skill in a fashion that allows them to                        Therefore, it is important for research to examine insight
demonstrate it. The development of a skill can occur in                in real-world environments. In this work, we begin to
several fashions; in particular, learning can occur rapidly or         address this need by attempting to examine insight in an
gradually over time. In some cases, learning takes the form            intelligent tutoring system—an authentic learning
of a sudden insight, or a "eureka" moment, where the                   environment. Insight is a difficult construct to measure. In
learner gains understanding of a concept in a brief moment.            this paper, we operationalize insight as the probability that
The question of how insight occurs during learning has been            the student just learned, according to a Bayesian Model that
an enduring question in Cognitive Science (as discussed in             detects sudden shifts from incorrect to correct performance.
Chu & MacGregor, 2011). There has been considerable                    This operationalization is open to question as a measure of
research on insight, across decades and in recent years.               insight, as it is less straightforward than traditional
Much of this research has involved insight problems, which             laboratory measures of insight. It may capture the
are designed to be solved in a moment of insight after                 culmination of a student’s thinking that leads to a qualitative
sustained effort (Schooler, Ohlsson, & Brooks, 1993). These            and rapid change in performance, rather than the true
problems typically are highly difficult, require a single              “eureka” experience. However, this measure has the benefit
insight, and have only one correct answer. Insight problems            of being feasible to use to study the phenomenon of insight
can be a useful instrument to study insight in a controlled,           (or simply moments of rapid learning) in authentic learning
replicable fashion. They have allowed researchers to learn a           contexts and tasks.
considerable amount about insight, such as the                            We base this work on two recent developments that have
incompatibility between verbalizing thoughts and solving               made it more feasible to study insight in real-world learning
insight problems (Schooler, Ohlsson, & Brooks, 1993), the              environments. First, the increasing availability of very large
ways that external stimuli can facilitate insight (Slepian,            data sets from online learning environments, in particular
                                                                   1631

intelligent tutoring systems that reify each of the steps of          insights are one way that this might occur (Baker, Gowda,
solving a specific problem (Koedinger & Corbett, 2006),               & Corbett, 2011).
allow us to find many examples of moments of rapid                       Finally, we also examined contextual guessing behaviors.
learning. Second, the recent advent of models that attempt to         Guessing is not mentioned in the literature as being
explicitly identify how much learning is occurring moment-            associated with robust learning, but we felt that it was worth
by-moment (Baker, Goldstein, & Heffernan, 2011) provides              examining because it is a behavior that only occurs before
a new opportunity to identify situations where unusually              learning moments. Additionally, guessing is measured as
rapid learning occurred and study what differentiated these           part of many knowledge modeling frameworks, such
situations from other situations where less learning                  Bayesian Knowledge Tracing (described below), but is
occurred. In addition, the longitudinal and intensive nature          typically unexamined.
of this data allows us to not just study what was occurring in
those moments of enhanced learning, but also what occurred                                      Method
in the moments leading up to them. As such, for the present
study, we combined these two resources to try to better               Learning Environment
understand what factors precede and are associated with               We studied learning moments within the context of
insight.                                                              Cognitive Tutor Geometry (CTG), a computer learning
   To do this, we first distilled a range of features of the data     environment that promotes learning by doing, currently used
for situations where unusually rapid learning occurred in an          by tens of thousands of students a year (Koedinger &
online learning environment, as well as for the situations            Corbett, 2006). In CTG, students individually solve
and student actions preceding those situations. Though our            mathematics problems, which are broken down into the
approach was a bottom-up data mining approach (cf. Baker              series of steps needed to solve them. As a student works
& Yacef, 2009), we distilled these features with specific             through a problem, a running cognitive model assesses
candidate hypotheses in mind.                                         whether the student’s answers map to correct understanding
   One particularly important candidate hypothesis involved           or to a known misconception (Anderson, Corbett,
self-explanation. Self-explanation is a self-directed,                Koedinger, & Pelletier, 1995). If the student inputs an
constructive activity that occurs when a student generates            incorrect answer, the answer turns red. If the student’s
explanations during learning (Conati & VanLehn,                       answer also indicates a known misconception (called a
1999;Hausmann, Nokes, VanLehn, & Gershman, 2009).                     “bug”), the student is given a message about their error.
Self-explanation can involve attempting to understand                    An important feature of CTG is that students need to input
worked examples (Conati & VanLehn, 1999; Shih,                        both an answer and a justification for that answer, in the
Koedinger, & Scheines, 2008), or attempting to understand             form of a geometric principle. Students can enter their
feedback (Baker, Gowda, & Corbett, 2011). While self-                 justification either by typing the name of the geometric
explaining instructional content, students develop an                 principle next to their answer or by choosing the geometric
understanding of complex phenomena, actively construct                principle from a Glossary, which contains a list of theorems
knowledge, and make knowledge personally meaningful                   and definitions that are relevant to the lesson as well as
(Jordan, Makatchev, & VanLehn, 2003; Roy & Chi, 2005).                illustrations and short examples demonstrating those
Self-explanation has been shown to promote deeper                     theorems and definitions (Aleven & Koedinger, 2002). In
processing and more robust learning (Hausmann, Nokes,                 addition to being used for justifying problems steps, the
VanLehn, & Gershman, 2009; Roy & Chi, 2005). Self-                    Glossary also acts as a reference for students to use to help
explanation’s positive effects arise in part because it can           them solve the problems (Aleven & Koedinger, 2002).
expose a student’s misconceptions about a concept (Roy &                 CTG also has context-sensitive multi-step hints, which are
Chi, 2005) and the gaps in the student’s knowledge                    tailored to the exact problem step the student is working on.
(VanLehn & Jones, 1993). We believe that some of the way              A student who requests a hint first receives a conceptual
that self-explanation may promote robust learning in real-            hint, and can then request further hints, which become more
world situations is through promoting "eureka" moments.               and more specific until the student is given the answer.
   Several other candidate hypotheses were also considered.              As students work through problems in a specific
These hypotheses are in line with past evidence from the              curricular area, the system uses Bayesian Knowledge-
cognitive and learning sciences that suggest that these               Tracing (Corbett & Anderson, 1995), or BKT, to estimate
specific factors are associated with positive learning                which skills the student knows and which skills the student
outcomes in online learning settings. In particular, we               is having difficulty with. BKT is a commonly-used student
examined the relationships between learning moments and               modeling algorithm that infers the probability of student
receiving “bug” messages (which inform a student if they              knowledge at a given time based on the student’s history of
have a common misconception), and between learning                    correct and incorrect answers and help requests. BKT also
moments and utilizing online help systems. Each of these              empirically determines the probability that the student got
experiences (and how students react to them) has been                 the answer correct without having the necessary knowledge
previously shown to be associated with robust learning, and           (called the guess probability) and the probability that the
                                                                  1632

student got the answer incorrect even though they had the             The calculation of P(J) builds upon BKT and is a two-
knowledge (called the slip probability). CTG then uses these       step process. First, we generate an initial value for each
estimates to give each student problems that are relevant to       problem step that represents the probability that the student
the skills that he or she is having difficulty with.               learned a knowledge component or skill on that specific
   CTG material is structured into independent lessons that        problem step. The assignment of these values is based on
each cover a set of related skills and concepts, such as           the idea that learning is indicated when a student does not
parallel and perpendicular lines, similarity, congruence,          know a skill at one point, but then starts performing
volume and surface areas, and vectors. Year-long courses           correctly afterwards. These initial probabilities are
are composed of sequences of lessons, where later lessons          generated using a combination of predictions of current
build upon knowledge from previous lessons. Log files are          student knowledge from BKT and data on future
automatically collected while the students use the software        correctness, integrated using Bayes’ Theorem. Thus, the
over the course of the year.                                       calculation uses evidence from both past and future data to
                                                                   assess the probability that learning occurred at a specific
Participants                                                       time.
The data set used in this research comes from the LearnLab            Second, these initial probabilities are then used as inputs
DataShop data repository (Koedinger, Stamper, Leber, &             to a model that infers the probability of learning at a specific
Skogsholm, 2013). Data was collected from 102 students at          problem step based only on past data. This model uses a
a high school in rural Western Pennsylvania. The students          broader feature set (e.g., response time, use of help, the type
used CTG across the course of the entire school year,              of interface widget, and the student’s problem-solving
approximately two days a week, as part of their regular            history with the tutor), but uses no data from the future. In
mathematics curriculum. Students in this school are 98%            this way, we create a model that can be used either at run-
Caucasian. While this is typical for rural schools in this         time or retrospectively to assess the probability that a
region, it is higher than the state average (73% Caucasian).       knowledge component is learned at a specific practice
There are approximately 16 students per teacher in the             opportunity. This process also “smoothes” model
school, which is about the same as the state average (15           predictions, reducing the degree to which extreme
students per teacher). Additionally, 28% of students in the        probability values are obtained by chance. This prediction
school qualified for free or reduced lunch, which is slightly      smoothing is useful because it makes the predictions more
less than the state average (33%). In this school, 69% of          stable and reliable and, in turn, allows us to examine the
students were rated proficient or higher on the math section       predictions more closely.
of the PSSA standardized exam, which is approximately
equal to the state average (72%). The students were                Data Analysis
approximately balanced in terms of gender.                         To examine insight, we compared two sub-sets of the data –
   Students made 683,285 total transactions with the system        the data associated with the top 1% of P(J) values, treated as
(a transaction is defined as any action that the student           rapid learning moments, and the data associated with the
makes, such as attempting to enter a problem step or asking        remaining 99% of P(J) values, treated as non-rapid learning
for help), within 509,854 total problem steps, for an average      moments. This 99/1 split is a somewhat arbitrary
of 1.34 transactions per problem step. There was an average        designation; it is hard to say if this is too liberal or too
of 6698.87 transactions per student, an average of 10845.79        conservative. It is possible that not all P(J) values in the top
transactions per lesson across all students, and an average of     1% are indicative of learning moments. However, moments
106.33 transactions per lesson per student. There was an           in the top 1% are definitely more likely to be rapid learning
average of 4998.57 problem steps per student, an average of        moments than those in the top 50%, for instance.
8092.92 problem steps per lesson across all students, and an          In order to examine the predictors of these moments, we
average of 79.34 problem steps per lesson per student.             looked at the preceding problem step on the same skill for
                                                                   each rapid and non-rapid learning moment. Depending on
Measuring Moment-by-Moment Learning                                the design of the lesson, the antecedent problem step of the
   We computed the probability that a student learned in a         same skill could have immediately preceded the moment or
specific problem step using the moment-by-moment                   been separated from the moment by several minutes, or
learning model, also referred to as P(J), the probability that     even a few days. Each antecedent problem step consisted of
the student Just learned (Baker, Goldstein, & Heffernan,           one or more student actions, such as asking for help or
2011). A high P(J) value indicates that there was a high           inputting a response. To create features (discussed below) at
probability that the student learned during the associated         the grain-size of problem steps, we averaged the data across
problem step. The full mathematical equations for the P(J)         all student actions in each individual problem step to create
model are given in Baker, Goldstein, & Heffernan (2011),           a single value per feature per problem step.
but we summarize the process here.                                    The top 1% of P(J) values was determined using all
                                                                   509,854 P(J) measurements in the data set. However, not all
                                                               1633

problem steps had an antecedent problem step. Problem                asking for a lot of help. All of the features distilled
steps were only included in the analysis if they had an              represent theoretically-justified hypotheses for factors that
antecedent problem step on the same skill. This produced a           may lead to learning moments. Furthermore, these features
set of 3996 problem steps with a P(J) in the top 1% and a            all represent unique, though potentially correlated, actions
comparison set of 467701 problem steps with a lower P(J).            and occurrences within the Cognitive Tutor. While a
   In order to better understand the situations in which             description of all of the features is out of the scope of this
insights occur, we used features of the antecedent problem           paper, six are listed in Table 1 to highlight the most relevant
steps of rapid and non-rapid learning moments to develop a           findings.
set of prediction models that attempt to infer whether a
problem step will be a rapid learning moment. Specifically,          Metrics Used
we built a set of step regression models (linear regression          We evaluated each of the models using cross-validation. In
with a step function; not the same as step-wise regression),         cross-validation, models are repeatedly built on a subset of
using RapidMiner 4.6 (Mierswa et al., 2006). Step                    the data, and tested on an unseen subset. In this analysis, we
regression models are a method for predicting binary data.           cross-validated at the student-level (e.g. the same student
In this case, we used them to predict whether an antecedent          was not represented in both the training and test folds),
problem step preceded a rapid learning moment or not. Step           using 6 folds. Cross-validation is an alternative to statistical
regression models postulate that there are sharp disjunctions        significance testing that is theoretically equivalent to the
between the values of a variable. They have been successful          Bayesian Information Criterion (BIC) (Raftery, 1995).
in many educational data mining problems, and seem                      The goodness of each model was determined using A’, a
particularly appropriate in this case, as we are trying to infer     metric mathematically identical to the Wilcoxon statistic
a sharp disjunction in student learning and performance. In          and to AUC, the “Area Under [the ROC] Curve” (Hanley &
this study, we created one model per potential feature in            McNeil, 1982). A’ is the probability that if a detector
order to understand the range of features that predict insight.      compares a problem step preceding a rapid learning moment
                                                                     to a problem step that is not, it will correctly identify which
Potential Predictors of Insight                                      is which. A model with an A’ of 0.5 performs at chance and
We distilled a set of features that were potential predictors        a model with an A’ of 1.0 performs perfectly. In this study,
of insight from the logs of students' interactions with the          A’ was calculated using custom code that can be found at
Cognitive Tutor. These features were quantitative or binary          http://www.columbia.edu/~rsb2162/computeAPrime.zip.
descriptors of key aspects of each problem step and were             This custom code avoids the computational errors that are
hypothesized to be associated with the construct of interest,        seen in A' implementations that compute the integral of the
insight. As discussed above, these features were computed            curve. Cohen’s Kappa (1960) is another goodness metric
using data from the problem step preceding each rapid or             that is often used for models of this type. However, due to
non-rapid learning moment.                                           the extreme imbalance between the number of cases in the
   One of the candidate features we examined was self-               comparison groups, it was not appropriate for this data.
explanation. This type of large-scale log data is analyzed              Along with the A' values, we also calculated the means
retrospectively. Therefore, it was not possible to directly          and standard deviations of each feature for each group.
measure whether students were engaging in self-                      These values, in general, represent the approximate
explanation. Instead, we adopted the operationalization used         proportion of the times that the action associated with the
by Baker, Gowda, and Corbett (2011). They suggested                  feature occurred. However, because the unit of analysis is
looking for when students pause after receiving a bug                problem steps and not all individual actions are treated
message or pause after asking for help. Previous research            equally, labeling these as proportions is not quite accurate.
suggests that long pauses in these situations may indicate           Additionally, some means and standard deviations, such as
self-explanation (Shih, Koedinger, & Scheines, 2008). We             the number of actions in a problem step, represented
specifically looked for pauses that were at least 10 seconds         average counts instead of proportions.
long. The cutoff of 10 seconds was chosen because this
amount of time indicates that the learner was probably doing                                    Results
something other than just making the next action in the
                                                                     In line with our initial hypothesis, students about to have a
system. These pauses can contain other behaviors, such as
                                                                     moment of rapid learning were more likely to self-explain
off-task behavior (typically 80 seconds or longer – Baker,
                                                                     bug messages and hints (M = 0.120, SD = 0.248) than
2007) or talking to the teacher, but are likely to contain a
                                                                     students not about to have a moment of rapid learning (M =
substantial proportion of self-explanation behavior.
                                                                     0.018, SD = 0.107). However, self-explanation was only
Eighteen other features were distilled as well, such as
                                                                     weakly predictive of rapid learning moments (A' = 0.578).
guessing behaviors and the number of actions it took the
                                                                     Other features were more predictive.
student to achieve a correct answer, the latter of which may
                                                                        Contextual guessing, calculated using the model from
indicate that students are making many mistakes and/or are
                                                                     Baker, Corbett, & Aleven (2008) and defined as having a
                                                                 1634

high probability of getting an answer correct due to guessing      before getting the correct answer (M = 2.199, SD = 2.376)
rather than knowing the skill, was the strongest predictor of      than students who were not about to have a rapid learning
rapid learning moments (A’ = 0.709). Students who were             moment (M = 1.347, SD = 1.557). This implies that
about to have a moment of rapid learning were more likely          persisting in working on a difficult problem is associated
to contextually guess (M = 0.100, SD = 0.128) than students        with moments of rapid learning.
not about to have a moment of rapid learning (M = 0.022,
SD = 0.071). This indicates that guessing may help students                      Discussion and Conclusions
learn when they do not understand a skill. Alternatively, it
                                                                   In this research, we looked to understand when insight
may indicate that students appear to guess when they have
                                                                   occurs within real-world learning contexts by studying
developed an understanding that is partially correct and only
                                                                   large quantities of log files from students using an
succeed intermittently.
                                                                   Intelligent Tutoring System. Specifically, we used the
                                                                   probability that a student had just learned as an indicator of
        Table 1: A’ values for a subset of the features
                           Feature                        A’
                                                                   whether insight occurred and compared rapid learning
    Low Probability of Knowing Before Answering and High
                                                                   moments (i.e., insights) to non-rapid learning moments (i.e.,
                                                         0.709     non-insights) in terms of a variety of features. It is our hope
                    Probability of Guessing
          Probability of Knowing Before Answering        0.706
                                                                   that this research is a first step towards being able to
                                                                   accurately study "eureka" moments in authentic learning
            Number of Actions in the Problem Step        0.639
                                                                   environments.
                   Receiving a Bug Message               0.626        In line with this, these results should be seen as opening
      Time > 10 Seconds and Previous Action Help or Bug  0.578     up new hypotheses rather than conclusively confirming
                        Asking for Help                  0.539     them. As is true of all measures developed using data
                                                                   mining and knowledge engineering, our operationalizations
   The probability of knowing the skill before answering (A’       are imperfect. For the purposes of this study, we have drawn
= 0.706) was also more predictive of rapid learning                from previous literature to operationalize these constructs as
moments that self-explanation. Students who had a lower            accurately as possible. However, it is difficult to verify the
probability of knowing the skill before completing an action       degree to which our operationalizations fully capture these
were more likely to have a moment of rapid learning (M =           constructs.
0.674, SD = 0.357) than those with a higher probability of            Despite this limitation, clear findings emerge from this
knowing the skill before completing an action (M = 0.889,          analysis. We initially hypothesized that self-explanation
SD = 0.250). This makes sense, as a student cannot have a          would lead to rapid learning moments, and this hypothesis
learning moment if they already know the skill.                    was weakly supported by the results. Other successful
   As hypothesized, another feature associated with rapid          predictors of moments of rapid learning included the
learning moments was receiving a bug message, though this          probability of knowing the skill, the number of actions it
feature was only weakly associated (A’ = 0.584). Students          took to complete the problem step, and receiving a bug
about to have a rapid learning moment were more likely to          message.
receive a bug message (M = 0.168, SD = 0.312) than                    However, contextual guessing was the most strongly
students not about to have a rapid learning moment (M =            associated with rapid learning moments. This is interesting
0.053, SD = 0.192). This suggests that the feedback present        because guessing is typically assumed to be associated with
in the bug messages helped the students learn the skill – a        behaviors that have negative effects on learning, such as
positive impact for that aspect of the Cognitive Tutor’s           gaming the system (Baker, Corbett, Roll, & Koedinger,
design. It is surprising that bug messages were not more           2008). Guessing is an event that occurs unexpectedly. This
predictive of learning moments though. A more detailed             may mean that unexpected events are good indicators of
examination of bug messages may clarify these results.             rapid changes in knowledge. Alternatively, it might mean
   However, contrary to our hypothesis, asking for help was        that the differences between unexpected events and rapid
not very predictive of rapid learning moments (A’ = 0.539).        changes in knowledge are hard to discriminate.
Given that help seeking behavior is commonly considered to            For these reasons, future work should focus on clarifying
be good for learning, this is a surprising result. It may          the relationships between rapid learning moments and their
indicate that the help being given was only intermittently         antecedents at a finer grain size, especially examining
useful or that students were abusing the help. However, this       unexpected events such as contextual guessing. Future work
result requires a more thorough investigation before we can        should also further examine how closely P(J) values relate
make any conclusions with confidence.                              to insight. One way to approach this may be to distill
  Finally, the number of actions it took a student to get the      features that have been shown to be associated with insight
correct answer to a problem step was also predictive of            (e.g., not verbalizing thoughts, minimized cognitive load)
rapid learning moments (A' = 0.639). Students about to             and to see how these features associate with P(J) values. In
have a rapid learning moment tended to make more attempts          this way, we can better understand the factors that lead
                                                               1635

students to experience insight, better understand how to           Corbett, A.T. & Anderson, J.R (1995). Knowledge tracing:
design online learning to facilitate learning moments, and           Modeling the acquisition of procedural knowledge. User
help fulfill Anderson’s (1993) vision for intelligent tutoring       Modeling and User-Adapted Interaction, 4, 253-278.
systems as both a way to transform education and a platform        De Dreu, C. K., Nijstad, B. A., Baas, M., Wolsink, I., &
for Cognitive Science research.                                      Roskes M. (2012). Working memory benefits creative
                                                                     insight, musical improvisation, and original ideation
                     Acknowledgments                                 through maintained task-focused attention. Personality
                                                                     and Social Psychology Bulletin, 38(5), 656-669.
This research was supported by the Pittsburgh Science and
                                                                   Hanley, J., & McNeil, B. (1982). The meaning and use of
Learning Center, NSF award number SBE-0836012.
                                                                     the area under a receiver operating characteristic (ROC)
                                                                     curve. Radiology, 143, 29-36.
                         References                                Hausmann, R. G. M., Nokes, T. J., VanLehn, K., &
Aleven, V. & Koedinger K. R. (2002). An effective                    Gershman, S. (2009). The design of self-explanation
  metacognitive strategy: Learning by doing and explaining           prompts: The fit hypothesis. Proc. of the Thirty-First
  with a computer-based cognitive tutor. Cognitive Science,          Conference of the Cognitive Science Society, 2626-2631.
  26, 147-179.                                                     Jordan, P., Makatchev, M., & VanLehn, K. (2003).
Anderson, J. R. (1993). Rules of the mind. Mahwah, NJ:               Abductive theorem proving for analyzing student
  Erlbaum                                                            explanations. Proc. of the Int’l Conf. on Artificial
Anderson, J.R., Corbett, A.T., Koedinger, K.R., & Pelletier,         Intelligence in Education (pp. 73-80).
  R. (1995). Cognitive Tutors: Lessons learned. Journal of         Koedinger. K. R. & Corbett, A. T. (2006). Cognitive Tutors:
  the Learning Sciences, 4(2), 167-207.                              Technology bringing learning science to the classroom. In
Baker, R.S.J.d. (2007) Modeling and understanding                    K. Sawyer (Ed.) The Cambridge Handbook of the
  students' off-task behavior in intelligent tutoring systems.       Learning Sciences. Cambridge University Press.
  Proceedings of ACM CHI 2007: Computer-Human                      Koedinger, K. R., Stamper, J. C., Leber, B., & Skogsholm,
  Interaction (pp. 1059-1068).                                       A. (2013) LearnLab's DataShop: A data repository and
Baker, R.S.J.d., Corbett, A.T., & Aleven, V. (2008) More             analytics tool set for cognitive science. Topics in
   Accurate Student Modeling Through Contextual                      Cognitive Science, 5, 668-669.
   Estimation of Slip and Guess Probabilities in Bayesian          Mierswa, I., Wurst, M., Klinkenberg, R., Scholz, M., &
   Knowledge Tracing. Proceedings of the 9th International           Euler, T. (2006). YALE: Rapid prototyping for complex
   Conference on Intelligent Tutoring Systems, 406-415.              data mining tasks. Proc. of the 12th Int’l Conf on
Baker, R.S.J.d, Corbett, A.T., Roll, I., & Koedinger, K. R.          Knowledge Discovery and Data Mining, 935-940.
   (2008). Developing a generalizable detector of when             Raftery, A. E. (1995). Bayesian model selection in social
   students game the system. User Modeling and User-                 research (with discussion). Sociological Methodology, 25,
   Adapted Interaction, 18(3), 287-314.                              111-195.
Baker, R.S.J.d., Goldstein, A.B., & Heffernan, N.T. (2011).        Roy, M. & Chi, M. T. H. (2005). The self-explanation
  Detecting learning moment-by-moment. Int’l Journal of              principle in multimedia learning. In: Mayer, R.E. (Ed.),
  Artificial Intelligence in Education, 21 (1-2), 5-25.              The Cambridge handbook of multimedia learning.
Baker, R.S.J.d., Gowda, S.M., & Corbett, A.T. (2011).                Cambridge University Press, New York.
  Automatically detecting a student's preparation for future       Schooler, J. W., Ohlsson, S., & Brooks, K. (1993).
  learning: Help use is key. Proc. of the 4th Int’l                  Thoughts beyond words: When language overshadows
  Conference on Educational Data Mining, 179-188.                    insight. Journal of Experimental Psychology: General,
Baker, R.S.J.d., & Yacef, K. (2009) The state of educational         122(2), 166-183.
  data mining in 2009: A review and future visions. Journal        Shih, B., Koedinger, K., & Scheines, R. (2008). A response
  of Educational Data Mining, 1(1), 3-17.                            time model for bottom-out hints as worked examples.
Bowden, E. M., Jung-Beeman, M., Fleck, J., & Kounios, J.             Proc. of the First Educational Data Mining Conference.
  (2005). New approaches to demystifying insight.                  Slepian, M. L., Weisbuch, M., Rutchick, A. M., Newman,
  TRENDS in Cognitive Science, 9(7), 322-328.                        L. S., & Ambady, N. (2010). Shedding light on insight:
Chu, Y., & MacGregor, J. N. (2011). Human performance                Priming bright ideas. Journal of Experimental Social
  on insight problem solving: A review. The Journal of               Psychology, 46, 696-700.
  Problem Solving, 3(2), 119-150.                                  VanLehn, K. & Jones, R. M. (1993). What mediates the
Cohen, J. (1960). A coefficient of agreement for nominal           self-explanation effect? Knowledge gaps, schema or
  scales. Educational and Psychological Measurement,               analogies? Proc. of the 15th Annual Conference of the
  20(1), 37-46.                                                    Cognitive Science Society, 1034 – 1039.
Conati, C. & VanLehn, K. (1999). A student model to
  assess self-explanation while learning from examples.
  Proc. of Seventh Int’l Conference on User Modeling.
                                                               1636

