 A latent-mixture quantum probability model of causal reasoning within a Bayesian
                                                    inference framework
                                             Percy K. Mistry (pkmistry@uci.edu)
                                          Jennifer S. Trueblood (jstruebl@uci.edu)
                                       Joachim Vandekerckhove (joachim@uci.edu)
                Department of Cognitive Sciences, University of California Irvine, Irvine, CA 92697-5100 USA
                                      Emmanuel M. Pothos (e.m.pothos@gmail.com)
                           Department of Psychology, City University London, London EC1R 0JD UK
                            Abstract                                  investigate the application and benefits of applying quantum
  We develop a quantum probability model that can account for
                                                                      probability models by using these models to explain the
  situations where people’s causal judgments violate the              empirical results reported in Rehder (2014), which
  properties of causal Bayes nets and demonstrate how the             demonstrated violations of the causal Markov condition, as
  parameters of our model can be interpreted to provide               well as failure to exhibit robust discounting (this occurs
  information about underlying cognitive processes. We                when the presence of one cause makes the presence of
  implement this model within a hierarchical Bayesian                 another less likely in certain casual structures).
  inference framework that allows us to systematically identify
  individual differences and also provide a latent classification
  of individuals into categories of causal and associative                  Description and Results of Experiments
  reasoners. Finally, we implement a basic normative causal           In Rehder (2014), participants were taught one of the three
  Bayes net within the same inference framework that allows us        causal network structures (common cause, chain or common
  to directly compare quantum and classical probability models        effect) encompassing a set of relationships between three
  using Bayes factors.
                                                                      binary variables as shown in Figure 1, instantiated in either
  Keywords: Causal reasoning; quantum probability; Bayesian           a domain-general (abstract) or domain-specific (economics,
  graphical models; causal Bayesian networks; individual              sociology, or meteorology) setting. The causal relations
  differences; latent mixture models; violations of normative         specified how variables were related, (e.g. in the economics
  properties; Bayesian inference; associative reasoning
                                                                      domain, the variables were interest rates, trade deficits, and
                                                                      retirement savings, each of which could be large (high) or
                        Introduction                                  small (low); a relationship could take the form: low interest
We investigate a subset of causal reasoning paradigms                 rates cause small trade deficits). Each individual
where people have to make judgments about causal systems              relationship in the causal structure was described as being
based on linguistic descriptions of the causal properties of          driven by independent causal processes.
the system, i.e. where precise statistical information is not
presented. In these situations, people’s judgments often
violate the properties of causal Bayes nets (Rottman &
Hastie, 2014; Park & Sloman, 2013; Rehder, 2014;
Fernbach & Sloman, 2009; Waldmann, Cheng, Hagmayer,
& Blaisdell, 2008; Hagmayer & Waldmann, 2002). One
important property of Bayes nets is the causal Markov
condition, which states that any node in the network is
conditionally independent of its non-effects, given its direct
causes (Hausman & Woodward, 1999). To account for
observed behavior, Bayes nets are often augmented with
heuristic-like shortcuts (Fernbach & Rehder, 2013) or with
the inclusion of variables that account for hidden aspects of           Figure 1: Causal structures considered in the experiments
the problem (that is, not part of the experimental paradigm,
and assumed to be the result of participants’ mental process)           The causal relationships were unidirectional, in the sense
such as alternative causes, shared disabling, mediating or            that if a particular (high or low) value of a cause variable
enabling conditions between variables, and so on. (Rehder,            facilitated the presence of an effect, the other binary value
2014).                                                                did not have the opposite effect (e.g. if low interest rates
  We propose that quantum probability models of causal                caused small trade deficits, high interest rates were causally
reasoning can provide a more formal, principled alternative           unrelated to trade deficits). Once the causal structures had
approach for explaining violations of the properties of               been taught, participants were asked to make a comparative
classical probability models, such as causal Bayes nets. We           inference on the probability of a target variable (Y) taking a
                                                                  1589

specific value (denoted y1), between two different network        disabling mechanism shared by the cause variables,
states within a particular causal structure. The eight network    assumption of an associative Markov random field
states used in the comparison (situations A to H; see Table       network), which when appropriately weighted could
1) represented different values of the remaining two              reproduce behavior for both causal and associative
variables X and Z, namely `0' (representing a state value         reasoners. Each of these models had between three to five
that does not exert any causal influence), `1' (representing a    free parameters, with an additional three free parameters for
state value that causally influences or is influenced), or ‘?’    the mixture weighting these models.
(unknown value). Participants were asked to compare states
A vs B, B vs C, D vs E, F vs G and G vs H, and indicate              Specifying the Quantum Probability Model
which of the two situations provided stronger inferential         We specify a 2-dimensional (2-d) quantum probability (QP)
support for the target variable (always referred to as Y for      model to reflect the mental representations of the three
the rest of the paper), or whether support was equal for each     binary variables X, Y and Z (Trueblood & Pothos, 2014). In
variable.                                                         this model, the three variables are deemed incompatible,
                                                                  that is these variables span separate subspaces within the 2-
            Table 1: Normative Inferential Predictions            dimensional space. This implies that consideration of these
                                                                  variables cannot take place concurrently, but rather has to be
     Situation    X     Z      CC          CH          CE         sequential, so that order effects may arise when both
         A        1     1                                         variables need to be assessed (e.g., in a conjunction).
         B        ?     1    A=B=C       A=B=C      C>B>A            Accordingly, the two dimensions for each subspace
         C        0     1                                         ({x1,x0},{y1,y0}{z1,z0}) shown in Figure 2 represent the
         D        1     ?                                         two values that each binary variable can take. Since the
                             D >> E      D >> E       D=E
         E        0     ?                                         causal structures are unidirectional (that is, only one value
         F        1     0                                         affects the system causally), the values (for instance y1 and
         G        ?     0    F=G=H       F=G=H       F=G=H        y0) are encoded such that y1 always indicates the value that
         H        0     0                                         is causally linked (e.g. if low interest rates cause high
                                                                  deficits, low interest rates and high trade deficits are
   For our analyses, we combined the data from four               encoded as 1, high interest rates and low trade deficits,
experiments in Rehder (2014) (i.e., experiments 2, 3, 4A          which do not influence or experience causal influence, are
and 4B). Across these four experiments, there were 315            encoded as 0).
participants. Each participant made twenty such
comparative judgments, with the causal structure (common
cause, chain, common effect) and domain of variables
(economics, sociology, meteorology, and an abstract domain
in one condition) as between-subject conditions.
   Table 1 also shows the normative predictions for each
possible pair of situations based on a causal Bayes net
treatment of the inference problem (see Rehder, 2014 for a
detailed analysis of the normative predictions). Two key
properties included the causal Markov condition and
discounting behavior in the common effect structure (the
known presence of one cause makes the presence of an
alternate cause less likely). Rehder (2014) found that a
significant number of participants violated these two
properties, and observed that about 23% of the 315
participants exhibited some form of associative reasoning,
that is, a lack of sensitivity to causal direction, ignoring               Figure 2: Representation of the 2-d QP model
conditional independence stipulated by the causal Markov
property or exhibiting anti-discounting behavior (i.e.               The model specifies a unit length state vector |ψ› which
judging the target cause as highly probable based on the          represents the current state of belief held by an individual.
presence of an alternative cause, which is opposite to            The relative degree of rotation of the state vector from each
normative expectation). These participants were classified        basis vector (e.g. θψ from the y1 basis vector) defines the
as associative reasoners, whereas the rest were classified as     individual’s belief in the probability of that variable. Thus,
causal reasoners.                                                 an individual’s belief in the probability of a certain variable
   Rehder (2014) accounted for these violations by                taking a certain value (e.g. p(y1) in Figure 2) can be
suggesting a mixture of normative behavior with three             obtained by projecting the state vector (black dotted line) on
additional inference strategies (conditional probabilities        to the coordinate axis of interest and taking the squared
being assessed conjunctively, assumption of a hidden              value of the resulting amplitude (black bar).
                                                              1590

  Conditional probabilities (for example, p(y1|x1)) are             p(y1) is given by p(y1 & Unknown = 1 | Known) + p (y1 &
measured by projecting the state vector onto the known (x1)         Unknown = 0 | Known). This is achieved by projecting the
basis vector, normalizing it (making it unit length) to             state vector |ψ› onto the basis vector representing the known
account for the fact that the state x1 is known (squared            variable value and normalizing it (unit length to reflect the
amplitude =1), and then projecting this vector to the basis         conditional probability), then projecting the normalized
vector y1. The squared amplitude of the resulting projection        vector on to the basis vector representing the unknown
along y1 gives the conditional probability p(y1|x1).                variable value `1'. The squared amplitude of this
Similarly, conjunctive probabilities (for example p(x1&y1))         intermediate projection reflects p(Unknown = 1 | Known).
are assessed by making successive projections to x1 and y1,         This projection (without normalizing) is then projected
but without normalizing the intermediate projection.                again on the basis vector y1. This final projection is squared
  We propose that this formulation can predict order                to get the first term on the left, that is, p(y1 & Unknown=1 |
effects, reciprocity (related to the inverse fallacy; Koehler,      Known) in the above probability. The second term is
1996), memoryless effects such as a lack of discounting,            obtained using a similar sequence of operations, with the
and violations of the Markov condition. In terms of assessed        intermediate projection being to the basis vector
probabilities, order effects, for instance, allow the               representing the unknown variable value `0' instead of ‘1’.
probability p(y1&x1) to differ from p(x1&y1). Reciprocity           The combination of these probabilities reflects the
is a specific property of the 2-d model, where for two              assumption that people consider the known information,
variables, e.g. Y and X, the conditional probabilities              then effectively integrate over the two conjunctive
reciprocate, that is p(y1|x1) = p(x1|y1). Memoryless effects        probabilities of the target variable (Y) being ‘1’ and each
refers to the fact that assessment of probabilities conditional     possibility for the unknown binary variable.
or more than one variable reduce to the conditional                    The second type of inference relates to situations where
probability based on the last updated information only, for         both the remaining variables, X and Z, are known (situations
instance, p(y1|x1,z0) = p(y1|z0) and p(y1|z0,x1) = p(y1|x1),        A, C, F and H in the experiment). Here the model
which hence also leads to order effects. A lack of                  specification is similar to that described above, except that
discounting can be explained by way of the memoryless               the intermediate projection is only made on the known value
property. Discounting refers to the fact that in a common           and is also normalized (projection rescaled to unit length to
effect scenario, considering classical probabilities,               reflect calculation of conditional probability). Since both X
p(y1|x1,z1) < p(y1|z1), where z1 is the common effect. The          and Z are known, the order of projections can vary and since
memoryless property however reduces p(y1|x1,z1) to either           the model exhibits memoryless properties, this can give rise
p(y1,z1) or p(y1|x1), depending on what projection order is         to order effects between participants, such that participants
used. In the former case, this leads to a lack of discounting.      can calculate either p(y1| Known X, Known Z) =
Unless the two bases are exactly at an angle of 45° to each         p(y1|Known Z) or p (y1| Known Z, Known X) =
other, the model also predicts violations of the Markov             p(y1|Known X). We include a free latent parameter that
condition, that is, a violation of the fact that p(y1|x1) should    allows the model to infer the most likely order
be equal to p(y1|x0), if X and Y are conditionally                  representation for each individual.
independent.                                                           Table 2 lists the probability calculations and projection
  To formulate the specific causal networks investigated we         sequences for each of the situations. For A, C, F, and H, the
set the basis for Y (all inference by participants is made on       individual differences in probability estimates can arise
the variable Y) as the standard basis, and two free                 from the projection order or rotation parameters. For B, G,
parameters (θX and θZ) denote rotations for the basis vectors       D, and E, individual differences arise from the rotation
of X and Z in the 2-dimensional space. The degree of                parameters.
rotation between the different bases determines the
conditional and conjunctive probability relationships                      Table 2: Probability specification in the 2-d model
between them. The rotation is restricted to the first quadrant
to reduce any identifiability issues (e.g. a rotation from y1         Situation     X     Z        Probability Specification
of 30° and 330° would result in an identical projection onto              A         1     1    p(y1 | x1, z1) or p(y1 | z1, x1)
y1). The state vector is not a free parameter but is fixed at a           B         ?     1    p(y1 & x1 | z1) + p(y1 & x0 | z1)
neutral position of 45° to the standard basis, reflecting the             C         0     1    p(y1 | x0, z1) or p(y1 | z1, x0)
assumption that people should not have any preconceived                   D         1     ?    p(y1 & z1 | x1) + p(y1 & z0 | x1)
bias towards the presence or absence of the target variable               E         0     ?    p(y1 & z1 | x0) + p(y1 & z0 | x0)
to be inferred, and that the randomized configurations                    F         1     0    p(y1 | x1, z0) or p(y1 | z0, x1)
provide no information on the base rate of events.                        G         ?     0    p(y1 & x1 | z0) + p(y1 & x0 | z0)
  The model separates two types of inference situations. In               H         0     0    p(y1 | x0, z0) or p(y1 | z0, x0)
the first, inference on Y needs to be made with only one of
the other two variables (either X or Z) being known and the            The probability of the target variable under any situation
other being unknown (situations B, D, E and G in the                A to H is calculated as p(Y=1|situation), based on the
experiment, see Table 1). Here, the model specification for         appropriate sequences of projections and normalization as
                                                                1591

described above. Probabilities for the two situations (say, s1       probability model might be represented under the QP model.
and s2) being compared are calculated separately, assuming           Note that when the values of X and Z are both known
the same parameter value for the rotations X and Z under             (situations A, C, F and H), the model exhibits a memoryless
both, so that comparisons are based on a consistent set of           property, that is, the projection order of considering X first
beliefs about the entire causal system. The final choice             and then Z reduce to making an inference based on the last
proportions are predicted based on a softmax decision rule,          seen value of Z only, and vice versa. Ideal normative
so that choice ratio (h) for s1 versus s2 is given by                reasoning for the common cause and chain structures, for
exp(logit(p(y1|s1))/τ) / Σs=s1,s2 exp(logit(p(y1|s))/τ), where τ     these situations (ACFH), then implies that the order of
is the temperature parameter and is fixed to a constant of 1.        processing is X followed by Z (equivalent to processing
We use this rule for consistency with the original study             only Z), where inference is made by a projection from z1 to
(Rehder, 2014) to ensure that any differences in prediction          y1 for situations A and C, and from z0 to y1 for situations F
can be attributed to the underlying probability models.              and H.
                                                                        For the common effect structure, an ideal causal reasoner
           Bayesian Latent Mixture Model                             can be represented with a projection sequence from z0 to y1
The quantum probability (QP) model requires inference on             for situations F and H, where no causal effect exists.
the rotation parameters for the X and Z bases, as well as the        However, for situations A and C where the value of Z = 1 (a
projection orders for each participant. We propose a                 common causal effect is known to exist), the projection
hierarchical Bayesian latent mixture model to infer these            sequence should include a final projection from the X vector
parameters, which allows us to account for individual                to y1, accompanied by ensuring that the rotation for the X
differences systematically, and build in a hyper-parameter           basis is significantly more than the rotation for the Z basis
for latent classification of participants between causal and         (ideally, also greater than π/4 to ensure that x0 has a higher
associative reasoning. The latent classification is built by         level of association with y1 than x1 does to reflect
specifying a different set of priors for specific projection         discounting). It should be noted that the causal reasoners
orders and rotation parameters.                                      identified in the cluster analysis in Rehder (2014) were not
   Parameters θZ and θX represent the rotation of the Z and X        ideal causal reasoners, and although they demonstrated
bases from the standard Y basis. Recollect that if the               normative behavioral patterns for the most part, there were
rotation θZ < π/4, then p(y1|z1) > p(y0|z1), and that p(y1|z1)       also some patterns of deviations. These deviations were
> p(y1|z0). Thus, θZ is modeled hierarchically with a probit         more salient in the common effect structure.
transformation and scaled to span [0, π/4]. This range                  To identify individual differences, we do not impose these
reflects the assumption that participants learn the causal           strict restrictions on causal reasoners (indeed, very few
structure of the networks (i.e. that z1 has a causal influence       participants, if any, would demonstrate alignment to the
on y1), and it is unlikely that they will reverse the implied        strictest criteria). Rather, we allow the model to flexibly
structure. The rotation θX is modeled with a prior range of          account for all types of behavior ranging from highly
[0, π/2]. Recollect that if the rotation θX = π/4, then there is     normative to highly associative. For each structure, we then
no causal influence of X. That is, p(y1|x1) = p(y1|x0) and           identify aspects of the model that potentially differentiate
p(y1|x1) = p(y0|x1). We allow θX to vary on both sides of            causal and associative reasoners along this continuum.
π/4, thus allowing individuals to construct positive and                Under the common cause network, we propose that
negative causal influences.                                          situation C reflects a unique situation where z1 and x0
   All hyper-parameters are separately modeled for causal            suggest a potential conflict (although not normatively) if the
and associative categories, and a latent classification              causal structure is assumed to be deterministic. Note that in
parameter (γi) is used to build a mixture model that                 this experimental paradigm, situation F with z0 and x1 does
classifies each individual into a causal or associative              not represent as strong a conflict since causal influence is
category. The binary projection orders for situations A, C, F        unidirectional. Similarly, for the chain network structure,
and H are modeled as Bernoulli processes, with the                   situation F represents a potentially conflicting situation if a
Bernoulli prior (α) for each being dependent on the causal           deterministic causal influence from X (value x1) to Z (value
structure type and the latent classification. The latent             z0) is expected, but does not occur. While multiple
classification parameter is itself modeled as a Bernoulli            experiments ensured that deterministic and probabilistic
process with equal prior probability of classification to            versions of causal influence were tested, differences in
causal or associative categories.                                    behavior across these experimental conditions were not
   The latent classification mechanism works because the             significant. Additionally, even probabilistic causal influence
model infers the projection orders that best explain the             under situation C in the common cause and situation F in
observed data, and since different orders are given different        the chain network would reflect some form of conflict as
priors under each category (causal and associative), it              measured against the expected direction of causal influence.
selects the category that provides the highest posterior                In our model, we use these potential sources of conflict to
probability for the best projection order. We examine this           model the latent classification between causal and
mechanism in greater detail below. First, we describe how            associative reasoners. Participants who are more likely to
behavior similar to the normative prescriptions of a classical       process X last under situation C in the common cause and
                                                                 1592

under situation F in the chain network are more likely to be         from 90% to 95%) and provides a significantly better fit
classified as associative reasoners. Note that this mechanism        compared to the baseline normative CGM model even for
is not necessary to provide a good fit to the data, but only         the causal reasoners. The QP model yielded an MSE of 0.01
for adding the latent classification mechanism to the model.         against 0.045 for the normative CGM model.
   For the common effect structure, the projection orders are
not envisaged to affect the classification, which is                          Table 3: Model Comparison and Performance
determined solely by the inferred rotation of the X and Z
bases. This is achieved by considering a partition of the                                             DIC (lower is better)
prior space for θX, with a prior space range of [θZ, π/2] for        Causal Structure                 QP         Normative CGM
causal reasoners (reflecting the fact that causal reasoners          Common Cause (CC)               1470             1936
will not hold a higher association between the two causes            Chain (CH)                      1547             1998
than between the cause and the effect) and [0, π/4] for              Common Effect (CE)              1641             2366
associative ones (reflecting the fact that associative                                                     Correlation
reasoners will hold some positive association between the                                          (model prediction and data)
two causes, leading to anti-discounting behavior). The prior         Structure / Reasoning            QP         Normative CGM
space for θZ itself is modeled through separate hierarchical         CC – Causal                     92.6              77.2
distributions. Thus, the inference mechanism decides on a            CC – Associative                93.4              31.2
latent classification to the causal category if the resulting        CH – Causal                     93.3              75.9
posterior for θX biased towards values higher than θZ                CH – Associative                93.6              30.7
provides a better account of the data. Implementing these            CE – Causal                     90.3              52.5
biases in the projection order for situations C and F in the         CE – Associative                95.0              16.0
common cause and chain structures respectively, and in the
rotation parameters for the common effect structure as                 A Bayes factor (BF) analysis was carried out using the
partitions of the prior space, enables the latent classification     product space method (Lodewyckx, Kim, Lee, Tuerlinckx,
mechanism to categorize participants as causal or                    Kuppens, & Wagenmakers, 2011). The analysis was
associative reasoners depending on which prior space                 inconclusive for 178 of the 315 participants since the BF in
provides the best posterior predictions.                             favor of the QP model for these participants ranged between
                                                                     1/5 to 5. No participants had a BF > 5 in favor of the CGM
              Modeling the empirical data                            model while 137 participants had a BF > 5 in favor of the
We fit the model to the mean choice proportions for the 20           QP model, of whom 103 had a BF > 100, showing a
inference questions for each of the 315 participants by              significant preference for the QP model.
estimating parameters to the quantum probability model
using the Bayesian inference model described above. A                         Explaining Individual Differences
version of the normative causal graphical model (CGM)                  The latent classification mechanism provided a Bayes
suggested in Rehder (2014) was also used to fit the data             Factor comparing the evidence for each individual being a
within a similar Bayesian inference framework. Figure 3              causal versus associative reasoner. Based on classifying a
shows the mean choice proportions (i.e., the number of               participant in a category if the BF > 1 in favor of that
times a situation was judged to provide stronger inferential         category, the model identified 265 of the 315 participants
support for the presence of the unknown target variable)             (84%) in accordance with the classification provided in the
made by the participants (empirical), compared to the                original study (Rehder, 2014). The model classified 32% of
posterior predictive choice proportions generated by the best        the participants as associative (as compared to 23% in the
fitting QP and normative CGM models. Table 3 summarizes              original study) without being provided any details about the
the performance of these models.1                                    base rate. Individual differences in the parameter space were
   The posterior predictive mean choice proportions are used         thus successful in identifying cognitive differences. We
to calculate the correlation with the actual data and the mean       discussed how projection orders can explain order effects
square error (MSE). The Bayesian modeling framework                  and specifically, violations of the causal Markov condition.
allows us to capture the deviance information criteria (DIC)         The projections orders for situations C and F in particular,
that assess both model fit and complexity, and use Bayes             for the common cause and chain conditions, were
Factors to compare the QP and normative CGM models at                instrumental in the latent classification process. The
an individual level. As shown in Table 3, the QP posterior           posterior samples from the model shows that for the
predictions show an excellent correlation to empirical data          common cause structures, causal reasoners were inferred to
across network structures and types of reasoners (ranging            make a final projection from Z onto y1 84% of the time and
1
                                                                     associative reasoners only 12% of the time for situation C.
    Overall the models and measured deviance show good               Similarly, for situation F under the chain structure, causal
convergence (R < 1.1), however examining the three individual
level parameters across 315 participants shows that the MCMC
                                                                     reasoners were inferred to make the normative projection
chains show poor convergence (R > 1.1) for about 0.8% of the         from Z to y1 77% of the time, and associative reasoners
individual estimates.                                                only 33% of the time. The more frequent projection from X
                                                                 1593

to y1 (67%) for the associative reasoners suggests that the            within a hierarchical Bayesian inference framework allowed
potentially conflicting signal provided by X in these                  us to develop such a latent classification model with a high
situations was not disregarded, as would be suggested by the           level of accuracy as well as compute Bayes factors to
causal Markov condition.                                               compare the QP model to a baseline CGM model. Future
                                                                       work will involve implementing more sophisticated CGM
                                                                       and Bayes net models into a similar framework so that these
                                                                       can explicitly be tested against the QP model.
                                                                                           Acknowledgments
                                                                       The authors thank Bob Rehder for sharing his data. PKM
                                                                       and JST were supported by NSF grant SES-1326275.
                                                                                                References
                                                                       Fernbach, P. M., & Rehder, B. (2013). Cognitive shortcuts
                                                                         in causal inference. Argument and Computation, 4 (1),
                                                                         64-88.
                                                                       Fernbach, P. M., & Sloman, S. A. (2009). Causal learning
                                                                         with local computations. Journal of Experimental
                                                                         Psychology: Learning, Memory, and Cognition, 35, 678-
                                                                         693.
                                                                       Hagmayer, Y., & Waldmann, M. R. (2002). A constraint
                                                                         satisfaction model of causal learning and reasoning. W. D.
                                                                         Gray & C. D. Schunn (Eds.), Proceedings of the twenty-
                                                                         fourth annual conference of the cognitive science society
                                                                         (p. 405-410). Mahwah, NJ: Erlbaum.
                                                                       Hausman, D. M., & Woodward, J. (1999). Independence,
                                                                         invariance, and the causal markov condition. British
                                                                         Journal for the Philosophy of Science, 50 (521-583).
                                                                       Koehler, J. J. (1996). The base rate fallacy reconsidered:
                                                                         Descriptive, normative, and methodological challenges.
                                                                         Behavioral and Brain Sciences, 19 (1), 1-17.
    Figure 3: Mean and SD of the mean choice proportions               Lodewyckx, T., Kim, W., Lee, M. D., Tuerlinckx, F.,
   (Normative: Bars indicate best fit normative CGM; Line plots          Kuppens, P., & Wagenmakers, E. J. (2011). A tutorial on
  indicate normative prescriptive predictions independent of data)       Bayes factor estimation with the product space method.
                                                                         Journal of Mathematical Psychology, 55(5), 331-347.
   Individual differences in the common effect structures              Park, J., & Sloman, S. A. (2013). Mechanistic beliefs
arise primarily due to differences in the inferred rotation              determine adherence to the markov property in causal
parameters. The mean of the posterior samples for the                    reasoning. Cognitive Psychology, 67 (4), 186-216.
rotation parameters was θX = 54° and θZ =43° for causal                Rehder, B. (2014). Independence and dependence in human
reasoners and θX = 23° and θZ = 27° for associative                      causal reasoning. Cognitive Psychology, 72, 54-107.
reasoners. Note that the rotations do not reveal the direction         Rottman, B. M., & Hastie, R. (2014). Reasoning about
of causality but the strength of the bidirectional association           causal relationships: Inferences on causal networks.
between the variables (lower rotation implies higher                     Psychological Bulletin, 140 (1), 109-139.
associative strength). Thus, the significantly lower inferred          Trueblood, J. S. & Pothos, E. M. (2014). A quantum
value for θX for associative reasoners signifies the increased           probability approach to human causal reasoning. P. Bello,
influence of x1 (as the projected value from x1 to y1                    M. Guarini, M. McShane, & B. Scassellati (Eds.),
increases), which in situation A would lead to anti-                     Proceedings of the 36th Annual Conference of the
discounting behavior as empirically observed. The higher                 Cognitive Science Society. (pp. 1616-1621). Austin, TX:
inferred value of θX (specifically, greater than π/4) for                Cognitive Science Society.
causal reasoners implies discounting, since any projection             Waldmann, M. R., Cheng, P. W., Hagmayer, Y., &
from x1 to y1 would have a much smaller amplitude.                       Blaisdell, A. P. (2008). Causal learning in rats and
                                                                         humans: A minimal rational model. N. Chater & M.
                          Conclusion                                     Oaksford (Eds.), The probabilistic mind. Prospects for
We showed how a QP model can account for violations of                   bayesian cognitive science. Oxford: University Press.
normative properties observed in a causal reasoning task,
and how its parameters of the model could be interpreted
from a cognitive perspective. Implementing a QP model
                                                                   1594

