                          Eye Movements Reveal Sensitivity to Sound Symbolism
                                           Early and Late in Word Learning
                                             Kate Pirog Revill (krevill@emory.edu)
                                 Facility for Education and Research in Neuroscience, 36 Eagle Row
                                                        Atlanta, GA 30322 USA
                                              Laura L. Namy (lnamy@emory.edu)
                                               Department of Psychology, 36 Eagle Row
                                                        Atlanta, GA 30322 USA
                                            Lynne C. Nygaard (lnygaar@emory.edu)
                                               Department of Psychology, 36 Eagle Row
                                                        Atlanta, GA 30322 USA
                              Abstract                                many languages and cultures (Bremner et al., 2013) and
                                                                      across development (Maurer et al., 2006). These types of
  Although the relationship between sound and meaning in
  language is arbitrary, reliable correspondences between sound       reliable correspondences between sound and meaning have
  and meaning have been found in natural language. These              been dubbed sound symbolism.
  sound symbolic relationships affect word learning, but less is        Correspondences between phonological form and
  known about how sound symbolism affects online processing           grammatical or semantic class have been shown to facilitate
  during learning or for well-learned stimuli. We use the visual      spoken sentence and word processing (Farmer, Christiansen
  world paradigm and an artificial lexicon featuring carefully        & Monaghan, 2006; Reilly et al, 2012). These
  controlled sound symbolic correspondences to examine the
  effects of sound symbolism on the online processing of novel
                                                                      correspondences have also been found to benefit learning.
  and well-learned stimuli. Initially, participants chose novel       For example, Nygaard et al. (2009) taught native English
  shapes matching the sound symbolic properties of the word           speakers the Japanese translations of English antonyms.
  above chance, reliably fixating consistent shapes around word       Learners responded more quickly and accurately when the
  offset. As learning approached ceiling, accuracy and reaction       Japanese words were paired with their true English
  time differences between matching and mismatching stimuli           equivalents during training than when they had been paired
  disappeared but a disadvantage in the online processing of          with a mismatched meaning. However, to date, little work
  mismatching stimuli persisted in the form of lagging target
  fixations. This suggests that sound symbolism affects the           has examined the consequences of sound-to-meaning
  online processing of spoken stimuli even for well-learned           correspondences for online processing during word learning
  words.                                                              or for the subsequent lexical access of well-learned words.
                                                                      To address this question, we use the visual world paradigm
   Keywords: sound symbolism; eyetracking; visual world
   paradigm; artificial lexicon                                       in which fixation duration and latency on the visual referent
                                                                      of a word and its competitors can be used as implicit
                          Introduction                                measures of real-time lexical processing (Creel, Tanenhaus,
                                                                      & Aslin, 2006; Revill, Tanenhaus, & Aslin, 2008).
Despite the apparent arbitrariness of the relationship                  If sound symbolism facilitates online lexical and semantic
between words and their meanings, both historical and                 processing, listeners should more rapidly fixate potential
recent evidence suggests that non-arbitrary correspondences           referents when the objects possess visual characteristics
between linguistic structure and categories of meaning exist          consistent with the sound symbolic auditory features of the
in natural language, and that language users are sensitive to         words. This study investigates the extent to which visual
these correspondences (Köhler, 1947; Maurer et al., 2006;             orienting to objects is influenced by the sound symbolic
Nygaard et al, 2009; Ramachandran & Hubbard, 2001;                    characteristics of novel labels, both at initial presentation
Revill et al., 2014; Sapir, 1929). For example, Maurer,               and as learning approaches ceiling. More specifically, we
Pathman, and Mondlock (2006) found that both adults and               investigated the effects of sound symbolic mappings when
children (2.5-year-olds) readily associated nonwords such as          sound properties match (e.g., round labels paired with
‘maluma’ and ‘bouba’ with round, amoeboid shapes and                  rounded objects) or mismatch (e.g., round labels paired with
words such as ‘kiki’ and ‘takete’ with sharp, spiky shapes            pointy objects) listeners’ off-line judgments. We used an
(see also Köhler, 1947; Ramachandran & Hubbard, 2001).                artificial lexicon paradigm in which language users acquired
Similarly, Sapir’s (1929) classic study demonstrated that             a novel lexicon by learning label-object pairings over the
adults reliably judged the nonword ‘mal’ to refer to large            course of a brief training session (e.g., Revill et al., 2008).
objects and the nonword ‘mil’ to refer to small objects.              An artificial lexicon allows us to precisely manipulate the
These sound-to-shape biases have been demonstrated across
                                                                  1967

correspondence between the auditory or linguistic properties       Materials
of object labels and the visual properties of object referents     During training, participants learned to pair 24 novel CVCV
in order to evaluate the role of sound to meaning                  word forms with 24 unfamiliar shapes. Both the verbal and
correspondences in processing.                                     visual stimuli were drawn from a larger set of stimuli
                                                                   previously normed by a separate group of participants (List,
                                                                   2014; McCormick et al., 2015). All pseudowords were
                 Materials & Methods                               recorded by a female speaker of American English and were
                                                                   edited into separate files and amplitude normalized for
Participants                                                       presentation. From this set, we selected eight novel words
Twenty four members of the Emory University community              that had been previously rated as highly ‘rounded’ (on
took part in the study (8M/16F, age 21.7±3.5). Data from           average, 9.8% of 34 norming participants selected ‘pointy’
two participants were excluded due to failure to comply            in a 2AFC task), eight that were highly ‘pointy’ (92.4%
with task instructions, and eyetracker malfunction resulted        selected ‘pointy’), and eight showing no evidence of sound
in the loss of eyetracking data from one additional                symbolism (50.0% selected ‘pointy’). Although ‘bouba’ and
participant, leaving N=22 for accuracy and reaction time           ‘kiki’ were not among the stimuli, we refer to the words
analyses and N=21 for eyetracking analyses. All participants       rated to sound highly rounded as ‘boubas’ and the words
were native English speakers (n=17) or early bilingual (n=4)       rated as pointy-sounding as ‘kikis’ since these words are
English speakers for whom English is the dominant                  canonically associated with the sound-to-shape matching
language (the pattern of results reported here did not differ      paradigm. Words that lacked a strong shape selection bias
reliably when these 4 participants' data were removed). All        are termed ‘nonsymbolic’. Phonemic transcriptions of the
participants had normal hearing and normal or corrected-to-        full list of pseudoword stimuli appear in Table 1. Average
normal vision and no history of language or learning               word duration was 558ms and did not differ among bouba,
disabilities.                                                      kiki, and nonsymbolic categories (F(2, 21) = 2.14, p > .1).
                                                                     Shape stimuli consisted of 24 line drawings of abstract
                                                                   rounded and angular shapes with 4-6 protuberances drawn
                                                                   from a larger set of abstract shapes previously rated for
                                                                   roundedness/pointiness by a separate group of 34
                                                                   participants. Twelve of the shapes had previously been rated
                                                                   as highly rounded (mean rating 2.1 on a Likert scale where
                                                                   1 = very rounded and 7 = very pointy) and twelve as highly
                                                                   pointy (mean rating 5.7). Four of each of the shape stimuli
                                                                   were paired with words that had a matching sound symbolic
                                                                   bias (rounded shapes  bouba words, pointy shapes  kiki
                                                                   words), four with mismatching words (rounded shapes 
                                                                   kiki words, pointy shapes  bouba words), and four of each
                                                                   with nonsymbolic words, for a total of eight match, eight
                                                                   mismatch, and eight nonsymbolic stimuli. To control for
                                                                   possible learnability biases, six different stimulus lists were
                                                                   created with different word-shape pairings, with individual
                                                                   words and shapes rotating through conditions.
                                                                                       Table 1: Word Stimuli
                                                                     Round-Biased          Pointy-Biased          Nonsymbolic
                                                                        “boubas”               “kikis”
                                                                           bubo                  kɛte                 bɛde
                                                                           gubu                  piki                  sefi
                                                                            lʊlu                 tɛpi                dʒuzo
                                                                           mʊnu                 fItʃe                 tʃufo
                                                                           bugu                  kiti                 tʃɛse
                                                                           lomu                 pIke                   leni
      Figure 1. Screen layouts for the (A) 2AFC pretest                   mumo                   teki                 gɛgi
                  and (B) 4AFC test blocks.                                nʊlo                  tite                 sotʃu
                                                               1968

Procedure                                                          category as the target, and two distracters from the opposite
Participants were seated comfortably in front of the display       shape category, so that two rounded and two pointy shapes
screen with their chins in a chinrest at a viewing distance of     were onscreen during every trial. After 250ms, participants
60cm. Stimulus presentation was controlled by E-Prime 2.0.         heard the name of one of the displayed shapes and used the
Visual shape stimuli subtended 5.5 degrees of visual angle.        mouse to click on the shape that they thought had been
Spoken stimuli were presented over Sennheiser HD280 Pro            named. No trial-by-trial feedback was given during test
headphones at a comfortable listening volume. Eye                  blocks, though participants were given a score (e.g. 18/24
movements were monitored using a table-mounted Eyelink             correct) at the end of each test block. Each word was
1000 eyetracker (SR Research). A nine-point calibration            presented once per test block, and each shape appeared four
was performed before beginning the experiment and drift            times per test block; once as the target, once as a same-
correction was performed before the start of each eyetracked       shape distracter, and twice as an opposite shape distracter.
test block. See Figure 1 for examples of the stimulus
displays during the pretest and test blocks.                                                  Results
                                                                   Full analysis of the data from the training and initial testing
Pretest Following eyetracker calibration, participants             blocks is beyond the scope of this report; here we focus on
completed 24 trials in a 2AFC pretest. Participants clicked        data from the pretest and final two test blocks. Linear and
on a central fixation cross to begin each trial. Two shape         logistic mixed effects models were used to analyze reaction
stimuli (one round, one pointy) appeared on the screen.            time and choice/accuracy data respectively (Jaeger, 2008)
After 250ms, participants heard the name of one of the             using R (v3.1.1) and lme4 (v1.1-7). Maximal random effects
displayed shapes and used the mouse to click on the shape          (random effects of subject on the intercept and slope) were
that they thought had been named, which ended the trial. No        included in all models. Fixations and saccades were
feedback was provided during the pretest block. Participants       automatically detected by the Eyelink software and
were instructed that guessing was fine and that they should        combined into gazes starting from the beginning of a
just listen to the word and decide which shape they thought        saccade to the end of the subsequent fixation. Only signal-
it named.                                                          driven fixations (i.e., gazes beginning 200ms after the onset
   Participants heard each word once during the pretest. The       of the spoken word to account for eye movement planning)
“correct” shape, i.e., the shape that would be paired with the     are shown.
word during training, was one of the two shape options
available; the other item was pseudorandomly drawn from            Pretest
the opposite shape category so that one round and one              Participants showed clear sensitivity to the sound symbolic
pointy shape was present on each trial and each shape              properties of the pseudowords during the initial pretest.
appeared onscreen twice during the pretest block (once as          Shape choice was strongly associated with the sound
the target and once as a distracter stimulus.)                     symbolic properties of the word, with participants choosing
                                                                   round shapes after hearing a ‘bouba’ word 69% of the time
Training Following the pretest, participants completed             and choosing a pointy shape 73% of the time after a ‘kiki’
sixteen interleaved blocks of training and testing. Each of        word. These tendencies mean that prior to any training,
the eight training blocks consisted of 48 2AFC trials. On          participants chose the ‘target’ shape that would be learned
each trial, two shapes were displayed on the screen. After         during training on 73% of match trials, 31% of mismatch
250ms, participants heard the name of one of the displayed         trials, and 52% of nonsymbolic trials. Including a fixed
shapes and used the mouse to click on the shape that they          effect of word category (match/mismatch/nonsymbolic) in
thought had been named. Regardless of whether they                 the model significantly improved the model fit (χ2 (2) =
selected the correct or incorrect choice, the incorrect shape      19.2, p < .001) over the baseline model which contained
disappeared and the correct shape remained on screen for           only a fixed effect of intercept and had random effects of
1000ms while its name was repeated.                                subject on the intercept and category slope term. Reaction
   Participants heard each word twice during each training         times during the pretest were not significantly affected by
block. Each shape was presented four times during each             word category whether sorted by eventual match status
training block, twice as the target stimulus and twice as a        (RTmatch = 1350ms, RTmismatch = 1384ms, RTnonsymbolic =
distracter stimulus. Unlike the pretest block, there was no        1419ms, χ2 (2) = 0.71, p > .1) or sound structure (RTbouba =
requirement that both a rounded and a pointy shape appear          1357ms, RTkiki = 1367ms, RTnonsymbolic = 1419ms, χ2 (2) =
on each trial so participants had to decide between two            0.35, p > .1). Thus the best fitting reaction time model
rounded or two pointy shapes half the time to make the             contained only an intercept term in the fixed effects along
visual discrimination more challenging.                            with random effects of subject on both the intercept and
                                                                   slope (category or match) term.
Testing A test block occurred immediately after each of the           Participants’ eye movements during pretest were also
eight training blocks. Each of the eight testing blocks            affected by the sound symbolic properties of the word. The
consisted of 24 4AFC trials. Four shapes appeared on each          difference in fixation proportions between the target and the
trial: the target shape, one distracter from the same shape        distracter shape was calculated for match, mismatch, and
                                                               1969

                                                                      intercept and had random effects of subject on the intercept
                                                                      and category slope term. Contrast analysis suggests that this
                                                                      effect is carried by a slight accuracy advantage for the
                                                                      nonsymbolic items over the mismatch items (b = -0.063, SE
                                                                      = 0.023, pnorm_approx = .024), with match items intermediate
                                                                      and not significantly different from either.
                                                                         Analysis of reaction times also suggested an advantage
                                                                      for nonsymbolic items (1699ms) relative to match (1971ms)
                                                                      and mismatch items (2018ms), with inclusion of word
                                                                      category as a regressor significantly improving model fit
                                                                      (χ2(2) = 6.2, p < .05) over a baseline model which contained
                                                                      only a fixed effect of intercept and had random effects of
                                                                      subject on the intercept and category slope term and contrast
                                                                      analysis showing faster reaction times for nonsymbolic
                                                                      items relative to both match (b = 271.4, SE = 128.4,
                                                                      pnorm_approx = .034) and mismatch items (b = 318.4, SE =
                                                                      159.0, pnorm_approx = .045). Importantly, reaction times for
                                                                      matching and mismatching items did not differ (b = 47.0, SE
     Figure 2. Pretest fixation proportion difference curves          = 178.5, pnorm_approx = .8).
  (target – distracter). Mean word offset is 558ms; mean RT              Although participants’ behavioral responses to match and
  ~1400ms. For display purposes, data has been binned into            mismatch items no longer differed by the end of training, a
           100ms windows. Error bars indicate SEM.                    disadvantage for mismatching word/shape pairings is still
                                                                      apparent in the eye movement data. Figure 3 shows target
nonsymbolic words without regard to the final click                   fixation proportions beginning 200ms after the onset of the
decision; all trials were included, whether they ended in the         word for matching, mismatching, and nonsymbolic stimuli.
participant correctly guessing the target stimulus or clicking        Only data from trials where the participant ultimately
on the distracter shape, since the participant had no basis for       selected the correct shape are shown. We fit a four-
knowing which were the correct pairings during the pretest            parameter logistic function to each subject’s average
block. Mean fixation proportions were calculated across the           fixation proportion curve for the match, mismatch, and
time window extending from 200ms after word onset (the                nonsymbolic conditions following methods described by
first signal-driven fixations) to 1400ms (the average RT              McMurray & colleagues (McMurray et al., 2010; Farris-
across conditions). Single sample t-tests were used to                Trimble et al., 2014). The four parameters include lower and
determine whether the difference in fixation proportions              upper asymptotes (representing baseline and peak fixations),
between the target and distracter significantly differed from         the crossover point (the timepoint where the function’s rate
zero; i.e., if participants showed a significant bias in looking      of change is maximal), and the slope at that timepoint. The
to either target or distracter shapes. As seen in Figure 2,           resulting parameter estimates for each combination of
participants showed a strong bias to fixate shapes consistent         subject and condition were analyzed in separate ANOVAs.
with the sound symbolic properties of the spoken word. In
the match condition, participants fixated the sound
symbolically consistent target shape more than the distracter
shape (Mmatch_difference = 0.15, t(22) = 5.28, p < .01). They
also preferred the shape consistent with the sound symbolic
properties of the word in the mismatch condition, fixating
the sound symbolically consistent distracter shape more than
the target (Mmismatch_difference = -0.14, t(22) = -3.19, p < .01).
Importantly, the difference in fixations between target and
distracter items was not significant for the nonsymbolic
stimuli (Mnonsymbolic_difference = 0.07, t(22) = 1.51, p > .1).
Final Test
By the final two test blocks, participants were approaching
ceiling performance on the 4AFC task with high accuracy in
all conditions (Mmatch = 91%, Mmismatch = 87%, Mnonsymbolic =
93%). However, inclusion of word category in the accuracy               Figure 3. Fixations to target items in final 4AFC test block
model marginally improved model fit (χ2 (2) = 4.9, p = .09)             for correct trials only. For display purposes, data has been
over a baseline model which contained only a fixed effect of              binned into 100ms windows. Error bars indicate SEM.
                                                                  1970

We found a significant main effect of condition on the
function’s slope parameter (F(2, 40) = 4.83, p < .05).
Pairwise comparisons show a lower slope (slower rate of
increase in fixations to the target) for the mismatch
condition relative to both the match (t(20) = 3.1, p < .01)
and nonsymbolic (t(20) = 2.92, p < .01) conditions, which
do not differ from each other (t(20) = 0.01, p > .1). The
upper asymptote and the crossover point parameters were
not significantly affected by condition. The lower asymptote
was artificially constrained to be zero by the choice to
include only signal driven fixations and was therefore not
analyzed.
                          Discussion
As expected, participants encountering novel words for the
first time showed a consistent bias in pairing unfamiliar
sound symbolic stimuli with novel shapes, matching bouba-
like words to shapes with curved contours and kiki-like              Figure 4. Reaction time and accuracy data for all 4AFC test
words to shapes with sharp edges at above-chance rates.              blocks. Only results of Q4 block are reported in detail here.
This effect was apparent in the pretest block both in                                 Error bars indicate SEM.
participants’ choices and in their eye movements. A clear
bias to fixate shapes consistent with the sound symbolic            properties of the word relative to both matching and
properties of the words began to emerge approximately               nonsymbolic stimuli. This suggests the sound symbolic
700ms after word onset. Given the mean duration of the              properties of the word were still affecting online processing
word stimuli and the roughly 200ms it takes to plan and             of well-learned stimuli. That this effect manifested as a
launch a saccade, this suggests that these effects emerge           disadvantage for mismatching word-shape pairings rather
rapidly, near word offset and several hundred milliseconds          than an advantage for matching pairings at the end of
before participants give an overt behavioral response.              training suggests that concordance between sound and
Words without sound symbolic properties were not                    meaning may facilitate early but not later stages of learning
associated with particular types of shapes, with participants’      whereas interference from discordant sound to meaning
overt responses at chance and no significant bias evident in        mappings persists. Indeed, examination of accuracy and
their eye movements.                                                reaction time data from earlier testing blocks (Figure 4)
   These findings are consistent with past studies in our lab       suggests that participants are initially slower and less
and others' and provide a mechanism by which sound                  accurate in pairing shapes that mismatch the sound symbolic
symbolic properties of a word affect word learning.                 properties of the word, though further exploration of sound
Prepotent biases to associate particular sounds with                symbolic effects over the entire timecourse of learning is
particular meanings increased the likelihood of a learner           beyond the scope of this report. Future experiments will be
making the correct word-to-meaning mappings in these                needed to determine whether these effects persist
cases, and words with more sound-to-meaning systematicity           indefinitely with overlearned stimuli or whether the eye
appear to have an earlier age of acquisition (Monaghan et           movement effects are learning-specific and are only present
al., 2014). However, there has been little evidence that            because accuracy, while high, may not yet have reached
sound symbolism continues to impact lexical processing of           asymptote for all participants.
words that are well-learned (Kunihira, 1971; Nygaard et al.,           One unexpected result that emerges from the final testing
2009). One possibility is that behavioral measures like             blocks is the advantage for nonsymbolic stimuli over
accuracy and reaction time are not sensitive enough to              matching and mismatching stimuli in both accuracy and
detect subtler effects that might occur during online               reaction times late in learning. This was unexpected given
processing of the well-learned stimuli. Indeed, by the end of       previous research showing a learning advantage for sound
training in the current study, participants achieved around         symbolic stimuli. However, a closer examination of the
90% accuracy across all conditions with little evidence that        word materials in Table 1 suggests that the nonsymbolic
whether the sound symbolic properties of the word matched           stimuli in this experiment may be more phonologically
or mismatched the physical properties of the referent               distinct from each other than items within the ‘bouba’ or
affected either accuracy or reaction time, despite the fact         ‘kiki’ stimulus groups, as the eight nonsymbolic stimuli
that at pretest, learners had exhibited a strong bias to choose     contained combinations of 10 consonants and 5 vowels
shapes with matching properties. However, participants’ eye         while each of the groups of sound symbolic stimuli drew
movements exhibited a persistent processing disadvantage            from a set of only 5 consonants and 3 or 4 vowels. Words
for mismatching stimuli, with a significantly slower latency        with sparser phonological neighborhoods are recognized
to fixate targets that mismatched the sound symbolic                faster and more accurately than words from denser
                                                                1971

neighborhoods (Luce & Pisoni, 1998), which may explain               comprehension. Proceedings of the National Academy of
the nonsymbolic advantage seen here. Future work will need           Sciences, 103, 12203-12208.
to control for the phonological makeup of the nonsymbolic          Farris-Trimble, A., McMurray, B., Cigrand, N., & Tomblin,
stimuli as well as the symbolic stimuli to ensure                    J. B. (2014). The process of spoken word recognition in
approximately equal neighborhood densities. Nevertheless,            the face of signal degradation. Journal of Experimental
initial exposure to the nonsymbolic stimuli during the               Psychology: Learning, Memory, and Cognition, 40, 308-
pretest confirms that there were no sound symbolic biases            327.
facilitating learning from the words designated as                 Jaeger, T.F. (2008). Categorical data analysis: Away from
nonsymbolic, and examination of Figure 4 suggests that this          ANOVAs (transformation or not) and towards logit mixed
effect emerges late in learning, with no advantage for               models. Journal of Memory and Language, 59, 434–446.
nonsymbolic words in the first half of training. Further,          Köhler, W. (1947). Gestalt psychology (Second Edition).
direct comparison of the match and mismatch stimuli late in          New York: Liveright.
learning reveal an effect of congruence of sound and               Kunihira, S. (1971). Effects of the expressive voice on
meaning on visual fixation independent of performance on             phonetic symbolism. Journal of Verbal Learning and
the nonsymbolic items.                                               Verbal Behavior, 10, 427-429.
   Non-arbitrary correspondences between the sound of a            List, S. M. (2014). The sound of shape: Functional and
novel word and the shape of a potential referent appear to           neural correlates of sound to shape mapping in natural
promote an initial pairing between the word and referent             language. (Unpublished honors thesis). Emory University,
that may speed the learning process. Here we demonstrate             Atlanta.
that this initial bias can also be seen in participants’ eye       Luce, P. A. & Pisoni, D. B. (1998). Recognizing spoken
movements, a rapid and implicit measure of online                    words: The neighborhood activation model. Ear and
processing. Furthermore, eye movements show evidence for             Hearing, 19, 1-36.
a continued cost when there is a mismatch between sound            Maurer, D., Pathman, T., & Mondloch, C. J. (2006). The
and shape late in learning, even when the effect is no longer        shape of boubas: Sound-shape correspondences in
evident in accuracy or reaction time measures. This effect           toddlers and adults. Developmental Science, 9, 316-322.
appears to emerge during or immediately following the              McCormick, K., Kim, J. Y., List, S., & Nygaard, L. C.,
presentation of the spoken word and is resolved by the time          (2015). Sound to meaning mappings in the Bouba-Kiki
an overt behavioral response is made, emphasizing the                effect. Proceedings of the 37th Annual Conference of the
importance of the availability of online, continuous                 Cognitive Science Society, Pasadena, CA.
measures of processing. This technique may therefore prove         McMurray, B., Samelson, V. M., Lee, S. H., Tomblin, J. B.
useful for examining the subtler effects of sound symbolism          (2010). Individual differences in online spoken word
in natural or well-learned language stimuli and in situations        recognition: Implications for SLI. Cognitive Psychology,
where an explicit judgment from the participant may be               60, 1-39.
difficult to obtain due to task, strategy, or participant age.     Monaghan, P., Shillcock, R. C., Christiansen, M. H., &
                                                                     Kirby, S. (2014). How arbitrary is language?
                    Acknowledgments                                  Philosophical Transactions of the Royal Society B, 369,
We thank Kelly McCormick, Christina Tzeng, and Sara List             20130299.
for sharing their sound and shape stimuli and norming data,        Nygaard, L. C., Cook, A. E., & Namy, L. L. (2009). Sound
and to the Dilks lab for eyetracker access. Laura Namy's             to meaning correspondences facilitate word learning.
effort on this project was supported by the National Science         Cognition, 112, 181-186.
Foundation. Any opinions, findings, and conclusions                Ramachandran, V. S., & Hubbard, E. M. (2001).
expressed in this material are those of the authors and do not       Synaesthesia - A window into perception, thought and
necessarily reflect the views of the National Science                language. Journal of Consciousness Studies, 8, 3-34.
Foundation.                                                        Reilly, J., Westbury, C., Kean, J., & Peelle, J.E. (2012).
                                                                     Arbitrary symbolism in natural language revisited: When
                                                                     word forms carry meaning. PLoS ONE, 7, e42286.
                         References                                Revill, K.P., Namy, L.L., DeFife, L.C., & Nygaard, L.C.
Bremner, A. J., Caparos, S., Davidoff, J., de Fockert, J.,           (2014). Cross-linguistic sound symbolism and crossmodal
   Linnell, K. J., & Spence, C. (2013) “Bouba” and “Kiki” in         correspondence: Evidence from fMRI and DTI. Brain &
   Namibia? A remote culture make similar shape-sound                Language, 128, 18–24.
   matches but different shape-taste matches to Westerners.        Revill, K. P., Tanenhaus, M. K., & Aslin, R. N. (2008).
   Cognition, 126, 165-172.                                          Context and spoken word recognition in a novel lexicon.
Creel, S.C., Tanenhaus, M.K., & Aslin, R.N. (2006).                  Journal of Experimental Psychology: Learning, Memory,
   Consequences of lexical stress on learning an artificial          and Cognition, 34, 1207-1223.
   lexicon. Journal of Experimental Psychology: Learning,          Sapir, E. (1929). A study in phonetic symbolism. Journal of
   Memory, and Cognition, 32, 15-32.                                 Experimental Psychology, 12, 225-239.
Farmer, T.A., Christiansen, M.H., & Monaghan, P. (2006).
   Phonological typicality influences on-line sentence
                                                               1972

