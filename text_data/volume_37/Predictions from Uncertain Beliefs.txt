                                             Predictions from Uncertain Beliefs
                                Samuel G. B. Johnson1, Thomas Merchant2, & Frank C. Keil1
                        (samuel.johnson@yale.edu, thomas_merchant@brown.edu, frank.keil@yale.edu)
                        1
                          Dept. of Psychology, Yale University, 2 Hillhouse Ave., New Haven, CT 06520 USA
 2
   Dept. of Cognitive, Linguistic, and Psychological Sciences, Brown University, 190 Thayer St., Providence, RI 02912 USA
                             Abstract                                   Anderson (1991) argued that people follow this principle
   According to probabilistic theories of higher cognition,
                                                                        in category-based prediction. That is, when estimating the
   beliefs come in degrees. Here, we test this idea by studying         likelihood that an object has a feature, people consider the
   how people make predictions from uncertain beliefs.                  various possible categorizations of that object, and then
   According to the degrees-of-belief theory, people should             weight the conditional probability of the feature given
   take account of both high- and low-probability beliefs               those categories by the probability of each category.
   when making predictions that depend on which of those                   But people usually do not consider all possible
   beliefs are true. In contrast, according to the all-or-none          categorizations of an object, but focus on the single most
   theory, people only take account of the most likely belief,
   ignoring other potential beliefs. Experiments 1 and 2 tested         likely category (Murphy & Ross, 1994). In our example,
   these theories in explanatory reasoning, and found that              people would ignore the possibility that the object is a
   people ignore all but the best explanation when making               skunk, and ‘round up’ the rabbit probability to 100%:
   subsequent inferences. Experiment 3A extended these                     P(Z)= P(Z|A)P(A) + P(Z|B)P(B) = (.8)(1) + (.02)(0) =.8
   results to beliefs fixed only by prior probabilities, while          That is, people only consider the conditional probability
   Experiment 3B found that people can perform the                      of a new feature given the most likely category, as though
   probability calculations when the needed probabilities are
                                                                        they believe that the object must belong to that category.
   explicitly given. Thus, people’s intuitive belief system
   appears to represent beliefs in a ‘digital’ (true or false)             This result has been found consistently across many
   manner, rather than taking uncertainty into account.                 studies. For example, Murphy and Ross (1994) presented
                                                                        participants with exemplars belonging to categories of
   Keywords: Explanation; abduction; causal reasoning;
                                                                        drawings by different children, which varied in color and
   belief; prediction; diagnosis; probability; uncertainty.
                                                                        shape. Participants were then told about a new exemplar
                                                                        (e.g., a triangle), and asked to categorize it. Because the
                          Introduction
                                                                        training exemplars included 5 triangles, of which 3 were
Our beliefs often entail other beliefs. Knowing an object’s             drawn by the same child (Bob), virtually all participants
category helps us to make predictions about that object                 responded that the new triangle was likely drawn by Bob
(Anderson, 1991; Murphy, 2002). If a furry object is a                  (with about 60% confidence). Participants then predicted
rabbit, it might hop; if it’s a skunk, it might smell.                  the color of the new exemplar. Participants based these
Likewise, causal beliefs facilitate predictions (Waldmann               predictions only on the distribution of colors within the
& Holyoak, 1992). If the house is smoky because Mark                    most likely category (Bob), as though the 60% chance of
burned the cookies, then we have an unpleasant dessert to               the exemplar belonging to that category had been
look forward to; if it’s smoky because Mark dropped a                   ‘rounded up’ to 100%. That is, people relied only on the
cigarette in the bed, then we may have bigger problems.                 single best categorization, ignoring the 40% chance that
   However, beliefs are often accompanied by uncertainty.               the exemplar belonged to a different category.
If we see a furry object from a distance, we may be only                   These findings may be unique to categorization.
70% confident that it is a rabbit rather than a skunk; if we            Categories are discrete representations (Dietrich &
are awoken from a nap by smoke, we may think there is a                 Markman, 2002)—an object is a rabbit or a skunk, not
20% chance that the house is burning down. In such cases                both. This basic underlying logic of categorization may
of uncertain beliefs, accurate inference about those                    account for people’s reluctance to entertain multiple
beliefs’ consequences requires these possibilities to be                possible categorizations, in which case we would not
weighted and combined. This can be done using the tools                 expect similar results in other cognitive domains.
of probability theory. Here, we test whether people use                    However, beliefs might be represented in an all-or-none
probabilities to represent beliefs as coming in degrees, or             (‘digital’) manner not only in categorization, but across
whether people might instead use shortcuts, representing                cognition. Such a result would be surprising from the
beliefs as though they are either true or false.                        standpoint of probabilistic theories of cognition (e.g.,
   Imagine there is a 70% chance that the furry object is a             Oaksford & Chater, 2009). On a common philosophical
rabbit (possibility A), and a 30% chance that it is a skunk             interpretation of probability, the purpose of probabilities
(B). What is the probability that it will hop (Z)? Suppose              is to reflect ‘degrees of belief’ (Jeffrey, 1965)—indeed,
80% of rabbits hop, while only 2% of skunks hop. That is:               some philosophical theories hold that only logical
     P(A) = .70, P(B) = .30, P(Z|A) = .80, P(Z|B) = .02.                tautologies should be assigned a probability of 1, and only
Then the probability of hopping (Z) can be calculated as:               logical contradictions a probability of 0 (Kemeny, 1955).
   P(Z)= P(Z|A)P(A) + P(Z|B)P(B) = (.8)(.7) + (.02)(.3) =.6             If people do not represent beliefs in degrees (as ‘graded’),
                                                                 1003

                                                                 (effects X and Y), the juga snails explanation (A) would be
                                                                 more compelling than the conjunctive scuta plus aspera
                                                                 snails explanation (B and C combined), even though
                                                                 either explanation could account for the data. Thus, we
                                                                 would expect participants to infer the simple explanation
                                                                 (A), given that they are told that X and Y are observed.
                                                                    To see whether people would make subsequent
                                                                 inferences that ignored the possibility that the complex
                                                                 explanation was true, participants learned about another
                                                                 effect, bacteria proliferation (Z), which occurs with
                                                                 different probabilities, depending on the cause. In the
                                                                 low/low condition, this effect had a low probability
                                                                 regardless of the cause (underlining not in original):
 Figure 1: Causal structure used in all experiments.                When a lake has juga snails [A], it occasionally has
 White indicates a variable that was observed, and                    bacteria proliferation [Z].
      grey indicates a variable that is unknown.                    When a lake has both scuta snails [B] and aspera snails
                                                                      [C], it occasionally has bacteria proliferation [Z].
                                                                 The high/low condition was like the low/low condition,
this poses serious difficulties for claims that people           except that P(Z|A) remained high while P(Z|B,C) was low:
perform Bayesian updating using normative principles.               When a lake has juga snails [A], it usually has bacteria
   In the current experiments, we tested whether people               proliferation [Z].
make predictions from uncertain beliefs in an all-or-none           When a lake has both scuta snails [B] and aspera snails
or a graded manner. We followed the logic of the Murphy               [C], it occasionally has bacteria proliferation [Z].
and Ross (1994) experiments, but rather than categorizing        Since participants would infer that A is the best
objects, participants either inferred causal explanations        explanation, we would expect a difference between the
from observations (Experiments 1 and 2) or inferred the          low/low and high/low conditions in judgments of P(Z),
most likely possibility given base rates (Experiment 3).         reflecting the higher value of P(Z|A). Finally, the low/high
   Participants learned about causal systems with the            condition was the reverse of the high/low condition, with
structure depicted in Figure 1. That is, two explanations        a low value of P(Z|A) and a high value of P(Z|B,C):
(A and B) could account for some data (X), and these                  When a lake has juga snails [A], it occasionally has
explanations had different implications for some novel                   bacteria proliferation [Z].
prediction (Z). We structured the problems so that                    When a lake has both scuta snails [B] and aspera
explanation A would be seen as more probable than                        snails [C], it usually has bacteria proliferation [Z].
explanation B. We tested whether people rely only on A           If participants ignore the possibility that the complex
or instead consider both A and B, by varying the                 explanation is true (effectively placing 100% of their
conditional probability of Z given each explanation [i.e.,       confidence in the simple explanation), then we would
P(Z|A) and P(Z|B)]. If people integrate across all possible      expect no difference between the low/low and the
explanations, both manipulations should have an effect on        low/high conditions in ratings of the likelihood of Z, since
judgments of P(Z). In contrast, if people rely only on the       the conditional probability given the conjunctive
most likely explanation, then manipulating P(Z|B) should         explanation would be irrelevant. Conversely, if they
have no effect at all on P(Z).                                   weight all possible explanations in a normative manner
                                                                 (Anderson, 1991), then they should differentiate between
                      Experiment 1
                                                                 the low/low and low/high conditions.
In Experiment 1, we relied on people’s known preference
for simple explanations (Lombrozo, 2007). Other things           Method
being equal, people prefer to explain data with one cause
                                                                 We recruited 120 participants from Amazon Mechanical
rather than two causes. Thus, we expected that when a
                                                                 Turk for Experiment 1; 8 were excluded from analysis
simple and complex explanation can both account for a
                                                                 because they incorrectly answered more than one-third of
set of observations, people will make subsequent
                                                                 a set of true/false check questions.
inferences as though only the simple explanation were
                                                                    Each participant completed three items—one each in
possible. For example, participants learned about a simple
                                                                 the low/low, high/low, and low/high conditions. For the
ecosystem in a lake (letters in brackets not in original):
                                                                 snail item, participants first read about the effects of A, B,
   Juga snails [A] cause lakes to lose sculpin fish [X] and
                                                                 and C on X and Y, using the above wording. They then
     lose crayfish [Y].
                                                                 read about the effects of these causes on Z, with either the
   Scuta snails [B] cause lakes to lose sculpin fish [X].
                                                                 above low/low, high/low, or low/high wording. Next,
   Aspera snails [C] cause lakes to lose crayfish [Y].
                                                                 participants indicated their favored explanation:
Thus, if a lake had lost both sculpin fish and crayfish
                                                            1004

                                                                             Judgments of P(Z)
     Crescent Lake has a loss of sculpin fish [X] and                                            70
     crayfish [Y]. Which do you think is the most
     satisfying explanation for this?
                                                                                                 60
Participants answered this question as a forced-choice
between “Crescent Lake has juga snails” [A] and                                                                 Exp. 1
                                                                                                 50
“Crescent Lake has scuta snails and aspera snails” [B and                                                       Exp. 2
C]. Finally, participants were asked to rate the probability
of Z (“What do you think is the probability that Crescent                                        40
Lake has bacteria proliferation”) on a scale from 0 to 100.                                              high/low       low/low       low/high
   Three vignettes were used (snails, bacteria, and fungus),                                                        P(Z|A) / P(Z|B,C)
and condition (low/low, high/low, or low/high) was
balanced with vignette using a Latin square. Items were                                               Figure 2: Results of Experiments 1 and 2.
completed in a random order, and all questions for each                     explanation was true when estimating P(Z).
item appeared on the same page.                                               These results suggest that, just as in category-based
                                                                            prediction (Murphy & Ross, 1994), people base
Results and Discussion                                                      predictions from uncertain explanations off of only their
  Most participants (78 out of 112) preferred the simpler                   preferred explanation, ignoring the possibility that other
explanation for all three items. Because our hypotheses                     explanations could be correct. This is a flagrant violation
are predicated on the assumption that participants inferred                 of probability theory, as all possible explanations must be
the simple explanation, we focus on these participants’                     weighted in making subsequent inferences (Anderson,
responses in analyzing the results of all experiments.                      1991). Indeed, such behavior seems to defeat the very
However, the results of all experiments are similar if all                  point of probabilistic inference, which is to allow for
participants are included who passed the check questions.                   degrees of belief rather than all-or-none acceptance of
  Figure 2 shows the mean estimates of P(Z), across the                     propositions (Jeffrey, 1965).
three conditions. When both the simple explanation and                        However, two aspects of this experiment might be
the complex explanation corresponded to a low                               cause for concern. First, we obtained participants’
probability of Z (it “occasionally” leads to Z) in the                      explanatory ratings as a forced-choice, perhaps creating
low/low condition, mean judgments were 50.74 (SD =                          some experimenter demand to focus on the explanation
23.63). But when the simple explanation instead                             the participant selected. Although Murphy and Ross
corresponded to a high probability of Z (it “usually” leads                 (1994) found similar results regardless of whether
to Z) in the high/low condition, mean judgments were                        participants were asked to categorize the exemplar, this is
much higher [M = 71.69, SD = 18.27; t(77) = 7.27, p <                       nonetheless a reasonable concern about this experiment.
.001, d = 0.82, BF10 > 1000]1. Thus, manipulating the                         Second, participants may have thought that the simple
P(Z|A) had a dramatic effect on judgments of P(Z). This                     explanation was so much more probable than the complex
result is consistent with either graded or digital beliefs,                 explanation that they were right to ignore the complex
since A was the single best explanation for the data.                       explanation in estimating the probability of Z. That is,
  Much more surprisingly, however, manipulating                             suppose participants thought there were a 99% chance of
P(Z|B,C) had no effect on the perceived probability of Z:                   A, and a 1% chance of B and C (this is not so
There was no difference between the low/low condition                       unreasonable, since Lombrozo, 2007 found a very strong
and the low/high condition [M = 48.53, SD = 21.06; t(77)                    simplicity bias, exceeding what is normatively
= -0.80, p = .43, d = -0.09, BF01 = 8.18]. That is, those                   appropriate). In that case, the contribution of P(Z|A)
participants who (reasonably) believed that the simple                      should be 99 times greater than that of P(Z|B,C), and our
explanation was more likely than the complex explanation                    experimental set-up may not be sufficiently sensitive to
reasoned as though the simple explanation were certain                      detect such a small effect of P(Z|B,C).
and the complex explanation were impossible:
Participants ignored the possibility that the complex                                                           Experiment 2
                                                                            In Experiment 2, we avoided these concerns by asking
1
                                                                            participants to estimate the probability of A [P(A|data)]
  Because null effects were predicted for some comparisons, all             and of B and C [P(B,C|data)] rather than making a forced
t-tests in this paper are accompanied by Bayes Factor (BF)
analyses (Rouder, Speckman, Sun, Morey, & Iverson, 2009),
                                                                            choice between the two explanations. First, this avoided
with a scale factor of 1. BFs can quantify evidence either against          experimenter demand to focus only on one explanation,
or in favor of a null hypothesis. When the evidence favors the              and, if anything, would seem to encourage participants to
alternative hypothesis, we denote this ‘BF10’, and when the                 weight both explanations. Second, this measurement
evidence favors the null hypothesis, we denote this ‘BF01’. For             allowed us to determine how much larger the effect of
example, “BF10 = 7.0” means that the data would be 7 times                  P(Z|A) should be, relative to the size of P(Z|B,C), and to
likelier under the alternative than under the null, while “BF01” =          compare performance to this normative benchmark.
4.0” means that the data would be 4 times likelier under the null
than under the alternative.
                                                                     1005

Method
We recruited 120 participants from Amazon Mechanical                 To further rule out this possibility, we can also compare
Turk for Experiment 2; 6 were excluded because they               each participant’s estimate of P(Z) to a normative
incorrectly answered more than one-third of the check             standard, calculated from that participant’s own
questions, and 12 because their total probability ratings         probability ratings of P(A), P(B,C), and P(Z). We included
for at least one item were not between 80% and 120%.              all 102 participants who passed the check questions in this
   The procedure for Experiment 2 was the same as                 analysis. Normatively, P(Z) can be calculated as:
Experiment 1, with two changes. First, rather than asking               P(Z) = P(Z|A)P(A) + P(Z|B,C)P(B,C)
which explanation participants favored as a forced-choice,        Since we used verbal labels (“occasionally” and
they were asked to rate the probability of each                   “usually”) rather than precise probabilities, we must use
explanation given the evidence [i.e., P(A) and P(B,C)],           an indirect method to calculate predicted values of P(Z).
and were instructed to ensure the probabilities added up to       From the high/low and low/low conditions, we estimated
100%. Second, the question about the probabilities of the         each participant’s implicit probability difference between
explanations was asked on one page, then the question             “usually” and “occasionally” (M = 9.33, SD = 38.04).
about the probability of Z was asked on a separate page.          This allowed us to calculate how large the difference
This change was made to avoid demand for consistency              between the low/high and low/low conditions should be.
across the two sets of questions. The probability                 Participants’ difference scores between the low/low and
information was repeated at the top of both pages.                low/high conditions were substantially smaller than these
                                                                  normative values, derived from their other ratings [M =
Results and Discussion                                            5.80, SD = 23.85 for the difference between actual and
                                                                  normative judgments; t(101) = 2.46, p = .016, d = 0.24,
Most participants (72 out of 102) rated P(A) at least as          BF10 = 1.43]. This analysis of individual participants thus
high as P(B,C) for all items. Among those participants,           corroborates the overall pattern of means, indicating that
the mean estimate of P(A) was 65.88 (SD = 16.33) and the          participants underweighted (in fact, did not weight at all)
mean estimate of P(B,C) was 34.06 (SD = 16.30). Thus,             the complex explanation in estimating P(Z).
despite their belief that the simpler explanation was more
probable, participants allocated substantial probability to
                                                                                 Experiments 3A and 3B
the complex explanation.
   Nonetheless, the results of Experiment 2 were similar to       In our final experiment, we aimed to test whether people
those of Experiment 1 (Figure 1). Participants gave higher        would underweight the probability of any unlikely belief
estimates of P(Z) in the high/low than in the low/low             in making subsequent inferences, or whether this effect
condition [M = 70.60, SD = 18.62 vs. M = 60.24, SD =              was confined to explanatory inferences (such as causal
22.66; t(71) = 3.41, p = .001, d = 0.40, BF10 = 18.85],           and category-based reasoning). Thus, instead of
though this effect is about half as large, compared to            manipulating the probability of two competing beliefs (A
Experiment 1. This difference appears to be due to task           and B) by varying their plausibility as explanations (e.g.,
demands, although it is not clear whether it is a demand in       by making A a simple explanation and B a complex
Experiment 1 to focus more on P(Z|A), or a demand in              explanation), we instead manipulated the base rates of A
Experiment 2 to focus less on P(Z|A), relative to a               and B, by asserting that A had a 65% chance of being true
condition in which participants did not make any explicit         while B had a 35% chance (the same base rates for A and
judgments about the explanations. In any case, however,           B that people gave for the simple and complex
this result is robust across both tasks, and the true effect      explanations in Experiment 2). If participants’ beliefs are
size likely lies somewhere in the middle.                         ‘digital’ only when they must infer a category or cause,
   Most critically, there is once again no difference             then they would rely on both P(Z|A) and P(Z|B) when
between the low/low condition and the low/high condition          making subsequent inferences about Z. But if any two
[M = 59.31, SD = 23.23; t(71) = -0.33, p = .74, d = -0.04,        incompatible beliefs are resolved in a digital fashion (so
BF01 = 10.22]. Thus, once again, while participants were          that either A or B is believed all-or-none), then
happy to use P(Z|A) in estimating the probability of Z,           participants would continue to ignore P(Z|B) in estimating
they completely ignored P(Z|B,C). This occurred even              P(Z). We tested this in Experiment 3A.
though participants indicated that there was about a one-            A second goal was to ensure that participants were not
third chance that explanation A was true.                         making normative errors simply because they are
   Could these results be driven by the assumption that the       incapable of performing the mathematics. Thus,
causes are not mutually exclusive? That is, perhaps               Experiment 3B gave participants all four numbers needed
participants are assuming that A could have occurred              to calculate P(Z) [i.e., P(Z|A), P(Z|B,C), P(A), and P(B,C)].
along with combinations of B and C, in which case the             If participants make more normative inferences here, it
evidence is a much better signal for A than for B and C.          would suggest that participants know that the likelihood
However, this explanation is untenable in light of                of Z given low-probability beliefs is relevant, but do not
participants’ explicit ratings of the explanations, which         use it spontaneously when forced to perform a task
indicated considerable credence in the B,C explanation.           without the benefit of complete probability information.
                                                             1006

Method                                                                                     70
                                                                       Judgments of P(Z)
We recruited 120 participants from Amazon Mechanical
Turk for Experiment 3A, and a different group of 119                                       60
participants for Experiment 3B; 5 were excluded because
                                                                                           50
they incorrectly answered more than one-third of the
check questions (2 and 3 from Experiments 3A and 3B,                                                   Exp. 3A
                                                                                           40
respectively), and 9 because their total probability ratings                                           Exp. 3B
for at least one item were not between 80% and 120% (6                                     30
and 3 from Experiments 3A and 3B, respectively).                                                  high/low      low/low         low/high
   Rather than manipulating participants’ inferences using                                                   P(Z|A) / P(Z|B)
simplicity, participants in Experiment 3A were simply
told the prior probability of each cause. They first read                                   Figure 3: Results of Experiments 3A and 3B.
about the probability of Z given either cause A or cause B.
For example, in the low/low condition, participants read:                importantly, however, estimates of P(Z) in the low/high
     When a lake has Juga snails [A], it occasionally has                condition were no higher than in the low/low condition
        bacteria proliferation.                                          and were, if anything, somewhat lower [M = 60.71, SD =
     When a lake has Scuta snails [B], it occasionally has               21.02; t(90) = -1.78, p = .078, d = -0.19, BF01 = 2.58].
        bacteria proliferation.                                          That is, once again, people did not take into account the
The high/low and low/high conditions differed as in                      possibility of the low-probability alternative (B) when
Experiments 1 and 2 (changing “occasionally” to                          estimating P(Z). This result suggests that people adopt
“usually” either for A or B, respectively). Next,                        beliefs in an all-or-none manner not only when the belief
participants were told the prior probabilities of the causes:            is the result of a categorization or a causal inference, but
     Crescent Lake has a 65% chance of having Juga                       even if the belief is determined by prior probability alone.
     snails and a 35% chance of having Scuta snails.                        These results stand in contrast to those of Experiment
These probabilities were adjusted across the three                       3B. This experiment differed from Experiment 3A only in
vignettes to match the probabilities of the simple and                   giving precise values of P(Z|A) and P(Z|B), so that
complex explanations obtained empirically in Experiment                  participants could in principle calculate P(Z) exactly.
2. Then participants were asked to rate the probability that             Here, participants differentiated not only between the
the lake had each kind of snail, just as in Experiment 2.                high/low and the low/low conditions in their ratings of
Finally, participants rated the probability of Z, using the              P(Z) [M = 64.75, SD = 17.63 vs. M = 34.33, SD = 27.90;
same scale as Experiments 1 and 2. Counterbalancing and                  t(71) = 11.81, p < .001, d = 1.39, BF10 > 1000], but also
randomization were the same as in Experiments 1 and 2.                   gave higher estimates of P(Z) in the low/high condition
   Experiment 3B was identical to Experiment 3A, except                  [M = 47.99, SD = 23.36; t(71) = 4.88, p < .001, d = 0.58,
that the conditional probabilities were also numerically                 BF10 > 1000]. Thus, people are aware that the
specified. Specifically, the word “occasionally” was                     probabilities of lower-probability beliefs are relevant.
always followed by the parenthetical “(about 20% of the                  They simply do not spontaneously use those probabilities
time)” and the word “usually” was always followed by                     if they are not given explicitly in the problem.
the parenthetical “(about 80% of the time).”                                This difference between Experiments 3A and 3B was
                                                                         also evident when we compared participants’ responses to
Results and Discussion                                                   normative benchmarks. We used the same strategy as in
                                                                         Experiment 2 to calculate, based on each participant’s
Figure 3 plots the results for both Experiments 3A and                   other probability ratings, how large that participant’s
3B. As in the other experiments, most participants rated                 difference in P(Z) ratings should be between the low/high
the probability of A higher than the probability of B for all            and low/low conditions. Whereas participants in
three items (91 out of 112 for Experiment 3A and 72 out                  Experiment 3A underutilized P(Z|B) by a substantial
of 113 for Experiment 3B). Ratings of P(A) and P(B) were                 margin [M = 8.95, SD = 21.00; t(111) = 4.51, p < .001, d
tightly clustered around the values given in the problem                 = 0.43, BF10 = 786.09], participants in Experiment 3B
(for P(A), M = 65.40, SD = 2.08 and M = 65.38, SD = 2.54                 were better calibrated and underutilized P(Z|B) to a
for Experiments 3A and 3B; for P(B), M = 34.72, SD =                     smaller degree [M = 5.09, SD = 19.87; t(112) = 2.72, p =
2.46 and M = 34.61, SD = 2.63). Thus, judgments of P(A)                  .008, d = 0.26, BF10 = 2.61].
and P(B) were very similar here to judgments of P(A) and
P(B,C) in Experiment 2.
                                                                                                       General Discussion
   For Experiment 3A, inferences about P(Z) were similar
to Experiment 2. Participants gave somewhat higher                       Do beliefs come in degrees? The current studies suggest
estimates of P(Z) in the high/low than in the low/low                    that they may not—that when making predictions from
condition [M = 71.49, SD = 19.01 vs. M = 66.04, SD =                     uncertain beliefs, those beliefs are treated as either true or
25.68; t(90) = 2.03, p = .045, d = 0.21, BF01 = 1.65],                   false, without reflecting the uncertainty that people
although this effect was surprisingly small. Most                        profess when asked explicitly. In Experiments 1 and 2,
                                                                1007

people acknowledged that a simple explanation had a                since people can simultaneously profess 65% confidence
65% chance of accounting for some observations, while a            in an explanation, but treat it in subsequent inference as
complex explanation had a 35% chance. In making                    though they are 100% confident. Thus, people may look
subsequent predictions dependent on the correct                    more or less like Bayesians depending on the nature of the
explanation, however, people ignored the lower-                    task and the associated cognitive architecture.
probability complex explanation, treating the simple                 Abductive      (data-to-explanation)    and    predictive
explanation instead as though it were certainly true. In           (explanation-to-predicted-data) reasoning are critical to
Experiment 3A, participants even ignored low-probability           diverse cognitive processes, including not just causal
beliefs when the prior probabilities were given explicitly.        reasoning and categorization, but also decision-making,
   However, when participants in Experiment 3B were                perception, and social cognition. Therefore, an important
given all relevant probability information, they were able         goal for future research will be to test whether a digital
to take low-probability possibilities into account.                belief architecture is confined to high-level cognitive
Although further work will be necessary to pinpoint the            tasks (such as causal reasoning and categorization), or
reason for this effect of task context, one possibility is         whether it might instead be a common architectural
that when all relevant probability information is given,           constraint across many cognitive domains.
participants are able to treat the inference as a math
problem rather than relying on their intuitive belief                                Acknowledgments
systems. Even if participants are unable to produce the            We thank the members of the Cognition and Development
precise Bayesian solution, they may recognize that all             Lab for helpful discussion.
four pieces of information are relevant and scale their
responses in qualitatively appropriate ways. Future
research might also examine other conditions that may
                                                                                          References
lead participants to combine multiple potential beliefs,           Anderson, J.R. (1991). The adaptive nature of human
such as priming participants with problems with two                  categorization. Psychological Review, 98, 409–429.
equally likely possibilities, where neither can be ignored.        Dietrich, E., & Markman, A.B. (2003). Discrete thoughts:
   If people represent beliefs implicitly as all-or-none,            Why cognition must use discrete representations. Mind
then why do they nonetheless profess uncertainty when                & Language, 18, 95–119.
asked explicitly? That is, why do participants not claim           Evans, J.St.B.T. (2007). Hypothetical thinking: Dual
that there is a 100% chance that the simple explanation is           processes in reasoning and judgement. New York, NY:
true, when asked explicitly? One possibility is that beliefs         Psychology Press.
such as ‘there is a 65% chance of possibility X’ can be            Fernbach, P.M., Darlow, A., & Sloman, S.A. (2011).
represented explicitly but that when we must rely on such            Asymmetries in predictive and diagnostic reasoning.
beliefs for subsequent inferences, they must be converted            Journal of Experimental Psychology: General, 140,
to the ‘digital’ format. For example, when people are                168–185.
planning what to wear during the day, they are clearly             Jeffrey, R.C. (1965). The logic of decision. New York,
able to represent explicitly the possibility that there is a         NY: McGraw-Hill.
65% chance of rain. But when they must use that belief             Kemeny, J.G. (1955). Fair bets and inductive
implicitly in subsequent reasoning (e.g., to determine               probabilities. Journal of Symbolic Logic, 20, 263–273.
whether the road will be slippery), people appear unable           Lombrozo, T. (2007). Simplicity and probability in causal
to use probabilities in a graded manner.                             explanation. Cognitive Psychology, 55, 232–257.
   This possibility is consistent with the singularity             Murphy, G.L. (2002). The big book of concepts.
principle (Evans, 2007), according to which people focus             Cambridge, MA: MIT Press.
on one possibility at a time in hypothetical thinking. For         Murphy, G.L., & Ross, B.H. (1994). Predictions from
example, when told about a cause that can lead to an                 uncertain categorizations. Cognitive Psychology, 27,
effect, people ignore other possible causes that could be            148–193.
in operation, focusing on the focal cause when estimating          Oaksford, M., & Chater, N. (2009). Précis of Bayesian
the probability of the effect (Fernbach, Darlow, &                   Rationality: The Probabilistic Approach to Human
Sloman, 2011). The current results show that people even             Reasoning. Behavioral and Brain Sciences, 32, 69–120.
neglect alternative causes in predictive reasoning when            Rouder, J.N., Speckman, P.L., Sun, D., Morey, R.D., &
one cause is merely more likely, rather than certain.                Iverson, G. (2009). Bayesian t tests for accepting and
   These results are challenging for probabilistic theories          rejecting the null hypothesis. Psychonomic Bulletin &
of cognition (Anderson, 1991; Oaksford & Chater, 2009),              Review, 16, 225–237.
in that the very purpose of probability is to reflect degrees      Waldmann, M.R., & Holyoak, K.J. (1992). Predictive and
of uncertainty (Jeffrey, 1965). Graded beliefs are critical          diagnostic learning within causal models: Asymmetries
for Bayesian updating, or modifying one’s beliefs in light           in cue competition. Journal of Experimental
of new evidence. The current results point to differences            Psychology: General, 121, 222–236.
between implicit and explicit representations of beliefs,
                                                              1008

