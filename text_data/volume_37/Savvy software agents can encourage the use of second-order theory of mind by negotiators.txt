                                Savvy software agents can encourage the use of
                                    second-order theory of mind by negotiators
                                      Harmen de Weerd, Eveline Broers, Rineke Verbrugge
                                         Institute of Artificial Intelligence, University of Groningen
                               Abstract                                     et al., 2012; Meijering et al., 2010, 2011, 2014; De Weerd
      In social settings, people often reason about unobservable            et al., 2014; Devaine et al., 2014), although participants typi-
      mental content of other people, such as their beliefs, goals,         cally need many trials before their behavior is consistent with
      or intentions. This ability helps them to understand and pre-         higher-order reasoning.
      dict the behavior of others. People can even take this abil-
      ity further, and use higher-order theory of mind to reason               In this paper, we investigate human-agent interactions in
      about the way others use theory of mind, for example in               the influential Colored Trails setting, introduced by Grosz,
      ’Alice believes that Bob does not know about the surprise’.           Kraus, and colleagues (Lin et al., 2008; Gal et al., 2010)1 ,
      However, empirical evidence suggests that people do not
      spontaneously use higher-order theory of mind in strategic            which provides a useful test-bed to study how different as-
      games. In this paper, we let participants negotiate with com-         pects of mixed-motive settings change interactions among
      putational theory of mind agents in the setting of Colored            agents and humans. In previous work in this negotiation
      Trails. We find that even though participants are unaware of
      the level of sophistication of their trading partner, within a        setting, we presented a computational model for theory of
      few rounds of play, participants offers are more indicative           mind agents to study the effectiveness of higher-order the-
      of second-order theory of mind reasoning when their trad-             ory of mind reasoning (De Weerd et al., 2013). We found
      ing partner was using second-order theory of mind as well.
                                                                            that the use of first-order and second-order theory of mind al-
   Keywords: theory of mind; social cognition; negotiation;                 lows software agents to balance competitive and cooperative
   strategic games
                                                                            aspects of the game. This way, the use of theory of mind pre-
                                                                            vents negotiations from breaking down the way they do for
                          Introduction
                                                                            agents without theory of mind. In the current paper, we use
In social settings, people reason about unobservable mental                 these agents to determine to what extent human participants
content, such as beliefs, desires, and goals, to predict and in-            reason at higher orders of theory of mind, by letting software
terpret the behavior of others. This theory of mind (Premack                agents interact directly with human participants.
& Woodruff, 1978) allows people to reason explicitly about
the goals of others, such as deciding whether the behavior of                                       Colored Trails
others is accidental or intentional. Empirical evidence from
                                                                            The game we study in this paper is a variation on the influ-
second-order false belief tasks (Perner & Wimmer, 1985;
                                                                            ential Colored Trails game. Colored Trails is a board game
Miller, 2009) reveals that people are also capable of reasoning
                                                                            designed as a research test-bed for investigating decision-
about the theory of mind of others. People use second-order
                                                                            making of people and software agents (Lin et al., 2008; Gal et
theory of mind when they reason about the beliefs others have
                                                                            al., 2010). We consider a specific setting in which two nego-
about the beliefs of yet other people, and realize that such
                                                                            tiating agents alternate in making offers. We have previously
nested beliefs can be incorrect. Second-order theory of mind
                                                                            used this setting to test the effectiveness of higher-order the-
allows people to form nested beliefs such as “Alice believes
                                                                            ory of mind in negotiations (De Weerd et al., 2013).
that Bob does not know about the surprise party”, and use
                                                                               The game is played on a square board consisting of 25 pat-
these beliefs to interpret and predict Alice’s behavior.
                                                                            terned tiles, like the one depicted in Figure 1a. At the start of
   While participants readily use second-order theory of mind
                                                                            the game, each player receives a set of four patterned chips,
reasoning in the second-order false belief task, empirical ev-
                                                                            selected at random from the same four possible patterns as
idence suggests that in strategic games, participants do not
                                                                            those on the board. Each player is initially located on the
appear to make spontaneous use of higher-order (i.e. at
                                                                            center tile of the board, indicated with the letter S in Figure
least second-order) theory of mind (Hedden & Zhang, 2002;
                                                                            1b. The goal of each player is to reach their personal goal
Camerer et al., 2004; Wright & Leyton-Brown, 2010; Goodie
                                                                            location, which is drawn randomly from the board tiles that
et al., 2012). Over a range of unrepeated single-shot games,
                                                                            are at least three steps away from the initial location (gray
Camerer et al. (2004) estimate the distribution of the level of
                                                                            tiles in Figure 1b). To move around on the board, players use
sophistication used by human participants. They find that par-
                                                                            their chips. A player can move to a tile adjacent to his current
ticipant reasoning is typically limited to the use of zero-order
                                                                            location by handing in a chip of the same pattern as the des-
or first-order theory of mind. Only few participants are found
                                                                            tination tile. Figure 1a shows an example of a Colored Trails
to be well-described as higher-order theory of mind reasoners
                                                                            board as well as a possible path across the board. A player
(Wright & Leyton-Brown, 2010). When games are repeated,
                                                                            following the path from location A to the blank tile marked B
participants can successfully adjust their level of reasoning to
accurately predict the behavior of other theory of mind rea-                    1 Also see http://coloredtrails.atlassian.net/wiki/
soners (Hedden & Zhang, 2002; Zhang et al., 2012; Goodie                    display/coloredtrailshome/.
                                                                        542

                                                                      petitive game. Since a player may need a different set of chips
                                                                      to achieve his goal than his trading partner, there may be an
                                                                      opportunity for a cooperative trade that allows both players
                                                                      to obtain a higher score. That is, although the score of a
                                                                      player does not depend on how closely his trading partner
                                                                      approaches his goal location, players can still benefit from
                                                                      taking into account the goal of their trading partner. Impor-
                                                                      tantly, however, Colored Trails is a game of imperfect infor-
                                                                      mation: while players know what chips are in possession of
                (a)                            (b)                    their trading partner, they do not know the goal location of
                                                                      their trading partner at the start of the game.
Figure 1: In Colored Trails, players spend chips to move
                                                                         In this paper, we investigate to what extent human partici-
around on a 5 by 5 board. (a) To follow the path from lo-
                                                                      pants reason using higher orders of theory of mind when play-
cation A to location B, a player needs to hand in one blank,
                                                                      ing Colored Trails with a software agent as trading partner,
one striped, and one dotted chip. (b) Each player is initially
                                                                      and to what extent participants adjust their level of theory
located on the central tile S and is assigned a goal location
                                                                      of mind reasoning in response to the behavior of their trad-
drawn randomly from the gray tiles.
                                                                      ing partner. Since simulation experiments with agents have
                                                                      shown that second-order theory of mind can help agents to
                                                                      avoid negotiation failure and balance cooperative and com-
would have to hand in one striped chip, one dotted chip, and          petitive aspects of the game (De Weerd et al., 2013), the Col-
one blank chip.                                                       ored Trails setting may facilitate theory of mind reasoning in
   Players are scored based on their success in reaching their        human participants as well.
goal location. Each player receives 50 points at the start of the
game. If the player successfully reaches his goal, he receives                   Theory of mind software agents
an additional 50 points. However, if the goal is not reached,         The theory of mind agents presented here as trading part-
10 points are deducted from the player’s score for each step          ners of human participants are adapted from De Weerd et
needed to reach the goal location. Finally, any chip that has         al. (2013) to allow for games with a known finite horizon.
not been used to move around the board is worth an additional         That is, the computational agents know that the game cannot
5 points to its owner. For example, consider the situation            last more than six turns. In this section, we describe the way
in Figure 2, and suppose that player i has goal location G.           these make use of theory of mind. The mathematical details
With his initial set of chips, player i can obtain a score of 50      of these agents can be found in De Weerd et al. (2013).
points. However, if player i would receive one of agent j’s
blank chips, he could obtain a score of 110 points.                   Zero-order theory of mind
   To get closer to their goal location, players can trade chips      A zero-order theory of mind (ToM0 ) agent is unable to reason
with their co-player. To capture the dynamic aspect of nego-          about unobservable mental content of its trading partner, in-
tiation, trading among players takes the form of a sequence           cluding its goal location. Instead, a ToM0 agent models the
of alternating offers. When a player makes an offer to re-            behavior of its trading partner in terms of the offers that the
distribute the chips a certain way, his trading partner decides       trading partner is willing to accept. Based on previous experi-
whether or not to accept this offer. If the offer is accepted,        ence in the Colored Trails game, a ToM0 agent constructs be-
the proposed distribution of chips becomes final, the players         liefs about the likelihood that certain offers will be accepted
move as close to their respective goal locations as possible,         by the trading partner. For example, over repeated games, a
and the game ends. Alternatively, the trading partner may de-         ToM0 agent will learn that the trading partner rarely accepts
cide to withdraw from negotiations, which makes the initial           offers that assign few chips to the trading partner, while of-
distribution final. As a third option, the trading partner may        fers that assign many chips to the trading partner are accepted
decide to continue the game by rejecting the current offer and        with a high frequency.
making his own offer for a redistribution of chips.                      Using these zero-order beliefs, a ToM0 agent can calculate
   There are no restrictions on the offers that players can           the expected gain of making a particular offer, and choose the
make. For example, a player is allowed to repeat an offer that        action that the agent expects to yield it the highest gain. Based
has been previously rejected by his trading partner, or make          on the actions of the trading partner, the ToM0 agent then up-
an offer that he has previously rejected himself. However, the        dates its zero-order beliefs. This way, the ToM0 agent can
game ends if six offers have been rejected. In any game, each         play Colored Trails without attributing any mental content to
player can therefore make at most three offers. If a game ends        others. In particular, although the ToM0 agent’s zero-order
because the maximum number of offers has been exceeded,               beliefs eventually reflect the desires of its trading partner, the
the initial distribution of chips becomes final.                      ToM0 agents cannot reason about such desires explicitly.
   Although a player’s score is based only on how closely he             In terms of negotiation strategies, the ToM0 agent engages
approaches his own goal, Colored Trails is not a purely com-          purely in positional bargaining (Fisher & Ury, 1981), by rea-
                                                                  543

                                                                       influence the beliefs of the trading partner about the agent’s
                                                                       goal, and select the offer that provides its trading partner with
                                                                       as much information about its goal location as possible.
                                                                          For example, suppose agent i in Figure 2 is a ToM2 agent
                                                                       with goal location G. Using second-order theory of mind,
                                                                       agent i knows that making any offer in which the striped chip
                                                                       is assigned to agent j, agent j can conclude that agent i does
Figure 2: Example of a negotiation setting in Colored Trails.          not need a striped chip to reach its goal location. This allows
Agent j offers to trade the striped chip owned by agent i              agent j to exclude many possible goal locations for agent i,
against the dotted chip owned by agent j. Since this trade             which can help agent j to make an offer that is acceptable to
would make it harder for agent i to reach his goal location            agent i. In this case, although agent i knows that agent j has
(tile G), agent i will reject this offer. The goal location of         a goal location, agent i remains unaware of what that goal lo-
agent j is not shown.                                                  cation is. A second-order theory of mind agent can therefore
                                                                       engage in interest-based negotiation (Fisher & Ury, 1981), by
                                                                       choosing its offers in such a way that they communicate the
soning only about offers and the likelihood that these offers          agent’s interests to its trading partner.
will be accepted by its trading partner.                                  Similar to the ToM1 agent, a ToM2 agent does not know the
                                                                       extent of its trading partner’s theory of mind abilities. Instead,
First-order theory of mind
                                                                       a ToM2 agent has zero-order, first-order, and second-order be-
In addition to its zero-order beliefs, a first-order theory of         liefs about the behavior of its trading partner. While negoti-
mind ToM1 agent can also determine what its own decision               ating in Colored Trails, the ToM2 agent keeps updating its
would have been if it had been in the position of its trading          beliefs concerning which of these beliefs most accurately de-
partner. This way, a ToM1 agent can consider that its trading          scribes the actual behavior of its trading partner. This means
partner has beliefs and goals similar to its own that determine        that a ToM2 agent may sometimes behave as if it were a ToM0
whether or not an offer will be accepted.                              agent, while behaving like a ToM2 agent on other occasions.
   A ToM1 agent believes that an offer will only be accepted
if it increases the score of both the agent itself and its trading                                 Methods
partner since the ToM1 agent itself would only accept offers
that increase its own score. In the same way, the ToM1 agent           Participants
realizes that its trading partner only makes offers that would
                                                                       Twenty-seven students (10 female) of the University of
increase its own score. This means that the offers made by the
                                                                       Groningen participated in this study. All participants were
trading partner contain information about its goal location.
                                                                       informed that after the conclusion of the study, the three par-
For example, consider the situation depicted in Figure 2. In
                                                                       ticipants with the highest score in the negotiation game re-
this example, agent j offers to trade its dotted chip for the
                                                                       ceived e15, e10, and e5, respectively. Each participant gave
striped chip owned by agent i. From this offer, a ToM1 agent
                                                                       informed consent prior to admission into the study.
would conclude that the striped chip allows agent j to move
closer to its goal location. Secondly, since the offered trade         Materials
would leave agent j without any dotted chips, a ToM1 agent
would believe that agent j does not need any dotted chips to           Twenty-four games were selected from a set of randomly gen-
reach its goal location. This excludes several possible goal           erated games. To ensure that these games would allow us to
locations for agent j.                                                 distinguish between different orders of theory of mind rea-
   Importantly, a ToM1 agent’s first-order theory of mind is           soning of participants, they were selected so that:
additional to its zero-order beliefs. Through repeated inter-
actions, a ToM1 agent may come to believe that first-order             • The participant’s goal could be reached with the eight chips
theory of mind fails to accurately model the behavior of its              in the game;
trading partner and that the use of zero-order theory of mind
would result in a higher score. In this case, a ToM1 agent may         • Simulations with computational agents predicted different
decide to play Colored Trails as if he were a ToM0 agent.                 outcomes for participants using zero-order, first-order, and
                                                                          second-order theory of mind; and
Second-order theory of mind
Agents capable of second-order theory of mind can also con-            • Simulations with computational agents predicted that the
sider the possibility that their trading partner is a ToM1 agent.         game would last at least two turns and at most six turns.
A second-order theory of mind (ToM2 ) agent believes that its
trading partner may be trying to interpret the offers made by          These games were divided into three blocks of eight games
the ToM2 agent to determine the ToM2 agent’s goal. This al-            each. The level of theory of mind reasoning of the software
lows the ToM2 agent to reason about the way different offers           agent was fixed within each block, and varied between blocks.
                                                                   544

Design and procedure
                                                                                                                                                    Agent's order of
                                                                                                                                                    theory of mind
Before the start of the experiment, participants were tested
                                                                                                                                                     ● Zero−order
on colorblindness. Participants were asked to distinguish                                                                                               First−order
patches of blue and orange, with four possible intensities of                                                                                           Second−order
each color. All participants passed the colorblindness test.
Next, participants played several Marble Drop games (Mei-
                                                                               Agent performance
jering et al., 2011).                                                                                                ●
                                                                                                                         ●
                                                                                                       ●
   The Colored Trails experiment consisted of a familiariza-
                                                                                                           ●
tion phase and an experimental phase. At the start of the fa-                                                           ●
                                                                                                                         ●●
                                                                                                                           ●        ●
miliarization phase, participants were asked to imagine them-                                                       ●          ●
                                                                                                                                               ●●
selves as an attorney for a major corporation. In this function,                                               ●         ●●    ●●         ●
they would be involved in a number of negotiations with dif-                                                                            ●● ●   ●
                                                                                                                        ●
ferent clients. Participants were told that their trading partner
was a computer player (Alex), which would always react on
                                                                                                   0
their offer as quickly as possible in a way it believed would
maximize its own score. To ensure understanding of the Col-                                            0
                                                                                                                   Participant performance
ored Trails game, participants answered a few questions about
the rules, scoring, and movements on the game board.
                                                                           Figure 3: Outcomes of Colored Trails per block. The solid
   In the experimental phase, participants played three blocks
                                                                           line indicates Pareto optimal outcomes. Dashed lines show
of eight games each. In each block, the participant either
                                                                           the score participants and software agents would achieve if
faced a ToM0 , ToM1 , or ToM2 agent. The order of the blocks
                                                                           they were to withdraw from negotiation in every game.
was randomized across participants. Participants were not in-
formed that the level of reasoning of the trading partner would
change over the course of the experiment, but participants
were told that they would face different clients. At the start                                                          Results
of the experiment, it was randomly decided whether the par-                Figure 3 shows the outcomes of the Colored Trails game. The
ticipant or the software agent would make the initial offer of             graph shows how the score of agents and participants changed
the first game. In subsequent games, participant and agent                 as a result of negotiation for each participant and for each
alternated in the role of initiating player.                               block. Dashed lines indicate the zero performance line, which
   Participants were allowed 60 seconds to decide on their                 is the score that players would have received if every game of
next action. During each round, the remaining decision time                the block had ended with withdrawal from negotiation. A
was presented to participants by means of a countdown timer.               score below the dashed line indicates that a player decreased
If a participant had not made a decision within 60 seconds,                its score through negotiation. As Figure 3 shows, only once a
the game continued without an offer being made, and the soft-              participant received a negative score in one of the blocks.
ware agent took its turn.                                                     The solid line in Figure 3 shows the boundary of Pareto ef-
   The zero-order beliefs of theory of mind agents were ini-               ficient outcomes. This boundary shows those outcomes for
tialized by playing 200 randomly generated Colored Trails                  which neither the participant nor the software agent could
games against another agent. This allowed agents to learn                  have received a higher score without a decrease in the score
what kind of offers were more likely to be acceptable to their             of the other player. The Pareto boundary gives an impression
trading partner. To conform to our cover story in which par-               of how well participants and software agents played Colored
ticipants were told that they would face a number of different             Trails. Participants and software agents generally negotiated
clients, the agent’s beliefs were reset to this initial value at           mutually beneficial solutions, while neither player systemat-
the start of each game. Additionally, theory of mind agents                ically exploited the other. Additionally, Figure 3 shows that
started every game reasoning at the highest order of theory                when participants negotiate with ToM2 agents, they tend to
of mind available to them. This means that although soft-                  end up closer to the Pareto optimality, while negotiations be-
ware agents learned from a participant’s offers within a sin-              tween participants and ToM1 agents typically end up far from
gle game, and adjusted their behavior accordingly, agents did              the Pareto boundary.
not exhibit any learning across games. This way, agents were                  Importantly, the use of theory of mind agents allows us to
prevented from adapting to specific participants, and every                estimate to what extent participants make use of theory of
participant faced the same agent in every scenario.                        mind while playing Colored Trails. We use a ToM3 ‘spec-
   After the Colored Trails games, participants answered a                 tator’ agent that observes the offers of a participant and de-
short questionnaire about the perceived difficulty of the task,            termines whether these offers are most consistent with zero-
the behavior of their trading partner, and the participant’s rea-          order, first-order, or second-order theory of mind reasoning.
soning strategies. In addition, participants took a test for their         The software agent constructs a confidence for each order of
interpersonal reactivity index (Davis, 1983).                              theory of mind at which it can reason to decide which order
                                                                     545

                                             0.5                                                                                points on average after negotiation when the software agent
                                                   Order of theory of mind
                                                   used by participant                                                          made the initial offer rather than when the participant was the
                                                    ● Zero−order
                                                       First−order
                                                                                                                                first to propose a trade. The only exception to this rule was
                                             0.4       Second−order                                                             that participants negotiating with a ToM2 agent ended up with
    Confidence in orders of theory of mind
                                                                                                                                a higher score when they made the initial offer themselves.
                                                                                                                                This effect can be explained by the way agents of different or-
                                             0.3                                                                                ders of theory of mind construct their offers. Both ToM0 and
                                                                                                                                ToM1 agents make offers that they believe will be accepted
                                                                                                                                by their trading partner. In contrast, ToM2 agents make offers
                                             0.2
                                                                                                                                that inform their trading partner about their own goals. As a
                                                                                                                                result, initial offers made by ToM0 and ToM1 agents are typi-
                                                                                                                                cally more favorable to their trading partner than those made
                                             0.1
                                                                                                                                by ToM2 agents. Similarly, when participants reasoned more
                                                             ●                         ●                       ●
                                                                                                                                like ToM2 agents, their initial offers were more favorable to
                                                                                                                                themselves than to their trading partner.
                                             0.0
                                                         Zero−order                 First−order
                                                                         Agent's order of theory of mind
                                                                                                           Second−order
                                                                                                                                              Discussion and conclusion
                                                                                                                                Experimental evidence suggests that participants do not make
Figure 4: Estimated similarity of participant offers to the of-                                                                 spontaneous use of higher-order theory of mind reasoning in
fers of ToM0 (red circles), ToM1 (green triangles), and ToM2                                                                    unrepeated games (Hedden & Zhang, 2002; Camerer et al.,
(blue squares) agents in each of the three blocks. Brackets                                                                     2004; Wright & Leyton-Brown, 2010; Goodie et al., 2012),
indicate one standard error.                                                                                                    though participants can successfully adjust their level of rea-
                                                                                                                                soning to accurately predict the behavior of other theory of
                                                                                                                                mind reasoners (Hedden & Zhang, 2002; Goodie et al., 2012;
of theory of mind would yield the best outcome (De Weerd                                                                        Meijering et al., 2010, 2011, 2014; Devaine et al., 2014). Sur-
et al., 2013). Each time the participant makes an offer O, the                                                                  prisingly, in this paper, we find that participants show behav-
ToM3 agent updates its confidence that this participant is us-                                                                  ior consistent with second-order theory of mind reasoning in
ing kth-order theory of mind by calculating the likelihood that                                                                 a negotiation game that lasts a few rounds only.
a ToMk agent would have made an offer similar to offer O.                                                                          In our experiments, human participants negotiated with
   For each of the three blocks, Figure 4 shows how similar                                                                     software agents that dynamically change their order of the-
participant offers were to offers of ToM0 , ToM1 , and ToM2                                                                     ory of mind reasoning in response to the behavior of their
agents, as judged by the ToM3 agent. Red circles indicate the                                                                   trading partner. We use these agent-based models to analyze
average similarity of a participant’s offers to zero-order the-                                                                 participant behavior in a dynamic setting. Our model explic-
ory of mind reasoning, green triangles indicate the similarity                                                                  itly takes into account that participants may differ in the or-
to first-order theory of mind reasoning, and blue squares show                                                                  der of theory of mind at which they reason, and that a par-
the similarity to second-order theory of mind reasoning. In-                                                                    ticipant may change the order of theory of mind at which he
terestingly, Figure 4 shows that participant offers are more                                                                    reasons over the course of a single game. Based on this agent-
similar to first-order and second-order theory of mind reason-                                                                  based analysis, we find that participants make offers that are
ing than they are to zero-order theory of mind reasoning.                                                                       more consistent with second-order theory of mind reasoning
   Figure 4 also shows that the similarity ratings of partici-                                                                  when their trading partner is capable of second-order the-
pant offers vary depending on the order of theory of mind of                                                                    ory of mind as well. Interestingly, while participants knew
the computer trading partner. Although similarity ratings for                                                                   that they would face different trading partners, they were un-
zero-order and first-order theory of mind reasoning show no                                                                     aware that these trading partners differed in their theory of
variation across different levels of sophistication of the trad-                                                                mind abilities. That is, the behavior of higher-order theory of
                2 = 0.52, ns, and X 2 = 2.67, ns, respectively),
ing partner (X(2)                   (2)                                                                                         mind agents apparently encouraged participants to make use
participant offers were significantly more similar to second-                                                                   of higher-order theory of mind as well.
order theory of mind reasoning when they were facing a ToM2                                                                        Experiments with adults typically show that individuals
trading partner (X(2)2 = 24.89, p < 0.001).
                                                                                                                                reason at low orders of theory of mind, and are slow to ad-
   Previous studies into negotiations show that the opening                                                                     just to an opponent that reasons using theory of mind (Hed-
bid of a negotiation can serve as an anchor for the entire ne-                                                                  den & Zhang, 2002; Camerer et al., 2004; Wright & Leyton-
gotiation process, making the first bid of a game especially                                                                    Brown, 2010; Goodie et al., 2012). In our setting, however,
influential in the negotiation process (Raiffa et al., 2002;                                                                    participants exhibited second-order theory of mind within a
Van Poucke & Buelens, 2002). In our experiment, the iden-                                                                       few games. It is possible that the negotiation setting, which
tity of the initiating player indeed influences negotiation out-                                                                involves both cooperative and competitive goals, emphasized
comes. In general, both players ended up with an extra 15                                                                       the social nature of the task. Such social framing has been
                                                                                                                          546

shown to encourage the use of theory of mind (Goodie et al.,           Fisher, R., & Ury, W. (1981). Getting to yes: Negotiating
2012; Devaine et al., 2014).                                             agreement without giving in. Penguin Books.
   Our results show that mixed groups of human and software            Gal, Y., Grosz, B., Kraus, S., Pfeffer, A., & Shieber, S.
agents can successfully negotiate a mutually beneficial out-             (2010). Agent decision-making in open mixed networks.
come. However, none of the negotiation outcomes in our ex-               Artificial Intelligence, 174(18), 1460–1480.
periment were Pareto efficient. That is, each participant could        Goodie, A. S., Doshi, P., & Young, D. L. (2012). Levels of
have received a higher score without reducing the score of               theory-of-mind reasoning in competitive games. Journal
their trading partner. This indicates that there is still room for       of Behavioral Decision Making, 25(1), 95–108.
significant improvement. One factor that may have limited              Hedden, T., & Zhang, J. (2002). What do you think I think
the effectiveness of negotiations in Colored Trails is the time          you think?: Strategic reasoning in matrix games. Cogni-
limit on the decisions of participants. Although participants            tion, 85(1), 1–36.
failed to make a decision before time ran out in only four oc-
                                                                       Lin, R., Kraus, S., Wilkenfeld, J., & Barry, J. (2008). Nego-
casions, it is likely that participants selected suboptimal ac-
                                                                         tiating with bounded rational agents in environments with
tions due to time constraints. Removing this time constraint
                                                                         incomplete information using an automated agent. Artifi-
in future experiments may increase negotiation performance.
                                                                         cial Intelligence, 172(6), 823–851.
   Our results suggest that computational theory of mind
agents can be used as a training tool for negotiation. When            Meijering, B., Taatgen, N. A., van Rijn, H., & Verbrugge, R.
participants negotiated with a trading partner capable of                (2014). Modeling inference of mental states: As simple as
second-order theory of mind, the outcome was generally                   possible, as complex as necessary. Interaction Studies, 15,
closer to a Pareto optimal solution than when participants               455–477.
faced less sophisticated trading partners. In addition, our re-        Meijering, B., van Maanen, L., van Rijn, H., & Verbrugge, R.
sults show that agents could benefit more from making the                (2010). The facilitative effect of context on second-order
opening bid than participants. Experience with theory of                 social reasoning. In S. Ohlsson & R. Catrambone (Eds.),
mind agents may therefore allow participants to learn to lever-          Proceedings of the 32nd annual conference of the cognitive
age the anchoring effect of the initial offer.                           science society (pp. 1423–1428).
                                                                       Meijering, B., van Rijn, H., Taatgen, N. A., & Verbrugge, R.
                     Acknowledgments                                     (2011). I do know what you think I think: Second-order
This work was supported by the Netherlands Organisation                  theory of mind in strategic games is not that difficult. In
for Scientific Research (NWO) Vici grant NWO 277-80-001,                 L. Carlson, C. Hoelscher, & T. F. Shipley (Eds.), Proceed-
awarded to Rineke Verbrugge for the project ‘Cognitive sys-              ings of the 33rd annual conference of the cognitive science
tems in interaction: Logical and computational models of                 society (pp. 2486–2491).
higher-order social cognition’.                                        Miller, S. A. (2009). Children’s understanding of second-
                                                                         order mental states. Psychological Bulletin, 135(5), 749–
                          References                                     773. doi: 10.1037/a0016854
Camerer, C., Ho, T., & Chong, J. (2004). A cognitive hier-             Perner, J., & Wimmer, H. (1985). “John thinks that Mary
   archy model of games. Quarterly Journal of Economics,                 thinks that...”. Attribution of second-order beliefs by 5 to
   119(3), 861–898.                                                      10 year old children. Journal of Experimental Child Psy-
Davis, M. H. (1983). Measuring individual differences in em-             chology, 39(3), 437–71.
   pathy: Evidence for a multidimensional approach. Journal            Premack, D., & Woodruff, G. (1978). Does the chimpanzee
   of Personality and Social Psychology, 44(1), 113–126.                 have a theory of mind? Behavioral and Brain Sciences,
Devaine, M., Hollard, G., & Daunizeau, J. (2014). The so-                1(4), 515–526.
   cial Bayesian brain: Does mentalizing make a difference             Raiffa, H., Richardson, J., & Metcalfe, D. (2002). Negotia-
   when we learn? PLoS Computational Biology, 10(12),                    tion analysis: The science and art of collaborative decision
   e1003992.                                                             making. Belknap Press.
de Weerd, H., Verbrugge, R., & Verheij, B. (2013). Higher-             Van Poucke, D., & Buelens, M. (2002). Predicting the out-
   order theory of mind in negotiations under incomplete in-             come of a two-party price negotiation: Contribution of
   formation. In G. Boella, E. Elkind, B. T. R. Savarimuthu,             reservation price, aspiration price and opening offer. Jour-
   F. Dignum, & M. K. Purvis (Eds.), Prima 2013: Princi-                 nal of Economic Psychology, 23(1), 67–76.
   ples and practice of multi-agent systems, Dunedin, New              Wright, J. R., & Leyton-Brown, K. (2010). Beyond equilib-
   Zealand, december 2013 (pp. 101–116).                                 rium: Predicting human behavior in normal-form games.
de Weerd, H., Verbrugge, R., & Verheij, B. (2014). Theory of             In Proceedings of the twenty-fourth conference on artifi-
   mind in the Mod game: An agent-based model of strategic               cial intelligence (pp. 901–907).
   reasoning. In A. Herzig & E. Lorini (Eds.), Proceedings             Zhang, J., Hedden, T., & Chia, A. (2012). Perspective-taking
   of the european conference on social intelligence (ECSI-              and depth of theory-of-mind reasoning in sequential-move
   2014) (pp. 129–136).                                                  games. Cognitive Science, 36(3), 560–573.
                                                                   547

