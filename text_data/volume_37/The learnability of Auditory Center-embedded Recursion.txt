                         The learnability of Auditory Center-embedded Recursion
                                                Jun Lai (J.Lai@tilburguniversity.edu)
          Tilburg Center for Logic, Ethics and Philosophy of Science; Tilburg Center for Cognition and Communication,
                                                     Tilburg University, the Netherlands
                                     Emiel Krahmer (E.J.Krahmer@tilburguniversity.edu)
                        Tilburg Center for Cognition and Communication, Tilburg University, the Netherlands
                                         Jan Sprenger (j.sprenger@tilburguniversity.edu)
                   Tilburg Center for Logic, Ethics and Philosophy of Science, Tilburg University, the Netherlands
                              Abstract                                    A large number of artificial grammar learning studies have
  A growing body of research investigates how humans learn              shown that statistical learning mechanisms contribute to
  complex hierarchical structures with center-embedded                  various aspects of language learning, such as word
  recursion (Bahlmann, Schubotz, & Friderici, 2008; Poletiek &          recognition, speech segmentation, etc. (Fiser & Aslin, 2002;
  Lai, 2012). Increasing evidence indicates that properties of the      Kirkham, Slemmer, & Johnson, 2002). For example,
  learning input have an impact on learning this type of                empirical research that       habituated infants to speech
  recursion. For instance, recent studies found that staged input,      sequences following a statistical pattern found that 8-month-
  fewer unique exemplars and unequal repetition facilitate
  learning (e.g. Lai, Krahmer, & Sprenger, 2014; Lai &
                                                                        old infants were able to discover the pattern based on
  Poletiek, 2011, 2013). Most of these studies investigated             transitional probabilities between adjacent elements
  learning center-embedded recursion through visual input,              (Saffran, Aslin, & Newport, 1996). The probabilistic
  whereas few studies examined the processing of auditory               information of linguistic structures, such as frequency of
  input. In the current study, we test: 1) whether participants are     occurrence, distribution of prosodic cues, or phonological
  able to learn center-embedded recursive structure from                patterns, can help learners detect regularities and improve
  exclusively auditory input; 2) whether the facilitative cues
  (ordering and frequency distribution) are attuned to the
                                                                        learning (Romberg & Saffran, 2010).
  auditory modality. Our results successfully demonstrate the             Although studies have shown that simple grammar
  learning of auditory sequences with center-embedded                   learning benefited from statistical information (Pena,
  recursion, and replicated the effect with visual input in the         Bonatti, Nespor, & Mehler, 2002), its role remains unclear
  previous study (Lai et al., 2014).                                    in processing a higher level of grammar, for example,
                                                                        center-embedded recursive grammar (Mueller, Bahlmann, &
   Keywords: auditory learning; artificial language; recursion;         Friederici, 2010). For example, “The student that the
   starting small; frequency distribution                               teacher helped improved.” is a typical center-embedded
                                                                        sentence. Due to the long distance dependencies between
                          Introduction                                  related elements, structures with center-embedded recursion
During infancy, human beings start to demonstrate amazing               are difficult to process and understand, but they are crucial
abilities of obtaining useful information from numerous                 in human language. Center-embedded recursion has been
streams of auditory signals, which appear unsystematically              proposed to be a unique structure of human language (Fitch,
in the environment. The crucial abilities enable humans to              Hauser, & Chomsky, 2005; Hauser, Chomsky, & Fitch,
encode relevant information in a temporal order, since we               2002).
do not receive all information at once (Conway &                          Previous artificial grammar learning research, which tried
Christiansen, 2005). For instance, when we listen to an                 to demonstrate the learnability of center-embedded
utterance, it is impossible to hear the whole sentence.                 recursion, provided diverging findings. Some studies
Instead, we hear word by word. In order to process all the              observed various factors that enhanced learning, such as the
information, we first need to understand the relationship               staged input facilitation (Elman, 1993; Kersten & Earles,
between segments. Statistical learning is a method to extract           2001). In a recent study, Lai and Poletiek (2011) trained
internal regularities or structural patterns from complex               participants with visual syllable sequences, generated by a
input (Romberg & Saffran, 2010).                                        hierarchical structured grammar, with the type of A(n)B(n).
  Many statistical learning studies adopt the artificial                Participants trained with staged input were compared with
grammar learning paradigm (Reber, 1967), which allows                   those trained with a random ordered input. For the staged
for investigating specific factors that affect language                 input group, participants saw artificial grammar learning
learning. It is a powerful tool to examine the cognitive                sequences in a “starting small” (SS) method, which arranged
mechanism of detecting statistical regularities from                    the input by increasing complexity. Thus, gradually,
sequences that do not have a real-world meaning.                        participants saw basic pairs with zero level of embedding
                                                                    1237

(0-LoE) first, then with one embedding (1-LoE), and two              (Holcomb & Neville, 1990). As regards to the modality
embedding (2-LoE) in the end. In the following                       difference, Glenberg and Fernandez (1988) found that the
classification test, participants were required to judge             manner of temporal coding, in terms of the order of
whether test items conformed to the same rule, which                 presentation, was more beneficial towards the auditory
governed the previous learning input. Results showed that            modality, compared to the visual modality, which relied
only the SS group was able to learn successfully and it              more on spatial senses. Moreover, the greater variability in
outperformed the random group significantly. The finding             the auditory stimuli assists people in processing
of staged input effect was supported by a follow-up study            information. For example, patterns and regulations in
(Lai & Poletiek, 2013), using a more complex form of                 rhythm (Rubinstein & Gruenberg, 1971) or in pitch (Evans
staged input. By contrast, other studies did not observe any         & Treisman, 2010) of the input yielded learning differences,
facilitation effect of incremental input (Fletcher, Maybery,         favoring the auditory modality but not the visual one. The
& Bennett, 2000; Rohde & Plaut, 1999; Rohde & Plaut,                 statistical cues helped people detect auditory patterns in a
2003).                                                               more efficient way.
  Another facilitative factor is skewed frequency                      Thirdly, with regard to the staged input effect, Conway,
distribution of input. In two experiments with visual center-        Ellefson, and Christiansen(2003) compared a starting small
embedded sequences, Lai and Poletiek (2013) found that               group with a random group under both modalities. In
learning was advanced, when the input was distributed                Experiment 1 with visual letters, the starting small group
unequally, favoring a larger number of basic exemplars (i.e.         was trained with increasing complexity (e.g. CW, CPTW,
sufficient 0-LoE learning exemplars, fewer 1-LoE ones, and           CPQMTW), whereas the random group received the same
even fewer 2-LoE ones). The frequency distribution effect            training material in a random order. In Experiment 2 with
has also been found in other aspects, such as learning of            auditory material, the same input was adopted by replacing
verbs and phrases (Casenhiser & Goldberg, 2005; Kidd,                letters with consonant-vowel-consonant syllables. Conway
Lieven, & Tomasello, 2010), long distance association in             et al. found a starting small effect for visual center-
the structures such as AXB (Gomez, 2002), and grammatical            embedded structures, but not for auditory ones. They
categorization (Mintz, 2003).                                        suggested that the lack of SS effect was due to intrinsic
  Controlling for the frequency of various levels of                 constraints of the auditory modality itself, since the auditory
embedding in the training set, Lai, Krahmer, and Sprenger            material appears in a temporal order. Note, however, that
(2014) investigated how the relative frequency of the                also Lai et al. (2014) presented the (visual) learning input
learning exemplars would affect learning center-embedded             syllable by syllable, emulating the auditory modality.
recursion. They found that the diversity of various                    Last but not the least, studies have shown that the
exemplars was not a necessity for successful learning of             probability distribution of acoustics helped participants in
visual center-embedded sequences. Instead, training of               speech perception (Clayards, Tanenhaus, Aslin, & Jacobs,
fewer unique exemplars, but with repetition, could also lead         2008). This resembles the frequency effect found by Lai et
participants to discover the complex recursive rule.                 al. (2014), but auditory stimuli were English words, instead
Moreover, the more high-frequency exemplars occurred, the            of center-embedded recursive structures. To our knowledge,
better participants learned. However, there are surprisingly         no previous research has probed into the frequency
few studies on facilitative cues, which aid in learning              distribution effect in processing auditory center-embedded
center-embedded recursion in the auditory modality. It               recursion.
deserves more attention in the field of artificial language            This paper replaces visual stimuli with auditory ones and
learning, for a number of reasons. Firstly, at the initial stage     tests two main hypotheses: 1) whether humans can learn
of life, children learn a language first and foremost via the        center-embedded recursion at all in the auditory modality,
auditory modality. Empirical studies with infants have also          and 2) whether the facilitative cues (the ordering cue and the
stressed the importance of positive auditory experiences in          frequency distribution cue) are attuned to the auditory
early brain maturation (McMahon, Wintermark, & Lahav,                modality. We test participants’ understanding and
2012). The developed auditory modality helps children with           processing of the same set of center-embedded structures,
information processing, language learning and memory                 but vary the training set. We compare learning performance
formation (Moon & Fifer, 2000).                                      under three conditions, i.e. Starting-small (SS), Starting-less
  Secondly, modality has an impact on the performance of             (SL), and Starting-high (SH), copying the design of Lai et
learning tasks (Huestegge & Hazeltine, 2011), and the                al. (2014). All conditions have the same number of training
sequential- or temporal way of presenting the input                  items (144) but differ in content. The SS condition provides
substantially determines the learning output (Conway &               an equal number of learning exemplars for each level of
Christiansen, 2005). As shown in previous research on early          complexity (0-, 1-, 2-LoE). By presenting the input
brain development, children often learn their native                 incrementally from the basic pairs to the most complex
language through the auditory modality, and refine their             ones, learning difficulty is increased gradually. Compared to
knowledge through the visual modality at a later stage               the SS group, the SL group has fewer unique exemplars
                                                                 1238

(36), which are repeated for an equal number of times (four          Figure 1(a) depicts the individual accuracies. Figure 1(b),
times each). The SH group has also 36 unique exemplars,            which shows the group mean, indicates a similar learning
which are repeated unequally, depending on the exemplars’          pattern across conditions in both auditory modality and
frequencies, which are skewed. For example, the number of          visual modality (Lai et al., 2014). A one-sample t-test
occurrences of an item is higher if this is a high-frequent        showed that all groups achieved above chance performance
item. Thus, high-frequent items appear more often than low-        significantly: MSS= .55, SESS=.01, t (23) = 3.13, p = .005, r2
frequent items. The SL and SH group both presented the             = .30; MSL= .57, SESL= .01, t (24) = 4.54, p < .001, r2 = .46;
input in a staged manner, according to the increasing              MSH= .62, SESH=.02, t (23) = 7.86, p < .001, r2 = .73. The
complexity of exemplars.                                           results suggested that these three groups succeeded in
                                                                   classifying grammatical test sequences from ungrammatical
                          Experiment                               ones, to different extent.
Method
Participants. Seventy-five students (54 female, mean age
21 year, SD 2.4) from Tilburg University participated for
course credit1. All were native Dutch speakers. Participants
had no prior knowledge about the experiment.
Materials and design. We applied the same set of syllable
sequences as in Lai et al. (2014), which applied a grammar
with the type of AnBn and generated non-sense syllable
sequences accordingly. A-syllables were [be, bi, de, di, ge,
gi] and B-syllables were [po, pu, to, tu, ko, ku]. Each A-
syllable was associated with a B-syllable according to its
consonant pair. For example, be/bi was related with po/pu,
de/di with to/tu, and ge/gi with ko/ku. Sequences consist of
two, four, or six syllables (e.g. bipo, bebepopo,
gebiditopoku). A Dutch speaker recorded all sequences.
Reading speed, pitch and intonation were held constant. The
                                                                   Figure 1(a). Scatterplot of individual accuracy. The dotted
recording time for each syllable was around 400 ms.
                                                                   line represents chance level (M= .50).
  The test set, which was the same for all groups, consisted
of 72 sequences, half grammatical and half not. The number
of sequences for each level of complexity (i.e. 0-, 1-, and 2-
LoE) was equal. Ungrammatical sequences were formed by
mismatching an A-syllable with an unrelated B-syllable (i.e.
beku).
Procedure. Participants were randomly assigned to one of
the three groups, 25 each. In the training phase, participants
were required to attentively listen to sequences of sounds.
The instruction stated that there was a rule underlying the
sounds that they heard. Every trial began with a beep,
followed by a sequence of sound, such as bebepopo. Each
sound was displayed individually. In the test phase,
participants were informed that they would hear new
sounds, some of which obeyed the same rule as that in the
previous training set, while some did not. Their task was to       Figure 1(b). Mean accuracy of all conditions in both
judge which test sounds followed the same rule. No                 auditory and visual modality (Lai et al., 2014). The dotted
feedback on answers was given during the test.                     line represents chance level (M= .50). Error bars indicate
  The whole experiment took approximately 30 minutes.              standard error of the mean.
   Results                                                           We conducted a repeated-measure analysis, with
                                                                   Condition as the between-subjects factor, Grammaticality
   1 Two of these 75 participants were excluded from the data
                                                                   and LoE as within-subjects factors. The analysis first
analysis due to interrupted termination of the experiment.
                                                               1239

indicated a main effect of Condition, F (2, 70) = 8.14, p =          .002, r2 = .33, respectively. Similarly, for the SH group,
.001, ƞp2 = .189. A post hoc Bonferroni test revealed that the       scores on 0-LoE (M= .77, SE= .03), t (23) = 9.07, p < .001,
SH group surpassed the SS group (p =.001) and the SL                 r2 = .78, and those on 1-LoE (M= .58, SE= .03), t (23) =
group (p =.021) significantly, while no significant                  2.84, p = .009, r2 = .05, were both significantly above
difference between the SS and the SL group (p = .715) was            chance level, while scores on 2-LoE (M= .53, SE= .02) did
observed.                                                            not differ from chance, t (23) = 1.13, p = .270.
   In addition, we conducted a dprime calculation, which was
consistent with the calculation on mean accuracy. It also                                      Discussion
demonstrated a main effect of condition: F (2, 70) = 7.95, p
                                                                     In the current study, we investigated the learnability of
= .001, ƞp2 = .185. The dprime scores were: d’SS= .22,
                                                                     center-embedded recursive structures in the auditory
SESS=.34, d’SL= .35, SESL=.39, d’SH= .65, SESH=.45.
                                                                     modality. We also examined whether the facilitative factors,
   The analysis further showed a main effect of
Grammaticality, F (1, 70) = 5.95, p = .017, ƞp2 = .078. The          which aided in learning visual center-embedded recursion,
general score on grammatical test sequences (M= .60, SE=             were also applicable for auditory stimuli. First, participants
.01) was significantly higher than that on ungrammatical             in the auditory modality achieved significantly better than
ones (M= .55, SE= .01), p = .017. Specifically, there was a          chance performance, independent of the relevant facilitative
main effect of Condition on ungrammatical sequences, F (2,           cue. These results markedly differ from the previous
70) = 6.06, p = .004, ƞp2 = .147, but no effect on                   findings by Conway et al. (2003). One possible explanation
grammatical ones, F (2, 70) = 2.20, p = .119. On                     is that their study used consonant-vowel-consonant
ungrammatical sequences only, the SH group (M= .62, SE=              syllables, such as “biff”, “rud”, “sig”, etc. Examples of
.02) outscored the SS group (M= .52, SE= .02), p = .007,             their auditory sequences were “biff-nep” (0-LoE), “biff-vot-
and the SL group (M= .53, SE= .02) significantly, p = .016.          cav-nep” (1-LoE), etc. There were no salient acoustic cues
                                                                     implanted in these sound sequences. Nevertheless, in the
                                                                     current design, there are inherent acoustic regularities
                                                                     underlying the sequences. The first regularity is that all A-
                                                                     syllables end with –e/-i and B-syllables end with –o/-u. The
                                                                     second pattern is that A-syllables were connected with B-
                                                                     syllables, depending on the consonant pairs. The presence of
                                                                     phonological information might assist our participants first
                                                                     to realize the categorization of A-/B-syllables, and then
                                                                     discover the relation between associated elements.
                                                                     Therefore, our results challenged the claim that the lack of
                                                                     learning center-embedded recursion through auditory input
                                                                     was due to the modality itself. Instead, it might be caused by
                                                                     lack of sufficient acoustic information indicating the
                                                                     statistical relationship.
                                                                         Secondly, we observed all three types of facilitative cues,
                                                                     i.e. staged input (SS), fewer exemplars (SL), unequal
                                                                     frequencies (SH), advanced learning center-embedded
                                                                     recursions in the auditory modality. There was no
                                                                     significant difference between the SS and the SL group, but
                                                                     the SH group surpassed these two groups significantly. In
                                                                     our experiment, the traditional SS setting is demonstrated to
Figure 2. Mean accuracy of all conditions on ungrammatical
                                                                     be useful in processing auditory center-embedded recursion.
and grammatical test sequences. The dotted line represents
chance level (M= .50).                                               Compared to the SS group, the other two groups obtained
                                                                     much fewer unique exemplars. This poverty in exemplar
  In order to pinpoint the substance of the facilitative effect,     diversity did not hinder learning. Instead, it helped
we examined the performance in different conditions at each          participants focus on the statistical properties of the
level of complexity. For the SS group, only scores on 0-LoE          relatively small set of samples. It also fits humans’ cognitive
(M= .61, SE= .02) were significantly above chance, t (23) =          processing window, which deals with segments of
4.74, p < .001, r2 = .49. This indicated that the SS manner in       information more efficiently (Christiansen & MacDonald,
the current study only helped participant make strong                2009). Furthermore, the large amount of repetition of these
associations between the basic related pairs. However, for           unique exemplars not only familiarizes participants with the
the SL group, performance on both 0-LoE (M= .64, SE=                 acquired knowledge, but also consolidates their memories
.03) and 1-LoE (M= .56, SE= 02) outperformed chance                  during learning. This indicates that a large number of
level, t (24) = 4.93, p < .001, r2 = .50, and t (24) = 3.42, p =     various exemplars might not be necessary for learning
                                                                 1240

complex center-embedded structures, even in the auditory           Christiansen (2006) suggested, statistical learning under
modality. Instead, a repetition of a smaller set of unique but     these two modalities is driven by separate subsystems and is
representative exemplars accelerates learning. For the SH          guided by different sensory mechanisms. Memory
group, the number of repetitions were unequal for exemplars        constraints and other cognitive loads might prohibit the
with different frequencies. This arrangement of unequal            processing of auditory long-distance dependencies.
repetition boosted learning, since participants were highly
familiar with the most probable and typical structure in the                                   Conclusion
grammar. The discovery of the most fundamental pairs aids          In the present study, we demonstrate for the first time that
in unpacking the complex syntactical structures.                   participants were able to learn center-embedded recursion in
   Thirdly, regarding to the grammaticality of test items, we      the auditory modality, with the assistance of staged input.
found that for all groups (SS+SL+SH), the general score on         Our results challenge the view that the modality constraints
grammatical test items was significantly higher than that on       prevented learning center-embedded recursion through the
ungrammatical ones. As Vokey and Brooks (1992) pointed             auditory modality. Furthermore, we also observed the
out, participants were likely to compare the test items with       starting small (SS), starting less (SL) and starting high (SH)
their memorized exemplars and make their judgments based           effect with auditory input: staged input and the repetition of
on similarity. Although test items are novel, the                  a smaller set of unique exemplars can promote efficient
grammatical ones follow the same underlying rule and               learning. So does the unequal number of repetition
possess higher similarity to the learning items.                   according to exemplars’ frequencies. The results of the
Ungrammatical items might have been harder to judge                current auditory study coincide with those of the previous
because of the absence of a similarity cue. Interestingly,         visual study. One possible reason is that Lai et al. (2014) did
both in visual and auditory modality, the groups did not           not use the traditional method to present visual sequences as
differ much in judging grammatical test items, However,            a whole (Conway et al., 2003; Reber, 1967). Instead, they
for ungrammatical test items in the auditory modality, the         presented the visual sequences in a temporal order, i.e.
SH group was more accurate than the other groups. This             syllable-by-syllable, to simulate the sequential order of
result is in line with the finding of Lai et al. (2014) for the    auditory stimuli.
visual modality. A possible explanation is that the unequal          Our findings shed light on how statistical information of
number of repetition fits an efficient way of cognitive            the input contributes to learning complex syntactical
processing, by giving prominence to the most representative        structure in the auditory modality. We manipulated three
structures.                                                        factors, i.e. staged input, repetition of exemplars, and
  Lastly, in accordance with the previous study with visual        unequal distribution in the statistical learning task. These
input (Lai et al, 2014), our results revealed that when the        three manipulations highly resemble a child-directed speech
complexity of auditory input increased, the accuracy of            environment, which contains a large amount of simple
grammaticality judgment decreased. The only difference is          structures but fewer complex sentences. Especially, the
that the study with visual input found the performance of the      utterances are constantly repeated, for an unequal number of
SH group on 0-, 1-, 2-LoE items were all significantly better      times (Snow, 1972). Further testing is worthwhile to verify
than chance. However, with auditory input, the SS group            the validity of auditory facilitation effect in natural language
only scored significantly better than chance on 0-LoE,             learning.
whereas the SL and the SH group achieved better than
chance performance on 0-, and 1-LoE, but not on 2-LoE.                                      References
This suggests that the successful learning of these two
                                                                   Bahlmann, J., Schubotz, R.I., & Friederici, A.D. (2008).
groups was not merely due to the recognition of basic
                                                                     Hierarchical artificial grammar processing engages
exemplars (0-LoE), but also due to accurate judgments of
                                                                     Broca’s area. Neuroimage, 42(2), 525-534.
more complex structures with embedding (1-LoE), though             Casenhiser, D., & Goldberg, A. E. (2005). Fast mapping
the most complex ones (2-LoE) seem too difficult for                 between a phrasal form and meaning. Developmental
learning within such a short exposure. The results indicated         Science, 8(6), 500-508.
that with auditory stimuli, the SS regimen might only              Christiansen, M. H., & MacDonald, M. C. (2009). A Usage-
advance learning at the basic level, i.e. the fundamental            Based Approach to Recursion in Sentence Processing.
associations (0-LoE). Nevertheless, the SL and the SH                Language Learning, 59, 126-161.
setting can promote learning to a higher level. Thus, it           Clayards, M., Tanenhaus, M. K., Aslin, R. N., & Jacobs, R.
seems more demanding in the auditory modality than in the            A. (2008). Perception of speech reflects optimal use of
visual modality to process higher level of complexity in the         probabilistic speech cues. Cognition, 108(3), 804-809.
recursive hierarchy (2-LoE). Since the previous study (Lai         Conway, C. M., & Christiansen, M. H. (2005). Modality-
et al., 2014) also controlled for the manner how visual              constrained statistical learning of tactile, visual, and
stimuli were presented, the temporal order of auditory               auditory sequences. Journal of Experimental Psychology-
stimuli is not the primary reason. As Conway and                     Learning Memory and Cognition, 31(1), 24-39.
                                                               1241

Conway, C. M., & Christiansen, M. H. (2006). Statistical            Conference of the Cognitive Science Society (pp. 797-
  learning within and between modalities - Pitting abstract         802). Austin, TX: Conitive Science Society.
  against stimulus-specific representations. Psychological         Lai, J., & Poletiek, F. (2011). The impact of adjacent-
  Science, 17(10), 905-912.                                         dependencies and staged-input on the learnability of
Conway, C. M., Ellefson, M. R., & Christiansen, M. H.               center-embedded hierarchical structures. Cognition,
  (2003). When Less is Less and When Less is More:                  118(2), 265-273.
  Starting Small with Staged Input. Paper presented at the         Lai, J., & Poletiek, F. H. (2013). How "small" is "starting
  Proceedings of the 25th Annual Conference of the                  small" for learning hierarchical centre-embedded
  Cognitive Science Society, Mahwah.                                structures? Journal of Cognitive Psychology, 25(4), 423-
Elman, J. L. (1993). Learning and Development in Neural             435.
  Networks - the Importance of Starting Small. Cognition,          McMahon, E., Wintermark, P., & Lahav, A. (2012).
  48(1), 71-99.                                                     Auditory brain development in premature infants: the
Evans, K. K., & Treisman, A. (2010). Natural cross-modal            importance of early experience. Neurosciences and Music
  mappings between visual and auditory features. Journal of         Iv: Learning and Memory, 1252, 17-24.
  Vision, 10(1).                                                   Mintz, T. H. (2003). Frequent frames as a cue for
Fiser, J., & Aslin, R. N. (2002). Statistical learning of           grammatical categories in child directed speech. Cognition,
  higher-order temporal structure from visual shape                 90(1), 91-117.
  sequences. Journal of experimental psychology. Learning,         Moon, C. M., & Fifer, W. P. (2000). Evidence of transnatal
  memory, and cognition, 28(3), 458-467.                            auditory learning. J Perinatol, 20(8 Pt 2), S37-44.
Fitch, W. T., Hauser, M. D., & Chomsky, N. (2005). The             Mueller, J. L., Bahlmann, J., & Friederici, A. D. (2010).
  evolution of the language faculty: Clarifications and             Learnability of Embedded Syntactic Structures Depends
  implications. Cognition, 97(2), 179-210.                          on Prosodic Cues. Cognitive Science, 34(2), 338-349.
Fletcher, J., Maybery, M. T., & Bennett, S. (2000). Implicit       Pena, M., Bonatti, L. L., Nespor, M., & Mehler, J. (2002).
  learning differences: A question of developmental level?          Signal-driven computations in speech processing. Science,
  Journal of Experimental Psychology-Learning Memory                298(5593), 604-607.
  and Cognition, 26(1), 246-252.                                   Reber, A. S. (1967). Implicit Learning of Artificial
Glenberg, A. M., & Fernandez, A. (1988). Evidence for               Grammars. Journal of Verbal Learning and Verbal
  Auditory Temporal Distinctiveness - Modality Effects in           Behavior, 6(6), 855-863.
  Order and Frequency Judgments. Journal of Experimental           Rohde, D. L. T., & Plaut, D. C. (1999). Language
  Psychology-Learning Memory and Cognition, 14(4), 728-             acquisition in the absence of explicit negative evidence:
  739.                                                              how important is starting small? Cognition, 72(1), 67-109.
Gomez, R. L. (2002). Variability and detection of invariant        Rohde, D. L. T., & Plaut, D. C. (2003). Less is less in
  structure. Psychological Science, 13(5), 431-436.                 language acquisition. In P. Quinlan (Ed.), Connectionist
Hauser, M. D., Chomsky, N., & Fitch, W. T. (2002). The              modelling of cognitive development. Hove, UK:
  faculty of language: What is it, who has it, and how did it       Psychology Press.
  evolve? Science, 298(5598), 1569-1579.                           Romberg, A. R., & Saffran, J. R. (2010). Statistical learning
Holcomb, P. J., & Neville, H. J. (1990). Auditory and               and language acquisition. Wiley Interdisciplinary
  Visual Semantic Priming in Lexical Decision - a                   Reviews-Cognitive Science, 1(6), 906-914.
  Comparison Using Event-Related Brain Potentials.                 Rubinstein, L., & Gruenberg, E. M. (1971). Intramodal and
  Language and Cognitive Processes, 5(4), 281-312.                  crossmodal sensory transfer of visual and auditory
Huestegge, L., & Hazeltine, E. (2011). Crossmodal action:           temporal patterns. Perception & Psychophysics, 9, 385-
  modality matters. Psychological research, 75(6), 445-451.         390.
Kersten, A. W., & Earles, J. L. (2001). Less really is more        Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).
  for adults learning a miniature artificial language. Journal      Statistical learning by 8-month-old infants. Science,
  of Memory and Language, 44(2), 250-273.                           274(5294), 1926-1928.
Kidd, E., Lieven, E. V. M., & Tomasello, M. (2010).                Vokey, J. R., & Brooks, L. R. (1992). Salience of Item
  Lexical frequency and exemplar-based learning effects in          Knowledge in Learning Artificial Grammars. Journal of
  language acquisition: evidence from sentential                    Experimental Psychology-Learning Memory and
  complements. Language Sciences, 32(1), 132-142.                   Cognition, 18(2), 328-344.
Kirkham, N. Z., Slemmer, J. A., & Johnson, S. P. (2002).
  Visual statistical learning in infancy: evidence for a
  domain general learning mechanism. Cognition, 83(2),
  B35-B42.
Lai, J., Krahmer, E. J., & Sprenger, J. M. (2014). Studying
  Frequency Effects in Learning Center-embedded
  Recursion. In M. Knauff, M. Pauen, N.Sebanz, & I.
  Wachsmuth (Eds.), Proceeding of the 35th Annual
                                                               1242

