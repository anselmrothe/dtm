Modeling Lexical Acquisition Through Networks
Nicole Beckage (nicole.beckage@colorado.edu)
Department of Computer Science, 111 Engineering Center
Boulder, CO 80309 USA

Ariel Aguilar (ariel.aguilar@microsoft.com)
Microsoft, One Microsoft Way
Redmond, WA 98052 USA

Eliana Colunga (eliana.colunga@colorado.edu)
Department of Psychology and Neuroscience, UCB 345
Boulder, CO 80309 USA
Abstract

Fenson, 1996). We use a graph-theoretic network representation where the words are the nodes in the graph and the edges
are based on semantic or phonological similarity. Finally, we
quantify the extent to which the network representation improves our ability to predict which words a child will learn
next. We summarize the modeling results as a function of
age, productive vocabulary size, and language skill.

We examine the nature of phonological and semantic similarity in early language learning. We consider how the use of this
information might change over the course of development. To
this end, we represent the lexicon as either a phonological or
semantic network and model the growth of this network. Constructing normative vocabularies from the Communicative Development Inventory norms, we utilize a preferential attachment growth algorithm. We predict and quantify the words
which will be learned next, comparing the two network representations. We consider the effect of age, total vocabulary size
and language ability as measured through CDI percentile. Our
findings suggest that the semantic representation does not outperform the baseline bag-of-words model, whereas the phonological representation conditionally does. More generally, we
show that the network representation influences the ability of
a model to capture vocabulary growth. We further offer a
method of analysis for testing representational assumptions in
network models.

Growth Networks
By assuming a network representation where the edges are
based on phonological or semantic similarity, we can model
the acquisition of individual words through a network growth
model. We turn to the work of Steyvers and Tenenbaum
(S&T) for their model of network growth in the context of
language acquisition (2005) and adapt it to our paradigm.
We also consider the methodology of Hills and colleagues
(Hills et al., 2010, 2009b) for their work of comparing network models and constructing a normative vocabulary.
S&T considered the structure of three semantic networks,
showing that these semantic networks had similar large scale
structure, with high local clustering and short average path
lengths between words. They also found evidence of a powerlaw in the degree distribution within these networks. This
led to the construction of a model of semantic growth where
words are more likely to be learned if they connect to known,
highly connected words in the graph. They call this model
preferential attachment because of its similarity to the growth
model of Barabási and Albert (BA model, 1999). Further,
the modeling results suggest a correlation between age of acquisition and global network structures of early language networks.
Hills and colleges extended this work by comparing the
content of the vocabulary, as generated by the models, to
a normative vocabulary constructed from the CDI norms.
Whereas the previous work considered three different models
of acquisition, we consider only the preferential attachment
model since this model is also used in the work of S&T. We
also maintain the assumption that the underlying network is
fixed and the nodes are labeled. We extend their definition
of normative language acquisition to compare a set of normative vocabularies across different ages and language abil-

Keywords: Language acquisition; word learning; lexical acquisition; network modeling; preferential attachment

Introduction
There is much evidence to support the idea that children learn
words systematically. A child’s vocabulary relates to that of
their parent’s suggesting that the environment plays an important role (Weizman & Snow, 2001). The interest of the
child further influences language learning (DeLoache et al.,
2007), and the words a child knows are useful in predicting
the words that child will learn next (Beckage & Colunga,
2013). Concrete nouns are learned earliest, as are shorter
words (Gentner, 1982). However, there is still systematicity in learning that is not fully understood. In this paper we
look at the changing role of two specific sources of information that influence the learning of words – phonological or
semantic information.
Here we examine the systematicity present in word learning. Specifically by focusing on whether phonological or semantic similarity dominate early language learning. We also
consider how the role of semantic and phonological information might change over the course of development. In our approach, we model growth in the normative productive vocabulary of 16 to 30 months olds, based on the MacArthur Bates
Communicative Development Inventory norms (CDI, Dale &

190

ities. Hills and colleagues assumed a semantic network as
the underlying network representation and compared different growth models. Here we instead assume a network model
and ask whether a semantic or phonological network representation is more predictive in modeling lexical acquisition.

for the observed word acquisition data. Thus, we ask: 1)
Which linguistic features capture and potentially guide lexical growth? 2) Are there different relevant linguistic features
at a) different points in development or b) across different developmental trajectories?

Linguistic Information

Normative vocabulary networks

There is evidence to suggest both phonological and semantic aspects play a role in early language learning. First, the
phonemic pattern and the length of the word play an important role in early word learning. Not only do length and the
number of phonemes matter, but the number of words that
are phonologically similar to a given word (the phonological neighborhood) also affects learning. Words that are part
of denser phonological neighborhoods are more likely to be
learned even when frequency and length are controlled for
(e.g., Storkel, 2009).
On the other hand, semantic aspects also play a role in
early word-learning. For example, sensory-motor semantic features have been shown to be available to even prelinguistic children (e.g., Bloom, 2002). In fact, Howell et
al. showed a significant improvement in word prediction accuracy by including sensory-motor features in a neural network model, suggesting that semantic features inform word
learning (2005). Hills and colleges also explore the issue of
semantic features by asking directly what type of semantic
edges–perceptual or conceptual–are most useful in predicting
acquisition (Hills et al., 2009b). Their results suggest that
perceptual features are more robust, but conceptual features
are more discriminating and more likely to be used. With our
network models, we try to understand the independent contributions of semantic and phonological information to early
word learning.

To achieve our modeling goals, we define a ’vocabulary snapshot’ to be a starting network (from a specific month) and a
goal network–the network one month later. This allows us to
test the ability of the model and representation to predict from
one month to the next. We utilize the MacArthur-Bates Communicative Development Inventory (Dale & Fenson, 1996,
CDI) norms to compute vocabulary snapshots. The CDI is
a parent report vocabulary checklist consisting of 680 words,
spanning 22 semantic categories and including the most common parts of speech. We utilize the 16-30 month production norms which aggregates productive vocabularies of 1130
children of different ages through parent report. For our modeling study, we focus specifically on nouns, and further consider only the 352 words that are normed in both the CDI and
by the Howell sensory-motor features which we use to construct our semantic network.
To construct normative (prototypical) vocabularies, we
convert the norms (which include the percentage of children
of a given age who produce each word) to vocabulary snapshots. To do this, we consider a word learned if the norm for
that word and age is above a certain threshold. We can construct a variety of normative vocabulary snapshots by varying
the percentage of the population that was reported to produce
a specific word. We consider thresholds between the range of
the 10% of the population through 90% (indicating the rate of
production) in increments of 5. We create a range of normed
vocabularies in the hopes of capturing the developmental differences in vocabulary growth. We consider age, vocabulary
size and language ability in our analysis. To assess language
ability, we use the CDI percentile which considers the size
of the vocabulary for a given age as compared to their peers.
This means that a child in the 90th CDI percentile will have
a larger vocabulary than a child in the 20th percentile. Thus
we use 100-threshold to approximate the CDI percentile in
our study. We use this CDI percentile as an approximation
of language ability. We also assume that if a word enters the
vocabulary, it stays in the vocabulary–a situation that is not always true when we use the norms to calculate the vocabulary.
In total there are 206 vocabulary snapshots pairs (starting and
predicted), representing 17 different thresholds for normative
vocabularies between 16 and 30 months.

Methods
In this paper we utilize a network growth model to understand
and quantify the relevance of phonological and semantic features on language acquisition in children. To isolate phonological or semantic features from each other and other important components of language acquisition, we make a few initial assumptions. We first assume that the productive vocabulary can be represented as a network with words as nodes and
relations between nodes determined by similarity in phonological or semantic space. We define the exact mapping between edges in the network and phonological/semantic similarity in more detail below. Second, we assume that the
growth of this vocabulary network can be modeled through
a process of preferential growth that is similar to preferential attachment (Barabási & Albert, 1999; Steyvers & Tenenbaum, 2005) and that this model captures some aspects of
language acquisition and language learning in children. We
finally assume that ’normative vocabularies’ as defined below
represent individual children’s acquisition trends. We hold
the underlying process of network growth constant as this allows for direct examination of how the definition of an edge
changes the ability of the network growth model to account

Preferential Growth Model
We adapt the S&T model to account for a fixed edge list
(Steyvers & Tenenbaum, 2005). The preferential attachment
model was tested on normative vocabularies by Hills and colleagues (2009b), though with a different set of edges and to
answer different questions. Because of the prevalence and
use of variants of preferential attachment in the literature, we

191

Networks

assume, for this study, that lexical networks grow according
to a process similar to preferential attachment. Preferential
attachment can be seen as a growth model in which, at each
step, a new node and some edges are added to an existing
network graph. The new node attaches to already existing
nodes proportionally to the number of neighbors of the existing node. This results in a ’rich get richer’ effect as wellconnected nodes (high degree words) in the existing graph
are likely to acquire edges from new nodes, further increasing their connectivity and thus increasing their likelihood of
’preferentially attaching’ to new incoming nodes.
This model cannot be directly applied to our vocabulary
networks since, in our case, we have a predefined maximal
network G0 (V 0 , E 0 )–the nodes (V 0 ) are labeled and edges (E 0 )
are fixed– such that for any network, two nodes are either connected or not connected. For example, a vocabulary containing words dog and cat will have a node for each of these two
words and those two nodes will always be connected in the
semantic network and always be not connected in the phonological network. We are trying to understand how the network
grows over time, not only where new nodes could attach. We
thus relax the definitions in the BA model to generalize it to
our case, as in (Hills et al., 2009b). In each iteration of this
model, we select an attachment node from the current vocabulary graph G(V, E) ⊆ G0 (V 0 , E 0 ) proportionally to the degree
of the word in graph G (as in the original BA model). We
then select an unknown neighbor of the attachment node and
assume that this is the newly learned word. Finally, we update the graph such that all edges between existing words and
the newly learned word are present in the vocabulary graph.
Under this algorithm, the probability that an unknown word j
is learned given the current graph G(V, E) is defined as:
Pr(learn( j)) ∝

∑

If the network representation is useful, our models will
outperform uniform acquisition (where each unknown word
has equal probability of being learned). We also consider
the importance of the underlying network representation by
running the model on a network with the same number of
edges but drawn at random. We evaluate the representation
by calculating the overlap between predicted words for
learning and the words that are actually learned, according
to norms, in a single month’s time. These networks, and
the comparison to the random models, offer a way of
understanding the importance of phonological and semantic
similarity on early language acquisition.
Phonological Network To construct a phonological
network, we convert the set of vocabulary words to the
international phonemic alphabet (IPA). This was done using
PhoTransEdit, a free Windows tool used to transcribe English
texts to phonetic transcriptions. This transcription was used
to create a feature by word matrix where the full features
were all phonemes in the English language and the word
specific features were counts of the number of times a
given phoneme appeared in a word. The phonetic similarity
of each word was then computed as a cosine similarity
of the phoneme-feature vector between two words. The
cosine-similarity calculation resulted in a symmetric matrix
of words by words where each cell contained a value between
0 (no phonemic overlap) and 1 (complete phonemic overlap).
The resulting matrix was thresholded to a binary matrix at
a value of 0.6 as there was a noticeable break in similarity
between words around this value making it a robust threshold
for the greatest range.

di I( j,i)∈E 0

i∈V, j6∈V

Semantic Networks We utilize the sensory-motor feature
matrix of Howell and colleagues for our semantic network
(2005). In the study by Howell and colleagues, participants
were asked to rate early learned nouns on a set of 97 different features. Participants were instructed to make judgments
from the perspective of a preschool aged child. These features included aspects such as size, color, texture and other
features. These ratings were collected for 352 nouns and
were averaged across at least 200 participants. These ratings capture population level averages indicating the extent
to which an object possesses a given feature. We compute the
semantic similarity of two words by calculating the cosinesimilarity of the feature vectors for each words This provided
us with a symmetric matrix that we convert to a binary matrix
by thresholding. We threshold at a level of 0.85 as there was
a break in the cosine-similarity ratings of all vectors at that
point. We chose the Howell feature norms for this analysis
because it specifically attempts to capture sensory-motor features that might be available and important to young children
and, as such, is well suited for our specific research question.
Since we only have the sensory-motor features for 352 nouns,
we include only these words in our modeling.

where di is the degree of node i given that node i is known.
This degree contributes to the probability of learning word j
if an edge exists between i and j in the full graph G0 (V 0 , E 0 ).
We run this algorithm for each vocabulary snapshot, initializing the current vocabulary graph to the starting CDI vocabulary. Preferential growth runs until the network is sizematched to the target vocabulary. Note that we still update the
current graph after each iteration to include the newly learned
word, and all its relevant edges, such that sequential effects
may appear in the model. That is, if dog gets added as an
attachment to cat, and puppy is already a node in the graph
(i.e. a known word), the new node for dog will link with both
cat and puppy. Further, a new word might attach to dog in the
next time step. We compare the words selected by a given run
of the algorithm to the words that have actually been learned
according to the normative vocabulary snapshots. The greater
the overlap, the more useful the underlying network is in
capturing language learning. To account for the stochasticity and intractability, we simulate a model run –growing the
vocabulary– and compare it to the predicted vocabulary 1000
times. We then compute the average model performance.

192

Table 1: Model performance: mean accuracy per word predicted, standard deviation of prediction, and performance
compared to 1/n random.
semantic
phonological
1/n rand
sem rand
phon rand

word prob.
.178
.192
.191
.191
.191

s.d.
.007
.006
.008
.013
.021

% better
31.55
43.68
58.00
64.56
54.36

ation of the linguistic model and an iteration of the 1/n random model. We find that only 31.55% (or 65 snapshots) are
statistically better fit by the semantic network than by the 1/n
random model. In fact the 1/n random model performs statistically better in 64.56% (or for 133 snapshots). See Table 1
for results. When we perform the same comparison on the
semantic network and the r-graph baseline model, we find
the exact same results, with each snapshot either beating both
random models or none. Over all of our analyses, we find that
there is no meaningful difference between the comparison of
the linguistic network to the random graph that is not captured by considering only the 1/n bag-of-words model. Thus
we talk only about the 1/n random model with the knowledge that the results also extend to the random graph (r-graph)
model.

% worse
64.56
51.45
37.62
31.55
40.77

Model Comparison
The main point of this paper is to test which representations
are useful in predicting words to be learned, and how this
may change with development. We mentioned briefly baseline models we use for comparison. In this section we cover
them in more detail. In our 1/n or bag-of-words model each
unknown word has an equal probability of being learned. A
bag-of-words, just learn anything model, has been shown to
produce early lexical graphs with structure similar to that of
the lexical graphs of children (Beckage et al., 2011) and thus
provides an interesting baseline model. The other random
model, our r-graph model, is based on network structure but
instead of a principled edge-list, the same number of edges
are randomly drawn. This measures any effect that the network structure might have in isolation from the linguistic information present in the semantic and phonological graphs.
Since we run many iterations and count the number of overlapping words, if we generate graphs entirely at random, our
r-graph model will approach our 1/n random model for large
numbers of simulations. Thus we fix the random graph representation for 100 runs before drawing a new random graph.

Though it seems that the random model is outperforming
the semantic network, it could be that there is some systematicity in the 31% of cases where the semantic network actually outperforms the random models. For example the semantic network might outperform the random model for vocabulary snapshots of young/older children or for vocabulary
snapshots created to capture high/low language ability. To
explore this possibility, we cluster the results with respect to
age, CDI percentile, and vocabulary size. Figure 1 shows the
same data as table 1 aggregated to capture possible trends in
development. The y-axis indicates the change from random,
with the scale varying across graphs. The x-axis aggregates
the data by relevant developmental features and varies across
plots. We consider effects of age, percentile, vocabulary size.
The results for the semantic network is shown in dark grey. If
performance was equal to random, this would be indicated as
a 0 on the graph. If the performance was better than random,
the line would be above the 0 mark. While we do not show
the results here, we also consider the number of words the
model is predicting in case there is an effect of the size of the
prediction set.

Results
Once we calculated the number of correctly predicted words
for each model, we consider trends in the data. We can look at
multiple levels of data analysis to shed light on different underlying mechanisms. The first question we ask is whether or
not the collective fits across all snapshots are better than our
random baseline models. To do this, we have to normalize the
network runs across snapshots since each snapshot captures
a different number of words to be learned. Thus, we consider the probability that the model correctly predicts a word.
This allows us to average each snapshot equally and to compare performance across models. The results, summarized in
Table 1 suggest that the probability of correctly predicting a
word for learning is nearly equal across models. The semantic network seems to be performing slightly worse than the
other models. We include the average standard deviation of
the probability of correctly choosing a word to suggest that
the model converged and that there is not much variability
across runs.

If the semantic network model captured learning of a subset of developmentally interesting and research motivated
snapshots, we should see this as a systematic increase of the
network performance over random. Instead, we find that regardless of age, percentile, vocabulary size or the size of the
prediction set, the semantic network is not performing better than the random models. In fact there is evidence of a
trend that, for higher CDI percentiles, the semantic model decreases in performance and is actually worse than random. A
similar trend is seen for the vocabulary size as well, where
aside from vocabulary sizes around 450, there is a steady decrease in performance of the semantic model as compared to
random for larger vocabularies.
However, this is averages of averages, which could mask
trends due to poor performance of the semantic network on
a subset of snapshots. When we consider the proportion of
snapshots that are better fit by the sensory-motor features than
any random network, we find that, regardless of the dimension used for clustering, there is no reliable trends in the data.

Semantic Network Results
Averaging across all vocabulary snapshots, and comparing
each model to the random models further suggests that the
semantic network does not outperform random. For each of
the snapshots, we utilize an unpaired t-test between each iter-

193

Performance by PERCENTILE

Performance by VOC size

16

18

20

22

24

26

-0.02

diff. from random
20

0.00

0.02

28

AGE

-0.06

howell
phono
random

-0.04

0.00
-0.01

diff. from random

-0.03

-0.02

0.02
0.00
-0.02
-0.04

diff. from random

0.01

Performance by AGE

40

60

PERCENTILE

80

0

100

200

300

400

500

600

VOC size

Figure 1: Performance on snapshots compared to random aggregated by either age, percentile or vocabulary size. Dark grey
indicates semantics and light grey indicates phonology.
In all cases, there are some snapshots that are best fit by the
semantic network but there seems to be no systematicity to
which snapshots they are.

words model. However, we find that the phonological network shows some systematic increase in performance over
the random network and bag-of-words model. This is an interesting result as it suggests that phonological features contain useful information in understanding how language may
be learned. Further, we can see that this type of phonological information and this process of growth are best able to
capture acquisition for snapshots created for older children,
children with larger vocabularies and normative vocabulary
snapshots that are constructed to mirror children with high
language ability.
We interpret the conditional success of the phonological
network in the context of the failure of the semantic network and revisit our initial assumptions as laid out in the
first paragraph of the methods section in light of these results.
We assumed that the phonological representation of overlapping phonemes and the semantic representation of sensory
motor features provided a useful initial network representation. This is an assumption that could easily be expanded
upon or directly challenged. However, even with the limited
choice of representations, we showed two important things.
First, this result shows how the representation chosen influences the ability of the model to capture vocabulary growth.
Further, this modeling approach suggests a way to compare
network representations by holding the process of network
growth constant. This type of model comparison may tell us
about structures useful to young learners as well as about how
language itself might be structured from the perspective of a
young children.
Our assumption of a preferential growth process of acquisition was not directly explored in this paper. In future work
we do hope to explore this model as compared to other types
of network growth models to understand both the nature and
variability of learning. But the fact that the phonological network representation and the preferential growth model were
able to outperform random for a certain class of snapshots
suggests that this model is able to capture aspects of the process of acquisition, if somewhat imperfectly.
Our final assumption that the normative vocabulary snapshots captures individual behavior is the most informative.
The vocabulary snapshots do provide a way in which the vocabulary of a child may change over time but this does not

Phonological Network Results
When the phonological network of overlapping phonemes is
considered, 43% of the snapshots are significantly better fit
by phonology than by random, and 51% are significantly
worse fit. This suggests that a phonological representation
performs worse than random acquisition on average. However, when we look at the trends across age, vocabulary size
and language ability, we find that certain types of snapshots
are reliably better fit by the phonological network than by
the random models. Figure 1 shows the performance of the
phonological model (light grey) again aggregated over different features of interest. We can see in the first frame that
when we consider age, snapshots generated from norms for
children between 20 and 25 months are reliably better fit by
the phonological preferential growth model than by the random models. Similarly, there is a general trend of an increase
in performance over random as the percentile of the snapshot increases. We also see a large increase in performance
of the phonological model for vocabulary sizes between 200
and 550 words. Further, when we consider the proportion
of vocabularies that are better than the random model, similar
trends emerge–we don’t see just an increase in probability but
also an increase in the number of snapshots that are better fit
by phonology than random. It is important to point out that,
in general, vocabularies that are larger are also more likely
to be from normative vocabularies constructed from norms of
older children and are, with our assumptions, also representative of higher language ability. So in some sense it is not
surprising that the effect of phonology seems to increase in
performance in all three cases. However, the redundancy also
confirms that the effect is not due to random noise but is a
property of the vocabularies. In the next section we discuss
these findings to understand the significance of the results.

Discussion and future directions
The results suggest that in most cases the semantic network
based on the Howell sensory-motor features is not able to outperform the random semantic network model or the bag-of-

194

References

capture the vocabulary of any individual child directly. It is
a big assumption that words that are reported as learned by
the fewest children are also the words that early talkers learn,
for example. This assumes that word learning proceeds in a
systematic and predictable fashion–that late talkers are just
typical talkers who are older– a result that has been shown
to be untrue (Thal et al., 1999; Beckage et al., 2011). The
normative vocabularies may not capture any individual child
very well, but capture the aggregate instead. This could be
particularly problematic in the domain of semantics since the
averaging of multiple vocabularies and the further assumption
of creating snapshots to indicate different language ability
would likely cancel out any sort of semantic consistency that
wasn’t shared across the majority of children. For example,
the vocabulary snapshots would not necessarily show preferences for animals or vehicles unless a large amount of children in the norming study showed such preferences at similar
times and with base rates roughly equal to their peers.
The aggregation process may also explain why the phonological model was especially useful for larger vocabularies
and normative vocabularies created for older children. The
CDI is a measure of productive vocabulary, meaning to check
as word as ”known” the parent needs to recognize the word
the child is producing. It has been established that there is
much regularity in the order in which phonemes are mastered
in development (e.g., Sander, 1972; Grunwell, 1981). Thus
the vocabulary snapshots are likely able to capture general
properties of the difficulty of production. In the case of large
vocabularies or high language ability, the phonological network does the best. This could be due to the fact that the
vocabulary contains a large set of phonemes which allows the
model to 1) distribute probability of learning over a greater
set of words and 2) to implicitly model the difficulty in production of phonemes that may play a role in learning. This
feature of phonology is likely to be more systematic across
children than semantic similarity, especially with the aggression procedure used to construct normative vocabularies.
The results, as they stand now, are intriguing in that we
have gained direct information as to the performance of the
preferential growth model within the context of language acquisition. We test the model and representations the model
uses and conclude that given this model and these data,
phonology outperforms the random models more often than
semantics does. This confirms that phonological information
may play a role in the learning of new words or it could suggest instead that, in averaging, the systematic nature of semantics is washed out while the phonological aspects are accentuated.

Barabási, A.-L., & Albert, R. (1999). Emergence of scaling
in random networks. Science, 286(5439), 509–512.
Beckage, N. M., & Colunga, E. (2013). Using the words
toddlers know now to predict the words they will learn next.
Proc. of the 35th Conf of the Cog. Sci. Society, 163-168.
Beckage, N. M., Smith, L. B., & Hills, T. T. (2011). Small
worlds and semantic network growth in typical and late
talkers. PloS one, 6(5), e19348.
Bloom, P. (2002). How children learn the meanings of words.
Dale, P. S., & Fenson, L. (1996). Lexical development norms
for young children. Behavior Research Methods, Instruments, & Computers, 28(1), 125–127.
DeLoache, J. S., Simcock, G., & Macari, S. (2007). Planes,
trains, automobiles–and tea sets: Extremely intense interests in very young children. Developmental Psychology,
43(6), 1576-1586.
Gentner, D. (1982). Why nouns are learned before verbs: linguistic relativity versus natural partitioning. In Language
development: Language cognition and culture.
Grunwell, P. (1981). The development of phonology: A descriptive profile. First Language(2), 161–191.
Hills, T., Maouene, J., Riordan, B., & Smith, L. B. (2010).
The Associative Structure of Language: Contextual Diversity in Early Word Learning. Journal of memory and language, 63(3), 259–273.
Hills, T., Maouene, M., Maouene, J., Sheya, A., & Smith,
L. (2009b). Longitudinal analysis of early semantic networks: preferential attachment or preferential acquisition?
Psychological science, 20(6), 729–39.
Howell, S. R., Jankowicz, D., & Becker, S. (2005). A
model of grounded language acquisition: Sensorimotor
features improve lexical and grammatical learning. Journal of Memory and Language, 53(2), 258–276.
Sander, E. K. (1972). When are speech sounds learned? Journal of Speech and Hearing Disorders, 37(1), 55–63.
Steyvers, M., & Tenenbaum, J. B. (2005). The large-scale
structure of semantic networks: statistical analyses and a
model of semantic growth. Cognitive science, 29(1), 41–
78.
Storkel, H. L. (2009). Developmental differences in the
effects of phonological, lexical and semantic variables on
word learning by infants. Journal of Child Language,
36(02), 291–321.
Thal, D. J., O’Hanlon, L., Clemmons, M., & Fralin, L.
(1999). Vaidity of a parent report measure of vocabulary and syntax for preschool children with language impairment. Journal of Speech, Language, and Hearing Research, 42(2), 482–496.
Weizman, Z. O., & Snow, C. E. (2001). Lexical output as
related to children’s vocabulary acquisition: Effects of sophisticated exposure and support for meaning. Developmental Psychology, 37, 265-279.

Acknowledgments
This work is an extension of Ariel Aguilar’s Computer Science senior thesis and was funded through an award from
the John Merck Scholars Fund and by NICHD grant R01
HD067315 to Eliana Colunga. The first author was funded
in part through the NSF GRFP.

195

