                          Crowdsourcing elicitation data for semantic typologies
                                       Barend Beekhuizen                         Suzanne Stevenson
                              Leiden University Centre for Linguistics      Department of Computer Science
                                          Leiden University                       University of Toronto
                                b.f.beekhuizen@hum.leidenuniv.nl                suzanne@cs.toronto.edu
                               Abstract                                 to avoid manually devising a set of semantic primitives to en-
                                                                        code the target word meanings. The semantic space captures
   In semantic typology, it is desirable to have quick and easy
   access to crosslinguistic elicitations describing stimuli from a     crosslinguistic patterns in the similarity of situations, such
   semantic domain. We explore the use of crowdsourcing for             that situations that are expressed similarly within many lan-
   obtaining such data, and compare it with fieldwork data ob-          guages are closer together, whereas situations that are often
   tained through in-person elicitations. Despite potential con-
   cerns about the quality of crowdsourced data, we find no dif-        expressed differently within a language are farther apart. That
   ference in the amount of between-language variation and can          is, while each language may divide up the semantic space of
   replicate a cognitive modeling experiment using the crowd-           spatial relation situations more or less differently, the seman-
   sourced data in place of the fieldwork data. Both results sug-
   gest that crowdsourcing elicitations is a viable method for          tic space encodes the common tendencies across languages
   gathering data for semantic typology and cognitive modeling.         in where they place boundaries among words or affixes for
   Keywords: semantic typology; cognitive modeling; data col-           describing conceptual distinctions.
   lection; spatial relations                                              BFS used cognitive modeling to explore the Typological
                                                                        Prevalence Hypothesis (Bowerman, 1993; Gentner & Bower-
                            Motivation                                  man, 2009), which states that, all else being equal, semantic
Languages vary quite a bit in where they place the seman-               groupings that are more common across languages are cogni-
tic boundaries between grammatical case affixes (Cysouw,                tively more ‘natural’ and therefore easier to learn. Using the
2014) and lexical items (Malt, Sloman, & Gennari, 1999;                 semantic space described above for representing word mean-
Bowerman & Choi, 2001). Despite the variation in the exact              ings, we trained a model that learned Dutch prepositions,
placement of the boundaries and the numbers of conceptual               associating them with regions of the space. We simulated
distinctions, there are also seemingly universal tendencies to          Gentner and Bowerman’s (2009) finding that Dutch children
group certain concepts together under one linguistic label.             acquire the prepositions op and in (which correspond to com-
Bowerman and Choi (2001) found, for instance, that situa-               mon semantic groupings of spatial relations) earlier than aan
tions of containment and surface support (expressed with on             and om, and that children often use op in situations where
and in in English) constitute prototypical cores of the mean-           adult speakers use aan or om. Using the crosslinguistically-
ings of spatial adpositions cross-linguistically.                       derived semantic space enabled us to explore the interaction
   Recently, semantic typology—the study of semantic varia-             between word frequencies and the lay-out of the space in driv-
tion and similarity between languages—has begun to be ex-               ing patterns of acquisition of word meaning.
plored with quantitative techniques. Much of this work starts              Using patterns of elicitation data to understand how people
from the method pioneered by Berlin and Kay (1969), in                  conceptually and linguistically carve up semantic domains
which speakers of various languages are asked to describe               thus has been important for both analysis of semantic do-
the same set of stimuli. The resulting elicitation data cap-            mains and for cognitive modeling of word meaning acquisi-
ture crosslinguistic patterns of expression that can reveal in-         tion. In order to extend this line of research to other semantic
sights into a semantic domain and its encoding across lan-              domains and a wide range of languages, we need quick and
guages. Using such data, researchers have been able to iden-            easy access to typological data for a sample of languages con-
tify crosslinguistically-salient conceptual distinctions (Majid,        cerning the semantic domains of interest. Major efforts have
Boster, & Bowerman, 2008), to explore how semantic do-                  been made to elicit expressions within a range of languages
mains are expressed using closed-class vs. open-class lexi-             across some selected cognitive domains (Majid et al., 2014).
cal items (Majid, Jordan, & Dunn, 2014), and to reveal con-             However, thus far such efforts have relied on traditional in-
straints on how linguistic systems for verbalizing various se-          person elicitations that are labor-intensive to acquire, and thus
mantic domains form categories of expression (Khetarpal,                the number of languages and domains is limited. In this pa-
Majid, & Regier, 2009; Regier, Kay, & Khetarpal, 2009).                 per, we explore the potential of crowdsourcing for obtaining
   Beekhuizen, Fazly, and Stevenson (2014) (henceforth                  semantic elicitations as a way to broaden the scope of possi-
BFS) extended this typological method to the domain of                  ble analytical and modeling research in this area.
cognitive modeling, in particular, modeling the aquisition of
word meaning. Using the crosslinguistic dataset from Levin-                      Crowdsourcing crosslinguistic data
son, Meira, et al. (2003), BFS derived a ‘universal’ semantic           We aimed at using crowdsourcing to create a similar dataset
space for the domain of spatial relations from the linguistic           to that of Levinson, Meira, and The Language and Cogni-
expressions of native informants. This approach enabled us              tion Group (2003) (henceforth the LM data). This dataset
                                                                    202

Figure 1: Four examples from the BowPed stimuli, 71 pic-                        Table 2: Coding schema and percentage of response type
tures of topological spatial relations between a Figure (the
highlighted object) and the Ground (the related object).
                                                                                                                  Ara
                                                                                                                  Bas
                                                                                                                  Dut
                                                                                                                  Ind
                                                                                                                  Nah
                                                                            Class description                     Que
                                                                                                                  Swa
                                                                                                                  Tha
                                                                            1       Contains a spatial marker    60   13   79   58   11   15   70   62
                                                                            2       Non-spatial expression        4    2    1    0    3    2    5    7
                                                                            3       Reversal of Figure-Ground     9    2    5    1    2    1    7    4
                                                                            4       Other invalid responses      25   82   15   41   83   80   17   25
                                                                            5       Coder uncertain               1    1    0    0    1    3    1    1
                                                                            manually-gathered elicitations. Since participants are paid to
                                                                            fulfill tasks, the data inevitably contains more noise. Our in-
                Table 1: The language sample.                               structions had to be tailored to encourage full meaningful re-
                                                                            sponses, also leading to more opportunity for a wider variety
 Language Affiliation           Country              n Speakers             of responses. We requested 15 responses per situation within
 Arabic       Afro-Asiatic      Egypt                53,990,000             each language, effectively obtaining 0 to 15 useable ones.
 Basque       isolate           Spain                   546,000                The response data was subsequently coded by the first au-
 Dutch        Indo-European     the Netherlands      21,944,690             thor using the five-code schema in Table 2, drawing on lan-
 Indonesian   Austronesian      Indonesia            22,800,000             guage resources online. Class 1 was used to identify valid
 Nahuatl      Uto-Aztecan       Mexico                1,500,000             expressions which contained some overt marking of the topo-
 Quechua      Quechuan          Peru                  8,913,000             logical spatial relation. This could be an adposition, a spatial
 Swahili      Niger-Congo       Kenya, Tanzania,     15,457,000             noun, or a case ending. Only data coded as Class 1 is used
                                Uganda                                      in the creation of our semantic representation, which uses the
 Thai         Tai-Kadai         Thailand             20,397,000             spatial markers as dimensions in the space.
                                                                               We used four additional categories to distinguish various
                                                                            types of responses that did not fit this requirement, so that
contains in-person elicitations for 1–26 speakers within each               we could explore other possible expressions in the future. In
of 9 languages who were asked to describe 71 pictures in                    Class 2, the relation between the Figure and Ground was ver-
the Topological Spatial Relations Set (Bowerman and Ped-                    balized using mechanistic rather than spatial language (e.g.,
erson (1992); see Figure 1).                                                the arrow pierces the apple), indicating a non-spatial concep-
   We used the same stimuli to elicit spatial descriptions on               tion of the situation. The reversals of Figure-Ground in Class
a crowdsourcing platform (www.crowdflower.com) with the                     3 (e.g., the table under the lamp rather than the lamp above
dual goals of expanding the languages for which we had data                 the table) indicate how likely certain Figures are conceived
in that semantic space, and of evaluating the viability of us-              of as Grounds. Class 4 held cases of miscategorization of
ing crowdsourcing as an alternative data collection method-                 the objects, non-relational responses, non-target language, or
ology. As with the LM data, we aimed to obtain a sample                     nonsense. Responses that could not be resolved into one of
of genetically unrelated languages with a wide geographi-                   these classes were placed in Class 5.
cal spread. Since we wanted to both compare with and ex-                       As seen in Table 2, the quality of the data varies between
tend the LM data, we targeted two of the same languages                     languages, with the proportion of Class-1 responses ranging
(Dutch and Basque), and added six new languages, shown                      from 11% to 69%. This is especially an issue for minority
in Table 1. Some differences in the datasets arise from the                 languages—Basque, Nahuatl, and Quechua—whose partic-
use of the crowdsourcing methodology: for example, we had                   ipants frequently appeared not to be native speakers. (Re-
to select languages in which the number of speakers is rel-                 sponses for Basque often appeared to have been automati-
atively large, in order to increase the likelihood of reaching              cally translated, and for the latter two were often in Spanish or
them online; we were unable to restrict responses to a par-                 consisted solely of the Figure noun.) Quality control is diffi-
ticular variety of a language (e.g., for Nahuatl and Quechua,               cult: we undertook what could be done within the constraints
which are better regarded as language groups); and we pre-                  of the platform. In future work, we plan to incorporate in-
sumed that most speakers would be bilingual, given the use                  sights from recent work on quality control in crowdsourcing
of an English-based online crowdsourcing platform.1                         experiments (Chen & Dolan, 2011; Pavlick, Post, Irvine, &
   In addition to differences in the properties of the languages            Kachaev, 2014).2
and participants, our methodology also led to the possibil-                    Despite additional noise and a wide variety of response
ity of differences in the nature of responses compared to                   types, the effort to code the data and extract the usable re-
    1 We restricted the locations per language to IP addresses from            2 We thank all three reviewers for constructive suggestions con-
the countries in Table 1.                                                   cerning quality control.
                                                                      203

sponses was only ±3-4 hours per language. Crowdsourc-                       Figure 2: Between-language distances for all languages
ing as a way to extend the reach of elicitation datasets thus
appears viable, so long as the resulting data has appropriate                                                               Quechua●
                                                                               0.1       Thai●
properties, the topic we turn to next. We first look at directly                                                           Swahili●
measuring a key aspect of elicitation data, and then turn to a                                    Arabic●
                                                                                                                 Indonesian●
                                                                                                                                            dataset
replication of our cognitive modeling work.                                    0.0         Trumai
                                                                                                            Yukatek
                                                                                                                             Basque
                                                                                                                                              ● CF
                                                                                                                         Basque●        Lao
                                                                                                Dutch ●
                                                                                                   Dutch       Nahuatl●                         LM
  Comparing crowdsourced and fieldwork data                                                            Lavukaleve
                                                                                                             Tiriyo
                                                                                                                                   Ewe
                                                                              −0.1
If crowdsourced data is to be used for linguistic study and                                                         Yeli Dnye
cognitive modeling, it needs to be the same in relevant prop-
                                                                                         −0.10        −0.05           0.00         0.05
erties as data gathered through fieldwork. One key property
is diversity: in order to use the resulting data as the basis for
a ‘universal’ semantic space, the languages must show varia-
tion reflective of the many ways in which that semantic space          a distance matrix Dl , whose rows and columns are the situa-
can be divided up. The languages that have sufficient num-             tions, and each cell contains δ(s, s0 |l).3
bers of speakers available on a crowdsourcing platform con-                We can now compare two languages l and l 0 by comparing
stitute a narrow subset of all languages spoken. We believe            how similarly they verbalize each situations—i.e., comparing
                                                                                                                    0
this admittedly skewed typological sample can nonetheless be           the distance matrices Dl and Dl . We first compare the repre-
used if the between-language variation it displays is not lower        sentation of each situation across the two languages, and then
than that of the manually-gathered sample of LM.                       averaging that per-situation distance. The distance between s
    In order to assess the overall variation among the languages       in two languages l and l 0 is the inverse of the cosine similarity
                                                                                                                                            0
in our dataset, we must consider a way to measure the dif-             between the rows containing s in each of Dl and Dl :
ferences in how two languages carve up the semantic space.
Unlike lexicostatistical work on language varieties, we lack                                           0
                                                                                             δ(sl , sl ) = 1 − sim(Dls, , Dls, )
                                                                                                                                      0
                                                                                                                                                    (2)
readily identified labels (cognate expressions) in the two lan-
guages between which the distance can be calculated. Instead           To compare how similar the two languages are in their over-
we take an approach similar to Malt et al. (1999).                     all conception of the semantic space, we calculate the mean
                                                                                 0
    The elicitations for every language give us a count matrix C       δ(sl , sl ) over all situations in S:
containing a set of situations S on the rows, and a set of spatial
markers M in that language on the columns. Every cell is                                                                     0      1
                                                                                               ∆(l, l 0 ) = ∑ δ(sl , sl ) ·                         (3)
filled with the count of participant responses to situation s that                                           s∈S                   |S|
use marker m. Matrix C captures the way that the language
carves up the space of situations: situations s and s0 are treated         Calculating the distances between all pairs of languages
similarly in the language to the extent that their use of spatial      in each dataset, we can now determine how the between-
markers have similar distributions, reflected in rows s and s0         language distances for our dataset compare to those of the
of C. However, we cannot compare the spatial representation            LM data. Using a t-test for independent samples, we found
                                                                 0
of two languages l and l 0 by simply comparing Cl and Cl ,             that the crowdsourced data displayed more between-language
                                       l      l 0
since the sets of spatial markers M and M are different, and           variation than the LM data (µCF = 0.146, µLM = 0.098,t =
hence the matrices have different columns.                             5.79, p < 0.001). However, as Levinson et al. (2003) did not
    In order to compare languages, instead of directly compar-         code general locative markers, we also compared our dataset
ing counts of markers, we need to compare the conceptualiza-           without such markers.4 In that case, our data is still more var-
tion of the set of situations within one language to that of the       ied, but the difference is no longer significant at the .05-level
other language. Building on the observation that situations            (µCF = 0.115, µLM = 0.098,t = 1.90, p < 0.1). This means
are similar within a language l to the extent that their rows          that using this sample of languages is not narrower in the
in Cl are similar, we can compare the verbalization of each            range of between-language variation it captures.
situation s ∈ S with each other situation s0 ∈ S by looking at             Further insight in the between-language variation can be
rows s and s0 of Cl . First, we normalize each row of Cl to            obtained by calculating the distance between any pair of lan-
yield the relative frequency of each of the markers given that         guages in either dataset—i.e., we find ∆(l, l 0 ) for all l and
situation. Each row s now gives us a probability distribution          l 0 in the LM dataset or our dataset (“CF”; we used the data
over the markers for a single situation in l, P(M l |s). We can        without the general locatives for this comparison). This
then compute the distance between two situations as:
                                                                            3 A cell may be unfilled: if no markers are used for a situation (in
                    0                    l        l 0                  our case, because all participants’ responses fell in other classes than
              δ(s, s |l) = 1 − sim(P(M |s), P(M |s ))          (1)     Class 1), no probability distribution can be calculated and hence no
                                                                       distance between that situation and any other situation.
where sim is the similarity of two distributions calculated us-             4 General locatives we consider: Basque -an, -tik; Indonesian di,
ing cosine. Calculating this δ for all situation pairs, we obtain      pada; Nahuatl -pan, -ko; Quechua -pi; Swahili ku, -ni; Thai thi.
                                                                   204

  Figure 3: Predicted prepositions for situations whose observed most-frequent preposition was one of the four under study.
(a) On the basis of the LM data.
                               'in' situations                                                  'om'
                                                                                             'om'    situations
                                                                                                  situations                                                          'aan' situations                                    'op' situations
                  1.00                                               1.00 1.00                                                                           1.00                                                1.00
    % predicted                                        % predicted                                                                         % predicted                                         % predicted
                  0.75                                               0.75                                                    predicted                   0.75                                                0.75
                  0.50                                               0.50 0.75                                               preposition                 0.50                                                0.50
                                                                       % predicted
                  0.25                                               0.25                                                       aan                      0.25                                                0.25
                                                                                     0.50                                       in
                  0.00                                               0.00                                                                                0.00                                                0.00
                         100   300   500   700   900                                   100    300     500   700       900       om                              100    300   500   700   900                        100   300   500   700   900
                                n input items                                        0.25      n input items                    op                                      n input items                                      n input items
(b) On the basis of the crowdsourced data.0.00
                                                                                             100    300   500   700    900
                                                                                                    n input items
                               'in' situations                                               'om' situations                                                          'aan' situations                                    'op' situations
                  1.00                                               1.00                                                                                1.00                                                1.00
    % predicted                                        % predicted                                                                         % predicted                                         % predicted
                  0.75                                               0.75                                                                                0.75                                                0.75
                  0.50                                               0.50                                                                                0.50                                                0.50
                  0.25                                               0.25                                                                                0.25                                                0.25
                  0.00                                               0.00                                                                                0.00                                                0.00
                         100   300   500   700   900                                  100     300     500   700       900                                       100    300   500   700   900                        100   300   500   700   900
                                n input items                                                  n input items                                                            n input items                                      n input items
yields a distance matrix whose results can be visualized two-                                                                         the LM data, thus obtaining a semantic space within which all
dimensionally with Multi-Dimensional Scaling, as in Fig-                                                                              situations were located. Using the first 6 components of the
ure 2. The fact that LM datapoints for Dutch and Basque                                                                               PCA, BFS trained a Gaussian Naı̈ve Bayes classifier on pair-
are very close in the space to those languages (respectively)                                                                         ings of a situation—i.e., its PCA semantic representation—
in our data constitutes a sanity check: Dutch participants in                                                                         and a preposition in Dutch expressing that situation in the
both studies described the situations in very similar ways.                                                                           LM data. The input items were generated on the basis of the
   Overall, while there are many differences in the two                                                                               frequency of the prepositions in child-directed speech, and
datasets in both language sample and response types, our                                                                              the frequency of association of a situation with a particular
dataset shows as much between-language variation as the LM                                                                            preposition in the elicitation data. Within every simulation,
dataset, supporting the view that crowdsourcing is a promis-                                                                          BFS incremented the size of training data with 20 new items
ing data collection method for typological research.                                                                                  at a time, up to 1000 input items, and at each iteration used
                                                                                                                                      a “leave-one-out” methodology to classify each situation on
 The crowdsourced data in cognitive modeling                                                                                          the basis of the data points associated with the other 70 situa-
                                                                                                                                      tions. The classification of a situation yielded the preposition
BFS trained a word-learning model on a semantic space de-
                                                                                                                                      the model predicted was best for that situation.
rived from the LM dataset, and showed that crosslinguisti-
cally more common semantic distinctions are easier to learn.                                                                             Figure 3a shows how the model classified the situations
Another way to evaluate the crowdsourced data is to consider                                                                          associated with the four prepositions over time; each graph
whether we can replicate those results. Doing so would fur-                                                                           corresponds to the group of situations whose most frequent
ther support the similarity of crowdsourced data to the LM                                                                            response was the labelled preposition (i.e., this is the target
data, and hence its viability.5                                                                                                       response for the model on that set of situations). In line
   The phenomenon under study. Gentner and Bowerman                                                                                   with the Typological Prevalence Hypothesis, the model ini-
(2009) suggested that Dutch prepositions op (‘surface sup-                                                                            tially overextends op to situations where most language users
port’) and in (‘containment’) are acquired earlier than aan                                                                           would use aan or om. After 1000 input items, the model pre-
(‘tenuous support’) and om (‘surrounding (support)’), be-                                                                             dicted the correct label in 74% of all cases on average.
cause op and in reflect natural semantic groupings of spatial                                                                            Replication using the crowdsourced data. We follow the
relations. They noted that children regularly overgeneralize                                                                          exact same procedure above, replacing the semantic represen-
the preposition op to situations where most adult speakers                                                                            tation of each situation with one derived from the new data
would use aan or om.                                                                                                                  (including general locatives). As we see in Figure 3b, the
   Previous experiments. BFS simulated Gentner and Bow-                                                                               qualitative pattern is the same as in BFS: op is overgeneral-
erman’s (2009) finding and further explored the interaction                                                                           ized in the early stages of learning to situations where aan
between the semantic domain and word frequencies. They                                                                                and om are expected to be used by adult speakers, and after
did so by applying Principal Component Analysis (PCA) to                                                                              this phase of overgeneralization, the model uses the correct
                                                                                                                                      preposition in most of the cases. The final overall accuracy is
    5 The cognitive modeling experiments involve learning semantics                                                                   76% over 30 simulations.6
of Dutch prepositions. Although the Dutch data was the cleanest,                                                                         Error analysis Given that the model never reaches full ac-
this remains a valid test of the dataset, since the semantic space was
derived from the entirety of the data, and as such reflects the proper-
ties of all languages, not just Dutch.                                                                                                     6 Data               and software are available on github.com/dnrb/cogsci15
                                                                                                                               205

Figure 4: Model errors. Situations are plotted on the PCA space, using text labels with the correct preposition for that situation.
                                        (a) After 40 input items.                                                              (b) After 1000 input items.
                                                  aan                                                                                      aan
                       10                aanaan   aan
                                             aan aan                                                            10                aanaan   aan
                                                                                                                                      aan aan
                                                                             proportion                                                                               proportion
                                                   aan aan
                                                         aan                 correctly                                                      aan aan
                                                                                                                                                  aan                 correctly
                                                aanaan
                                                aan om om
                                                        om                   predicted                                                   aanaan
                                                                                                                                         aan om om
                                                                                                                                                 om                   predicted
        component 2                                                                              component 2
                        5                                                                                        5
                                             op aan omom
                                                      aan
                                                       omaan
                                                          omin               a   0.00                                                 op aan omom
                                                                                                                                               aan
                                                                                                                                                omaan
                                                                                                                                                   omin               a   0.00
                                    opop         op in                       a                                               opop         op in                       a
                        0
                                       op op opop
                                            op
                                                                                 0.25                            0
                                                                                                                                op op opop
                                                                                                                                     op
                                                                                                                                                                          0.25
                                      op                                                                                       op
                                           opop         in inin              a   0.50                                               opop         in inin              a   0.50
                      −5         op               in op                      a                                 −5         op               in op                      a
                             opop                                                0.75                                 opop                                                0.75
                            op op
                              op                               in   in       a   1.00
                                                                                                                     op op
                                                                                                                       op                               in   in       a   1.00
                      −10    op                                                                                −10    op
                                                                      inin
                                                                       in
                                                                       in
                                                                        in                                                                                     inin
                                                                                                                                                                in
                                                                                                                                                                in
                                                                                                                                                                 in
                            −20        −10          0          10                                                    −20        −10          0          10
                                             component 1                                                                              component 1
curacy, it is interesting to see for which situations it makes                                     Another methodological difference with Levinson et al.
errors; see Figures 4a and 4b. We limit the discussion to the                                   (2003) is that they did not consider markers with a general
four prepositions studied by Gentner and Bowerman (2009).                                       locative meaning. As we could not discriminate general loca-
   With the model trained on only 40 inputs, the overgeneral-                                   tives on the crowdsourcing platform, our data contains many
ization of op to the aan and om regions is very evident. For                                    cases of these as well. The reason a speaker uses a gen-
the aan region, this is striking, as large parts of it are rela-                                eral locative may be pragmatic (i.e., no communicative need
tively remote from any instance of op. We interpret this as                                     to mark the specific spatial relation), or more systemic (the
an effect of the frequencies of the prepositions: with spatial                                  language has no specific marker for that relation). Since
op being far more frequent in child-directed speech than spa-                                   the pragmatic set-up in our task (responding to the instruc-
tial aan, the stronger representation of the more frequent op                                   tion) does not vary, any between-situation differences in the
extends into the aan region of the space early on.                                              amount of general locatives are likely due to systemic rea-
   After the model has seen 1000 input items, most aan errors                                   sons. Here, we assume that general locatives are used when
are resolved, but four items between the op and in clusters                                     the situation is not prototypical ‘support’ or ‘containment’.
defy classification. Interestingly, none of these cases is a pro-                               We therefore expect that, as with Class 2 and 3 items, the sit-
totypical instance of surface support or containment: ‘apple                                    uations where general locatives are used will fall in the space
in ring’, ‘hole in towel’, and ‘cork in bottle’ (all in in Dutch)                               of situations for which children make errors.
and ‘boat on water’ (op in Dutch). Because languages vary                                          As expected, we find higher amounts of all three of these
in their grouping of these situations (e.g., Thai groups ‘hole                                  response types—non-spatial expressions (Class 2), Figure-
in towel’ with an on-like preposition), the situations fall be-                                 Ground reversals (Class 3), and general locatives—in the cen-
tween the two clusters. To the extent that the semantic space                                   tral upper region of the space (Fig. 5). This is also the region
captures universal tendencies, these results would predict that                                 where children make underextension errors (cf. Fig. 4a). All
children may have persistent difficulties in such cases as well.                                three are remarkably less frequent in the regions where we
                                                                                                find prototypical ‘support’ (bottom left) and ‘containment’
 Further exploration of the crowdsourced data                                                   (bottom right) situations. Following Gentner and Bower-
The crowdsourced data displays similar between-language                                         man’s (2009) reasoning, the higher amount of non-specific or
variation and yields comparable modeling results to                                             non-spatial marking in the central region suggests that these
manually-gathered data, but do the differences in methodol-                                     situations are less naturally construed as involving a (specific)
ogy behind our crowdsourced data also lead to new insights                                      spatial relationship than the prototypical cases of ‘contain-
in the understanding of semantic typologies? One difference                                     ment’ and ‘support’. Furthermore, if languages differ in the
is that we were not able to give feedback to participants in                                    set of situations they (conventionally) conceptualize as ‘spa-
the online environment on the appropriateness of a response.                                    tial’, learning what the boundaries of this set are (i.e., taking
While this resulted in many non-target responses, many of                                       into account Class 2 and 3 responses) should ideally be part
these are nonetheless informative. Notably, responses in                                        of the cognitive modeling task.
Classes 2 and 3 (non-spatial expressions and Figure-Ground
reversals) could not be used for the comparison with the LM                                                                               Conclusion
data (which contain only spatial relation markers), but contain                                 When doing semantic typology, it is desirable to have quick
valid relational descriptions. We suggest that when a situa-                                    and easy access to elicitation data. In this paper, we explored
tion has many Class 2 and 3 responses, it is less readily con-                                  the use of crowdsourcing platforms for obtaining such data.
strued as a spatial relation between the particular Figure and                                  We gathered a dataset of elicitations for the Topological Spa-
Ground. Under this assumption, we expect that most Class 2                                      tial Relations stimuli set (Bowerman & Pederson, 1992), and
and 3 responses will be found in the region where the Dutch                                     compared it to the in-person elicitations of Levinson et al.
children make errors: the aan and om situations (cf. Fig. 4).                                   (2003). The between-language variation is similar for both
                                                                                          206

                                                                                        Figure 5: Further exploration of the data
                       (a) Class 2 codings per situation.                                                     (b) Class 3 codings per situation.                                                    (c) General locatives per situation.
                                           27                                                                                     27                                                                                     27
                10                44 25
                                      37 41  920                                                       10                44 25
                                                                                                                             37 41  920                                                       10                44 2537 41 920
                                            63 5721                                                                                63 5721                      n Class 3                                                 63 5721
                                                   55                    n Class 2                                                        55                    per language                                                     55
                 5                        56
                                           33 50 51
                                              10                         per language                   5                        56
                                                                                                                                  33 50 51
                                                                                                                                     10                                                        5                        56
                                                                                                                                                                                                                         33 50 51
                                                                                                                                                                                                                            10                         proportion
 component 2                                                                            component 2                                                                            component 2
                                          45 61                                                                                  45 61                                                                                  45 61                          general
                                       35      4644266
                                                    70
                                                     15                  a   0                                                35      4644266
                                                                                                                                           70
                                                                                                                                            15                  a   0
                                                                                                                                                                                                                     35      4644266
                                                                                                                                                                                                                                  70
                                                                                                                                                                                                                                   15                  locatives
                 0            752     12  48 18 69                                                      0            752     12  48 18 69                       a   1                          0            752     12  48 18         69
                               173 28
                                    68 22                                a   1                                        173 28
                                                                                                                           68 22                                                                             173 28
                                                                                                                                                                                                                  68  22                               a   0.2
                                   5 29           62 3926                                                                 5 29           62 3926                a   2                                            5 29           62 3926                a   0.4
                                         19 11                           a   2
                                                                                                                                19 11                                                                                  19 11
               −5
                      65348                                              a   3
                                                                                                      −5
                                                                                                             65348                                              a   3                        −5
                                                                                                                                                                                                    65348                                              a   0.6
                       23                                                                                     23                                                a   4                                23
               −10    140
                     59                                47        67                                   −10    140
                                                                                                            59                                47        67                                   −10    140
                                                                                                                                                                                                   59                                 47        67
                                                                  14
                                                                   271
                                                                   54
                                                                   32                                                                                    14
                                                                                                                                                          271
                                                                                                                                                          54
                                                                                                                                                          32                                                                                     14
                                                                                                                                                                                                                                                  2
                                                                                                                                                                                                                                                  54
                                                                                                                                                                                                                                                  32
                                                                                                                                                                                                                                                  71
                     −20        −10          0              10                                              −20        −10          0              10                                              −20        −10          0               10
                                      component 1                                                                            component 1                                                                            component 1
data sets, suggesting that using only languages accessible                                                                                       opment. In Proceedings Child Language Research Fo-
through crowdsourcing does not limit the variational band-                                                                                       rum (pp. 7–15). Stanford: CSLI Publications.
width of the typological sample.                                                                                                           Bowerman, M., & Choi, S. (2001). Shaping meanings for
   In Beekhuizen et al. (2014), we trained a model of word-                                                                                      language: universal and language-specific in the ac-
meaning acquisition on a semantic space derived from the                                                                                         quisition of semantic categories. In M. Bowerman &
elicitation data of Levinson et al. (2003). The interaction                                                                                      S. C. Levinson (Eds.), Language acquisition and con-
of the lay-out of this space and the frequencies of the vari-                                                                                    ceptual development (pp. 475–511). Cambridge: CUP.
ous words accounted for the overgeneralization of the Dutch                                                                                Bowerman, M., & Pederson, E. (1992). Cross-linguistic stud-
preposition op to cases where the prepositions aan and om are                                                                                    ies of spatial semantic organization. In Annual Report
licensed. In this paper, we replicate those findings using the                                                                                   of the MPI for Psycholinguistics (pp. 53–56).
crowdsourced data, further supporting that the information in                                                                              Chen, D. L., & Dolan, W. B. (2011). Building a persistent
the online elicitations yields a semantic space that is usable                                                                                   workforce on Mechanical Turk for multilingual data
for purposes of cognitive modeling.                                                                                                              collection. In Proceedings AAAI.
   Our method of using a crowdsourcing platform allows for                                                                                 Cysouw, M. (2014). Inducing semantic roles. In S. Luraghi &
quick access to semantic elicitations. However, quality con-                                                                                     H. Narrog (Eds.), Perspectives on Semantic Roles (pp.
trol remains an issue. Many respondents give invalid answers,                                                                                    23–68). Amsterdam: Benjamins.
and even for valid answers, it is sometimes hard to judge                                                                                  Gentner, D., & Bowerman, M. (2009). Why some spatial
whether respondents are native speakers. A next step is to                                                                                       semantic categories are harder to learn than others. The
adapt recent mechanisms for quality control available within                                                                                     Typological Prevalence Hypothesis. In J. Guo et al.
the technical constraints of the crowdsourcing platforms.                                                                                        (Ed.), Crosslinguistic approaches to the psychology of
   Nonetheless, the use of crowdsourcing to obtain semantic                                                                                      language. Research in the tradition of Dan Isaac Slobin
elicitations is a viable method. With relatively little effort,                                                                                  (pp. 465–480). New York: Psychology Press.
a usable dataset ranging over geographically and genetically                                                                               Khetarpal, N., Majid, A., & Regier, T. (2009). Spatial
distant languages can be created. Paradoxically, there are                                                                                       terms reflect near-optimal spatial categories. The anal-
benefits to having less control over the nature of the responses                                                                                 ogy with color. In Proceedings CogSci.
compared to manual elicitations, and getting responses that                                                                                Levinson, S. C., Meira, S., & The Language and Cognition
were not what one hoped for. For some situations, many re-                                                                                       Group. (2003). ’Natural concepts’ in the spatial topo-
spondents avoided static spatial terms, opting for a mecha-                                                                                      logical domain – Adpositional meanings in crosslin-
nistic description instead. Findings like these provide insight                                                                                  guistic perspective: An exercise in semantic typology.
into the boundaries of the semantic domain of static space.                                                                                      Language, 79(3), 485–516.
                                                                                                                                           Majid, A., Boster, J. S., & Bowerman, M. (2008). The cross-
Acknowledgements: We gratefully acknowledge NWO of the                                                                                           linguistic categorization of everyday events: a study of
Netherlands (grant 322.70.001), NSERC of Canada, Stephen Levin-                                                                                  cutting and breaking. Cognition, 109(2), 235–50.
son and Asifa Majid for making the data and stimuli available, and                                                                         Majid, A., Jordan, F., & Dunn, M. (2014). Semantic systems
three anonymous reviewers for useful comments and suggestions.                                                                                   in closely related languages. Language Sciences, 1–18.
                                                                                                                                           Malt, B. C., Sloman, S. A., & Gennari, S. (1999). Knowing
                                                    References                                                                                   versus naming: Similarity and the linguistic categoriza-
Beekhuizen, B., Fazly, A., & Stevenson, S. (2014). Learning                                                                                      tion of artifacts. J. Mem. Lang., 262, 230–262.
      meaning without primitives: Typology predicts devel-                                                                                 Pavlick, E., Post, M., Irvine, A., & Kachaev, D. (2014). The
      opmental patterns. In Proceedings CogSci.                                                                                                  language demographics of Amazon Mechanical Turk.
Berlin, B., & Kay, P. (1969). Basic Color Terms: Their                                                                                           In Proceedings ACL.
      Universality and Evolution. Berkeley: UC Press.                                                                                      Regier, T., Kay, P., & Khetarpal, N. (2009). Color naming
Bowerman, M. (1993). Typological perspectives on language                                                                                        and the shape of color space. Language, 85, 884–892.
      acquisition: Do crosslinguistic patterns predict devel-
                                                                                                                                    207

