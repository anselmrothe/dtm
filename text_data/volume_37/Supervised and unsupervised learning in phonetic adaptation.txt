                    Supervised and unsupervised learning in phonetic adaptation
                              Dave F. Kleinschmidt1 , Rajeev Raizada1 , and T. Florian Jaeger1,2,3
                                   {dkleinschmidt, raizada, fjeager} @ bcs.rochester.edu
       1 Department    of Brain and Cognitive Sciences, 2 Department of Computer Science, and 3 Department of Linguistics,
                                             University of Rochester, Rochester, NY, 14607 USA
                               Abstract                                    phonetic adaptation were from supervised paradigms. For in-
                                                                           stance, after repeatedly hearing an ambiguous /f/-/s/ sound
   Speech perception requires ongoing perceptual category learn-           spliced into words that can only end in /f/ (e.g., sheriff ), lis-
   ing. Each talker speaks differently, and listeners need to learn
   each talker’s particular acoustic cue distributions in order to         teners classified more items on an /f/-/s/ continuum as /f/, and
   comprehend speech robustly from multiple talkers. This pho-             vice-versa when the ambiguous /f/-/s/ was spliced into /s/-
   netic adaptation is a semi-supervised learning problem, be-             final words (e.g., Norris, McQueen, & Cutler, 2003; Kraljic
   cause sometimes a particular cue value occurs with informa-
   tion that labels the talker’s intended category for the listener,       & Samuel, 2005).
   but other times no such labels are available. Previous work has
   shown that adaptation can occur in both purely supervised (all             A small number of recent studies have demonstrated that
   labeled) and purely unsupervised (all unlabeled) settings, but          phonetic adaptation can occur in an unsupervised context as
   the interaction between them has not been investigated. We
   compare unsupervised with (semi-) supervised phonetic adap-             well. Both Clayards, Tanenhaus, Aslin, and Jacobs (2008)
   tation and find, surprisingly, that adult listeners do not take ad-     and Munson (2011) had listeners listen to /b/-/p/ minimal pair
   vantage of labeling information to adapt more quickly or effec-         words (e.g., beach/peach) with different VOTs, and click on
   tively, even though the labels affect their categorization. This
   suggests that, like language acquisition, phonetic adaptation in        a picture to indicate the word they heard. Across trials, the
   adults is dominated by unsupervised, distributional learning.           VOTs were drawn from a bimodal distribution with a low and
   Keywords: Cognitive Science, Linguistics, Psychology, Lan-              a high VOT cluster. Listeners learned these distributions, as
   guage understanding, Learning, Speech recognition
                                                                           reflected in how they classified the VOT continuum, both the
                                                                           location and slope of their category boundary.
                           Introduction
                                                                              Such unsupervised adaptation requires that listeners com-
Everyone speaks differently. In order to deal with this vari-
                                                                           bine the cue distributions they actually observe with their
ability, listeners need to adapt to each new talker they meet,
                                                                           prior knowledge about what distributions are typical across
learning how they produce each phonetic category. For in-
                                                                           talkers (Kleinschmidt & Jaeger, 2015). If a listener hears
stance, in order to tell whether a talker intended to produce
                                                                           words with VOTs that cluster around 0 ms and 40 ms, they
a /b/ or /p/, a listener needs to first learn that talker’s /b/ and
                                                                           can infer that the mean VOT for /b/ is 0 ms and for /p/ is
/p/ distributions of phonetic cues like voice onset time (VOT).
                                                                           40 ms, and that their classification should switch from /b/ to
We refer to this distributional learning as phonetic adaptation.
                                                                           /p/ around 20 ms. In the absence of labels, each cue value is
   Like all perceptual category learning, phonetic adaptation              in principle ambiguous, and listeners need to observe enough
can be supervised or unsupervised. In supervised learning,                 different cue values to infer the underlying clusters.
each observed VOT value is labeled with information that
tells the listener whether the talker intended to produce /b/ or              In actual experience, however, phonetic adaptation is rarely
/p/. Such labeling information might come from, for instance,              purely unsupervised or supervised, with a mix or labeled and
the surrounding word (bash vs. ∗ pash), or from visual cues                unlabeled observations. This raises the question: do listeners
to articulation. In unsupervised learning, however, no such                take advantage of extra information provided by labeled ob-
labeling information is available. This is the case during lan-            servations in phonetic adaptation? Work on domain-general
guage acquisition (e.g., Vallabha, McClelland, Pons, Werker,               semi-supervised category learning suggests that learners can
& Amano, 2007) but it can also occur in adult language adap-               leverage labeled trials to make learning from unlabeled tri-
tation when a VOT value occurs in a novel word, or a word                  als even more effective (Gibson, Rogers, & Zhu, 2013). Ex-
that could have either /b/ or /p/, like beach/peach. In general            isting phonetic adaptation paradigms do not directly answer
unsupervised learning is harder: in addition to figuring out               this question, being purely supervised or purely unsuper-
the distribution of VOTs for each category from limited ob-                vised. Moreover, it’s possible that what appears to be su-
servations, listeners also have to figure out how each of those            pervised learning in phonetic adaptation actually reflects a
observations should be categorized. Each of these depends                  combination of cue-combination and unsupervised learning
on the other: how to categorize VOTs depends on the dis-                   (Kleinschmidt & Jaeger, 2011, 2015). In this paper, we in-
tributions for each category, while the distributions for each             vestigate the effect of adding some labeled trials to an other-
category depend on which VOTs are thought to belong to that                wise unsupervised phonetic adaptation paradigm. This allows
category.                                                                  us to compare unsupervised and semi-supervised adaptation
   Both supervised and unsupervised phonetic adaptation                    in the same paradigm, and thus directly assess the role that
have been observed in experiments. The earliest findings of                labeling information might play in phonetic adaptation.
                                                                       1129

         50
         40
                                             supervised
         30
         20
         10                                                 Trial type
 Count
          0                                                     labeled
         50
                                                                unlabeled
                                             unsupervised
         40
         30                                                                         (a) Unlabeled trial with minimal pair distractor “peach”.
         20
         10
          0
              −20   0      20      40   60
                        VOT (ms)
Figure 1: Stimuli distributions for unshifted condition in Ex-
periment 1. The implied category boundary is at 20ms                               (b) Labeled trial with non-minimal pair distractor “peas”.
                                                                               Figure 2: Example trial displays for the target word “beach”
                          Experiment 1
Methods                                                                        ±10 ms VOT from the modal values (−10 ms, 10 ms, 30 ms,
Subjects We recruited 124 subjects via Amazon’s Mechan-                        and 50 ms in the unshifted condition) were always unlabeled,
ical Turk, who were paid $2.00 for participation, which took                   and other stimuli were always labeled (−20 ms, 20 ms, and
about 20 minutes. We excluded subjects whose accuracy at                       60 ms).
0 ms and 70 ms VOT—as extrapolated via a logistic GLM—
                                                                               Results
was less than 80% correct. 10 subjects were excluded for this
reason, leaving 114 for analysis.                                              People used the labels for classification On labeled trials
                                                                               in the supervised condition, listeners responded consistently
Stimuli Following Clayards et al. (2008), subjects heard
                                                                               with the label 98% of the time. This means that the response
spoken words, all members of /b/-/p/ minimal pairs
                                                                               options available did, as we intend, effectively label the per-
(beach/peach, bees/peas, and beak/peak) synthesized with
                                                                               cept.
VOTs ranging from −20 ms to 90 ms. The actual VOT values
that subjects heard were drawn from a bimodal distribution.                    Learning was good overall Figure 3 (top) shows the ag-
The baseline, unshifted distribution (Figure 1) had a mean of                  gregate classification functions (averaged over subjects) for
0 ms for /b/ and 40 ms for /p/ with an implied /b/-/p/ boundary                each third of the experiment. To evaluate how well listen-
at 20 ms. Subjects heard either this unshifted distribution, or                ers learned the distributions of VOTs they were exposed to,
a version that was shifted up by 10 ms VOT, with an implied                    we analyzed the classification responses on unlabeled tri-
category boundary at 30 ms VOT.                                                als1 using a mixed-effects logistic regression model. This
                                                                               model included fixed effects for stimulus VOT, supervised
Procedure On each trial, two pictures (target + distractor)
                                                                               vs. unsupervised condition, distribution shift condition (0 ms
were shown, and subjects were instructed to click on the pic-
                                                                               or 10 ms), trial, and all interactions thereof. We used the max-
ture that matched a spoken target word (e.g., beach). There
                                                                               imal random effects structure for this design, with by-subject
were two kinds of trials. On unlabeled trials, the distractor
                                                                               random intercepts and slopes for all the within-subject vari-
picture was the minimal pair neighbor of the target word (e.g.,
                                                                               ables (trial, VOT, and their interaction). Table 1 shows the
a peach, Figure 2a), meaning that listeners had no additional
                                                                               fixed effect coefficient estimates for this model and describes
information besides the VOT about whether the word started
                                                                               the details of how each variable was coded.
with a /b/ or a /p/. On labeled trials, the onset of the distrac-
                                                                                  Figure 3 (bottom) shows the predictions of these fixed ef-
tor picture’s name was a minimal pair neighbor of the target
                                                                               fects (i.e., the fitted classification functions) for each condi-
word, but the rest was unrelated (e.g., bees, Figure 2b). This
                                                                               tion at the midpoint of each third of the experiment. We eval-
meant that the end of the word served as a label for the initial
                                                                               uated learning as the location of the /b/-/p/ category boundary,
segment, and hence labeled the VOT value as either /b/ or /p/.
                                                                               or where the fitted classification functions crossed the 50%
   Subjects were randomly assigned to one of two conditions.
                                                                               /p/-response line.
In the unsupervised condition, all trials were unlabeled. In
                                                                                  Listeners learned well overall, and their classifications re-
the supervised condition half were labeled and half unla-
                                                                               flected the implied category boundaries of 20 ms and 30 ms
beled. In the supervised condition, each possible VOT was
                                                                               within 2 ms.
either always labeled, or always unlabeled (Figure 1). Specif-
ically, the modal VOTs for /b/ and /p/ (0 ms and 40 ms in                        1 In the unsupervised condition, we only analyzed trials that
the unshifted condition) were always labeled, the stimulus at                  would also have been unlabeled in the supervised condition.
                                                                            1130

                                                  Trials 0 − 73                                 Trials 74 − 147                            Trials 148 − 221
                            1.00                                      ●
                                                                      ●
                                                                          ●
                                                                          ●                                       ●
                                                                                                                      ●
                                                                                                                      ●
                                                                                                                           ●
                                                                                                                           ●
                                                                                                                                                         ●
                                                                                                                                                              ●
                                                                                                                                                              ●
                                                                                                                                                                  ●
                                                                                                                  ●                                      ●
                                                                ●
  Proportion /p/ response
                                                                ●
                                                            ●                                                ●
                                                                                                             ●
                            0.75                            ●
                                                                                                                                                     ●
                                                                                                                                                     ●
                                                                                                                                                                                       Shift (ms)
                            0.50                       ● ●                                             ● ●                                      ● ●                    actual           ● 0
                                                                                                                                                                                        ●
                            0.25                  ●
                                                       ●
                                                       ●                                               ●                                        ●
                                                                                                                                                ●                                       ● 10
                                                                                                                                                                                        ●
                                                  ●                                               ●                                         ●
                                                                                                  ●                                         ●
                                      ●   ●                                         ●
                            0.00                                                            ●                                      ●
                                                                                                                                   ●   ●
                                                                                                                                       ●
                            1.00
                                                                                                                                                                                       Condition
                                                                                                                                                                       fixed effects
                            0.75
                                                                                                                                                                                            supervised
                            0.50                       ● ●                                             ● ●                                      ● ●
                                                                                                                                                                                            unsupervised
                            0.25
                            0.00
                                          0           20        40        60                0         20         40       60           0        20       40       60
                                                                                                      VOT (ms)
Figure 3: In Experiment 1, listeners’ classification of unlabeled trials (lines) closely matches the implied category boundaries
(open circles) for the unshifted (red) and 10 ms shifted (blue) distributions, but there is no difference between supervised and
unsupervised learning (solid vs. dashed lines). Learning appears as the differences between 0 ms and 10 ms shifts (red vs.
blue) and increasingly steep category boundaries (left to right). Top lines are raw average responses, and bottom lines are fitted
logistic classification functions and 95% CIs on fixed effects (see Table 1).
                                                                                                                               to determine whether labels affect adaptation when the same
                50
                                                                                                                               stimuli occur as labeled and unlabeled, and when unlabeled
                40                                                                              Trial type
                                                                                                                               test trials occur over a broader range of VOTs.
 Count                                                                              mixed
                30                                                                                    labeled
                20
                                                                                                      unlabeled                Methods
                10
                            0                                                                                                  The design was identical to that of Experiment 1, except for
                                −20           0            20        40        60                                              the following modifications. First, we modified the super-
                                                      VOT (ms)
                                                                                                                               vised condition, spreading out labeled and unlabeled trials
                                                                                                                               more evenly (see Figure 4). Across trials, many VOT val-
Figure 4: Stimuli distributions in Experiment 2, unshifted                                                                     ues occurred as both labeled and unlabeled trials, unlike in
condition.                                                                                                                     the supervised condition of Experiment 1 where each VOT
                                                                                                                               value only occurred as labeled, or only occurred as unlabeled.
                                                                                                                               Second, we only ran this modified supervised condition, and
Supervision had no effect on learning Because labels re-
                                                                                                                               compared it to the unsupervised condition of Experiment 1.
duce the difficulty of the distributional learning problem, we
expected that learning would be faster or better overall in the                                                                Subjects We recruited 62 subjects via Amazon’s Mechani-
supervised condition. Contrary to these expectations, learn-                                                                   cal Turk, who were paid $2.00 for participation, which took
ing in the supervised condition was neither faster, nor more                                                                   about 20 minutes to complete. 2 subjects were excluded for
complete, than in the unsupervised condition: the estimated                                                                    failing to reliably classify the continuum, and 2 were ex-
category boundaries differ by less than 1 ms VOT between                                                                       cluded from analysis because they had already participated
conditions.                                                                                                                    in Experiment 1, leaving 58 subjects for analysis.
                                                        Experiment 2                                                           Results
One of the shortcomings of the design of Experiment 1 is                                                                       As in Experiment 1, on labeled trials listeners used the labels
that in the supervised condition, listeners never heard exactly                                                                to guide their responses, responding consistently with the la-
the same stimulus with and without a label. This means that                                                                    bel 98% of the time.
the apparent inability or unwillingness of listeners to use the                                                                    We analyzed learning in the same way as Experiment 1, us-
labels for learning might reflect stimulus-specific learning, as                                                               ing the unsupervised condition from Experiment 1 as a base-
might be predicted by an episodic model of speech perception                                                                   line. Unlike in the analysis of Experiment 1, we considered
(Goldinger, 1998; Johnson, 1997). The sparse distribution                                                                      all trials from the unsupervised condition, because the labeled
of unlabeled trials may also reduce the statistical power by                                                                   trials in the supervised condition of Experiment 2 covered the
reducing the resolution with which the classification bound-                                                                   entire continuum. Figure 5 shows the raw data (top) and the
ary can be estimated. Experiment 2 varies the design slightly                                                                  fitted classification functions (bottom) and Table 1 shows the
                                                                                                                          1131

                                           Trials 0 − 73                          Trials 74 − 147                          Trials 148 − 221
                            1.00                        ●
                                                             ●
                                                             ●
                                                             ●   ●    ●                        ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                         ●
                                                                                                         ●
                                                                                                         ●
                                                                                                               ●
                                                                                                                                         ●
                                                                                                                                         ●
                                                                                                                                         ●
                                                                                                                                              ●
                                                                                                                                              ●
                                                                                                                                                  ●
                                                                                                                                                  ●    ●
                                                                                               ●
                                                                                               ●                                         ●
                                                        ●
  Proportion /p/ response
                                                                                                                                     ●
                                                                                           ●
                            0.75                    ●
                                                    ●
                                                                                           ●                                         ●
                                                                                                                                                                           Shift (ms)
                                                                                                                                                           actual
                                                    ●
                                                                                                                                     ●
                                               ● ●                                     ● ●                                      ● ●
                                                                                           ●
                            0.50                                                                                                                                            ● 0
                                                                                                                                                                            ●
                                               ●                                       ●                                        ●
                            0.25           ●
                                               ●
                                               ●                                       ●
                                                                                       ●                                    ●
                                                                                                                                ●
                                                                                                                                ●
                                                                                                                                                                            ● 10
                                                                                                                                                                            ●
                                           ●
                                           ●                                                                                ●
                                       ●                                          ●
                                       ●                                          ●
                                                                                  ●                                         ●
                                   ●   ●                                  ●
                                                                          ●   ●   ●                                    ●    ●
                            0.00   ●
                                       ●
                                                                          ●
                                                                              ●
                                                                              ●                                    ●
                                                                                                                   ●   ●
                            1.00
                                                                                                                                                                           Condition
                                                                                                                                                           fixed effects
                            0.75
                                                                                                                                                                                mixed
                            0.50               ● ●                                     ● ●                                      ● ●
                                                                                                                                                                                unsupervised
                            0.25
                            0.00
                                       0       20       40       60           0       20       40       60             0        20       40       60
                                                                                      VOT (ms)
Figure 5: In Experiment 2, for both distributions listeners’ classification (lines) closely matches the category boundary implied
by the distributions (open circles), just as in Experiment 1 (compare with Figure 3). Labels still made no difference (solid
vs. dashed lines), even though labeled trials were distributed more evenly over the VOT continuum than in Experiment 1.
fixed effects estimates.                                                                                     consistently labeled it as either /s/ or /S/. However, when
   As in Experiment 1, listeners learned quickly and their cat-                                              Norris et al. (2003) spliced the same sound in novel words
egory boundaries were very close to those implied by the dis-                                                that provided no labeling information, listeners did not adapt,
tributions of VOTs they heard. Again, however, learning in                                                   suggesting that labeling is crucial for phonetic adaptation.
the supervised condition (of Experiment 2) was neither faster                                                How can we reconcile these apparently contradictory results?
nor more complete than in the unsupervised condition (of Ex-                                                 We briefly discuss four possibilities here: that the kind of la-
periment 1): the category boundaries for supervised and un-                                                  bel matters, that learning was too easy, that self-supervision
supervised were within 2 ms of each other.                                                                   overwhelms any outside labels in this task, and that our labels
                                                                                                             were not sufficiently informative.
Discussion
Even when the same stimuli occur with and without labels,                                                    What kind of label?
the availability of labels appears to make little difference in                                              One possibility is that the kind of label matters. In previous
adapting to a novel talker’s /b/ and /p/ categories. This sug-                                               studies on phonetic adaptation where labels are provided, the
gests that the failure to find effects of supervision in Exper-                                              labels come either from a visual component of the stimulus
iment 1 was not due to the fact that labeled and unlabeled                                                   (e.g., a video of a natural production of /aba/, dubbed over
stimuli were acoustically different.                                                                         audio of an ambiguous /aba/-/ada/, Bertelson, Vroomen, &
                                                                                                             de Gelder, 2003) or from the lexical context (e.g., an am-
                                           General Discussion                                                biguous /s/-/S/ spliced into the word dino aur, Norris et al.,
In two experiments we directly compared phonetic adapta-                                                     2003; Kraljic & Samuel, 2005). In both cases, the label is an
tion with and without supervision. The presence of informa-                                                  intrinsic part of the (audio-visual) speech signal itself. In our
tion that labels an acoustic stimulus as a /b/ makes the task                                                design, the label comes from the pragmatic context, the avail-
of learning the distribution of acoustic cues for the /b/ cate-                                              able response choices. It is possible that listeners can use this
gory easier, at least in principle. Normative theories that treat                                            sort of pragmatic information to guide their responses, but
phonetic adaptation as a kind of distributional learning thus                                                that it is nevertheless not available to whatever systems are
predict that, in general, the availability of labels should make                                             responsible for perceptual learning.
adaptation faster, more complete, or both (Kleinschmidt &                                                       A related possibility is that labels that are intrinsic to the
Jaeger, 2015).                                                                                               signal affect distributional learning in a purely bottom-up
   Contrary to this prediction, we did not find any effect of su-                                            way. That is, disambiguating visual information (a natural
pervision on the distributional learning of cue-category map-                                                video of /aba/) might function not at the level of identify-
pings in adults. At first glance this contradicts the results of                                             ing the category that the talker intended to produce, but by
other studies on supervised phonetic adaptation, which sug-                                                  changing the cue that is perceived. Indeed, there is abundant
gest that people do use labeling information to facilitate learn-                                            evidence that cues are combined in this way within and across
ing. For instance, Norris et al. (2003) found adaptation when                                                modalities, in speech perception (Bejjanki, Clayards, Knill, &
listeners heard an ambiguous /s-S/ spliced into words that                                                   Aslin, 2011; Toscano & McMurray, 2010) and in perception
                                                                                                        1132

more generally (cf. Ernst & Bülthoff, 2004). If adaptation is             did not gain enough extra information about the underlying
driven by distributional learning of the integrated multimodal             distributions from the labels we provided them for it to make
percept, rather than the component cues, then what appears to              a difference in their learning behavior. This possibility seems
be sensitivity to category labels in previous adaptation studies           the most likely explanation of our results, and calls for further
may instead by bottom-up distributional learning of not-fully-             work using the same kind of labels, but with shorter exposure
ambiguous multimodal cues (Kleinschmidt & Jaeger, 2011).                   where the labels are more informative along the lines of ear-
                                                                           lier supervised adaptation studies (e.g., Norris et al., 2003).
A learning ceiling effect?
Listeners adapted very well to both the unshifted and 10 ms-                                         Conclusion
shifted distributions, with their classifications matching the
implied category boundaries even in the first third of the ex-             In two studies, we found that phonetic adaptation was insen-
periment. This suggests that learning these distributions may              sitive to label information, even thought those labels changed
have been too easy for the labels to make any difference.2 It              listeners’ classifications. Normative theories that see phonetic
remains a question for future work to see whether a more sen-              adaptation as a sort of statistical inference predict that lis-
sitive paradigm can find an effect of labels by, for instance,             teners should use all information available to them in order
using a smaller number of exposure trials to induce adapta-                to more effectively adapt to novel talkers (Kleinschmidt &
tion coupled with with a separate pre- and post-test to assess             Jaeger, 2015). While our results appear to violate that predic-
adaptation.                                                                tion, there are some important caveats. Most importantly, the
                                                                           labels we used may not have provided enough additional in-
Self-supervision                                                           formation about the underlying distributions, and for the pur-
Unlike most studies on domain-general semi-supervised                      poses of learning the category distributions may have been
learning, listeners in our studies have a great deal of prior              redundant with the statistics of the cues themselves. This
experience with the categories we are teaching them, at least              suggests a more nuanced understanding of the predictions of
as they are produced by other talkers. This makes even our                 normative models of adaptation. The combination of prior ex-
unsupervised condition partially supervised: listeners’ prior              perience with other talkers and sufficient observations from a
experience provides a self -supervision signal, or, in Bayesian            category might mean that, in many everyday situations, the
terms, a prior (Kleinschmidt & Jaeger, 2015). It thus could                availability of labels does not contribute enough extra infor-
be the case that this prior is sufficiently informative to make            mation to change listeners’ behavior. Further modeling and
any additional information provided by the labels themselves               behavioral work is required to investigate the tradeoff be-
redundant.                                                                 tween prior experience, number of observations, and infor-
   A related, if more extreme, possibility is that listeners               mativity of labels in adaptation. Regardless, it is still impor-
might decide the first time they hear, for instance, a VOT of              tant to note that the same labels may be informative about
10 ms that it is a /b/, and never change that belief. However,             how to classify but relatively uninformative about the overall
the fact that the category boundaries grow steeper with more               distribution.
exposure suggests that this is not correct: if listeners commit-
ted to a categorization of each individual stimulus early, then                                 Acknowledgments
their categorization functions should be sharp and constant                This work was partially funded by an NSF Graduate Research
throughout the experiment.                                                 Fellowship to DFK and NIHCD R01 HD075797 as well as
How informative is each label?                                             an Alfred P. Sloan Fellowship to TFJ. The views expressed
                                                                           here are those of the authors and not necessarily those of the
Previous phonetic adaptation studies that used labels applied              funding agencies.
those labels to trials that were acoustically maximally am-
biguous (e.g., Bertelson et al., 2003; Kraljic & Samuel, 2005;                                       References
Norris et al., 2003). This makes each label maximally infor-
mative without causing a cue conflict between the label and                Bejjanki, V. R., Clayards, M., Knill, D. C., & Aslin, R. N.
how listeners would have classified the cue without a label.                  (2011). Cue integration in categorical tasks: Insights from
In our design, labels occurred on many different cue values,                  audio-visual speech perception. PLoS ONE, 6(5), e19812.
many of which listeners would already have classified con-                    doi: 10.1371/journal.pone.0019812
sistently with the label a priori. Thus, on average, each label            Bertelson, P., Vroomen, J., & de Gelder, B. (2003). Visual
in our design provides substantially less information for the                 recalibration of auditory speech identification: a McGurk
listener than in previous designs. This may explain the fail-                 aftereffect. Psychological Science, 14(6), 592–597. doi:
ure to find any effect of labels on adaptation: listeners simply              10.1046/j.0956-7976.2003.psci 1470.x
                                                                           Clayards, M. A., Tanenhaus, M. K., Aslin, R. N., & Jacobs,
    2 We also investigated larger shifts of 20 ms and 30 ms, for which        R. a. (2008). Perception of speech reflects optimal use of
adaptation was incomplete. Nevertheless, labels made no difference
and so for the sake of brevity we do not report the detailed results          probabilistic speech cues. Cognition, 108(3), 804–9. doi:
here.                                                                         10.1016/j.cognition.2008.04.004
                                                                       1133

                                                             Experiment 1                     Experiment 2
                 (Intercept)                                    −0.08 (0.08)                     −0.09 (0.08)
                 VOT                                              1.83∗∗∗ (0.08)                  1.83∗∗∗ (0.07)
                 Shift                                            0.65∗∗∗ (0.16)                  0.75∗∗∗ (0.16)
                 Supervised                                       0.001 (0.16)                    0.16 (0.15)
                 Trial                                          −0.02 (0.16)                      0.17 (0.18)
                 VOT : Shift                                      0.05 (0.14)                    −0.03 (0.14)
                 VOT : Supervised                               −0.06 (0.14)                     −0.19 (0.13)
                 Shift : Supervised                             −0.02 (0.32)                     −0.27 (0.30)
                 VOT : Trial                                      0.76∗∗∗ (0.15)                  1.01∗∗∗ (0.14)
                 Shift : Trial                                    0.35 (0.27)                    −0.11 (0.33)
                 Supervised : Trial                             −0.34 (0.27)                      0.13 (0.32)
                 VOT : Shift : Supervised                       −0.04 (0.29)                     −0.13 (0.26)
                 VOT : Shift : Trial                              0.36 (0.25)                     0.18 (0.25)
                 VOT : Supervised : Trial                       −0.22 (0.25)                      0.12 (0.25)
                 Shift : Supervised : Trial                     −0.40 (0.54)                     −0.38 (0.64)
                 VOT : Shift : Supervised : Trial               −0.25 (0.50)                     −0.49 (0.49)
                 Observations                                   12,312                          18,378
                 Note:                                                          ∗ p<0.05; ∗∗ p<0.01; ∗∗∗ p<0.001
Table 1: Fixed effect coefficients (and standard errors) for mixed effects regression models of data from Experiments 1 and 2.
All categorical predictors were sum-coded (with range normalized to 1). To minimize collinearity between distribution shift
and stimulus VOT, stimulus VOT was re-coded relative to the implied category boundary. This means that the VOT predictor
was uncorrelated with the distribution shift predictor. To improve convergence, the VOT and boundary shift predictors were
coded as continuum steps (divided by 10) to put them on roughly the same scale as the other predictors. Finally, trial number
was centered and scaled to a range of 1 (very first trial = −0.5, very last trial = 0.5).
Ernst, M. O., & Bülthoff, H. H. (2004). Merging the senses           pathways of processing. Unpublished doctoral dissertation,
  into a robust percept. Trends in Cognitive Sciences, 8(4),          University of Iowa.
  162–9. doi: 10.1016/j.tics.2004.02.002                            Norris, D., McQueen, J. M., & Cutler, A. (2003). Perceptual
Gibson, B. R., Rogers, T. T., & Zhu, X. (2013). Human semi-           learning in speech. Cognitive Psychology, 47(2), 204–238.
  supervised learning. Topics in Cognitive Science, 5(1),             doi: 10.1016/S0010-0285(03)00006-9
  132–72. doi: 10.1111/tops.12010                                   Toscano, J. C., & McMurray, B. (2010). Cue integra-
Goldinger, S. D. (1998). Echoes of echoes? An episodic the-           tion with categories: Weighting acoustic cues in speech
  ory of lexical access. Psychological Review, 105(2), 251–           using unsupervised learning and distributional statistics.
  79.                                                                 Cognitive Science, 34(3), 434–464. doi: 10.1111/j.1551-
Johnson, K. (1997). Speech perception without speaker nor-            6709.2009.01077.x
  malization: An exemplar model. In Johnson & Mullennix             Vallabha, G. K., McClelland, J. L., Pons, F., Werker, J. F., &
  (Eds.), Talker variability in speech processing (pp. 145–           Amano, S. (2007). Unsupervised learning of vowel cate-
  165). San Diego: Academic Press.                                    gories from infant-directed speech. Proceedings of the Na-
Kleinschmidt, D. F., & Jaeger, T. F. (2011). A Bayesian               tional Academy of Sciences of the United States of America,
  belief updating model of phonetic recalibration and selec-          104(33), 13273–8. doi: 10.1073/pnas.0705369104
  tive adaptation. In Proceedings of the 2nd acl workshop on
  cognitive modeling and computational linguistics. Strouds-
  burg, PA: Association for Computational Linguistics. Talk.
Kleinschmidt, D. F., & Jaeger, T. F. (2015). Robust speech
  perception: Recognize the familiar, generalize to the simi-
  lar, and adapt to the novel. Psychological Review, 122(2).
  doi: 10.1037/a0038695
Kraljic, T., & Samuel, A. G. (2005). Perceptual learning for
  speech: Is there a return to normal? Cognitive Psychology,
  51(2), 141–78. doi: 10.1016/j.cogpsych.2005.05.001
Munson, C. M. (2011). Perceptual learning in speech reveals
                                                               1134

