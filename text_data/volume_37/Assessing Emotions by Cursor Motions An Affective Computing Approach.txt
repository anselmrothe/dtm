Assessing Emotions by Cursor Motions: An Affective Computing Approach
Takashi Yamauchi1, Hwaryong Seo2, Yoonsuck Choe3,
Casady Bowman1, and Kunchen Xiao1
1

Department of Psychology, 2Department of Visualization,
3
Department of Computer Science and Engineering
Texas A&M University, TX 77843
(takashi-yamauchi@tamu.edu)

Abstract
Choice reaching, e.g., reaching a targeted object by hand,
involves a dynamic online integration of perception, action and
cognition, where neural activities of prefrontal cortical regions
are concurrently coordinated with sensori-motor subsystems.
On the basis of this theoretical development, the authors
investigate the extent to which cursor movements in a simple
choice-reaching task reveal people’s emotions, such as anxiety.
The results show that there is a strong correlation between
cursor trajectory patterns and self-reported anxiety in male
participants. Because computer cursors are ubiquitous, our
trajectory analysis can be augmented to existing affective
computing technologies.
Keywords: affective computing; cursor motion; choice
reaching

Introduction
An adaptive computer system that can read users’ emotions
and tailor its output dynamically will transform the nature of
human-computer interactions. Present affective computing
methods apply facial expressions, vocal tones, gestures, and
physiological signals for emotion assessment (Calvo &
D’Mello, 2010; Zeng, Pantic, Roisman, & Huang, 2009); yet,
these methods are not always practical for everyday
applications (e.g., wearing a multi-channel EEG cap). This
article investigates the possibility of analyzing cursor motion
for affective computing in a choice reaching task.
To reach a target object by hand, thousands of muscles and
billions of nerve cells have to coordinate. In this process,
higher cortical systems (e.g., the prefrontal cortex) can only
make a coarse action plan (e.g., move your hand), and local
sensori-motor subsystems modulate the hand movement by
dynamically processing contextual and cognitive information
(Thelen, 1998). Choice-reaching behavior is dynamic in
nature, where motor coordination is adjusted in real time in a
continuous feedback loop (Spivey, 2007; Song & Nakayama,
2007). We hypothesize that emotions influence this process
and fine-tuned analysis of cursor trajectories can help assess
users’ emotional states.

Affective Computing
Two influential reviews published in 2009 and 2010 (Calvo
& D’Mello, 2010; Zeng et al., 2009) suggest the following
short-comings in the current Affective Computing (i.e., AC)

technologies: (1) many of the visual- and audio-based
methods (e.g., detecting emotions by facial expressions and
speech) do not fare well in a natural setting; (2) assessment
methods based on physiological signals (e.g., EEG) are still
impractical for everyday application. Our independent
review of the studies published in major Human Computer
Interaction (HCI) conferences and journals show significant
improvements in AC technologies in the last several years.
Techniques developed in “wearable computers” made great
progress in assessing people’s physiological states in
everyday settings (Hedman et al., 2009; McDuff, Karlson,
Kapoor, Roseway, & Czerwinski, 2012). The scope of AC
research has grown significantly, as AC technologies are now
applied for public speech training (Pfister & Robinson,
2011), gaze detection in infant-parent communication
(Cadavid, Mahor, Messinger, & Cohn, 2009), and intelligent
tutoring/game systems (D’Mello, Graesser, & Picard, 2007;
Graesser & D’Mello, 2011).
Cursor motion analysis originated in the late 1970s when
researchers started to evaluate the performance of different
input devices (Accot & Zhai, 1997, 1999; Card, English, &
Burr, 1978). In the last 15 years, a number of research studies
have employed cursor movement analysis for emotion
assessment. Zimmermann (2008) employed a film-based
emotion elicitation technique and investigated the impact of
arousal and valence on cursor motion in an online shopping
task. Kapoor et al. (Kapoor, Burleson, & Picard, 2007)
adopted a pressure-sensitive mouse for their multichannel
automatic affect detection system and measured mean,
variance, and skewness of mouse pressure while participants
(middle school students,) learned to solve a Tower of Hanoi
puzzle. Azcarraga and Suarez (Azcarraga & Suarez, 2012)
evaluated EEG signals and mouse activities (the number of
mouse clicks, distance traveled, click duration) during
algebra learning in an intelligent tutoring system (ITS) to
predict participants’ emotions. Prediction rates based solely
on EEG were 54 to 88%. When mouse activity data were
augmented to the EEG data, accuracy rates increased up to
92%. Yamauchi (2013) presents a new machine learning
technique involving feature selection associated with cursor
motions and emotion detection. Beyond these studies, clear
evidence that links cursor activities and affects remains
sparse.

2721

Theoretical Rationale

Experiment

Embodied cognition. Recent advances in “embodied
cognition” introduce a new way of analyzing human
behavior. People’s cognitive, attitudinal, and affective states
are expressed in their bodily actions, and their bodily actions
invoke affective states (Barsalou, 1999; Barsalou,
Niedenthal, Barbey, & Ruppert, 2003). These intricate
interactions among cognition, emotion and action are
articulated by Barsalou’s (1999) perceptual symbol systems
hypothesis, which states that the essence of off-line cognition
involves a reenactment (simulation) of sensory and
perceptual modules.
Physiological findings provide another layer of evidence
that emotions can be reflected in voluntary hand motions. The
dorsolateral prefrontal region—the control center of highorder cognition—is connected to all premotor areas and
controls limb movements; this area receives a considerable
amount of input from dopaminergic cells, which influence
emotional states such as feelings of reward and pleasure
(Kolb & Whishaw, 2009).
The basal ganglia, which play a pivotal role in voluntary
motor control, receive excitatory input from almost all
cortical areas, and transfer the information back to the same
cortical areas through the thalamus. These feedback loops
involve not only motor-related cortices (e.g., primary motor,
supplementary motor and primary somatosensory cortices),
but also other cortical and subcortical regions that control
emotion, motivation and decision making (Mendoza &
Foundas, 2008). It is well known that dopamine deficiency in
the basal ganglia results in neurological movement disorders
such as Parkinson’s disease and Tourette syndrome. These
motor disorders often come with emotional disorders. More
than 40% of the people suffering from Tourette syndrome
experience symptoms of Obsessive-compulsive disorder,
which is an anxiety disorder (Mink, 2008). Apathy—“a
decrease of goal-directed behavior, thinking, and mood”—
occurs about in 40% of the patients suffering from
Parkinson’s disease (Weintraub & Stern, 2007). Those
individuals with deficits in dopamine production often
exhibit impairments in motor control as well as emotion and
higher order cognition (Mink, 2008).
Recent behavioral research suggests that high-order
cognitive judgments such as inductive reasoning and
knowledge formation are affected by tacit knowledge, affects
and mindsets, which in turn can be captured by the movement
of a computer cursor (Dale, Kehoe, & Spivey, 2007;
Freeman, Pauker, Apfelbaum, & Ambady, 2009; Spivey et
al., 2005; Xiao & Yamauchi, 2014; Yamauchi, 2013;
Yamauchi & Bowman, 2014; Yamauchi, Kohn, & Yu, 2007).
On the basis of these findings, we postulate that subtle
emotional states can be reflected in the way people move
computer cursors and fine-tuned analysis of cursor
trajectories can be applied for affective computing. Below,
we present an empirical study that explores this possibility.

Our
experiment
consisted
of
visual perception
task
involving
judgments
of
similarities
of
simple
figures
Figure 1: A screen shot of a choice(Kimchi
&
reach trial (the dotted line was not
Palmer,
1982;
shown in the actual experiment.)
Yamauchi,
2013). Participants were presented with a triad of geometric
figures on a computer monitor (96 trials in total), and selected
which choice figure, left or right, was more similar to the base
figure shown at the bottom (Figure 1). Participants indicated
their choice by pressing the “left” or “right” button placed at
the top of each choice figure (Figure 1). We selected this
choice-reaching task because the perception of similarity is
one of the most fundamental psychological functions that
mediates decision making, memory, generalization,
impression formation and problem solving (Hahn &
Ramscar, 2001).
In each trial, our program recorded the x-y coordinates of
the cursor location every 20-30 milliseconds from the onset
of a trial (participants pressing the “Next” button) until the
end of the trial (participants pressing either the left- or rightchoice button). From this data set, we extracted 16 features
of cursor motions, and examined the extent to which cursor
movement patterns of individual participants reflect their
self-reported state anxiety scores (Spielberger, Gorsuch,
Lushene, Vagg, & Jacobs, 1983).

(3-4)

(9-10)

(15-16)

(36)

Figure 2: Sample stimuli used in the choice-reaching
task.

Method
Participant. Participants (N = 133; female = 75, male = 58)
were undergraduate students participating for course credit.
Materials and Procedure. The stimuli for the choicereaching task were 32 triads of geometric figures—two
choice figures placed at the two top-corners of the frame and
a base figure placed at the bottom-center of the stimulus
frame (Figures 1&2). Each figure shows an overall shape
(either a square or a triangle) with smaller squares or
triangles, yielding four types of figures—a global square or
triangle made of local squares or triangles.
In each triad, two choice-figures placed at the upper two
corners of a stimulus frame were similar to the base figure

2722

either in their overall shape or local shapes. In total, 16 basic
triads were produced by varying the number of local
shapes—figures made of 3-4, 9-10, 15-16, or 36 local shapes
(Figure 2). In the experiment, 32 triads were produced from
the 16 basic triads by swapping the locations of the choice
figures; these 32 triads were shown 3 times, yielding 96 trials
of choice reaching for each participant.
To start each trial, participants pressed the “Next” button,
and a triad stimulus appeared. Participants indicated their
responses by pressing the “left” or “right” button (Figure 1).
After their response, the “Next” button appeared again. This
cycle was repeated 96 times. Note that there are no
correct/incorrect answers in this task, and participants were
instructed to make a selection based on their personal
preference.
Shortly after the completion of the choice-reaching
experiment, participants received the state anxiety
questionnaire (Spielberger et al., 1983) and rated each
statement (e.g., “I feel afraid”) on a four-point scale (20
questions in total). This questionnaire has been used widely
to assess generalized anxiety disorder (GAD). In this study,
we focused on anxiety for our analysis because anxiety is one
of the key affective states that arise at the time of cognitive
disequilibrium, and anxiety is also a key emotion pertinent to
deep learning (D’Mello, Dale, & Graesser, 2011).

position to the end position (Figure 4). These cursor
trajectory features were selected because these features have
been shown to be significant in cognitive decision making
(Dale et al., 2007; Freeman et al., 2009; Spivey et al., 2005;
Xiao & Yamauchi, 2014; Yamauchi, 2013; Yamauchi &
Bowman, 2014; Yamauchi et al., 2007).
For individual participants, means and standard deviations
of these features were calculated over trials, yielding 16
predictors (2 features x 4 segments x 2 statistical properties
(mean, SD)). D’Mello and colleagues (D’Mello et al., 2011)
investigated body movements of users in an intelligent
tutoring system and showed that inconsistent body motions
during learning reflect high levels of anxiety. In this vein,
standard deviations of cursor properties over different trials
are likely to reflect participants’ emotional states.

Figure 4: Illustrations of (a) attraction and (b) zigzags
Design. For the cursor trajectory data, we employed linear
regression analysis with anxiety scores as the dependent
variable and 16 cursor trajectory features as the independent
variables (Figure 3). The values of independent variables
(i.e., extracted cursor trajectory properties) and the dependent
variable (i.e., observed anxiety scores) were normalized so
that the mean and standard deviation of each variable were 0
and 1, respectively. For the cursor trajectory analysis, the
trials that took more than 6 seconds were not analyzed. Thus,
a total of 11,555 trials (90.1 % of the entire trials) were
analyzed.

Figure 3: An illustration of cursor trajectory features.
16 features were extracted for each participant.

Results and Discussion
Data analysis. To pre-process the cursor movement data,
we first applied a linear interpolation method and
standardized cursor trajectories of all trials into 100 equallyspaced time steps starting from the onset time of the first
cursor move to the time slice of the final move (at which the
choice button, either left or right, was pressed (Dale et al.,
2007; Freeman et al., 2009; Spivey et al., 2005; Yamauchi,
2013).
For each trajectory, we divided the 100 time-steps into four
equal segments (Figure 3) and extracted two features—
attraction and zigzags (Figure 4)—from the four segments.
Attraction was defined as the area of departure from the
shortest path and the zigzag is the number of changing
directions with respect to the straight line from the starting

Anxiety questionnaire data. The anxiety questionnaire
asked participants to indicate their levels of anxiety on a 1-4
scale (20 questions). Our questionnaire results showed that
female participants reported a higher level of anxiety (M =
2.0, SD = 0.56) than male participants (M = 1.8, SD = 0.46),
t(132) = 2.36, p = 0.02, d = 0.3, 95% CId [-0.04, 0.64].
Linking cursor trajectories to anxiety. To investigate the
relationship between cursor trajectories and self-reported
anxiety scores, we applied stepwise regression analysis
separately to female (n = 75) and male (n = 58) participants.
This separate analysis procedure was adopted because a large
number of studies demonstrate sex differences in emotionally
charged stimuli (e.g., Bradley & Lang, 2007), and our anxiety
quetionnaire data revealed significant sex differences. For

2723

this analysis, a total of 16 predictors were submitted to a
stepwise linear regression (Figure 3) with the Akaike
Information Criterion (AIC) for the predictor selection
criterion.
Female

Male
4

-1.5

Anxiety score

Anxiety score

3

2

1

0
-1

-0.5

0

0.5

1

1.5

-1

3

2

1

0
-3

-2

-1

0

1

2

3

-1

-2

-2

R² = 0.47

R² = 0.12

extent to which randomly generated pseudo predictors could
explain the empirical anxiety scores obtained in the
experiment. If the 16 cursor properties extracted from
individual participants performed no better than randomly
generated pseudo-predictors, our method should be judged as
ineffective.
In this simulation analysis, we replaced the 16 trajectory
predictors with 16 vectors of arbitrary numbers sampled
randomly from the standard normal distribution. We applied
the same stepwise regression analysis to the “pseudo
predictors” and calculated R2. This process was repeated
1000 times to estimate the distribution of R2 obtained from
the pseudo predictors.

-3

-3

Fitted values

Fitted values

(a)

(b)

Figure 5: Graphical summaries of two regression analyses.
The units of the x-y coordinates of the graphs are
standardized “z-scores.”
Consistent with the studies that report gender differences
in emotional experience (Cahill, 2006), our results revealed a
strong gender effect. Cursor trajectory patterns obtained from
female participants were moderately correlated with their
self-reported anxiety scores; F(2, 72) = 4.81, p = 0.01, R2 =
0.12 (adjusted R2 = 0.09); 12 % of the variance observed in
female participants’ anxiety scores was explained by two
predictors identified in the stepwise regression. Given male
participants, our regression analysis indicated that 47% of the
variance was explained by seven predictors; F(7, 50) = 6.22,
p < 0.001, R2 = 0.47 (adjusted R2 = 0.39) (Figure 5).
Table 1: Coefficients selected by the regression analysis
Female
Segments
Attract

Mean

SD

Male
Mean

76-100
51-75

.34**

26-50

.51**

1-25
Zigzag

SD

76-100

Figure 6: Results from the simulation study based on female
participants (a), and male participants (b).
Figure 7 shows the results of this simulation study. The
dotted red lines represented R2 obtained from the actual
experiment. Given the female participants, our empirical
predictors outperformed random pseudo predictors slightly
more than 50% of the time, suggesting that the cursor
trajectory predictors extracted from female participants were
barely effective compared to randomly generated predictors.
Given the data from male participants, our empirical
predictors outperformed the random pseudo predictors more
than 99% of the time, suggesting that our cursor trajectory
worked well in explaining male participants’ self-reported
anxiety levels.

Discussion

-.29*
-.16

#

-.81***

51-75

.77***

26-50

-.23#

.39*

.24#

1-25
Note. p***< .001, .001 ≤ p**< .01 .01≤p*< .05, .05≤p#.

Overall, two properties, attraction and zigzag, extracted
during the midsection time-steps (26-50 & 51-75) appear
particularly important. For male participants, zigzags
extracted from 51-75th time-steps and 76-100th time-steps
were shown to be highly correlated with self-reported anxiety
scores (Table 1). Given female participants, attraction taken
in the middle section (51-75th time-steps) was critical.
Assessing the validity of the regression result. To assess the
validity of our cursor trajectory analysis, we examined the

The extracted cursor trajectories for male participants
predicted about 47% of the variance of their self-reported
anxiety scores. For female participants, the same predictors
were not very effective. Although we found a statistically
significant correlation between some of the identified
predictors and anxiety scores, our verification analysis
showed that randomly sampled pseudo predictors can
achieve a comparable level of accountability in female
participants. It is well known that there are considerable sex
differences in male and female brains especially in the
amygdala. The way that emotional states are expressed is also
different between male and female (Burleson & Picard, 2007;
Conati, 2002). It appears that such basic sex differences are
at play in the cursor movements observed in our male and
female participants as well.

2724

The idea that emotion influences bodily motions has been
investigated in HCI (Glowinski & Mancini, 2011; Thrasher,
Van der Zwaag, Bianchi-Berthouze, & Westerink, 2011).
Other studies suggest that emotional states are expressed
through keystrokes (Epp, Lippold, & Mandryk, 2011). The
present study extends these studies by showing that people’s
emotional states (at least for male participants) can be
reflected by the subtle movements of computer cursors in a
simple choice-reaching task.
Our cursor trajectory analysis provides a new method for
affective computing for male participants with added
advantage for the ease of implementation and computation.
Computer cursors are by far among the most ubiquitous
means connecting people and computers, and almost all
computers, including tablets, require some form of cursor or
finger movements for interaction. Because movement can be
traced in time-stamped x-y coordinate points, the cost for
online data processing can be miniscule.

Limitations and Future directions
Our study is correlational and the causal link between
cursor motion and emotion is unknown. The impact of
emotion on cursor motion should be tested experimentally
where a certain emotion is experimentally elicited. This
study employed a simplified task and our procedure was
effective only for male participants. Although such a
controlled situation is needed for the initial investigation of a
new technology, the proposed method should be vetted
thoroughly in more realistic settings. The applicability of the
cursor-based method should be examined further with more
rigorous statistical methods (e.g., cross validation). It is
possible that the cursor-based analysis is viable only in the
task context that requires choice-reaching. The
generalizability of our procedure should be investigated
further in contexts that do not involve choice reaching. It
should be also noted that the cursor-based affective
computing method is limited because it requires direct
interaction with computers (e.g., facial expressions can be
assessed without computers). These limitations should be
effectively addressed in future studies.

Conclusion
In recent years, there has been an increasing consensus
about the need to broaden our understanding of human
emotion and its impact on human computer interaction. The
present study combines the virtues of the integrated
understanding of human physiology, emotion and motor
control and shows the intricate link between the three. We
suggest that cursor trajectory analysis can be integrated into
existing AC technologies, providing an economical method
of affective computing.

References
Accot, J., & Zhai, S. (1997). Beyond Fitts' law: models for
trajectory-based HCI tasks. Proceedings of the SIGCHI

conference on Human factors in computing systems (CHI
1997), 295-302, ACM Press.
Accot, J., & Zhai, S. (1999). Performance evaluation of input
devices in trajectory-based tasks: an application of the
steering law. Proceedings of the SIGCHI conference on
Human factors in computing systems (CHI 1999), 466-472,
ACM Press.
Azcarraga, J., & Suarez, M. (2012). Predicting Academic
Emotions Based on Brainwaves, Mouse Behaviour and
Personality Profile. In P. Anthony, M. Ishizuka & D.
Lukose (Eds.), PRICAI 2012: Trends in Artificial
Intelligence (Vol. 7458, pp. 728-733): Springer Berlin
Heidelberg.
Barsalou, L. W. (1999). Perceptual symbol systems.
Behavioral Brain Sciences, 22, 577-660.
Barsalou, L. W., Niedenthal, P. M., Barbey, A. K., &
Ruppert, J. A. (2003). Social embodiment. In B. Ross
(Ed.), The Psychology of Learning and Motivation (Vol.
43, pp. 43-92). Boston: Academic Press.
Bradley, M. M., & Lang, P. J. (2007). The International
Affective Digitalized Sounds: Affective Ratings of Sounds
and Instruction Manual. Technical report B-3. University
of Florida, Gainesville, Fl.
Burleson, W., & Picard, R. W. (2007). Gender-Specific
Approaches to Developing Emotionally Intelligent
Learning Companions. IEEE Intelligent Systems, 22, 6269.
Cadavid, S., Mahor, M. H., Messinger, D. S., & Cohn, J. F.
(2009). Automated classification of gaze direction using
spectral regression and support vector machine.
Proceeding of 3rd International Conference on Affective
Computing and Intelligent Interaction and Workshops,
(ACII 2009), 1-6, IEEE Explore.
Cahill, L. (2006). Why sex matters for neuroscience. Nature
Reviews Neuroscience, 7, 477-484.
Calvo, R. A., & D’Mello, S. (2010). Affect detection: An
interdisciplinary review of models, methods, and their
applications. IEEE Transactions on Affective Computing,
1(1), 18-37.
Card, S. K., English, W. K., & Burr, B. J. (1978). Evaluation
of mouse, rate-controlled isometric joystick, step keys, and
text keys for text selection on a CRT. Ergonomics, 21(8),
601-613.
Conati, C. (2002). Probabilistic assessment of user's emotions
in educational games. Applied Artificial Intelligence, 16,
555-575.
D’Mello, S., Dale, R., & Graesser, A. (2011). Disequilibrium
in the mind, disharmony in the body. Cognition and
Emotion, 26 (2), 362-374.
D’Mello, S., Graesser, A., & Picard, R. (2007). Towards an
Affect-Sensitive AutoTutor. IEEE Intelligent Systems,
22(4), 53-61.
Dale, R., Kehoe, C., & Spivey, M. (2007). Graded motor
responses in the time course of categorizing atypical
exemplars. Memory & Cognition, 35(1), 15-28.
Epp, C., Lippold, M., & Mandryk, R. L. (2011). Identifying
emotional states using keystroke dynamics. Proceedings of

2725

the SIGCHI conference on Human factors in computing
systems (CHI 2011), 715-724, ACM Press.
Freeman, J. B., Pauker, K., Apfelbaum, E. P., & Ambady, N.
(2009). Continuous dynamics in the real-time perception of
race. Journal of Experimental Social Psychology, 46, 179185.
Glowinski, D., & Mancini, M. (2011). Towards real-time
affect detection based on sample entropy analysis of
expressive gesture. Proceeding of 4th International
Conference on Affective Computing and Intelligent
Interaction, (ACII 2011), 527-537, LNCS 6974: Spinger.
Graesser, A., & D’Mello, S. K. (2011). Theoretical
Perspectives on Affect and Deep Learning. In R. A. Calvo
& S. K. D’Mello (Eds.), New Perspectives on Affect and
Learning Technologies (pp. 11-21): Springer.
Hahn, U., & Ramscar, M. (2001). Similarity and
categorization. Oxford, UK: Oxford University Press.
Hedman, E., Poh, M.-Z., Wilder-Smith, O., Fletcher, R.,
Goodwin, M. S., & Picard, R. (2009). iCalm: Measuring
electrodermal activity in almost any setting. Proceeding of
3rd International Conference on Affective Computing and
Intelligent Interaction and Workshops, (ACII, 2009), 1-2,
IEEE Explore.
Kapoor, A., Burleson, W., & Picard, R. W. (2007). Automatic
prediction of frustration. International Journal of HumanComputer Studies, 65(8), 724-736.
Kimchi, R., & Palmer, S. E. (1982). Form and texture in
hierarchically
constructed
patterns.
Journal
of
Experimental Psychology: Human Perception and
Performance, 8, 521-535.
Kolb, B., & Whishaw, I. Q. (2009). Fundamentals of Human
Neuropsychology (6th ed.). New York: Worth Publishers.
McDuff, D., Karlson, A., Kapoor, A., Roseway, A., &
Czerwinski, M. (2012). AffectAura: An Intelligent System
for Emotional Memory. Proceedings of the SIGCHI
conference on Human factors in computing systems (CHI
2012),849-858, ACM Press.
Mendoza, J. E., & Foundas, A. L. (2008). Clinical
Neuroanatomy: A Neurobehavioral Approach. New York:
Springer.
Mink, J. W. (2008). The Basal Ganglia. In L. Squire (Ed.),
Fundamental Neuroscience (3rd ed., pp. 725-750). San
Diego, CA: Academic Press.
Pfister, T., & Robinson, P. (2011). Real-time recognition of
affective states from nonverbal features of speech and its
application for public speaking skill analysis. IEEE
Transactions on Affective Computing, 2(3), 66-78.
Song, J.-H., & Nakayama, K. (2009). Hidden cognitive states
revealed in choice reaching tasks. Trends in Cognitive
Sciences, 13(8), 360-366.
Spielberger, C. D., Gorsuch, R. L., Lushene, R., Vagg, P. R.,
& Jacobs, G. A. (1983). Manual for the state–trait anxiety
inventory. Palo Alto, CA: Consulting Psychologists Press.
Spivey, M. J. (2007). The Continuity of Mind. Oxford:
Oxford University Press.
Spivey, M. J., Grosjean, M., & Knoblich, G. (2005).
Continuous attraction toward phonological competitors.

Proceedings of National Academy of Sciences of the United
States of America, 102(29), 10393-10398.
Thelen, E. (1995). Motor development: A new synthesis.
American Psychologist, 50(2), 79-95.
Thrasher, M., Van der Zwaag, M. D., Bianchi-Berthouze, N.,
& Westerink, J. H. D. M. (2011). Mood Recognition Based
on Upper Body Posture and Movement Features.
Proceeding of 4th International Conference on Affective
Computing and Intelligent Interaction, (ACII 2011), 377386, LNCS 6974: Spinger.
Weintraub, D., & Stern, M. B. (2007). Disorders of mood and
affect in Parkinson's disease. Handbook of clinical
neurology, 83, 421-433.
Xiao, K., & Yamauchi, T. (2014). Semantic Priming
Revealed
by
Mouse
Movement
Trajectories.
Consciousness and Cognition, 27, 42-52.
Yamauchi, T. (2013). Mouse Trajectories and State Anxiety:
Feature Selection with Random Forest. Proceeding of the
5th International Conference on Affective Computing and
Intelligent Interaction, (ACII 2013), 399-404, IEEE
Computer Society.
Yamauchi, T., & Bowman, C. (2014). Mining cursor motions
to find the gender, experience and feelings of computer
users. Proceeding of the IEEE International Conference on
Data Mining (ICDM 2014): Workshop on Domain Driven
Data Mining, 221-230. IEEE Computer Society.
Yamauchi, T., Kohn, N., & Yu, N. (2007). Tracking mouse
movement in feature inference: Category labels are
different from feature labels. Memory & Cognition, 35(5),
852-863.
Zeng, Z., Pantic, M., Roisman, G. I., & Huang, T. S. (2009).
A survey of affect recognition methods: Audio, visual, and
spontaneous expressions. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 31(1), 39-58.
Zimmermann, P. (2008). Beyond Usability–Measuring
Aspects of User Experience. Doctoral Dissertation. Swiss
Federal Institute of Technology.

2726

