Manipulating the Contents of Consciousness
A Mechanistic-Manipulationist Perspective on Content-NCC Research
Alfredo Vernazzani (alfredo-vernazzani@daad-alumni.de)
Institut für Philosophie, Am Hof 1
53113 Bonn, Germany

Abstract

consciousness. The mechanisms behind the contents of
visual consciousness should be understood as neural
prerequisite of conscious vision. I call such systems
“intentional mechanisms”. In the final section, I briefly
draw attention to some implications for future researches.

I argue for a manipulationist-mechanistic
framework for content-NCC research in the case of visual
consciousness (Bechtel 2008; Neisser 2012). Reference to
mechanisms is common in the NCC research. Furthermore,
recent developments in non-invasive brain stimulation
techniques (NIBS) lend support to a manipulationist
standpoint. The crucial question is to understand what is
changed after manipulation of a brain mechanism. In the
second part of the paper I review the literature on
intentionalism, and argue that intervention on the neural
mechanism is likely to change the intentional content of
consciousness. This urges us to shift from content-NCC to
what I call “intentional mechanisms”. Such mechanisms, it
is argued, should be understood as neural prerequisites of
conscious visual experience.

NIBS and NCC research

Keywords: Consciousness; Manipulationism; NCC; Visual
Experience; Intentionalism; NIBS; Mechanisms; Explanation.

Introduction
In the last years, we have witnessed a spurt of progress in
the search for the neural correlates of consciousness (NCC).
The growing scientific literature seems to suggest that, in
the next years, non-invasive brain stimulation techniques
(NIBS) will play an important role in NCC research (e.g. de
Graaf & Sack 2014).
In this paper I focus on the search for content-NCC, i.e.
the neural correlates of a specific conscious experience, the
content of consciousness. Specifically, I narrow down my
attention to NCCs of the visual contents of consciousness.
This set of experiences embraces, for example, seeing
something red, seeing an object, and so on.
Following the suggestion of Neisser (2012), I argue that
NIBS urges us to rethink Chalmers’s received view on
content-NCC. However, in contrast with Neisser who
suggests adopting Craver’s (2007) account of explanation in
neuroscience, I put forward Bechtel’s (2008) account of
mental mechanisms.
In the first section I outline the new frontier of NCC
research through NIBS. In the second section I show how
the received view should be changed, moving toward a
manipulationist-mechanistic approach. This raises the
challenge of understanding what is actually changed
through manipulation of the neural machinery. I finally
argue that what is changed is the intentional content of
consciousness. Research on content-NCC does not target

In his account of explanation in neuroscience, Craver
(2007) observes that neuroscience is mainly driven by two
goals. The first goal is explanation. Under this goal we
group researches about how the brain develops from infancy
to adulthood, how memory is realized by the brain, and so
on. The second goal is to control the brain. Under this goal
we find the attempt to diagnose and treat neural diseases, for
example.
These two goals are also visible in neuroscience’s search
for NCCs. One goal is to explain consciousness, whilst the
other is to manipulate and control brain mechanisms that
implement our conscious experience. Intervention on the
NCCs might prove helpful not only for diagnostic purposes,
but also in locating them (e.g. Koubeissi et al. 2014; Parivizi
et al. 2012). Furthermore, manipulating brain mechanisms
somehow related to conscious experience can help us
moving from a mere correlation to causation (Koch 2004:
100), thus helping us explaining consciousness. Finally, in a
recent review paper, de Graaf & Sack (2014) highlight the
role of NIBS techniques in disentangling neural
prerequisite, substrates, and consequences of conscious
experience (e.g. Aru et al. 2012; de Graaf et al. 2012).
Among NIBS techniques we find transcranial magnetic
stimulation (TMS), and transcranial electric stimulation
(TES), which includes transcranial direct current stimulation
(tDCS) as well as transcranial alternating current
stimulation (tACS). In the search for NCCs, NIBS does not
represent an alternative, but a valuable complement to
refined neuroimaging techniques (e.g. Friston 2011). The
reason is simple: whilst a regional BOLD response in fMRI
cannot tell us whether the neural processing is «imperative
for the task at hand» (de Graaf & Sack 2014: 6),
manipulating a specific brain mechanism thanks to NIBS
might change the corresponding conscious percept. If
manipulation of a mechanism disrupts or elicits a conscious
percept, than we have good reasons to infer that such a
mechanism has some functional role for consciousness.
The use of NIBS techniques in NCC research is
flourishing. A TMS pulse on the occipital lobe can, for
example, generate a phosphene (e.g. Kammer 1999).
Application of TMS pulse on the motion area MT/V5

2487

(Fellman & Van Essen 1991) elicits moving phosphenes (de
Graaf & Sack 2014: 6). Another example of application of
TMS is the induction of virtual lesions in the parietal cortex
in cases of experiments in bistable vision (e.g. Carmel et al.
2010).
Such experiments suggest that, in the next years,
manipulation of brain mechanisms will be a valuable tool in
finding out the NCCs. In addition, I believe that they
suggest us to revise the current paradigm of content-NCC
research and to carefully rethink our understanding of the
NCC problem.

In contrast with this paradigm, Neisser puts forward an
alternative framework: the manipulationist-mechanistic
model of explanation articulated by Carl Craver (2007).
However, the search for the visual content-NCC is better
described as the search for mental mechanisms (Bechtel
2008). Since “mechanisms” and “manipulation” are key
concepts for the present analysis, we must first briefly dwell
on their definitions.
Mechanisms. Bechtel defines a mechanism as:
…a structure performing a function in virtue of its
component parts, component operations, and their
organization. The orchestrated functioning of the
mechanism is responsible for one or more phenomenon
(Bechtel 2008: 13).

Steps Towards a New Paradigm for NCC
Research
The Standard NCC approach
The standard definition of content-NCC has been put
forward by Chalmers:
An NCC (for content) is a minimal neural representational
system N such that representation of a content in N is
sufficient, under conditions C, for representation of that
content in consciousness. (Chalmers 2000: 31)
There are three features I would like to highlight in this
study. First, between the neural system N and conscious
experience there is only a correlative relation. In this sense,
the correlation is better understood as a statistically
significant co-occurrence of a given conscious content and
activation of the putative content-NCC. The correlation is
meant to capture a “metaphysically” neutral stance on the
issue that sidesteps the causal problem (Neisser 2012).
The second feature is that the conscious experience at
stake is a specific conscious state, what we in the
philosophical jargon call a specific “content of
consciousness” (e.g. Siegel 2010).
Finally, the neural system N is constrained through the
condition of minimal sufficiency. Chalmers (2000: 24-25)
argues that this requirement is introduced in order to screen
off redundant neural activity. If one takes a content-NCC to
be a merely sufficient neural system, then the whole brain
would count as NCC. But obviously, what we are looking
for is a much more specific brain system that appears to be
directly involved in conscious experience.

Mechanisms and Manipulation
Neisser (2012) points out that the supposedly neutral
connection between N and a specific conscious content does
not capture the scientific understanding of the issue.
Furthermore, he argues that the requirement of minimal
sufficiency is a logical condition that betrays a commitment
with a classical paradigm of explanation: the search for
covering laws, well represented by the deductivenomological (DN) model of explanation (Hempel &
Oppenheim 1948).

The growing body of literature on mechanistic
explanation often draws attention to the ubiquitous
reference to mechanisms in psychology and the life sciences
(Bechtel 2008; Bechtel & Richardson 1993; Darden 2006),
and specifically in neuroscience (Craver 2007). Although
very few philosophers have paid attention to this
(exceptions are Hohwy 2009, Neisser 2012), reference to
mechanisms is also ubiquitous in research on the NCCs.
Consider only few examples: “Still wanted – the
mechanisms of consciousness” (Aru & Bachmann 2015);
«These [the NCC] are the smallest set of brain mechanisms
[…] sufficient for some conscious feeling […]» (Koch
2004: xv-xvi). Commenting on the problem of emergence,
Francis Crick also seemed to suggest a mechanistic strategy
in NCC research: «while the whole may not be the simple
sum of the separate parts, its behavior can, at least in
principle, be understood from the nature and behavior of its
parts plus the knowledge of how all these parts interact»
(1994: 11). Here we observe a typical mechanistic
explanatory strategy: mechanistic decomposition (Bechtel &
Richardson 1993; Kauffman 1971).
Mechanistic decomposition is a key step toward a
mechanistic explanation. In contrast with the DN model,
mechanistic explanation does not rely on covering laws, but
explains a phenomenon by showing how entities and
activities produce the explanandum (Bechtel & Abrahamsen
2005; Craver 2005). In short: a mechanistic explanation
explains why a phenomenon occurred by exposing how it
occurs.
Manipulation. The other key concept is that of
manipulation. I think that Neisser’s suggestion can receive
substantial support precisely thanks to the recent
developments in NIBS techniques that I outlined in the first
section.
Relying on Woodward (2003), Craver defines X as
causally relevant to Y iff there is:

2488

…an ideal intervention on X that changes the value of Y,
or the probability distribution over the values of Y (Craver
2007: 198).
Conceptualizing the search for content-NCC according to
the manipulationist (or “interventionist”) view means to
intervene on the putative brain mechanism related to
conscious content and observe the elicited change in visual
phenomenology. In an experimental setting, this might
involve screening off interfering factors that affects X in
normal conditions (Campbell 2007 calls it “surgical”
intervention).
It should be stressed that whilst manipulation can help us
sorting out different kinds of neural activity, its role within a
mechanistic explanation is that of localizing operations
within specific mechanistic parts (Bechtel & Richardson
1993). This is likely to put additional constraints on the
model, unveiling the mechanism’s structure. However,
localization also requires understanding of what operations
are carried out by the different functions. This suggests that
localization is but only one step towards a mechanistic
explanation (Bechtel 2008).
Still,
the
manipulationist-mechanistic
framework
represents a promising conceptualization of the NCC
problem. However, intervening on the brain mechanisms of
the contents of consciousness demands to properly define
the changed, altered, phenomenon. Understanding the
function of such mechanism is of paramount importance in
constructing a mechanistic explanation. Mechanisms are for
a specific function (Glennan 1996). Circumscribing the
function of the mechanisms of the contents of consciousness
means to tackle the issue of what they actually do, which in
turn enable us to put constraints in modeling a mechanism.
The relevance of this question is obvious: if we can
establish a causal (manipulative) relation between a neural
mechanism and a specific conscious experience we could
finally explain consciousness. Unfortunately, things are not
so easy. In the next section I review the philosophical
literature on intentionalism and show that intervention on
brain mechanism only elicits a change in the intentional
content.

Manipulating the Intentional Content
In the definition given above, Chalmers (2000) made
explicit reference to the representational (or “intentional”)
character of consciousness. As we know, intentionalism is
the thesis according to which conscious experience has an
intentional (i.e. representational) character. However, few, if
any, philosophers contend that representing things to be
thus-and-so exhausts what there is to say about
consciousness.
We commonly distinguish different philosophical groups
regarding the relation between intentionality and
consciousness (Chalmers 2004; Fish 2010; Staudacher
2011). Here I adopt William Fish’s (2010) taxonomy, and
identify
three
forms
of
intentionalism:
strong
phenomenology-first, strong content-first, and weak

intentionalism. According to the first and third group
conscious intentional content has phenomenal properties,
whilst the second group maintains a reductive stance
towards phenomenal properties. I will examine them in this
order: the third, the first, and finally the second group. As I
declared in the outset, the reader should bear in mind that I
only focus on visual experiences.

Weak Intentionalism
According to weak intentionalism, phenomenal
experiences always have intentional content (Chalmers
2004; Peacocke 1983; Searle 1983). However, weak
intentionalism allows that two distinct phenomenal
experiences may have the same intentional content.
Consider Block’s argument (1993). Suppose that you are
travelling through a dark tunnel and you see a brightly lit
scene at its end. According to Block, there would be a
phenomenal difference if you keep both eyes open or you
close one of them, even though the intentional content
remains the same. Conscious experience, according to weak
intentionalism, is partially independent from the intentional
content. This poses two problems for the manipulationist
approach.
First, it is likely that the approach I have argued for does
not actually target phenomenal properties. There is no
compelling reason for thinking that manipulation of the
neural mechanism should change conscious experience.
Indeed, it is plausible to imagine the following scenario: a
manipulation of the mechanism that does not produce a
change in consciousness, but only in intentional content.
Manipulating the neural mechanisms underlying the
contents of visual consciousness therefore does not help us
explaining why that content is conscious.
The second problem concerns the surjective relation
between intentional and phenomenal properties. We
individuate the contents of consciousness precisely in virtue
of their being conscious. But since two different experiences
might have the same intentional content, we are left with the
difficult task of explaining why and how this is possible.

Strong Phenomenology-First Intentionalism
A way to sidestep the latter problem is to hold that every
variation in phenomenal character is mirrored by a variation
in intentional content. Byrne argues that:
For any two possible experiences e and e*, if they differ
in phenomenal character, then they differ in [intentional]
content. (Byrne 2001: 217).
This is what Fish (2010) calls “strong phenomenologyfirst intentionalism”. However, it should be clear that even
this option does not solve the problem posed by weak
intentionalism, since phenomenal properties are not
identical with intentional properties.

2489

Strong Content-First Intentionalism

of consciousness. Indeed, there is no principal conceptual
problem in linking functional and structural aspects of
consciousness to the underlying brain mechanisms. The
picture I am describing is perfectly compatible with the hard
problem of consciousness (Chalmers 1996). Notice that this
conclusion is convergent with recent debates on the nature
of the NCCs (Bayne 2007; Howhy 2009; Searle 2004).
Significantly, combining insights provided by the
neurosciences and philosophy, I think that the framework
that I have sketched out paves the way to some fruitful
perspectives on the search for the NCCs.
If the mechanistic-manipulationist framework for contentNCC does not explain consciousness, nonetheless it can
rightly be conceptualized as the search for visual intentional
mechanisms. Following Bechtel’s definition of mechanism
(see §2), an intentional mechanism could be defined as:

Another option is to deny the existence of any
phenomenal property, or simply to show that they can be
reduced to some functional requirement or additional
process. Strong content-first intentionalists espouse
precisely this thesis. However, philosophers disagree about
the nature of such additional requirements.
Higher order theories of consciousness (HOT) claim that
a first-order intentional state is conscious only when it is
object of a higher order state. The character of such higher
order state is disputed. Lycan (1996) contends that the
higher order state is a kind of internal scanner akin to a
perceptual state, whilst Rosenthal (1990) claims that the
higher order state is a belief, or thought.
According to HOTs, the manipulationist-mechanist
approach does not suffice to explain consciousness. In
addition to mechanisms for the visual contents of
consciousness, we should also postulate the existence of
other higher-order mechanisms whose overall function is
necessary to make the first order state conscious.
Furthermore, HOTs may lead to some empirical problems.
For example, one would have to disentangle first-order from
higher-order mechanisms, since they presumably co-activate
when a subject is consciously visually aware of a specific
content.
There is still another viable option. Some philosophers
maintain that first-order intentional states suffice for
consciousness if they have the right sort of content, and
when it plays some functional role (Dretske 1995; Tye
1995). Michael Tye ‘s PANIC theory is a paradigmatic
example:

A structure performing the proper function of fixing the
visual intentional content in virtue of its component parts,
component operations, and their organization. The
orchestrated functioning of the mechanism is responsible for
the intentional content of vision.

Prerequisite Mechanisms and Matching Content
Doctrine

Phenomenal content, I maintain, is content that is
appropriately poised for use by the cognitive system,
content that is abstract and nonconceptual (Tye 1995: 137).
Specifically, the intentional content must be abstract and
nonconceptual, and it must be functionally poised, i.e. must
be available for other cognitive processes. (Hence the
acronym: Poised Abstract Non-Conceptual Intentional
Content). Can the manipulationist-mechanistic approach
explain the contents of consciousness according to Tye’s
PANIC theory?
The answer should be a clear “no”. The fact is that, again,
intentional content alone does not suffice for consciousness.
Tye’s theory shows that in order to be conscious an
intentional content must not only have some specific
features – i.e. being abstract, and nonconceptual – but that it
must also be functionally poised. This seems to imply that
there is some additional functional requirement that can
possibly be accounted for through additional mechanisms.

Intentional Mechanisms
The foregoing discussion makes clear that the
manipulationist-mechanistic approach does not explain
consciousness. However, it is entirely plausible to contend
that the neural machinery can alter the intentional contents

Prerequisites of Consciousness. What is the relation
between intentional mechanisms and consciousness? Even if
intentional mechanisms do not account for conscious
experience, they can be regarded as neural prerequisite for it
(De Graaf et al. 2012). A neural prerequisite for
consciousness is a neural system – in our case, a neural
mechanism – whose function is required by other neural
mechanisms directly related to consciousness. Once the
intentional content has been processed by an intentional
mechanism, it can then become conscious thanks to some
further neural processing.
To see why, it is sufficient to reflect about intentionalism,
which, as we have seen, is the thesis according to which
consciousness has an intentional character. If consciousness
– or at least visual consciousness – has an intentional
content, it is entirely plausible to conceive the function of
intentional mechanisms as a necessary prerequisite for
conscious visual experience. One way to reject this
conclusion is to reject intentionalism altogether, and simply
deny that consciousness has any intentional content, or to
(ideally, at least) disjoint conscious experience from any
content1.
Since intentional mechanisms are not directed at
consciousness at all, the manipulationist view only fills in
the causal gap between intentional content and brain
mechanisms. Consequently, there still is a correlative
relation between conscious experience and the underlying
mechanism (see §2). It is obvious that understanding the
1

Although I pass this problem in silence here, the very idea of
being conscious without being conscious of something strikes me
as utterly mysterious, if not preposterous (see also Hohwy 2009).

2490

Acknowledgements

relation between phenomenal and intentional character still
preserve its priority over the explanatory problem.
Revising the Matching Content Doctrine. An interesting
aspect of standard content-NCC research is that the contents
of consciousness should match, or correspond, to the neural
content (Chalmers 2000: 35). The “matching content
doctrine” (MCD) serves as a methodological guide to the
search for content-NCC, and is expressed within the very
idea of a correlation. Roughly stated, the idea is this: if a
conscious content is “matched” by a specific neural
population in a statistically significant number of cases, they
are probably correlated. So far, criticism of the MCD has
mainly been motivated on the basis of a phenomenological
objection against the contents of consciousness (e.g. Noë &
Thompson 2004; Neisser 2012). In this study, I merely
observe that the intentional mechanisms standpoint
conceptualizes the MCD as a function-to-mechanism
relation. In other words: from a given content of
consciousness (the function), one can (tentatively) infer the
existence of a mechanism that produces it and test this
hypothesis through empirical techniques.

Spandrels of Vision?
Before I conclude, I would like to mention a conceptual
problem that follows from the final considerations on the
MCD. Rigorous phenomenological descriptions might serve
both the initial task of decomposing a mechanism (Bechtel
& Richardson 1993; Darden 2006; Kauffman 1971) – thus
leading us to look for a mechanism responsible for a
specific kind of content – and the observation of the
conscious percept elicited by NIBS techniques, which might
help us refining and understanding the results.
Yet, not every single feature of our conscious visual field
needs to have a specific functionally related mechanism. For
example, it seems plausible to me that some features of our
visual phenomenology might actually turn out to be
spandrels (Gould & Lewontin 1979), rather than direct
products of a single intentional mechanism. This latter
aspect, I think, should urge us to adopt an evolutionary
perspective regarding the contents of visual consciousness.
For reasons of space, I cannot elaborate on this suggestion
here. However, I believe that the framework developed here
offers us yet another reason, to think the mind-brain relation
in evolutionary terms.

Conclusion
To sum up, I hope to have persuasively argued for a
reconceptualization of the content-NCC problem. Recent
work on NIBS techniques seems to support the
manipulationist standpoint on the content-NCC problem.
Although what I called “intentional mechanisms” cannot
explain consciousness, they can clearly help us in the quest
of finding out how the brain generates the intentional
structure of our conscious experience.

I would like to express my gratitude to the BarbaraWengeler-Stiftung for the financial support. I am also
indebted to Prof. Andreas Bartels (University of Bonn), and
his PhD students for the discussion and helpful comments
on an earlier version of this paper during the winter
semester of 2014-2015. Many thanks also to Dr. Alexander
Staudacher (University of Magdeburg) for his precious
support.

References
Aru, J., Bachmannm, T., Singer, W., Meloni, L. (2012).
Distiling the neural correlates of consciousness.
Neuroscience & Biobehavioral Reviews, 36, 737-746.
Aru, J. & Bachmann, T. (2015). Still Wanted – the
Neural Mechanisms of Consciousness. Frontiers of
psychology, 6
Bayne, T. (2007). Conscious States and Conscious
Creatures: Explanation in the Scientific Study of
Consciousness. Philosophical Perspectives, 21, 1-22.
Bechtel, W. (2008). Mental Mechanisms. New York,
Routledge.
Bechtel, W. & Richardson, R. (1993/2010). Discovering
Compelxity. Cambridge MA, MIT Press.
Bechtel, W. & Abrahamsen, A. (2005). Explanation: A
Mechanistic Alternative. Studies in the History and
Philosophy of Biological and Biomedical Sciences, 36, 421441.
Block, N. (1993). Review of D. Dennett Consciousness
Explained. Journal of Philosophy, 90, 181-193.
Bogen, J. & Woodward, J. (1988). Saving the phenomena
The Philosophical Review, 97, 303- 352.
Byrne, A. (2001). Intentionalism Defended. The
Philosophical Review, 110, 199-240.
Campbell, J. (2007). An Interventionist Approach to
Causation in Psychology. in A. Gopnik & L. Schulz (Eds.),
Causal Learning: Psychology, Philosophy and Computation
(pp. 58-66). Oxford, Oxford University Press.
Carmel, D., Walsh, V., Lavie, N., Rees, G. (2010). Right
parietal TMS shortens dominance durations in binocular
rivalry. Current Biology, 20.
Chalmers, D. (1996). The Conscious Mind. New York,
Oxford University Press.
Chalmers, D. (2000). What Is a Neural Correlate of
Consciousness? in T. Metzinger (Ed.), Neural Correlates of
Consciousness (pp. 17-39). Cambridge MA, MIT Press.
Chalmers, D. (2004). The Representational Character of
Experience. In B. Leiter (Ed.), The Future of Philosophy.
New York, Oxford University Press. Reprinted in D.
Chalmers (2010), The Character of Consciousness (pp. 339379). New York, Oxford University Press.
Craver, C. (2005). Beyond reduction: mechanisms,
multifield integration and the unity of neuroscience. Studies
in History and Philosophy of Biological and Biomedical
Sciences, 36, 373-395.

2491

Craver, C. (2007). Explaining the Brain. New York,
Oxford University Press.
Crick, F. (1994). The Astonishing Hypothesis. New York,
Simon & Schuster.
Darden, L. (2006). Reasoning in Biological Discovery.
Cambridge MA, Cambridge University Press.
De Graaf, T., Hsieh, P.J., Sack, A.T. (2011). The
‘Correlates’ in Neural Correlates of Consciousness.
Neuroscience and Biobehavioral Reviews, 36, 191-197.
De Graaf, T. & Sack, A.T. (2014). Using Brain
Stimulation to Disentangle Neural Correlates of Conscious
Vision. Frontiers in psychology, 5, 1-13.
Dretske, F. (1995). Naturalizing the Mind. Cambridge
MA, MIT Press.
Fellman, D.J. & Van Essen, D.C: (1991). Distributed
Hierarchical Processing in the Primate Cerebral Cortex.
Cerebral Cortex, 1/1, 1-47.
Fish, W. (2010). Philosophy of Perception. New York,
Routledge.
Friston, K.J. (2011). Functional and effective
connectivity: a review. Brain Connect, 1, 13-16.
Glennan, S. (1996). Mechanisms and the Nature of
Causation. Erkenntnis, 44, 49-71.
Gould, S.J. & Lewontin, R. (1979). The Spandrels of San
Marco and the Panglossian Paradigm: A Critique of the
Adaptationist Program. Proceedings of the Royal Society of
London. Series B, Biological Sciences, vol. 205 (pp. 581598).
Hempel, C.G. & Oppenheim, P. (1948). Studies in the
Logic of Explanation. Philosophy of Science, 15, 135-175.
Hohwy, J. (2009). The Neural Correlates of
Consciousness: New Experimental Approaches Needed?
Consciousness and Cognition, 18, 428-438.
Kauffman, S. (1971). Articulation of Parts Explanation in
Biology and the Rational Search for them. In R.C. Buck &
R.S. Cohen (Eds.), PSA 1970 (pp. 257-272). Dordrecht,
Reidl.
Kammer, T. (1999). Phosphenes and transient scotomas
induced by magnetic stimulation of the occipital lobe: their
topographic relationship. Neuropsychologia, 37, 191-198.
Koch, C. (2004). The Quest for Consciousness,
Englewood, Roberts & Company.
Koubeissi, M.Z., Bartolomei, F., Beltagy, A., Picard, F.
(2014). Electrical stimulation of a small brain area
reversibly disrupts consciousness. Epilepsy & Behavior, 37,
32-35.
Levine, J.
(1983). Materialism and Qualia: The
Explanatory Gap. Pacific Philosophical Quarterly, 64, 354361.
Lycan , W. (1996). Consciousness and Experience.
Cambridge MA, MIT Press.
Neisser, J. (2012). Neural Correlates of Consciousness
reconsidered. Consciousness and Cogntion, 21, 681-690.
Noë, A. & Thompson, E. (2004). Are there neural
correlates of consciousness? Journal of Consciousness
Studies, 11, 3-28.

Parivizi, J., Jacques, C., Foster, B.L., Withoft, N.,
Rangarajan, V., Weiner, K.S., Grill-Spector, K. (2012).
Electrical stimulation of human fusiform face-selective
regions distorts face perception. The Journal of
Neuroscience, 32, 14915-14920.
Peacocke, C. (1983). Sense and Content. Oxford, Oxford
University Press.
Rosenthal, D. (1990). A Theory of Consciousness. In N.
Block, O. Flanagan, G. Güzeldere (Eds.), The Nature of
Consciousness (pp. 773-788). Cambridge MA, MIT Press.
Searle, J. (1983). Intentionality. Cambridge, Cambridge
University Press.
Searle, J. (2004). Mind: A brief introduction. New York,
Oxford University Press.
Siegel, S. (2010). The Contents of Visual Experience,
New York, Oxford University Press..
Staudacher, A (2011). Das Problem der Wahrnehmung.
Paderborn, Mentis Verlag..
Tapia, E. & Beck, D.M. (2014). Probing feedforward and
feedback contributions to awareness with visual masking
and transcranial magnetic stimulation. Frontiers in
psychology, 5, 1-14.
Tye, M. (1995). Ten Problems of Consciousness.
Cambridge MA, MIT Press.
Woodward, J. (2003). Making things happen. New York,
Oxford University Press.

2492

