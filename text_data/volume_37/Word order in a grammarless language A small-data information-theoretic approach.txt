       Word order in a grammarless language: A ‘small-data’ information-theoretic
                                                                 approach
                                           Nicholas A. Lester (nlester@umail.ucsb.edu)
                                               Department of Linguistics, South Hall 3432
                                                       Santa Barbara, CA 93106 USA
                                   Fermín Moscoso del Prado Martín (fmoscoso@umail.ucsb.edu)
                                               Department of Linguistics, South Hall 3432
                                                       Santa Barbara, CA 93106 USA
                              Abstract                                  not so shocking, as similar arguments have been made for
                                                                        other languages. For example, Hengeveld (2013) points out
   David Gil has argued that Riau Indonesian (Sumatra.
   Indonesia) has no syntax, or at least not much. This                 the difficulty of assigning Samoan words to default word
   controversial analysis undermines all current models of              classes. In Samoan, most words can occur in any of the
   grammar, especially those describing acquisition and on-line         morphosyntactic frames defining predication, reference, and
   processing. To test the strength of this analysis, we computed       modification. This phenomenon has been widely discussed
   the information gain holding between unigram and bigram              as a form of lexical flexibility (van Lier & Rijkhoff, 2013).
   models of regular and randomized samples of English and              But Gil goes further, arguing that RI has largely
   Riau Indonesian. English samples were included as a
   relatively syntax-heavy baseline. We then correlated
                                                                        unconstrained word order and no inflectional morphology;
   information gain values with language (English vs. Riau              that is, he argues that RI has no syntax. This last point
   Indonesian), text type (original vs. randomized), and their          sharply differentiates RI from languages like Samoan, in
   interaction within a linear mixed-effects regression. The            that the latter indeed provides systematic, grammatically
   results suggest (a) that English and Riau Indonesian have the        encoded cues for reconstructing meaning: interpretation of a
   same amount of bigram informativity and (b) that                     word’s functional-semantic contribution to the sentence is
   randomization eliminates this effect in both languages. These        guided by its morphosyntactic positioning. By contrast,
   findings do not support Gil’s syntax-free analysis; rather, they
   point to some kind of productive constraints on Riau                 according to Gil, RI has no set of syntactic constructions to
   Indonesian word order.                                               which regular interpretations could be linked.
                                                                           The existence of a language like RI contradicts the most
      Keywords: Indonesian; word classes; n-gram models;                basic assumptions underlying most (if not all) established
   information gain; entropy.
                                                                        theories of grammar, especially in the domains of
                                                                        processing and acquisition. For example, linguists generally
                          Introduction                                  assume that all humans acquire their respective native
   Most theories of grammar posit a layer of categorization             language(s) by means of the same perceptual-cognitive
that discriminates words into different functional types, or            system. In one formulation, this apparatus constitutes a
word classes.1 These word classes define the combinatorial              genetically pre-specified Language Acquisition Device
possibilities of words, and so serve a central function within          (LAD) which mediates the interaction between linguistic
the syntax of any given language. Examples of common                    experience and the inborn set of grammatical categories and
word classes include nouns, verbs, adjectives, adverbs, and             rules known as Universal Grammar (UG). Other
adpositions. The widespread recurrence of these classes                 formulations emphasize the role of domain-general (i.e., not
cross-linguistically has led some researchers to argue for              purely linguistic) statistical learning mechanisms during
their either being cognitively basic or universally available           language acquisition. According to these theories, all
as part of the genetically endowed human linguistic                     humans bring the same simple learning algorithms to bear
apparatus. Over the past few decades, however, a growing                on the problem of parsing input sequences (e.g., the
body of evidence from languages across the globe has come               ‘chunking’ of sequences with high internal transitional
to challenge the basic or universal status of even the most             association strengths). Under either theory, knowledge of
common word classes, including nouns and verbs (cf.                     word sequences, either in the form of innate constraints
Rijkhoff & van Lier, 2013). The most radical argument to                within UG or statistical generalizations over the likelihood
emerge from this line of research comes from David Gil and              of candidate word combinations, stands at the heart of
his analysis of Riau Indonesian (RI), a colloquial variety of           linguistic competence. But how could a language like RI,
Bahasa Indonesian (BI) spoken on the central-eastern coast              which lacks reliable constraints on word order, arise from –
of Sumatra.                                                             or be acquired by – a cognitive system that depends so
   According to Gil (1994; 2013), RI essentially lacks any              heavily on sequence-driven (i.e., syntactic) generalizations?.
grammatically relevant word classes. In itself, this claim is              In the next section, we describe the grammatical analysis
                                                                        of RI as developed by David Gil over the past two decades.
1
  I use the term ‘functional’ in its broadest sense to refer to         We then introduce a corpus methodology capable of
both the syntactic and semantic properties of words.                    measuring differences in the regularity of local syntactic
                                                                    1314

structure between two languages on the basis of extremely           parameters governing choices of constructional alternatives
small samples (n < 3000 words). Next, we apply this                 (e.g., the dative alternation; Arnold, Wasow, Lonsongco, &
comparative method to naturalistic data from RI and English         Ginstrom, 2000). Therefore, their presence in RI does not
and present the results. Finally, we discuss these results with     rule out the possibility that they are linked directly to
reference to usage-based theories of language structure.            syntactic representations.
                                                                       To the extent that RI word order is unconstrained (with
Riau Indonesian: A language without (much)                          respect to surface tokens), local sequences of words should
grammar                                                             approach near-random distribution. For any given pairing of
                                                                    words (w1, w2), we should find an equal probability of
Like other Austronesian languages of western Indonesia, RI          observing the order w1+w2 as the alternative w2+w1. In other
is close to the ideal isolating language: its words exhibit         words, knowledge of the preceding word should not help
few, if any, inflectional variants. RI does make limited use        much in guessing the word to follow. We can refer to this
of a sparse and functionally heterogeneous set of affixes           situation as one of minimal bigram informativity. This
(e.g., the common Indonesian voice-altering prefixes N- and         would be the case for purely randomly distributed strings of
di-) and some other morphological processes (e.g.,                  words, and so can be considered a theoretical lower-bound
reduplication, compounding; Gil, 2008). However, these              for bigram structure. Given Gil's account of the presence of
processes are never inflectional in RI, nor are they ever           at least some ordering effects, we expect RI to exceed this
obligatory. Rather, they represent ‘optional semantic               lower-bound. However, based on Gil's claims of lexical
embellishments’ (Gil, 2008: 127).                                   flexibility at both the syntactic and thematic levels of
   Unlike other closely related Austronesian languages, RI          structure, we can predict that RI should come closer to the
also closely approximates a hypothetical monocategorial             minimal threshold than a language like English, which is
language (Gil, 2008). Monocategoriality is related to the           well known to exhibit robust syntactic constraints on word
notion of lexical flexibility introduced earlier, though it         order. In the next section, we describe an information-
differs in one crucial respect. In highly flexible languages,       theoretic measure known as information gain, which can be
‘precategorial’ words are combined with morphosyntactic             used to estimate the degree of bigram informativity of a
templates to derive specifically referential, predicative, or       sample text, relative to the baseline probabilities of words.
modificational interpretations for each item (Hengeveld &           Using this measure, we can compare RI with English to
Rijkhoff, 2005). Monocategorial languages, on the other             determine just how flexible RI word order is.
hand, offer no such links between semantic interpretation
and morphosyntactic form. Words in these languages are              Information gain
therefore not ‘flexible’ in the sense that they can appear in a
                                                                    Information gain is calculated in three stages. First, a
number of contrastive syntactic functions; they are
                                                                    unigram model and a bigram model are estimated on the
‘monocategorial’ in the sense that they are at all times
                                                                    basis of a training text (e.g., some connected subset of a
equivalent in ontological and syntactic status. They are in
                                                                    corpus of writing or transcribed speech). Next, an
principle free to occur in any syntagmatic combination with
                                                                    information-theoretic measure known as cross entropy is
any interpretation (provided a few principled exceptions).
                                                                    computed for each model to assess the fit of the trained
   To be clear, Gil does not argue that RI lacks word order
                                                                    model for an unseen test sample. The cross entropy
altogether. In fact, he proposes one syntactic and several
                                                                    represents the average number of bits needed to code an
competing extra-syntactic forces to account for what he sees
                                                                    event from one distribution as if it belonged to a different
as apparent syntactically-driven constraints on order (Gil,
                                                                    distribution. Applying this to the problem of model fit, we
2005). Syntactically, he argues that RI has a vanishingly
                                                                    can measure the number of bits needed to code a target
small set of functionally heterogeneous particles. These
                                                                    event according to the distribution predicted by a model
particles must precede the constituent with which they
                                                                    trained on part of a text (the training sample) when that
combine. However, these forms are few in number and may
                                                                    event actually belongs to the distribution instantiated by the
precede (as well as follow) any other word form (that is,
                                                                    remainder of that text (the test sample). The resulting value
they are collocationally unrestricted). Apart from syntax, Gil
                                                                    measures the incompatibility of the expectations of the
proposes several soft constraints related to functional
                                                                    model with the observed properties of the test sample.
interpretations and discourse-pragmatics. Thus, conceptual
                                                                       Cross entropy is expressed formally as a variation of
heads tend to precede their modifiers, topical and discourse-
                                                                    Shannon’s entropy (Shannon, 1948). Shannon’s entropy
old information tends to surface earlier within 'clauses'
                                                                    represents the average uncertainty of observing an event
(though he does not recognize any qualitative difference
                                                                    which belongs to a given probability distribution. It is
between individual words and clauses), and so on. However,
                                                                    expressed as the statistical expectation of the minus-log
these principles are only optionally applied. Furthermore, as
                                                                    probability of events in some distribution. Cross entropy, on
with the particles, they do not dictate the choice of lexical
                                                                    the other hand, is expressed as the negative sum of the
item: any word may serve any syntactic and thematic
                                                                    probabilities of events within some distribution P times the
function in any position relative to any other word. Finally,
                                                                    log probabilities of those events within a comparison
these tendencies have been implicated within more rigid
                                                                    distribution Q. The uncertainty associated with any event e
syntactic systems, as well, only there they are treated as
                                                                1315

in Q is weighted by its probability in P with the effect that      each text (i.e., by randomizing the texts). IG can then be
cross entropy H(P, Q) increases as P and Q diverge. The            computed for the randomized and non-randomized versions
equation is presented as Eq. 1 below.                              for each sample, and scaling up, for each language.
                                                                   Comparing the IG of a sample against it corresponding
                                                                   minimal (randomized) IG tells us how much information is
              H,  = −          log              (1)     contained in the bigram word order of our samples above
                                                                  and beyond what would be contributed by chance for that
                                                                   same sample. In this way, IG values observed for different
                                                                   samples can be anchored to a common lower bound, and so
   In the present context, Q represents the probabilities as       are rendered comparable in magnitude.
estimated on the basis of the trained model, P represents the         Following Gil's analysis, we should expect that the IG
probability distribution observed within the test sample, and      value for an RI text should approximate that of the
x represents a target event (i.e., the occurrence of a             corresponding randomized text. Furthermore, the difference
particular word type). P(x) and Q(x) represent the                 between the IG values for randomized and non-randomized
probabilities of event x as defined within the respective          samples should be smaller for RI than for English, if only
distributions. As mentioned earlier, H(P, Q) increases as the      because English is assumed to have a much less fluid
shape of probability distribution Q diverges from that of P.       lexicon and much more rigid constraints on word ordering.
High cross-entropy values thus reflect a poor fit of Q as a        We dub this set of predictions the Variable Order
model of P. Conversely, H(P, Q) approaches H(P) as the             Hypothesis to reflect the fact that word order in RI –
probabilities of events within Q approximate the associated        irrespective of functional interpretation – allows for more
probabilities within P.                                            variability than English. If no such difference were to be
   To calculate IG, we need only subtract the bigram cross         found between RI and English, then we can conclude that
entropy from the unigram cross entropy (the models must be         the apparent syntactic structure of RI introduced but rejected
trained and tested on the same texts). The resulting value         by Gil (1994; 2005) may in fact play a much more serious
reflects the compression rate in bits attributable to              role in structuring RI speech. We dub this alternative the
knowledge of the immediately preceding word. IG is                 Regular Order Hypothesis to indicate that under this
positive by definition (unigram models necessarily have            scenario, words in RI tend to be placed into regular patterns
higher entropies than the corresponding bigram models).            of syntagmatic association.
   IG can be used to compare the contribution of bigrams to
models of different languages, a task which is not entirely                   Experiment: IG in RI and English
straightforward. For instance, languages might differ in their     We test the above hypotheses with respect to surface
baseline unigram entropies (and bigram entropies for that          (unstemmed) n-grams in RI and English. We apply the logic
matter) for any number of reasons (e.g., as a function of          of IG as formulated above to size-matched samples of RI
morphological complexity of words). IG counters this               and English transcribed speech. To further compensate for
difficulty by relativizing the performance of the bigram           the size of the corpora under investigation, we introduce a
model to that of the unigram baseline.                             bootstrapping procedure designed to maximize the
   Another useful feature of IG is that it can be applied to       reliability of small-sample IG estimates. We then model the
relatively small text samples, where all comparison models         resulting IG estimates as a function of language (RI vs.
are trained on samples of the same size. This property is          English) and text type (original vs. randomized) using linear
critical considering that the RI corpus published by Gil and       mixed-effects regression.
colleagues contains only 2,700 words, well below what is
typically needed to draw reliable statistical inferences.          Data
    One might argue that bigram models trained on such
small samples will always perform remarkably poorly.               The data for RI were taken from Gil’s corpus as published in
However, the goal of this analysis is not to create an optimal     four text files on the Max Plank Institute for Evolutionary
model, but to test to what extent bigram knowledge                 Anthropology Jakarta Field Station website2. Each file
improves classification in RI and English. And yet the             contains a stretch of transcribed naturalistic face-to-face
magnitude of this increase in informativity naturally              interactions, including the telling of stories and extended
depends on model performance. Therefore, comparing IG              riddles. The transcriptions have been broken into lines, and
estimates for different samples requires that we take careful      each line is annotated for the following set of
steps to ensure the comparability of our samples and               representational dimensions: orthography, phonetic form,
interpretability of our results. First, we must match all          morphological parse, and morpheme-by-morpheme English
samples for size (larger samples will ceteris paribus yield        gloss. Based on the orthographic tier, the RI corpus
more accurate models). Second, we must establish a                 comprises 2,727 words (unintelligible speech, marked with
common baseline against which the IG increase can be               sequences of ‘x’, was removed prior to the analysis).
assessed. One way to obtain a common baseline is to derive
                                                                   2
the corresponding minimal informativity distribution for               http://lingweb.eva.mpg.de/jakarta/data_PKN.php:       data
                                                                   accessed 7/11/2014.
                                                               1316

   All four recordings were taken from the same native              English samples represent diverse genres, ranging from
speaker, making the corpus less than ideal for purposes of          intimate conversations to evangelical sermons. They
generalization. However, given the strength of Gil’s claims,        therefore vary along a number of dimensions, including
it is not clear how the idiosyncratic behavior of a single          formality, mono-/dialogicality, and the total number of
individual could result in the appearance of bigram structure       speakers and/or other justified conversational participants.
when the underlying grammar remains as free and
underspecified as the system described above.                       Procedure
   For the purposes of this analysis, the four individual files     We generated IG estimates for randomized and non-
were combined into a single text. This means that the corpus        randomized versions of each of the 20 samples. This
is multiply discontinuous as there are three unauthentic            required several steps. First, we created a randomized
junctures. This heterogeneity of content could be                   version of each sample by scrambling the words contained
problematic for the generation of n-gram models. For                therein at the level of the complete text. In so doing, we
instance, it might be that the training sample (randomly            eliminated (a) any non-random, semantically motivated
selected) comprises text from three of the four text files,         proximity effects and (b) any principled ordering of
while the test sample comes from the fourth. Differences in         words/constituents. This process left us with a total of 20
topic, register, and genre, among others, might lead such a         randomized texts (19 English, 1 RI) and 20 non-randomized
model to underperform in the classification of the unseen           texts (19 English, 1 RI).
text given the over- or under-representation of certain                Next, we estimated the IG values for all 40 samples
distributionally biased unigrams or bigrams. As it turns out,       (random and non-random). In order to maximize the
however, these issues are not all that serious for this             representativeness of the IG value, we calculated ten cross
particular corpus considering the goals of this study. First,       entropies for each sample by using ten-fold leave-one-out
all four of the texts are more or less closely related in terms     cross-validation. All models were trained using the n-gram
of register (informal speech) and genre (story telling vs.          model estimator from the Natural Language Toolkit (NLTK)
riddles). Therefore, we should not expect the files to differ       module for Python (cf. Bird, Klein, & Loper, 2009) with
substantially in their basic structural properties because of       Lidstone probability smoothing (γ = 0.2) to account for the
these discourse-level features. Second, as mentioned above,         existence of unigram/bigram types not observed in the
the four files were all collected from the same speaker.            sample. This process yielded 400 unigram cross entropy
While undoubtedly harmful for generalization to the whole           estimates (10 estimates per 40 samples; 200 random and
population, this fact actually works to solve the problem of        200 original). We then repeated these steps, substituting
discontinuity. Because we are not dealing with different            bigram models (with unigram backoffs), to generate a total
speakers, the concatenation of these four files can be              of 800 n-gram cross entropy estimates. Following the
considered a proxy for the evolution of topics across               procedure outlined above, we subtracted each bigram cross
extended conversation. Finally, even if the discontinuities         entropy from its associated unigram cross entropy, creating
present in the collapsed corpus did lead to artificially high       a total of 400 IG estimates (380 English, 20 RI). These
cross entropies for the individual models, this would only          estimates serve as the dependent variable in the regression
bias the results in favor of the monocategorial analysis, and       analysis, discussed below.
so serve to increase the conservativeness of the estimates.            Finally we computed the type-token ratios for each
   In addition to the RI data, we extracted 19 English              sample. We calculated these values on the basis of surface
comparison samples. All English data were sampled from              forms (i.e., we did not apply any stemming in my estimation
the Santa Barbara Corpus of Spoken American English (Du             of the number of types) by dividing the size of the unique
Bois, Chafe, Meyer, Thompson, Englebretson, & Martey,               set of lexical forms by the overall size of the sample.
2000-2005), which contains approximately 249,000 words
of transcribed spoken English from 60 different naturalistic        Results
face-to-face interactions. Each sample was matched to
                                                                    To evaluate the hypotheses laid out above, we computed a
length of the RI corpus. Full files with word counts between
                                                                    linear mixed effects model with IG estimate as dependent
2500 and 3000 words were taken whole. There were twelve
                                                                    variable, language (RI vs. English), text type (original or
such files. The remaining seven samples consist of the first
                                                                    randomized), and type-token ratio as fixed effects, and
2750 words of seven files (respectively), which were
                                                                    filename as a random effect. In order to test the Variable
selected randomly from among those having length greater
                                                                    Order Hypothesis, language and text type were allowed to
than 3000 words.
                                                                    interact as an additional fixed effect. All possible effects
   The reasoning behind selecting exactly 19 comparison
                                                                    were included in the initial model. Non-significant
samples is that a difference in behavior of the one RI text
                                                                    contributors to the model were removed through a
out of twenty total texts would mirror the 5% α-threshold
                                                                    hierarchical backward elimination of factors: the predictor
commonly adopted for significance testing. In this way, we
                                                                    with the largest non-significant p-value (α = 0.05) was
guard against the possibility that non-representative
                                                                    eliminated so long as it did not participate in any higher
idiosyncrasies of individual English files could lead to
                                                                    order interaction. This process continued until only
spurious results. This is especially important, given that the
                                                                1317

significant predictors or predictors participating in                                   higher than those from randomized texts. Crucially, this
significant higher-order effects remained.                                              relationship holds for both English and RI.
  Only type-token ratio (F(1, 18) = 20.81; p < .0001) and
text type (original vs. random; F(1, 378.68) = 2739.73; p <                             Discussion
.0001) emerged as significant predictors. Importantly, no                               The analysis did not reveal any interaction between
significant interaction was observed between language and                               language and text type. Therefore, the Variable Order
text type. Further, no significant main effect was observed                             Hypothesis was not supported: RI and English exhibit
for language after removing the interaction of language and                             equivalent preferences for ordering of word pairs. Notice
text type.                                                                              that, given our design, this interaction between language and
                                                                                        text randomization should have been the only way for
                                                                                        language to impact IG scores in this model. The reasoning is
                                                                                        this: randomization should have the same effect on all
                                                                                        samples (so long as sample size and TTR have been
                                                                                        controlled for). A main effect of language, however, would
     Information Gain (bits)
                                                                                        mean that both non-randomized and randomized IG values
                                                                                        were consistently higher for one of the two language groups.
                                                                                        Such a finding would suggest either that our measure is
                                                                                        sensitive to properties of the samples beyond those included
                                                                                        in our design or that our randomization strategy left unequal
                                                                                        residues of non-random sequencing within the samples.
                                                                                           We observed a significant effect of text type, as predicted
                                                                                        by the Regular Order Hypothesis. The advantage in IG
                                                                                        boosting effects found for bigram models of non-
                                                     TTR                                randomized texts in English can be attributed to generalized
                                                                                        syntactic constraints. Should we impute the same source to
                               Figure 1: Main effect of type-token ration (TTR) on
                                                                                        the effect observed for RI? While the answer to this question
                                      information gain (measured in bits)
                                                                                        must for several reasons remain tentative, the fact that
                                                                                        bigram sequencing was identically informative requires
  As shown in Figure 1, TTR correlated negatively with IG
                                                                                        explanation. Gil’s monocategorial analysis could either
(β=-1.84, s.e.=.4). Therefore, as expected, models based on
                                                                                        attribute this effect to the small class of particles described
more lexically diverse samples (i.e., samples with higher
                                                                                        above or else rely exclusively on semantic and pragmatic
TTR values) tended to benefit less from knowledge of the
                                                                                        regularity. The former case would only offer a compelling
previous word. This term was only included in the model as
                                                                                        counter if the internal speciation of the particle class was on
a control, and so will not be considered further.
                                                                                        par with that of English word classes generally (i.e., to
                                                                                        admit a the existence of highly differentiated word classes in
                                                                                        RI). The latter case would suggest that preferences on the
                                                                                        combination of certain semantic types within certain
                                                                                        pragmatic contexts translate into particular sequencing of
                                                                                        the words instantiating those types. This contingency
 Information Gain (bits)
                                                                                        between meaning and form would be indistinguishable from
                                                                                        that posited of the fundamental syntactic constituent of
                                                                                        Construction Grammar (and other usage-based theories),
                                                                                        namely the construction (see Goldberg, 1995). In either
                                                                                        case, explaining these results would push the
                                                                                        monocategorial analysis ever closer to the more traditional
                                                                                        syntactic accounts of word order.
                                                    Text type                                                   Conclusions
                                                                                        Previous studies have argued that RI lacks generalized word
                                 Figure 2: Main effect of text type (was the text       classes or syntactic constraints on word order. This analysis
                                randomized or not) on information gain values           constitutes an important departure from our generally
                                                                                        accepted understanding of the human language faculty. The
  Above and beyond the effect of type-token ratio, the                                  present study showed that if this analysis is correct, then it is
regression returned a main effect of text randomization (β=-                            of little practical relevance to RI speech. An examination of
.62, s.e.=.01). Figure 2 shows that, overall, IG scores from                            surface- derived bigram models of RI and English speech
properly ordered (original) texts are approximately 0.7 bits                            revealed that these languages show an indistinguishable
                                                                                        benefit (IG increase) over unigram models trained on and
                                                                                     1318

applied to identical samples. English word order is largely                              References
syntactically determined, raising the question of whether
                                                                  Arnold, J. E., Wasow, T., Losongco, A., and Ginstrom, R.
this similarity in surface structure can be attributed to the
                                                                     (2000). Heaviness vs. newness: The effects of structural
same (syntactic) source for RI. On the one hand, we see that
                                                                     complexity and discourse status on constituent ordering.
RI behaves as if it were syntactically constrained (in
                                                                     Language, 76, 28-55.
comparison with English), and we know that closely related
                                                                  Baayen, R. H., Milin, P., Filipović-Đurđević, D., Hendrix, P.
varieties of Indonesian and Malay exhibit something like
                                                                     & Marelli, M. (2011). An amorphous model for
‘traditional’ syntax (Sneddon, 1996). On the other hand, we
                                                                     morphological processing in visual comprehension based
know that word order is co-determined by several other
                                                                     on naive discriminative learning. Psychological Review,
factors, including prosodic, segmental, semantic, and
                                                                     118, 438-482.
pragmatic variables. Further evidence is needed to tease this
                                                                  Bird, S., Klein, E., & Loper, E. (2009). Natural language
network of effects apart. However, these factors have
                                                                    processing with Python. Sebastopol: O’Reilly.
themselves been implicated in the grammaticalization
                                                                  Du Bois, J. W., Chafe, W. L., Meyer, C., Thompson, S. A.,
process whereby syntactic forms emerge out of local
                                                                     Englebretson, R., and Martey, N. (2000-2005). Santa
contingency of form and meaning. It is therefore unclear
                                                                     Barbara corpus of spoken American English, Parts 1-4.
whether these additional factors can ever be fully
                                                                     Philadelphia: Linguistic Data Consortium.
disentangled from syntax in the diachrony of a language,
                                                                  Gil, D. (1994). The structure of Riau Indonesian. Nordic
much less in the synchrony. Indeed, many frameworks argue
                                                                     Journal of Linguistics, 17, 179-200.
for these parameters being directly encoded in syntactic
                                                                  Gil, D. (2002). The prefixes di- and N- in Malay/Indonesian
representations (e.g., Goldberg, 1995).
                                                                     dialects. In F. Wouk & M. Ross (Eds.), The history and
   Whatever the explanation, the degree of structure
                                                                     typology of Western Austronesian voice systems (241-
observed here suggests the presence of pervasive functional
                                                                     283). Canberra: Pacific Linguistics.
grouping in RI. Depending on the quantity and
                                                                  Gil, D. (2005). Word order without syntactic categories:
distinctiveness of these groups, and of course their
                                                                     How Riau Indonesian does it. In A. Carnie, H. Harley,
diachronic depth, RI might present a case of intermediate
                                                                     and S. A. Dooley (Eds.), Verb first: On the syntax of
grammaticalization of syntactic structures, whereby
                                                                     verb-initial languages (243-263). Amsterdam: John
probabilistic biases have begun to crystallize into
                                                                     Benjamins.
constituent order constraints. On the other hand, this
                                                                  Gil, D. (2008). How Much Grammar Does It Take to Sail a
apparent structure might simply be the product of
                                                                     Boat. In G. Sampson, D. Gil, & P. Trudgill (Eds.),
simplification via widespread second language acquisition
                                                                     Language complexity as an evolving variable (123-130).
(McWhorter, 2006). In this scenario, lower level structural
                                                                     Oxford University Press, Oxford.
features like the co-occurrence probabilities examined here
                                                                  Gil, D. (2013). Riau Indonesian: A language without nouns
might have persisted while overt morphosyntax wore away.
                                                                     and verbs. In J. Rijkhoff & E. van Lier (Eds.), Flexible
In either case, Gil’s monocategorial analysis does not appear
                                                                     word classes: Typological studies of underspecified parts
capable of eluding the specter of grammar.
                                                                     of speech (89-130). Oxford: Oxford University Press.
   On another level, this finding provides a more reasonable
                                                                  Goldberg, A. E. (1995). Constructions: A condtruction
solution to the underspecification problem faced by speakers
                                                                     grammar approach to argument structure. Chicago:
of a language like RI. Mired in ambiguity, they appear to
                                                                     University of Chicago Press.
have adopted methods to structure their utterances in
                                                                  Hengeveld, K. (2013). Parts-of-speech system as a basic
consistent, conventionalized ways. As more richly annotated
                                                                     typological determinant. In J. Rijkhoff & E. van Lier
corpora become available, we can begin to examine whether
                                                                     (Eds.), Flexible word classes: Typological studies of
these     conventionalized      orderings     correlate  with
                                                                     underspecified parts of speech (31-52). Oxford: Oxford
conventionalized interpretations. Based on Gil (2005), we
                                                                     University Press.
should expect that, indeed, particular orderings impose at
                                                                  McWhorter, J. (2006). Language interrupted: Signs of non-
least the tendency for particular interpretations.
                                                                     native acquisition in standard language grammars. New
   Methodologically, this study has demonstrated that even
                                                                     York: Oxford University Press.
small corpora of understudied languages can provide for
                                                                  Rijkhoff, J. & van Lier, E. (Eds.). (2013). Flexible word
relatively rich analyses of probabilistic structure.
                                                                     classes: A typological study of underspecified parts-of-
Particularly, the relativization vis-à-vis (1) the English to
                                                                     speech. Oxford: Oxford University Press.
Riau sample ratio and (2) the unigram-bigram differential
                                                                  Shannon, C. E. (1948). A mathematical theory of
ensured that comparisons could be established on the basis
                                                                     communication. The Bell System Technical Journal,
of a normalized baseline. Without this additional layer, it
                                                                     28(3), 379-423.
would be difficult to determine what magnitude of IG score
                                                                  Sneddon, J. N. (1996). Indonesian: A comprehensive
should be treated as indicating a meaningful difference in
                                                                     grammar. New York: Routledge.
amount of structure.
                                                              1319

