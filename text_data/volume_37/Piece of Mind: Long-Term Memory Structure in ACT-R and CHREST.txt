           Piece of Mind: Long-Term Memory Structure in ACT-R and CHREST
                                         Martyn Lloyd-Kelly (martynlk@liverpool.ac.uk)
                                          Fernand Gobet (fernand.gobet@liverpool.ac.uk)
                                     Department of Psychological Sciences, University of Liverpool,
                                               Bedford Street South, Liverpool, L69 3BX, UK
                                              Peter C. R. Lane (peter.lane@bcs.org.uk)
                                         School of Computer Science, University of Hertfordshire,
                                                  College Lane, Hatfield, AL10 9AB, UK
                               Abstract                                  rent3 information regarding how ACT-R and CHREST struc-
                                                                         ture LTM. This will facilitate both understanding and efficient
   Creating a plausible Unified Theory of Cognition (UTC) re-
   quires considerable effort from large, potentially distributed,       comparisons of the similarities and differences between the
   teams. Computational Cognitive Architectures (CCAs) pro-              two architectures with respect to this feature and allow psy-
   vide researchers with a concrete medium for connecting dif-           chologists using ACT-R or CHREST to tailor their investiga-
   ferent cognitive theories to facilitate development of a robust,
   unambiguous UTC. However, due to wide dissemination of re-            tions accordingly. Second, the comparison highlights novel
   search effort, and broad scope of cognition as a psychological        ways of developing both architectures and should foster dia-
   science, keeping track of CCA contributions is difficult.             logue and exchange of ideas between cognitive psychologists
   We compare the structuring of long-term memory (LTM) in               in general and the ACT-R and CHREST development groups
   two CCAs: ACT-R and CHREST. LTM structuring is consid-                in particular. Third, by identifying common and disparate el-
   ered in particular since it is an essential component of CCAs
   and underpins most of their operations. We aim to consolidate         ements of LTM structuring in both architectures, a consensus
   knowledge regarding LTM structuring for these CCA’s and               upon the subject can begin to be formalised to some degree,
   identify similarities and differences between their approaches.       enabling the construction of a valid UTC.
   We find that, whilst the architectures are similar in a number
   of ways, providing consensus for some concepts to be included            ACT-R and CHREST are, respectively, examples of top-
   in a UTC, their differences highlight important questions and         down and bottom-up approaches to cognitive modelling:
   development opportunities.                                            ACT-R is inherently pluralistic (Jilk, Lebiere, O’Reilly, &
   Keywords: ACT-R, CHREST, Cognitive Architectures,                     Anderson, 2008) and can accommodate a number of cogni-
   Long-term Memory
                                                                         tive theories. It therefore adopts a laissez-faire attitude to-
                                                                         wards how its structures and functions operate. CHREST, on
                           Introduction                                  the other hand, focuses on modelling learning and the devel-
Several CCAs are currently available to psychologists; some              opment of expertise, and contains a number of hard-coded
benefit from large user-bases and development teams aim-                 limitations on how its structures and functions operate. Con-
ing to create pan-optic models of cognition, of which ACT-               sequently, to find some common ground between the two
R (Anderson, 2007) is a notable example. Others, however,                architectures, we focus on the architecture of ACT-R as-is
have a relatively smaller community and focus upon partic-               (Bothell, n.d.), rather than considering it in accordance with
ular aspects of cognition: CHREST (Gobet & Lane, 2010)                   any particular implementation.
focuses on modelling general mechanisms that govern the in-                 The paper is structured as follows: sections ACT-R and
terplay between perception and cognition resulting in learn-             CHREST discuss, in detail, the architectures’ mechanisms
ing and acquisition of expertise in disparate domains such as            for LTM organisation to provide a centralised location for
games, physics, language and concept formation1 . CCAs are               current information regarding LTM structuring in CHREST
powerful tools that force psychologists to specify theories of           and ACT-R. The Architecture Comparison section then per-
cognition unambiguously, facilitating the testing and refine-            forms a comparison based upon the content of the previous
ment of general cognitive principles in domains that apply               two sections allowing for the identification of similarities and
large numbers of constraints (Newell, 1990). They also, cru-             differences between the architectures approach to structur-
cially, allow psychologists to analyse the overlap and dispar-           ing LTM. Finally, the Conclusions and Future Work section
ity between different theories of cognition.                             briefly summarises the contributions of the paper and outlines
   In this paper, we delineate how the latest versions of ACT-           our plans for future work.
R and CHREST (6.0 and 5.0, respectively) structure LTM
with a focus on LTM topology2 . The purpose of our com-                                               ACT-R
parison is three-fold: first, it offers psychologists investigat-
                                                                         ACT-R is composed of a number of core modules that en-
ing theories of LTM structuring a centralised location for cur-
                                                                         capsulate the operations of particular regions of the human
    1 For an overview, see Gobet et al. (2001).                          brain and is primarily a production-rule system, since all in-
    2 “Topology”  is defined here in the sense of a physical network
topology.                                                                   3 At the time of writing.
                                                                     1422

put/output from core modules must pass through a central              takes a simulated period of time (dictated by the parameters
production system using module-specific buffers as an inter-          of the sub-symbolic system). Two simple methods exist to
face. ACT-R has simulated cognition in a wide array of do-            modify information in declarative memory: chunk addition or
mains, including games (Martin, Gonzalez, & Lebiere, 2004),           chunk merging, both of which are performed instantaneously.
arithmetic (Lende & Taatgen, 2012) and language (Oliva, Ser-             Adding new information can be performed explicitly or im-
rano, del Castillo, & Ángel Iglesias, 2010).                         plicitly. Explicit addition entails a module creating a new in-
   LTM in ACT-R is embodied as declarative or procedural              stance of a particular chunk-type, whereas implicit addition
information that is handled by the declarative module or pro-         entails collecting chunks from module buffers at the conclu-
cedural system, respectively (Anderson, 2007). ACT-R uses             sion of an ACT-R cycle. Chunks that are referenced by the
chunks (Chase & Simon, 1973) as currency for these modules            collected chunks and which do not currently exist in declara-
which include a reference and vectors of slots, one of which          tive memory are then created automatically.
defines the chunk’s type. Chunk references act as pointers               To merge chunks, candidates must have the same values
to LTM information and facilitate memory retrieval; taken in          for the slots that they share. If a chunk-type’s slots have been
isolation, references offer little practical information to mod-      extended at any point prior to a merge, this can cause issues
ules. Chunk types are mutable, dictate what slots the chunk           during the merge process since a statically extended chunk
has (along with their default values) and can be super or sub-        will not have a value for an extended slot unless the slot value
classes of other chunk types. This enables construction of            has been explicitly set, increasing the chance of a chunk mis-
chunk type hierarchies that enable slot name and slot value           match. Non-statically extended chunks, however, will have
inheritance. Values for slots may contain references to other         default values set for extended slots, so the chance of a chunk
chunks or simple information, such as a number. In version            mismatch occurring is reduced.
6.0 of ACT-R, the slots for a chunk type can be extended stat-           Declarative memory topology appears to loosely reflect the
ically or non-statically; this has implications when managing         external environment that an ACT-R model is situated in: fre-
declarative memory information (discussed below).                     quency of chunk presentation is only considered when merg-
   ACT-R contains a mathematical, sub-symbolic system that            ing chunks and does not affect the topology of declarative
underpins the declarative and procedural modules (Bothell,            memory. In addition, all chunks remaining in module buffers
n.d.). This system governs what chunks are returned and               are always completely learned at once, so presentation fre-
how quickly (by using activation levels for declarative mem-          quency is disregarded during this operation. The only impact
ory and utilities for productions) after external input is pre-       upon topological structure appears to be caused by the order
sented to ACT-R (Anderson, 2007). To determine what is                of chunk presentation, since it is only chunks that are present
returned, the greater the activation level for a chunk in declar-     in module buffers at the conclusion of a cycle that are assim-
ative memory or the value of a production’s utility, the more         ilated into declarative memory, and module buffers may only
likely it is to be retrieved or selected after it has been found      store one chunk at any time.
in LTM. To determine how quickly a chunk or production is
selected, the activation level or utility affects the simulated       Procedural System
time taken but does not influence real world time. Since the          The procedural system is composed of the procedural, util-
sub-symbolic system does not affect the topology of LTM, it           ity and production-compilation modules. It is responsible for
is not considered in detail here.                                     producing ACT-R’s rational behaviour by maintaining a set
                                                                      of production rules that produce optimal4 chunks in response
Declarative Module
                                                                      to input chunks. Since this paper is concerned with LTM
The declarative module maintains chunks used by ACT-R.                structure, the only modules that will be considered further
Chunks can be created by any module at any time and all               in the procedural system are the procedural and production-
those that remain in module buffers at the conclusion of an           compilation modules. The procedural module stores produc-
ACT-R cycle are collected and added to the declarative mod-           tions and the production-compilation module is concerned
ule instantly. Chunk learning can occur at model compile-             with creating new productions from existing ones.
time (initial memories) or run-time but is, in either case, ab-          Adding productions can occur at compile and run-time; if
solutely concurrent but usually incremental when applied in           there are no productions specified by a modeller at compile-
an ACT-R model. This temporal dissonance arises due to                time, production compilation can not occur at run-time since
ACT-R’s sub-symbolic system; a new chunk has all its in-              there are no pre-existing productions to compile. Productions
formation added concurrently to the declarative module but,           have no topological organisation within the procedural mod-
if its assigned activation is below that of the defined retrieval     ule and adding a production whose name already exists in
threshold, only part of the chunk may be retrieved (if at all).       procedural memory causes the old production to be replaced
   The structure of declarative memory is distinctly graph-           by the new one.
like, since the only links that exist between chunks are slot            To modify productions, the production-compilation mod-
value references; a slot value for a chunk, C, may reference          ule collapses two distinct productions into one. Therefore,
another chunk C0 . Retrieval of LTM consists of performing a
non-directed search through LTM for a matching chunk and                  4 Equivalent to a production’s utility.
                                                                  1423

after multiple production compilations, an ACT-R model can               pert behaviour and, particularly, the acquisition of language
produce a sequence of actions without considering intermedi-             (Jones, Gobet, & Pine, 2007).
ate inputs as it did previously. For example, to produce the an-            Four procedures are used to add or modify LTM informa-
swer to a mathematical operation such as “24 + 57”, a model              tion and are considered in detail: discrimination, familiari-
may simply write “81” in response to this input after produc-            sation, node linkage and template creation/modification. If
tion compilation, rather than using an algorithm that divides            any of these procedures are being performed, subsequent re-
the numbers into units and adding them together. If a newly              quests are blocked. The times taken for LTM to complete
compiled production, P0 , is semantically equivalent to a pro-           each of these procedures are distinct and can be set by mod-
duction that has not been created through production compi-              ellers at run-time. However, times for discrimination and
lation, P, then P0 is discarded. If P0 is semantically equiva-           familiarisation are considered to be part of the architecture
lent to a production that has been created through production            since they have been validated independently by empirical re-
compilation, P∗, and utility learning is enabled in ACT-R, P0            search (Feigenbaum & Simon, 1984; Gobet et al., 2001).
is not added but the utility of P∗ is updated.
   Productions are only compiled if they meet a set of con-              Discrimination & Familiarisation
ditions. Most of these check syntactic aspects of production
                                                                         Discrimination and familiarisation are the procedures by
rules so that they can be feasibly combined within the com-
                                                                         which CHREST adds new nodes to LTM or modifies existing
putational constraints of ACT-R’s architecture and so are not
                                                                         ones, respectively. Therefore, discrimination increases the to-
discussed here. Those of interest are: productions must have
                                                                         tal number of nodes in LTM and familiarisation increases the
been executed in sequence, and the time between the relevant
                                                                         size of individual nodes in LTM. These procedures rely upon
productions being activated must be less than the threshold
                                                                         chunks presented to CHREST having a finished property set
time specified. These conditions, in conjunction with the im-
                                                                         that indicates a complete unit of information.
plicit constraint that only two productions can be compiled at
a time, mean that production compilation is incremental and                 Discrimination occurs when any of the following condi-
enforces temporal contiguity.                                            tions are true for a pattern presented to LTM, P, and a chunk
                                                                         retrieved from LTM after P has been presented, C. Tests are
                             CHREST                                      applied in the order specified and are cumulative:
CHREST’s implementation of LTM contains one data struc-
                                                                         • C is a root node for a modality
ture comprising a hierarchical discrimination network that in-
dexes a pool of nodes connected by test-links. Nodes contain
                                                                         • C’s finished property is:
chunks (Chase & Simon, 1973), and in combination with test-
links, enable LTM to provide similarity functions and act as a
                                                                            – True and:
retrieval device. CHREST’s current implementation divides
LTM memory into three modalities: action, auditory and vi-                    ∗ The number of primitives in C isn’t equal to the number
sual. These three modalities are root nodes in LTM; chunks                      of primitives in P.
presented to CHREST must have their modality specified so                     ∗ P’s finished property is set to false.
LTM can be organised appropriately.                                         – False and the number of primitives in P is less than the
   CHREST stores the entirety of a chunk’s information in                      the number of primitives in C.
the chunk’s reference. For example: a chunk containing an
addition fact such as <[26][+][6]> is composed of three                  • A primitive in P is not contained in C.
primitives: [26], [+] and [3]. Its semantics, “this is an ad-
dition fact”, are not explicitly represented by the contents of          • The order of primitives in P is not the same in C.
the chunk. Encoding perceptual information this way makes
it possible to act on a pattern rapidly (Lane & Gobet, 2011).
                                                                            When discrimination occurs, a new test-link is added from
   Learning in CHREST is incremental and on-line: external               C containing the first mismatched primitive in P. Thus,
information is learned in discrete steps during the model’s in-          CHREST’s incremental learning is hard-coded and uses the
teraction with its external environment. For example, if the             least amount of information possible to discriminate between
addition fact above were presented, each individual primitive            external domain features in keeping with the concept of
must be committed to LTM in discrete operations (see Dis-                bounded rationality (Simon, 1955) and expert behaviour in
crimination & Familiarisation section below for an explana-              general (Gobet et al., 2001).
tion) before the concatenation thereof can be committed to
                                                                            Familiarisation appends a new primitive from P to C and
LTM5 . This incremental, on-line learning enables CHREST
                                                                         occurs if the number of primitives in P is greater than in C and
to pick up the statistical distribution of the environment it is
                                                                         C’s finished property is set to false. As with discrimination,
situated in naturally, a feature that is critical for simulating ex-
                                                                         only one primitive is added to LTM, i.e. the first primitive of
    5 For a discussion of data supporting this design see Feigenbaum     P, p, that is not present in C. Note that p must be present in
and Simon (1984).                                                        LTM before it can be appended to C.
                                                                     1424

Node Links                                                            expounds their differences. This comparison offers insights
Node links give CHREST’s LTM a graph flavour; they can                into what cognitive modellers appear to agree on and should
exist between nodes that have different descendent paths              be taken forwards into UTCs, new CCAs or new versions of
through LTM. Thus, horizontal and vertical traversal of LTM           ACT-R and CHREST, and new ideas that could significantly
is possible. Similarity links are created without modeller in-        advance the state-of-the-art for cognitive science.
tervention when a user-defined number of duplicate primi-             Similarities
tives, n, exist in two distinct visual chunks that are both com-
                                                                      Notably, both ACT-R and CHREST use chunks, i.e. aggre-
pletely committed to LTM and present in visual STM. The
                                                                      gated features of the external environment, as their LTM cur-
latter constraint ensures that links between nodes are based
                                                                      rency. Consequently, it seems sensible to propose that a UTC
on a spatial or temporal contiguity, preserving an essential
                                                                      should also use chunks as its cognitive units. Addition of
property of perceptual chunking (Gobet et al., 2001). Un-
                                                                      chunks into LTM in both architectures can be on-line, i.e.
like discrimination and familiarisation, the order of primitive
                                                                      during the model’s interaction with an environment and, po-
occurrence in chunks presented to CHREST does not factor
                                                                      tentially, incremental (see the Declarative Module section for
into the creation of similarity links. Note that semantic links
                                                                      why incremental learning may not be always implemented in
are bi-directional too: if a similarity link exists between two
                                                                      ACT-R). Furthermore, the mechanism that controls implicit
LTM nodes N and N 0 , it is possible to retrieve N 0 from N and
                                                                      chunk addition is also similar between ACT-R and CHREST:
vice-versa.
                                                                      if a chunk, C, references another chunk C0 and C0 is not yet
   Production links are created at run-time without modeller
                                                                      learned (present in LTM) then, if C is already present in LTM,
intervention between a visual node and an action node that are
                                                                      both ACT-R and CHREST will attempt to add C0 to LTM au-
held at the same time in visual and action STM. These links
                                                                      tomatically. However, the likelihood of C0 being committed
hold a value that can be used, for example, to indicate the util-
                                                                      to LTM differs between CHREST and ACT-R: in ACT-R this
ity of a production. For example, in chess, if the visual pattern
                                                                      is guaranteed but is not in CHREST.
<[p g 2][p h 2]> and the action pattern <[p g2 g3]> are
                                                                         With regard to controlling whether or not addition/merging
held in STM, then a production link can be created, with the
                                                                      and discrimination/familiarisation occurs when requested, the
visual pattern as a condition and the action pattern as the out-
                                                                      paired operations of ACT-R and CHREST are more similar
put. When this production is used, its associated value can be
                                                                      than they are different. Addition and discrimination will only
incremented or decremented accordingly to denote the util-
                                                                      add a chunk to LTM if that chunk does not already exist in
ity of the production to inform action-selection in subsequent
                                                                      LTM and to modify or familiarise a chunk the shared infor-
situations. Note that the visual pattern and the action pattern
                                                                      mation in the chunks to be merged must be the same.
can be of arbitrary complexity.
                                                                         In both architectures, chunks are also capable of having
Template Creation and Modification                                    production links created between them. These production
                                                                      links originate and terminate with distinct chunks and each
Templates (Gobet & Simon, 1996) evolve from frequently re-            production incorporates a measurement of utility. This would
trieved LTM nodes, N, that contain a number of core primi-            suggest that the concept of productions is something that is
tives in their chunk, c, and a number of varying primitives, v,       agreed upon although, currently, CHREST only supports pro-
in their chunks that are either descendants of, or have similar-      duction links between visual and action chunks whereas this
ity links to, N; values of c and v can be set by the user. If N       restriction does not appear to exist in ACT-R.
is converted to a template, CHREST attempts to convert any
children of N that can become templates into templates too            Differences
but not nodes that are linked to using similarity links. When         The salient difference between ACT-R and CHREST is ACT-
converted into a template, N contains slots that can have v           R’s use of a sub-symbolic system and CHREST’s non-use of
primitives swapped in/out quickly. Information in slots can           such a system. It may be that cognition, in reality, uses a com-
concern locations of objects, types of object or chunks can be        bination of ACT-R and CHREST’s approaches. The topo-
(recursively) encoded into template slots. Currently, template        logical structure of CHREST tends to represent the statistical
generation itself incurs no time cost. However, filling a slot        distribution of the environment since the order and frequency
has a default time cost of 250ms and this value is considered         of external information has a large effect upon how test-links,
to be part of template theory.                                        nodes and links between nodes in LTM are formed. Such a
                                                                      complete reflection of the external environment is missing in
                 Architecture Comparison                              the structure of declarative memory of ACT-R. Instead, or-
Given the descriptions provided in the ACT-R and CHREST               der and frequency of external information presentation is em-
sections above we now outline similarities and differences            bodied more in the sub-symbolic aspects of ACT-R’s LTM.
between the concepts discussed, namely: topological LTM               The crucial idea that stems from this comparison is that it
structure, chunk structure, chunk addition/modification and           may be the case that whilst frequently encountered informa-
chunk linkage. This section is split in two: the first part dis-      tion is organised in the “specialised” hierarchical discrimina-
cusses similarities between the architectures and the second          tion network implemented by CHREST, infrequently encoun-
                                                                  1425

tered, “general” knowledge may organised in the less struc-          previous paragraph), these chunk-types may serve to help
tured network implemented by ACT-R. The exact function-              organise general knowledge topologically, facilitating a di-
ality for memory retrieval would then differ depending upon          rected search and reducing reliance upon brute-force retrieval
whether external information is represented in the specialised       methods that may cause the utility problem noted in investiga-
area of LTM or not (if it is, the sub-symbolic system could          tions using large LTMs in ACT-R (Kennedy & Trafton, 2006;
be given less precedence and vice-versa). In other words,            Rodgers, Douglass, & Ball, 2009).
a CHREST-like structuring of LTM may emerge in human                     When adding information to chunks, ACT-R and CHREST
LTM after information has first been assimilated and struc-          differ in how the existence of this new information is checked.
tured in a manner akin to ACT-R’s LTM structuring. This              When performing addition, ACT-R only checks to see if the
modification of structure could provide a measure of exper-          reference for a chunk exists in order to determine whether a
tise in a particular domain and the resulting architecture may       chunk should be added. CHREST checks that the chunk’s in-
provide a more complete and psychologically valid model of           formation does not already exist in the order specified. There-
human LTM structure.                                                 fore, CHREST is more concerned with presentation order
   To control transposition of generic LTM information into          than ACT-R given its goal of modelling expertise develop-
specialised LTM information, one could make use of the sub-          ment. It may be that this checking behaviour could be toggled
symbolic functionality and LTM node meta-data that is al-            if the a retrieved chunk is part of specialised LTM or not.
ready present and maintained in ACT-R. For example, given                Another interesting difference between chunk structure in
a certain activation level, a LTM node may then be selected          ACT-R and CHREST relates to where the information in a
for transposition into specialised LTM. This would entail that       chunk is contained. In both ACT-R and CHREST it ap-
nodes are tagged with their modality, a feature currently un-        pears that every piece of information used in LTM needs to
supported by ACT-R, but trivial to implement. Such a mecha-          be internalised as a chunk before it can be used. However,
nism would provide a precise, unambiguous and formal basis           from what we have been able to ascertain research under-
for topological structuring of LTM, since sub-symbolic in-           taken thus far, CHREST may encode redundant information
formation would control whether information becomes hier-            by duplicating chunks. For example, if a LTM node encodes a
archically structured or not. Used in conjunction with long-         chunk, <[26]> then, if this chunk is present in another chunk
term human data regarding learning in a particular domain,           <[26][+][3]>, the chunk containing the single primitive is
this hybrid theory’s psychological validity could be deter-          not referenced in the chunk that contains multiple primitives.
mined adequately.                                                    Instead, the single chunk is duplicated. According to ACT-R
   It may also be interesting to combine ACT-R’s sub-                however, a chunk is stored in one location in LTM and that
symbolic system with CHREST so that it directly influences           location is referenced whenever the chunk is used in another
the structure of LTM components such as templates. Chunks            chunk, removing redundancy. Determining which implemen-
with higher activation values could gain precedence for tem-         tation is psychologically valid is an interesting research ques-
plate slots and would therefore be swapped into a slot space         tion and could help further the current state-of-the-art.
before a chunk with a lower activation value. This follows               With regard to productions, ACT-R and CHREST differ in
the idea of Baddeley (1990), where frequently encountered            a number of ways. First, production creation in CHREST
chunks are processed and memorised more quickly.                     is automatic (no modeller intervention required) and entirely
   With regard to how ACT-R and CHREST structure chunks,             novel productions can be created at run-time. Conversely,
ACT-R is much less restrictive with respect to classifying           ACT-R requires modellers to specify an initial set of produc-
chunk types than CHREST. In ACT-R, it is possible for a user         tions at compile-time and can only compile these pre-defined
to define chunk types at will, allowing super or sub-classes         productions at run-time. Second, production granularity dif-
of chunk types to be created freely. Conversely, CHREST’s            fers with a single production firing in a wide range of situa-
chunk types are governed by the modalities of their con-             tions in ACT-R, so long as its conditions are met and produc-
stituent primitives and are essentially constricted by the input     tions are optimised by tuning their parameters. In contrast,
interface used to generate a chunk. It would seem plausible          productions in CHREST are more akin to micro-productions
to suggest that human cognition can make use of both strate-         since their conditions tend to be specific and their range of
gies, i.e. whilst certain information is encoded as being of a       application limited. In this sense, it seems that ACT-R is able
particular modality: visual, auditory etc., higher-order classi-     to produce, in certain cases, abstract productions that may be
fications can also be applied that may be entirely novel. For        used when new situations occur (where particular productions
example, whilst one may construct a visual chunk contain-            do not apply) but appear to be similar to previous situations.
ing a mathematical formula, we could classify that formula           Currently, CHREST is not capable of creating productions
as being an instance of a mathematical-operation chunk type.         in this way and may therefore benefit from a consideration
More specifically, the formula may be an instance of an addi-        of how ACT-R achieves such functionality. Unifying these
tion chunk type (a sub-class of the mathematical-operation           processes may produce a clearer picture of production gen-
chunk type). If a CCA were produced that is capable of               eration for a UTC. Finally, ACT-R’s production rules allow
organising LTM into specialised and general memory (see              for sequences of actions to be compiled and performed in one
                                                                 1426

step whereas in CHREST, sequences of actions are possible           Feigenbaum, E. A., & Simon, H. A. (1984). EPAM-like
but not the compilation of two productions. This is an area of         models of recognition and learning. Cognitive Science, 8,
potential development and also raises an interesting observa-          305–336.
tion/question: if experts can perform sequences of moves, are       Gobet, F., & Lane, P. C. R. (2010). The CHREST architecture
these learned production sequences ever revised? If so, is the         of cognition: The role of perception in general intelligence.
whole sequence revised after its execution or does an expert           In E. Baum, M. Hutter, & E. Kitzelmann (Eds.), Proceed-
consider each subsequent production in the sequence whilst             ings of the 3rd conference on artificial general intelligence
the sequence is being performed?                                       (Vol. 10, pp. 7–12).
                                                                    Gobet, F., Lane, P. C. R., Croker, S. J., Cheng, P. C.-H.,
             Conclusions and Future Work                               Jones, G., Oliver, I., & Pine, J. M. (2001). Chunking mech-
Our intention in this paper has primarily been to create a cen-        anisms in human learning. Trends in Cognitive Sciences, 5,
tralised repository of information regarding the LTM struc-            236–243.
turing approaches used by ACT-R and CHREST. In the long-            Gobet, F., & Simon, H. A. (1996). Templates in chess mem-
term, we hope that this will provide an efficient resource for         ory: A mechanism for recalling several boards. Cognitive
cognitive modellers to decide between ACT-R and CHREST                 Psychology, 31, 1–40.
and to tailor their experiments appropriately given the infor-      Jilk, D. J., Lebiere, C., O’Reilly, R. C., & Anderson, J. R.
mation discussed. In addition, we also attempted to outline            (2008). SAL: an explicitly pluralistic cognitive architec-
where these CCAs overlap/differ in order to both facilitate            ture. Journal of Experimental and Theoretical Artificial
agreement on underlying processes of LTM structuring for a             Intelligence, 20(3), 197-218.
UTC, and highlight questions that need to be answered before        Jones, G. A., Gobet, F., & Pine, J. M. (2007). Linking
other UTC concepts can be formalised. In the short-term, we            working memory and long-term memory: A computational
hope this this work will foster a constructive dialogue and ex-        model of the learning of new words. Developmental Sci-
change of ideas between ACT-R and CHREST’s development                 ence, 10, 853–873.
teams/user-bases, who are currently disconnected.                   Kennedy, W. G., & Trafton, J. G. (2006). Long-term
   For those interested in using ACT-R or CHREST, the cru-             symbolic learning in SOAR and ACT-R. In D. Fum,
cial consideration depends upon how much flexibility with              F. D. Missier, & A. Stocco (Eds.), Proceedings of the 7th
regard to LTM operations a domain-modeller requires. ACT-              international conference on cognitive modeling (p. 166-
R contains less hard-coded functionality (it is possible to            171).
have an ACT-R model learn 30 chunks at once, for exam-              Lane, P. C. R., & Gobet, F. (2011). Perception in chess and
ple), whereas CHREST hard codes structural functionality               beyond: Commentary on Linhares and Freitas (2010). New
that imposes adherence of the architecture to the principle            Ideas in Psychology, 29, 156–61.
of bounded-rationality. Whilst increased flexibility provides       Lende, L. K., & Taatgen, N. (2012). Modeling representa-
the ability to implement and test multiple theories of cogni-          tional shifts in learning the number line. In N. Rußwinkel,
tion, it also increases the programming overhead for domain-           U. Drewitz, & H. van Rijn (Eds.), Proceedings of the 11th
modellers since LTM functions will also need to be scheduled           international conference on cognitive modeling (p. 175-
in addition to the creation of an input/output interface etc.          180).
   In future work we intend to take the ideas delineated in         Martin, M. K., Gonzalez, C., & Lebiere, C. (2004). Learning
the Differences sub-section of the Architecture Comparison             to make decisions in dynamic environments: ACT-R plays
and expand upon them. Of particular interest to us is the              the beer game. In M. Lovett, C. Schunn, C. Lebiere, &
idea that general LTM knowledge (organised topologically in            P. Munro (Eds.), Proceedings of the 6th international con-
a graph-like manner implemented by ACT-R) may become                   ference on cognitive modeling (Vol. 420, p. 178183).
specialised (topological structuring becomes hierarchical as        Newell, A. (1990). Unified theories of cognition. Cambridge,
in CHREST) when certain sub-symbolic conditions are met.               MA: Harvard University Press.
                                                                    Oliva, J., Serrano, J. I., del Castillo, M. D., & Ángel Iglesias.
                           References                                  (2010). Cognitive modeling of the acquisition of a highly
Anderson, J. R. (2007). How can the human mind occur in                inflected verbal system. In D. D. Salvucci & G. Gunzel-
   the physical universe? Oxford University Press.                     mann (Eds.), Proceedings of the 10th international confer-
Baddeley, A. D. (1990). Human memory: Theory and prac-                 ence on cognitive modeling (p. 181-186).
   tice. Boston: Allyn & Bacon.                                     Rodgers, S. M., Douglass, S. A., & Ball, J. (2009). Large
Bothell, D.              (n.d.).      ACT-R 6.0 reference              declarative memories in ACT-R. In A. Howes, D. Peebles,
   manual - working draft.                   Retrieved from            & R. P. Cooper (Eds.), Proceedings of the 9th international
   http://act-r.psy.cmu.edu/actr6/reference-                           conference on cognitive modeling (p. 222-228).
   manual.pdf                                                       Simon, H. A. (1955). A behavioral model of rational choice.
Chase, W. G., & Simon, H. A. (1973). The mind’s eye in                 The Quarterly Journal of Economics, 69, 99–118.
   chess. In W. G. Chase (Ed.), Visual information processing
   (pp. 215–281). New York: Academic Press.
                                                                1427

