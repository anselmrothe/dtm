                                  Voice-specific effects in semantic association
                                                   Ed King (etking@stanford.edu)
                                       Department of Linguistics, Margaret Jacks Hall, Bldg. 460
                                                           Stanford, CA 94305 USA
                                             Meghan Sumner (sumner@stanford.edu)
                                       Department of Linguistics, Margaret Jacks Hall, Bldg. 460
                                                           Stanford, CA 94305 USA
                              Abstract                                   social category like gender, which resonates back into all the
                                                                         exemplars linked to that gender. So, hearing a woman say a
   Benefits to lexical access are provided by acoustically-cued
   speaker characteristics (such as gender and age), but little work     word eventually activates all exemplars produced by women.
   has investigated these effects in meaning-based tasks. Word              The exemplar resonance model predicts associations be-
   recognition is affected both by a word’s base-level activation        tween social categories and lexical items, but it cannot handle
   and by associative spread of activation among words, and is
   correlated with speed of lexical access. In a free association        differences in word association given different phonetically-
   task and a semantic priming task, we find off-line and on-line        cued social categories. There is intuitive reason to believe that
   evidence of speaker-specific relationships between words. Our         such an interaction should exist. For example, when hearing
   results suggest the need to extend existing models of spoken
   word recognition to include interactions between linguistic in-       the word princess spoken by an adult with a British accent,
   formation and social information that is cued by variation in         people will probably think of a member of the real-life Royal
   speech.                                                               Family; when hearing princess spoken by an American child,
   Keywords: linguistics; speech perception; spoken word                 they may think of a fictional Disney character. Similarly, the
   recognition; semantic priming; free association                       word clothes, spoken by a woman, is likely to be more asso-
                                                                         ciated with dresses and skirts than the word clothes spoken
                          Introduction                                   by a man.
Over the past thirty years, researchers in speech perception                Despite the intuition that semantic association should inter-
have established that, rather than filtering out the phonetic            act with speaker characteristics, there has been relatively little
details of incoming speech, listeners utilize these specific             empirical work done to establish whether these effects exist.
phonetic cues when recognizing words. Listeners remember                 Neuroscience work has shown that listeners have difficulty
studied words better when they are produced by the same                  incorporating semantic information when a spoken message
speaker (Goldinger, 1996), a speaker of the same gender                  is inconsistent with perceived speaker identity (e.g., a child
(Schacter & Church, 1992), or at the same rate (Bradlow, Ny-             saying “I think I might be pregnant”) (Van Berkum, van den
gaard, & Pisoni, 1999) as when they were learned. Listen-                Brink, Tesink, Kos, & Hagoort, 2008; see also Creel & Tum-
ers shift their perception of phoneme boundaries depending               lin, 2011).
on audio or visual cues to speaker sex (Johnson, Strand, &                  Taken together, these studies show that listenersuse voice
D’Imperio, 1999) or speaker dialect (Niedzielski, 1999; Hay              characteristics as a context that may lead them to generate ex-
& Drager, 2010).                                                         pectations about the content of an utterance given a sentential
   In a different domain, we know that word recognition is               context. In other words, listeners are sensitive to the proba-
faster following a related word than an unrelated word. For              bility of a word given a specific voice in a specific sentence:
example, people are faster to recognize the word NURSE                   as predicted by Johnson, 2006’s resonance model, voice pro-
when it was immediately preceded by the related word DOC-                vides a context for the recognition of a word. We still do not
TOR than when it was immediately preceded by the unre-                   know, however, whether voice provides a context for the in-
lated word BREAD. Semantic priming effects have been es-                 terpretation of a word. Given the same word in two different
tablished for the recognition of visual words (e.g, Meyer &              voices, do listeners understand the word differently in voice-
Schvaneveldt, 1971) and spoken words (e.g., Radeau, 1983).               specific ways?
   The existence of word association effects in spoken words                This paper tests the hypothesis that words are interpreted
raises the possibility of an interaction between these effects           in speaker-specific ways. Using a free association task, we
and the aforementioned phonetic specificity effects: specific            establish that, when listeners hear a spoken prompt and are
phonetic cues in spoken words may be able to aid activation              asked what word first comes to mind, responses differ de-
of other words. This was argued by, e.g., Johnson, 2006,                 pending on the speaker of the word. With a subset of the
who proposed a model of exemplar-category resonance: the                 prompt-response pairs from the free association task, we then
acoustic signal activates exemplars based on similarity, so              show that this effect appears in on-line spoken word recog-
acoustic cues to a woman’s voice give preferentially more ac-            nition: the speed with which listeners recognize a target (re-
tivation to female-produced exemplars than to male-produced              sponse) word, after hearing a prime (prompt) in a specific
exemplars. The activation of all of these exemplars feed into a          voice, improves as a function of the voice-specific associa-
                                                                     1111

tion strength derived from the free association task.                constrain associative interactions between different words.
                                                                     Evidence for this connection is particularly lacking in the cur-
      Combining phonetic detail and semantic                         rent literature because work on this topic has manipulated se-
                         relatedness                                 mantic context by using different sentences; however, since
                                                                     listeners may store sentence-size exemplars (Bybee, 2006),
The idea that speaker-specific phonetic cues may affect se-          we cannot assume that sentential context provides a semantic
mantic interpretation goes back at least to Geiselman and            context independent of speaker-indexed exemplars, which is
Bellezza (1976), who proposed a “voice connotation hypoth-           necessary in order to examine speaker-mediated interactions
esis”, in which acoustic cues to speaker sex are used to link        between words.
words with sex-specific connotations. Across a number of                In this paper, we instead propose that the effects of speaker-
studies, they played listeners sets of sentences spoken by one       specific semantic meaning can be best examined by using
of two speakers; despite having only been told to remem-             tasks that specifically target word interpretation: free asso-
ber the sentences, the listeners later performed above chance        ciation and semantic priming. Rather than manipulating both
when asked to identify the sex of the speaker of each sen-           speaker and semantic context (the latter of which may not be
tence. Geiselman and colleagues suggest that this effect is          independent of speaker context), we hold the baseline seman-
due to specific semantic connotations for men and women.             tic context constant by focusing on individual words, and look
   Other authors have argued for voice-specific semantic as-         for speaker-specific interpretations of those words by manip-
sociations in similar ways. Creel and Tumlin (2011) used a           ulating speaker context.
visual world task to track listeners’ eye movements to novel
word-item pairs that were previously presented in either a                                   Experiment 1
male or female voice. In their test session, when a sentence
                                                                     Experiment 1 addresses the question of whether listeners in-
was spoken by the same speaker as in their learning session
                                                                     terpret a given word as having different semantic associations
(and when the speaker/sentence mapping was one-to-one),
                                                                     depending on the voice of the speaker. We use a word as-
listeners looked more quickly to the novel item referred to
                                                                     sociation task (Battig & Montague, 1969), in which listeners
in the sentence. They argue that this effect is due to semantic
                                                                     hear a prompt word and provide the first word that comes to
encoding of speaker voice – and not due to exemplar memo-
                                                                     mind; the frequency with which each response word is pro-
ries for specific word/speaker associations – because listeners
                                                                     vided for a given prompt is a strong reflection of the asso-
looked to the novel item during the frame sentence, before the
                                                                     ciative strength between the probe and the response (Nelson,
actual novel word was spoken.
                                                                     McEvoy, & Dennis, 2000).
   Evidence for an interaction between phonetically-cued so-
                                                                        In our particular free-response word association task, we
cial characteristics and semantic meaning has also been ar-
                                                                     compare the response frequencies of prompt-response pairs
gued for longer-term associations, as opposed to associa-
                                                                     across two speakers. Our hypothesis does not provide a priori
tions that are learned within the course of an experiment.
                                                                     predictions about what particular speaker characteristics (age,
Van Berkum et al. (2008) presented listeners with a series
                                                                     gender, race, dialect, etc.) will lead to differing semantic as-
of sentences that were either consistent or inconsistent with
                                                                     sociation; we thus chose two speakers who differ across many
the speaker, such as a woman or man (respectively) say-
                                                                     social categories. Speaker J is an African-American man in
ing “I always check my make-up before I leave”; they used
                                                                     his early 80s, and speaker M is a White American woman
event-related potential (ERP) monitoring to observe what this
                                                                     in her late 30s. J was raised in the Southern United States,
speaker-specific semantic consistency looks like at a neural
                                                                     and M in a Northern US city, raising the possibility of dialect
level. They found that listeners exhibit an N400 – a negative
                                                                     differences, but both produced word tokens in a Mainstream
ERP spike related to difficulty incorporating semantic infor-
                                                                     American English register.
mation – when a spoken message was inconsistent with per-
ceived speaker identity; this effect was similar to, but smaller     Methods
than, the N400 seen when processing semantic anomalies.
                                                                     Participants were recruited via Amazon’s Mechanical Turk
   These studies provide compelling evidence that speaker
                                                                     (MT) online survey system, and were directed to a webpage
voice characteristics can affect the processing of the mean-
                                                                     containing an in-house presentation script. After a slide of in-
ings of spoken words. In particular, they suggest that listen-
                                                                     structions, participants clicked through a series of individual
ers use speaker characteristics to generate expectations about
                                                                     pages, one for each prompt word; on each page, they clicked
what words will appear in a sentence. They fall short, how-
                                                                     a button that played the prompt word, and then typed the first
ever, of completely connecting models of acoustically-cued
                                                                     word that came to mind into a text box before continuing
indexical information with psycholinguistic models of se-
                                                                     to the next slide. Each participant heard either speaker J or
mantics, because they do not consider the spread of activation
                                                                     speaker M.
between words. Since associative spread is a crucial part of
semantic models, a more complete synthesis would require             Stimuli Speakers J and M each read a list of 262 words;
evidence that speaker characteristics can not only affect ex-        these words were chosen randomly, with no attempt to choose
pectations about the presence of a word, but can additionally        words that would specifically elicit different semantic asso-
                                                                 1112

ciates (e.g., depending on speaker gender). The stimuli words         choose two new “top associates” for each prompt based on
were a mix of nouns, adjectives, and verbs.                           this split, and compare them to each other to estimate the pro-
Participants 200 subjects with U.S. IP addresses partici-             portion of different top associates. We contrast this with the
pated via MT; 100 subjects heard words produced by speaker            across speaker baseline, where we randomly resample from
J, and 100 heard words by speaker M. 9 sets of results were           both speaker J and speaker M and compare the new “top as-
excluded because subjects did not complete the task (all for          sociates” across speakers. Because agreement on the top as-
speaker J), and 4 subjects were excluded for not being native         sociate increases with the number of subjects in the sample,
speakers of English (1 from speaker J, 3 from speaker M),             we always sample subject groups of 45 (the largest possible
leaving a total of 187 sets of responses (90 to speaker J, 97 to      number, due to the 90 responses to speaker J).
speaker M). The remaining participants had a median age of               After 1000 iterations of random resampling, we find that
31 years and were 55% female (with marginally more women              the across-speaker differences are robustly larger than the
than men responding to speaker J).                                    within-speaker differences. The results are displayed in
                                                                      Figure 1. Across-speaker comparisons yield a difference
Data clean-up Responses were spell-checked via a                      proportion with a mean of 0.283 (σ̂ = 0.022), compared
semi-automated process: a Python script automatically                 to within-speaker means of 0.274 for J (σ̂ = 0.018) and
spellchecked the responses while outputting a log of changes,         0.266 for M (σ̂ = 0.021). The across-speaker difference
then a human annotator reviewed the log and manually fixed            was significantly higher than the within-speaker differences
incorrect changes. Nominal and verbal morphology was re-              (t(1815.0) = 16.05, p < 0.001). There was also a significant
moved using the WordNet stemmer in the NLTK Python                    difference in agreement rates across the within-speaker con-
package (Bird, Klein, & Loper, 2009).                                 ditions (t(1954.4) = 9.9, p < 0.001), with speaker J yielding
                                                                      significantly higher within-speaker disagreement rates than
Results                                                               speaker M. This result is corroborated by a log-log model of
We define the top associate, for a given prompt and a given           target frequency by rank, in which speaker M elicits a higher
speaker, as the response that was given most frequently to that       frequency intercept (at the most common responses to her
prompt spoken by that speaker. Overall, 183 prompts (69.8%)           prompts) than speaker J.
resulted in exactly the same top associate set (including ties
                                                                                                                 ●
for the top associate) for both speakers; 203 prompts (77.5%)
resulted in top associates (or, including ties, sets of top as-                             0.35                 ●
                                                                                                                                    ●
sociates) with at least one response that was the same across                                                                                         ●
                                                                          proportion different responses
                                                                                                                                    ●                 ●
speakers. Thus, 22.5% of prompts resulted in different top
associates, depending on the speaker.
   These differences were difficult to attribute to any one dif-
ference in the speakers’ voices: a small number of the top-
associate differences might be attributable to the different
                                                                            0.25             0.30
speakers’ sexes (e.g., “yeast” in speaker J’s voice yielded the
top associate ”bread”, but in speaker M’s voice yielded “in-
fection”), but most were relatively uninterpretable (e.g., for J
and M, respectively: “question” yielded “answer”/“mark”).                                                        ●
                                                                                                                                    ●
                                                                                                                                    ●
                                                                                                                                    ●
Further research into responses that differ across sex, age,                                                     ●
dialect region, and other characteristics would be welcome;                                 0.20
however, to avoid speculation about the particular differences,                                            between−spkrs        J (within)        M (within)
and to determine whether the responses were truly speaker-                                                      between− or within−speaker sampling type
dependent, we analyzed the results at a more general level by
randomly resampling responses.                                        Figure 1: Proportion of different top associates in three types
Random resampling of responses The observation that                   of random resampling: between-speakers, within-speaker
22.5% of prompt words resulted in a different top associate,          (speaker J), and within-speaker (speaker M). The between-
depending on the speaker, is not meaningful without a basis           speakers condition yields higher disagreement on top asso-
for comparison: is this proportion greater than the proportion        ciates than either within-speaker condition.
of responses that would differ within a single speaker, sim-
ply due to random variation in the response frequencies? We
estimate a baseline difference proportion by randomly resam-          Discussion
pling from our observed response distributions, both within-          The results of this experiment suggest that there are seman-
and between-speakers. For the within-speaker baselines, we            tic associations that are differentially cued by speaker-specific
take all of the responses to a given speaker and randomly             phonetics. When responses to a set of prompt words are com-
split them in half (or approximately in half; see below); we          pared across speakers, there is significantly more disagree-
                                                                   1113

ment (in terms of the most common response) than when re-            (prime; J target; M target) were created based on the criteria
sponses are compared within each individual speaker.                 above. The design was within-subject with two experimental
   An unexpected result is that there is more agreement on           conditions (VoiceMatch and VoiceMismatch) and two speak-
“what first comes to mind” when a prompt word is spoken by           ers (J and M); Depending on the trial, listeners heard a prime
speaker M, relative to when it is spoken by speaker J: The ran-      spoken by J and responded to a target that was a top response
dom resampling analysis indicates that, across prompt words,         to J (J-VoiceMatch) or to M (J-VoiceMismatch); or they heard
responses to speaker M exhibit fewer differences in what con-        a prime spoken by M and responded to a target that was a
stitutes the most frequent response; listeners are more likely       top response to J (M-VoiceMismatch) or M (M-VoiceMatch).
to give the same response to speaker M’s prompts, while re-          Four counterbalanced lists were created to ensure that each
sponses to speaker J’s prompts are more varied.                      target was preceded by a prime in each voice, with no sub-
                                                                     ject responding to any prime or target more than once. Each
                        Experiment 2                                 list of twenty-four critical items was augmented with twenty-
The results from Experiment 1 support the hypothesis that            four unrelated (control) pairs, and forty-eight non-word tar-
speaker-specific information influences semantic interpreta-         gets preceded by a real-word prime.
tion, at least in self-reports of what words first came to lis-
                                                                     Procedure Participants were run individually or in groups
teners’ minds. The response frequencies derived from this
                                                                     of 2-3 in a sound-attenuated booth. Each trial consisted of
type of free association task are typically thought to be (or,
                                                                     an auditory prime, a 100ms ISI, and a visual target. Listen-
at least, to be related to) the strength of association between
                                                                     ers were instructed to decide whether the visual target was a
words in the mental lexicon. If this is the case, we would ex-
                                                                     word or pseudoword by pressing the correspondingly labeled
pect to find evidence for speaker-specific associations in an
                                                                     response button.
online task sensitive to meaning.
   In this experiment, we investigate listener reactions to tar-     Results
gets when preceded by primes, based on the top associate
results found in Experiment 1. We augment this standard              Reaction times below 300ms and above 1101 milliseconds
cross-modal semantic priming task with our factor of inter-          (the latter equal to two standard deviations above mean log
est: the spoken primes are produced by both of the speakers,         reaction time) were excluded from all analyses. Initially, log-
and the targets are the speaker-specific responses that were         transformed reaction times were subjected to mixed-effects
observed in Experiment 1. In other words, we compare lis-            linear regression with main effects of condition (VoiceMatch
teners’ reaction times, in a lexical decision task, to the tar-      v. VoiceMismatch) and speaker (J v. M) and the interaction
get “infection” when preceded by the prime “yeast” produced          of condition and speaker; we included a random intercept of
either by speaker M (speaker match) or speaker J (speaker            prime word, and a random slope of condition. The results
mismatch); we similarly compare reaction times to the target         of this model were inconclusive: with the exception of the
“bread” when primed by “yeast” spoken by M (mismatch) or             intercept, all t-values were less than 1.0; we therefore cannot
J (match).                                                           reject the null hypothesis that the VoiceMatch condition and
   It is important to note that, unlike typical semantic priming     the VoiceMismatch condition produce categorically different
studies which compare related and unrelated primes, we are           priming effects.
comparing two related primes across speakers. We expect re-             Two factors led us to consider a second analysis. First, our
latedness priming as a baseline, but additionally predict that       Experiment 1 found a difference in the associative strength of
priming is affected by the association strength (operational-        top targets between speakers J and M; we may see a similar
ized as the response frequency from Experiment 1) that is            speaker-specific response effect in the lexical decision task.
specific to the speaker of the prime.                                Second, and more importantly, each target word was asso-
                                                                     ciated with its prime to some degree, even in the VoiceMis-
Methods                                                              match condition where the target was not the most highly as-
Participants 48 monolingual speakers of American En-                 sociated word given that prime and that speaker. In a meta-
glish participated in this study for pay. The participants were      review of semantic priming experiments, Lucas (2000) sug-
all undergraduate students. None reported hearing-related is-        gests that strength and type of word association can affect
sues.                                                                priming; we therefore want to consider association strength
                                                                     as a continuous measure, and determine whether it has a
Stimuli We chose our prime-target stimuli from the results
                                                                     speaker-specific effect on reaction time.
of Experiment 1, using two criteria: (1) the prime (prompt)
                                                                        To account for these two factors, we split our data based
yielded different top associate responses, depending on the
                                                                     on speaker: one data set (553 trials) contained responses to
speaker, and (2) the top associate was given as a response to
                                                                     targets preceded by speaker J, and the other (548 trials) con-
the prompt by at least 20% of the participants in Experiment
                                                                     tained responses to targets preceded by speaker M. We fit two
1.
                                                                     separate models to each data set: one in which log reaction
Design We used a cross-modal auditory-visual semantic                time is predicted by the strength of the prime/target associa-
priming paradigm. Twenty-four critical prime-target triplets         tion in speaker J’s voice, and one in which log reaction time
                                                                 1114

is predicted by the strength of the prime/target association in                                                J strength
speaker M’s voice. We predict a gradient effect of speaker-                            6.40
specific association strength: J’s association strength should
linearly improve reaction times to targets following primes                            6.30
spoken by J, and M’s association strength should linearly
                                                                              log RT
improve reaction times to targets following primes spoken
                                                                                       6.20
by M. We crucially predict that, despite the correlation be-
tween prime/target association strengths across speakers (as
                                                                                       6.10
calculated by the response frequencies from Experiment 1),
we should not observe M’s association strength affecting re-                                  0.0     0.1     0.2         0.3      0.4   0.5
sponses to J, or J’s association strength affected responses to                                             associative strength
M.                                                                                                            M strength
    All models include the maximal random effects, including                           6.40
a random intercept of target and random slopes of associa-
tion strength (of either one or both speakers, depending on                            6.30
model) by subject; random slopes of target are not justified                  log RT
because each target has only one strength value per speaker.                           6.20
Due to the moderate correlation of association strength across
speakers (Pearson’s r = 0.54, T (1099) = 21.5, p < 0.001)
                                                                                       6.10
model comparison was conducted using R’s anova() func-
tion: models containing only effects of one speaker’s associ-                                 0.0     0.1     0.2         0.3      0.4   0.5
                                                                                                            associative strength
ation strength were compared to a full interactive model of
both speakers’ association strength (with the interaction jus-
tified by that model’s better fit compared to a non-interactive     Figure 2: Partial effects of J’s association strength (top) and
model, χ2 (1) = 4.71, p = 0.03).                                    M’s association strength (bottom) on log reaction times when
    For the speaker J dataset, the model fitting log reaction       primes were spoken in M’s voice.
time to J’s prime/target association strength resulted in a log-
likelihood of 101.15, and the model fitting log reaction time
to M’s association strength resulted in a log-likelihood of         We did not observe the expected categorical effect of voice
101.97; the full model resulted in a log-likelihood of 101.55.      matching: listeners responded just as quickly to associated
When compared to the partial models, the full model did not         prime/target pairs regardless of the specific speaker.
perform any better (full v. J: χ2 (2) = 0.78, p = 0.67; full v.        Because of the qualitatively different responses to speak-
M: χ2 (2) = 0, p = 1), indicating that neither speaker’s asso-      ers J and M that we found in Experiment 1, and because of
ciation strength contributed anything more than the other’s.        the gradient differences in prime/target association strength
    For the speaker M dataset, the model fitting log reaction       across speakers, we fit two sets of gradient models: one in
time to J’s prime/target association strength resulted in a         which each speaker’s association strength was used to pre-
log-likelihood of 97.157, and the model fitting log reaction        dict reaction times following primes spoken by J, and one
time to M’s association strength resulted in a log-likelihood       in which each speaker’s association strength predicted reac-
of 98.753; the full model resulted in a log-likelihood of           tion times following primes spoken by M. We observed that
101.108. When compared to the partial model of M’s asso-            speaker-specific association strength significantly improved
ciation strength, the full model did not perform significantly      within-speaker reaction times, but only for speaker M; no
better (full v. M: χ2 (2) = 4.9, p < 0.1); however, when com-       model suggested a gradient effect of association strength to
pared to the partial model of J’s association strength, the full    speaker J’s voice.
model provided a significant increase in log-likelihood (full
v. J: χ2 (2) = 7.9, p = 0.02), indicating that adding the partial                                   General Discussion
effects of M’s association strength improves the model con-         The goal of this paper was to determine whether speaker-
taining only the effects of J’s association strength. The partial   specific phonetic cues affect the interpretation of spoken
effects of J’s and M’s association strengths on reaction times      words. In two different experiments, we establish that lis-
to M’s voice are displayed in Figure 2.                             teners respond to spoken words in speaker-specific ways: in
                                                                    the first experiment, the most common responses to spoken
Discussion                                                          words differed across-speakers to a greater extent than ex-
This experiment tested whether listeners responded more             pected; in the second experiment, listeners responded to one
quickly to target words when the targets were preceded by           of our speakers in a way that depended only on that speaker’s
a spoken prime when the prime/target pair was the most              specific association strengths from the first experiment. We
strongly associated pair for that particular speaker, as com-       thus found robust effects of speaker-specific word associa-
pared to when the prime was spoken by a different speaker.          tions in both off-line (free association) and on-line (semantic
                                                                1115

priming) tasks.                                                        Bradlow, A. R., Nygaard, L. C., & Pisoni, D. B. (1999). Ef-
   Our two speakers differ along many dimensions that are                fects of talker, rate, and amplitude variation on recognition
cued by phonetic details in speech – including age, race,                memory for spoken words. Perception & psychophysics,
gender, and dialect background – making it difficult to in-              61(2), 206–19.
terpret the variety of speaker-specific semantic differences           Bybee, J. L. (2006). From Usage to Grammar: The Mind’s
we found. One particularly odd effect, consistent across                 Response to Repetition. Language, 82(4), 711–733.
our experiments, is the asymmetry between our two speak-               Creel, S. C., & Tumlin, M. A. (2011). On-line acoustic and
ers. In the first experiment, speaker M’s voice prompted                 semantic interpretation of talker information. Journal of
significantly more agreement in the composition of top re-               Memory and Language, 65(3), 264–285.
sponses than did speaker J’s voice; listeners were more likely         Geiselman, R. E., & Bellezza, F. S. (1976). Long-term mem-
to give the same response to prompts spoken by M, and gave               ory for speaker’s voice and source location. Memory &
more varied responses to prompts spoken by J. We suggest                 Cognition, 4(5), 483–9.
that this difference – particularly the possibility that listeners     Goldinger, S. D. (1996). Words and voices: episodic traces in
have fewer unique word associations, and thus fewer seman-               spoken word identification and recognition memory. Jour-
tic competitors, to words spoken by M – explains why asso-               nal of Experimental Psychology: Learning, Memory, and
ciation strength played a role in Experiment 2 only for words            Cognition, 22(5), 1166–83.
spoken by M.                                                           Hay, J., & Drager, K. (2010). Stuffed toys and speech per-
   A potential explanation for this asymmetry is that our sub-           ception. Linguistics, 48(4).
jects may have more experience with the voice characteris-             Johnson, K. (2006). Resonance in an exemplar-based lexicon:
tics of M – a younger, white, woman – than with those of J –             The emergence of social identity and phonology. Journal
an older, African-American, man; this additional experience              of Phonetics, 34(4), 485–499.
with voices like M’s would lead to more robust activation of           Johnson, K., Strand, E. A., & D’Imperio, M. (1999).
lexical items and thus to greater priming in M’s voice. This             Auditory–visual integration of talker gender in vowel per-
interpretation, however, cannot be verified without additional           ception. Journal of Phonetics, 27(4), 359–384.
research into how characteristics such as age, race, and gen-          Lucas, M. (2000). Semantic priming without association:
der affect listeners’ reactions to these speakers, and a much            a meta-analytic review. Psychonomic Bulletin & Review,
closer look at how these social characteristics relate to the            7(4), 618–30.
free responses to M and J. Future work will investigate these          Meyer, D., & Schvaneveldt, R. (1971). Facilitation in Recog-
characteristics and their effects on word associations in order          nizing Pairs of Words : Evidence of a Dependence Between
to better understand the free response results and the cross-            Retrieval Operations. Journal of experimental psychology,
task asymmetry between our two speakers.                                 90(2), 227–234.
   Our experiments provide evidence for a role of speaker-             Nelson, D. L., McEvoy, C. L., & Dennis, S. (2000). What
specific phonetic information in semantic interpretation.                is free association and what does it measure? Memory &
Across two experiments, single words robustly prompt dif-                cognition, 28(6), 887–99.
ferent word associations depending on speaker; this interac-           Niedzielski, N. (1999). The effect of social information on
tion cannot be accounted for by standard accounts of seman-              the perception of sociolinguistic variables. Journal of Lan-
tic priming (which could handle word associations) or stan-              guage and Social Psychology, 18(1), 62–85.
dard exemplar-based accounts (which could handle speaker               Radeau, M. (1983). Semantic priming between spoken
specific effects for individual words). These results require            words in adults and children. Canadian Journal of Psy-
a model of spoken word recognition which explicitly incor-               chology/Revue canadienne . . . , 37(4), 547–556.
porates social information (as encoded by speaker-specific             Schacter, D., & Church, B. (1992). Auditory priming: Im-
acoustic cues) and linguistic information (including seman-              plicit and explicit memory for words and voices. Journal
tic relatedness); a model like that of Sumner, Kim, King, and            of Experimental Psychology: Learning, Memory, and Cog-
McGowan (2014), for example, provides a framework for un-                nition, 18(5), 915–930.
derstanding how these two sources of information can interact          Sumner, M., Kim, S. K., King, E., & McGowan, K. B. (2014).
in spoken word recognition.                                              The socially weighted encoding of spoken words: a dual-
                                                                         route approach to speech perception. Frontiers in Psychol-
                         References                                      ogy, 4(January), 1–13.
                                                                       Van Berkum, J., van den Brink, D., Tesink, C., Kos, M., &
Battig, W., & Montague, W. (1969). Category norms of ver-                Hagoort, P. (2008). The neural integration of speaker and
   bal items in 56 categories A replication and extension of             message. Journal of Cognitive Neuroscience, 20(4), 580–
   the Connecticut category norms. Journal of Experimental               91.
   Psychology, 80(3).
Bird, S., Klein, E., & Loper, E. (2009). Natural language
   processing with python: Analyzing text with the natural
   language toolkit. O’Reilly Media.
                                                                   1116

