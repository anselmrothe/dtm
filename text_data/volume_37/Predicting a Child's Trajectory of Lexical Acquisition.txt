                          Predicting a Child’s Trajectory of Lexical Acquisition
                                          Nicole Beckage (nicole.beckage@colorado.edu)
                                        Department of Computer Science, University of Colorado
                                                           Boulder, CO 80309 USA
                                               Michael Mozer (mozer@colorado.edu)
                                        Department of Computer Science, University of Colorado
                                                           Boulder, CO 80309 USA
                                         Eliana Colunga (eliana.colunga@colorado.edu)
                                  Department of Psychology and Neuroscience, University of Colorado
                                                           Boulder, CO 80309 USA
                              Abstract                                   top frame, shows an example of the CDI norms. These norms
   How does a child’s vocabulary production change over time?            are typically used to assess a child’s vocabulary in relation to
   Past research has often focused on characterizing population          her peers, as quantified by a CDI percentile for a given age
   statistics of vocabulary growth. In this work, we develop             and vocabulary size. However, the CDI population statistics
   models that attempt to predict when a specific word will be
   learned by a particular child. The models are based on two            can extended as a means to predict an individual’s learning of
   qualitatively different sources of information: a representa-         a given word at a given age.
   tion describing the child (age, sex, and quantifiers of vocabu-
   lary skill) and a representation describing the specific words a                          month 16    month 17    ...   month 29
   child knows. Using longitudinal data from children aged 15-36                  airplane     38.5         39.4     ...     95.0
   months collected at the University of Colorado, we constructed                 light        35.9         30.3     ...     90.0
   logistic regression models to predict each month whether a                     zoo           9.0         9.1      ...     66.7
   word would be learned in the coming month. Models based
   on either the child representation or the word representation                      age   sex    ...   voc. sz  dog    house    ...  zoo
   outperform a baseline model that utilizes population acquisi-                     16.2    F     ...     32      0       0      ...   0
   tion norms. Although the child- and word-representation mod-            kid A     17.1    F     ...     49      1       0      ...   0
   els perform comparably, an ensemble that averages the predic-                     18.9    F     ...    132      1       0      ...   1
   tions of the two separate models obtains significantly higher
   accuracy, indicating that the two sources of information are                      19.3    M     ...    257      1       0      ...   0
   complementary. Through the exploration of such models, we               kid B     20.5    M     ...    345      1       1      ...   0
   gain an understanding of the factors that influence language
   learning, and this understanding should inform cognitive the-         Figure 1: Example of normed CDI entries (top) and longitu-
   ories of development. On a practical level, these models may          dinal CDI data for sample children (bottom).
   support the development of interventions to boost language ac-
   quisition.
   Keywords: Language acquisition; word learning; lexical ac-               The accuracy of these predictions for any individual de-
   quisition                                                             pends on the nature of variability within the population. Any
                                                                         prediction model based on normed data assumes that children
                           Introduction                                  learn in a fundamentally similar fashion to one another. For
How does a child’s current vocabulary inform and relate to               example, implicit in a prediction model based on normed data
their vocabulary in the future? We know that deficits in a               is that late talkers (children below the 20th CDI percentile for
child’s early lexicon is a predictor of future language skills           vocabulary size given their age) have the same vocabulary
(Dale et al., 2003). Potentially, if researchers can recommend           trends as early talkers (children above the 80th percentile).
words that the child is ready and able to learn, early learning          The aggregation essentially suggests that these late talkers do
deficits might be corrected. However, reliable prediction can            not learn words in a different order, just that they learn words
be made only if word learning develops in a systematic way.              later. This suggestion has been directly examined and shown
In this paper, we explore whether there are regularities in the          to be false: typical and late talkers learn not only at different
growth of a child’s vocabulary that allow the trajectory of an           rates but they learn different lexical items (e.g., Beckage et
individual’s learning to be predicted.                                   al., 2011). More generally, limitations of the norms have been
   One source of information that can be used to model vocab-            noted by many researchers. For example, the norms don’t
ulary acquisition is population-level norms. The most com-               generalize to all populations (e.g., Arriaga et al., 1998; Thal
prehensive study (Dale & Fenson, 1996) collected productive              et al., 1999) and the norms mask idiosyncrasies in an individ-
vocabulary for over 1130 children between the ages of 16 and             ual’s learning (e.g., Mayor & Plunkett, 2011).
30 months, based on parent reports on 649 words. Summary                    Despite their shortcomings, the CDI norms may be useful
statistics from this communicative development inventory or              for characterizing an individual child’s lexical growth. In this
CDI, describe norms of acquisition. For example, 78.7% of                paper, we compare predictions based on the CDI norms with
children produce the word dog by age 18 months. Figure 1                 predictions based on child-specific sources of information. In
                                                                     196

                                     Child-level features:
                                    Child-level features:
                                     colored by age(mon.)                                      The content of the child’s vocabulary may reflect the language
                       100          colored by age(mon.)                                       learning environment, the child’s interests and possibly learn-
                      100                                          30                          ing strategies that the child has. Consequently, the words
                        80                                         30                          known by the child may be predictive of which words they
                       80
                                                                        age (in month)
                                                                   25                          learn next; co-occurrence of words in a child’s vocabulary in-
      percentile
                        60
                                                                   25                          creases predictability of future language learning above and
         percentile
                       60
                        40                                         20                          beyond the normed age of acquisition data (Beckage & Col-
                       40                                          20                          unga, 2013). Work also suggest that there is a strong relation-
                        20
                       20
                                                                   15                          ship between what words a child will learn and the language
                                                                   15                          learning environment of the child (Weizman & Snow, 2001)
                            0
                        0       0    100 200 300 400 500 600 700                               and their specific interests (DeLoache et al., 2007). These as-
                                0   100 200 300 400 500 600 700
                                         vocabulary size                                       pects of learning may be better captured by the content of the
                                        vocabulary size                                        child’s vocabulary than by features related to the child’s age
Figure 2: Graphical representation of the child-level features.                                and vocabulary size.
x-axis is vocabulary size, y-axis percentile. The color of the                                    In this article, we compare models that utilize child fea-
data points is related to the age of the child with darker point                               tures and/or word features to predict the learning of individ-
indicating older children.                                                                     ual words over a time window of roughly a month. That is,
                                                                                               we use information about the child and the child’s vocabulary
the case of the normed model, we consider two instantiations,                                  at time t to predict whether an individual word not known
one aggregated across both male and female children and one                                    at time t will be learned by time t + ∆t. (Ideally, observa-
based on the norms for males and females separately. For                                       tions are a month apart, but as we explain in the methodol-
the child-specific information sources, we specifically have                                   ogy section, ∆t varies across observations.) We build logis-
two sources of information at our disposal from a data set                                     tic regression models for each word individually and include
we’ll describe in detail shortly. First, we have child features:                               features related to the child and/or to the vocabulary of the
the child’s age, sex, vocabulary size, and language skill as                                   child. We discuss the modeling assumptions in detail below
estimated by CDI percentile. Figure 2 visualizes three of                                      but to summarize, we compare performance of logistic re-
these features in relation to one another. Second, we have                                     gression models to models based on the age of acquisition
the specific productive vocabulary of a child at a particular                                  data. The performance of the logistic regression models, with
moment of time, as assessed by parent report; we character-                                    child- and/or word- features, helps us understand the features
ize the vocabulary as a binary vector of word features indi-                                   relevant to predicting the learning of individual words, in-
cating whether or not a word is known. These two sources                                       forming our models of lexical acquisition in young children.
of information come from longitudinal studies. Figure 1 bot-
tom frame shows examples of specific children’s vocabulary                                                           Methodology
trajectories.
   We test two hypotheses. First, are child- and word-features                                 Vocabulary Data
as useful as the population acquisition norms for predicting                                   We use data collected as part of a 12-month longitudinal study
whether a specific word will be learned by a child in a certain                                in Dr. Colunga’s Lab at the University of Colorado Boul-
window of time? Second, do the child- and word-features                                        der. The data were collected over three recruitment phases in
provide redundant information, or can the two qualitatively                                    which parents and children came to the lab for recurrent vis-
different sources combine to yield greater predictive power                                    its over 12 consecutive months. Visits were timed at nearly
than either individually?                                                                      monthly intervals and, on average, we have 9 visits for each
   The child-language literature suggests that information                                     child. Overall, we include 112 monolingual children. At each
about an individual learner may be useful in predicting the                                    visit, parents completed a vocabulary report. The parental
learning of unknown words. For example, the sex of the child                                   vocabulary report was collected using the MacArthur-Bates
is a significant factor in language development as vocabulary                                  Communicative Development Inventory (CDI, Dale & Fen-
size and the sex of the child are correlated: females have                                     son, 1996) and included commonly used, early learned En-
larger vocabularies on average than their age-matched male                                     glish words. Across all recruitment phases, we have a total of
peers (Fenson et al., 1994). Clearly, age is a critical feature                                996 CDI snapshots of children’s’ vocabulary knowledge.
as well: certain words are more likely to be learned earlier                                      The study represents many different types of language
than others. The CDI percentile, which is formed by combin-                                    learners with the age of the children in the study ranging
ing information about the child’s age and vocabulary size as                                   from 15.3 months to 33 months. The median age of a child
compared to peers, is itself useful for predicting the specific                                across all the CDIs is 22 months. We also have a full range
words a child knows (Beckage & Colunga, 2013). Thus, we                                        in language ability represented as well. To approximate lan-
find justification for predicting word learning using the child                                guage ability, we utilize the CDI percentile which is calcu-
features of age, sex, vocabulary size, and CDI percentile.                                     lated based on the size of the child’s vocabulary as compared
   Nonetheless, these child features don’t tell the whole story.                               to their age matched peers. The range of the CDI percentile
                                                                                         197

represented in the CDI vocabulary snapshots was between 0              models. The training and test sets are created by selecting all
and 99, with a median percentile of 54. We should note that            children who do not know the target at the beginning of the
recruitment of participants in the longitudinal study was bi-          study. We then place 80% of the children in the training set
ased to over-represent late-talkers as late-talkers are a popu-        and the remaining 20% in the test set. Because the number of
lation of particular interest in language acquisition.                 children who initially know a word varies across words, the
   Of the 680 words on the full CDI, 649 of these words are            training and test set is created uniquely for each target.
normed and exactly match the words in the CDI snapshots.                  We evaluate each alternative model for each target via the
These 649 words are the words we use to represent an indi-             log-likelihood and with the ROC area under the curve (AUC)
vidual child’s vocabulary in this study. As part of these 649          metric applied to the test set. Both measures weight each
words, all types of word classes are represented. The most             prediction equally, and thus later learning children play more
common are concrete nouns (dog, chair, etc.) followed by               heavily into the measure. To obtain a single measure of per-
action verbs (drink, run, etc.) as well as connecting words,           formance for each alternative model, we sum log-likelihoods
descriptive words and words about time and routine. Because            or combine ROC curves over all 649 target words. To deter-
of the variation in the type of words as well as the baseline          mine the reliability of difference between alternative models
knowledge of a word (both in the norms and our observed                across targets, we compute a paired t-test treating target as the
data) we construct an independent logistic regression model            random variable.
for each word. We utilize different information from each
CDI snapshot as the input to our model and predict acqui-              Baseline Normed Acquisition Model
sition forward to the next CDI–capturing the probability of            We constructed baseline normed models utilizing published
learning a specific word in approximately one month’s time.            CDI statistics that indicate the normative age of acquisition
Though we model each word individually, we are not inter-              (Dale & Fenson, 1996). These norms are based on 1130 CDIs
ested in performance across different types of words so we             collected for children between the ages of 16 and 30 months.
consider the performance of a model to be based on the fea-            In the Dale study, the CDIs are binned by age (rounded to
tures included in training across all types of words–that is to        the nearest month) and then the percentage of children who
say a model refers to the features included in training, not the       were reported to produce a specific word is calculated. We
specific word we train on.                                             use these values, for each word, for each month, to estimate
                                                                       the probability of learning a currently unknown word. In
Model Construction and Evaluation                                      the first normed model, only one feature is used for predic-
We construct separate models for each target word. To gen-             tion: the age of the child. Because the norms exist only for
erate training and test sets for each target, we use the snap-         children between 16 and 30 months and the children in our
shots from all children up to and including the point in time at       study are occasionally younger or older, we establish bound-
which the child transitions from not knowing to knowing the            ary conditions–for children over 30 months age or younger
target. (We use the terms ’know’ and ’learn’ loosely; the CDI          than 16 months, we use either the 30 month or 16 month
snapshots are in fact a parent’s report of a child’s productive        norms. We also consider the norms separately for male and
vocabulary, however, we hope they capture something about              female children. This allows for a more informed baseline
learning and the acquisition process.) The point of transition         model since age and the sex of the child are features in the
can vary from one child to the next as well as one target to           model. However, the number input CDIs used to construct
the next. For example, one child may show initial learning of          the norms separately for male and female children are fewer
the word ’dog’ at month 18, and if CDIs are available for that         and thus may be more subject to population level fluctuations
child for the preceding months 15, 16, and 17, then that child         that are not informative in prediction.
will provide 3 separate snapshots (predicting to month 16, 17             The CDI norms are not predictive in nature. They simply
and 18) from which model training and testing is performed,            report population level acquisition rates. However, we can
2 of which involve a prediction of not knowing the target and          use the acquisition data captured by these norms for predic-
one of which involves knowing the target.                              tion. We must first transform the norms from a probability of
   We explore a set of alternative models for each target word,        knowing a word at a given age (and sex) to the probability of
as we will describe. The models take as input a representa-            learning a currently unknown word at a given age. The dif-
tion of a child’s snapshot at some time t, and predict whether         ference between the CDI norms at month m and month m − 1
or not the target is known at the next snapshot, collected at          might seem like a measure of learning, but the difference is
t + ∆t. Specifically, the model outputs the probability of tar-        occasionally negative (due to the fact that the data used to
get acquisition at t + ∆t. In all cases of training and test, the      construct the norms are cross-sectional: the children in the
target is not known at t. We make predictions conditional on           16 month group are not the same children as in the 17 month
the target not being known because once a target is learned            group). To ensure monotonicity of the normed model, we
it remains known, and one can trivially use the conditional            smooth out negative differences by replacing them with the
models we develop to make unconditional predictions.                   rate of vocabulary change over the minimum time span that
   For each target, the full data set is split into training and       yields a positive rate of change.
test sets, and the same split is held constant for all alternative        Because the CDI norms are binned by months and we may
                                                                   198

                                                                    Table 1: Performance of the normed, child-feature and word-
be required to make a prediction for a child at age t + ∆t          feature models.
which may lie between two months, linear interpolation on
                                                                                        llk train    llk test   AUC     % best fit
the smoothed differences of the CDI norms is performed.                   norms         -123076     -30849      .588      1.39
                                                                          norms(m/f)    -123813     -31135      .563      1.39
Logistic Regression Models                                                child          -84698     -22774      .812      67.02
We use lasso regression, a penalized (L1-regularized) logistic            word           -65703     -24059      .801      30.20
regression model that performs feature selection to exclude         the best for each word. Column 5 of Table 1 indicates
(set coefficients to zero) features that do not meaningfully        the percentage of words for which a given model outper-
contribute to the prediction. In principle, lasso regression        forms the others using log-likelihood as the evaluation met-
serves to regularize a model; that is, it attempts to prevent       ric. Consistent with the log-likelihood results, both child- and
overfitting by reducing the number of nonzero coefficients in       word-feature models outperform both normed models, and
the model. We perform lasso regression in R using the li-           the child-feature model outperforms the word-feature model.
brary glmnet (Friedman et al., 2010), which internally per-
                                                                       Because lasso regression discards input features it deems
forms cross-validation using the training data to select the
                                                                    to be irrelevant, we use the presence or absence of a feature
regularization parameter, and the remainder of the data are
                                                                    as a proxy for importance. Since a model is trained indepen-
used to determine model coefficients.
                                                                    dently for each predicted word, we determine the percentage
    We develop a set of alternative logistic regression models
                                                                    of models that include a particular child-feature to measure
that differ in the features provided as input. The two sets
                                                                    the importance of a feature. The child-feature models have an
of features we consider are child features and word features.
                                                                    average of 4.7 parameters, and range from having 1 parameter
The child features are: the sex of the child, the number of
                                                                    (the intercept) to 7 (all child features plus intercept). Across
words spoken by the child, the CDI percentile, and the age
                                                                    child-feature models, 64.1% included the child’s sex, 64.1%
of the child at snapshot t. We include two additional features
                                                                    included either age or age-at-prediction, but only 22.8% in-
pertaining to the child: ∆t and the session (visit) number. The
                                                                    cluded both, suggesting that the time between visits is less
reason for including ∆t is that the time between snapshots is
                                                                    important than the general age of the child. The session visit
designed to be one month, but this desideratum is not always
                                                                    appears significant in nearly 60% of models. Most important
satisfied and the variation of ∆t may be useful for prediction.
                                                                    to the child-feature model are percentile and total vocabulary
We include the session number to capture how long into the
                                                                    size. Percentile is present in in 87.1% and total vocabulary
12 month longitudinal study the child is. We have found that
                                                                    size at time t appears in 73.1% of the models respectively.
the child’s participation in this longitudinal study positively
affects their vocabulary growth and influences their vocabu-           For the word-feature model, the number of parameters
lary size and percentile, thus this child-level feature may af-     could range from 1 (intercept) to 650 (each of the 649 words
fect our ability to predict the acquisition of words.               plus the intercept). The actual range based on the model fit
    Turning to the word-level features, we construct an indica-     for each word was between 1 and 83 features with an average
tor vector with one element per word. The ith element of the        of 31 features. Since only a subset of the 649 words ended
vector is set to 0 or 1 depending on whether the parent reports     up in the logistic regression models we can conclude that a
that the child can produce word i at snapshot t.                    localized representation was at least as useful in predicting
                                                                    acquisition than the full vocabulary. Of the features included
                            Results                                 in the model, 83% had a positive weight indicating an in-
We first compare performance of the normed models, the              creased probability of learning the target word if the word
child-feature model, and word-feature model (Table 1). The          was known. We hope to investigate the relationships between
performance is assessed via log-likelihood where values             individual words, as well as why some of the coefficients in
closer to zero are better and ROC area under the curve (AUC)        the model were negative in future work.
where values closer to 1 are better. As expected, the fit to           We can conclusively say that both the child and word fea-
the training set (column 2) is related to the complexity of         tures outperform the models based on the acquisition norms.
the model. The model with the most free parameters, the             We can also conclude that the set of child features outperform
word-feature model, best fit the training data. However, on         the word-vector features. To see how much of the increase in
the test set (column 3, llk; column 4, AUC), this model did         performance of the child features over the word features was
not perform as well as the child-feature model, due to over-        due to overfitting of the word-feature model, we perform a
fitting of the training set. Nonetheless, both the child- and       dimensionality reduction on the word features. We perform
word-feature models outperform the normed models (using a           principal component analysis on all 996 vocabularies, regard-
paired two-tailed t-test comparing to the normed model that         less of whether a specific vocabulary is in the training or test
considers only the child’s age, child t(649)=44.71, p <.001;        set. We use the first 18 components of the PCA reduction as
word t(648)=30.62, p <.001).                                        determined by viewing a Scree plot of the components. We
    The log-likelihood score and AUC score combine perfor-          then take the binary vocabulary vector of a child at a particu-
mance across individual words. We can also examine which            lar point in time and project it it into the principal components
of the models–normed, child-, and word-feature–performs             space. This is done for each snapshot resulting in a vector of
                                                                199

                                   Reduced word-level features:                                                         Table 2: Performance of the logistic regression models with
                                   colored by
                                   Reduced    knowledge
                                            word-level    in CDI
                                                       features:                                                        different features.
                                   colored by knowledge in CDI
                           0.05                                                                                                            total llk   AUC    pos. param   # params
                                                                                  # of CDIs where word is known
                                                                            800
                           0.05                                             800                                           child            -22774      .812        7         4.70
         PCA
       PCA    component
           component 2 2
                                                                                                                          word             -24059      .801      650         31.20
                                                                            600
                           0.00                                                                                           redux-word       -22654      .810       19         8.39
                                                                            600                                           redux-w+child    -22848      .803       25         9.72
                           0.00
                                                                            400
                                                                                                                          ensemble         -22263      .816       26          13
                           -0.05                                            400
                                                                                                                        that lasso regression, while designed to minimize overfitting
                           -0.05
                                                                            200                                         via weight penalties, is not infallible. Any model trained on
                                                                            200
                                                                                                                        finite data and a large number of input variables is likely to
                                    -0.05   -0.04   -0.03   -0.02   -0.01                                               overfit. As a means of avoiding this overfitting, we explored
                                    -0.05   -0.04
                                             PCA -0.03 -0.021
                                                component           -0.01                                               an alternative means of combining the child features and the
                                            PCA component 1                                                             reduced-word features into a single model: by constructing
Figure 3: Graphical representation of two of the reduced word                                                           an ensemble that consists of the two individual (pretrained)
features. The value of each word along the first (x-axis) and                                                           models.
second (y-axis) principal components is plotted. Each word is                                                              Our ensemble simply averages the predictions of the child
colored based on the number of CDI reports where the word                                                               model and the reduced word-feature model. This ensemble
is known.                                                                                                               significantly outperforms the other models, with a lower total
                                                                                                                        likelihood value and higher AUC value (see Table 2 last row).
18 features, representing each child’s vocabulary snapshot in                                                           We confirm this improvement in a paired t-test, comparing to
a reduced dimensionality. With figure 3 we visualize what                                                               both the child model (t(649)=9.96, p <.001) and the reduced
word-specific features are part of the reduced word model.                                                              word-feature model (t(648)=9.52, p <.001). The improve-
We plot the projection of each word onto the first two prin-                                                            ment of the ensemble model over the independent child- and
cipal components. The coloring of each word indicates the                                                               word-feature models suggests that both sources of informa-
number of CDI snapshots where the word is known. Here                                                                   tion are contributing some amount of independent informa-
we can see that the first two components capture the overall                                                            tion that improves prediction.
frequency that the word is known across all CDIs.
   Utilizing this reduced representation of the vocabulary data                                                                                Conclusions
(redux-word), we now find that the total likelihood of this                                                             Our results show that models can predict the acquisition of
model is less than the child-feature model. We compare pre-                                                             a particular target word by a specific child. In contrast, past
diction performance of the reduced word model to the child-                                                             research has primarily focused on characterizing general pop-
feature model and a model that contains both the child and                                                              ulation trends in vocabulary growth. We find that two qual-
reduced word features. Column 2 of Table 2 shows the total                                                              itatively different sources of information are useful for pre-
log-likelihood (llk) and column 3 shows the ROC area under                                                              diction: features that describe the child (such as age, sex and
the curve value for the models based on child features, word                                                            total vocabulary size) and features that specify the vocabulary
features, reduced-word features (redux-word), and both re-                                                              content. Models based on either child- or word-features out-
duced word and child features. Referring back to Table 1, we                                                            perform the traditional age-of-acquisition norms in predicting
confirm that all of these models outperform the models based                                                            whether a specific word will be learned by a specific child.
on the CDI production norms. The number of free param-                                                                     We investigated which of the child features were most use-
eters (which is correlated with performance on the training                                                             ful for prediction via lasso regression, and found that CDI
set) is included in column 3, as are the average number of                                                              percentile (chosen for 87% of models), vocabulary size (cho-
features seen in each model across all words (column 4). On                                                             sen for 75% of models), and age (chosen for 64% of models)
the test data, model fit is best for the child- and the reduced                                                         were common features. Although CDI percentile is a func-
word feature models. These two models, are not significantly                                                            tion of both vocabulary size and age, the three features were
different in a paired t-test (t(649)=1.44, p = 0.148) but the                                                           often (38% of models) included together in the model for a
reduced-word-feature model is significantly better than the                                                             specific word, consistent with previous work suggesting that
other models. We report the results of a t-test between the                                                             CDI percentile contains useful information about the interac-
two redux models (t(649)=3.07, p = 0.002). We find that the                                                             tion between age and vocabulary size as compared to the peer
child-feature model is not significantly different than the re-                                                         group (Thal et al., 1999; Beckage & Colunga, 2013).
duced word model with child features included.                                                                             The success of the word-feature representation, both with
   A priori, it seems likely that adding extra child features                                                           and without dimensionality reduction, indicates that the con-
should only improve the performance of the reduced-word                                                                 tent of the vocabulary is predictive of language learning.
(redux-word) model. We instead find that the model with the                                                             This result is exciting because understanding how the known
extra child features performs more poorly than the reduced                                                              vocabulary supports future vocabulary learning provides a
word-feature model without the child features. The observed                                                             new opportunity for understanding the developmental process
drop in performance with additional features reflects the fact                                                          (Smith, 2000). Further, this type of modeling can potentially
                                                                                                                  200

be extended to interventions: if we know how words build on         resentations found to be useful for prediction should inform
one another, can we teach children certain words to create vo-      cognitive models of child language development.
cabularies that are more useful for future language learning?
   We found that reducing the word-feature vector via princi-
                                                                                        Acknowledgments
pal components analysis improves model performance com-             This work was funded through an award from the John Merck
pared to using the original word-feature vector. This reduc-        Scholars Fund and by NICHD grant R01 HD067315 to Eliana
tion is beneficial because PCA performs noise suppression           Colunga. The first author was funded in part through the NSF
when we drop non-primary components and because it re-              GRFP. Data was collected by the DACS Lab at the University
duces the opportunity for overfitting. In addition, the reduced     of Colorado Boulder with much help from the DACS Lab
representation may be more interpretable and psychologically        undergraduates and the Boulder community parents.
relevant. Referring to Figure 3, we see that the frequency at
                                                                                              References
which the word is known in the overall set of vocabularies
seems to be strongly related to the first 2 components but          Arriaga, R. I., Fenson, L., Cronan, T., & Pethick, S. J. (1998).
other components might include semantic or phonological               Scores on the macarthur communicative development in-
features that can tell us more about the process of acquisi-          ventory of children from lowand middle-income families.
tion. We plan to explore this research question in more detail        Applied Psycholinguistics, 19(02), 209–223.
in future work.                                                     Beckage, N. M., & Colunga, E. (2013). Using the words
                                                                      toddlers know now to predict the words they will learn next.
   Perhaps our most important finding is that the child and
                                                                      Proc. of the 35th Conf of the Cog. Sci. Society, 163-168.
word features are complementary. This complementarity was
                                                                    Beckage, N. M., Smith, L. B., & Hills, T. T. (2011). Small
not evident when we constructed a single regression model
                                                                      worlds and semantic network growth in typical and late
with both sets of features, but stood out when we combined
                                                                      talkers. PloS one, 6(5), e19348.
predictions of child-feature and word-feature models. The
                                                                    Dale, P. S., & Fenson, L. (1996). Lexical development norms
combination, obtained by averaging the two models’ outputs,
                                                                      for young children. Behavior Research Methods, Instru-
achieves a statistically reliable improvement in prediction.
                                                                      ments, & Computers, 28(1), 125–127.
The resulting ensemble is proof that the child and word fea-
                                                                    Dale, P. S., Price, T. S., Bishop, D. V., & Plomin, R. (2003).
tures contain different types of information, both of which are
                                                                      Outcomes of early language delay. predicting persistent
useful for predicting future language learning.
                                                                      and transient language difficulties at 3 and 4 years. Journal
   The key value of modeling in this domain is to help us             of Speech, Language, and Hearing Research, 46(3), 544–
understand the sources of information that aid in prediction          560.
the acquisition of new words. We showed, in this work, that         DeLoache, J. S., Simcock, G., & Macari, S. (2007). Planes,
both child and word features are useful, and that the nature of       trains, automobiles–and tea sets: Extremely intense inter-
representation matters (e.g., unreduced versus reduced word           ests in very young children. Developmental Psychology,
vectors). Clearly, there are many other source of information         43(6), 1576-1586.
that could be incorporated into a model, such as demographic        Fenson, L., Dale, P. S., Reznick, J. S., Bates, E., Thal, D. J.,
characteristics, the linguistic environment, and cognitive and        Pethick, S. J., . . . Stiles, J. (1994). Variability in early
motor assessments of the child. Of course, obtaining these            communicative development. Monographs of the society
measures can be costly, and future modeling will be directed          for research in child development, 59(5), 1–185.
at determining which measures provide the most diagnostic           Friedman, J., Hastie, T., & Tibshirani, R. (2010). Regular-
features. One dimension we have begun exploring is the se-            ization paths for generalized linear models via coordinate
mantics and phonology of the child’s productive vocabulary.           descent. Journal of Statistical Software, 33(1), 1–22.
In our present work, we treat the words as independent sym-         Mayor, J., & Plunkett, K. (2011). A statistical estimate of
bols, but in principle a word representation which character-         infant and toddler vocabulary size from cdi analysis. De-
izes known words and the target word in terms of semantic             velopmental Science, 14(4), 769–785.
and phonological features could be utilized.                        Smith, L. B. (2000). Learning how to learn words: An as-
   Beyond exploring new types of features that might be use-          sociative crane. In Becoming a word learner: A debate on
ful in modeling language acquisition, we would also like to           lexical acquisition (pp. 51–80).
expand the class of models used to predict acquisition. The         Thal, D. J., O’Hanlon, L., Clemmons, M., & Fralin, L.
most natural extension of logistic regression is a multilayer         (1999). Vaidity of a parent report measure of vocabu-
neural network. In a network’s hidden layer, we can look              lary and syntax for preschool children with language im-
for the emergence of new features that have psychological             pairment. Journal of Speech, Language, and Hearing Re-
plausibility. Indeed, the success of our ensemble model sug-          search, 42(2), 482–496.
gests that an intermediate level of representational transfor-      Weizman, Z. O., & Snow, C. E. (2001). Lexical output as
mation may serve the prediction task. Although the models             related to children’s vocabulary acquisition: Effects of so-
we have focused on in this work are not intended to charac-           phisticated exposure and support for meaning. Develop-
terize cognitive and developmental processes per se, the rep-         mental Psychology, 37, 265-279.
                                                                201

