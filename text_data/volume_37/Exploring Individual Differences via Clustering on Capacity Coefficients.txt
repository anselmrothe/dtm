   Exploring Individual Differences via Clustering Capacity Coefficient Functions
                                            Joseph W. Houpt (joseph.houpt@wright.edu)
           Wright State University, Department of Psychology, 3649 Colonel Glenn Highway, Dayton, OH 45435 USA
                                                Leslie M. Blaha (leslie.blaha@us.af.mil)
   711th Human Performance Wing, Air Force Research Laboratory, 2255 H Street, Wright-Patterson AFB, OH 45433 USA
                               Abstract                                    We use the cumulative reverse hazard function, defined by
   The capacity coefficient function is a well-established, model-      Ki (t) = ln [Fi (t)], where for channel i, Fi (t) = P(Ti ≤ t). K(t)
   based measure comparing performance with multiple sources            is interpreted as the amount of work left to be done by the
   of information together to performance on each of those in-          system after t time has passed. In a system with more efficient
   formation sources in isolation. Because it is a function across
   time, it may contain a large amount of information about a           throughput, the K(t) increases faster to reach 0 earlier than a
   participant. In many applications, this information has been ig-     less efficient system.
   nored, either by using qualitative assessment of the function or        In an UCIP model, individual sources of information are
   by using a single summary statistic. Recent work has demon-
   strated the efficacy of functional principal components analysis     processed simultaneously without statistical interactions, and
   for extracting important information about the capacity func-        the addition of more sources never helps nor hurts the pro-
   tion. We extend this work by applying clustering techniques to       cessing speeds of other sources. Under AND stopping, all
   examine individual capacity differences in configural learning.
                                                                        sources must be completely processed before a response can
   Keywords: Configural Learning; Individual Differences; Ca-           be made. The exhaustive UCIP model predicts that the in-
   pacity Coefficient; Human Information Processing Modeling
                                                                        formation throughput during the joint processing of multiple
                            Introduction                                sources is the sum of their individual throughput measures.
A critical facet of characterizing the cognitive mechanisms             The CCF compares this prediction for a set of n information
involved human information processing is capturing changes              sources to the observed RT distribution from a condition re-
as information sources change. These models are applied                 quiring the simultaneous processing of all n sources together,
to individual participant data, so they have strong potential           as defined by Eq. 1.
to indicate individual differences. However, because of the                                                         n
functional nature of many information processing modeling                                     Cand (t) = Kn (t) − ∑ Ki (t)              (1)
approaches, it is challenging to find meaningful ways to ag-                                                       i=1
gregate the individual analyses to identify group trends while             AND processing is often juxtaposed with ST-ST process-
accounting for the variability of the processes of interest. We         ing. This is when target information is presented either alone
implement a rigorous approach to quantifying individual dif-            or among distracting information. For ST-ST, the UCIP
ferences and group patterns in a functional statistic measuring         prediction is that the information throughput for the target
the processing of multiple information sources, the capacity            source, i, will be the same regardless of whether or not there
coefficient function (CCF). We then employ clustering tech-             are additional, non-target sources of information presented.
niques to capture both qualitative and quantitative trends in           The CCF for ST-ST processing is
CCF data from a configural learning study (Blaha, 2010).
   CCF analysis models the effects of changing information                                     Cstst (t) = KiX (t) − Ki (t).            (2)
demands on an individual’s information throughput. Informa-
tion throughput refers to how much information can be pro-              CCFs are interpreted relative to 0. If C(t) = 0, then observed
cessed in a given amount of time. The CCF is a model-based              throughput is equal to the UCIP model and unlimited capac-
analysis comparing response times (RTs) in a task with mul-             ity is inferred. C(t) > 0 indicates super capacity processing,
tiple sources of information to RTs from task with a single             i.e., additional information sources resulted in more efficient
isolated source of information (Townsend & Wenger, 2004;                performance. C(t) < 0 indicates limited capacity, wherein
Houpt, Blaha, McIntire, Havig, & Townsend, 2014). There                 additional sources resulted in less efficient performance. Ex-
are a number of factors known to change performance as                  amples of the C(t) classes are shown in Figure 1.
the number of information sources increases. These include                 In early CCF applications, analysis was limited to visually
correlated processing of the sources, facilitation/inhibition           assessing the function. Houpt and Townsend (2012) recently
among the processes, processing strategy, and task demands.             derived statistics for testing a null hypothesis of UCIP pro-
The CCF controls for the effects of task demands by utilizing           cessing. While this statistic improves upon visual-only as-
a baseline prediction from an unlimited capacity, independent           sessment, it marginalizes information about the shapes of the
parallel (UCIP) model. UCIP predictions depend on the stop-             CCF.
ping rule for the task, and in this paper we will model ex-                Burns, Houpt, Townsend, and Endres (2013) demonstrated
haustive (AND) and a single-target self-terminating (ST-ST)             the use of functional principal components analysis (fPCA;
tasks.                                                                  Ramsay & Silverman, 2005) for analyzing differences in the
                                                                    932

                    Example Capacity Coefficients                              in CCFs only previously described in qualitative ways. K-
                                                                               means clustering refers to a technique in which a set of points
             Simulated                           Observed
                                                                               (in any finite dimensional vector space) are modeled as mem-
4                                     4
                         Super                                                 bers of one of K different clusters. The free parameters of the
                         Unlimited
                         Limited                                               model are the locations of the center of each of the K clusters,
                                                                               chosen to minimize the Euclidean distance between each da-
2                                     2
                                                                               tum and its nearest cluster center. The number of clusters
                                                                               to use, K, is experimenter-specified, either using a scree plot
0                                     0                                        or comparing the ratio of within cluster variation to between
                                                                               cluster variation across different values of K. We employ k-
                                                                               means clustering to determine the number of unique shapes
−2                                    −2                                       among a set of CCFs.
                                                                                  Hierarchical clustering builds successively more inclusive
                                                                               groupings of data (agglomerative) or successively dividing
−4                                    −4
                                                                               the data into more exclusive groupings (divisive). We use
       500   1000     1500     2000        500   1000      1500   2000         a basic agglomerative procedure which first clusters the clos-
               Time                                 Time                       est nodes. The next cluster is formed by either grouping a
                                                                               different pair of nodes which have the next smallest distance
Figure 1: Example capacity coefficients. The left plot demon-                  between them or by clustering a datum with the previously
strates data simulated from super, unlimited and limited ca-                   formed cluster if the distance between the datum and the clus-
pacity generating models. The right plot demonstrates capac-                   ter is less then the distance between any pair of data. This
ity functions estimated from participant data (Day 4 of the                    procedure iterates until a single cluster forms. We use hier-
configural learning study).                                                    archical clustering to examine group trends emerging from
                                                                               individual participant CCF modeling.
forms of the capacity functions. fPCA is similar to standard                                 Configural Learning Data
PCA. In PCA, the data are described as a linear combina-
                                                                               We analyzed the data from a configural learning study by
tion of orthogonal vectors which are ordered by the amount
                                                                               Blaha (2010) in which the CCFs qualitatively changed over
of variance in the data along that vector. In fPCA, the data
                                                                               the course of training. Configural learning is the process by
are described as a linear combination of orthogonal functions
 R                                                                             which individual object features are unified into a single per-
( fi f j = 0) which are ordered by the amount of variance in
                                                                               ceptual unit. Configural learning through unitization changes
the data along that function (i.e., fi maximizes ∑Nk=1 ( fi xk )2
                                                             R
                                                                               the perceptual representation of the objects, and Blaha and
whereR k
         x are the observed functions, subject to the constraint
                                                                               colleagues demonstrated that this not only changes the in-
that fi f j = 0 for j < i).
                                                                               formation throughput supporting object classification (Blaha,
   fPCA and PCA are often used to describe a dataset with                      2010) but also changes the supporting scalp-level neural re-
a dimensional subspace than the original data by only us-                      sponses (Blaha, Busey, & Townsend, 2009).
ing the first n bases (effectively projecting the data onto a
                                                                                  The study entailed two categorization tasks based on
lower dimensional subspace). Each individual datum is de-
                                                                               Goldstone (2000). A conjunctive categorization task was de-
scribed by its factor scores on those n bases. For example, if
                                                                               signed to require AND processing of the category 1 object by
xi = a1 f1 + a2 f2 . . . am fm where the f j are the basis functions
                                                                               systematic variation of the category 2 object features. Manda-
from fPCA, then we can use a lower dimensional representa-
                                                                               tory AND processing encouraged participants to chunk the
tion of xi given by xi ≈ a1 f1 + a2 f2 . fPCA reduction can pro-
                                                                               features into a single object; thus, we expected (and previ-
vide us with a tractable vector space together with represen-
                                                                               ously observed) unitization of this object. Unitization in-
tative functions to describe CCF data. In particular, similarity
                                                                               creases information throughput over the course of learning,
in the vector fPCA score space captures similarity in CCF
                                                                               captured by CCFs shifting from limited to super capacity
shapes, thereby providing a way to quantify properties of the
                                                                               over training. A single-feature categorization task served as
full functions. Thus, fPCA quantifies the shapes among a set
                                                                               a baseline estimate for the UCIP predictions. Each category
of CCFs derived from individual participants, and we can fur-
                                                                               in this task only contained a single object, with one feature
ther analyze the fPCA weights to identify trends among the
                                                                               differing between the two objects. Thus, RTs in this task cap-
individual differences.
                                                                               tured the speed of responding as participants learned to dis-
                                                                               tinguish individual visual features. A total of fourteen partic-
                              Clustering                                       ipants completed 10-14 experimental sessions, including 5-7
We applied two popular clustering methods to the fPCA-                         training sessions of both the conjunctive and single-target cat-
reduced capacity coefficients. Our goal is systematically and                  egorization tasks. Each one-hour session consisted of 1200
quantifiably capturing patterns of similarity and differences                  trials. In all, the statistical learning herein utilized 12,000-
                                                                         933

                                                         Absolute AND Capacity Coefficients
                    Subject 1                Subject 4                       Subject 7                   Subject 10               Subject 13
        4
                                   2                             4                             2                        2
        2
                                                                                                                        0
                                   0                             2                             0
        0                                                                                                               2
        2                          2                             0                             2
                                                                                                                        4
        4                          4                             2                             4
                                                                                                                        6
        6                          6                             4                             6                        8
              500   1500    2500       500   1500    2500              500   1500    2500          500    1500   2500       500    1500      2500
                    Subject 2                Subject 5                       Subject 8                   Subject 11               Subject 14
                                   4                             3                                                      2
        2                                                                                      4
                                   2                             2                                                      0
        0
                                   0                             1                             2                        2
        2
                                   2
        4                                                        0                             0                        4
                                   4
        6                                                        1                                                      6
                                   6                                                           2
        8                                                        2                                                      8
              500   1500    2500       500   1500    2500              500   1500    2500          500    1500   2500       500    1500      2500
                    Subject 3                Subject 6                       Subject 9                   Subject 12
        4                          2                             6
                                                                                                                                   Cluster   1
        3                                                                                      2                                   Cluster   2
                                   0                             4
                                                                                                                                   Cluster   3
        2                                                                                      0                                   Cluster   4
                                   2                             2
        1                                                                                                                          Cluster   5
                                   4                                                           2
                                                                 0
        1 0                        6                             2                             4
        2                                                                                      6
                                   8                             4
        3
              500   1500    2500       500   1500    2500              500   1500    2500          500    1500   2500
                                                         Relative AND Capacity Coefficients
                    Subject 1                Subject 4                       Subject 7                   Subject 10               Subject 13
        4                                                        4                             4                        2
                                   2
        2                                                        2                             2                        0
                                   0
        2 0                        2                             2 0
                                                                                               0                        2
                                                                                               2                        4
        4                          4                             4
        6                                                                                      4
                                   6                             6                                                      6
                                                                                               6
                                   8                             8                                                      8
        10                                                                                     8
              500   1500    2500       500   1500    2500              500   1500    2500          500    1500   2500       500    1500      2500
                    Subject 2                Subject 5                       Subject 8                   Subject 11               Subject 14
                                   2
        2                                                        2                             4                        2
                                   0
        0                                                                                                               0
                                                                 0
                                   2                                                           2                        2
        2                                                        2
                                   4                                                                                    4
        4                                                                                      0
                                                                 4
                                                                                                                        6
        6                          6
                                                                 6                             2                        8
        8                          8
              500   1500    2500       500   1500    2500              500   1500    2500          500    1500   2500       500    1500      2500
                    Subject 3                Subject 6                       Subject 9                   Subject 12
        4                          2                             4
                                                                                               2                                   Cluster   1
                                   0                             2                                                                 Cluster   2
        2                                                                                                                          Cluster   3
                                                                                               0                                   Cluster   4
                                   2                             0
                                                                                               2                                   Cluster   5
        0
                                   4                             2
        2                                                                                      4
                                   6                             4
                                                                                               6
        4                          8                             6
                                                                                               8
              500   1500    2500       500   1500    2500              500   1500    2500          500    1500   2500
Figure 2: AND Capacity coefficients for all participants over all training. The upper half gives the absolute Cand (t) data, and
the lower half gives the relative Cand (t) data. The thickness of each line indicates the training session where the thinnest lines
are the first session and the thickest line in each plot is that participant’s final day of training. Line colors indicate the K = 5
K-means cluster assignment for each Cand (t) curve.
16,800 trials for each of the 14 participants (see Blaha, 2010,                     for full study details).
                                                                              934

    For every day of training, four CCFs were estimated for                                         Absolute AND Centroid Capacity Coefficients
                                                                               20
each participant. First, based on the mandatory AND stop-                      15
                                                                                                                                                         Cluster 1 (n=16)
                                                                                                                                                         Cluster 2 (n=24)
                                                                                                                                                         Cluster 3 (n=27)
ping rule, the unitized object was examined with Cand (t). The                 10                                                                        Cluster 4 (n=6)
                                                                                                                                                         Cluster 5 (n=12)
complementary non-conjunctive responses required the iden-                     5
                                                                               0
tification of features unique to category 2, engaging an ST-                   −5
ST response rule. Thus, category 2 RTs were analyzed with
                                                                               −15
Cstst (t). For both Cand (t) and Cstst (t), absolute and relative
                                                                                     500     1000             1500              2000              2500             3000
capacity coefficients were estimated. Absolute learning mea-
                                                                                                    Relative AND Centroid Capacity Coefficients
sured changes in the CCFs with the UCIP estimate derived
                                                                                                                                                         Cluster 1 (n=6)
from the first training day, to give an overall estimate of ca-                20                                                                        Cluster 2 (n=8)
                                                                                                                                                         Cluster 3 (n=37)
pacity improvement from the start of the learning process.                     10
                                                                                                                                                         Cluster 4 (n=2)
                                                                                                                                                         Cluster 5 (n=32)
Relative learning varied the UCIP estimate for each day, to                    0
account for the single-target discrimination learning occur-
                                                                               −10
ring in parallel with configural learning.
    Figure 2 illustrates the AND CCF data for all participants.                      500     1000             1500              2000              2500             3000
Day 1 of training is shown in the thinnest line, and the last day
of training is the thickest in each plot. All participants exhib-
ited Cand (t) improvements over training, but as Figure 2 high-                Figure 3: Representative Cand (t) functions for each K-means
lights, there was a variety of individual differences observed                 cluster in both the absolute (upper) and relative (lower) fPCA-
by Blaha (2010). For example, Subject 4 exhibited a gradual                    reduced capacity spaces. Centroid Cand (t) functions deter-
improvement from limited Cand (t) < 0 to super Cand (t) > 0,                   mined by the linear combination of the centroid scores and
whereas Subjects 8 and 11 showed a more step-like shift from                   the fPCs for each space.
limited directly to super capacity. Subjects 9, 3, and 12 had
strong speed-accuracy trade-offs, with super capacity early
                                                                               ing highly efficient throughput by the end of training. K-
in training at the cost of lower accuracy. By applying un-
                                                                               means clustering shows that the raw CCF data in configural
supervised learning to systematically determine the numbers
                                                                               learning can be classified into 5 fundamental shapes.
of unique patterns in the data we can quantify these verbal
descriptions of the various learning patterns that would other-                Hierarchical Clustering
wise be merely observational inferences.
                                                                               In order to look for groupings among the learning trends, we
K-means Clustering                                                             mapped the functional learning traces into a high-dimensional
For all four CCF estimates, we extracted the first 4 fPCs, cre-                linear space by aggregating each participant’s fPCA scores
ating four 4-dimensional vector spaces in which we could                       over all days of training. Participants exhibiting similar func-
compare the capacity data. fPCA analysis was performed                         tional learning traces are represented by vectors close in this
separately for each of the four types of CCFs, and so we first                 space. Note that because fPCA scores further represent a
analyze the unique components within each of the those C(t)                    standardization of CCFs, we can map both the Cand (t) and
classes. K-means analysis was used to identify the number of                   Cstst (t) learning into the same high-dimensional space. Hier-
unique C(t) function shapes exhibited within each condition.                   archical clustering was performed on 20-dimensional fPCA
   In all conditions, K = 5 clusters of functions fit the data.                score space. In this space, each participant was represented
Figure 3 illustrates the five clusters for both the absolute                   by four vectors, one for each type of CCF (relative and abso-
(top) and relative (bottom) Cand (t) fPCA score spaces, with                   lute Cand (t) and Cstst (t)). The 20D vectors contained the four
similar results for Cstst (t) fPCA scores. The CCFs plot-                      fPC weights over five days of training (the first five days if
ted in Figure 3 illustrate the Cand (t) functions representative               a participant trained longer). Distance between vectors, D,
of the centroids of each cluster. These were computed by                       was estimated with the Euclidean metric. A heatmap of D is
xi ≈ a1 f1 + a2 f2 + a3 f3 + a4 f4 where {a1 , . . . , a4 } are the 4D         shown in Figure 4, with the rows ordered according to the hi-
centroid score values.                                                         erarchical clustering results. Agglomerative clustering on D
   The shapes of the centroid CCFs (Figure 3) are consistent                   was performed with Ward’s minimum variance method, min-
with the generally observed trends over learning. One clus-                    imizing total within-cluster variance (Ward, 1963).
ter shows strict limited capacity Cand (t) < 0 values, consis-                    Figure 5 depicts the dendrogram resulting from the hier-
tent with the inefficient performance early in training. Other                 archical clustering analysis. It is immediately obvious that
clusters show mixed values above and below 1, reflecting the                   there is a clear division in fPCA score space between the
functions in the middle of training that tend to shift from lim-               data from the STST and AND conditions. The red bound-
ited to unlimited to super capacity, as well as often showing                  ing boxes illustrate a cut tree with four groupings. Note that
non-flat shapes (e.g., super capacity for fast RTs, limited ca-                increasing the number of groups in the cut tree further di-
pacity for slow RTs). A final cluster exhibits strict super ca-                vided the Cand (t) half of the dendrogram, leaving the Cstst (t)
pacity Cand (t) > 0 values, consistent with participants reach-                portion clustered into a single group. One group contains all
                                                                         935

                                                                      this cluster represents those participants whose learning tra-
                                                                      jectories, measured by relative capacity, contain at least one
                                                                      function falling into all the CCF shapes illustrated by the rel-
                                                                      ative centroid functions in the lower part of Figure 3. Again,
                                                                      there is a small subgroup of absolute capacity vectors that
                                                                      clustered into a similar part of 20D fPCA-reduced space.
                                                                          We note that the small subgroup of relative (absolute) ca-
                                                                      pacity scores clustering with the majority of the absolute (rel-
                                                                      ative) capacity scores doesn’t mean the original CCFs were
                                                                      the same between these two groups. This is because the fPCA
                                                                      scores were derived separately on the two types of capacity
                                                                      measures, and the weights in the fPCA-reduced space refer
                                                                      to different fPCs. What is important is that the separation of
                                                                      these small subgroups implies that whether measured in ab-
                                                                      solute or relative terms, configural learning can be supported
                                                                      by two different learning trends (three if you count the trend
                                                                      of Subject 9). With few exceptions in this data set, the sub-
                                                                      groups consist of individual participants whose absolute and
                                                                      relative capacity measures clustered into similar portions of
                                                                      the fPCA-reduced space. Further analysis is needed to un-
                                                                      derstand how this relates to similarity between the fPCs and
Figure 4: Heatmap of Euclidean distances in the 20D fPCA              other functional measures.
scores space. The columns are ordered according to the den-
drogram depicted in the margins from the Wald hierarchi-                                        Discussion
cal clustering. Green coloring gives smaller distances; white
                                                                      In this paper we have demonstrated the use of clustering tech-
gives the largest distances.
                                                                      niques to find group trends among individual differences in
                                                                      configural learning. The CCF gives a model-based measure
                                                                      of how people are using the information sources together
the Cstst (t) fPCA vectors, indicating that all participants ex-      without making specific assumptions about the RT distribu-
hibited similar changes in Cstst (t) over the course of learning.     tions. Although the raw functions may be unwieldy for ex-
The D values illustrated in Figure 4 confirm that all Cstst (t)       ploring sub-groups of participants, fPCA can be used to cap-
fPCA scores were highly similar.                                      ture the important variation across CCFs. We then used stan-
   The AND scores were split into three groups. Subject 9             dard clustering techniques to examine different performance
separates early into her own cluster (confirmed by pairwise D         patterns. The cluster memberships attained with these meth-
values at the high end of the range), reflecting a unique pat-        ods can either be used for additional exploratory analysis or
tern of AND learning different from all other participants. As        for further comparisons with other types of data (e.g., clinical
illustrated in Figure 2, Subject 9 exhibited a unique combina-        diagnosis or working memory capacity). Importantly, cluster-
tion of an increasing, strictly super absolute capacity learning      ing and other statistical learning approaches can provide prin-
curve with a U-shaped relative capacity learning pattern, re-         cipled methods for finding generalizable patterns or trends in
sulting from a strong speed-accuracy trade-off.                       individual data without losing the characteristics in the indi-
   The second AND cluster (dendrogram middle) contains the            vidual participant data, which can be particularly challenging
majority of the absolute Cand (t) results. This indicates that        for functional or time series data.
in fPCA-reduced space, most participants exhibited similar                In previous CCF applications, analysis had been confined
learning-based changes in their CCFs. From Figure 2, we               to either qualitative, verbal descriptions of different patterns
can see similarities in their profiles based on the K-means           across capacity functions or to an aggregate statistic from
clustering of the individual curves. The colors in Figure 2 il-       Houpt and Townsend (2012). The approach presented in
lustrate that participants in this cluster have CCFs landing in       this paper allowed us to objectively identify different patterns
all 5 clusters. That is, their learning trajectories move through     across participants using the full functional information from
all the average function shapes illustrated in the absolute ca-       the CCFs. From this we are able to conclude that configural
pacity centroid AND CCFs of Figure 3. This cluster also con-          learning requires at least five unique CCF shapes to describe
tains a subgroup of relative fPCA score vectors, which clus-          all the observed stages of learning captured in C(t) functions.
ter with each other before clustering with the AND vectors.           Each participant fell into one of three learning patterns iden-
Similarly, the final AND cluster contained mostly relative ca-        tified by hierarchical clustering. So while all participants uni-
pacity fPCA score vectors. Referring back to the K-means              tized the objects in the task and showed overall information
color coding for the relative capacity coefficients in Figure 2,      throughput increases, there were three different trajectories
                                                                  936

                                                                     ing information sources (and hence the degree of configu-
        Sub9.STabs                                                   ral learning). Ancillary assumptions are necessary in most
      Sub13.STabs
         Sub9.STrel                                                  approaches, including the present analyses (e.g., Euclidean
       Sub13.STrel                                                   distances metrics). However, measurement assumptions are
      Sub3.STabs
    Sub12.STabs                                                      far less constraining with respect to the potential underlying
       Sub3.STrel                                                    cognitive processes than direct assumptions about the RT dis-
     Sub12.STrel
        Sub1.STrel                                                   tributions. Clustering and other statistical learning methods
        Sub1.STabs                                                   applied to the full functional CCF data enables principled,
     Sub7.STabs
    Sub10.STabs
                                                                     quantified individual differences analysis with minimal as-
       Sub7.STrel                                                    sumptions about the best parametric model for capturing the
     Sub10.STrel
      Sub11.STabs
                                                                     underlying cognitive processes.
      Sub11.STrel
       Sub2.STrel                                                                        Acknowledgments
      Sub5.STabs
     Sub4.STabs                                                      This work was supported by AFOSR Grant FA9550-13-1-
     Sub6.STabs                                                      0087 to J. W. H. and AFOSR LRIR to L. M. B. Distribution A.
     Sub14.STabs
      Sub2.STabs                                                     Approved for public release; distribution unlimited. 88ABW
      Sub8.STabs                                                     Cleared 03/11/2015; 88ABW-2015-0982.
      Sub4.STrel
      Sub6.STrel
     Sub14.STrel                                                                              References
      Sub5.STrel
      Sub8.STrel                                                     Blaha, L. M. (2010). A dynamic Hebbian-style model of con-
              Sub7.ANDabs                                               figural learning (Unpublished doctoral dissertation). Indi-
    Sub8.ANDabs
   Sub14.ANDabs                                                         ana University, Bloomington, Indiana.
               Sub10.ANDabs                                          Blaha, L. M., Busey, T. A., & Townsend, J. T. (2009, August).
               Sub12.ANDabs
           Sub11.ANDabs                                                 An lda approach to the neural correlates of configural learn-
    Sub4.ANDabs                                                         ing. In N. A. Taatgen & H. van Rijn (Eds.), Proceedings of
    Sub6.ANDabs
              Sub1.ANDabs
                                                                        the 31st annual conference of the cognitive science society.
              Sub3.ANDabs                                               Austin, TX: Cognitive Science Society.
             Sub10.ANDrel
             Sub12.ANDrel
                                                                     Burns, D. M., Houpt, J. W., Townsend, J. T., & Endres, M. J.
              Sub1.ANDrel                                               (2013). Functional principal components analysis of work-
              Sub3.ANDrel                                               load capacity functions. Behavior Research Methods, 45,
                           Sub9.ANDrel
                          Sub9.ANDabs                                   1048-1057.
              Sub11.ANDrel                                           Eidels, A., Donkin, C., Brown, S. D., & Heathcote, A. (2010).
      Sub4.ANDrel
      Sub6.ANDrel                                                       Converging measures of workload capacity. Psychonomic
            Sub13.ANDrel                                                Bulletin & Review, 17, 763-771.
           Sub2.ANDrel
       Sub8.ANDrel                                                   Goldstone, R. L. (2000). Unitization during category learn-
     Sub14.ANDrel                                                       ing. Journal of Experimental Psychology: Human Percep-
     Sub2.ANDabs
     Sub5.ANDabs                                                        tion and Performance, 26, 86-112.
             Sub7.ANDrel                                             Houpt, J. W., Blaha, L. M., McIntire, J. P., Havig, P. R., &
         Sub5.ANDrel
      Sub13.ANDabs
                                                                        Townsend, J. T. (2014). Systems Factorial Technology
                                                                        with R. Behavior Research Methods, 46, 307-330. doi:
                                                                        10.3758/s13248-013-0377-3
                                                                     Houpt, J. W., & Townsend, J. T. (2012). Statistical measures
Figure 5: Dendrogram visualization of hierarchical clustering           for workload capacity analysis. Journal of Mathematical
on 20D fPCA score vector space. The red boundaries indicate             Psychology, 56, 341-355.
the cut tree segmentation into group groupings.                      Ramsay, J. O., & Silverman, B. W. (2005). Functional data
                                                                        analysis (2nd ed.). New York: Springer.
                                                                     Townsend, J. T., & Wenger, M. J. (2004). A theory of in-
through CCF space to get to that same trained end state. But            teractive parallel processing: New capacity measures and
this analysis also revealed that multiple ways of measuring             predictions for a response time inequality series. Psycho-
capacity (absolute and relative) were needed to identify these          logical Review, 111, 1003-1035.
learning patterns.                                                   Ward, J. H., Jr. (1963). Hierarchical grouping to optimize
   An alternative to summary statistics is comparing parame-            an objective function. Journal of the American Statistical
ters of a fitted model (cf. Eidels, Donkin, Brown, & Heath-             Association, 58, 236-244.
cote, 2010). The downside to the model fitting approach is
that it relies on many more assumptions about how RTs are
generated that are ancillary to analyzing the effect of increas-
                                                                 937

