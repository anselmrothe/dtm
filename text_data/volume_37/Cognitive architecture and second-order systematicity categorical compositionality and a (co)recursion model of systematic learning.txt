Cognitive architecture and second-order systematicity: categorical
compositionality and a (co)recursion model of systematic learning
Steven Phillips (steve@ni.aist.go.jp)
Mathematical Neuroinformatics Group, National Institute of Advanced Industrial Science and Technology (AIST),
Tsukuba, Ibaraki 305-8568 JAPAN

William H. Wilson (billw@cse.unsw.edu.au)
School of Computer Science and Engineering, The University of New South Wales,
Sydney, New South Wales, 2052 AUSTRALIA
Abstract
Systematicity commonly means that having certain cognitive
capacities entails having certain other cognitive capacities.
Learning is a cognitive capacity central to cognitive science,
but systematic learning of cognitive capacitiesâ€”second-order
systematicityâ€”has received little investigation. We proposed
associative learning as an instance of second-order systematicity that poses a paradox for classical theory, because this form
of systematicity involves the kinds of associative constructions
that were explicitly rejected by the classical explanation. In
fact, both first and second-order forms of systematicity can
be derived from the formal, category-theoretic concept of universal morphisms to address this problem. In this paper, we
derived a model of systematic associative learning based on
(co)recursion, which is another kind of universal construction.
This result increases the extent to which category theory provides a foundation for cognitive architecture.
Keywords: cognitive architecture; systematicity; compositionality; learning; category theory; coalgebra

Introduction
The problem of systematicity for theories of cognitive science is to explain why certain cognitive capacities typically
co-exist (Fodor & Pylyshyn, 1988); why, for example, having
the ability to identify square as the top object in a scene consisting of a square above a triangle implies having the ability
to identify triangle as the top object in a scene consisting of
a triangle above a square. More formally, an instance of systematicity occurs when one has cognitive capacity c1 if and
only if c2 (McLaughlin, 2009): thus, systematicity is the partitioning of cognitive capacities into equivalence classes. The
problem is to provide an explanation for systematicity that
does not rely on ad hoc assumptions: i.e., auxiliary assumptions that are motivated only to fit the data, cannot be verified
independently of verifying the theory, and are unconnected to
the theoryâ€™s core principles (Aizawa, 2003).
Learning is another cognitive capacity. Hence, using the
characterization of systematicity as equivalence classes of
cognitive capacities (McLaughlin, 2009), we have another
form of systematicity: i.e., the capacity to learn cognitive capacity c1 if and only if the capacity to learn cognitive capacity c2 , which is sometimes referred to as second-order systematicity (Aizawa, 2003). Aizawa (2003), citing Chomsky
(1980), provides an example from language: a person has the
capacity to learn one natural language (say, Chinese) if they
have the capacity to learn another (say, German). Importantly,
the learned capacities need not be systematically related to

each other. An example that is pertinent to the classical explanation is the learning (or memorization) of arbitrary associations. For instance, if one has the capacity to learn (memorize) that the first day of the Japanese financial year is April
1st, then one also has the capacity to learn (memorize) that
the atomic number of carbon is 6. This example is a legitimate instance of systematicity (at the second level) given that
systematicity has been characterized as equivalence classes
of cognitive capacities (McLaughlin, 2009).
Elsewhere (Phillips & Wilson, submitted), we argue that
associative learning is problematic for classical theory, because it involves the kinds of associative constructions that
were explicitly rejected by the classical explanation. Our
category theoretic explanation of systematicity resolves this
problem, because both first and second-order forms of systematicity are derived from the same categorical construction:
universal morphisms. Here, we derive a model of systematic
associative learning based on (co)recursion, which is another
kind of universal construction.

Outline of paper
The remaining four sections of this paper are outlined as follows. The second section provides the basic category theory
definitions and motivating examples needed for our model.
The third section provides concrete examples of anamorphisms (corecursion) as a conceptual guide to the model given
in the fourth section. Discussion of this work is in the last
section. Readers already familiar with the category theory approach to corecursion may prefer to skip straight to the fourth
section, since the category theory employed here is already
well known, with the possible exception of the recently developed adjoint extensions (Hinze, 2013). Readers not familiar with a category theory approach may prefer to skip to the
third section for simple concrete examples as a way of orienting themselves for the model that follows. The second section, then, provides points of reference for technical details
and motivating examples when needed.

Basic category theory
In this section, we provide the basic category theory needed
for our model. In the interests of brevity and clarity, we only
provide definitions and examples directly pertaining to the
model, omitting the (albeit, well known) theorems and lemmas that justify statements. Deeper and broader introductions

1877

to category theory and categorical treatments of (co)recursion
can be found in many textbooks on the topic (e.g., Mac Lane,
1998; Bird & de Moor, 1997). In the context of systematicity, this paper builds upon our earlier work (see Phillips &
Wilson, 2010), and particularly in the context of recursive capacities (Phillips & Wilson, 2012), where the theoretical principles of first-order systematicity and other technical details
can be found.
Definition 1 (Category). A category C consists of:
â€¢ a collection of objects (A, B, ...);

Example 2 (Right product functor). The right product functor Î B : Set â†’ Set sends each set X to the Cartesian product
X Ã— B and each function f : X â†’ Y to the product of functions
f Ã— 1B : X Ã— B â†’ Y Ã— B, (x, b) 7â†’ ( f (x), b), i.e., f Ã— 1B maps
(x, b) to ( f (x), b).
Example 3 (Right exponential functor). The right exponential functor Î›B : Set â†’ Set sends each set X to the function
set X B , which is the set of functions { f : B â†’ X}, and each
function g : X â†’ Y to the function Î›(g) : X B â†’ Y B , f 7â†’ g â—¦ f .
Example 4 (List). List-related constructions built from a set
of elements A are obtained from an endofunctor on the category Set: i.e., FA : X 7â†’ 1 + A Ã— X, f 7â†’ 11 + 1A Ã— f , where 1
corresponds to the empty list, and + and Ã— are (respectively)
the disjoint union and Cartesian product of sets or functions.

â€¢ a collection of morphisms ( f , g, ...), written f : A â†’ B
to indicate that A and B are respectively the domain and
codomain of f , including an identity morphism, denoted
1A : A â†’ A, for each object A in C; and
â€¢ a composition operation that sends a pair of compatible
morphisms f : A â†’ B and g : B â†’ C, i.e., where the
codomain of f equals the domain of g, to their composite
morphism, denoted g â—¦ f : A â†’ C,
that satisfy the axioms of: associativityâ€”hâ—¦(gâ—¦ f ) = (hâ—¦g)â—¦
f ; and identityâ€” f â—¦ 1A = f = 1B â—¦ f for each f in C.

Definition 5 (Natural transformation). A natural transformation Î· from a functor F : C â†’ D to a functor G : C â†’ D, writ.
ten Î· : F â†’ G, is a family of D-morphisms {Î·A : F(A) â†’
G(A)|A is an object in C} such that for each morphism f :
A â†’ B in C we have G( f )â—¦Î·A = Î·B â—¦F( f ), i.e., the following
diagram is commutative (equational):

Example 1 (Set). The category Set has sets for objects, functions between sets for morphisms, and composition is composition of functions.

F(A)

F(B)

Definition 3 (Isomorphism). An isomorphism is a morphism
f : A â†’ B such that their exists a morphism g : B â†’ A satisfying f â—¦ g = 1B and g â—¦ f = 1A . Morphism g is called the
inverse of f , and denoted f âˆ’1 .

â€¢ identity: F(1A ) = 1F(A) for each object A in C; and
â€¢ compositionality: F(g â—¦C f ) = F(g) â—¦D F( f ) for each pair
of compatible morphism ( f , g).
Remark. An endofunctor is a functor F : C â†’ C, i.e., the
domain and codomain are the same category C. Endofunctors
are used to model (co)recursion.

(1)

Î·B


/ G(B)

Definition 6 (Final morphism). A final morphism from a
functor F : C â†’ D to an object X in D is a pair (A, Ï•) consisting of an object A in C and an morphism Ï• : F(A) â†’ X
in D such that for every object Z in Z and every morphism
f : F(Z) â†’ X in C there exists a unique morphism u : Z â†’ A
such that f = Ï• â—¦ F(u), as indicated by the following commutative diagram (dashed arrows indicate unique existence):
Z

u


A

Remark. In a category C, the collection of morphisms with
domain object A and codomain object B is called a hom-set,
denoted HomC (A, B). As we shall see, hom-sets play an important role in category theory.
Definition 4 (Functor). A functor F from a category C to a
category D is a structure-preserving map, written F : C â†’ D,
that maps each object A in C to the object F(A) in D and each
morphism f : A â†’ B in C to the arrow F( f ) : F(A) â†’ F(B)
in D such that the following axioms are satisfied:

/ G(A)
G( f )

F( f )

Definition 2 (Terminal object). In a category C, a terminal
object is an object, denoted 1, such that for every object Z
there exists a unique morphism u : Z â†’ 1.
Remark. In Set, a singleton set is a terminal object, whose
only element is denoted âˆ— when its identity is not required.
Other categories may have terminal objects with further internal structure, as we shall see for categories of (co)algebras.

Î·A

F(Z)
 BB
BB f

BB
F(u)

BB
/X
F(A)

(2)

Ï•

Remark. The dual of final morphism is initial morphism,
whose definition is obtained by reversing the directions of the
morphisms in the definition of final morphism. A universal
morphism is either a final morphism or an initial morphism.
In general, category theory concepts are dualized by reversing
all the arrows in the definition of the original concept.
Definition 7 (Adjunction). An adjunction from a category C
to a category D is a triple, written (F, G, Îµ) : C â‡€ D, consisting
of a functor F : C â†’ D, a functor G : D â†’ C and a natural
.
transformation Îµ : F â—¦ G â†’ 1D such that for each object Y in
D, the pair (G(Y ), ÎµY ) is a final morphism from F to Y , as

1878

states, or equivalently a unary function Ï„S : A â†’ SS from an
input to function between states, as given by the bijection
HomSet (A Ã— S, S) âˆ¼
= HomSet (A, SS ). We make use of this universal construction in our associative learning model.

indicated by the following commutative diagram:
F(X)
FF
FF g
FF
F( f )
FF

F#
F â—¦ G(Y ) Îµ / Y

X

f

G(Y )

(3)

Definition 8 (F-coalgebra). An F-coalgebra on an endofunctor F : C â†’ C is a pair (A, Î±) consisting of an object A and an
morphism Î± : A â†’ F(A) in C.

Y

Remark. The functor F is called the left adjoint of functor G,
and G is called the right adjoint of F. The relationship between F and G is called an adjoint situation, denoted F âŠ£ G.
The morphism ÎµY is the component of the natural transformation Îµ at object Y . Definition 7 emphasizes the natural transformation and universal morphism aspects of adjunctions, cf.
diagrams 3 and 2.
Example 5 (Product-exponential). The right product functor
is left adjoint to the right exponential functor, Î B âŠ£ Î›B , see
examples 2 and 3, is indicated by commutative diagram
A Ã— BE
EE
EEf
EE
fËœÃ—1B
EE

"
/C
CB Ã— B

A

fËœ 

CB

(4)

where fËœ is called the exponential transpose of f , and eval is
the evaluation of each function fËœ in CB at each b in B.
Remark. An equivalent definition of adjunction emphasizes
the relationship between hom-sets: an adjunction is a bijection (i.e., one-to-one correspondence) between hom-sets
HomC (X, G(Y )) and HomD (F(X),Y ) that is natural (in the
natural transformation sense) in variables X and Y , written
HomD (F(X),Y ) âˆ¼
= HomC (X, G(Y )), as indicated by diagram
F

/ F(X)


G(Y ) o

(5)

g

f

G

Definition 10 (Category of F-coalgebras). Suppose an endofunctor F : C â†’ C. A category of F-coalgebras, denoted
CoAlg(F), has F-coalgebras for objects and F-coalgebra homomorphisms for morphisms. Composition is composition
of F-coalgebra homomorphisms.
Definition 11 (Final F-coalgebra). Suppose we have a category of F-coalgebras, CoAlg(F). A final F-coalgebra is an
F-coalgebra, denoted (A, fin), such that for every F-coalgebra
(B, Î²) in CoAlg(F) there exists a unique F-coalgebra homomorphism h : (B, Î²) â†’ (A, fin).

eval

X

Definition 9 (F-coalgebra homomorphism). An F-coalgebra
homomorphism from a coalgebra (B, Î²) to a coalgebra (A, Î±)
is a morphism h : (B, Î²) â†’ (A, Î±) such that F(h) â—¦ Î² = Î± â—¦ h.

 Y

Hence, one can think of an adjunction as a kind of isomorphism that is local to hom-sets, but not necessarily global to
categories. This aspect will be useful when considering adjunctions in the context of corecursion.
Example 6 (Curry-uncurry). The product-exponential adjoint is familiar in functional programming in the form of
the curry-uncurry operator, which converts an n-ary function
(i.e., a function of n arguments) to a unary function (i.e., a
function of one argument). For instance, the curry of addition, written as the binary function add : N Ã— N â†’ N, is
the unary function addN : N â†’ NN , which takes a number x
and returns the addx function: e.g., addN : 1 7â†’ add1, where
add1 : n 7â†’ n + 1. Uncurry is the inverse of curry. These two
operators are either sides of the bijection HomSet (NÃ—N, N) âˆ¼
=
HomSet (N, NN ) obtained from the product-exponential adjoint. Similarly, a state transition function is a binary function Ï„ : A Ã— S â†’ S from inputs, a âˆˆ A, and states, s âˆˆ S, to

Definition 12 (Anamorphism). An anamorphism is an Fcoalgebra homomorphism to a final F-coalgebra homomorphism, as indicated by the following commutative diagram:
B

h

A

Î²

fin

/ F(B)

 F(h)

/ F(A)

(6)

Remark. Anamorphism h is denoted [(Î²)], using lens brackets
(Meijer, Fokkinga, & Paterson, 1991), since h is completely
determined by Î². Anamorphism is also called unfold.
Definition 13 (Conditional function). A conditional function
is a function consisting of a predicate p? : A â†’ {False, True}
and two alternative functions f : A â†’ B and g : A â†’ C, written
(p? â†’ f , g) : A â†’ B +C, that is defined as:
{
f (a) Â¬p?(a);
(p? â†’ f , g) : a 7â†’
g(a) otherwise.
That is, a function that applies alternative f to argument a if
p?(a) is false, otherwise alternative g. Recall that B +C is the
disjoint union of sets B and C.
Example 7 (List anamorphism). For list-related constructions built from elements in a set A, we have a category of
coalgebras on the endofunctor FA : X â†’ 1 + A Ã— X. It can be
shown that a final coalgebra for this category consists of conditional function (empty? â†’ Iâˆ— , âŸ¨head, tailâŸ©) : L â†’ 1 + A Ã— L,
where L is the set of lists constructed from elements of a
set A, predicate empty? tests for empty list, constant function
Iâˆ— : L â†’ 1 returns unnamed element âˆ—, and product function
âŸ¨head, tailâŸ© : L â†’ A Ã— L returns a pair consisting of the head

1879

and the tail of the given list. Every anamorphism to this final
coalgebra is given by commutative diagram
X

[( p?â†’Iâˆ— ,âŸ¨ f ,gâŸ©)]

L

(p?â†’Iâˆ— ,âŸ¨ f ,gâŸ©)

is either 0, for the empty list, or one plus the count of the rest
(tail) of the list. For instance,
fold(0, inc)[a, b, c]
= 1 + fold(0, inc)[b, c]

/ 1+AÃ—X

 1+1 Ã—[( p?â†’I ,âŸ¨ f ,gâŸ©)]
âˆ—
A

/ 1+AÃ—L

= 1 + (1 + fold(0, inc)[c]
= 1 + (1 + (1 + fold(0, inc)[ ]))
= 1 + (1 + (1 + 0))

(empty?â†’Iâˆ— ,âŸ¨head,tailâŸ©)

(7)
Since (empty? â†’ Iâˆ— , âŸ¨head, tailâŸ©) is an isomorphism, traversing diagram 7 from X to L clockwise yields the definition:
{
[]
Â¬p?(x);
[( p? â†’ Iâˆ— , âŸ¨ f , gâŸ©)] : x 7â†’
f (x) Â· [(Â· Â· Â·)](g(x)) otherwise.
We also write [( p? â†’ Iâˆ— , âŸ¨ f , gâŸ©)] as unfold(p? â†’ Iâˆ— , âŸ¨ f , gâŸ©).
Remark. The preceding definitions pertaining to coalgebras
have duals, which are obtained by reversing morphisms. For
comparison, a catamorphism k : (A, in) â†’ (B, Î²) from initial
F-algebra (A, in) to F-algebra (B, Î²) as indicated by
F(A)


F(k)

F(B)

in

Î²

/A


k

/B

(8)

Catamorphism k is denoted (|Î²|), by banana brackets (Meijer
et al., 1991), since k is determined by Î². Catamorphism is also
called fold. For lists built from elements of A, catamorphisms
are given by
1 + A Ã— L

1+1A Ã—(|Iv , f |)


1+AÃ—X

[empty,cons]

[Iv , f ]

/L


 (|Iv , f |)
/X

= 3.
Remark. Every list is entirely deconstructed before folding
into a result. This approach is unrealistic as a cognitive model
of learning, since it requires having seen all examples before
any learning can take place. Nonetheless, list catamorphisms
provide an important step in that they are closely related to the
dual construction that affords a model of (on-line) learning at
each input presentation, which we turn to next.

Corecursion for lists
Category theory provides a systematic treatment of corecursion in the form of anamorphisms, which is the basis for our
categorical model of associative learning. Several simple examples of anamorphisms provide a guide to our model.
Repeating an item n number of times is realized as the
anamorphism, unfold(0? â†’ Iâˆ— , âŸ¨1, decâŸ©) : N â†’ L, where 0?
tests whether a number is zero, 1 is the constant function returning 1, and dec decrements a number by 1 (cf. diagram 7).
For instance,
unfold(0? â†’ Iâˆ— , âŸ¨1, decâŸ©)(3)
= 1 Â· unfold(0? â†’ Iâˆ— , âŸ¨1, decâŸ©)(2)
= 1 Â· 1 Â· unfold(0? â†’ Iâˆ— , âŸ¨1, decâŸ©)(1)
= 1 Â· 1 Â· 1 Â· unfold(0? â†’ Iâˆ— , âŸ¨1, decâŸ©)(0)

(9)

= 1Â·1Â·1Â·[]
= [1, 1, 1].

where empty : âˆ— 7â†’ [ ] returns the empty list, cons : (h,t) 7â†’ h Â·t
returns the list with (head) element h prepended to (tail) list t,
and Iv assigns the value v to the empty list. An initial algebra
is an isomorphism. Thus, traversing diagram 9 from L to X
counterclockwise yields the following definition:
{
[]
7â†’ v;
(|Iv , f |) :
h Â· t 7â†’ f (h, (|Iv , f |)(t)).
We also write (|Iv , f |) as fold(Iv , f ).
Example 8 (Counting). Counting list elements is computed
by the catamorphism, fold(0, inc) : L â†’ N, where the first argument, 0, assigns the result of zero to the empty list, and the
second argument, inc, ignores the head (first element) of the
list and increments the count of the tail (remaining elements)
of the list (cf. diagram 9). In other words, the count of a list

Notice that the anamorphism just given is a state-less (or,
memory-less) computation. To count list items, we need to
maintain a state for the number of previously counted items.
For example, unfold(e? â†’ Iâˆ— , âŸ¨incl, tailrâŸ©) : N Ã— LX â†’ LN
takes the number of items counted so far, n âˆˆ N, and a list
l âˆˆ LX of elements from X, and returns the progressive count
of list items c âˆˆ LN . In this example, the conditional e?
tests for an empty list (at the second component of a given
pair), i.e., no more items to be counted, effectively terminating the count when the list of remaining items is empty, via
Iâˆ— , or incrementing the count and removing the counted item
from the list, via product function âŸ¨incl, tailrâŸ©. The function
incl : (n, l) 7â†’ n + 1 increments the counter (left component)
and ignores the list; the function tailr : (n, h Â· t) 7â†’ (n + 1,t)
maintains the new count and removes the counted item from
the list of items to be counted. Compare diagram 7: object A
is now the set of natural numbers N, and X is the Cartesian

1880

product N Ã— LX of the natural numbers with the set of lists of
elements from a set X. For instance,
unfold(e? â†’ Iâˆ— , âŸ¨incl, tailrâŸ©)(0, [a, b, c])

â€¢ Âµ : P Ã— G â†’ G is a function that merges the current pair of
associated elements with the current association network,
returning an association network; and
â€¢ Î½ : P Ã— G â†’ P Ã— G is the next state function that returns
the list of remaining pairs, and the merged association network: i.e., Î½ = âŸ¨Ï„, ÂµâŸ©, where Ï„ : P Ã— G â†’ P returns the tail
of the pairs list, which ignores the association network.

= 1 Â· unfold(e? â†’ Iâˆ— , âŸ¨incl, tailrâŸ©)(1, [b, c])
= 1 Â· 2 Â· unfold(e? â†’ Iâˆ— , âŸ¨incl, tailrâŸ©)(2, [c])
= 1 Â· 2 Â· 3 Â· unfold(e? â†’ Iâˆ— , âŸ¨incl, tailrâŸ©)(3, [ ])
= 1Â·2Â·3Â·[]
= [1, 2, 3].
Notice, further, that this count anamorphism returns a list
of counts, not a single count. The elements of such output
(likewise, input) lists are commonly interpreted as being indexed by steps in time for corecursive models of data streams,
i.e., infinite lists (Rutten, 2000). We invoke a similar temporal
interpretation of lists for our learning model.

Categorical (corecursion) model
We develop our model in two steps for expository purposes.
The first step treats the association network as an explicit input. This approach is simpler, but unrealistic since memory
is treated as external input. The second step treats memory as
internal using adjoint anamorphisms (adjoint unfolds).

An example illustrates the mechanism. The anamorphism
given by diagram 10 is relabeled mext , the model with external memory. Suppose the initial list of pairs: [(bread, butter),
(knife, fork), (knife, butter)]. The initial state of the association network is set to the empty graph e. We denote pair
and network lists at time t as pt and gt , respectively. Hence,
the initial pair list p0 contains three pairs, and the inital network g0 = e. One time step is the mapping mext : (p0 , g0 ) 7â†’
g1 Â· mext (p1 , g1 ), where g1 is the association network containing the single edge Ïƒ1 : bread â†’ butter (i.e., an association
from bread to butter with strength of association Ïƒ1 ), and p1 is
the pairs list [(knife, fork), (knife, butter)]. This process continues corecursively until we obtain g1 Â· g2 Â· g3 Â· mext (p3 , g3 )
at which point the model returns the empty list (of networks)
and terminates with the list [g1 , g2 , g3 ]. That is the evolution
of association networks over time steps, with g3 being the final network state indicated by the following diagram:

Network state as external input
The capacity for learning associations is modeled as a function from a list of pairs (associates) to an association network.
Recall, from the counting example, that a simple anamorphism does not maintain a state, and so does not suffice as
an associative learning model, since previous associations are
lost. A memory is maintained by passing the results of earlier
items as an explicit input to the model. Accordingly, associative learning is modeled as a function from a list of pairs and
an association network to an updated association network.
The anamorphism (model) is indicated by the diagram
P Ã— G

[(e?â†’Iâˆ— ,âŸ¨Âµ,Î½âŸ©)]


L

(e?â†’Iâˆ— ,âŸ¨Âµ,Î½âŸ©)

/ 1 + G Ã— (P Ã— G)

 1+1 Ã—[(e?â†’I ,âŸ¨Âµ,Î½âŸ©)]
âˆ—
A


/ 1+GÃ—L

Ïƒ1

/ butter
:
uu
u
u
u
uu
uu Ïƒ2
/ fork
knife

bread

(11)

Ïƒ3

An important feature of the anamorphism approach, in contast to a catamorphism approach, is that the computation at
each (time) step proceeds independently of the remaining
steps. For example, the first item of the list g1 Â· mext (p1 , g1 ),
i.e., g1 , is not affected by the computation of the rest of the
list. This property of anamorphisms justifies the temporal interpretation of lists. Effectively, then, there is only one association graph produced by the model, whose state is indexed by
time step t: i.e., the network gt in the list g0 Â· Â· Â· gt Â· mext (pt , gt ).

Network state as internal memory

(pempty â†’Iâˆ— ,âŸ¨head,tailâŸ©)

(10)
where:
â€¢ P is a list of pairs of associated items;
â€¢ G is the set of (labeled) directed graphs (association networks), where each graph g âˆˆ G is a pair (E,V ) consisting
of a set of edges E and a set of vertices V , and each edge
is a triple (s, Ïƒ,t), where s and t are the source and target
vertices and Ïƒ is the strength of association; hence

The previous model depends on treating network state as
a kind of external memory. The theory of adjoint catamorphisms and anamorphismsâ€”adjoint folds and unfolds
(Hinze, 2013) allows us to treat network state as internal to
the model. We make use of the product-exponential adjoint
introduced earlier. Recall that this construction effectively
provides a universal means of transforming the external state
map into an internal state map, as indicated by the following
diagram (highlighting the bijection aspect of this adjunction):

â€¢ L is the set of lists of association networks;
â€¢ e? tests whether the list of associates is empty;

1881

P 

^
[(e?â†’
Iâˆ— ,âŸ¨Âµ,Î½âŸ©)] 

LG o

Î G

Î›G

/ PÃ—G

 [(e?â†’I ,âŸ¨Âµ,Î½âŸ©)]
âˆ—

 L

(12)

The internal model, which we denote mint , is the exponential
g
transpose of the external model mext . That is, mint = m
ext .
A final algebra is a universal construction. Thus, we have
shown that the (second-order) systematicity of associative
learning follows from the same category theoretical principles as other (first-order) forms of systematicity.

Discussion
The advantage of a category theory approach is that it provides a principled approach to (co)recursive cognitive capacities. Symbol systems admit arbitrary recursion, but not every recursive formulation is systematic, in the sense of being
well-defined over all possible inputs. Well-definedness, categorically, depends only on the well-definedness of the given
F-(co)algebra, since the (unique) existence of an anamorphism (or, catamorphism) is guaranteed by the universal
property. Existence and uniqueness were motivations for taking a category theory approach to recursion in the first place
(see, e.g., Bird & de Moor, 1997).
The anamorphic (corecursion) explanation for secondorder systematicity of learning is quite general. Moreover,
extensions to other forms of learning and associated models
are straightforward. For instance, in the case of supervised
learning, P is a list of pairs of input-target representations,
and G is a set of neural (feedforward, error backprogagation)
networks. Supervised learning proceeds in the same corecursive manner as already described, except that we replace the
coalgebra updating associative networks with one for updating (feedforward) neural networks. Unsupervised learning,
which omits the target, is similarly straightforward.
The generality of anamorphisms may leave some people
wondering whether it is too general. In particular, since many
species have the capacity for simple associative learning, why
then do they not also have the capacity for more advanced
forms of learning, such as learning via analogy? Recall that
the systematicity problem is at the level of the complex entities, not at the level of their components. For example, the
capacity to understand that John loves cricket implies the capacity to understand John loves baseball given that one understands that John refers to a person, and that cricket and
baseball refer to games. The capacity to understand that John
loves cricket does not imply the capacity to understand John
loves hanafuda when one does not understand the meaning of
hanafudaâ€”a Japanese card game. Likewise, we donâ€™t expect
a capacity for learning associations to imply a capacity for
learning by analogy, because association and analogy involve
different kinds of underlying structures (Halford, Wilson, Andrews, & Phillips, 2014); categorically, they involve the existence of different objects. Rather, we expect that if a subject
has the capacity for the underlying structures, then a capacity
for learning with respect to one kind of structure implies a capacity for learning with respect to the other kind of structure,
because they both involve the same form of (co)recursion.
To test such claims of systematicity empirically, we need
three things: (1) a test for the base capacities, analogous to a

test for the understanding of John and Mary, (2) a test for the
understanding of a complex entity case, analogous to a test
for the understanding of John loves Mary, and (3) a test of the
prediction for another complex entity belonging to the same
equivalence class, analogous to a test for the understanding of
Mary loves John. Failure to exhibit capacity to other members
of the equivalence class counts against the theory of systematicity that predicts that class. Hence, the category theory explanation that we have put forward is testable, and amenable
to further empirical work.

Acknowledgments
We thank the reviewers for helpful comments. This work was
supported by a Japanese Society for the Promotion of Science
Grant-in-aid (26280051).

References
Aizawa, K. (2003). The systematicity arguments. New York:
Kluwer Academic.
Bird, R., & de Moor, O. (1997). Algebra of programming.
Harlow, England: Prentice Hall.
Chomsky, N. (1980). Rules and representations. New York,
NY: Columbia University Press.
Fodor, J. A., & Pylyshyn, Z. W. (1988). Connectionism
and cognitive architecture: A critical analysis. Cognition,
28(1â€“2), 3â€“71.
Halford, G. S., Wilson, W. H., Andrews, G., & Phillips, S.
(2014). Categorizing cognition: Toward conceptual coherence in the foundations of psychology. Cambridge, MA:
MIT Press.
Hinze, R. (2013). Adjoint folds and unfoldsâ€”an extended
study. Science of Computer Programming, 78, 2108â€“2159.
Mac Lane, S. (1998). Categories for the working mathematician (2nd ed.). New York, NY: Springer.
McLaughlin, B. P. (2009). Systematicity redux. Synthese,
170, 251â€“274.
Meijer, E., Fokkinga, M., & Paterson, R. (1991). Functional
programming with bananas, lenses, envelopes and barbed
wire. In Proceedings on the conference on functional programming and computer architecture (Vol. 523, pp. 125â€“
144). Berlin, Germany: Springer-Verlag.
Phillips, S., & Wilson, W. H. (2010). Categorial compositionality: A category theory explanation for the systematicity
of human cognition. PLoS Computational Biology, 6(7),
e1000858.
Phillips, S., & Wilson, W. H. (2012). Categorial compositionality III: F-(co)algebras and the systematicity of recursive
capacities in human cognition. PLoS ONE, 7(4), e35028.
Phillips, S., & Wilson, W. H. (submitted). The second-order
systematicity of associative learning: a paradox for classical compositionality and a coalgebraic resolution.
Rutten, J. J. M. M. (2000). Universal coalgebra: a theory of
systems. Theoretical Computer Science, 249, 3â€“80.

1882

