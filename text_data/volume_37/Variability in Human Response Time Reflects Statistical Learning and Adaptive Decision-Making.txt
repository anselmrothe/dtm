  Variability in Human Response Time Reflects Statistical Learning and Adaptive
                                                           Decision-Making
                                                    Ning Ma (nima@eng.ucsd.edu)
                      Department of Electrical and Computer Engineering, University of California San Diego
                                               9500 Gilman Drive, La Jolla, CA 92037 USA
                                                     Angela J. Yu (ajyu@ucsd.edu)
                                  Department of Cognitive Science, University of California San Diego
                                               9500 Gilman Drive, La Jolla, CA 92037 USA
                               Abstract                                  some time after the go stimulus (stop-signal delay; SSD). We
                                                                         model trial-by-trial behavior in SST, using a Bayesian hidden
   Response time (RT) is an oft-used but ”noisy” behavioral mea-
   sure in psychology. Here, we combine modeling and psy-                Markov model to capture across-trial learning of stop signal
   chophysics to examine the hypothesis that RT variability may          frequency (P(stop)) and onset asynchrony (SSD), and a ra-
   reflect ongoing statistical learning and consequent adjustment        tional decision-making control policy, which combines prior
   of behavioral strategy. We utilize the stop-signal task, in which
   subjects respond to a go stimulus on each trial, unless in-           beliefs and sensory data to produce behavioral outputs un-
   structed not to by a subsequent, rare stop signal. We model           der task-specific constraints/objectives, to model within-trial
   across-trial learning of stop signal frequency (P(stop)) and          decision-making.
   stop-signal onset time (SSD) with a Bayesian hidden Markov
   model, and within-trial decision-making as optimal stochas-              This work builds on several previous lines of modeling
   tic control. The model predicts that RT should increase with          research. The new model combines a within-trial rational
   expected P(stop) and SSD, a prediction borne out by our hu-
   man data. Thus, it appears that humans continuously moni-             decision-making model for stopping behavior (Shenoy & Yu,
   tor environmental statistics and adjust behavioral strategy ac-       2011) and an across-trial statistical learning model (Dynamic
   cordingly. More broadly, our approach exemplifies the use of          Belief Model; DBM) that sequentially updates beliefs about
   ”noisy” RT measures for extracting insights about cognitive
   and neural processing.                                                P(stop) (Yu & Cohen, 2009; Ide, Shenoy, Yu*, & Li*, 2013);
   Keywords: Bayesian modeling, decision making, learning, re-           it also incorporates a novel across-trial learning component,
   sponse time, behavioral psychophysics                                 essentially a Kalman filter, that updates beliefs about the tem-
                                                                         poral statistics of the stop-signal onset (SSD). Using this new
                          Introduction                                   model, we can then predict how RT on each trial ought to
                                                                         vary as a function of the sequence of stop/go trials and SSD’s
Response time (RT) is an oft-reported behavioral measure in
                                                                         previously experienced by the subject, and compare it to the
psychology and neuroscience studies. As RT can vary greatly
                                                                         subject’s actual RT.
across trials of apparently identical experimental conditions,
average or median RT across many identical trials is typically              Several key elements of the combined model have previ-
used to examine how task performance or an internal speed-               ously received empirical support. For example, we showed
accuracy tradeoff might be affected by different experimental            that the rational decision-making model for stopping behavior
conditions. Separately, a specialized subfield of quantitative           (Shenoy & Yu, 2011), which separately penalizes stop error,
psychology has used not only the first-order statistics (e.g.            go (discrimination and omission) error, and response delay,
mean and median) but also second-order (e.g. variance) and               can account for both classical effects in the SST (Logan &
higher-order (e.g. skewness, kurtosis) statistics to make infer-         Cowan, 1984), such as an increase in rate of stop errors as a
ences about the cognitive or neural processes underlying be-             function of SSD and the faster stop-error responses (relative
havior (Laming, 1968; Luce, 1986; Smith, 1995; Ratcliff &                to correct go responses), as well as some recently discovered,
Rouder, 1998; Gold & Shadlen, 2002; Bogacz et al., 2006).                subtle influences on stopping behavior by contextual factors,
In general, RT is considered a very noisy experimental mea-              such as motivation/reward (Leotti & Wager, 2009) and the
sure, with single-trial responses yielding little useful informa-        baseline frequency of stop trials (Emeric et al., 2007). We
tion about the underlying mental processes.                              also showed that the across-trial learning model, DBM, can
   In this work, we approach RT modeling from a different                account for sequential adjustment effects not only in SST (Ide
angle, attempting to capture trial-to-trial variability in RT as         et al., 2013), but also more broadly in simple 2AFC percep-
a consequence of statistically normative learning about en-              tual decision-making tasks (Yu & Cohen, 2009) and a multi-
vironmental statistics and corresponding adaptations within              target visual search task (Yu & Huang, 2014). Neurally, we
an internal decision-making strategy. We focus on behav-                 have evidence from fMRI studies that a key prediction error
ior in the stop-signal task (SST) (Logan & Cowan, 1984), a               signal related P(stop) is encoded in the brain region known
classical inhibitory control task, in which subjects respond             as dorsal anterior cingulate cortex (dACC) (Ide et al., 2013),
to a go stimulus on each trial unless instructed to with-                and that dACC response is altered in young adults at-risk for
hold their response by an infrequent stop signal that appears            developing stimulant addiction (Harlé et al., 2014).
                                                                     1446

     In the following, we first describe the experimental design,            Sensory processing as Bayes statistical inference. Fig-
then the modeling details, followed by the results; we finally            ure 1A graphically illustrates the Bayesian generative model,
conclude with a discussion of broader implications and future             whereby the two hidden variables correspond respectively to
directions for research.                                                  the identity of the go stimulus, d ∈ {0, 1}, and whether or
                                                                          not this trial is stop trial, s ∈ {0, 1}. The priors of d and s
                                  Experiment                              are P(d = 1) and r = P(s = 1). Conditioned on the go stim-
22 UCSD students participated in the stop signal task. On                 ulus identity d, a sequence of iid sensory inputs are gener-
each trial, the subject was presented with a two alterna-                 ated on each trial, x1 , ... ,xt , ... ,where t indexes time steps
tive forced-choice (2AFC) perceptual discrimination task,                 within a trial. The likelihoods of the sensory inputs given d
in which he must press a left or right arrow depending on                 are f0 (xt ) = p(xt |d = 0) and f1 (xt ) = p(xt |d = 1), which are
whether the stimulus was a square or circle or the direction              assumed to be Bernoulli distribution with respective rate rate
of random dot motion(stimulus-key association was counter-                parameters qd and 1 − qd . The dynamic variable zt denotes
balanced across subjects). On approximate 25% of trials, an               the presence/absence of the stop signal. z1 = ... = zθ−1 = 0
auditory ”stop” signal was presented some time after the go               and zθ = zθ+1 = ... = 1 if a stop signal appears at time θ,
(discrimination) stimulus, indicating that the subject should             where θ represents stop signal delay SSD. For simplicity, we
withhold their response to the go stimulus. Trials containing             assume that the onset of the stop signal θ (SSD) follows an
a stop signal are stop trials; otherwise they are go trials. The          geometric distribution: p(θ = t|s = 1) = q(1 − q)t−1 . The
delay in presentation between the go stimulus and the the stop            mean of θ is equal to 1q which is the expected SSD (E [SSD])
signal is known as the stop-signal delay (SSD), which was                 within a trial. Conditioned on zt , a stream of iid observations
uniformly and randomly sampled from 100 ms, 200 ms, 300                   are generated. The likelihoods of the the sensory inputs, as-
ms, 400 ms, 500 ms, and 600 ms in stop trials. Each sub-                  sociated with the stop signal, are p(yt |zt = 0) = g0 (yt ) and
ject participated in 12 blocks, with each block containing 75             p(yt |zt = 1) = g1 (yt ). We assume that the likelihood func-
trials.                                                                   tions, g0 and g1 , are also Bernoulli distributions with respec-
                                                                          tive rate parameters qs and 1 − qs .
                                    Models                                   In Bayesian statistical inference process, Bayes’ Rule is
In this section, we give a brief description of the three com-            applied in the usual iterative manner way to compute the
putational models: a stochastic control model for within-trial            sequential posterior probability associated with go stimulus
sensory processing and decision-making, a hidden Markov                   identity, ptd := P(d = 1|xt ), and the presence of the stop sig-
model (DBM) for across-trial learning of stop signal fre-                 nal, pts := P(s = 1|xt ), where xt = {x1 , x2 , ..., xt } denotes all
quency, and a Kalman filter model for across-trial learning               the data observed so far. ptz := P(θ < t|yt ) denotes the pos-
of SSD.                                                                   terior probability that the stop signal is already present. The
                                                                          belief state at time t is defined to be the vector bt = (ptd , pts ),
Stochastic Control Model for Within-Trial
                                                                          which can be iteratively computed from step to step via
Processing
                                                                          Bayes’ Rule, by inverting the generative model (Figure 1).
We briefly summarize the rational decision-making model for
                                                                             Decision process as optimal stochastic control. Fig-
stopping behavior here; a more detailed description can be
                                                                          ure 1B graphically illustrates the sequential decision-making
found elsewhere (Shenoy & Yu, 2011).
                                                                          process. On Go trials, if the Go action is taken by the re-
                                                                          sponse deadline D, it is recorded as a Go response (correct on
  (A)                                     (B)
                                                                          Go trials, stop error on Stop trials); otherwise the trial termi-
                                                                          nates and a Stop response is recorded (omission error on Go
                                                                          trials, correct on Stop trials). We define a cost (loss) function
                                                                          to account for the cost and penalty structure of the stop-signal
                                                                          task. The observer is assumed to minimize the expected value
                                                                          of this loss function in choosing whether to Go or Wait at each
  Figure 1. Within-trial sensory processing and decision-                 tilmestep, based on the current belief state. A Go response
making. (A) Bayesian generative model of iid sampled sen-                 terminates the current trial, while a Wait response lengthens
sory observations (x1 , . . . , xt , . . .) conditioned on Go stimulus    the current trial by at least one more time step (unless termi-
identity (d = 0, d = 1), and an independent stream of obser-              nated by the externally imposed response deadline).
vations (y1 , . . . , yt , . . .) conditioned on the presence (zt = 1)       Let τ denote the trial termination time, so that τ = D if no
or absence (zt = 0) of the Stop signal. (B) The decision of               response is made before the deadline D, and τ < D if a Go
whether to Go, when to do so, and which Go response to                    action is chosen. δ ∈ {0, 1} represents the possible binary Go
select are modeled as a sequential decision-making process,               choices produced by making a Go response. We also assume
where the subject chooses at each moment in time whether to               there is a basic cost c per unit time on each trial, a stop error
select a Go response (δ = 0 for square, δ = 1 for circle), or to          penalty of cs for choosing to respond on a stop-signal trial,
wait at least one more time point.                                        and a unit cost for making a discrimination error on a go trial
                                                                      1447

(since the cost function is invariant with respect to scaling,         In DBM, γk is the probability the subject will see a stop trial
we can normalize one of the cost parameters to 1 without loss          at time step k and has a Markovian dependence on γk−1 , so
of generality). We assume the cost function to be:                     that with probability α, γk = γk−1 , and probability 1 − α, γk
                                                                       is redrawn from a fixed Beta distribution p0 (γk ). The ob-
      l(τ, δ; d, s, θ, D) = cτ + cs 1{τ<D,s=1} + 1{τ<D,δ6=d,s=0}       servation sk represents the occurrence of a stop trial and is
                            +1{τr =D,s=0}                              assumed to be drawn from a Bernoulli distribution with pa-
                                                                       rameter γk . The predicted      value of γk is the mean of its poste-
   The optimal decision policy minimizes the expected loss,                                   R
                                                                       rior: < γk |sk−1 >= γp(γ|st−1 )dγ. The posterior and iterative
Lπ = E [l(τ, δ; d, s, θ, D)]. It is computationally intractable to     prior of γk can be updated by
directly minimize Lπ over the policy space. Fortunately, Bell-
man’s dynamic programming principle provides an iterative                    p(γ|sk−1 ) = αp(γk−1 = γ|sk−1 ) + (1 − α)p0 (γk = γ)
relationship between the optimal state-value function and op-                 p(γk |sk ) ∝ p(γ|sk−1 )
timal action-value function. The Bellman optimality equation
                                                                          We adapt DBM to model the prior probability of observ-
for optimal state-value function, V t (bt ), is
                          Z
                                                                       ing a Stop trial (as opposed to Go trial) based on trial history
                                                                       (see Figure 2A for a graphical illustration of the generative
         V t (bt ) = min[    P(bt+1 |bt ; a)V t+1 (bt+1 )dbt+1 ]
                        a                                              model, and Figure 2B for simulated dynamics of DBM given
where a ranges over all possible actions. The optimal pol-             a sequence of sample observations). We briefly describe the
icy is to choose the action corresponding to the smallest ac-          model here; more details can be found elsewhere (Yu & Co-
tion cost. Using the Bellman optimality equation for optimal           hen, 2009; Ide et al., 2013).
action-value function, we can obtain the cost functions                Kalman Filter Model for Learning Expected SSD
           Qtg (bt ) = ct + cs pts + (1 − pts )min(ptd , 1 − ptd )     We use a classical linear-Gaussian dynamical systems model,
                                                                       otherwise known as a Kalman Filter (Welch & Bishop, 2006),
          Qtw (bt ) = 1{D>t+1} E V t+1 (bt+1 )|bt bt+1
                                                   
                                                                       to model the trial-by-trial estimation of the mean and vari-
                     + 1{D=t+1} (c(t + 1) + 1 − pts )                  ance of SSD in the stop-signal task. As shown in Figure 2C,
           V (b ) = min(Qtg , Qtw )
              t   t                                                    Kalman Filter tries to estimate the state h of a discrete-time
                                                                       controlled process governed by the linear stochastic equation
Since the observer can no longer update the belief state nor
take any action at the deadline, the optimal state-value func-                            hk = Ahk−1 + Buk−1 + wk−1
tion can be initially computed at D as V t (bD ) = cD + (1 −           with a measurement z which is
pDs ). The recursive relationship between the optimal action-
value and state-value functions in Bellman optimality equa-                                         zk = Hhk + vk
tion allows us to the compute the optimal state-value func-            The random variable wk and vk represent the process and mea-
tions and Q factors backwards in time from t = D − 1 to t = 1.         surement noise, respectively. They are assumed to be inde-
In our simulation, we discretize the space of ptd and ptz each         pendent, white and with normal distribution
into 200 bins.
   With this model, the mean Go RT can be obtained by simu-                                       p(w) ∼ N(0, Q)
lating the model for a certain parameter setting (variability in                                   p(v) = N(0, R)
outcome arises entirely from assumed observation noise, pa-
                                                                       The equation for the Kalman filter consists of two parts: time
rameterized by qd and qs , thus providing a way to study how
                                                                       update equations and measurement update equation. The
the Go RT is related to expectation of environmental statis-
                                                                       time update equation obtains a prior estimate from the next
tics, e.g. P(stop) and E [SSD]. E [SSD] is the mean of geo-
                                                                       time step. ĥ−k is defined as a priori estimate at step k given
metrically distributed prior of SSD (E [SSD] = q1 ) and P(stop)
                                                                       information before step k ,and ĥk as a posteriori estimate at
(P(stop) = r) represents the expectation of the probability of
                                                                       step k given the measurement zk . P̂k− is defined to be a priori
seeing a stop trial.
                                                                       estimate of error covariance and P̂k to be a posterior estimate.
Dynamic Belief Model for learning P(stop)                                                      ĥ−
                                                                                                 k = Aĥk−1 + Buk−1
We use a previously proposed Bayesian hidden Markov
                                                                                               Pk− = APk−1 AT + Q
model, the Dynamic Belief Model (DBM) (Yu & Cohen,
2009; Ide et al., 2013), to model trial-by-trial evolution of          The measurement update equations incorporates a new mea-
prior (and posterior) beliefs about P(stop). We briefly de-            surement into the priori estimate to obtain an improved a pos-
scribe the model here; more details can be found elsewhere             terior estimate of the state.
(Yu & Cohen, 2009; Ide et al., 2013).
                                                                                          Kk = Pk− H T (HPk− H T + R)−1
   Dynamic Belief Model (DBM) was proposed to explain se-
quential effects in reaction time and accuracy in 2AFC tasks,                             ĥk = ĥ−                  −
                                                                                                   k + Kk (zk − H ĥk )
as a function of experienced trial history (Yu & Cohen, 2009).                           Pk− = (I − Kk H)Pk−
                                                                   1448

                                                                      ×10 -3
 (A)                               (B)                1                              (C)                            (D) 0.6
                                                                               2.5                                                                0.07
                                                                                                                                                  0.06
                                                                               2
                                                                                                                                                  0.05
                                     P (sk |s k−1 )                                                                  E[SSD]
                                                                               1.5                                                                0.04
                                                      0.5                                                                 0.3
                                                                                                                                                  0.03
                                                                               1
                                                                                                                                                  0.02
                                                                               0.5                                                                0.01
                                                                                                                          0.1
                                                      0                                                                      0      25       50
                                                          0    25     50
                                                              Trial                                                               Trial
 Figure 2. Bayesian sequential inference model for learning P(stop) and E [SSD]. (A) Graphical model for DBM. γ ∈ [0,1], sk
∈ {0, 1}. p(γk |γk−1 ) = αδ(γk − γk−1 ) + (1 − α)p0 (γk ), where p0 = Beta(a, b). Numbers inside circles indicate example random
variable values. (B) Evolution of predictive probability mass for DBM p(γt |sk−1 ) (grayscale) and its mean, the predictive
probability P(sk = 1|sk−1 ) (cyan), for a randomly generated sample sequence of observations (red dots valued 1 or 0). P(sk =
1|sk−1 ) fluctuates with transient runs of stop (e.g. starting at trial 11) and go trials (e.g. starting at trial 6). Simulation
parameters: α = 0.75, p0 = Beta(2.5, 7.5). (C) Graphical model for the Kalman filter. p(hk |hk−1 ) = N (hk−1 , Q), p(zk |hk ) =
N (hk , R), p(h1 ) = N (h0 , P0 ). Numbers inside circles indicate example random variable values. (D) Evolution of posterior
mean (cyan) and probability mass (grayscale) of SSD over time, for a randomly generated sequence of observations (red
circles) with values in {0.1, 0.2, 0.3, 0.4, 0.5, 0.6}. E [SSD] tends to increase when a number of large SSD have been observed
(e.g. starting at trial 6) and decrease when a number of small SSD (e.g. starting at trial 11) have been observed. Simulation
parameters: Q = 0.03, R = 0.15, h0 = 0.35, P0 = 1. Unless otherwise stated, these parameters are used in all the subsequent
simulation.
In this paper, we use a simple Kalman Filter model, where                            strate how Go RT ought to vary as a function of prior beliefs
B = 0, A = 1 and H = 1, to compute the E [SSD] (ĥ− k ) by in-                       about P(stop) and SSD. Intuitively, we would expect that Go
corporating real observed SSD (zk ) to the filter. Figure 2D                         RT ought to increase as prior P(stop), since the higher prob-
shows simulated dynamics of the Kalman filter given a se-                            ability of encountering a stop signal should make the subject
quence of sample observations.                                                       more willing to wait for the stop signal despite the cost associ-
                                                                                     ated with response delay. We also expect that Go RT ought to
                           Results                                                   increase with E [SSD] for the prior distribution, since expecta-
Our main modeling goal here is to develop a principled ex-                           tion of an earlier SSD should give confidence to the observer
planation for how Go RT ought to vary from trial-to-trial in                         that no stop signal is likely to come after a shorter amount
the stop-signal task. We can then compare model predictions                          of observations and thus respond earlier. Simulations of the
with human data to see whether our assumptions about the                             stochastic control model (Figure 3) shows that Go RT indeed
underlying computational processes hold. There are two key                           increases monotonically with both P(stop) and E [SSD], and
components to the model: (1) how subjects’ beliefs about task                        does so linearly. Note that P(stop) and E [SSD] are specified
statistics vary across trials as a function of previously expe-                      explicitly in the statistical model here (details in the Models
rienced outcomes, and (2) how subjects’ behavioral strategy                          section), so we only need to change these parameters and ob-
within each trial depends on prior beliefs (learned from prior                       serve their normative consequences by running the stochastic
experience). For the first component, we separately model                            control model.
the evolution of subjects’ beliefs about the frequency of stop                          Next, we want to examine how subjects’ actual Go RT
trials, P(stop), using a Bayesian hidden Markov model known                          varies with prior beliefs about P(stop) and SSD. Since the
as the Dynamic Belief Model (DBM), and their beliefs about                           experiment does not explicitly manipulate the baseline fre-
the temporal onset of the stop signal, stop-signal delay (SSD),                      quency of stop signals or SSD, we estimate these psychologi-
using a Kalman Filter model. For the second component, we                            cal quantities by assuming that subjects continuously modify
use an optimal stochastic control model to predict when and                          their prior beliefs according to experienced trial history. We
whether the subject produces a GO response on each trial, as                         apply the across-trial learning models to a subject’s experi-
a function of prior beliefs about P(stop) and SSD, dynami-                           enced sequence of go/stop trials and SSD to estimate their
cally evolving posterior beliefs about the type of Go stimulus                       priors on each trial, and then plot how Go RT varies with
and presence of stop signal, as well as the relative cost of                         the model-based estimates of P(stop) and E [SSD] Figure 4
GO now and WAIT another time-step depending on the ex-                               shows that the subjects’ Go RT increases approximately lin-
pected costs associated with making a go (discrimination or                          early with prior P(stop) and E [SSD], just as predicted by the
omission) error, a stop error (not stopping on a stop trial), and                    model (Figure 3). These result imply that subjects both con-
response delay (Shenoy & Yu, 2011) . Details of the model                            tinuously monitor and update internal representations about
can be found in the Models section.                                                  environmental statistics, and adjust their behavioral strategy
   We first simulate the stochastic control model to demon-                          rationally according to those evolving representations.
                                                                           1449

 (A)         42                                  (B)         41                                  (C)
                                                                                                                                         44
                                                                                                   Go RT (steps)
             40                                              40                                               50
  Go RT (steps)                                   Go RT (steps)
                                                                                                                                         42
             38                                              39                                                                          40
                                                                                                              40
             36                                              38                                                                          38
                                                                                                              30                         36
             34                                              37
                                                                                                                   0.5              15   34
             32                                              36                                           P(stop)        0 5
                                                                                                                               10
               0   0.2     0.4     0.6     0.8                 5     10          15         20                                  E[SSD]
                         P(stop)                                      E[SSD]
 Figure 3. Model prediction of Go RT versus P(stop) and E [SSD]. (A) Go RT vs. P(stop): simulated Go RT for a ranged of
P(stop) values (.1, .15, ..., .75). Data averaged over 10000 simulated Go trials for each value of P(stop). Straight line denotes
best linear fit. Error bars denote s.e.m. 1/q = E [SSD] = 10. (B) Go RT vs. E [SSD]: simulated Go RT for a range of SSD values
(8, 9, ..., 18). Data averaged over 10000 simulated Go trials for each value of E [SSD]. Straight line denotes best linear fit. Error
bars denote s.e.m. P(stop) = 0.45. (C) Go RT vs. P(stop) and E [SSD]: simulated Go RT for a range of P(stop) and E [SSD])
values, where P(stop) varies between .1 and .75, and E [SSD] varies between 8 and 18. Data averaged over 10000 simulated Go
trials for each (P(stop), E [SSD]). Simulation parameters for A-C: qd = 0.55, qs = 0.72, D = 50, cs = 0.4, c = 0.002. Initial string
of Go trials in each block (on average 3 trials, 1/4 time none at all) are excluded from all analyses, as subjects’ initial beliefs
about task statistics may vary widely and unpredictably before any stop trials are observed.
                          Discussion                                      1997; Nigg, 2000). Stopping behavior is also known to be
In this paper, we presented a rational inference, learning, and           impaired in a number of psychiatric populations with pre-
decision-making model of inhibitory control, which can ac-                sumed inhibitory deficits, such as attention-deficit hyperac-
count for significant variability of human RT in the stop-                tivity disorder (Alderson, Rapport, & Kofler, 2007), sub-
signal task. Unlike most previous models of human response                stance abuse (Nigg et al., 2006), and obsessive-compulsive
time, which assumes RT variability to be due to irreducible               disorder (Menzies et al., 2007). The work shown here
noise, we conclude that this variability is largely driven by             elucidates the psychological and potential neural underpin-
fluctuations in experienced empirical statistics, which ob-               nings of inhibitory control, and makes powerful predictions
servers use to continuously update their internal representa-             that can be validated using experimental methods. For ex-
tion of environmental statistics and rationally adjust their be-          ample, this work can investigate how different individuals’
havioral strategy as needed.                                              ability to represent and respond to those expectations, e.g.
                                                                          P(stop) and E [SSD], may be correlated with eventual devel-
   The reader may well wonder why we choose to use a dif-
                                                                          opment/absence of abusive stimulant behavior, as we have al-
ferent model for capturing sequential effects in SSD (Kalman
                                                                          ready done in some previous work in collaboration with neu-
Filter) than for P(stop) (DBM). The Kalman Filter primarily
                                                                          roimaging researchers (Ide et al., 2013; Harlé et al., 2014).
differs from DBM in that the hidden variable s is assumed
to undergo (noisy) continuous dynamics, such that the mean
                                                                                             Acknowledgments
of the new variable is centered at the old s (it is a Martin-
gale process), whereas DBM assumes that the new hidden                    We are grateful to Pradeep Shenoy and Joseph Schilz for
variable s is either identical to its value at the last time step,        helping to collect data in the stop-signal task, and to Pradeep
or redrawn from a generic prior distribution p0 (s), which is             Shenoy for preliminary discussions on how to model sub-
identical on each trial. This means that hidden variables dy-             jects’ evolving beliefs about SSD. Funding was provided in
namics in DBM are not Martingale, and the variable s can                  part by an NSF CRCNS grant (BCS- 1309346) to AY.
readily undergo large, discrete jumps, which are not likely
in the Kalman Filter. We used both the Kalman Filter and                                           References
an adapted version of DBM to model subjects’ beliefs about                Alderson, R. M., Rapport, M. D., & Kofler, M. J. (2007).
E [SSD], and found that the Kalman Filter does a significantly              Attention-deficit hyperactivity disorder and behavioral
better of accounting for trial-by-trial variability in RT than              inhibition: A meta-analytic review of the stop-signal
does DBM (data not shown).                                                  paradigm. Journal of Abnormal Child Psychology, 35(5),
   The work is also important for making a substantial con-                 745–58.
tribution in advancing the understanding of inhibitory con-               Barkley, R. A. (1997). Behavioral inhibition, sustained at-
trol. Inhibitory control, the ability to dynamically modify                 tention, and executive functions: Constructing a unifying
or cancel planned actions according to ongoing sensory pro-                 theory of ADHD. Psychological bulletin, 121(1), 65-94.
cessing and changing task demands, is considered a fun-                   Bogacz, R., Brown, E., Moehlis, J., Hu, P., Holmes, P., &
damental component of flexible cognitive control (Barkley,                  Cohen, J. D. (2006). The physics of optimal decision
                                                                   1450

 (A)          0.7                    (B) 0.66                                      (C)                                                 (D)
                                                                                             0.8                                                      0.7
                                                                                                                                         Go RT (s)
                                                                                     Go RT (s)
                                                0.64
  Go RT (s)
         0.65                                                                                                                                        0.65
                                         Go RT (s)
                                                                                             0.7
                                                                                                                                                      0.6
                                                0.62
                                                                                             0.6
              0.6                                                                                                                                    0.55
                                                                                                                                                      0.4
                                                     0.6                                                                                                                          0.6
                                                                                                                                                            0.3             0.4
                                                                                                    0.4
                                                                             0.6                           0.3                   0.6                  P(stop)     0.2 0.2
         0.55                                   0.58                                             P(stop)                   0.4                                              E[SSD]
            0.2     0.25    0.3   0.35                     0.2   E(SSD)
                                                                     0.4    0.6                                  0.2 0.2     E[SSD]
                      P(stop)                                    E[SSD]
 Figure 4. Human Go RT versus model-estimated P(stop) and SSD. (A) Go RT vs. P(stop): P(stop) on each trial estimated by
DBM based on actual sequence of stop/go trials the subject experienced prior to the current trial. Binning of E [SSD] spaced to
ensure equal number of data points in each bin. Straight line denotes best linear fit of average Go RT for each bin versus average
P(stop) for each bin. Linear regression of group data: R2 = 0.97, p < 0.0001. Error bars denote s.e.m. DBM parameters: α =
0.75, p0 = Beta(2.5, 7.5). (B) Go RT vs. E [SSD]: E [SSD] on each trial estimated by a Kalman filter based on actual sequence of
SSD the subject experienced prior to the current trial. Binning of E [SSD] spaced to ensure equal number of data points in each
bin. Straight line denotes best linear fit between average Go RT versus average E [SSD] for each bin. Linear regression of group
data: R2 = 0.52, p = 0.0003. Error bars denote s.e.m. Kalman filter (KF) parameters: Q = 0.03, R = 0.15, h0 = .35, P0 = 1.
(C) Go RT vs. P(stop) and E [SSD]: P(stop) and E [SSD] are equally discretized into 5 bins between minimum and maximum
”observed” values (by applying the model to subjects’ experienced sequence of trials). Each point in the grid contains RT data
from all trials and all subjects where P(stop) and E [SSD] fell within corresponding bins. (D) Fitted surface plot of the scatter
plot in (C), by applying Matlab function griddata(...,0 v40 ), a biharmonic spline interpolation method, to the data in (C).
  making: A formal analysis of models of performance in                          order. Brain, 130(12), 3223-36.
  two-alternative forced choice tasks. Psychological Review,                   Nigg, J. T. (2000). On inhibition/disinhibition in develop-
  113(4), 700-65.                                                                mental psychopathology: Views from cognitive and per-
Emeric, E. E., Brown, J. W., Boucher, L., Carpenter, R. H. S.,                   sonality psychology and a working inhibition taxonomy.
  Hanes, D. P., Harris, R., . . . others (2007). Influence of                    Psychological Bulletin, 126(2), 220-46.
  history on saccade countermanding performance in humans                      Nigg, J. T., Wong, M. M., Martel, M. M., Jester, J. M., Put-
  and macaque monkeys. Vision Research, 47(1), 35-49.                            tler, L. I., Glass, J. M., . . . Zucker, R. A. (2006). Poor
Gold, J. I., & Shadlen, M. N. (2002). Banburismus and the                        response inhibition as a predictor of problem drinking and
  brain: decoding the relationship between sensory stimuli,                      illicit drug use in adolescents at risk for alcoholism and
  decisions, and reward. Neuron, 36, 299-308.                                    other substance use disorders. Journal of Amer Academy
Harlé, K. M., Shenoy, P., Steward, J. L., Tapert, S., Yu*, A. J.,               of Child & Adolescent Psychiatry, 45(4), 468-75.
  & Paulus*, M. P. (2014). Altered neural processing of the                    Ratcliff, R., & Rouder, J. N. (1998). Modeling response
  need to stop in young adults at risk for stimulant depen-                      times for two-choice decisions. Psychological Science, 9,
  dence. Journal of Neuroscience, 34, 4567-4580. (*Yu and                        347-56.
  Paulus are co-senior authors)                                                Shenoy, P., & Yu, A. J. (2011). Rational decision-making in
Ide, J. S., Shenoy, P., Yu*, A. J., & Li*, C.-R. (2013).                         inhibitory control. Frontiers in Human Neuroscience. (doi:
  Bayesian prediction and evaluation in the anterior cingu-                      10.3389/fnhum.2011.00048)
  late cortex. Journal of Neuroscience, 33, 2039-2047. (*Yu                    Smith, P. L. (1995). Psychophysically principled models of
  and Li contributed equally as senior authors)                                  visual simple reaction time. Psychol. Rev., 10, 567-93.
Laming, D. R. J. (1968). Information theory of choice-                         Welch, G., & Bishop, G. (2006). An introduction to the
  reaction times. London: Academic Press.                                        kalman filter.
Leotti, L. A., & Wager, T. D. (2009). Motivational influences                  Yu, A. J., & Cohen, J. D. (2009). Sequential effects: Supersti-
  on response inhibition measures. J. Exp. Psychol. Hum.                         tion or rational behavior? Advances in Neural Information
  Percept. Perform., 36(2), 430-447.                                             Processing Systems, 21, 1873-80.
Logan, G., & Cowan, W. (1984). On the ability to inhibit                       Yu, A. J., & Huang, H. (2014). Maximizing masquerading
  thought and action: A theory of an act of control. Psych.                      as matching: Statistical learning and decision-making in
  Rev., 91, 295-327.                                                             choice behavior. Decision, 1(4), 275-287.
Luce, R. D. (1986). Response times: Their role in inferring
  elementary mental organization. New York: Oxford Uni-
  versity Press.
Menzies, L., Achard, S., Chamberlain, S. R., Fineberg, N.,
  Chen, C. H., del Campo, N., . . . Bullmore, E. (2007). Neu-
  rocognitive endophenotypes of obsessive-compulsive dis-
                                                                           1451

