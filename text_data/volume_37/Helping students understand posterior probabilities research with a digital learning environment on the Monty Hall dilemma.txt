                            Helping Students Understand Posterior Probabilities:
        Research with a Digital Learning Environment on the Monty Hall Dilemma
                                        Lore Saenena (Lore.Saenen@ppw.kuleuven.be),
                                   Mieke Heyvaerta (Mieke.Heyvaert@ppw.kuleuven.be),
                                 Wim Van Doorenb (Wim.VanDooren@ppw.kuleuven.be),
                                 & Patrick Onghenaa (Patrick.Onghena@ppw.kuleuven.be)
                         a
                           Methodology of Educational Sciences, KU Leuven, Tiensestraat 102, 3000 Leuven
                  b
                    Instructional Psychology and Technology, KU Leuven, Dekenstraat 2, 3000 Leuven, Belgium
                              Abstract                                    Previous research on the MHD has provided strong
                                                                       evidence for the following four findings. First, there exists a
  When initially confronted with the Monty Hall dilemma
  (MHD), people show a very strong tendency to stick with              strong sticking tendency: When first confronted with the
  their initial choice, although switching maximizes winning           dilemma, the vast majority of participants choose to stay
  chances. Previous research demonstrated that certain                 with the initial choice (Burns & Wieth, 2004; Friedman,
  interventions helped participants to discover and apply the          1998; Granberg & Brown, 1995; Granberg & Dorr, 1998).
  optimal strategy, but generally failed to increase participants’     Cross-cultural research revealed that staying percentages
  understanding of the MHD solution. An exception on the               range between 79% and 87% (Granberg, 1999). These high
  latter finding is DiBattista’s (2011) digital learning
  environment study, reporting that the majority of participants
                                                                       percentages indicate how extremely counterintuitive the
  who used the learning environment learned to understand the          MHD solution is.
  MHD solution. However, a major shortcoming was                          Second, participants have a strong belief that their choice
  DiBattista’s (2011) methodology, which did not allow to infer        – either staying or switching – does not matter, because they
  causal relations and to conclude which (combination of)              consider both posterior probabilities as being equal (Franco-
  manipulation(s) was most important for participants’                 Watkins, Derks, & Dougherty, 2003; Granberg & Brown,
  understanding of the MHD solution. The aim of the present            1995; Stibel, Dror, & Ben-Zeev, 2009). Participants’
  study was to fill this research gap by conducting a controlled
  randomized experiment with an analogous digital learning             preference to stay with their initial choice, despite the fact
  environment. Participants were high-school students between          that they judge winning probabilities for staying and
  16 and 19 years old. The results showed that receiving               switching as equally large, can be explained by the larger
  explanation about the MHD solution was the most important            amount of regret participants anticipate to experience after a
  manipulation to improve understanding. Implications for              loss due to switching compared with a loss due to staying
  education in (posterior) probability are discussed.                  (Stibel et al., 2009).
  Keywords: Monty Hall dilemma; probability; posterior                    Third, previous research has shown that many factors can
  probability; digital learning environment; experience-based          alter participants’ sticking tendency. For example, switching
  learning; traditional learning                                       behavior is more likely to occur when more alternatives are
                                                                       included in the problem compared with only three
                           Introduction                                alternatives in the classic MHD (Burns & Wieth, 2004;
The Monty Hall dilemma (MHD) was adapted from the                      Franco-Watkins et al., 2003; Saenen, Heyvaert, Grosemans,
popular TV game show Let’s Make a Deal and is known as                 Van Dooren, & Onghena, 2014; Stibel et al., 2009). Also
one of the most counterintuitive posterior probability                 repeated experience with the problem has a strong impact:
problems (Friedman, 1998). In the classic version of the               When participants are given a series of MHD trials,
MHD, a guest is confronted with three identical doors. One             switching rates increase across trials, showing that people
door conceals a valuable prize, usually a car. The two                 adjust their behavior to increase the gain (e.g., Franco-
remaining doors conceal worthless prizes such as goats.                Watkins et al., 2003; Petrocelli, 2013; Petrocelli & Harris,
After the guest initially chooses one door, the host, who is           2011; Saenen, Van Dooren, & Onghena, 2015a).
aware of the location of the prize, opens a non-chosen door            Importantly, none of these studies, containing the repeated
to show that there is a worthless prize behind it. Next, the           experience with the dilemma, led participants to consistently
guest faces a dilemma when the host asks him to either stay            switch on all trials. Thus, optimal behavioral performance
with his initial choice, or to switch to the other unopened            was not observed.
door. By applying Bayes’ Theorem with the correct prior                   Fourth, there exists a dissociation between participants’
and marginal likelihoods, it can be derived that switching is          behavioral MHD performance and their understanding of
the strategy that maximizes the probability to win the                 the problem’s solution. Some studies did not only examine
valuable prize. More specifically, switching yields a                  participants’ behavioral MHD performance, but also asked
posterior winning probability of 2/3, whereas staying only             participants to estimate the posterior probabilities in order to
yields a 1/3 posterior winning probability.                            investigate their MHD understanding (Burns & Wieth,
                                                                       2003, 2004; DiBattista, 2011; Franco-Watkins et al., 2003;
                                                                   2057

Saenen et al., 2014, 2015a; Saenen, Heyvaert, Van Dooren,           the digital learning environment statistically significantly
& Onghena, 2015b; Stibel et al., 2009). The results showed          more often gave a satisfactory explanation for why
that although behavioral performance was easily improved            switching was beneficial, compared to those who never
by adding particular interventions, correct posterior               accessed it (62.7% and 6.2% respectively). No other
probability estimates ranged from 0% to 50%. Thus, overall,         empirical study so far ever reported percentages of
participants still failed to understand the MHD and its             participants understanding the MHD solution as high as
underlying probabilities (Burns & Wieth, 2003, 2004;                61.2% and 62.7%.
Franco-Watkins et al., 2003; Saenen et al., 2014, 2015a,               A major shortcoming to DiBattista’s (2011) study is that
2015b; Stibel et al., 2009).                                        the characteristics that were designed to promote the
   DiBattista (2011) developed a digital learning                   understanding of the MHD solution were not systematically
environment aimed at tackling people’s general inability to         manipulated between (or within) participants. Next, the
understand to MHD solution. Its characteristics were                study was not conducted in a controlled environment, and
specially designed to increase people’s understanding of the        its use was not experimentally manipulated. Moreover,
MHD solution and can be described as follows. First, in the         participants’ use of the digital learning environment was
‘playing’ part, one could complete as many trials as one            self-selected and thus not randomly assigned. Thus, it is
wanted of both a 3-door and 20-door MHD. After each trial,          impossible to infer causal relations and to conclude which
feedback about the number of trials one had won and lost,           (combination of) manipulation(s) was most important to
conditional on the behavior (i.e., staying or switching), was       improve participants’ understanding of the MHD solution.
updated. Second, in the ‘simulation’ part, one could ask the           To investigate that question, we developed our own MHD
computer to generate N trials of both a 3-door and 20-door          digital learning environment, analogous to the one
MHD and choose the desired type of behavior (i.e., always           developed by DiBattista (2011), and conducted various
staying, always switching, or alternating between staying           controlled randomized experiments. This paper presents the
and switching). In this part, constantly updated feedback           results of our first experiment, in which we examined the
was also provided. Third, in the ‘explanation’ part, one            effects of both repeated experience with the MHD and
could access explanations for both the 3-door and 20-door           explanation. The choice for the inclusion of repeated
MHD solution.                                                       experience was made because there is already a lot of
   In DiBattista’s (2011) study, participants solved the            research literature available on this manipulation (e.g.,
classic MHD in paper-and-pencil format as a pretest                 Franco-Watkins et al., 2003; Petrocelli, 2013; Petrocelli &
measure. Participants were asked to indicate the optimal            Harris, 2011; Saenen et al., 2015a), which makes it easy to
behavioral response in order to win the prize (staying,             compare our results. The choice for the inclusion of
switches, or it makes no difference) and to explain in detail       explanation about the MHD solution as a manipulation was
their reasoning behind their chosen response. Next, the             made because of the practical relevance for education (see
participants were motivated to use the digital learning             discussion section).
environment with unlimited access for a period of five
weeks. Hereafter, the participants completed a 6-door                                         Methods
variant of the MHD as a posttest measure. Another four
weeks later (i.e., nine weeks after the pretest), participants      Participants and Design
again completed the classic MHD – identical to the pretest –
as a follow-up measure. The results of DiBattista’s (2011)          Two-hundred and thirteen Flemish high-school students
pretest-posttest study revealed that at the pretest, only 4.5%      participated in the experiment. Seventy-eight of them were
                                                                    excluded from the data analyses because of prior familiarity
of the participants correctly indicated switching as the
                                                                    with the MHD. As a result, our final sample consisted of
optimal behavioral response and none of them could give a
satisfactory explanation for why switching was beneficial.          135 participants (80 females, 55 males; age range: 16-19
For the posttest and follow-up measure, the answers of              years, Mage = 16.92, SDage = 0.54).
participants who accessed the digital learning environment            Participants were randomly assigned to one of four
at least once were compared with the answers of those who           conditions, created by a 2 × 2 between-subjects design. The
never accessed it. The results were impressive: At the              first independent variable was ‘Explanation’ and indicated
posttest, participants who accessed the digital learning            whether or not participants could access the ‘explanation
environment gave the optimal behavioral response and a              part’ of the MHD game. The second independent variable
satisfactory explanation statistically significantly more often     was ‘Playing’ and indicated whether or not participants
compared with participants who never accessed it (77.5%             could access the ‘playing part’ of the MHD game. This led
and 61.2% vs. 41.4% and 13.8% respectively). At the                 to the following four conditions: control condition (neither
follow-up, no statistically significant difference was found        explanation nor playing), ‘playing only’ condition (playing,
on how often the optimal behavioral response was given              but no explanation), ‘explanation only’ condition
between participants who accessed the digital learning              (explanation, but no playing), ‘playing and explanation’
environment and those who never accessed it (89.4% and              condition (both playing and explanation). Data of
87.5% respectively). However, participants who accessed             respectively 28, 38, 34, and 35 participants were included in
                                                                    the analyses.
                                                                2058

  The study protocol was approved by the Ethical                       stepwise by providing little information at a time on each
Committee of the KU Leuven − University of Leuven.                     screen. Both forward and backward navigation was possible
                                                                       in the ‘explanation’ part.
Materials                                                                When opening the digital learning environment, a
The following materials were used in the study: a paper-               description of the classic MHD was always presented first
and-pencil questionnaire operating as the pretest measure,             in which all necessary elements were mentioned: the host,
another paper-and-pencil questionnaire operating as the                the three doors, the random location of the prize, the
posttest measure, and a digital learning environment.                  participant’s initial choice, followed by the host opening
  Our pretest questionnaire included the classic MHD, as in            another door than the one chosen by the participant showing
DiBattista’s (2011) study. Participants were asked to answer           it did not contain the prize, and ultimately the participant’s
three questions. First, participants were asked to indicate the        final choice. Next, the same description was given for a 20-
optimal behavioral response (i.e., question 1) by choosing             door MHD variant in which the host, after the participant
between one of three options: staying, switching, or it does           made an initial choice, opened 18 other doors that did not
not matter. This behavioral response question was the same             contain the prize. After navigating through the descriptions
as in DiBattista’s (2011) study. Unlike DiBattista (2011),             of both the classic MHD and the 20-door MHD variant, the
we operationalized understanding of the MHD solution by                participant got to see a menu bar that listed the specific parts
asking participants to estimate the posterior winning                  of the digital learning environment the participant could use.
probability for both staying (i.e., question 2) and switching          Which parts were listed in the menu bar depended on the
(i.e., question 3), instead of letting them explain their              condition a participant was assigned to. For example, a
reasoning behind the behavioral response answer they gave              participant assigned to the ‘playing only’ condition only saw
on question 1.                                                         the ‘playing: 3 doors’ and the ‘playing: 20 doors’ parts
  In our posttest questionnaire, we included the items that            listed in the menu bar, whereas a participant assigned to the
DiBattista (2011) used for his posttest and follow-up                  ‘explanation only’ condition only saw the ‘explanation: 3
measure. Thus, our own posttest questionnaire included two             doors’ and the ‘explanation: 20 doors’ parts. Thus, in
items. The first item was a 6-door MHD variant with one                contrast to DiBattista’s (2011), in our digital learning
prize (cf. DiBattista’s (2011) posttest), in which the                 environment, it was possible to limit participants’ access to
participant initially selected two doors, the host then opened         particular parts of the learning environment. Also in contrast
three other non-winning doors, and the participant then was            with DiBattista (2011), it was possible to set time
faced with the dilemma to either stay with his two initially           limitations on the use of our digital learning environment.
selected doors (winning the prize when located behind one              These adaptions were made in order to conduct controlled
of those two doors), or to switch to the one remaining                 randomized experiments.
unopened door. Note that the posterior probabilities of this
6-door MHD variant are equal to the posterior probabilities            Procedure
of the classic MHD: Staying leads to winning the prize in              Participants came to the laboratory in groups of eight for the
1/3 of the cases, while switching yields a 2/3 winning                 experiment. Before the start of each experimental session,
probability. The second item of our posttest questionnaire             the experimenter placed an informed consent form and a
was the classic MHD (cf. DiBattista’s (2011) follow-up                 laptop on eight separate tables. Tables and seats were placed
measure), completely identical to the item of the pretest              so that no interaction was possible between participants.
questionnaire. For both items of our posttest questionnaire,              Upon arriving, the experimenter asked the participants to
participants were asked to complete the same three                     take place at one of the eight tables on which there was an
questions as in our pretest questionnaire. Summarized, for             informed consent form. Participants were randomly
all MHD items there were three dependent variables. The                assigned to the experimental conditions, with the limitation
first dependent variable was the behavioral response, the              that in each experimental session two participants were
second one was the posterior winning probability for                   assigned to each of the four different conditions. After
staying, and the third one was the posterior winning                   completing the informed consent form, participants received
probability for switching.                                             the pretest questionnaire. Next, the six participants that were
  The MHD digital learning environment we created1 was                 assigned to an experimental condition (i.e., ‘playing only’
analogous to the one developed by DiBattista (2011) and                condition, ‘explanation only’ condition, or ‘playing and
contained the same three major parts: a ‘playing’ part, a              explanation’ condition) were asked to use the digital
‘simulation’ part, and an ‘explanation’ part. In the ‘playing’         learning environment for a duration of 20 minutes.
and ‘simulation’ parts, feedback about the number of trials                How the participants exactly spent and divided those 20
one had won or lost, conditional on the behavior (i.e.,                minutes between the different parts of the digital learning
staying or switching), was constantly updated and provided.            environment that were made available, was up to the
In the ‘explanation’ part, the MHD solution was explained              participants themselves. After 20 minutes, the digital
                                                                       learning environment automatically stopped working. Next,
                                                                       the participants received the posttest questionnaire from the
1
  Researchers interested in using our digital learning environment     experimenter. During the 20 minutes that the six
for research and/or educational purposes can contact the authors.
                                                                   2059

participants assigned to an experimental condition used the                          Table 2: Logistic regression analysis results for variables
digital learning environment, the two participants assigned                        predicting outcomes on the classic MHD pretest questions.
to the control condition immediately completed the posttest
                                                                                                     β      SE β     OR     95% Wald       Wald
questionnaire. Afterwards, they were asked to use the digital                                                                  CI          χ²(1)
learning environment as well (with unlimited access) so that                   Optimal behavior
they would keep quiet during the remaining time of the                           Play              0.37     0.57     1.44 [-0.76; 1.49]      0.40
experimental session. An entire experimental session lasted                      Explain          -0.75     0.68     0.47 [-2.08; 0.57]      1.24
approximately 50 minutes.                                                        Play*Explain      0.68     0.89     1.97 [-1.08; 2.43]      0.57
                                                                               P (win | stay)
Statistical Analysis                                                             Play             -0.03     0.75     0.97 [-1.51; 1.44]      0.00
                                                                                 Explain           0.09     0.75     1.10 [-1.38; 1.56]      0.02
To investigate participants’ behavioral responses and
                                                                                 Play*Explain -0.58         1.04     0.56 [-2.63; 1.46]      0.31
understanding of the underlying posterior probabilities of                     P (win | switch)
the MHD, we performed a logistic regression analysis with                        Play             -0.73     0.90     0.48 [-2.50; 1.04]      0.65
‘Explanation’, ‘Playing’, and the interaction between                            Explain          -0.28     0.95     0.75 [-2.14; 1.57]      0.09
‘Explanation’ and ‘Playing’ as predictors. The significance                      Play*Explain      0.39     1.25     1.48 [-2.05; 2.83]      0.10
level was set at α = .05. To follow up on statistically                        Note. β = unstandardized β coefficients; SE = standard error; OR =
significant effects, post-hoc pairwise comparisons were                        odds ratio; CI = confidence interval.
performed using a Tukey-Kramer (HSD) correction.
                                                                               Posttest: Classic MHD
                         Results                                               For the 3-door MHD in the posttest Table 1 clearly shows
                                                                               that in all experimental conditions participants performed
Pretest: Classic MHD                                                           better compared with participants assigned to the control
For each dependent variable and each of the four conditions,                   condition. Participants assigned to the ‘playing and
percentages correct answers are presented in Table 1. As                       explanation’ condition performed best on the optimal
can be derived from Table 1, participants performed poorly                     behavioral response question, whereas participants assigned
on both the behavioral response question and the posterior                     to the ‘explanation only’ condition performed best on both
probability estimate questions during the pretest.                             posterior probability questions.
  The results of the logistic regression analyses (see                           First, the results of the logistic regression analyses (see
Table 2) showed no statistically significant differences                       Table 3) showed a statistically significant main effect of
between the conditions before the intervention started,                        Explanation on behavioral response, Wald χ²(1) = 6.32, p =
which is consistent with our random assignment scheme.                         .012. The odds ratio equaled 7.61, meaning that it is 7.6
                                                                               times more probable that a participant indicates switching as
   Table 1: Percentages correct answers given on the items                     the optimal behavioral response when assigned to a
       of both the pretest and posttest questionnaire.                         condition with explanation compared to a condition without
                                                                               explanation. Second, there were also statistically significant
                                             Condition                         main effects of Explanation on the posterior winning
                                                                               probability when staying and when switching questions,
                                                                               Wald χ²(1) = 10.89, p = .001, OR = 5.91, and Wald χ²(1) =
                                      Explanation             Explanation      11.47, p = .001, OR = 6.06, respectively. Those odds ratios
                            Control
                                                    Playing                    mean that it is approximately 6 times more probable that a
                                      only          only      and playing      participant gives a correct posterior winning probability
Dependent variable                                                             estimation for both staying and switching when assigned to
Pretest: Classic MHD                                                           a condition with explanation compared to a condition
   Optimal behavior         25.0        26.5        10.5        20.0           without explanation. Finally, there was a statistically
   P (win | stay)           17.9        11.8        10.5        11.4           significant interaction effect on the posterior winning
   P (win | switch)         10.7        11.8         7.9         5.7           probability when switching question, Wald χ²(1) = 3.87, p =
Posttest: Classic MHD                                                          .049, OR = 6.19. To follow up on this interaction effect,
   Optimal behavior         25.0        88.2        68.4        94.3           post-hoc pairwise comparisons (HSD) revealed that the
   P (win | stay)           17.9        84.8        39.5        79.4           following comparisons reached statistical significance.
   P (win | switch)         10.7        81.8        21.1        61.8           Participants in the ‘explanation only’ condition more often
Posttest: 6-door MHD                                                           gave the correct answer on the posterior winning probability
   Optimal behavior         28.6        76.5        39.5        62.9           when switching question compared with participants
   P (win | stay)           28.6        70.6        43.2        66.7           assigned to the ‘playing only’ condition, p < .001, OR =
   P (win | switch)         46.4        73.5        18.9        54.5           11.905, and compared with participants assigned to the
                                                                               control condition, p < .001, OR = 3.205. In addition,
                                                                               participants in the ‘playing and explanation’ condition more
                                                                               often correctly answered the posterior winning probability
                                                                            2060

when switching question compared with participants                      participant indicates switching as the optimal behavioral
assigned to the ‘playing only’ condition, p < .001, OR =                response and gives the correct answer on the posterior
5.143, and compared with participants assigned to the                   winning probability when switching question when assigned
control condition, p < .001, OR = 1.385.                                to a condition with explanation compared to a condition
                                                                        without explanation.
Posttest: 6-door MHD
For the 6-door MHD variant in the posttest Table 1                                               Discussion
demonstrates that especially participants assigned to the               Previous research on the MHD demonstrated that although
‘playing and explanation’ condition and the ‘explanation                participants’ behavioral performance could be enhanced by
only’ condition performed better compared with the control              particular interventions, participants’ understanding of the
condition. Participants assigned to the ‘explanation only’              MHD solution did not improve very much (Burns & Wieth,
condition performed best on all three questions.                        2003, 2004; Franco-Watkins et al., 2003; Saenen et al.,
    The logistic regression analyses (see Table 4) indicated            2014, 2015a, 2015b; Stibel et al., 2009). So far, only
statistically significant main effects of Explanation on                DiBattista’s (2011) study showed a major increase in
behavioral response, Wald χ²(1) = 3.91, p = .048, OR =                  participants’ understanding of the MHD solution. In his
2.60, and on the posterior winning probability for switching            study, participants used an MHD digital learning
question, Wald χ²(1) = 8.99, p = .003, OR = 5.14. Thus, it              environment, developed to improve participants’
is respectively 2.6 and 5.1 times more probable that a                  understanding of the problem’s solution. The problem with
                                                                        DiBattista’s (2011) study, however, is that it could not
    Table 3: Logistic regression analysis results for variables         answer the question which (combination of) manipulation(s)
 predicting outcomes on the classic MHD posttest questions.             of the digital learning environment exactly was most helpful
                      β    SE β     OR     95% Wald         Wald        to increase participants’ understanding of the MHD
                                                CI          χ²(1)       solution. This is because his study was not conducted in a
Optimal behavior                                                        controlled environment, the several characteristics of the
   Play              0.79 0.90 2.20 [-0.98; 2.56]           0.76        digital learning environment were not experimentally
                                                                 *
   Explain           2.03 0.81 7.61        [0.45; 3.61]     6.32        manipulated, and there was no random assignment of his
   Play*Explain      1.08 1.06 2.95 [-1.00; 3.16]           1.04        participants.
P (win | stay)                                                            With the present study, we aimed to fill (part of) this
   Play             -0.37 0.64 0.69 [-1.64; 0.89]           0.33        research gap and to extend DiBattista’s (2011) research. To
                                                                 **
   Explain           1.78 0.54 5.91        [0.72; 2.83]    10.89        this end, we developed our own digital learning
   Play*Explain      1.47 0.88 4.35 [-0.25; 3.19]           2.82        environment – analogous to the one developed by DiBattista
P (win | switch)                                                        (2011) – in which it was possible to limit participants’
   Play             -1.03 0.57 0.36 [-2.15; 0.10]           3.20        access to particular parts of the learning environment so that
                                                                 **
   Explain           1.80 0.53 6.06        [0.76; 2.84]    11.47
                                                                  *     it would be possible to conduct controlled randomized
   Play*Explain      1.82 0.93 6.19        [0.01; 3.64]     3.87
                                                                        experiments and next, to infer causal relations. The current
Note. β = unstandardized β coefficients; SE = standard error; OR =
                                                                        paper reports on the first experiment we carried out, in
odds ratio; CI = confidence interval.
*         **
  p < .05. p < .01.
                                                                        which we focused on two out of the three major parts of the
                                                                        digital learning environment: repeated experience with the
                                                                        MHD and explanation about the MHD solution.
    Table 4: Logistic regression analysis results for variables
                                                                           First, the results of our experiment are consistent with
 predicting outcomes on the 6-door MHD posttest questions.
                                                                        previous research on the MHD. At the pretest measure,
                      β    SE β     OR     95% Wald         Wald        participants in all conditions massively failed to indicate the
                                                CI          χ²(1)       optimal behavioral response (see Burns & Wieth, 2004;
Optimal behavior                                                        Friedman, 1998; Granberg, 1999; Granberg & Brown, 1995;
   Play             -0.65 0.53 0.52 [-1.70; 0.40]           1.49        Granberg & Dorr, 1998) and to give correct posterior
                                                                 *
   Explain           0.95 0.48 2.60        [0.01; 1.90]     3.91        winning probability estimates (see Burns & Wieth, 2003,
   Play*Explain      1.14 0.76 3.13 [-0.34; 2.62]           2.28
                                                                        2004; Franco-Watkins et al., 2003; Saenen et al., 2014,
P (win | stay)
                                                                        2015a, 2015b; Stibel et al., 2009). Next, the results of our
   Play             -0.18 0.53 0.83 [-1.22; 0.85]           0.12
   Explain           0.97 0.50 2.62 [-0.01; 1.94]           3.78        posttest measure showed that when participants completed a
   Play*Explain      0.83 0.75 2.29 [-0.64; 2.30]           1.21        series of MHD trials without receiving further explanation
P (win | switch)                                                        about the MHD solution (i.e., ‘playing only’ condition),
   Play             -0.84 0.52 0.43 [-1.86; 0.19]           2.58        their behavioral response improved, but the majority of
                                                                 **
   Explain           1.64 0.55 5.14        [0.57; 2.71]     8.99        participants still did not grasp the underlying posterior
   Play*Explain -0.47 0.77 0.62 [-1.98; 1.04]               0.38        probabilities of the problem (see Franco-Watkins et al.,
Note. β = unstandardized β coefficients; SE = standard error; OR =      2003; Saenen et al., 2015b).
odds ratio; CI = confidence interval.                                      Second and most important, our study showed which
*         **
  p < .05. p < .01.                                                     specific manipulation helped participants most in
                                                                    2061

understanding the MHD solution. The results provide strong                                  References
evidence for the effect of receiving explanation about the
                                                                   Burns, B. D., & Wieth, M. (2003). Causality and reasoning:
MHD solution. Interestingly, being able to experience
                                                                     The Monty Hall dilemma. Proceedings of the 25th annual
multiple MHD trials – besides having access to explanation
                                                                     conference of the cognitive science society (pp. 198−203).
about the MHD solution – did not further increase
                                                                     Boston, MA: Cognitive Science Society.
participants’ MHD understanding nor did it affect their
                                                                   Burns, B. D., & Wieth, M. (2004). The collider principle in
understanding in a negative way. This finding is of practical
                                                                     causal reasoning: Why the Monty Hall dilemma is so
importance for (posterior) probability education. Although
                                                                     hard. Journal of Experimental Psychology: General, 133,
experience-based learning may occur in many areas, it
                                                                     434−449.
appears that repeated experience with the MHD is not
                                                                   DiBattista, D. (2011). Evaluation of a digital learning object
enough to help participants reflect about and understand the
                                                                     for the Monty Hall dilemma. Teaching of Psychology, 38,
solution. Explanation about the MHD solution, however,
                                                                     53−59.
which parallels much more the traditional learning
                                                                   Franco-Watkins, A. M., Derks, P. L., & Dougherty, M. R. P.
environment (cf. teacher controlled), seems to be more
                                                                     (2003). Reasoning in the Monty Hall problem: Examining
appropriate for teaching students the difficult concept of
                                                                     choice behaviour and probability judgements. Thinking &
posterior probabilities.
                                                                     Reasoning, 9, 67−90.
   However, this conclusion should be considered very
                                                                   Friedman, D. (1998). Monty Hall’s three doors:
carefully for several reasons. First, general implications
                                                                     Construction and deconstruction of a choice anomaly. The
about the use of digital learning environments for (posterior)
                                                                     American Economic Review, 88, 933–946.
probability learning are hard to make given the narrow
                                                                   Granberg, D. (1999). Cross-cultural comparison of
nature of our study and research paradigm. Second, there is
                                                                     responses to the Monty Hall dilemma. Social Behavioral
a crucial limitation in both DiBattista’s (2011) and our own
                                                                     and Personality, 27, 431−438.
performed study. More specifically, the operationalization
                                                                   Granberg, D., & Brown, T. A. (1995). The Monty Hall
of understanding the MHD solution may have been
                                                                     dilemma. Personality and Social Psychology Bulletin, 21,
inadequate in both studies. In DiBattista’s (2011) study,
                                                                     711−723.
participants’ explanation for why they indicated a particular
                                                                   Granberg, D., & Dorr, N. (1998). Further exploration of
behavioral response as the optimal one were interpreted as
                                                                     two-stage decision making in the Monty Hall dilemma.
(no) understanding of the MHD solution. Which criteria
                                                                     American Journal of Psychology, 111, 561−579.
were used to interpret participants’ explanation as either
                                                                   Petrocelli, J. V. (2013). Pitfalls of counterfactual thinking in
correct or incorrect, is however unclear. Therefore, we
                                                                     medical practice: Preventing errors by using more
operationalized understanding the MHD solution as being
                                                                     functional reference points. Journal of Public Health
able to give correct posterior probability estimates.
                                                                     Research, 24, 136−143.
However, these do not necessarily reflect understanding:
                                                                   Petrocelli, J. V., & Harris, A. K. (2011). Learning inhibition
Participants might give correct probability judgments
                                                                     in the Monty Hall problem: The role of dysfunctional
accidentally by guessing. Furthermore, the 6-door MHD
                                                                     counterfactual prescriptions. Personality and Social
variant – which we included in order to be able to compare
                                                                     Psychology Bulletin, 37, 1297−1311.
our results with the results of DiBattista (2011) – has the
                                                                   Saenen, L., Heyvaert, M., Grosemans, I., Van Dooren, W.,
same underlying posterior probabilities as the classic MHD.
                                                                     & Onghena, P. (2014). The equiprobability bias in the
Therefore, it is impossible to determine whether
                                                                     Monty Hall dilemma: A comparison of primary school,
participants’ – who were assigned to a condition in which
                                                                     secondary school, and university students. Proceedings of
they received explanation about the solution – correct
                                                                     the 36th annual conference of the cognitive science
posterior probability estimates were the result of
                                                                     society (pp. 2859−2864). Austin, TX: Cognitive Science
understanding the MHD solution, or only showed that they
                                                                     Society.
had copied the probabilities they just had been reading but
                                                                   Saenen, L., Van Dooren, W., & Onghena, P. (2015a). A
still did not understand these posterior probabilities and the
                                                                     randomized Monty Hall experiment: The positive effect
problem’s solution. Future research could clarify this by
                                                                     of conditional frequency feedback. Thinking &
including MHD variants in the posttest questionnaire with
                                                                     Reasoning, 21, 176−192.
other optimal behavioral responses (e.g., staying) and other
                                                                   Saenen, L., Heyvaert, M., Van Dooren, W., & Onghena, P.
underlying posterior probabilities.
                                                                     (2015b). Inhibitory control in a notorious brain teaser:
                                                                     The Monty Hall dilemma. ZDM Mathematics Education.
                    Acknowledgments                                  Advance online publication.
This research was carried out with the financial support of        Stibel, J. M., Dror, I. E., & Ben-Zeev, T. (2009). The
the Concerted Research Action ‘Number sense: Analysis                collapsing choice theory: Dissociating choice and
and Improvement’ of the KU Leuven (GOA/12/010).                      judgment in decision making. Theory and Decision, 66,
   The authors would like to thank Kevin Van Langendonck             149−179.
for his help with the data collection.
                                                               2062

