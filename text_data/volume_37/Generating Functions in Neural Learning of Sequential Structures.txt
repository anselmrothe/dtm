               Generating Functions in Neural Learning of Sequential Structures
                                                  Yanlong Sun (ysun@tamhsc.edu)
                                                Hongbin Wang (hwang@tamhsc.edu)
                           Center for Biomedical Informatics, Texas A&M University Health Science Center
                                                           Houston, TX 77030 USA
                               Abstract                                     Now we take a different measure. Let E[T ∗ ] denote the
   A cornerstone of human statistical learning is the ability to         pattern’s waiting time, which is the expected number of flips
   extract abstract regularities from sequential events. Here we         since the beginning of the process until the first occurrence of
   present a unique method to derive the generating functions for        the pattern, then,
   the waiting time of sequential patterns, then compare these
   functions with the neural mechanisms for learning sequential                           E[THH∗
                                                                                                 ] = (1/2)−1 + (1/2)−2 = 6,
   structures. We show that the way the neocortex integrates infor-
                                                                                               ∗
   mation over time bears a striking resemblance to the way these                         E[THT  ] = (1/2)−1 + (1/2)−1 = 4.
   normative functions operate. They both operate by organizing
   combinatorial objects into meaningful groups then compressing         That is, it actually takes longer to see the first HH (a repetition)
   the representations by discarding irrelevant information. As a        than the first HT (an alternation).
   result, discrete-time signals are converted into frequency sig-
   nals, and similarity-based structures are converted into abstract        The example of coin flipping demonstrates some intricate
   relational structures. Our analyses not only reveal surprisingly      relations between our intuition about random sequences and
   rich statistical structures embedded in the seemingly random          the normative predictions of probability theory. In terms of
   sequences, but also offer an explanation for how higher-order
   cognitive biases may have emerged as a consequence of tempo-          statistical learning, implicit learning without instruction can be
   ral integration.                                                      rapid and robust, but it does not always agree with explicit and
   Keywords: generating function; waiting time; statistical learn-       structured rule learning (Aslin & Newport, 2012). Aiming at
   ing; temporal integration; compressed representation.                 possible reconciliations, many theories propose that the eval-
                                                                         uation of the biases in human randomness perception should
                           Introduction                                  consider other factors beyond a single normative measure,
The human mind has a unique capacity to find order in chaos              for example, the difficulty of encoding complexity (Falk &
(Gazzaniga, 2008). From betting cards in casinos to investing            Konold, 1997), the limited short-term memory capacity (Hahn
money in stocks, people constantly attempt to extract regulari-          & Warren, 2009; Kareev, 2000), and inferences with com-
ties from the seemingly random sequences. For theories deal-             peting generating processes (Nickerson, 2002; Tenenbaum,
ing with human statistical learning, there are always two types          Kemp, Griffiths, & Goodman, 2011). Based on the waiting
of challenges: How is the implicit learning without instruc-             time statistics, we have argued that the alternation bias in
tion is connected with the explicitly structured rule learning?          the gambler’s fallacy can be understood as a consequence of
How can heuristics and biases deviate systematically from                time in that repeating patterns are “delayed” than alternating
normative rules?                                                         patterns (Sun, Tweney, & Wang, 2010; Sun & Wang, 2010a,
   Consider the following situation. A fair coin is flipped              2010b, 2012). However, these theories have been limited at the
repeatedly in independent Bernoulli trials. Which of the two             behavioral level where one could only align the overall human
patterns, two heads in a row (HH), or a head followed by a tail          behavior with a certain normative measure in its abstract form.
(HT), is more likely to happen? To measure the frequency of a            It remains to be answered where the alternation bias has origi-
pattern, let E[T ] denote the pattern’s mean time, which is the          nated, and more critically, how the abstract representations in
expected number of coin flips between any two consecutive                the human mind have taken shape from the beginning.
occurrences of the pattern,                                                 In the present paper, we present a unique method to derive
                   E[THH ] = E[THT ] = (1/2)−2 = 4,                      the generating functions for the waiting time statistics of se-
                                                                         quential patterns. This method was first introduced by Graham,
which means that on average, HH and HT are equally likely,               Knuth, and Patashnik (1994). Here we extend this method
each occurring once in every 4 flips.                                    and elaborate on the procedures where combinatorial objects
   This answer may sound simple. However, it appears to be               are perceptually organized then compressed into abstract and
at odds with a gambler’s intuition. In a game of roulette at             closed-form representations. We then discuss a neural network
the Monte Carlo casino in 1913, black repeated a record 26               model that can actually capture the waiting time statistics with
times, people began extreme betting on red after about 15                unsupervised learning (Sun et al., 2015). By comparing the
repetitions (Huff, 1959). The gambler’s fallacy, which is often          generating functions with the neural learning mechanisms, we
attributed to the representativeness bias, reflects the belief that      offer an explanation for how human randomness perception
chance is a self-correcting process such that it is more likely          can take shape through mere exposure to the input stimuli
to produce alternating patterns than repeating ones (Tversky             without instruction, and how object representation can lead to
& Kahneman, 1974).                                                       probability induction.
                                                                     2302

      Generating Functions for Waiting Times                               Letting z = 1, we have GHH (1) = 1, which means that the
Following the notations by Graham et al. (1994), a generating              pattern HH eventually will happen with probability 1.
function, A(z), is the sum of a power series that “organizes” an              Then, from Equation 3, the pattern HH’s waiting time is:
infinite sequence ha0 , a1 , a2 , . . .i with an auxiliary variable z,                                         1   1
                                                                                                         ∗
                                                                                                     E[THH ]=    + 2.                     (6)
            A(z) = a0 + a1 z + a2 z2 + · · · =                                                                 p p
                                                   ∑ ak zk ,       (1)
                                                  k>0                                                                 ∗ ] = 6. (Hereafter we
                                                                           For example, at p = 1/2, we have E[THH
and, a probability generating function, GX (z), where X is a               omit the calculation of the variance.)
random variable that takes only nonnegative integer values, is                Without losing any mathematical rigor, this method of de-
the sum of the probability distribution,                                   riving generating functions is remarkably simple. To recapture
                                                                           the critical steps, first of all, the generating function SHH in
                    GX (z) =   ∑ Pr(X = k)zk .                     (2)     Equation 4 partitions the probability space Ω with a “juxtapo-
                              k>0                                          sition” (i.e., multiplication) of two terms: the binomial term
The coefficients of GX (z) sum to 1, which can be written as               (T + HT)n and the pattern HH itself. The binomial term orga-
GX (1) = ∑k>0 Pr(X = k) = 1. The function GX (z) contains                  nizes all possible sequences where the pattern HH has failed
the information of all cumulants in the distribution of X. For             to occur (such that the waiting has to start all over), into the
example, the first and the second cumulants, namely, the mean              power groups by the number of failures, n. For example, the
and variance, are given by                                                 sequence TTHT belongs to the group (T + HT)3 , since it is
                                                                           obtained by stacking either T or HT 3 times. Then, the right-
                 E[X] = G0X (1),                                           hand side of Equation 4 is simply the sum of a power series.
                                                                   (3)     Next, in Equation 5, the z-transformation from SHH to GHH (z)
              Var(X) = G00X (1) + G0X (1) − G0X (1)2 .
                                                                           compresses the representation further by discarding the exact
   In the following, we use these definitions to derive the wait-          order of H’s and T’s. As a result, GHH (z) only preserves the
ing time for patterns in binary sequences. We first introduce              exact number of flips in each sequence, which is indexed by
the solution by Graham et al. (1994) to the pattern HH’s wait-             the power of z. Finally, averaging all sequence lengths with
ing time in independent Bernoulli trials. Then, we extend the              G0HH (z = 1), which effectively removes the index z, we have
method to the pattern HT and the waiting time in first-order               the waiting time for the pattern HH.
dependent Markov trials.                                                      What is even more remarkable about this method is that it
                                                                           may also shed light on how human randomness perception
Waiting Time in Bernoulli Trials                                           might have taken shape in a similar fashion. Particularly, this
Assuming that a coin, with probability of heads, p, and proba-             method directly operates on object representations. It illus-
bility of tails, q = 1 − p, is flipped repeatedly in independent           trates how combinatorial objects, namely, sequences unfolding
Bernoulli trials. In waiting for the pattern HH, we consider the           over time, can be organized into meaningful groups then com-
probability space consisting of all sequences that end with the            pressed into an abstract and closed-form representation. We
first occurrence of HH:                                                    will elaborate further on this point in the next section.
        Ω = {HH, THH, TTHH, HTHH, TTTHH, THTHH, · · · }.                   Partitioning by Auxiliary Sum
                                                                           The example above shows one way to partition the probability
Letting SHH be the generating function that sums up all mem-
                                                                           space. It should be noted that the way to organize the com-
bers of Ω:
                                                                           binatorial objects can be rather flexible. One simple method
   SHH = HH + THH + TTHH + HTHH + TTTHH + THTHH + · · · ,                  is to use an auxiliary sum, which is the sum of all sequences
                                                                           that do not contain any occurrences of the expected pattern.
and by the expansion of the power series,                                  In the following, we use this method to derive the generating
                                                                           functions for the pattern HT’s waiting time in Bernoulli trials.
                                                      1
              1 + z + z2 + z3 + · · · =    ∑ zn = 1 − z ,                     In waiting for the first occurrence of HT, we consider two
                                          n>0                              sets of sequences: SHT represents the sum of all sequences that
                                                                           end with the first HT, and M represents the auxiliary sum of all
we can write SHH in a “closed-form”:
                                                                           sequences that do not contain any HT.1 We can then write two
                                                  HH                       linear equations:
             SHH =   ∑ (T + HT)n HH = 1 − (T + HT) .               (4)
                    n>0                                                                       SHT + M = M(H + T) + H + T,
   We can then obtain the probability generating function for                                      SHT = MHT + HT,
the waiting time of HH by replacing each H with pz and each T                  1 Note that different from the method by (Graham et al., 1994),
with qz:                                                                   our auxiliary sum here does not include the empty sequence. This
                                         p2 z2                             is to emphasize the idea that all members in the sum are directly
                     GHH (z) =                     .               (5)     observable.
                                  1 − qz − pqz2
                                                                       2303

where the first equation partitions the entire probability space              A                              B                 R
into either SHT or M, and the second equation states that any                                   R                                  A
                                                                                         MH          SHH                 MH          SHT
member of SHT is obtained either by extending a member of                           H                               H
M with HT at the end or directly from the first two coin flips.                ∅       A      A               ∅        A
   Solving for SHT , we have
                                                                                    T                               T
                                                                                         MT      R                       MT        R
                                   HT
                     SHT =                   .
                             (H − 1)(T − 1)
                                                                       Figure 1: Markov chains for generating the first occurrence of
Replace each H with pz and each T with qz, we have the                 the patterns HH (figure A) and HT (figure B). States SHH and SHT
probability generating function for the pattern HT’s waiting           represent all sequences that end with the first occurrence of the
time in Bernoulli trials:                                              expected pattern. States MH and MT represent all sequences
                                                                       that end with either an H or a T but do not contain the expected
                                    pqz2                               pattern. After the first transition out of the initial empty state
                  GHT (z) =                    .
                              (pz − 1)(qz − 1)                         (∅), later transitions are characterized by either a repetition
                                                                       (R) or an alternation (A).
Then, from Equation 3, we have
                          ∗      1     1                               Solving for SHH , we have the generating function
                      E[THT ]=     +        ,                  (7)
                                 p 1− p                                                                    T + HA
                                                                                           SHH = HR +                 AR .
For example, at p = 1/2, we have E[THT   ∗ ] = 4, which is 2 flips                                       1 − R − AA
short of the HH’s waiting time (cf., Equation 6).                      Replacing each H and each T with z/2 (since πH = πT = 1/2),
                                                                       each R with (1 − pA )z, and each A with pA z, we have the
First-order Dependent Markov Trials                                    probability generating function for the pattern HH’s waiting
In studies on human randomness perception, another widely              time,
used model is the first-order dependent Markov trials, parame-                                   (pA − 1)(2pA z − z + 1)z2
terized by the probability of alternation between consecutive                        GHH (z) =                                   .
                                                                                                   2(p2A z2 − pA z + z − 1)
trials (e.g., Budescu, 1987; Falk & Konold, 1997; Lopes &              Therefore, from Equation 3,
Oden, 1987; Nickerson, 2002; Oskarsson, Van Boven, McClel-
land, & Hastie, 2009; Sun & Wang, 2012). In the following,                                    ∗             1        2
                                                                                          E[THH ] = 1+          +          .             (8)
we derive the generating functions for both patterns HH and HT                                            2pA 1 − pA
in such a process.                                                     For example, when pA = 1/2, we have E[THH           ∗ ] = 6, which is
   We first assume that the process is H-T symmetrical (i.e.,          the same result from Equation 6. When pA = 1/3, we have
exchangeable) with stationary probabilities,                           E[THH∗ ] = 5.5.
                                                                          Similarly, according to Figure 1B, the waiting time for the
                         πH = πT = 1/2,                                pattern HT can be solved from the following equations:
which means that in the long run, heads and tails are equally                                MH = H + MH R + MT A ,
likely. Then, we use the probability of alternation, pA , to                                 MT = T + MT R ,
simplify the transition probabilities,
                                                                                            SHT = MH A ,
             pA = pH,T = pT,H = 1 − pH,H = 1 − pT,T .                  resulting in the generating function,
                                                                                                     HA − HRA + TAA
   In waiting for the pattern HH, we first consider the sum SHH                             SHT =                      ,
for all sequences that end with the first occurrence of HH. We                                           (1 − R)2
then split the auxiliary sequences that do not contain the pat-        and the probability generating function,
tern into two parts, MH for all sequences that end with H and MT                                     pA (2pA z − z + 1)z2
for all sequences that end with T. This partitioning is plotted                          GHT (z) =                           .
                                                                                                      2(pA z − z + 1)2
as a Markov chain in Figure 1A, which shows that extending
any member of MH with a repetition (R) produces a member               Therefore,
of SHH , extending any member of MH with an alternation (A)                                      ∗            1      1
produces a member of MT , and so on.                                                        E[THT  ] = 1+        + .                     (9)
                                                                                                            2pA pA
   According to Figure 1A, we can write three equations,                                                                   ∗ ] = 4, which is
                                                                       For example, when pA = 1/2, we have E[THT
                     MH = H + MT A ,                                   the same result from Equation 7. When pA = 1/3, we have
                                                                       E[THT∗ ] = E[T ∗ ] = 5.5. That is, alternations have to be this
                     MT = T + MT R + MH A ,                                           HH
                                                                       much less frequent than repetitions to make the patterns HH
                     SHH = MH R .                                      and HT have the same waiting time.
                                                                   2304

Asymmetry in the Additional Time                                            into frequency signals (e.g., as a power series), and similarity-
The Markov chains in Figure 1 depict a structural asymmetry                 based structures (e.g., sequences that end with the same ele-
in the trajectories of different patterns. This asymmetry can               ments) are transformed into abstract relational structures (e.g.,
be more obvious if we only look at a portion of the waiting                 given an H, the first HT arrives earlier than the first HH). Such
time. Whereas the waiting time E[T ∗ ] is always counted from               transformations bear a striking resemblance to the currently
the beginning of the process (i.e., the initial state ∅ is empty),          proposed learning mechanisms in the human brain, for exam-
we can define the additional time, denoted by E[T j|i ], as the             ple, perceptual processing (Marr, 1982), temporal integration
expected number of transitions from any initial state i until               (Elman, 1990; O’Reilly, Munakata, Frank, Hazy, & Contribu-
the first arrival of the state j. For example, E[THH∗ ] and E[T ∗ ]         tors, 2012; O’Reilly, Wyatte, & Rohrlich, 2014), neural pop-
                                                               HT
in Equations 8 and 9 share the same component E[TH∗ ] =                     ulation encoding (Pouget, Beck, Ma, & Latham, 2013), and
E[TH|∅ ] = 1 + 1/2pA . Cancelling the common terms, we have                 Bayesian abstraction (Tenenbaum et al., 2011). Then, it would
                                                                            be a plausible conjecture that processes similar to these gener-
                               2                         1                  ating functions may also take place in the human brain. That is,
             E[THH|H ] =           ,     E[THT|H ] =        .     (10)
                            1 − pA                       pA                 by merely observing random sequences unfolding over time,
                                                                            the mind should be able to naturally capture abstract structures
The difference between E[THH|H ] and E[THT|H ] is illustrated in            summarized by the waiting time statistics.
Figure 1. Before reaching SHH , an alternation after state MH                  Indeed, we have recently reported a biologically-motivated
leads the process to state MT thus “delays” the transition to               neural model that did just that (Sun et al., 2015). In the light of
the destination. In contrast, before reaching SHT , a repetition            the generating functions developed above, here we recapture
after state MH makes the process stay in the same state thus                some of the major findings from the model.
the distance to the destination is unchanged. Together, when
repetitions and alternations are equally likely, pA = 1/2, the
                                                                                A                                                B
temporal distance from MH to SHH is greater than that from MH
                                                                                                              Temporal Context
to SHT : E[THH|H ] = 4, and E[THT|H ] = 2.                                                     Internal
                                                                                                                                     Detector Ratio (R:A)
                                                                                                                                                             2
   Similarly for independent Bernoulli trials, canceling the                                  Prediction
common terms in Equations 6 and 7, we have                                                                                                                  1.5
                            1                        1                                                                                                       1
              E[THH|H ] =      ,      E[THT|H ] =        .
                            p2                      1− p                             Input     H      H    Input                                            0.5
                                                                                    (t−1)      T      T     (t)
By extending Figure 1 to longer sequences, we can show that
the difference increases exponentially as the pattern length
                                                                                                                                                                  1   ⁄3   3   ⁄7   ⁄2
                                                                                                                                                                                    1    ⁄7
                                                                                                                                                                                         4
                                                                                    Data     · · · H T H H T· · ·                                             Probability of Alternation (pA )
increases. When p = 1/2, given an existing streak of k heads,
despite that the next flip can be equally likely a head or a tail,
the additional time until a streak of (k + 1) heads is much                 Figure 2: A neural network model of temporal integration
longer than that for the pattern of k heads followed by a tail:             (figures adopted from Sun et al., 2015). A. Architecture of the
                              1                           1                 neural model. A single input layer scans a sequence of binary
         E[T(k+1)H|kH ] =         ,     E[TkH T|kH ] =        .             digits one digit at a time (input at time t − 1 is for illustration
                             pk+1                        1− p
                                                                            only). An internal prediction layer, with its temporal context
    Neural Learning of Sequential Structures                                representation, attempts to predict the next input. B. Neural
The generating functions reveal a great deal about the rich sta-            model behavior depicted by the ratio between the numbers of
tistical structures embedded in random sequences. A question                repetition and alternation detectors in response to the actual
that immediately follows then is whether these structures can               probability of alternation (pA ) in the input sequence. Error bars
be implicitly captured by the human mind. We have argued                    (±SEM) represent the variability of model predictions. The
before that at the behavioral level, people’s preference for                dotted line is the squared total time ratio between alternation
alternating patterns (e.g., HT) over repeating ones (e.g., HH)              and repetition patterns (Equation 11).
appears to be driven by the patterns’ waiting time statistics
(Sun & Wang, 2010a, 2010b, 2012). Considering the way the
                                                                            A Neural Model of Temporal Integration
generating functions for waiting times are derived, here we
argue that the alternation bias might have actually emerged at              Our neural model is extremely simple (Figure 2A). It employs
the neural level.                                                           a recently-developed neural algorithm for temporal integra-
   In particular, the way these generating functions operate                tion (O’Reilly et al., 2014). At the sensory level, a 2-unit
is to organize combinatorial objects into smaller groups then               input layer scans non-overlapping signals of heads (H) versus
compress the representation into a closed form where irrele-                tails (T) one digit at a time from sequences generated by the
vant information is discarded. By doing so, discrete-time sig-              first-order dependent Markov trials. Then, a 100-unit internal
nals (e.g., sequences encountered over time) are transformed                prediction layer attempts to predict the next input, with the
                                                                         2305

benefit of a prior temporal context representation. The bidi-             First of all, we argue that the alternation bias in human
rectional activation dynamics between the input layer and the          randomness perception is the consequence of temporally dis-
internal prediction layer allow us to use a single input layer         tributed learning. While neurons in the neocortex integrates in-
for both providing inputs and receiving predictions.                   formation over time through different contributions of the deep
   By unsupervised learning, the model was trained with bi-            versus superficial layers (e.g., layers 5b and 6, see, O’Reilly et
nary sequences generated at various levels of probability of           al., 2014), they act in the same way as the generating functions
alternation (pA ), each sequence consisting of 10,000 trials.          by transforming discrete-time signals into representations of
After training, the model was tested with a sequence of 1,000          frequency. For example, Figure 1 and Equation 10 show that
trials generated at the same pA level. Through an activation-          at pA = 1/2, the additional time travelling from MH to SHT is
based receptive field analysis, we decoded the representations         shorter than that from MH to SHH . This means that the neu-
on the internal prediction layer and classified its units as either    rons monitoring the (H → HT) transitions are more likely to
repetition detectors (sensitive to either HH or TT) or alternation     sustain their activations over time than those monitoring the
detectors (sensitive to either HT or TH). We then counted the          (H → HH) transitions. By the principles of self-organizing
numbers of detectors and used the ratio (R/A, repetition over          learning (Hebb, 1949), more neurons would be tuned to tem-
alternation) to measure the model’s performance (Figure 2B).           porally associating an existing H with a future HT instead of
   We found that the model’s behavior can be mostly replicated         a future HH. In a certain sense, in the process of maximiz-
by a simple equation that averages the effects of the mean time        ing the temporal correlation, these neurons have incidentally
and waiting time statistics (the dotted line in Figure 2B):            committed themselves to the gambler’s fallacy.
                                                                          Second, as we have seen in the generating functions, a
                            E[TA ] + E[TA∗ ] 2
                                            
                      R
                        ≈                      ,              (11)     critical step towards a compressed representation is to discard
                      A     E[TR ] + E[TR∗ ]                           irrelevant information (e.g., in the z-transformation). Then,
where E[T ] is the mean time, E[T ∗ ] is the waiting time,             the structures based on perceptual similarity are transformed
and subscripts R and A represent repetition (either HH or TT)          into the abstract and relational structures. In the same way,
and alternation (either HT or TH), respectively. For example,          for neurons to maximize the correlation between temporally
at pA = 3/7, E[THH ] + E[THH   ∗ ] = E[T ] + E[T ∗ ], the model        adjacent events, information such as the exact order of the
                                        HT        HT
showed about the same numbers of repetition and alternation            past events has to be discarded. There are many reasons to
detectors, R/A ≈ 1.                                                    believe that a primary function of the cortical processing is to
   Most interestingly, at pA = 1/2 (i.e., flipping a fair coin         actively discard massive amounts of information so that only
independently), despite the same training frequency of the pat-        the most relevant signals are retained and processed further
terns (e.g., E[THH ] = E[THT ] but E[THH∗ ] > E[T ∗ ]), the model      (for a review, see, O’Reilly et al., 2014). For neurons that
                                                  HT
consistently produced fewer repetition detectors than alter-           can only monitor sequential events unfolding over time, what
nation detectors at a ratio of R/A ≈ .70. We then used this            is relevant in the past is determined by what happens in the
R/A ratio to compute the subjective probability of alterna-            future (i.e., following the arrow of time, see Figure 1).
tion, p0A , as the model’s internal representation of its actually        Third, the generating functions we derived above are not
experienced pA ,                                                       meant to predict random sequences. Rather, they are built to
                                                                       capture the statistical structures embedded in time. Likewise,
                          A          1
                  p0A =       =             ≈ 0.59.                    our neural model would generally fail to predict each coin flip.
                        R + A 1 + R/A                                  The predictions made by the model are rather implicit than
                                                                       explicit. This feature relieves the network from the burden of
This p0A value was consistent with the value from empirical
                                                                       predicting every last detail of the input, and merely requires
findings. From a comprehensive review of previous studies
                                                                       that the internal network state learn to be compatible with the
(Falk & Konold, 1997), a unanimous finding was that people
                                                                       new inputs. As a result, learning is distributed across popula-
perceived or generated random sequences with a p0A value
                                                                       tions of neurons and spanned over time, therefore allows the
around 0.58 ∼ 0.63 .
                                                                       network to be more adaptive to the statistical structures of the
Generating Functions in the Human Brain                                learning environment.
It should be noted that our neural model was not specifically             Lastly, the generating functions can operate from both direc-
tasked to capture the waiting time statistics. Rather, it was          tions as either the summation of discrete-time objects or the
built on the well-established sensitivity in the neural learning       expansion of a closed form (e.g., Equation 4). Mapped onto
of sequential structures (Elman, 1990) and implemented with            the bidirectional activation dynamics in our neural model, this
biologically realistic algorithms that aim to explain the neu-         corresponds to the integration of sensory inputs (bottom-up)
ral basis of cognition in a wide range of different domains            and the prediction from more abstract internal representations
(O’Reilly et al., 2012, 2014). Nevertheless, given that the neu-       (top-down). Different from a standard simple recurrent net-
ral model’s behavior was systematically biased by sequential           work that implements separate input and output layers (Elman,
patterns’ waiting time, here we offer an interpretation through       1990), the bidirectional activation dynamics in our model al-
the lens of the generating functions.                                  low flexible encoding and inferring of relational structures,
                                                                   2306

thus provide a more natural mechanism for predictive learning          Kareev, Y. (2000). Seven (indeed, plus or minus two) and
in the brain (George & Hawkins, 2009).                                   the detection of correlations. Psychological Review, 107(2),
                                                                         397–402. doi: 10.1037/0033-295x.107.2.397
                           Conclusion                                  Lopes, L. L., & Oden, G. C. (1987). Distinguishing between
The generating functions presented in this paper provide a nor-          random and nonrandom events. Journal of Experimental
mative measure for the sequential structures embedded in time.           Psychology: Learning Memory and Cognition, 13(3), 392–
By organizing combinatorial objects with a simple “juxtapo-              400. doi: 10.1037/0278-7393.13.3.392
sition” arithmetic, they break down the process of extracting          Marr, D. (1982). Vision. San Francisco, CA: W. H. Freeman.
statistical regularities into a set of summation and multiplica-       Nickerson, R. S. (2002). The production and perception of
tion operations. In this aspect, these functions may help us             randomness. Psychological Review, 109(2), 330–357. doi:
understand the neural learning mechanisms in the process of              10.1037//0033-295X.109.2.330
extracting sequential relational structures, by revealing how          O’Reilly, R. C., Munakata, Y., Frank, M. J., Hazy,
object representations can build up to a compressed probabilis-          T. E., & Contributors. (2012). Computational cog-
tic representation, and vice versa, how a learned structure may          nitive neuroscience. Wiki Book, 1st Edition, URL:
bias predictions on discrete-time events. Overall, these func-           http://ccnbook.colorado.edu.
tions can be a powerful tool to bridge the gap between implicit        O’Reilly, R. C., Wyatte, D., & Rohrlich, J. (2014). Learn-
statistical learning without instruction and explicitly structured       ing through time in the thalamocortical loops. Preprint at:
rule learning, and to reconcile the deviation of heuristics and          http://arxiv.org/abs/1407.3432.
biases from normative rules.                                           Oskarsson, A. T., Van Boven, L., McClelland, G. H., & Hastie,
                                                                         R. (2009). What’s next? Judging sequences of binary
                     Acknowledgments                                     events. Psychological Bulletin, 135(2), 262–285. doi:
This work was supported by the Air Force Office of Scien-                10.1037/a0014821
tific Research (AFOSR) grant number FA9550-12-1-0457, the              Pouget, A., Beck, J. M., Ma, W. J., & Latham, P. E. (2013).
Office of Naval Research (ONR) grant number N00014-08-1-                 Probabilistic brains: Knowns and unknowns. Nature Neuro-
0042, and the Intelligence Advanced Research Projects Ac-                science, 16(9), 1170–1178. doi: 10.1038/nn.3495
tivity (IARPA) via Department of the Interior (DOI) contract           Sun, Y., OReilly, R. C., Bhattacharyya, R., Smith, J. W., Liu,
number D10PC20021.                                                       X., & Wang, H. (2015). Latent structure in random se-
                                                                         quences drives neural learning toward a rational bias. Pro-
                           References                                    ceedings of the National Academy of Sciences, 112(12),
Aslin, R. N., & Newport, E. L. (2012). Statistical learning:             3788–3792. doi: 10.1073/pnas.1422036112
   From acquiring specific items to forming general rules. Cur-        Sun, Y., Tweney, R. D., & Wang, H. (2010). Occurrence and
   rent Directions in Psychological Science, 21(3), 170–176.             nonoccurrence of random sequences: Comment on Hahn
   doi: 10.1177/0963721412436806                                         and Warren (2009). Psychological Review, 117(2), 697–703.
Budescu, D. V. (1987). A Markov model for generation of                  doi: 10.1037/a0018994
   random binary sequences. Journal of Experimental Psychol-           Sun, Y., & Wang, H. (2010a). Gambler’s fallacy, hot hand
   ogy: Human Perception and Performance, 13(1), 25–39.                  belief, and time of patterns. Judgment and Decision Making,
   doi: 10.1037/0096-1523.13.1.25                                        5(2), 124–132.
Elman, J. L. (1990). Finding structure in time. Cognitive Sci-         Sun, Y., & Wang, H. (2010b). Perception of randomness: On
   ence, 14(2), 179–211. doi: 10.1207/s15516709cog1402 1                 the time of streaks. Cognitive Psychology, 61(4), 333–342.
Falk, R., & Konold, C. (1997). Making sense of randomness:               doi: 10.1016/j.cogpsych.2010.07.001
   Implicit encoding as a basis for judgment. Psychological Re-        Sun, Y., & Wang, H. (2012). Perception of randomness: Sub-
   view, 104(2), 301–318. doi: 10.1037/0033-295x.104.2.301               jective probability of alternation. In N. Miyake, D. Peebles,
Gazzaniga, M. S. (2008). Human: The science behind what                  & R. P. Cooper (Eds.), Proceedings of the 34th annual con-
   makes us unique. New York: HarperCollins e-books.                     ference of the cognitive science society (pp. 1024–1029).
George, D., & Hawkins, J. (2009). Towards a mathematical                 Austin, TX: Cognitive Science Society.
   theory of cortical micro-circuits. PLoS Computational Biol-         Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman,
   ogy, 5(10), e1000532. doi: 10.1371/journal.pcbi.1000532               N. D. (2011). How to grow a mind: Statistics, struc-
Graham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete            ture, and abstraction. Science, 331(6022), 1279–1285. doi:
   mathematics. Reading MA: Addison-Wesley.                              10.1126/science.1192788
Hahn, U., & Warren, P. A. (2009). Perceptions of randomness:           Tversky, A., & Kahneman, D. (1974). Judgment under un-
   Why three heads are better than four. Psychological Review,           certainty: Heuristics and biases. Science, 185(4157), 1124–
   116(2), 454–461. doi: 10.1037/a0015241                                1131. doi: 10.1126/science.185.4157.1124
Hebb, D. O. (1949). The organization of behavior. New York:
   Wiley.
Huff, D. (1959). How to take a chance. New York: W. W.
   Norton.
                                                                   2307

