                         Computational evolution of decision-making strategies
                                                   Peter Kvam (kvampete@msu.edu)
                           Center for Adaptive Rationality, Max Planck Institute for Human Development
                                                   Lentzeallee 94, 14195 Berlin, Germany
                                                   Joseph Cesario (cesario@msu.edu)
                                           Department of Psychology, Michigan State University
                                               316 Physics Rd, East Lansing, MI 48824, USA
                                                     Jory Schossau (jory@msu.edu)
                            Department of Computer Science and Engineering, Michigan State University
                                            428 South Shaw Rd, East Lansing, MI 48824, USA
                          Heather Eisthen (eisthen@msu.edu), Arend Hintze (hintze@msu.edu)
      Department of Integrative Biology, BEACON Center for the Study of Evolution in Action, Michigan State University
                                                 288 Farm Ln, East Lansing, MI 48824, USA
                              Abstract                                  herence. The clarity and intuitiveness of a theory undoubt-
                                                                        edly play an immense role, as does its ability to explain and
   Most research on adaptive decision-making takes a strategy-
   first approach, proposing a method of solving a problem and          predict behavior, but whether or not a strategy is a plausi-
   then examining whether it can be implemented in the brain            ble result of selection pressures is rarely considered. To be
   and in what environments it succeeds. We present a method for        fair, this is largely because the process of evolution is slow,
   studying strategy development based on computational evolu-
   tion that takes the opposite approach, allowing strategies to        messy, and often impossible to observe in organisms in the
   develop in response to the decision-making environment via           lab. Fortunately, recent innovations in computing have en-
   Darwinian evolution. We apply this approach to a dynamic             abled us to model this process with artificial agents. In this
   decision-making problem where artificial agents make deci-
   sions about the source of incoming information. In doing so,         paper, we propose a method of studying the evolution of dy-
   we show that the complexity of the brains and strategies of          namic binary decision-making using artificial Markov brains
   evolved agents are a function of the environment in which they       (Edlund et al., 2011; Marstaller, Hintze, & Adami, 2013; Ol-
   develop. More difficult environments lead to larger brains and
   more information use, resulting in strategies resembling a se-       son, Hintze, Dyer, Knoester, & Adami, 2013) and investigate
   quential sampling approach. Less difficult environments drive        the evolutionary trajectories and ultimate behavior of these
   evolution toward smaller brains and less information use, re-        brains resulting from different environmental conditions.
   sulting in simpler heuristic-like strategies.
                                                                           In order to demonstrate the method and investigate an in-
   Keywords: computational evolution, decision-making, se-
   quential sampling, heuristics                                        teresting problem, we focus on the simple choice situation
                                                                        where a decision-maker has to choose whether the source of
                          Introduction                                  a stimulus is ’signal’ S or ’noise’ N (for preferential deci-
Theories of decision-making often posit that humans                     sions, nonspecific choices A or B can be substituted). A sim-
and other animals follow decision-making procedures that                ilar decision structure underlies a vast array of choices that
achieve maximum accuracy given a particular set of con-                 people and other animals make, including edible/inedible,
straints. Some theories claim that decision-making is optimal           healthy/sick, safe/dangerous, and so on. The task requires a
relative to the information given, involving a process of max-          decision-maker to take in and process information over time
imizing expected utility or performing Bayesian inference               and make a decision about which source yielded that informa-
(Bogacz, Brown, Moehlis, Holmes, & Cohen, 2006; Griffiths               tion. However, the decision maker is free to vary the amount
& Tenenbaum, 2006; Von Neumann & Morgenstern, 1944).                    of information it uses and processing it applies, and different
Others assume that behavior makes trade-offs based on the               theories make diverging predictions about how each of these
environment, tailoring information processing to achieve suf-           should vary. On one hand, it may be more advantageous to
ficient performance by restricting priors (Briscoe & Feldman,           use every piece of information received, feeding it through a
2011), ignoring information (Gigerenzer & Todd, 1999), or               complex processing system in order to obtain maximum ac-
sampling just enough to satisfy a particular criterion (Link            curacy. On the other, a simpler processing architecture that
& Heath, 1975; Ratcliff, 1978). In most cases, mechanisms               ignores information may be sufficient in terms of accuracy
underlying the initial development of these strategies are as-          and more robust to random mutations, errors, or over-fitting.
sumed – either explicitly or implicitly – to be the result of
                                                                        More complex models
natural and artificial selection pressures.
   In cognitive science research, however, the evolution of a           Many of the most prominent complex decision-making mod-
strategy often takes a back seat to its performance and co-             els fall under the sequential sampling framework (Bogacz et
                                                                    1225

al., 2006; Link & Heath, 1975; Ratcliff, 1978). These models        more detail.
assume that a decision-making agent takes or receives sam-
ples one by one from a distribution of evidence, with each                                     Methods
sample pointing toward the signal or noise distribution. They
                                                                    We were interested in examining the strategies and evolution-
posit that agent combines samples to process information, for
                                                                    ary trajectories that digital agents took to solve a simple dy-
example by adding up the number favoring S and subtracting
                                                                    namic decision-making problem. To do so, we developed a
the number favoring N. When the magnitude of this differ-
                                                                    binary decision-making task for the agents to solve. The fit-
ence exceeds a criterion value θ (e.g. larger than 4 / smaller
                                                                    ness of an agent was defined as the number of correct deci-
than -4), a decision is triggered in favor of the corresponding
                                                                    sions it made over 100 trials of the task, and the probability
choice option (+θ ⇒ S, −θ ⇒ N). This strategy implements
                                                                    that it would reproduce was determined by this fitness value.
a particular form of Bayesian inference, allowing a decision-
                                                                    Note that fitness was determined by the number of correct an-
maker to achieve a desired accuracy by guaranteeing that the
                                                                    swers, reflecting agents’ propensity to respond together with
log odds of one hypothesis (S or N) over the other is at least
                                                                    their accuracy when they did respond - there was no fitness
equal to the criterion value.
                                                                    penalty or cost for agent complexity. Formally, the proba-
   In these models, each piece of information collected is used
                                                                    bility that it generated each child of the next generation was
to make a decision. Although organisms may not literally add
                                                                    given by its fitness divided by the total fitness across the total
and subtract pieces of information, we should expect to ob-
                                                                    population (roulette wheel selection). An agent reproduced to
serve two characteristics in organisms that implement these
                                                                    the next generation by creating a copy of itself with random
or similar strategies. First, they should be relatively com-
                                                                    mutations. Over the course of 10,000 generations, this selec-
plex, storing the cumulative history of information to make
                                                                    tion and mutation process led to evolution of agents that could
their decisions. Second, they should give each piece of infor-
                                                                    successfully perform the task, and enabled us to analyze the
mation they receive relatively equal weight, spreading out the
                                                                    strategies that the evolved agents ultimately developed.
weights assigned to information across a long series of inputs.
Less complex models                                                 Decision task
Toward the other end of the spectrum of model complexity            The task that the agents had to solve was a binary decision
are heuristics which deliberately ignore information in or-         problem, where they received information from one source S
der to obtain better performance in particular environments         or another N. The information coming from either source in-
(Brandstätter, Gigerenzer, & Hertwig, 2006; Gigerenzer &           cluded two binary numbers, and therefore could yield any of
Brighton, 2009; Gigerenzer & Todd, 1999). Many of these             the inputs [00], [01], [10], or [11]. Source S would yield pri-
strategies are non-compensatory, meaning that they termi-           marily 0s on the left and 1s on the right, and source N would
nate the use of information as soon as one piece of evidence        yield primarily 1s on the left and 0s on the right. The exact
clearly favors either S or N. Accordingly, a decision maker         proportion of these inputs was varied in order to alter the dif-
can have a relatively simple information processing architec-       ficulty of the task. For example, an easy S stimulus would
ture, as it can just copy incoming information to its output        give 90% 0s (10% 1s) on the left, and 90% 1s (10% 0s) on
indicators to give an answer. Some of these require ordinal in-     the right. The two inputs were independent, so this would
formation about different sources of information and their va-      ultimately give 81% [01] inputs, 9% [11], 9% [00], and 1%
lidity, resulting in increased complexity (Dougherty, Franco-       [10]. In a more difficult environment, an S stimulus might
Watkins, & Thomas, 2008), but for the current problem we            have 60% 0s on the left and 60% 1s on the right, yielding
assume that all information comes from a single source.             36% [01], 24% [11], 24% [00], and 16% [10]. For an N stim-
   As a result of the relatively simple architecture and one-       ulus, the possible inputs would be the same, but the frequency
piece decision rules, we can expect to observe two character-       of [01] and [10] inputs would be flipped (i.e. more 1s on the
istics in organisms that implement strategies similar to these      left and 0s on the right). These frequencies were not shown to
heuristics. First, they should have relatively simple informa-      the agents at the start of each trial. Instead, each trial started
tion processing architectures, favoring short and robust path-      with a random frequency of 50%, increasing each consecutive
ways that do little integration. Second, they should appear to      step by 1% until the target frequency was reached. This was
give the most weight to the last piece(s) of information they       done in part to emulate how agents encounter stimuli in real
receive before making their decision, yielding a relationship       situations (i.e. stimuli progressively come into sensory range,
between the final decision and the sequence of inputs that is       increasing in strength over time rather than simply appear-
heavily skewed to the most recently received inputs.                ing), but also to avoid ’sticking’ at a local maximum where
   Of course, the real behavior of artificially evolved organ-      agents simply copy their first input to outputs.
isms will probably lie somewhere along the spectrum be-                The target frequency of 1s and 0s was manipulated to be
tween these two poles. However, we can compare the relative         60 − 90% (in 5% increments), resulting in 7 difficulty levels
leanings of different populations of organisms by varying the       for different populations of agents.
characteristics of the environments in which they evolve. We           For each decision, the agents received up to 100 inputs.
next describe the decision-making task and manipulations in         Each new input constituted one time step during which the
                                                                1226

agent could process that information. If an agent gave an an-          pings in the gate tables (e.g. it could change between any of
swer by signaling [01] to indicate S or [10] to indicate N (see        the gates shown in Figure 1). This code consisted of 2000-
below), then the decision process would come to a halt, where          200,000 ’nucleotides’ and included mutation rates of 0.005%
no new inputs would be given and the agent would be graded             point mutations, 0.2% duplication mutations, and 0.1% dele-
on its final answer. An agent received 1 point toward its fit-         tion mutations, consistent with previous work (Edlund et al.,
ness if it gave the correct answer or 0 points if it was incorrect     2011; Marstaller et al., 2013; Olson et al., 2013). More pre-
or if it failed to answer before 100 inputs were given.                cisely, logic gates are specified by ’genes’ within this genetic
   In addition to the difficulty manipulation, we included a           code. Each gene consists of a sequence of nucleotides, num-
“non-decision time” manipulation, where an agent was not               bered 1-4 to reflect the four base nucleotides present in DNA,
permitted to answer until t time steps had elapsed (i.e. the           and starts with the number sequence ’42’ followed by ’213’
agent had received t inputs). This number t was varied                 (start codon), beginning at an arbitrary location within the
from 10 to 50 in 5-step increments, yielding 9 levels of non-          genome. Genes are typically about 300 nucleotides long and
decision time across different environments. Increasing t              can have ’junk’ sequences of non-coding nucleotides between
tended to make agents evolve faster, as longer non-decision            them, resulting in the large size of the genomes.
time tended to allow agents to more easily implement strate-              The first generation of Markov brain agents in each popu-
gies regardless of difficulty level.                                   lation was generated from a random seed genome. The first
                                                                       100 agents were created as random variants of this seed brain
                                                                       using the mutation rates described above, resulting in approx-
                                                                       imately 20 − 30 random connections per agent. These 100
                                                                       agents each made 100 decisions, and were selected to repro-
                                                                       duce based on their accuracy. This process was repeated for
                                                                       each population for 10,000 generations, yielding 100 agents
                                                                       per population that could perform the decision task.
                                                                       Data
                                                                       For each of the 63 conditions (7 difficulty levels × 9 non-
                                                                       decision times), we ran 10,000 generations of evolution for
                                                                       100 different sub-populations of Markov brains, giving 6300
Figure 1: Diagram of the structure of a sample Markov brain
                                                                       total populations. From each of these populations, a random
with input, processing, and output nodes (circles) with con-
                                                                       organism was chosen and its line of ancestors was tracked
necting logic gates (rectangles). Each gate contains a corre-
                                                                       back to the first generation. This set of agents from the last
sponding table mapping its input values (left) to output values
                                                                       to the first generation is called the line of decent (LOD). For
(right). Note that our actual agents had twice the number of
                                                                       each of the 100 replicates per experimental conditions, all pa-
nodes shown here available to them.
                                                                       rameters (such as fitness) of agents on the LOD were aver-
                                                                       aged for each generation.
Markov brain agents                                                       In each of these LODs, we tracked the average number of
The Markov brain agents (Edlund et al., 2011; Marstaller et            connections between nodes (see Figure 1) that agents had in
al., 2013; Olson et al., 2013) consisted of 16 binary nodes and        each condition and each generation. We refer to this property
of directed logic gates that moved and/or combined informa-            of the agents as “brain size” — the analogous properties in an
tion from one set of nodes to another (see Figure 1). Two of           organism are the number and connectivity of neurons — and
these nodes (1 and 2) were reserved for inputs from the en-            we show its evolutionary trajectory in Figure 2.
vironment, described above. Another two (15 and 16) were                  Finally, we took a close look at the behavior of generation
used as output nodes. These output nodes could show any                9970 – this is near the end to ensure that the generation we ex-
combination of two binary values. When they did not read               amined could solve the task, but slightly and somewhat arbi-
[01] (indicating S), or [10] (indicating N), the agents were           trarily removed from generation 10,000 to ensure that agents
permitted to continue updating their nodes with inputs until           in this generation weren’t approaching one of the random dips
time step 100. To update their nodes at each time step, the            in performance (i.e. random mutations from this generation
agents used logic gates (represented as squares in Figure 1,           were less likely to be deleterious than more recent ones). For
which took x node values and mapped them onto y nodes us-              these agents, we examined each trial to see what information
ing an x × y table.                                                    they received at each time step, which step they made their
   The input nodes, table, and output nodes for these gates            decision, and which decision they made (coded as correct or
were all specified by an underlying genetic code that each             incorrect). This allowed us to examine the relationship be-
Markov brain possessed. Point, insertion, or deletion mu-              tween the inputs they received and the final answer they gave,
tations in the genetic code would cause them add / subtract            giving an estimate of the weight they assigned to each new
inputs to a gate, add / subtract outputs, or change the map-           piece of information.
                                                                   1227

Materials
The agents, tasks, and evolution were implemented in C++
using Visual Studio Desktop and Xcode, and the full evolu-
tion simulations were run at Michigan State University’s High
Performance Computing Center.
                            Results
With the exception of high difficulty, low non-decision time
conditions, most populations and conditions of agents were
able to achieve essentially perfect accuracy on the decision
task after 10,000 generations. However, the strategies imple-
mented by each population varied heavily by condition.
   It is perhaps worth noting at this point the tremendous
amount of data that our approach yields. Each condition con-
sisted of 100 populations of 100 agents that made 100 deci-
sions each generation, yielding 10,000 agents and 1 million
decisions per generation per condition. This tremendous sam-
ple size renders statistical comparisons based on standard er-
ror, for example, essentially moot. For this reason, we present
mostly examples that illustrate important findings rather than
exhaustive statistical comparisons.                                  Figure 2: Mean number of connections in agent brains across
                                                                     generations for three levels of task difficulty. For the sake of
Brain size                                                           comparison, the trajectories shown are all from populations
                                                                     with a non-decision time of 40 steps
Final brain size (number of connections among nodes) var-
ied as a function of both stimulus difficulty and non-decision
time. We focus primarily on high non-decision time condi-            −1, and others ([00] and [11]) were assigned a value of 0. An-
tions, as many of the low non-decision time populations —            swers favoring S were also given a value of +1 and answers
particularly in the difficult stimuli conditions — were unable       favoring N a value of −1. Doing so allowed us to track the
to achieve the high performance of other groups. As Figure           sequence of −1, 0, +1 — which we refer to as the trajectory
2 shows, agents faced with the easiest conditions (10-15%)           — leading to the decision and to correlate this with the final
tended to have the smallest final brain size, with means of          +1 or −1 answer. The result of this analysis for the example
around 15 − 20 connections. Agents faced with medium dif-            conditions is shown in Figure 3.
ficulty environments evolved approximately 25 − 30 connec-              As shown, the trajectory correlations in the more difficult
tions, and agent brain size in the most difficult conditions ap-     conditions tend to be flatter than those in the easy conditions,
proached 35 connections and appeared to still be climbing            and final answers tend to correlate with a longer history of
with further generations.                                            inputs. This indicates that these agents were assigning more
   Perhaps more interesting, though, is the evolutionary tra-        similar weight to each piece of information they use, utilizing
jectory that each of the populations in these conditions took.       the full history of inputs they had received rather than just the
As shown, each group started with 25-30 connections in the           final piece. Note that all agents appeared to use the most re-
initial generation, and in all of them the number of connec-         cent pieces of information more heavily. This will be the case
tions initially dropped for the first 200-400 generations. Af-       for almost any model that generates the data, as the last pieces
ter that, however, the conditions appear to diverge, with the        of information tend to be those that trigger the decision rule
agents in the easy conditions losing even more connections,          – for example, in sequential sampling this will be the piece
agents in the medium conditions staying approximately level,         of information that moves the evidence across the threshold
and agents in the difficult conditions adding more and more          – and as such will always be highly correlated with the final
connections.                                                         answer. 1
                                                                        Information use also varied somewhat across levels of non-
Strategy use
                                                                     decision time, but its effect was not particularly pronounced
In order to examine the pattern of information use in the            except in the more difficult conditions (e.g. 60-70%). How-
agents, we additionally examined the relationship between            ever, this effect is largely a consequence of agent populations’
each piece of information received and the final answer              failure to evolve to perform the task as well when stimulus
given. We did so by taking the series of inputs (e.g.
                                                                         1 However,  since it can sometimes take several updates / time
[00],[11],[01],[01],[11]) and assigning each one a value - in-
                                                                     steps to move a ’trigger’ input through the brain to the output nodes,
formation favoring S ([01] inputs) was assigned a value of +1,       the final piece of information will not always be perfectly correlated
information favoring N ([10] inputs) was assigned a value of         with the output.
                                                                 1228

                                                                      other side of the same coin, this result is particularly interest-
                                                                      ing because we did not impose any penalties for larger brains.
                                                                      Although other researchers have suggested that metabolic
                                                                      costs limit the evolution of large brains (Isler & Van Schaik,
                                                                      2006; Laughlin, van Steveninck, & Anderson, 1998) and can
                                                                      be substantial in real brains (Kuzawa et al., 2014), they were
                                                                      not necessary to drive evolution toward smaller brains.
                                                                          Instead, we suspect that the drop in brain size is a result of
                                                                      the agents’ response to mutations, or the mutation load im-
                                                                      posed by the size of its genome. For example, a random mu-
                                                                      tation in the genome that connects, disconnects, or re-maps
                                                                      a gate is more likely to affect downstream choice-critical el-
Figure 3: Example correlations between inputs and final deci-
                                                                      ements of a brain that uses more nodes and connections to
sion for easy (blue), medium (purple) and difficult (red) con-
                                                                      process information (has a higher mutation load), particularly
ditions. The trajectories are time-locked on the final answer
                                                                      if it has a larger ratio of coding to non-coding nucleotides. In
on the right side, so the last piece of information an agent re-
                                                                      this case, a smaller brain would be a tool for avoiding dele-
ceived is the rightmost value, and to the left is moving back-
                                                                      terious mutations to the information processing stream. Al-
ward through the trajectory.
                                                                      ternatively, the minimum number of nodes and connections
                                                                      required to perform the task is likely lower in the easier con-
discriminability and non-decision time were low. For exam-            ditions than in the more difficult ones, so mutations that re-
ple, agents in the difficult, short non-decision time condition       duce brain size and function might be able to persist in the
(red in left panel of Figure 3) attained accuracy of only 82%,        easier but not the more difficult conditions. In either case,
compared to 95+% in other conditions. Higher difficulty still         it is clear that a larger brain does not offer sufficient bene-
led to larger brains and a longer history of processing in these      fits in the easier conditions to overcome the mutation load it
conditions, but its effect was less pronounced. Therefore,            imposes.
high values of non-decision time apparently made it easier                Another potential risk of having a larger brain is the chance
to evolve complex strategies, likely because agents were ex-          of a random mutation preventing information from reaching
posed to more information before making their decisions.              the output nodes – with a longer chain of processing nodes
                                                                      being easier to interrupt or confuse than a shorter one. While
                          Discussion                                  the agents in more difficult conditions were evidently able to
                                                                      overcome such a possibility (usually answering within 20
While agents’ strategies spanned a range of complexity, more          steps of the end of non-decision time), it may be a barrier that
difficult environments pushed them toward more complex                required substantial fitness rewards to cross, which were not
strategies resembling sequential sampling while easier envi-          present in the easier conditions.
ronments led to strategies more similar to non-compensatory               We hesitate to make claims that are too broad given the
heuristics. Therefore, both sequential sampling and heuristics        scope of our study, but the finding that brain size can be lim-
seem to be strategies that could plausibly result from different      ited by mutation load is provoking. This may explain why
environmental demands. However, our results run counter to            systems that are subject to mutations and selection pressures
the idea that heuristics are invoked when decisions are par-          – including neurons and muscle cells – are reduced when they
ticularly difficult or choice alternatives are not easily distin-     are unused, even when the energetic costs of maintaining the
guished (Brandstätter et al., 2006).                                 structure appear to be low. It seems a promising direction for
   The final strategies may not support the claim that organ-         future research to examine in-depth how mutation rate and
isms are primarily heuristic decision-makers (Gigerenzer &            robustness contribute to organisms’ fitness above and beyond
Brighton, 2009), but it still lends credence to the premise of        the costs associated with metabolism.
ecological rationality on which many heuristics are based.
This approach suggests that different environments (choice            Approach
ecologies) lead to different decision-making strategies rather        We hope to have presented a method for examining ques-
than a one-size-fits-all process. It is certainly plausible that      tions regarding adaptation and evolution that often arise in
agents in environments with mixed or changing difficulty lev-         cognitive science and psychology. Whereas previous stud-
els converge on a single strategy, but for the moment it seems        ies have worked from a particular strategy and examined the
that multiple strategies can be implemented across multiple           choice environments in which it succeeds, we present a way
choice environments.                                                  of answering questions about how the environment can shape
   While difficult conditions led to larger brains and more in-       the evolution of a strategy. The strategies resulting from this
formation processing, perhaps a more critical finding is that         computational evolution approach are adaptive, easily imple-
simpler choice environments led to simpler decision strate-           mented in the brain, and the result of realistic natural selec-
gies and architectures. While this may initially seem like the        tion pressures. Additionally, we have shown that this ap-
                                                                  1229

proach is capable of addressing important questions about ex-                                 References
isting models of simple dynamic decisions, though it could          Bogacz, R., Brown, E., Moehlis, J., Holmes, P., & Co-
undoubtedly shed light on an array of related problems.                hen, J. D. (2006). The physics of optimal decision
   Of course, there are limitations to this approach, many of          making: a formal analysis of models of performance in
which are computational. The agents we used had only 16                two-alternative forced-choice tasks. Psychological Review,
nodes, 4 of which were reserved for inputs and outputs, mean-          113(4), 700–765.
ing that only 12 could be used for storing (memory) and pro-        Brandstätter, E., Gigerenzer, G., & Hertwig, R. (2006). The
cessing information. Although more nodes could be added –              priority heuristic: Making choices without trade-offs. Psy-
and certainly an accurate model of even very simple nervous            chological Review, 113(2), 409–432.
systems would have many times more – this would severely            Briscoe, E., & Feldman, J. (2011). Conceptual complexity
slow down the steps required for evolution. It might also lead         and the bias/variance tradeoff. Cognition, 118(1), 2–16.
to problems that are analogous to the over-fitting that occurs      Dougherty, M. R., Franco-Watkins, A. M., & Thomas, R.
when more parameters are added to a model, though this is              (2008). Psychological plausibility of the theory of prob-
itself a question worth exploring.                                     abilistic mental models and the fast and frugal heuristics.
                                                                       Psychological Review, 115(1), 199–211.
Conclusions                                                         Edlund, J. A., Chaumont, N., Hintze, A., Koch, C., Tononi,
                                                                       G., & Adami, C. (2011). Integrated information increases
In this paper, we presented a computational evolution frame-
                                                                       with fitness in the evolution of animats. PLoS Computa-
work that could be used to examine how environments lead to
                                                                       tional Biology, 7(10), e1002236.
different behaviors. This framework allowed us to examine
                                                                    Gigerenzer, G., & Brighton, H. (2009). Homo heuristicus:
the strategies that might have arisen in organisms to address
                                                                       Why biased minds make better inferences. Topics in Cog-
the problem of dynamic decision-making, where agents re-
                                                                       nitive Science, 1(1), 107–143.
ceive information over time and must somehow use this input
                                                                    Gigerenzer, G., & Todd, P. M. (1999). Simple heuristics that
to make decisions that affect their fitness.
                                                                       make us smart. New York, NY: Oxford University Press.
   We found that both the evolutionary trajectory and the           Griffiths, T. L., & Tenenbaum, J. B. (2006). Optimal predic-
strategies ultimately implemented by the agents are heavily            tions in everyday cognition. Psychological Science, 17(9),
influenced by the characteristics of the choice environment,           767–773.
with the difficulty of the task being a particularly notable        Isler, K., & Van Schaik, C. P. (2006). Metabolic costs of brain
influence. More difficult environments tended to encourage             size evolution. Biology Letters, 2(4), 557–560.
the evolution of complex information integration strategies,        Kuzawa, C. W., Chugani, H. T., Grossman, L. I., Lipovich,
while simple environments actually caused agents to decrease           L., Muzik, O., Hof, P. R., . . . Lange, N. (2014). Metabolic
in complexity, perhaps in order to maintain simpler and more           costs and evolutionary implications of human brain devel-
robust decision architectures. They did so despite no explicit         opment. Proceedings of the National Academy of Sciences,
costs for complexity, indicating that mutation load may be             111(36), 13010–13015.
sufficient to limit brain size.                                     Laughlin, S. B., van Steveninck, R. R. d. R., & Anderson,
   Finally, we discussed these results in the context of exist-        J. C. (1998). The metabolic cost of neural information.
ing models of human decision-making, suggesting that both              Nature Neuroscience, 1(1), 36–41.
non-compensatory strategies such as fast and frugal heuris-         Link, S., & Heath, R. (1975). A sequential theory of psycho-
tics (Gigerenzer & Todd, 1999) and complex ones such                   logical discrimination. Psychometrika, 40(1), 77–105.
as sequential sampling (Link & Heath, 1975) may provide             Marstaller, L., Hintze, A., & Adami, C. (2013). The evolu-
valid descriptions – or at least serve as useful landmarks –           tion of representation in simple cognitive networks. Neural
of the strategies implemented by evolved agents. In doing              Computation, 25(8), 2079–2107.
so, we provided evidence that strategy use is environment-          Olson, R. S., Hintze, A., Dyer, F. C., Knoester, D. B., &
dependent, as different decision environments led to differ-           Adami, C. (2013). Predator confusion is sufficient to
ent patterns of information use. More generally, we have               evolve swarming behaviour. Journal of The Royal Society
shown that a computational evolution approach integrating              Interface, 10(85), 20130305.
computer science, evolutionary biology, and psychology is           Ratcliff, R. (1978). A theory of memory retrieval. Psycho-
able to provide insights into how, why, and when different             logical Review, 85(2), 59–108.
decision-making strategies evolve.                                  Von Neumann, J., & Morgenstern, O. (1944). Theory of
                                                                       games and economic behavior. Princeton, NJ: Princeton
                     Acknowledgments                                   University Press.
This work was supported by Michigan State University’s
High Performance Computing Facility and the National Sci-
ence Foundation under Cooperative Agreement No. DBI-
0939454 and Grant No. DGE-1424871.
                                                                1230

