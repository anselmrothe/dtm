         Not by number alone: The effect of teachers’ knowledge and its value in
                                               evaluating “sins of omission”
             Ilona Bass (ibass@wesleyan.edu)1 , Daniel Hawthorne-Madell (djthorne@stanford.edu)2 ,
               Noah D. Goodman (ngoodman@stanford.edu)2 , Hyowon Gweon (hyo@stanford.edu)2
                             1  Department of Psychology, Wesleyan University, Middletown, CT 06459
                                 2 Department of Psychology, Stanford University, Stanford CA, USA
                              Abstract                                 demonstrates one function of a single-function (thus being
                                                                       fully informative) (Gweon, Pelton, et al., 2014), and given a
   What constitutes good teaching, and what factors do learners
   consider when evaluating teachers? Prior developmental work         binary choice, even four-year-olds favor a fully-informative
   suggests that even young children accurately recognize and          teacher over an under-informative teacher (Gweon & Asaba,
   evaluate under-informativeness. Building on prior work, we          2015; see also Barner, Brooks, & Bale, 2011 for similar in-
   propose a Bayesian model of teacher evaluation that infers the
   teacher’s quality from how carefully he selected demonstra-         ferences in linguistic communication). These results suggest
   tions given what he knew. We test the predictions of our model      that even early in life, human learners recognize and evalu-
   across 15 conditions in which participants saw a teacher who        ate “sins of omission”–under-informative pedagogy that mis-
   demonstrated all or a subset of functions of a novel device and
   rated his helpfulness. Our results suggest that human adults        leads the learner to draw an inaccurate inference.
   seamlessly integrate information about the number of func-             Intuitively, not all sins of omissions are equally blamewor-
   tions taught, their values, as well as what the teacher knew,
   to make nuanced judgments about the quality of teaching; the        thy. What affects our evaluations of under-informative teach-
   quantitative pattern is well predicted by our model.                ing? One simple possibility is that the degree to which we pe-
   Keywords: pedagogy, Bayesian models, social learning,               nalize sins of omission is inversely related to the learner’s de-
   causal learning, pragmatics                                         gree of belief in the correct hypothesis. Thus the more infor-
                                                                       mation a teacher omitted, the more blame he would deserve.
                          Introduction                                 However, there are reasons to believe that people make more
Learning from others is beneficial, but the benefits come              nuanced judgments about under-informative teaching.
with hazards. By learning from knowledgeable, helpful oth-                First, going beyond the amount of omitted information,
ers, learners can draw powerful inferences that go beyond              people might also consider the value of what was omitted.
the face value of information. However, because its power              Because not all knowledge is equally useful or valuable,
hinges on the assumption that the teacher is knowledgeable             omission can have varying consequences for the learner de-
and helpful, learning can go awry when teachers are inac-              pending on the utility of the resulting knowledge. Consider
curate or misleading. Thus it is critical for learners to be           a gadget that has two buttons; one turns the gadget into an
sensitive to others’ quality as teachers.                              auto-navigating robot vacuum and the other activates a blink-
   Reasoning in pedagogical contexts can be formally de-               ing light on the side. Because learning about the former
scribed as a set of mutually constraining inferences (Shafto,          would be more useful than the latter, showing just the vac-
Goodman, & Griffiths, 2014). The teacher selects informa-              uum function would be considered less blameworthy than
tion that increases the learner’s belief in the target hypoth-         showing just the blinking light.
esis (pedagogical sampling), and the learner rationally up-               Furthermore, people might be sensitive to the reason be-
dates his beliefs with the assumption that the information has         hind the omission (i.e., the teacher’s intentions). In eval-
been pedagogically sampled. This leads to a strong expec-              uating harmful actions, both children and adults are sensi-
tation that information provided by the teacher is not only            tive to the intent of a perpetrator and appropriately exonerate
true but also sufficient for the learner to draw accurate infer-       those who caused accidental harms due to their ignorance or
ences. For instance, when a teacher pedagogically demon-               false beliefs (Hebble, 1971; Yuill & Perner, 1988; Young,
strates just one function of a multi-function device, a naı̈ve         Cushman, Hauser, & Saxe, 2007). In linguistic communica-
learner would (inaccurately) infer that the toy has one, and           tion, listeners flexibly adjust their interpretation of an utter-
only one, function; if there were more, a knowledgeable and            ance depending on the speaker’s knowledge; if the speaker
helpful informant would have shown them.                               didn’t have the knowledge to justify the stronger alternative,
   Prior developmental work suggests that young children               listeners don’t draw implicatures (Goodman & Stuhlmüller,
draw strong inferences from pedagogically sampled infor-               2013). Thus even in the absence of explicit information
mation in ways that are consistent with the model predic-              about others’ intentions, people spontaneously use informa-
tions (Bonawitz et al., 2011; Xu & Tenenbaum, 2007), and               tion about the others’ epistemic states to infer their intent.
appropriately respond to teachers who violate pedagogical              Similarly, in evaluating sins of omission, people might care
sampling (Gweon, Pelton, Konopka, & Schulz, 2014). For                 about whether or not the teacher knowingly omitted some-
instance, 6- and 7-year-olds rate a teacher as less help-              thing. Consider someone who demonstrated just one func-
ful when he demonstrates one function of a multi-function              tion of a four-function gadget, simply because he was un-
toy (thus being under-informative), compared to when he                aware of the other three functions. Although he might be
                                                                   166

independently blamed for his ignorance, we might exoner-            (α = 0) would choose demonstrations at random, preferring
ate him from being guilty of a “sin of omission” because his        less costly demonstrations; as α increases, a teacher would
ignorance suggests that the omission was unintended.                be more likely to select demonstrations that have high peda-
   In this study, we investigate whether people consider the        gogical utility, as good teachers would.
amount and the value of information as well as the teacher’s           For our model to predict how people evaluate the teacher,
knowledge to evaluate under-informative pedagogy. Previ-            we must specify the utility of the teacher: what counts as
ous Bayesian models of pedagogical reasoning have been              successful teaching? Shato et al. suggested that the teacher’s
extremely useful in formalizing our intuitions about what an        utility should be proportional to the log-probability that the
ideal learner might infer from pedagogically sampled data           learner will guess the correct hypothesis (2014). To apply
(Shafto et al., 2014) and in how learners might choose be-          this idea to cases where a device has different functions that
tween different teachers. For instance, Shafto, Gweon, Far-         vary in value, we must generalize this utility to capture the
gen, and Schulz (2012) looked at people’s evaluations of ef-        fact that there are different aspects of the device that the
ficient vs. inefficient teaching, and modeled people’s rela-        teacher could convey, each of which has its own utility to
tive preferences between two teachers as a ratio of two like-       the learner. Thus we can define the pedagogical utility of a
lihoods. However, these models assume that teachers are             particular set of demonstrations (d) as:
always fully knowledgeable and that all facts that could be
taught are equally valuable. Furthermore, they do not pro-                               U(d) = ∑ V ( fi ) ln pL ( fi |di )         (2)
                                                                                                     i
vide explicit, systematic predictions about people’s evalua-
tions of teachers based on their knowledge.                         where di is 1 if the ith function was presented and 0 other-
   Building on prior work, here we provide a computational          wise, pL ( fi |di ) is the teacher’s model of the learner’s beliefs
model of teacher evaluation. The model captures the idea            about function i after demonstration di , and V ( fi ) is the value
that good teachers will work harder to teach well, where            of function i. This pedagogical utility function is a general-
“teaching well” is specified by the pedagogical sampling as-        ization of previous accounts which examined the special case
sumption. We extend the underlying pedagogical model to             where all functions are equally valuable (effectively drop-
account for incomplete knowledge of the teacher as well             ping V ( fi ) from the equation). Assuming that a demonstra-
as the value of information taught. To test the model pre-          tion of each function provides an equal amount of informa-
dictions, we designed a behavioral task to get parametric           tion to the learner, and that a priori belief in each function is
evaluations of teachers’ ability in which we manipulated the        the same, Eq. (2) becomes (up to an additive constant which
knowledge of the teacher, the value of the knowledge, and           does not impact decisions):
the amount of knowledge communicated to the learner.
                                                                                             U(d) = ∑ kdiV( fi ),                   (3)
                             Model                                                                      i
Reasoning about a pedagogical situation requires a notion           where k is a constant reflecting the change in the learner’s
of the causal relations between the world and the teacher’s         belief that a function exists, resulting from a demonstration
actions—an intuitive theory of pedagogy that captures the           (this constant will be absorbed into the overall calibration of
teacher’s goal of informing the learner, and specifies what         utility below).
examples should be given to teach a particular fact or con-            The demonstrations that a teacher selects using Eq. (1),
cept. This theory can be used in learning from teachers (as         which uses this pedagogical utility (Eq. 3), depends on the
in Shafto et al., 2014), but also learning about the teach-         precise balance between the cost of demonstrations, the
ers themselves—the importance they place on informing the           teacher’s quality, and the value of each function. The demon-
learner and their ability to do so by choosing effective exam-      stration cost pulls against the tendency of high-quality teach-
ples of things that will be useful to the learner. To formalize     ers to teach everything they know, such that a high-quality
a theory of pedagogy, we first describe how a teacher might         teacher with high communication costs may only teach the
choose what demonstrations to give in different situations.         high value functions.
We do so with the standard softmax decision rule:                      To use this theory of pedagogy to evaluate (rather than
                                                                    learn from) a teacher, consider a person who knows that
                   p(d| f , α) ∝ eα U(d)−C(d) ,             (1)     a teacher knows functions f and observes the teacher’s d
                                                                    demonstration(s). This observer can use Bayes’ rule to in-
where f is the set of functions known to the teacher, and
                                                                    vert their model of how teacher’s select demonstration (Eq.
d is the set of demonstrations he provides to the learner.
                                                                    (1)) to infer the teacher’s quality:
C(d), which we set equal to the number of demonstrations
provided, corresponds to the cost of a given set of demon-                                p(α| f , d) ∝ p(d| f , α)p(α),            (4)
strations, and U(d) is the utility a learner is expected to ac-
crue from the demonstrations (Eq. 2). The parameter α con-          where p(α) represents the person’s prior beliefs of the
trols the degree to which the teacher chooses to maximize           teacher’s quality (we assume p(α) ∼ Uniform(0, 1)). The
the pedagogical utility of his demonstration. Thus α can be         resulting estimates of teacher quality are sensitive to the
interpreted as the teacher’s “quality.” An indifferent teacher      teacher’s epistemic state and the value of the functions
                                                                167

demonstrated. For example, the quality estimate of a teacher
who demonstrates two low-value functions but also knew of
a high value function will be lower than someone who just
knew the two low-value functions he taught. Similarly, a
teacher who knows both a high- and a low- value function
would get the highest rating for showing both, a lower rating
for omitting the low-value function, and an even lower rating
for omitting the high-value function.
                          Experiment
Methods
Participants All participants were recruited from Amazon
Mechanical Turk, and were paid $0.50 for compensation.
We excluded a total of 462 participants from analyses based
on a priori criteria (responses to check questions; see Proce-
dure) and 71 for participating more than once. The final sam-
ple consisted of 1024 participants (Age: µ(σ) = 36.2(12.6),
range: 18 - 72 yrs; 575 female).
Stimuli We generated cartoon scenarios in which one char-
acter (e.g., Paul) encounters a novel device and discov-
ers all four, or a subset (one or two) of its functions, and
then shows another character (e.g., Laura) all or a sub-
set of its functions. The device had four distinctive but-
tons that corresponded to each function. Pressing a red
circular button made the device verbally report the current
time; the purple lightning-shaped button reported the local
weather; the orange crescent-shaped button made the device
say “hello!”; and the green square button generated a beep
sound. The relative values of these functions were validated             Figure 1: Schematic of procedure in the KLL TL condition.
by a separate group of 52 mTurk participants who rank-                   The teacher discovers two low-value functions and teaches
ordered the four functions by their usefulness. Weather and              just one low-value function.
Time (µ(σ) = 3.4(0.29) ranked higher than Beep and Hello
(µ(σ) = 1.6(0.29);t(51) = 23.3p < .001), with no difference
within the high-value pair or the low-value pair (p’s> .298).            teacher to show her how the device works. In the fourth
Design We varied the number of functions the teacher dis-                phase, the teacher demonstrated some, or all, of its functions
covered (1, 2, or 4), the utility of the functions he discov-            (see Figure 1). Participants then answered the critical ques-
ered (H for high, L for low), and the number of functions he             tion: 1. Overall, how would you rate his teaching abilities?
demonstrated to the learner (1, 2, or 4). Crossing these vari-           We also asked additional questions in fixed order (2. Which
ables while excluding impossible cases yielded 15 conditions             functions did he discover? 3. Which functions did he teach?
(see Figure 2A for a full list of conditions). For instance, in          4. How well-intentioned do you think he was? 5. How nice
the KA TA condition the teacher Knew All and Taught All;                 do you think he is? 6. Given what he knew, how good a
in KHL TH, he knew two functions (one high-value and one                 job did he do? 7. How willing would you be to learn from
low-value) but taught only one high-value function. The ex-              him?). Finally we asked the first question again (8. Over-
act function taught among the two equally valued functions               all, how would you rate his teaching abilities?). We used a
(e.g. Weather vs. Time) was counterbalanced throughout.                  seven-point Likert scale for questions 1 and 4-8. Questions
                                                                         2 and 3 were used as check questions to exclude participants
Procedure Participants were randomly assigned to one of                  who did not pay close attention.
the 15 conditions and were shown the cartoon scenario that
corresponded to that condition. The first phase of the car-              Results and Discussion
toons introduced the device to ensure that the participants              Participants’ ratings of teacher ability in the first and the last
knew about all the functions; the second phase showed the                questions (Q1 and Q8: the teacher’s overall teaching abili-
teacher discovering some or all of the device’s functions. In            ties) were highly correlated (r(1021) = 0.833, p < .001). We
the third phase, the learner entered the room1 and asked the             therefore used the average of the two ratings in our analy-
   1 In conditions where the teacher did not know all the functions,
                                                                         ses. See Figure 2A for mean ratings of teacher ability in
the learner’s entrance interrupted the teacher’s discovery; this was     fected by the teacher’s incompetence or failure to discover all func-
to minimize the possibility that the participants’ ratings were af-      tions.
                                                                     168

all conditions. We conducted a linear regression to exam-            others’ knowledge after having been explicitly prompted to
ine the effect of (1) the number of functions demonstrated           think about it; if so, answering these questions would lead
by the teacher, (2) the value of these functions, and (3) num-       to amplified differences in people’s ratings of omissions. To
ber of functions the teacher knew on participants’ estimate          test this idea we performed an exploratory analysis compar-
of his ability. We coded these three factors as continuous           ing conditions in which the informant always taught just one
variables (to code the effect of the value of the demonstrated       function, with his knowledge base ranging from one to four
functions as a continuous variable, we quantified it as the          functions across conditions. We used the difference between
proportion of the high valued functions known to the teacher         the two “Overall” questions as the DV (as opposed to the
that were demonstrated). All three factors were highly sig-          mean) in a one-way ANOVA and found a significant main
nificant predictors. The higher the number of demonstra-             effect of prior knowledge (F(2, 527) = 31.9, p < .001). That
tions the higher the teacher was rated (β = 1.1,t(796) =             is, the less the teacher knew, the more likely participants
17, p < .001); the higher the value of his demonstrations, the       were to give a more generous rating for the teacher. When
higher he was rated (β = .66,t(796) = 4.8, p < .001); and            the teacher taught just one function but knew just one or two
the more functions the teacher knew, the lower he was rated          functions, people significantly increased their ratings relative
(β = −.3,t(796) = 17, p < .001); that is, when the teacher           to their initial rating (K1: µdi f f (σ) = 0.77(1.1),t(145) =
did not know as many functions, people were more likely to           8.4, p < .001; K2: µdi f f (σ) = 0.25(.95),t(256) = 4.1, p <
exonerate him for his limited knowledge. We further inves-           0.001). Conversely, when the teacher knew all functions but
tigated these main effects with targeted analyses of a subset        just taught one function, participants gave a harsher rating in
of the conditions that highlights the predicted effects of (a)       the final question relative to their initial rating (µdi f f (σ) =
naı̈ve omission, (b) the teacher’s prior knowledge, and (c) the      −.12(.63),t(126) = 2.1, p = .035).
effect of prompting intention and knowledge.
                                                                     Model Fit The two free parameters in the model—the dif-
a) Naı̈ve omission We first looked at conditions in which            ference in the utility of knowing a high vs. a low value
the informant discovered only a subset of the device’s func-         function, and the cost the teacher incurs by communicating a
tions, but taught everything he knew (KL TL, KH TH,                  function—were fit to the mean of participants’ estimates of
KLL TLL, KHH THH). A 2 (number: 1 or 2) x 2 (value:                  the teacher’s overall ability. As seen in Figure 2C, the result-
H or L) ANOVA found a significant main effect of number              ing model well predicts these ability estimates (R2 =0.96).
(F(1, 297) = 21.1, p < .001). We also observed a marginally
significant main effect of value (F(1, 297) = 2.9, p = .088),                            General Discussion
and the interaction was not significant (F(1, 297) = .27, p =        Here we presented a formal Bayesian account of how a
.603). Thus even when the teacher communicated all he                learner might evaluate a teacher. Our model considers the
knew, participants’ ratings still reflected the number of func-      amount of information a teacher provided, the value of that
tions taught.                                                        information, and what he knew (but didn’t show) to infer his
                                                                     “quality” as a teacher. Going beyond using the amount of
b) Informant’s prior knowledge We then looked at con-
                                                                     communicated information as a proxy for evaluating teach-
ditions in which the informant taught two functions but ei-
                                                                     ers, our behavioral results showed that human learners spon-
ther taught all he knew (KHH THH, KLL TLL) or a subset
                                                                     taneously consider both the reason behind a teacher’s omis-
of what he knew (KA THH, KA TLL). A 2 (prior knowl-
                                                                     sion (i.e., he didn’t show because he didn’t know) as well
edge: Knew Two (Taught All) or Knew All (Omitted)) x 2
                                                                     as the consequences for the learner (i.e., teaching X is more
(value: HH, LL) ANOVA found a significant effect of Prior
                                                                     valuable for the learner than teaching Y). Participants appro-
Knowledge (F(1, 285) = 30.9, p < .001): Even though the
                                                                     priately penalized or exonerated a teacher, generating graded
teacher showed the same number of functions, participants
                                                                     ratings that reflect the teacher’s quality in ways that are con-
took into account the teacher’s knowledge when rating his
                                                                     sistent with our formal analysis.
teaching abilities. See Figure 2B. We also saw a signif-
icant main effect of value (F(1, 285) = 12.0, p = .001) as              Both knowledgeability and helpfulness are important traits
well as an interaction (F(1, 295) = 5.6, p = .019). More             of good teachers, but not everyone around us is equally
specifically, the value of functions taught affected ratings         knowledgeable and helpful. In fact, violation of pedagogical
only when the teacher taught just a subset of what he knew           sampling occurs frequently in real-world learning contexts.
(t(132) = 3.8, p < .001); if he taught all he knew, the value        For instance, a well-intended, helpful teacher might provide
had no effect (t(153) = .084, p = .40).                              insufficient information because he didn’t have all the rele-
                                                                     vant knowledge. A fully knowledgeable teacher might omit
c) The effect of prompting intention and knowledge Our               information because she thought it is not worth teaching.
questionnaire had 8 questions, with the first and the last ques-     Furthermore, we have an intuitive sense that a “good” teacher
tion serving as our main dependent measure. Between these            is not just someone who provides everything he knows; it is
two identical questions, people were asked a few check ques-         someone who knows what’s best for the learner and prior-
tions as well as questions that prompted them to think about         itizes teaching “what matters”. Critically, what matters for
the knowledge of the teacher and the intention of the teacher.       the learner might not be the same as what matters for the
Thus it is possible that people are more likely to consider          teacher. Although our model does not yet capture all the
                                                                 169

Figure 2: A. Mean teacher ability rating in all 15 conditions. B. The effect of value depends on whether or not the teacher
knew more than he taught. C. Comparison of behavioral data and the model predictions. Each colored point corresponds to a
bar in the same color in A. The fit between model and human data is R2 = 0.96.
complexities and sophistication in gauging someone’s qual-            observer is still influenced by the pedagogical utility of the
ity as a teacher, it builds on, and importantly extends, prior        demonstration. Consistent with what is predicted by our
computational work on pedagogical reasoning by assuming               model, in our behavioral task participants were asked to eval-
that human learners integrate different sources of informa-           uate the teacher’s overall helpfulness, rather than the blame-
tion to distinguish potentially misleading teachers from those        worthiness of the omission per se.
who are truly knowledgeable and helpful.                                 In the current model, the teacher’s quality was defined
   Our behavioral results were remarkably well predicted by           as the degree to which he considered pedagogical utility
the model predictions. When the teacher knew all functions            when choosing demonstrations, with the assumption that the
of the device, people’s evaluations were rationally affected          learner would learn what was shown once. However, this
by both the number and the value of the functions he taught;          global weighting represents just one of many dimensions on
the more he showed, and the more valuable the functions that          which teaching can be evaluated. Indeed, people’s evalua-
he showed, the higher people rated his teaching effective-            tions of teaching may be even more nuanced than our model
ness. Furthermore, given two teachers who taught exactly the          presented here, and sensitive to factors that are left unex-
same functions, people’s judgments reflected the knowledge            plored in our current work. For example, one of the hall-
of the teacher; the less he knew (thus the less he omitted), the      marks of a good teacher is sensitivity to the difficulty of the
more generous the ratings were. While we used the average             subject material for the learner (i.e., “this is a difficult con-
of the first and the last questions for better reliability, these     cept, so I should show this example multiple times”), as well
effects were robustly present even in people’s responses to           as the learner’s epistemic states, learning style, and abilities
the first question (R2 = .93). These results suggest that hu-         (i.e., “she is quick so I shouldn’t dwell on this”, or “I’ll skip
man adults spontaneously consider both the potential intent           what he already knows”). Thus in some cases, omissions
of the teacher’s omission and its consequences for the learner        might not only be forgivable but even desired, especially
to give nuanced, graded judgments about others’ qualities as          when transmitting information can be costly (see Gweon,
teachers even without being explicitly prompted about their           Shafto, & Schulz, 2014 for children’s sensitivity to learner’s
intentions or knowledge.                                              epistemic states and cost of information). These abilities cor-
   One might wonder why we still observed an effect of num-           respond to rich knowledge of the subject domain and a more
ber of demonstrated functions when the teacher taught all             sophisticated model of learners’ abilities and goals, both of
he knew (see Naı̈ve Omission under Results). This is still            which were simple in the current model.
reasonable, because the teacher’s quality as judged by the               Furthermore, we have assumed that both the learner and
                                                                  170

the teacher have identical utility functions. Indeed, this is         an incredibly rich and exciting area for future computational
often not true in the real world, particularly in cases where         and empirical work. Our work provides an important step to-
young children or students learn from adult teachers; chil-           wards delineating the factors that we all consider in learning
dren are often taught what adults think is valuable for chil-         from whom to learn.
dren, rather than what children they themselves think is valu-
able (e.g., the value of math or history classes). Even within                           Acknowledgments
learners and within teachers there are vast differences in how        This work was supported by Varieties of Understanding grant
they value and prioritize different kinds of knowledge. These         from the John Templeton Foundation to HG and Jerome
are subtle yet critically important considerations that go into       Davis Research Fund at Oberlin College to IB.
designing curriculums in real-world educational settings, and
where future computational and empirical work can be use-                                      References
ful in formalizing what constitutes “good teaching.”                  Barner, D., Brooks, N., & Bale, A. (2011). Accessing the un-
   In our current work, we have considered cases where a                said: The role of scalar alternatives in children’s pragmatic
teacher omits functions with positive values. However, there            inference. Cognition, 118(1), 84–93.
are cases where omission leads to negative consequences               Bonawitz, E., Shafto, P., Gweon, H., Goodman, N. D.,
(e.g., a building manager who forgot to announce 3-day                  Spelke, E., & Schulz, L. (2011). The double-edged sword
water shutdown in your apartment). In fact, these are the               of pedagogy: Instruction limits spontaneous exploration
kinds of omissions that can elicit the harshest evaluations,            and discovery. Cognition, 120(3), 322–330.
and perhaps the most indicative of informants who should              Goodman, N. D., & Stuhlmüller, A. (2013). Knowledge and
be avoided in the future. Understanding the asymmetries                 implicature: Modeling language understanding as social
in omitting positively-valued and negatively-valued informa-            cognition. Topics in cognitive science, 5(1), 173–184.
tion is an interesting topic for future work.                         Gweon, H., & Asaba, M. (2015). Knowing what he could
   Recall that in our behavioral results, we observed a change          have shown: The role of alternatives in children’s evalu-
in people’s ratings between the first and the last questions            ation of under-informative teachers. Proceedings of the
(both of which were about his overall teaching abilities; see           37th Annual Conference of the Cognitive Science Society.
The effect of prompting intention and knowledge under Re-             Gweon, H., Pelton, H., Konopka, J. A., & Schulz, L. E.
sults). Between these two questions, people answered ques-              (2014, September). Sins of omission: Children selectively
tions that prompted them to think about the teacher’s inten-            explore when teachers are under-informative. Cognition,
tions and his knowledge. Even though these prompts are not              132(3), 335–341.
necessary for accurate evaluation, the effect of these prompts        Gweon, H., Shafto, P., & Schulz, L. E. (2014). Children
suggest that explicitly thinking about these factors can make           consider prior knowledge and the cost of information both
the differences even more pronounced. One interesting pos-              in learning from and teaching others. Proceedings of the
sibility is that people’s ability to think about others’ beliefs        36th Annual Conference of the Cognitive Science Society.
(Theory of Mind) is directly related to the extent to which           Hebble, P. W. (1971). The development of elementary
learners consider the teachers’ knowledge and intentions.               school children’s judgment of intent. Child Development,
Thus one might predict that people with impaired or low                 1203–1215.
Theory of Mind abilities might (a) show less consideration            Shafto, P., Goodman, N. D., & Griffiths, T. L. (2014). A
of the teacher’s knowledge and intent, but (b) benefit more             rational account of pedagogical reasoning: Teaching by,
from explicit prompting of these factors. Follow-up research            and learning from, examples. Cognitive psychology, 71,
is under way to investigate these possibilities.                        55–89.
                                                                      Shafto, P., Gweon, H., Fargen, C., & Schulz, L. (2012).
   We note that although our behavioral experiments allowed
                                                                        Enough is enough: Inductive sufficiency guides learners
a precise manipulation of what was taught and what the
                                                                        ratings of informant helpfulness. In Proceedings of the
teacher knew, it leaves an open question about whether stu-
                                                                        34th annual conference of the cognitive science society.
dents in real-world pedagogical settings are also sensitive to
                                                                      Xu, F., & Tenenbaum, J. B. (2007). Sensitivity to sampling
these factors. Furthermore, our participants were third-party
                                                                        in bayesian word learning. Developmental science, 10(3),
observers of a teacher-student interaction rather than the stu-
                                                                        288–297.
dents themselves. An interesting extension of this work is to
                                                                      Young, L., Cushman, F., Hauser, M., & Saxe, R. (2007). The
ask whether young learners, as students, also consider these
                                                                        neural basis of the interaction between theory of mind and
factors to evaluate teachers in more realistic, live interactions
                                                                        moral judgment. Proceedings of the National Academy of
with a teacher.
                                                                        Sciences, 104(20), 8235.
   As learners in the real world, we often face a challenge           Yuill, N., & Perner, J. (1988). Intentionality and knowledge
of dealing with both uncertainty about the world as well                in children’s judgments of actor’s responsibility and re-
as the uncertainty about others’ qualities as teachers. How             cipient’s emotional reaction. Developmental Psychology,
real-world learners exploit diverse sources of information,             24(3), 358.
including their own exploration of the world, to simultane-
ously learn about both other people and about the world is
                                                                  171

