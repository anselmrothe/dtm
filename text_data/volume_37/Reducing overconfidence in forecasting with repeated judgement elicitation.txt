         Reducing overconfidence in forecasting with repeated judgement elicitation
                                  Matthew Brian Welsh (matthew.welsh@adelaide.edu.au)
                                          Steve. H. Begg (steve.begg@adelaide.edu.au)
                                                      Australian School of Petroleum,
                                                   University of Adelaide, North Terrace
                                                        Adelaide, SA 5005 Australia
                             Abstract                                   future states of the world. For instance, oil industry
                                                                        economics are dependent on the accurate forecasting of
   Overconfidence is the tendency for people to underestimate
   the true range of uncertainty regarding unknown or future            future oil prices. The efficacy of the MOLE method on these
   values. It results in observed outcomes falling outside              sorts of tasks is, therefore, of interest.
   people’s estimated ranges more often than their stated
   confidence would suggest. Previous research has, however,            The MOLE process
   demonstrated various ways of reducing this bias and the
                                                                        The MOLE was developed with four key insights in mind.
   More-Or-Less-Elicitation (MOLE) tool has been designed to
   take these into account while leading people through an              The first has been known for over a century (Galton, 1907)
   elicitation. Previous research showed MOLE’s benefit on a            – that repeated estimates of a parameter can, to the extent
   visual estimation task but real world elicitation is more likely     that errors in the estimates are independent, be averaged to
   to involve forecasting future values. The current study              produce a better estimate. Previous work on elicitation has
   compared forecast ranges, for 7 and 28 day windows, elicited         also shown that repeatedly asking the same person to make
   via the MOLE and direct estimation. A significant reduction          the same estimate can increase accuracy to the extent that
   in overconfidence (the mismatch between stated confidence
   and the proportion of ranges containing the true value) was          independence in the estimates is maintained (Herzog &
   observed – from more than 25% to only 7%. We conclude                Hertwig, 2009; Vul & Pashler, 2008).
   that the MOLE is a useful tool for assisting forecasting.              The second is that people are better at making relative
                                                                        than absolute judgements (Stevens, 1957). That is, allowing
   Keywords: repeated judgement; elicitation; calibration;
   overconfidence; MOLE.
                                                                        people to select from amongst options rather than having to
                                                                        generate their own leads to more accurate estimates; an
                          Introduction                                  observation with echoes in the overconfidence literature,
                                                                        specifically Winman, Hansson and Juslin’s (2004)
Overconfidence (Tversky & Kahneman, 1974) refers to the                 observation that people are better at evaluating the
tendency for elicited ranges of possible outcomes to                    probability of a value falling within a range than they are at
underestimate the true uncertainty in a person’s knowledge.             generating a range to match a stated level of confidence.
That is, if a person is asked to give a range that they are               The third insight is that providing a starting point in an
confident to some stated level of confidence that a future (or          estimation process biases people’s estimates. Specifically, it
otherwise unknown) value will fall within, then the common              seems to set the region that they are willing to explore when
observation is that the true value is less likely to fall within        contemplating possible answers, such that estimates tend to
that range than their stated confidence indicates.                      cluster near any such anchoring value (Tversky &
   This effect, while robust and demonstrated to affect both            Kahneman, 1974). The same sort of priming effect seems,
naïve and expert participants (Lichtenstein, Fischhoff, &               sometimes, to occur when people generate their own starting
Phillips, 1982; Morgan & Henrion, 1990), has been shown                 point (for a discussion of this, see Block & Harper, 1991).
to be context dependent, with different elicitation methods               The final insight is that people, when deciding on an
known to affect the degree of overconfidence observed in a              estimate, have some range of values that they would
sample (see, e.g., Block & Harper, 1991 ).                              consider appropriate and, within which, they are indifferent.
   In light of the contextual nature of overconfidence, the             This explains the impact of anchoring values in that
MOLE (More-Or-Less-Elicitation) process was developed                   adjustments away from the anchor stop when this region of
to improve calibration of estimated ranges. Specifically,               indifference is reached and thus estimates tend to lie at the
reducing overconfidence by leading participants through an              anchor end of the region a person considers possible
elicitation process designed to limit bias and work in concert          (Kahneman, 2011). The implication of this for range
with people’s natural cognitive tendencies. Previous                    estimation is that a process building a range from the centre
experiments (Welsh, Lee, & Begg, 2008, 2009), have shown                out will tend to produce a narrower range than one that
that this process increased accuracy of best guesses as well            creates a range from the outside in, as shown in Figure 1.
as improving calibration on a simple, perceptual task –
estimating the number of circles on a display.                          Aims
   The elicitation tasks that are of greatest application to
                                                                        The aim of this paper is to compare the calibration achieved
real-world problems, however, involve the prediction of
                                                                     2637

by the computerized elicitation method (MOLE) described            into a graphical user interface (GUI) for delivery via the
above with that of a direct estimation elicitation in which        MOLE but delivered as a paper and pencil test for the direct
participants are asked to provide minimum and maximum              estimation. For the UK participants, both the MOLE and
values directly. Specifically, whether the advantage               direct estimation methods were delivered via GUI. Figure 2
observed for the MOLE on visual tasks remains on a                 shows the GUI as it appears during elicitation using MOLE.
forecasting task, where participants estimate ranges they are
confident will contain the true value that a parameter of                    Table 1. Commodities/parameters by quiz.
interest will take at specified points in the future.              Q.    Forecast Quiz 1 (Gold)              Quiz 2 (Silver)
                                                                         Window
(a)              Possible Low-End Values                           1     7           Gold price              Silver price
                                                                   2     28          Gold price              Silver price
                                                                   3     7           Maximum Temp            Minimum Temp
Minimum                                                            4     28          Maximum Temp            Minimum Temp
                                                      Best Guess   5     7           Rainfall total          Wind Speed
                                                                   6     28          Rainfall total          Wind Speed
(b)              Possible Low-End Values                           7     7           Share price             Share index
                                                                   8     28          Share price             Share index
                                                                   9     7           Oil price               Gas price
 Figure 1. Pictorial representation of estimating the low-end
                                                                   10 28             Oil price               Gas price
  value of an uncertainty range, working from: (a) the best
                                                                   NB – the specific values asked from varied across locations.
  guess; (b) a minimum value. Note that working from best
                                                                   E.g., the Share price asked for was for each participant’s
guess rather than the minimum value results in a higher low-
                                                                   own company and the share index was for their country of
    end estimate and thus a narrower range overall.
                                                                   residence (Dow Jones for US; FTSE100 for UK).
                            Method
Participants
Participants were 158 oil industry personnel employed in
the US (n =115) and UK (n = 43). While, for confidentiality
reasons, demographic data are not included, previous work
suggests a mean age of around 40 and an average of 15
years of industry experience is typical; as is a 3 or 4:1 male
to female gender ratio (see, e.g., Welsh, Begg, & Bratvold,
2006; Welsh, Bratvold, & Begg, 2005). Given the involved
companies’ interests in seeing overall results for their
personnel, all participants willing to take part were
accepted, rather than determining numbers in advance.
However, analyses were not begun until all data collection
was complete within a given jurisdiction.
Materials
                                                                         Figure 2. GUI showing snapshot of MOLE process
The MOLE and direct estimation methods both asked
participants 10 questions regarding the values of 5                Procedure
commodities/shares at times 7 and 28 days following
testing. Two equivalent question sets were developed –             Participants were tested in small groups (2-4) within their
labeled Gold and Silver after the first commodity included         company offices over a period of approximately 1 month –
in each. Table 1 lists the commodities asked for in each.          in each case. Which quiz a participant undertook under each
  It is important to note that this design, with testing across    elicitation method was determined randomly. That is,
an extended period and yet with all participants making            approximately half of participants completed the Gold quiz
forecasts across the same duration, results in individual          using the MOLE and Silver using the standard elicitation,
results being dependent on the volatility of the parameters        while the remainder did the reverse. Which of the methods
across that period. That is, participants using the same           was delivered first was also randomized. The specific
starting value on different days and making the same range         procedure used within each method is described below.
estimate may end up with different calibration scores as a
result of the true value on the target days differing. A period    Standard Elicitation Procedure
of low volatility could, thus, mask poor calibration.              Under the standard elicitation condition, participants were
  For the US participants, the quiz questions were coded           asked to give ranges they were certain would contain the
                                                                   true value of the parameters of interest at the specified time.
                                                                 2638

That is, they were asked for their minimum and maximum                  each parameter) with the range that remained at the end
values. (This was done in preference to the more common                 recorded as the participant’s final range estimate. As noted
80 or 90% confidence intervals to ensure comparability with             in previous versions of this task (Welsh, et al., 2008, 2009),
the MOLE, which generates 100% confidence intervals.)                   it is possible to use MOLE results to generate a full
   These were either recorded on a paper copy of the quiz or            distribution and calculate a best estimate from a
entered directly into the GUI. Prior to testing, participants           participant’s responses. Given the use of a simple range
were asked to record the current value of the parameter of              elicitation as the comparison condition, however, this was
interest – to ensure that they had some idea of what the true           not done here – avoiding concerns about the assumptions
value was and thus better reflect real forecasting tasks where          used to generate a best estimate from the raw data.
people forecast values that they are familiar with.                        Participants were not made aware of the underlying
   It was decided not to ask participants for a best guess as           MOLE algorithm, ensuring that any attempts to ‘game the
this affects the width of elicited ranges in complex ways               system’ would be made blind.
(see, e.g., Block & Harper, 1991; Heywood-Smith, Welsh,
& Begg, 2008), including a suggestion that it affects ranges                      Table 2. Initial bounds for MOLE process.
differentially according to a person’s level of expertise in a                            US                           UK
subject (Bruza, Welsh, Navarro, & Begg, 2011).                          Q. Gold             Silver           Gold          Silver
                                                                        1     ±5%           ±5%              ±10%          ±10%
MOLE Procedure                                                          2     ±10%          ±10%             ±10%          ±10%
The MOLE required the elicitor to set initial bounds on the             3     30-110F       30-110F          -20-40C       -20-40C
range of values that the computer uses – based on                       4     30-100F       30-110F          -20-40C       -20-40C
extrapolations of historical data or natural limits (where              5     0-7 in.       0-60 mph         0-100mm       0-90kmph
available). The bounds used for the different quiz questions            6     0-20 in.      0-60 mph         0-200mm       0-90kmph
are shown in Table 2. Note that some were based on the                  7     ±5%           ±5%              ±5%           ±5%
parameter’s current value while others were based on
                                                                        8     ±10%          ±10%             ±10%          ±10%
historical data. In both cases, however, the participant was
                                                                        9     ±5%           ±10%             ±5%           ±10%
tasked with entering the current value into the MOLE GUI
                                                                        10 ±10%             ±20%             ±10%          ±20%
immediately prior to the elicitation beginning. In this way,
participants were assured of knowing something about the                   Note: where a ±% value is indicated, the bounds were
                                                                        calculated from the current value of the parameter. Note 2:
parameter in question.
                                                                        the UK 7-day bounds are, in places, wider than their US
   For each parameter elicitation, the program randomly
selected two values from the uniform distribution delimited             equivalents for reasons detailed below.
by these bounds and presented both to the participant,
asking which was closer to the true value. The participant                                          Results
then rated their confidence in their choice on a scale from             On Bounds
guessing to very high1 (as seen in Figure 1).                           The US sample was collected several months before the UK
   This confidence rating was used by the MOLE to                       sample and, as such, observations from this were used to
determine whether the range of values being considered                  update our process for determining bounds. Specifically, it
should be truncated. Specifically, if the participant selected          was observed that the bounds used for the Silver price
an option with maximum confidence, the MOLE ruled out                   underestimated the volatility in the market – preventing a
any values lying closer to the non-selected option. That is, it         number of participants from being able to capture the true
truncated the range at the midpoint of the two current values           value in their final ranges, no matter what choices they
and selected future values only from the remaining range.               made during the MOLE. In light of this, the ranges used for
Any confidence level below the maximum resulted in no                   the UK sample were widened on this question and analyses
truncation of the range – the interpretation being that lower           exclude this question from the US.
confidence ratings indicated a person still believed it                    Otherwise, the differences in bounds reflect differences in
possible that the alternate value could lie closer to the truth.        expected weather for the participants’ local areas and
   Following this, the MOLE selected a new pair of values               changes of units from metric to imperial where appropriate.
from the (possibly truncated) range and presented these for
the participant to choose between – as detailed above.                  Equivalency of Quizzes
   The MOLE iterated through his process 10 times (for
                                                                        Apart from the effect noted above for the silver question, the
                                                                        US sample’s performance on the questions from the Gold
   1
     This scale was mapped over the top of the 50% - 100%               and Silver quizzes was statistically equivalent. Calibration
confidence scale used in previous versions of the MOLE – as a           on the ‘Gold’ and ‘Silver’ question sets was compared for
result of discussions with the companies providing participants.        both 7 day and 28 forecasts using Welch’s t-tests. These
While this, necessarily, reduces our ability to interpret results, it   showed no difference between people’s performance on the
should be noted that the effect of this can only be to narrow ranges
                                                                        two sets of questions, M = 82.8 and 84.0, t(228) = 0.42, p =
when the numerical scale might otherwise leave it intact. Thus, this
change can only hinder the MOLE.
                                                                        0.674 on the 7 day forecasts and M = 84.0 and 85.7, t(228)
                                                                      2639

= 0.58, p = 0.566 on the 28 day forecasts.                          the MOLE and direct estimation was 17% on the 7 day
  The UK sample is slightly more complex in that, while             forecast and 27% at 28 days. Paired sample t-tests
there is no observed difference between participants’               comparing mean calibration at each forecast length
performance on the Gold and Silver quizzes under the                confirmed these differences were significant, t(42) = 4.3 and
MOLE, there is one using the standard elicitation method,           5.9, p = 1.06x10-4 and p = 5.97x10-7, A = 0.734 and 0.779.
with the average calibration being 20% lower on the Gold
quiz. On examination of the data, it was noted that, during
                                                                                              1
the period of testing for the UK sample, the parameters on
the Gold quiz happened to be markedly more variable than
                                                                          Mean with 95% CI
those on the Silver quiz. The average difference between the                                 0.9
minimum and maximum values observed for the various
parameters across the date range (i.e., D = (Max-Min)/Max)                                   0.8
was 0.37 for the Gold quiz compared to 0.22 for the Silver.
  In light of the larger US sample’s results, however, it was                                0.7
decided that this did not call into question the equivalency
of the questions, per se, and analyses are carried out on the                                0.6
combined data in both cases.
                                                                                             0.5
Calibration                                                                                        7 Day                28 Day
Participants’ calibration was calculated simply as the
proportion of their ranges containing the true value (given                                           MOLE        Est
that 100% confidence intervals were elicited). Figures 3 and              Figure 3. Mean calibration by elicitation condition and
4 show mean calibration by forecast window and elicitation                            forecast window (US sample)
conditions for the US and UK samples, respectively.
   Looking at Figure 3, initially, one sees two very clear
results. The first is that the forecast length had no effect on                               1
people’s calibration – with little difference seen between the
7 and 28 day forecasts under either condition in paired                                      0.9
                                                                          Mean with 95% CI
samples t-tests, t(114) =0.493 and 1.81, p = .623 and .073, A
(common language effect size - specifically, the measure of                                  0.8
stochastic superiority; Vargha & Delaney, 2000) = .526 and
.539, for the direct estimation and MOLE conditions
                                                                                             0.7
respectively. That is, while participants did, in both
conditions, increase the width of their ranges for the 28 day
forecasts relative to the 7, the benefit in terms of calibration                             0.6
was zero as the additional range width was offset by the
parameters’ greater volatility in the longer term.                                           0.5
   The second observation is that the MOLE method                                                  7 day                28 day
produced markedly better calibration for both 7 and 28 day
forecasts – with approximately 17% more of its ranges                                                 MOLE        Est
containing the true value than is observed for the direct
estimation method.         Paired sample t-tests comparing                Figure 4. Mean calibration by elicitation condition and
participants’ calibration on the two elicitation methods (for                        forecast window (UK sample)
each forecast length separately) unambiguously support this,
t(114) = 6.92, p = 2.78x10-10 for the 7 day data and t(114) =          Looking at Figure 4 and the t-test results described above,
6.06, p = 1.77x10-8 for the 28 day forecasts. The effect sizes      it seems clear that there is an interaction effect – with the
were large and close to identical, A = 0.734 and 0.730.             longer period affecting calibration only for participants
   Turning to Figure 4, one sees a similar pattern of results –     during the direct estimation condition. That is, greater
although the 28 day result for the direct estimation method         volatility on the Gold quiz questions (discussed above) led
shows a decline in calibration as a result of the greater           to a decrease in calibration for participants undertaking the
volatility in the Gold quiz questions discussed above. A            direct estimation conditions, but no such decrease for
paired sample t-test indicated that the difference observed         participants answering the same questions using the MOLE.
here was significant, t(42) = 3.1, p = .004, A = .604. A
second, paired sample t-test indicated no difference between                                         Discussion
participant’s 7 and 28 day forecast calibration using the           The results confirm that the MOLE’s advantaged over direct
MOLE, t(42) = 0.22, p = 0.824, A = 0.521.                           estimation elicitation methods in previous, perceptual
   The difference between participants’ mean calibration on         studies (Welsh, et al., 2008, 2009) transfers to a forecasting
                                                                   2640

paradigm with greater applicability to real world problems.         It should also be noted that a typical calibration task
   While the MOLE does not eliminate overconfidence (this        asking for 80% confidence intervals can equally easily be
may, in fact, be impossible where error is involved - as         ‘gamed’ by providing 80% extremely wide ranges and 20%
discussed by Soll & Klayman, 2004), it reduces it to less        extremely narrow (or just plain wrong) estimates. Any
than 10% in all conditions – averaging just under 7%. This       tendency that a person has towards such behavior would,
is less than a third the overconfidence observed in the direct   presumably, benefit their calibration scores in the direct
estimation conditions, which averages just over 25% across       estimation task to a greater extent than in the MOLE which,
all conditions.                                                  as noted above, did not make clear to participants the
   Some other results do, however, require additional            process by which it created a range from their responses.
explanation; for instance, in the UK sample, additional          Thus, to the extent that such effects impact the data, it
volatility in some parameters across the experiment’s            would be expected to erode differences between the two
(moving) forecast window led to a marked decrease in             conditions – which remain marked.
calibration in the direct estimation task but not the MOLE.         The second concern is the requirement that the
A likely cause of this is the outside-in method the MOLE         experimenter set the initial bounds for the MOLE – as
uses to construct its final range. As shown in Figure 1, this    demonstrated by our own failure to account for the volatility
is predicted to result in wider ranges – as was observed.        of the silver price. While this increases the potential for
   These ranges are, however, still expected to correspond to    overconfidence in the MOLE results – by causing cases
an individual’s beliefs. By requiring participants to            where it is impossible to create a range that contains the true
definitively rule values out before removing them from           value – more judicious use of historical data and natural
consideration (rather than asking whether they should be         bounds renders this a relatively minor concern. Certainly,
included), the MOLE preserves as much of a person’s              defining an initial range is a problem shared with any
‘region of uncertainty’ as possible. Given the participant       elicitation method that seeks to guide participants to
(presumably) believes any value within this range is             consider a wider range (see, e.g., Haran, Moore, &
possible – all of them should fall within a 100% confidence      Morewedge, 2010, who ask participants to assign
interval and the MOLE makes this far more likely.                probabilitites across the full range of possible answers - as
   That this makes ranges wider is unsurprising but the fact     defined by the experimenters).
that it also prevents the drop off in calibration seen with
unexpectedly high volatility demonstrates the approach’s         Future Research
strength and seems to have strong parallels with Yaniv and       While the basic efficacy of the MOLE process for reducing
Foster’s (1995) accuracy/informativeness trade-off. That is,     overconfidence has been demonstrated, there remain a
people accept values presented by the MOLE as possible,          number of questions regarding its operation that require
despite the fact that they would not report such values          further exploration. The first is to test the impact of
themselves for fear of them being deemed uninformative.          changing the initial bounds on the final ranges generated
   Another interesting observation is the equivalence of         from the MOLE – beyond the initial requirement of getting
results across the forecast windows. Specifically,               the bounds wide enough to begin with to ensure that the
participants maintained the same calibration when                participants can create a range that contains the observed
predicting further into the future by giving wider ranges,       value. If the MOLE is working as it should, then wider
mirroring the observation that expert and novice forecasters     ranges shoulder result only in people cutting more of the
maintain similar levels of overconfidence despite                range away to reach the same final width – with the other
differences in knowledge (McKenzie, Liersch, & Yaniv,            possibility being that the initial selection of bounds affects
2008). This suggests that people may have a stable,              the final range and thus that a reevaluation of the MOLE
preferred level of calibration.                                  might be required in light of such evidence of bias.
                                                                    Additional work is also required to determine whether the
Caveats                                                          current mechanism for reducing those bounds is too
As noted above, both the MOLE and direct estimation              conservative or, alternatively, not conservative enough. That
conditions are assumed, herein, to yield 100% confidence         is, whether people are accidentally removing sections of
intervals – that is intervals the participant believes will      range that they do not intend to or unable to remove sections
definitely contain the true range. While this could, in the      that they consider unfeasible. The current MOLE process
direct estimation condition, lead to ‘sandbagging’ (i.e.,        does not have a mechanism for testing this – for example,
generating 0 to ∞ ranges to guarantee success), this is not      by occasionally providing a value from outside the current
observed in the data due to people’s tendency towards            range as a test that it is, in fact, considered unfeasible.
informativeness (Yaniv & Foster, 1995). (In fact, such wide         Finally, while not contemplated in the current experiment,
ranges are not generally appropriate. For example,               the MOLE procedure is designed to improve accuracy as
“temperature measured at Heathrow Airport” will not ever         well as calibration – via repeated judgements and the
exceed 400°C - the autoignition point of jet fuel and, thus,     elimination or watering down of anchoring/priming effects.
the temperature at which the airport (and its thermometers)      Given this, a variety of experimental tests are possible. For
will cease to exist.)                                            instance: altering the number of iterations the MOLE runs
                                                               2641

for and observing the effect this has on best estimates; and        Calibration of probabilities: the state of the art to 1980.
measuring the decline in the strength of any anchoring              In D. Kahneman, P. Slovic & A. Tversky (Eds.),
values as the MOLE progresses.                                      Judgment under Uncertainty: Heuristics and biases.
   This work would seem to lead, naturally, to consideration        Cambridge: Cambridge University Press.
of the best algorithms for selecting values to be presented to   McKenzie, C. R., Liersch, M. J., & Yaniv, I. (2008).
participants. Currently, the MOLE selects values randomly           Overconfidence in interval estimates: What does
from a uniform distribution covering the remaining range at         expertise buy you? Organizational Behavior and Human
any point in the experiment and runs for a set number of            Decision Processes, 107(2), 179-191.
iterations. A more intelligent algorithm, however, could take    Morgan, M. G., & Henrion, M. (1990). Uncertainty: a guide
into account past values or select the most efficient               to dealing with uncertainty in quantitative risk and
comparisons when testing a participant’s range or                   policy analysis. Cambridge: Cambridge University
determining when the process should be terminated.                  Press.
                                                                 Soll, J. B., & Klayman, J. (2004). Overconfidence in
Conclusion                                                          Interval Estimates. Journal of Experimental Psychology:
The MOLE method produces ranges significantly wider                 Learning, Memory and Cognition, 30(2), 299-314.
than those generated by participants required to directly        Stevens, S. S. ( 1957). On the psychophysical law.
estimate the minimum and maximum points of a range. This            Psychological Review, 64(3), 153-181.
results in markedly less overconfidence.                         Tversky, A., & Kahneman, D. (1974). Judgment under
   Given the common observation that people, in general,            uncertainty: Heuristics and biases. Science, 185, 1124-
are overconfident – underestimating the range of possible           1131.
outcomes – the use of elicitation tools such as the MOLE,        Vargha, A., & Delaney, H. D. (2000). A critique and
designed in line with established psychological theory,             improvement of the CL common language effect size
seems a useful method for improving forecasting accuracy.           statistics of McGraw and Wong. Journal of Educational
                                                                    and Behavioral Statistics, 25(2), 101-132.
                    Acknowledgments                              Vul, E., & Pashler, H. (2008). Measuring the crowd within:
                                                                    probabilistic     representations    within    individuals.
The authors thank the sponsors of the Centre for Improved           Psychological Science, 19(7), 645-647.
Business Performance research program at the University of       Welsh, M. B., Begg, S. H., & Bratvold, R. B. (2006). SPE
Adelaide’s Australian School of Petroleum: BG Group,                102188: Correcting common errors in probabilistic
ExxonMobil, Santos & Woodside.                                      evaluations: efficacy of debiasing. Paper presented at the
                                                                    Society of Petroleum Engineers 82nd Annual Technical
                        References                                  Conference and Exhibition., Dallas, Texas, USA.
Block, R. A., & Harper, D. R. (1991). Overconfidence in          Welsh, M. B., Bratvold, R. B., & Begg, S. H. (2005). SPE
    estimation: testing the anchoring-and-adjustment                96423 - Cognitive biases in the petroleum industry:
    hypothesis. Organizational Behavior and Human                   impact and remediation. Proceedings of the Society of
    Decision Processes, 49, 188-207.                                Petroleum Engineers 81st Annual Technical Conference
Bruza, B., Welsh, M. B., Navarro, D. J., & Begg, S. H.              and Exhibition.
    (2011). Does anchoring cause overconfidence only in          Welsh, M. B., Lee, M. D., & Begg, S. H. (2008). More-or-
    experts? Paper presented at the Annual Meeting of the           Less Elicitation (MOLE): Testing a heuristic elicitation
    Cognitive Science Society (33rd: 2011: Boston, USA)             method. In V. Sloutsky, B. Love & K. McRae (Eds.),
    CogSci 2011.                                                    30th Annual Conference of the Cognitive Science
Galton, F. (1907). Vox populi. Nature, 75, 450-451.                 Society. Austin, TX: Cognitive Science Society.
Haran, U., Moore, D. A., & Morewedge, C. K. (2010). A            Welsh, M. B., Lee, M. D., & Begg, S. H. (2009). Repeated
    simple remedy for overprecision in judgment. Judgment           judgments in elicitation tasks: efficacy of the MOLE
    and Decision Making, 5(7), 467-476.                             method. In N. Taatgen, H. v. Rijn, L. Schomaker & J.
Herzog, S. M., & Hertwig, R. (2009). The wisdom of many             Nerbonne (Eds.), Proceedings of the 31st Annual
    in one mind: improving individual judgments with                Conference of the Cognitive Science Society. Austin,
    dialectical bootstrapping. Psychological Science, 20(2),        TX: Cognitive Science Society.
    231-237.                                                     Winman, A., Hansson, P., & Juslin, P. (2004). Subjective
Heywood-Smith, A., Welsh, M. B., & Begg, S. H. (2008).              probability intervals: how to reduce overconfidence by
    Cognitive errors in estimation: does anchoring cause            interval     evaluation.    Journal    of    Experimental
    overconfidence? Paper presented at the Society of               Psychology: Learning, Memory and Cognition, 30(6),
    Petroleum Engineers 84th Annual Technical Conference            1167-1175.
    and Exhibition, Denver, Colorado.                            Yaniv, I., & Foster, D. D. (1995). Graininess of judgment
Kahneman, D. (2011). Thinking, Fast and Slow. New York,             under uncertainty: an accuracy-informativeness trade-
    NY: Farrar, Straus, Giroux.                                     off. Journal of Experimental Psychology: General,
Lichtenstein, S., Fischhoff, B., & Phillips, L. D. (1982).          124(4), 424-432.
                                                               2642

