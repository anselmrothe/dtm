             Restoring the Context of Interrupted Work with Desktop Thumbnails
              Adam Rule, Karen Boyd, Jim Hollan (acrule, hollan@ucsd.edu, karenboyd@gmail.com)
                Department of Cognitive Science, UC San Diego, 9500 Gilman Drive, San Diego, CA 92093 USA
                                       Aurélien Tabard (aurelien.tabard@univ-lyon1.fr)
                                                        Université de Lyon, CNRS
                                         Université Lyon 1, LIRIS, UMR5205, F-69622, France
                              Abstract                                 ton, 2002) and their retrieval can be "blocked" if the inter-
                                                                       rupting activity is sufficiently similar to the suspended one
   Knowledge work is frequently interrupted. Interruptions ena-        (Gillie & Broadbent, 1989). We refer to these memories as
   ble collaboration and bring timely information, but they dis-       an activity’s mental context. This context can be quite com-
   rupt the fragile context of ongoing activities. Computers, now      plex, especially for dynamic, creative, and non-linear activi-
   ubiquitous in knowledge work, have improved in their ability
   to track and restore digital context (documents and files), but
                                                                       ties like data analysis, programming, and writing. It often
   they do a poor job of helping users restore mental context: the     includes information that is ephemeral or difficult to repre-
   ideas, intentions, and motivations behind their work. Thumb-        sent externally such as intentions (“I’ll call Bill next”), mo-
   nail images are an efficient way to help computer users re-         tivations (“this letter needs to sound more professional”),
   find documents; we ask if they can also be used to restore          and ideas (“this graph may look better on a log scale”).
   mental context. We tested how three manipulations to thumb-
   nails of personal computer screenshots impact their ability to      Activity-Based Computing
   help viewers recognize past activities and recall accurate and
   detailed context. In a 2-week study we found that thumbnails        Knowledge work increasingly involves computers, but
   of portions of the screen need to be larger than thumbnails of      computers have historically done a poor job supporting in-
   the entire screen for successful activity recognition and that      terrupted and interleaved work (Bannon et al., 1983). In the
   static screenshots prompted more accurate contextual recall         realm of restoring artifacts, switching tasks on a computer
   than animations.                                                    can take a flurry of finding, opening, and rearranging win-
   Keywords: interruptions; memory; thumbnails; activity-              dows. Activity-Based Computing has attempted to address
   based computing                                                     this issue by making it easier to manipulate groups of doc-
                                                                       uments (Bardram, Bunde-Pedersen & Soegaard, 2006). The
                          Introduction                                 paradigm can trace its roots back to Henderson and Card’s
Knowledge work is frequently interrupted. One 13-month                 Rooms work in 1986 and has seen a resurgence of interest in
study found that knowledge workers switch activities once              recent years (Dumais et al., 2003; Kaptelinin 2003; Karger
every 12 minutes (e.g. from writing a report to calling a              et al., 2005; Rattenbury & Canny 2007) but has yet to have
customer) and that the majority of these activities (57%) are          a significant presence in mainstream operating systems.
interrupted (Mark, Gonzalez & Harris, 2005). This fragmen-             Regardless, this research only addresses half the problem.
tation is not necessarily bad. Interruptions bring timely in-          Computers provide even less support for what is often the
formation, foster collaboration, and direct attention to inter-        harder part of restarting an interrupted activity: restoring
esting or urgent work. But resuming interrupted activities             mental context (Iqbal & Horvitz, 2007).
takes time and energy. Early research estimated that pro-
grammers spend 15 minutes after each interruption “regain-             Visual Memory
ing concentration” (Solingen, Berghout & Latum 1998).                  One promising approach to restoring mental context was
Another field study by Iqbal and Horvitz (2007) confirmed              demonstrated by Cangiano et al. (2009) who found that
that people spend a significant amount of time restoring               people who watched screen-recordings of past work were
their mental state after re-finding relevant papers and docu-          able to remember contextual details such as why they were
ments. Likewise, knowledge workers find it harder to restart           working on a particular project or who they were talking to
interrupted tasks than to start new ones (Czerwinski, Horvitz          at the time. Humans have excellent visual memory. Partici-
& Wilhite, 2004).                                                      pants shown 2560 images for 10 seconds each were able to
   Resuming knowledge work, which is characterized by                  correctly select which of two images they had seen before
manipulating information in external artifacts and internal            90% of the time when tested two days later (Standing et al.,
memory to solve non-routine problems, takes cognitive ef-              1970). A more recent study found that subjects were able to
fort. While interruptions can make artifacts hard to find,             correctly identify the image they had seen before 87% of the
physically or digitally obscuring them under the artifacts of          time when the only difference between the images was the
intervening tasks, they are particularly disruptive to the con-        pose of an object, such as the arrangement of beads on an
tents of working memory. These memories get harder to                  abacus (Brady et al., 2008).
reactivate the longer an interruption lasts (Altmann & Traf-
                                                                   2045

   Cangiano et al. demonstrated that humans can do more              H1: People will recognize activities with smaller thumb-
than discriminate; they can also attach complex meaning to         nails if those thumbnails show a cropped portion of the
images, even passively taken ones. Sellen et al. (2007) con-       screen. By forcing people to “fill-in” screen content,
firmed this result, finding that images taken automatically        cropped thumbnails will cue less accurate but more detailed
by a wearable camera cued as detailed of episodic memories         memories than full-screen thumbnails as people search
as images taken by actively pressing a button. Passively           memory for context rather than read it off the thumbnail.
recording and then visualizing knowledge work may ease
the burden of resuming interrupted activities by helping           Animation
people restore mental context that was never externalized in       By displaying activity over time, animations provide more
artifacts.                                                         information than individual screenshots, potentially helping
                                                                   users distinguish similar activities and retrieve more specific
Thumbnails                                                         memories. However, making sense of animations takes fo-
Research on visualizing and recognizing computer activity          cus and may cause viewers to neglect context held in
has focused on website thumbnails. Kaasten, Greenberg &            memory (Tversky, Morrison, & Betrancourt 2002).
Edwards (2002) showed that people could reliably (80% of             H2: Animations will cue more accurate but less detailed
the time) identify a website domain they had previously            memories than screenshots.
visited (e.g. www.cnn.com) using a 132 x 132px thumbnail
image of that website and could identify its exact topic (e.g.     Rehearsal
a CNN article on the 2008 election) with a 208 x 208px             Rehearsing memories makes them easier to recall, but can
thumbnail. Moreover, Teevan et al. (2009) found that peo-          also change their contents (Hupbach et al., 2008). Asking
ple were able to re-find previously visited websites more          people to reflect on particular moments may make those
quickly using thumbnails than page titles.                         moments easier to recall, but can also restrict the number of
   But, these studies are limited to web-browsers and the          details they remember about them.
recognition of well-defined pages. While useful, they do not         H3: Memories for moments that have been rehearsed will
address the complex nature of real-world work that typically       be more accurate but less detailed than those for unre-
involves not only multiple applications but also dynamic,          hearsed moments.
creative, and non-linear activities. Our work expands on this
research by asking if thumbnails can be used to represent                                      Methods
not only documents, but also whole activities and their men-
tal context.
                                                                   Participants and Materials
           Research Question & Hypotheses                          Six graduate students (4 female, ages 23-29) recorded their
                                                                   workday (Mon-Fri) computer activity for two weeks using a
Q: How do the cropping, animation and rehearsal of a
                                                                   modified version of Selfspy1, an open-source key-logger.
thumbnail showing a computer desktop impact its ability to
                                                                   The computers used for recording included stand-alone lap-
help people recognize past activities and recall accurate and
                                                                   tops, laptops connected to an external monitor, and all-in-
detailed context.
                                                                   one desktops. The tool took a screenshot every time a partic-
                                                                   ipant clicked or typed, and every 30 seconds while their
Cropping
                                                                   computer was awake but idle. All screenshots were stored
Small thumbnails that show a full desktop can be ambigu-           on an SD card. Participants received $50 in gift cards.
ous; windows are tiny, text is unreadable, and it is hard to
see the user’s cursor. Keeping the thumbnail the same size         Procedure - Recording
but having it show only a small portion of the screen, such
                                                                   Participants could pause the recording at any time and were
as the area around a user’s cursor, may support better activi-
                                                                   instructed to do so whenever they used their computer to
ty identification as users see one region in detail and may be
                                                                   communicate with someone outside the study. Every 30
able to mentally “fill in” the rest from memory (Figure 1).
                                                                   minutes, Selfspy showed the participant a recent screenshot
                                                                   and asked them “What are you doing?” Participants could
                                                                   ignore these experience samples, but were encouraged to fill
                                                                   out as many as possible. At the end of each day, participants
                                                                   were asked to provide additional detail on up to five sam-
                                                                   ples from earlier that day. While viewing each sample’s
                                                                   screenshot and textual description participants answered the
                                                                   following questions:
  Figure 1: Cropped thumbnails (B) can be the same size as              1.    What do you remember about this moment?
    full-screen thumbnails (A) but show less of the screen
                                                                     1
                                                                       https://github.com/activityhistory/selfspy
                                                               2046

      2.   How do you know these details? (I remember this         Measures
           moment exactly, I know from experience, or I’m          We measured participant’s responses in six ways:
           guessing)
      3.   How well does this image represent what you were              1.   Thumbnail size (for static thumbnails) or duration
           doing? (Very well, Somewhat, or Not at all)                        (for animations) at the point of activity recognition
                                                                         2.   Self-rated Memory Strength and Thumbnail Ap-
These responses gave us a detailed baseline description of                    propriateness
what participants were doing at the time of the sample.                  3.   Memory Accuracy
Work by Brandt, Weiss and Klemmer (2007) has shown that                  4.   Episodic Detail
asking users to write short descriptions in the moment and               5.   Event Specificity
fill in details later reduces the impact of experience sam-              6.   Time Discussed
pling interruptions but maintains response quality.
                                                                   We coded each response for measures 3-6. Memory Accu-
Procedure - Testing thumbnails                                     racy was coded on a scale of how well the activity described
Participants attended a one-hour lab session at the end of         in the review matched the activity described in the end-of-
each week to review up to 40 thumbnails representing mo-           day debrief. The levels included 0) no match, 1) partial
ments from the prior week.                                         match, and 2) mostly matches. Accuracy could only be cod-
   The thumbnails varied along three conditions, meaning           ed for rehearsed thumbnails since unrehearsed thumbnails
we tested 8 variations in a 2x2x2 design:                          had no end-of-day debrief responses for comparison. For
                                                                   Episodic Detail, we recorded the number of contextual de-
         A. Screenshot or animation                                tails shared about an activity including who, what, where,
         B. Full screen or cropped                                 when, why and feeling information. For Event Specificity,
         C. Rehearsed moment (e.g. described in detail at the      we recorded the number of events described in the response
             end of a day earlier that week) or unrehearsed        at the Action (i.e. “copy and pasting”), Activity (“editing
             moment (randomly selected)                            this discussion slide”), or Project (“working on my presenta-
                                                                   tion”) level. Lastly, we coded whether the text mentioned
We tested the four types of screenshot thumbnail during the        events that took place in the Past, Present, or Future relative
first week’s review (i.e. screenshot condition with BxC).          to the time the thumbnail was taken.
Similar to Kaasten et al. (2002), when the participant                 Two authors (AR and KB) coded the responses to the
pressed a start button, a 20px high thumbnail would appear.        end-of-day debriefs for the first week of the study and iter-
(The width of the thumbnail depended on the recording              ated the coding rubric until they achieved a Cohen’s Kappa
computer’s screen ratio). Every two seconds the thumbnail          of >0.60 for each category. They then separately coded the
grew 20px taller and proportionately wider until the partici-      thumbnail responses.
pant recognized the represented activity and pressed a but-
ton to stop the growth. Full screenshots showed the partici-                                   Results
pant’s entire screen whereas cropped screenshots showed an
                                                                   We fit a mixed linear model to each measure, using anima-
expanding area around the user’s mouse. Participants then
                                                                   tion, cropping, and rehearsal as our predictor variables. Sig-
answered the three questions used in the end-of-day debriefs
                                                                   nificant effects were detected by removing individual pre-
and moved on to the next thumbnail.
                                                                   dictors from each model and using a one-way ANOVA to
   We tested the four types of animation thumbnail in the se-
                                                                   test for differences between the full and reduced models.
cond week. Each animation showed a time-lapse of five
minutes of computer activity played at 5x normal speed.            Size of Screenshot Thumbnails
Full animations showed the participant's full screen at the
native resolution of the recording computer, while cropped         Participants reliably (80% of the time) recognized their ac-
animations showed a 520px high area around the partici-            tivity when full screenshots thumbnails were 320px tall (x̄
pant’s cursor location at the time of recording. (520px was        =240px, σ=154px) and when cropped screenshot thumbnails
the height at which our first four participants could recog-       were 460px tall (x̄ =370px, σ =210px). For our participants,
nize 80% of the activities in their week 1 cropped screen-         these heights corresponded to thumbnails that were 30% and
shots). Participants pressed a button to start each animation,     45% the height of their screen, respectively. This difference
pressed a second button once they recognized the represent-        was significant (χ2=23.50, df=2, p<0.001). Rehearsing,
ed activity, and then filled out the debrief questions before      however, did not have an effect on the required thumbnail
moving on to the next thumbnail.                                   size (x̄ r=306px, x̄ u=305px, χ2=1.79, df=2, p>0.05).
   Two participants had too few debriefed experience sam-
ples in the second week to include their data. In total, we        Duration of Animation Thumbnails
collected 145 responses to screenshots and 70 to animations.       Participants reliably (80% of the time) recognized their ac-
                                                                   tivity before the 9.5 second mark of full-screen animations
                                                                   (x̄ =8.0s, σ=4.1s) and the 14.5 second mark of cropped ani-
                                                               2047

mations (x̄ =8.1s, σ=5.3s). This difference was not signifi-       Time Discussed
cant (χ2=1.79, df=2, p>0.05) nor was the difference between        Participants were also consistent across conditions in how
rehearsed and unrehearsed thumbnails (x̄ r=8.2s, x̄ u=7.9s,        often they discussed past events (29% of responses) or fu-
χ2=1.91, df=2, p>0.05).                                            ture events (24%). Nearly half (47%) of responses included
                                                                   a reference to either past or future events. Of those cases
Memory Strength, Thumbnail Appropriateness,                        where multiple time periods were mentioned, participants
and Accuracy                                                       were equally likely to move forward or backward in time
Participants tended to rate memories cued by animations as         (χ2=0.096, df=1, p=0.757).
stronger than those cued by screenshots (x̄ a=1.53, x̄ s=1.26,
max=2, χ2=8.87, df=4, p=0.064) but gave similar ratings                                     Discussion
across the cropping and rehearsal conditions. Thumbnails
were given similar ratings of appropriateness across all con-      Cropping
ditions. However, memories were more accurate when cued
by screenshots than animations (x̄ s=1.70, x̄ a=1.27, max=2,       Cropped thumbnails had to be larger than full-screen
χ2=11.628, df=2, p<0.01).                                          thumbnails to cue recognition of past computer activity, but
                                                                   there was no difference in the accuracy or detail of the
Episodic Detail                                                    memories they cued. This evidence does not support H1.
                                                                     Looking at how participants used thumbnails helps ex-
Participants were remarkably consistent across conditions in       plain why. In some cases a small cue such as a unique photo
the number and type of details they shared in their respons-       brought back a set of memories. For example, upon seeing a
es. While responses to animations were significantly shorter       160px high cropped screenshot showing part of a gorilla,
(x̄ a=34.1 words, x̄ s=61.0 words χ2=16.68, df=4, p<0.01),         one participant recognized that they were “watching a
they were equally likely to include each of the six types of       webpage to look up some information about Koko the goril-
contextual information we tracked. Figure 2 shows the fre-         la and his vocalization abilities.” But more often, partici-
quency of each type of contextual information across all           pants pieced together what they were doing from multiple,
conditions.                                                        distributed cues. For example, in the following response, the
                                                                   participant uses the fact that two windows were open simul-
                                                                   taneously to remember a past meeting, why they had that
                                                                   meeting, and what they planned to do afterwards. “Here I
                                                                   have the Github page for DIVY open and I also have the
                                                                   Terminal window open so this is when I was meeting with
                                                                   John… so I could try out some of my data clustering with
                                                                   this code to see if it works for me and then we could show it
                                                                   to the Smith lab.” The cropped screenshot thumbnail that
                                                                   cued this response had to expand to be 640px high before
                                                                   the participant recognized their activity.
                                                                     We also found that the mouse is not a good measure of at-
                                                                   tention. Often the mouse was over a blank or unremarkable
 Figure 2: Participants recalled why, who, and when context        portion of the screen so participants had to wait a long time
               in a large proportion of responses                  before the cropped thumbnail included relevant information.
Event Specificity                                                  Animation
Participants were consistent across conditions in the ab-          Participants tended to be more confident of memories
stractness of events they described. Of those cases where          prompted by animations but these memories were surpris-
participants mentioned multiple levels of events, such as          ingly less accurate. Animations prompted shorter responses
talking about an activity and then describing the individual       but these included as much contextual information
actions that made up that activity, they were much more            (who/what/where/when/why/feeling) as responses prompted
likely to start with high-level events and then describe low-      by static screenshots. This evidence does not support H2.
er-level ones (as happened 71% of the time) than to go from          One cause of this mismatch between perceived and actual
describing low-level events to high-level ones (28% of the         accuracy was that in several cases participants simply de-
time) (χ2=21.6, df=1, p<0.001). Thus statements of the form        scribed what was happening in an animation and ignored
“Here I was trying to find car insurance again [high], trying      mental context. For example, compare the following end-of-
to get a quote from a different company [low]” were more           day debrief and review text cued by an animation.
common that those of the form “I'm copying labels in the             Debrief: “So I released a batch of twenty participants
dictionary [low] so that I can make a count of how many            through Mechanical Turk this morning at 9am and for some
certain types of signs there are in the sign language and          reason the traffic was very slow today. So until 2pm I think I
handshake dictionary [high]”.                                      had only gotten about ten people. But then I didn't want to
                                                               2048

wait until I get all twenty so I went ahead and analyzed the        events included motivations, a number were outcomes “this
data just to see the pattern and saw that it wasn't in the di-      isn't the way I ended up solving [this problem].”
rection that I wanted.”
   Review: “So I was making a pivot table and I was trying          Limitations
to see if I saw any pattern from my data, but I'm not sure if       Given privacy concerns with recording computer activity,
it was before I got all my data or after.”                          we only recruited 6 participants, who provided 215 respons-
   The debrief focuses on motivating events and talks about         es. These participants were graduate students whose work
the activity abstractly, “analyzed the data”, whereas the re-       often involves a small number of projects. Other working
view text is much more specific, “making a pivot table”, but        styles could have produced different results. We also did not
fails to mention the larger context.                                balance presentation of screenshots and animations across
                                                                    the two weeks of our study, so the differences between
Rehearsal                                                           screenshots and animations may be an artifact of having an
We found no difference in the memories cued by rehearsed            extra week to practice giving responses.
and unrehearsed thumbnails. Several factors could have led
to this result. First, there may have been too much time be-                         Implications for Design
tween debriefing and reviewing. Whatever memory benefit
the rehearsal provided may have dissipated by the time of           Thumbnails of full-screen images
review. Alternatively, our participants, all graduate students,
                                                                    Without a better predictor of users’ attention than the mouse
may have been working on too few projects for rehearsing
                                                                    (e.g. gaze), full-screen thumbnails can be smaller than
to have a targeted effect. Since graduate students usually
                                                                    cropped thumbnails and covey as detailed of memories.
work on a few large projects, letting them rehearse five
                                                                       Our results also suggest that thumbnails still work for
memories from the day may have effectively let them reflect
                                                                    recognizing cross-application activities, but need to be larg-
on most of their projects. This evidence does not support
                                                                    er (320px high for 80% recognition) than those used for
H3.
                                                                    recognizing website (208px high according to Kaasten et al.
Content of Memories                                                 (2002)). This result is encouraging since a website thumb-
                                                                    nail is a summary of one window, but a desktop thumbnail
A large proportion of responses described why an activity           contain more content (overlapping windows, toolbars, etc.).
was taking place (47%), who was involved (40%) and when             This size increase may also be an artifact of computer moni-
it occurred (38%). Some explanations of why an activity             tors increasing in pixel density over the last decade.
occurred were quite complex, describing multiple, conflict-
ing motivations or a sequence of actions that depended on           Animations are less effective than expected
the current action. Descriptions of when an activity took
                                                                    We found that animations, at least 5x time-lapses, cue less
place were often relative such as “before starting my day” or
                                                                    accurate memories than screenshots and found no evidence
“during lab meeting.” Absolute time (e.g., 3pm) was rarely
                                                                    that they produce memories that are any more detailed.
mentioned, though participants did use the computer clock
                                                                    Showing activity over time may be better accomplished
in thumbnails to distinguish similar activities or confirm
                                                                    with small-multiples or thumbnails that allow scrubbing.
guesses, such as “Oh, yep. Tuesday morning. That would
make sense.”
                                                                    No need for rehearsing
   To check if these contextual details were recalled from
memory or could have been read directly from the thumb-             We did not find evidence that random experience sampling
nail we conducted a post-hoc analysis. On average, respons-         and rehearsing improved memory in our tasks. This is in
es included 4.47 (σ =1.89) episodic details and of these,           line with Sellen et al.’s (2007) finding that passively taken
1.95 (σ =1.60) seemed to be reconstructed from memory.              images were as good of triggers for remembering past
Specifically, the majority of feeling information (98%), why        events as actively taken images. This does not diminish the
(81%), and where (78%) information seemed to be recon-              value of bookmarking past events to create landmarks for
structed from memory whereas when (47%), who (41%) and              future reviewing, but one should not expect these events to
what (34%) information were more likely to have been rep-           be more memorable than others.
resented directly in the thumbnail.
   Participants mentioned activities in most of their respons-                               Conclusion
es (86%) such as “going through and finding references              Existing computer systems do a poor job of helping users
from other references” or “trying to find pictures of my two        restore the mental context of interrupted activities. This res-
advisors”. They also mentioned actions in most responses            toration is particularly challenging for dynamic, creative,
(56%), but these were often just descriptions of what was on        and non-linear activities that span multiple applications.
the screen, “I see that I was sending an email to someone”.         Given humans’ excellent visual memory, we investigated
   Participants also frequently mentioned events leading up         how visual thumbnails of computer desktops could help
to or after the thumbnail (47% of responses). Many of the           restore the memories that make up this context. Our work
past events were motivation, and while many of the future           extends the scope of previous thumbnail research from rep-
                                                                2049

resenting previously visited websites to representing cross-        Brandt, J., Weiss, N., & Klemmer, S. R. (2007). txt 4 l8r:
application activities and their context.                             lowering the burden for diary studies under mobile condi-
   Our two-week field study of six graduate students con-             tions. Proceedings from CHI ‘07 (pp. 2303–2308). ACM.
firmed that thumbnails cue a significant amount of contex-          Cangiano, G. R., & Hollan, J. D. (2009). Capturing and re-
tual information. We compared eight types of thumbnails:              storing the context of everyday work: A case study at a
full screenshots, cropped screenshots, full animations, and           law office. In Human Centered Design (pp. 945–954).
cropped animations (each with or without rehearsal). Across           Springer.
conditions, a non-trivial proportion of thumbnail responses         Czerwinski, M., Horvitz, E., & Wilhite, S. (2004). A diary
included information about what activity was taking place             study of task switching and interruptions. Proceedings
(99%), why it was happening (47%), who was involved                   from CHI ‘04 (pp. 175–182). ACM.
(40%), and when it happened (38%). Between conditions,              Dumais, S., Cutrell, E., Cadiz, J. J., Jancke, G., Sarin, R., &
we found that 80% of activities could be recognized with              Robbins, D. C. (2003). Stuff I’ve seen: a system for per-
full screenshot thumbnails that were 320px high, whereas              sonal information retrieval and re-use. Proceedings from
thumbnails cropped around a region of interest (cropped               SIGIR ‘03 (pp. 72–79). ACM.
screenshots) needed to be 460px high. Animations cued               Gillie, T., & Broadbent, D. (1989). What makes interrup-
more targeted but less accurate memories than screenshots,            tions disruptive? A study of length, similarity, and com-
which is surprising as we expected that seeing the activity           plexity. Psychological Research, 50(4), 243–250.
unfold would lead to more accurate memories. Rehearsal              Hupbach, A., Hardt, O., Gomez, R., & Nadel, L. (2008).
had no discernable impact on the accuracy or detail of re-            The dynamics of memory: Context-dependent updating.
called context.                                                       Learning & Memory, 15(8), 574–579.
   There is a rich design space to be explored in future re-        Iqbal, S. T., & Horvitz, E. (2007). Disruption and recovery
search. For example, we plan to explore composing activity-           of computing tasks: field study, analysis, and directions.
specific thumbnails from snippets of multiple application             Proceedings from CHI ‘07 (pp. 677–686). ACM.
events (e.g., a series of movements between applications            Kaasten, S., Greenberg, S., & Edwards, C. (2002). How
related to accomplishing a specific activity) rather than fo-         people recognise previously seen Web pages from titles,
cusing exclusively on thumbnails of a specific screen loca-           URLs and thumbnails. In People and Computers XVI-
tion at a specific moment in time. Animations may be more             Memorable Yet Invisible (pp. 247–265). Springer.
useful in showing these tightly coupled sequences. Another          Kaptelinin, V. (2003). UMEA: translating interaction histo-
important next step will be to document how the contextual            ries into project contexts. Proceedings from CHI ‘03 (pp.
information cued by thumbnails is actually used to restart            353–360). ACM.
interrupted activities, as the use of this information will in-     Karger, D. R., Bakshi, K., Huynh, D., Quan, D., & Sinha, V.
form how it should be represented.                                    (2005). Haystack: A customizable general-purpose infor-
   Our findings support the notion that visual cues can be            mation management tool for end users of semistructured
used to recall the detailed context of complex activities.            data. In Proc. of the CIDR Conf.
This finding is important because recovering context is a           Mark, G., Gonzalez, V. M., & Harris, J. (2005). No task left
key first step towards restarting interrupted activities.             behind?: examining the nature of fragmented work. Pro-
                                                                      ceedings from CHI ‘05 (pp. 321–330). ACM.
                    Acknowledgments                                 Rattenbury, T., & Canny, J. (2007). CAAD: an automatic
This research was funded by NSF grant #1319829                        task support system. Proceedings from CHI ‘07 (pp. 687–
                                                                      696). ACM.
                                                                    Sellen, A. J., Fogg, A., Aitken, M., Hodges, S., Rother, C.,
                         References                                   & Wood, K. (2007). Do life-logging technologies support
Altmann, E. M., & Trafton, J. G. (2002). Memory for goals:            memory for the past?: an experimental study using
   An activation-based model. Cognitive Science, 26(1), 39–           sensecam. Proceedings from CHI ‘07 (pp. 81–90). ACM.
   83.                                                              Standing, L., Conezio, J., & Haber, R. N. (1970). Perception
Bannon, L., Cypher, A., Greenspan, S., & Monty, M. L.                 and memory for pictures: Single-trial learning of 2500
   (1983). Evaluation and analysis of users’ activity organi-         visual stimuli. Psychonomic Science, 19(2), 73-74.
   zation. Proceedings from CHI ‘83 (pp. 54–57). ACM.               Teevan, J., Cutrell, E., Fisher, D., Drucker, S. M., Ramos,
Bardram, J., Bunde-Pedersen, J., & Soegaard, M. (2006).               G., André, P., & Hu, C. (2009). Visual snippets: summa-
   Support for activity-based computing in a personal com-            rizing web pages for search and revisitation. Proceedings
   puting operating system. Proceedings from CHI ‘06 (pp.             from CHI ‘09 (pp. 2023–2032). ACM.
   211–220). ACM.                                                   Tversky, B., Morrison, J., & Betrancourt, M. (2002). Ani-
Brady, T. F., Konkle, T., Alvarez, G. A., & Oliva, A.                 mation: can it facilitate? International Journal of Human-
   (2008). Visual long-term memory has a massive storage              Computer Studies, 57, 247–262.
   capacity for object details. Proceedings of the National         Van Solingen, R., Berghout, E., & van Latum, F. (1998).
   Academy of Sciences, 105(38), 14325-14329.                         Interrupts: just a minute never is. IEEE Software, 15(5),
                                                                      97–103.
                                                                2050

