            Go fishing! Responsibility judgments when cooperation breaks down
   Kelsey Allen (krallen@mit.edu), Julian Jara-Ettinger (jjara@mit.edu), Tobias Gerstenberg (tger@mit.edu),
                    Max Kleiman-Weiner (maxkw@mit.edu) & Joshua B. Tenenbaum (jbt@mit.edu)
                    Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139
                                Abstract
   Many social judgments hinge on assigning responsibility to in-
   dividuals for their role in a group’s success or failure. Often the
   group’s success depends on every team member acting in a ra-
   tional way. When someone does not conform to what others
   expect of them, cooperation breaks down. We present a com-
   putational model of responsibility judgments for individuals
   in a cooperative setting. We test the model in two behavioral
   experiments where participants were asked to evaluate agents
   acting in a cooperative, one-shot game. In Experiment 1, we
   show that participants’ action predictions are consistent with a
   recursive reasoning model. In Experiment 2, we show that peo-          Figure 1: Set-up of three fishermen in a fishing village with a
   ple’s assignments of blame are influenced by both an agent’s           road blocked by three trees.
   presumed rationality, or adherence to an expected policy, as
   well as the pivotality of the agent’s actions, or how close the        based on retrospective evaluations of how much an action
   situation was to one in which the action would have made a             contributed to a good or bad outcome. A specific action re-
   difference to the outcome.
   Keywords: responsibility attribution; theory of mind; recur-           ceives more blame to the extent that it made a negative differ-
   sive reasoning; multi-agent coordination.                              ence to the team’s outcome.
                                                                             Our work is in part inspired by Lagnado et al. (2013), who
                           Introduction                                   proposed a specific model for these two factors in the con-
Imagine that you are a fisherman living in a remote village in            text of team actions with all-or-nothing reward, i.e., the team
the Amazonian rainforest. Your village survives by trading                either succeeds or fails. They captured action-centric respon-
fish with neighboring groups who visit each day, and then                 sibility with a counterfactual measure they called “pivotal-
distributing the profit amongst all villagers. One morning,               ity”, and person-centric responsibility with a measure they
you wake up to find out that the only road into your village              called “criticality”. We find that in extending this approach
is blocked by three trees that fell during an overnight storm.            to cooperative action with graded potential rewards, where
Someone needs to clear the road or else your village will be              the team can succeed to a greater or lesser extent, both of
unable to trade today. You know most of the fishermen are                 these notions have to be generalized. Pivotality is relatively
stronger than you, and certainly strong enough to move the                straightforward; in the example above, only the strong fish-
trees without your help before traders arrive. Since it is in             ermen were pivotal, because only if they had chosen to clear
everyone’s best interest to clear the road, you assume that               the road would the outcome have been different. The most
the stronger fishermen will clear the road, and you head out              interesting new contribution of our work is in assessing the
early to fish. When you come back with the day’s catch, you               person-centric aspect of responsibility. We find that rational-
discover that the road is still blocked. Everyone went fishing            ity, or the assumption that your teammates will do what you
and assumed that someone else would clear the trees. Who’s                expect them to do, influences people’s responsibility judg-
to blame?                                                                 ments.
   Assigning responsibility when a team’s efforts go right or                Intuitively, rationality is a key component of blame attribu-
wrong is an essential element of social life. Our goal in this            tion for many everyday cooperative tasks. If you are distribut-
paper is to propose and test a new computational model for                ing bonuses to employees at an investment firm, you may not
these responsibility judgments in a cooperative setting. Pre-             want to give as much money to a broker whose strange de-
vious psychological accounts of credit and blame (Lagnado,                cisions cost the company revenue. A coach who made a bad
Gerstenberg, & Zultan, 2013; Gerstenberg, Ullman, Kleiman-                call instructing the quarterback to pass the football instead of
Weiner, Lagnado, & Tenenbaum, 2014; Spellman, 1997) have                  running it up the field might be blamed more for the team’s
identified two broad factors as important in evaluating agents            failure than the receiver who didn’t catch the ball. To illus-
and their actions. The first are person-centric (Gerstenberg              trate the importance of rationality in our fishermen example,
et al., 2014), based on expectations about how people are                 imagine once again you see three trees blocking the road. In
likely to act, or norms of how they should act in a given set-            this life, you are strong, so you could either go clear all three
ting. Someone is blamed more to the extent that they failed to            trees, or collect three fish sacks. Your two friends Arnold and
act the way they were expected to. This motivates a consid-               Bob, however, are weaker. Bob can either clear one tree from
eration of rationality as capturing an agent’s ability to plan            the road, or collect one fish sack, while Arnold can clear two
according to an appropriate norm (Johnson & Rips, 2015).                  trees, or collect two fish sacks (see Figure 1). Because you
The second are action-centric judgments (Spellman, 1997),                 know that neither of your friends is strong enough to clear the
                                                                       84

road themselves, you choose to go clear the trees and expect       more than one way for the group to get the optimal reward,
your friends will go fishing. However, when you get to the         and these have conflicting strategies for each agent, the choice
road you find that Arnold is also there, and it’s too late now     is less clear.
for him to go fishing. The road is cleared at the end of the
                                                                   Recursive reasoning with soft-max We model the uncer-
day, but your village ended up trading only one fish sack (that
                                                                   tainty in this decision making process by considering rational
Bob collected). Arnold’s choice didn’t cause the group to
                                                                   agents who each try to best respond to their companions at a
fail, but it nevertheless turned out to have been a bad choice.
                                                                   level k depth of reasoning (Yoshida, Dolan, & Friston, 2008).
What matters here is not just the pivotality of each action in
                                                                   We can then define the probability of a fisherman i taking ac-
hindsight, but also each agent’s rationality at the stage when
                                                                   tion ai at a depth of reasoning k according to a soft-max on his
the actions were planned. If Arnold had reasoned similarly
                                                                   expected reward for action ai . This involves two steps: first
to you, he would have realized that you would clear the trees,
                                                                   calculating the probabilities for the actions of the other agents
and therefore he would have gone fishing. It was therefore
                                                                   at a level k − 1, and then choosing a response that maximizes
his inability to predict the actions of the other agents in the
                                                                   your own expected reward under these probabilities:
group and plan accordingly which led to the group receiving
less than the ideal outcome.                                                                            exp(βr̂k [ai ])
   The remainder of the paper is organized as follows. We                            pk (ai ) =                                    (1)
                                                                                                       ∑ exp(βr̂k [ai ])
first develop and experimentally verify a model of how agents                                     ai ∈actions
in this coordinative, one-shot game should act under various                          r̂k [ai ] = E−ik−1 [R|ai ]                   (2)
configurations of fishermens’ strengths and number of trees.
We then show that both person-centric rationality and action-      pk (ai ) is the probability, at level k, that fisherman i should
centric pivotality are important aspects of blame attribution      take action ai . R is the reward table describing the number of
when the fishermen are not able to achieve their optimal out-      fish sacks sold by the fishermen under each combination of
come. Finally we suggest follow-up experiments to test the         actions. R|ai is then the subset of rewards where fisherman i
sensitivity of human judges to optimality, as well as investi-     took action ai . r̂k [ai ] is the expected reward at level k of ac-
gations of credit attribution and how judgments change over        tion ai , calculated using pk−1 [a−i ]. Finally, β is a rationality
time when there are repeated interactions between fishermen.       parameter describing how likely the agent is to choose a ran-
                                                                   dom action (with β = 0 being completely random, and β >> 1
                  Computational Models
                                                                   corresponding to always choosing the action which gives the
We use the experimental paradigm outlined in the introduc-         maximal expected reward).
tion and consider three fishermen (A, B and C) living in
the village. They live far away from each other, each near         Alternative uniform choice over optimal strategies A
a pond in which they can fish. There is also a road en-            reasonable alternative model might be to consider agents who
tering the village which is blocked by either one, two or          choose an action uniformly from those which might lead to
three fallen trees (referred to as T = 1, 2, 3). The fishermen     an optimal reward. In the case T = 3, S(A) = S(B) = 1, and
each have an associated strength (between one and three, re-       S(C) = 2, this model would predict a 50% likelihood for fish-
ferred to as S(A), S(B) and S(C)) which corresponds to how         erman A to clear the trees and a 100% likelihood for fisher-
many sacks of fish they can obtain from one day of fishing,        man C to clear the trees. Here, there are two sets of actions
or the number of trees they can clear from the road. The           leading to optimal reward: fisherman A fishes while B and C
scenario from Figure 1 would therefore be represented as           clear the road, or fisherman A and C clear the road while B
T = 3, S(A) = 2, S(B) = 1, S(C) = 3. At the end of the day,        fishes. In both situations, fisherman C must clear the road,
if the road has been cleared, the fishermen equally distribute     and so his action is clear. However, for fisherman A, there
the money earned from the fish sacks they have collected. If       is one scenario in which he should fish, and one in which
the road is not cleared, they receive nothing.                     he should clear the trees, so this model predicts that he will
   We first develop two possible models of rational action se-     choose either action with 50% likelihood.
lection for a fisherman in this paradigm. After discussing the
                                                                   Model of blame
models of rational action, we consider two models of pivotal-
ity, and suggest that blame judgments are related to violations    Now that we have a model for how agents should choose an
of expectations as well as pivotality considerations.              optimal action in a given scenario, we define the “rationality”
                                                                   aspect of blame as an expectation violation. Mathematically,
Model of action                                                    this is 1 - p(ai ), one minus the rational-action probability of
In a purely cooperative coordination game, individuals should      the action ai that the agent took (fishing, or clearing the road).
attempt to find an optimal strategy to maximize the expected       When it was perfectly clear what action an agent should have
reward of the group (Schelling, 1980). If there is only one        chosen (p(a f ish ) = 1 for example), then the agent should re-
way for the group to succeed, and you know all group mem-          ceive full blame if he cleared the road, and 0 blame if he went
bers are rational, you can choose your action without worry-       fishing. However, this model completely lacks any consider-
ing about what the others will do. However, when there is          ation of the other agents’ actions. In hindsight, perhaps one
                                                                85

of the fishermen made the wrong choice but it didn’t matter,
because another fisherman also made a bad choice. However,
if the other fishermen made the right choices, and only one
did not (and he cost the group a lot!) then he may be seen
as more to blame. For example, consider the case of T = 2,
S(A) = S(B) = 1 and S(C) = 3. Imagine first that fisherman
C goes fishing, and fisherman B goes to clear the trees. We
may blame fisherman A more for fishing than we would have
if fisherman B had also gone fishing. This is captured by the
pivotality measure discussed briefly in the introduction. The        (a) Experiment 1. Participants were asked to judge fisherman A’s
pivotality of a person’s action for a specific outcome in a sit-     best action.
uation is defined as:
                                       1
                       Pivotality =                           (3)
                                     N +1
where N is the minimum number of other agents whose ac-
tions need to be changed to make the reward outcome coun-
terfactually dependent on the fisherman in question. In cases
where the fisherman made the right choice, but his colleagues
failed to do so, pivotality would be 0. A fisherman’s pivotal-
ity would be 1 if he needed to act differently for the group to
receive a reward.
   In our scenario, there are discrete rewards, rather than
merely binary as in Lagnado et al. (2013). We therefore
looked at two modifications to this structural pivotality mea-
sure: a distance to the closest optimal strategy, or a distance
to the closest strategy where any reward was received.
                                                                     (b) Experiment 2. Example image for blame attribution. Underneath
Distance to optimal Pivotality is measured as the distance           the image is the textual representation of this scenario.
to the closest optimal strategy.
                                                                         Figure 2: Example images from the two experiments.
                                           1
                 Pivotalityoptimal =                          (4)     Consider the scenarios laid out above for optimal pivotality
                                     Noptimal + 1
                                                                     (for T = 3, S(A) = 2, S(B) = 1, and S(C) = 3). In the first
Consider the case where T = 3, S(A) = 2, S(B) = 1, and               case where fisherman A clears the trees, fisherman A would
S(C) = 3. This configuration has two strategies leading to           still have pivotality 0, but both fishermen B and C would have
maximum reward: either both fisherman A and fisherman B              pivotality 1 (because either of them could have acted to ob-
clear the trees while fisherman C fishes, or fisherman C clears      tain reward). In the second case where fishermen A and B
the trees while fishermen A and B both fish. Now consider the        clear the trees, everyone would have pivotality 0 because they
scenario when only fisherman A went to clear the trees, while        received a nonzero reward (and therefore their policy was sat-
both fishermen B and C fished. In this case, the closest opti-       isfactory). This model effectively downweights the blame for
mal strategy is the one in which fisherman B changes his ac-         agents in any situation where they received reward, and heav-
tion to clear the trees. Therefore, the pivotality for fisherman     ily penalizes stronger agents in cases where a weaker agent
A is 0 (in the closest optimal world, he should have done what       (or combination of weaker agents) should have gone to clear
he did), while the pivotality for fisherman B is 1, and for fish-    the trees (like the T = 2, S(A) = 1, S(B) = 1, S(C) = 3 case,
erman C is 0 (like A, his action in the closest optimal world is     where fisherman C could have cleared the trees to obtain a
the same as his actual action). If fisherman C had also chosen       suboptimal reward).
to clear the trees, then the new closest optimal strategy would         We will discuss four models of blame attribution which
be when fisherman A’s action is switched, leading to pivotal-        differ in terms of what aspects they consider: rationality
ity scores of 1 for fisherman A, 0 for fisherman B, and 0 for        alone, optimal reward pivotality alone, any reward pivotality
fisherman C.                                                         alone, and a linear mixture of rationality and optimal pivotal-
                                                                     ity given by a weight w.
Distance to any reward In this version of pivotality, in-
stead of considering the closest optimal strategy, we consider                                 Experiments
any strategy in which the agents would have received some
reward.                                                              In the first experiment, we asked participants to judge which
                                         1                           action fisherman A should take on a sliding scale from “Def-
                     Pivotalityany =                          (5)    initely fish” to “Definitely clear road” (see Figure 2a). They
                                     Nany + 1
                                                                  86

              Recursive rationality k = 2 β = 1.5                        Uniform over best                                            Rationality only                                       Optimal Reward Pivotality
                                                            1.0
        1.0                                                                                                           1.0                                                       1.0
                                                            0.5
        0.5
                                                                                                                      0.5                                                       0.5
Human                                               Human
                                                                                                             Human                                                     Human
        0.0                                                 0.0
                                                                                                                      0.0                                                       0.0
    −0.5                                                −0.5
                                                                                                                     −0.5                                                      −0.5
                                    r = 0.929                                           r = 0.913
    −1.0                                                −1.0
                                                                                                                                                       r = 0.846                                                 r = 0.823
              0.00   0.25    0.50    0.75    1.00                 0.00   0.25    0.50   0.75   1.00                  −1.0                                                      −1.0
                            Model                                               Model
                                                                                                                            0.00    0.25    0.50      0.75     1.00                   0.00       0.25    0.50   0.75     1.00
(a) The soft-max recursive rea-                     (b) Uniform action selection                                                           Model                                                        Model
soning model (k = 2, β = 1.5).                      from optimal strategies.                                                       Any Reward Pivotality                        Rationality − Optimal Reward Pivotality w = 0.6
Figure 3: The two models of action selection for Experi-                                                             1.0                                                       1.0
ment 1.
                                                                                                                     0.5                                                       0.5
were given a tutorial explaining the fishermen’s situation
(similar to the introduction of this paper), and asked to an-                                               Human    0.0                                              Human    0.0
swer some comprehension checking questions. We generated                                                            −0.5                                                      −0.5
different situations by considering all unique permutations of                                                                                     r = 0.393                                                    r = 0.914
1-3 trees and three fishermen with strengths 1-3, leading to 54                                                     −1.0                                                      −1.0
different scenarios. Participants were then shown a randomly                                                               0.00    0.25     0.50
                                                                                                                                           Model
                                                                                                                                                      0.75     1.00                  0.00       0.25     0.50
                                                                                                                                                                                                        Model
                                                                                                                                                                                                                0.75     1.00
selected subset of 27 of these. 50 participants were recruited
through Amazon Mechanical Turk, giving 25 judgments for                                                    Figure 4: Four models of blame attribution across all 140 fish-
each trial.                                                                                                ermen scenarios
   In the second experiment, we asked participants to judge                                                clearly incorrect. This category also included intriguing cases
how much each fisherman was to blame for the group’s failure                                               such as those where everyone made the incorrect choice, but
to get the best possible outcome (see Figure 2b). The actions                                              some reward was still received (like in Figure 6k).
of the fishermen were represented as arrows either towards                                                    During the experiment, participants were shown 21 out of
their pond, or towards the trees on the road. Participants were                                            the 63 total trials. We recruited 60 participants through Ama-
additionally shown the number of fish sacks which the fish-                                                zon Mechanical Turk to participate in this study, leading to
ermen actually collected, as well as the best possible number                                              20 judgments per trial.
they could have collected, next to the image. The blame for
each fisherman was assessed on a sliding scale from “Not at                                                                                                  Results
all” to “Very much”. Participants were additionally required                                               We first used the data collected in Experiment 1 to determine
to go through an introductory tutorial, answer comprehension                                               which model of action selection best predicts participants’
testing questions, and give optimal strategies for 7 example                                               judgments. In order to account for individual subjects in-
scenarios (of which they needed to answer 6 correctly to con-                                              terpreting the slider’s values differently, we z-scored within
tinue).                                                                                                    subjects before averaging and comparing to the model pre-
   Since there are many possible combinations of strengths,                                                dictions.
trees, and choices, we selected only a subset of trials falling                                               As seen in Figure 3, both models fit the participant data
into 4 distinct categories. The first category consisted of those                                          well with respect to the correlation coefficient. However,
trials where all agents chose to go fishing. These were cho-                                               the uniform action selection over optimal policies model has
sen by ordering trials according to participants’ average judg-                                            some large outliers. These outliers correspond to situations
ments from Experiment 1, and then selecting every fifth el-                                                such as T=3, S(A)=3, S(B)=1 and S(C)=2, where there are
ement of the resulting ordered list, leading to 10 such trials                                             two optimal policies, but one of these requires less coordina-
(Figures 6a, 6d, 6e and 6j). The second category consists of                                               tion by the fishermen to clear the trees. In this case, the uni-
12 scenarios in which at least one fisherman went to clear the                                             form optimal policy model would say that fisherman A should
trees, but the fishermen failed to collect any reward, and this                                            clear the trees only 50% of the time. However, the recursive
was due to their collective failure to clear the fallen trees (see                                         reasoning model suggests that he should clear the trees 93%
Figures 6f and 6h). For comparison, we also included 8 cases                                               of the time under the fitted parameters. Participants state that
where no fishermen cleared the trees.                                                                      fisherman A should clear the trees 82% of the time. The dif-
   The third category includes 15 cases in which the amount                                                ference between the predictions of these models results from
of reward received was non-zero, but sub-optimal, and it was                                               the importance of reasoning about other agents when cooper-
not clearly one agent’s fault (because there were multiple best                                            ation is key. Fitting the recursive rationality model to the z-
responses, like in Figures 6b and 6c). Finally, the fourth cate-                                           scored participant data using a least-squares regression yields
gory also consisted of 18 cases with sub-optimal reward out-                                               a value for k of 2 and β of 1.5.
comes, where the action of one agent in the group was more                                                    As the main contribution of this work, we assess the impor-
                                                                                                      87

                               Rationality Only                                            Optimal Reward Pivotality                   the scenarios). The mixture model better accounts for scenar-
         1.0                                                                  1.0
                                                                                                                                       ios in which at least one fishermen went to clear the road, such
                                                                                                                                       as those shown in Figure 6f and Figure 6h (see Figure 5 for
         0.5                                                                  0.5                                                      fit). Additionally, in highly unusual cases where all the fish-
                                                                                                                                       ermen made bad decisions (such as that shown in Figure 6j),
Human    0.0                                                         Human    0.0
                                                                                                                                       participants are clearly sensitive to the optimal reward out-
        −0.5                                                                 −0.5
                                                                                                                                       come rather than a suboptimal but fairly good reward. How-
                                                    r = 0.7                                                     r = 0.658              ever, both of the models overpredict how much blame fish-
        −1.0                                                                 −1.0
                                                                                                                                       erman C will receive in Figure 6i. This is likely due to par-
                      0.25          0.50
                                    Model
                                              0.75            1.00                  0.00    0.25      0.50
                                                                                                    Model
                                                                                                               0.75        1.00
                                                                                                                                       ticipant’s sensitivity to fisherman C being responsible for any
                        Any Reward Pivotality                                  Rationality + Optimal Reward Pivotality w = 0.6         reward being received, which is common across other similar
                                                                                                                                       cases. In this instance, although the pivotality for fisherman
         1.0
                                                                              1.0
                                                                                                                                       C is 0, the rationality model predicts that fisherman C should
         0.5                                                                  0.5
                                                                                                                                       have gone fishing, because he could have reasonably assumed
                                                                                                                                       one of his companions would have cleared the road. There-
Human                                                                Human
         0.0                                                                  0.0
                                                                                                                                       fore, the “right” decision for receiving reward was actually
        −0.5                                                                 −0.5
                                                                                                                                       less rational. For many of these scenarios, the “any reward”
                                                  r = 0.703                                                     r = 0.87               pivotality measure is a much better indicator of human blame
        −1.0
                                                                             −1.0
                                                                                                                                       judgments, although when considering all cases, it still per-
               0.00     0.25         0.50
                                    Model
                                                  0.75        1.00              0.00       0.25      0.50
                                                                                                    Model
                                                                                                               0.75        1.00        forms significantly worse than the optimal reward pivotality
                                                                                                                                       measure.
Figure 5: Four models of blame attribution across those cases
                                                                                                                                          Examining the cases where the fishermen received nothing
where no reward was received.
                                                                                                                                       due to their inability to coordinate clearing the road yields fur-
tance of rationality and pivotality for blame attribution when                                                                         ther insights into the importance of pivotality (Figure 5). Un-
the fishermen do not collect the optimal reward. There are                                                                             der this set of examples, the “any reward” pivotality model’s
63 separate scenarios where all fishermen are judged by a                                                                              correlation jumps from 0.39 (when we considered all trials)
participant for a given trial. In total this yields 140 unique                                                                         up to 0.70 across only these cases. This relatively high cor-
judgments of fishermen, for which we have 20 data points                                                                               relation is driven by the endpoints (where fishermen received
each. As in Experiment 1, we z-scored the data on the level                                                                            either full or no blame). However, combined with the analy-
of individual participants before averaging their judgments.                                                                           sis of individual scenarios, it seems that participants are more
All model fits were done using a coarse-grained search for                                                                             sensitive to decisions which would change the reward out-
k, β and w where appropriate minimizing the residuals from                                                                             come to 0 or from 0 rather than some suboptimal but nonzero
a linear regression between the z-scored human data and the                                                                            outcome. In these trials, the difference between the “rational-
model predictions.                                                                                                                     ity only” model and the mixture model also becomes statisti-
                                                                                                                                       cally significant, demonstrating the heightened importance of
    Scatter plots of model predictions and participants’ aver-
                                                                                                                                       pivotality for these cases.
age judgments for four versions of the model are shown in
Figure 4. The rationality model has two fitted parameters: k
and β. With k = 2 and β = 1.9, the best-fitting parameters for
                                                                                                                                                                Discussion
this model are similar to the values found for Experiment 1,                                                                           Overall, participants find both person-centered aspects (in the
and consistent with the rationality + optimal pivotality model                                                                         form of rationality based on an expected action), as well as
as well. Neither the optimal pivotality model nor the any re-                                                                          action-centered aspects (optimal pivotality) to be important
ward pivotality model have any fitted parameters, and fit the                                                                          when assessing the blame of agents in a coordinative game.
data significantly worse than the mixture model. The mix-                                                                              Unlike previous experiments in responsibility attribution, this
ture model has an additional fitted parameter w which corre-                                                                           paradigm critically incorporates an agent’s ability to plan an
sponds to a linear weighting between rationality and pivotal-                                                                          appropriate action as important for assigning blame. Because
ity (blame = w × rationality + (1 − w) × pivotality). The best                                                                         the fishermen aren’t able to communicate with each other,
fit is w=0.60 using the optimal pivotality measure, suggesting                                                                         their planning has to rely on their intuitive theory of how oth-
an almost equal contribution of rationality and pivotality for                                                                         ers are going to act in the given situation. Our results suggest
blame attribution. Replacing the “optimal pivotality” with the                                                                         that people assume the norm is for each fisherman to reason
“any pivotality” yields a worse fit.                                                                                                   in the same way - namely as a recursive model in which each
    In order to determine more precisely what the pivotality                                                                           fisherman tries to model what actions the others will take.
and rationality models individually capture, we looked at sev-                                                                            These observations suggest several different directions for
eral representative cases in Figure 6, comparing human judg-                                                                           future work. First, we will look at credit attribution when the
ments to the rationality only, and rationality mixture model                                                                           fishermen are able to split their work between tree clearing
(which were the only models to give graded responses across                                                                            and fishing, keeping half of the fish they catch for themselves
                                                                                                                                  88

Figure 6: Mean blame judgments (white bars) and model predictions (gray bars) for a selection of different trials. Error bars
indicate ±1 SEM. Note: Str = Strength of each fisherman; Dec = Decision to go fishing or clear the trees; ideal = ideal reward;
actual = actual reward.
(for example). Second, we will investigate settings in which        chines (CBMM), funded by NSF STC award CCF-1231216. MKW
some of the agents may have negative intentions, or responsi-       was supported by a Hertz Foundation Fellowship and NSF-GRFP.
bility attribution from the perspective of an agent with differ-
                                                                                               References
ent goals from the group (like feeding a very large family).We
                                                                    Baker, C. L., Saxe, R., & Tenenbaum, J. B. (2009). Action under-
will incorporate the insights gained from these experiments           standing as inverse planning. Cognition, 113(3), 329–349.
with work on inverse planning for determining agent’s goals         Chockler, H., & Halpern, J. Y. (2004). Responsibility and blame: A
and intentions (Baker, Saxe, & Tenenbaum, 2009; Ullman et             structural-model approach. JAIR, 22(1), 93–115.
                                                                    Gerstenberg, T., Ullman, T. D., Kleiman-Weiner, M., Lagnado,
al., 2010), to capture the “person-centric” aspect of responsi-       D. A., & Tenenbaum, J. B. (2014). Wins above replacement: Re-
bility attribution.                                                   sponsibility attributions as counterfactual replacements. In Pro-
   In future experiments, we will also look at a wider range          ceedings of the 36th annual conference of the cognitive science
                                                                      society.
of strengths and trees. Consider the case of T = 1, S(A) = 90,      Johnson, S. G. B., & Rips, L. J. (2015). Do the right thing: The
S(B) = S(C) = 1. Here, the difference between suboptimal              assumption of optimality in lay decision theory and causal judg-
and optimal reward is more extreme than any of the cases              ment. Cognitive Psychology, 77, 42–76.
                                                                    Lagnado, D. A., Gerstenberg, T., & Zultan, R. (2013). Causal re-
we presented and therefore we may expect a larger range of            sponsibility and counterfactuals. Cognitive Science, 47, 1036–
responses.                                                            1073.
   Finally, we will extend the current scenario to consider re-     Schelling, T. C. (1980). The strategy of conflict. Harvard university
                                                                      press.
peated interactions between the same fishermen. Repeated            Spellman, B. (1997). Crediting causality. Journal of Experimental
interactions help to establish norms that can guide future ac-        Psychology, 126(4), 323–348.
tion selection (like where the fishermen have settled on a so-      Ullman, T. D., Baker, C. L., Macindoe, O., Evans, O., Goodman,
                                                                      N. D., & Tenenbaum, J. B. (2010). Help or Hinder: Bayesian
lution with one of two similarly strong fishermen being the           Models of Social Goal Inference. NIPS, 22, 1874–1882.
tree-cutter).                                                       Yoshida, W., Dolan, R. J., & Friston, K. J. (2008). Game theory of
                                                                      mind. PLoS Computational Biology, 4(12).
Acknowledgements
This work was supported by the Center for Brains, Minds and Ma-
                                                                 89

