         Visuo-spatial Working Memory and the Comprehension of Iconic Gestures
                                              Ying Choon Wu (yingchoon@gmail.com)
                                Institute for Neural Computation (Mail Code 0523), 9500 Gilman Drive
                                                           La Jolla, CA 92093 USA
                                                   Bonnie Chinh (bchinh@ucsd.edu)
                                         Cognitive Science (Mail Code 0515), 9500 Gilman Drive
                                                           La Jolla, CA 92093 USA
                                                 Seana Coulson (scoulson@ucsd.edu)
                                         Cognitive Science (Mail Code 0515), 9500 Gilman Drive
                                                           La Jolla, CA 92093 USA
                               Abstract                                   Coulson, 2014). Reaction times for related picture probes
   Multi-modal discourse comprehension requires speakers to
                                                                          are typically faster following discourse primes with
   combine information from speech and gestures. To date, little          congruent gestures that match the concurrent speech, than
   research has addressed the cognitive resources that underlie           incongruent gestures that do not, suggesting congruent
   these processes. Here we used a dual task paradigm to test the         iconic gestures help convey information about the discourse
   relative importance of verbal and visuo-spatial working                referents (Wu & Coulson, 2014).
   memory in speech-gesture comprehension. Healthy, college-                 Consistent with the suggestion that speech-gesture
   aged participants encoded either a series of digits (verbal            integration recruits the visuo-spatial WM system, the
   load) or a series of dot locations in a grid (visuo-spatial load),
   and rehearsed them (secondary memory task) as they                     magnitude of these congruity effects has been shown to be
   performed a (primary) discourse comprehension task. The                larger in participants with greater visuo-spatial WM
   latter involved watching a video of a man describing                   capacity (Wu & Coulson, 2014). Moreover, imposing a
   household objects, viewing a picture probe, and judging                concurrent verbal load during this task yielded additive
   whether or not the picture was related to the video. Following         effects of gesture congruity and WM load, while a
   the discourse comprehension task, participants recalled either         concurrent visuo-spatial load yielded interactive effects, as
   the verbally or visuo-spatially encoded information.
                                                                          gesture congruity effects were greatly attenuated under
   Regardless of the secondary task, performance on the
   discourse comprehension task was better when the speaker’s             conditions of high visuo-spatial load (Wu & Coulson,
   gestures were congruent with his speech than when they were            2014).
   incongruent. However, the congruency advantage was smaller                Prior research thus suggests speech-gesture integration
   when the concurrent memory task involved a visuo-spatial               recruits cognitive resources shared by visuo-spatial WM
   load than when it involved a verbal load. Results suggest that         load tasks. One shortcoming of this earlier research,
   taxing the visuo-spatial working memory system reduced                 however, is that the impact of verbal load on gesture
   participants’ ability to benefit from the information in
   congruent iconic gestures.
                                                                          comprehension was assessed in one group of participants,
                                                                          while the impact of visuo-spatial load was assessed in
   Keywords: depictive gesture; iconic gesture; language                  another. Observed differences in verbal versus visuo-spatial
   comprehension; multi-modal discourse; working memory                   load might reflect incidental differences in the underlying
                                                                          cognitive abilities of the two groups of participants, or
                          Introduction                                    differences in the strategies each employed.
During multi-modal discourse comprehension, listeners are                    The former possibility is particularly salient in view of
tasked with integrating visual information conveyed in                    models of working memory that emphasize the importance
speakers’ gestures with semantic information conveyed by                  of individual differences in domain general abilities in
their speech. Utilizing gestural information likely recruits              executive function over modality specific working memory
working memory (WM) resources because it relates to                       systems (e.g. Engle, 2002). According to such models,
linguistic information at varying levels of granularity, such             working memory capacity differences arise from domain
as the word-, phrase, and sentence-levels (Kendon, 2004).                 general differences in the ability to maintain recently
Here we investigate the relative import of verbal versus                  encoded information in the face of intervening information.
visuo-spatial working memory resources for multi-modal                    Such executive attention models could explain results
discourse comprehension.                                                  reported by Wu & Coulson (2014) as reflecting group
   Prior research on multi-modal discourse comprehension                  differences in executive attention and fluid intelligence.
has used a picture probe classification task in which                        In the present study, we utilized similar picture probe
participants view a multi-modal discourse prime followed                  classification task to Wu & Coulson (2014). However, we
by a picture probe that they judge as either related or                   adopted a within- participants design to directly compare the
unrelated to the previous stretch of discourse (Wu &                      impact of a concurrent verbal versus visuo-spatial load on
                                                                      2673

multi-modal discourse comprehension. The logic of this             and verbal output in incongruent items, the speaker’s face
dual task paradigm is that if the two tasks recruit shared         was blurred in all discourse primes (congruent and
cognitive resources, performance of the secondary task will        incongruent). In an independent norming study using a five
impair performance on the primary one. In the present              point Likert scale, the degree of semantic match between
study, the primary task was the picture probe classification       speech and gesture in the congruent trials was rated on
task described above.                                              average as 1.6 points higher than in the incongruent trials
  Participants’ ability to integrate information in the speech     (3.8 (SD=.8) vs. 2.2 (SD=.7)).
and gestural channels was indexed in this paradigm by faster         Related picture probes were derived from photographs
responses following congruent than incongruent gestures.           depicting objects and scenes denoted by both the spoken and
Consequently, if the secondary tasks divert cognitive              gestured portions of a discourse prime (see Figure 1).
resources from the primary task, it would be indexed by the        Unrelated filler trials were constructed by creating new
reduction or the elimination of congruency effects. That is,       prime-probe pairings that the experimenters deemed were
the presence of a large congruency effect, even under              unrelated to one another. Related and unrelated trials were
conditions of memory load, would suggest that the                  counterbalanced across four randomized lists, each
resources used in the two tasks are largely independent of         containing 168 trials, and such that each picture occurred as
one another. Alternatively, a small congruency effect would        a related probe following its associated congruent and
signal that resources needed for speech-gesture integration        incongruent discourse primes, and as an unrelated probe
were unavailable due to the demands of the secondary               following a different pair of congruent and incongruent
memory task.                                                       discourse primes. No probes or primes were repeated
  Given that the secondary tasks used here have previously         within any list. Verbal and visuo-spatial secondary recall
been shown to be roughly matched for difficulty (Wu &              tasks were evenly distributed across fifty percent of each
Coulson, 2014), the critical question is whether congruency        trial type.
effects are larger when the discourse comprehension task
was paired with a concurrent verbal versus visuo-spatial           Secondary Recall Tasks
load task. Hypothesizing that visuo-spatial WM resources           Each participant performed two types of secondary recall
are more important for speech-gesture integration than             tasks. The verbal load task involved remembering
verbal WM, we predicted the congruency effects would be            sequences of spoken numbers. The visuo-spatial load task
smaller under conditions of visuo-spatial than verbal WM           involved remembering sequences of dot locations in a two-
load. Executive attention models, by contrast, would predict       dimensional grid. During the encoding phase of the verbal
similar sized congruency effects under both sorts of loads.        task, a series of four numbers (each ranging between one
                                                                   and nine) were selected pseudo-randomly, and presented via
                          Methods                                  digitized audio files while a central fixation cross remained
                                                                   on the computer screen. For the visuo-spatial task, four dots
Participants                                                       were shown sequentially in squares selected pseudo-
60 undergraduates (39 female) gave informed consent and            randomly within a 4 × 4 matrix.
received academic course credit for participation. All                After the intervening primary task, participants were
participants were fluent English speakers.                         prompted to recall the secondary memory sets. In the case
                                                                   of verbal loads, an array of randomly ordered digits from 1-
Materials                                                          9 appeared in a row in the center of the screen, and
                                                                   participants clicked the mouse on the numbers that they
Materials for the Primary (Discourse Comprehension) Task
                                                                   remembered hearing in the order that they were presented.
were identical to those used in Wu & Coulson (2014).
                                                                   In the case of visuo-spatial loads, a blank 4 × 4 grid
Discourse primes were derived from continuous video
                                                                   appeared, and participants clicked the mouse in the boxes
footage of spontaneous discourse centered on everyday
                                                                   where the dots had appeared in the order that they
activities, events, and objects. The speaker in the video was
                                                                   remembered seeing them. For both types of recall, written
naïve to the experimenters’ purpose and received no explicit
                                                                   feedback (either “Correct” or “Incorrect”) was shown on the
instructions to gesture.
                                                                   monitor for half a second after the final mouse click.
  Short segments (2 – 8 s) were extracted in which the
speaker produced both speech and gesture during his
utterance. Topics varied widely, ranging from the height of
a child, the angle of a spotlight, the shape of furniture,
swinging a golf club, and so forth. For congruent primes,
the original association between the speech and gesture was
preserved. To create incongruent counterparts, audio and
video portions of congruent clips were swapped such that
across items, all of the same speech and gesture files were
presented; however, they no longer matched in meaning.
Because of the discontinuity between oro-facial movements
                                                               2674

         Figure 1. Primary Picture Relatedness Task
Trial Structure
As outlined in Figure 2, each trial began with a fixation
cross (1s), followed by the encoding phase of the secondary          Figure 2. Trial Structure. Note that on any given trial,
task. In the case of visuo-spatial loads, each dot remained         participants performed only one secondary memory task
visible on the grid for one second. In the case of verbal          (encoding and recalling either the visuo-spatial load with
loads, sound files lasting approximately 500ms each were                   the grid, or the verbal load with the digits).
presented successively with 500ms pauses in between. A
half second pause concluded the encoding phase.                  Procedure
   Primary Task The picture classification portion of each
trial began with a discourse video, presented at a rate of       Participants were told they would be watching a series of
30ms per frame in the center of a computer monitor. A            short videos while rehearsing secondary memory items.
picture probe appeared in the center of the screen               Instructions began with an explanation of each kind of
immediately following the video offset, and remained             memory task, the verbal load task, referred to as ‘Digits’
visible until a response was registered. Two squares labeled     trials, and the visuo-spatial task, referred to as ‘Dots’ trials.
“Yes” versus “No” accompanied each picture at the bottom         Participants were then told that each trial also involved a
of the screen. Squares were arranged side by side, and the       video of a man describing everyday objects and actions
mouse cursor was initialized to a location equidistant           followed by a photograph. Participants were asked to watch
between the two. Participants responded by clicking the          and listen to each video, to respond ‘yes’ or ‘no’ whether
mouse in the square labeled “Yes” on related trials and          the photograph depicted what the speaker was describing,
“No” on unrelated ones. No feedback was given.                   and then to recall numbers or dot locations as prompted.
   Secondary Recall Task After a brief pause (250ms),            Participants were encouraged to respond both as quickly and
participants were prompted to recall secondary memory            accurately as possible on the primary and secondary tasks.
items. Written feedback on secondary recall accuracy             They were also encouraged to either visually or verbally
(“Correct” versus “Incorrect”) was presented for 500ms.          rehearse items to be remembered. The dual-task portion of
Between trials, the screen was blank for a half second and       the experiment began after a short practice block comprised
the mouse cursor was reset to a neutral, hidden position.        of two ‘Dots’ trials and two ‘Digits’ trials.
                                                                    After completion of the dual-task portion of the
                                                                 experiment, verbal and visuo-spatial WM capacity was
                                                                 assessed through two short tests – the Sentence Span task
                                                                 (Daneman and Carpenter, 1980) and the Corsi Block task
                                                                 (Milner, 1971) (see Wu & Coulson, 2014 for more detail
                                                                 about the implementation of these measures). The Sentence
                                                                 Span task involved listening to sequences of unrelated
                                                                 sentences and remembering the sentence final word in each.
                                                                 All trials contained between two and five items, and were
                                                                 presented in blocks of three. An individual’s span was the
                                                                 highest consecutive level at which all sentence final words
                                                             2675

were accurately recalled (in any order) on at least two of the     interaction between speech-gesture congruency and load
three trials in a block.                                           modality (F(1,110)=5.2, p<0.05). Follow-up t-tests revealed
   In the Corsi Block task, an asymmetric array of nine            a reliable speech-gesture congruency effect when
squares was presented on a computer monitor. On each               participants engaged in both visuo-spatial (t(55)=-4, p<0.5)
trial, between three and nine of the squares flashed in            and verbal (t(55)=-5, p<0.05) rehearsal. However, as can be
sequence, with no square flashing more than once.                  seen in Figure 3, the magnitude of this effect was
Participants reproduced patterns of flashes immediately            considerably smaller when the secondary task involved
afterwards by clicking their mouse in the correct sequence         sequences of dot locations (visuo-spatial load) versus digits
of squares. An individual’s Corsi span was the highest level       (verbal load).
at which at least one sequence out of five was correctly
replicated (Conway et al., 2005). The entire experimental
session lasted approximately two hours.                                   2000
                                                                                           congruent
Analysis                                                                                   incongruent
                                                                          1800
Data from four participants were excluded due to chance
level accuracy on the primary task. Response latencies were
computed from the onset of the picture probe to the time of               1600
the key press. Only correct responses to related probes were
analyzed, yielding a 2 (Congruent/Incongruent Discourse                   1400
Primes) x 2 (Verbal/Visuo-Spatial Recall) design. Response
times were trimmed within 2.5 standard deviations of each
participant’s mean response time. On average, 3% (sd=1%)                  1200
of the data were lost. RTs by subjects, as well as
proportions of accurate responses, underwent two-way                      1000
repeated measures ANOVA, and follow-up contrasts were
performed with t-tests. A repeated measures ANOVA test
with the same factors was also conducted on recall accuracy                800
of secondary memory items (numbers or dot locations).                                   dots                 digits
                                                                       Figure 3. RTs for Discourse Comprehension task with a
                          Results                                      concurrent load on visuo-spatial (dots) versus verbal
                                                                                            (digits) WM
Secondary Recall Accuracy Rates
Secondary memory items were recalled slightly more                 Individual Differences
accurately on trials involving congruent than incongruent
discourse primes – 83.4% versus 81% correct (Congruency            Finally, we modeled the relationship between WM abilities
F(1,55)=5, p<0.05). Sequences of digits were recalled              and sensitivity to gesture through two multiple regressions.
reliably more accurately than spatial locations of the dots --     The dependent variable was the magnitude of the discourse
89% versus 79% correct (Load Modality F(1,55)=70,                  congruency on decision times under either a verbal or visuo-
p<0.05). No interaction between these factors was detected         spatial load. Span scores on the Corsi Block and Sentence
(F < 1, n.s.).                                                     Span tasks served as predictor variables. All measures were
                                                                   normalized.
Primary Picture Classification Accuracy Rates                         Multiple regression analysis indicated that the magnitude
                                                                   of the speech-gesture congruency effect under visuo-spatial
On average, pictures were classified slightly more
                                                                   load was reliably predicted by Corsi Block (β=0.74,
accurately when primed by congruent (93% correct, SD =
                                                                   t(51)=2.3, p<0.05), but not Sentence Span scores (β=0.21,
7%) than incongruent (90% correct, SD = 10%) speech and
                                                                   t<1, n.s.). That is, individuals with superior visuo-spatial
gestures (Congruency F(1,55)=22, p<0.05). No reliable
                                                                   abilities tended to exhibit greater sensitivity to speech-
effect of load modality or load modality × congruency
                                                                   gesture congruency while rehearsing dot locations. A
interaction was detected (F’s < 1, n.s.).
                                                                   similar analysis of the congruency effect under verbal load
                                                                   failed to reveal any relationship between the Corsi and
Primary Picture Classification Response Times
                                                                   Sentence Span predictor variables and participants’
Pictures were classified more rapidly when primed by               sensitivity to speech-gesture congruency.
congruent than incongruent speech and gestures
(Congruency F(1,55)=43, p <0.05).           They were also                                  Discussion
classified more rapidly when the secondary task involved a
visuo-spatial versus verbal load (Load Modality F(1,55)=24,        Speech-gesture congruency effects were less pronounced
p<0.05). Crucially, main effects were qualified by an              with the concurrent visuo-spatial than the verbal load task,
                                                                   consistent with our suggestion that understanding iconic
                                                               2676

gestures recruits visuo-spatial memory resources. According           Visuo-spatial WM and Iconic Gestures
to our visuo-spatial resources hypothesis, the meaning of                Our finding that visuo-spatial WM helps mediate multi-
iconic gestures is often difficult to discern until they can be       modal discourse comprehension is consistent with existing
mapped onto concepts evoked by the speech. The visuo-                 research on speech-gesture integration. For example, Wu
spatial WM system is used to store gestural information               and Coulson (2011) describe evidence suggesting that
until it can be matched and integrated with verbally evoked           gestures are interpreted through image-based semantic
concepts.                                                             analysis – analogous to the manner whereby objects in a
   Participants’ ability to benefit from the information              picture are discerned through the analysis of contours and
conveyed by gestures was manifested in the present study              shapes. Additionally, it has been shown that listeners use
by reliable congruency effects in all three dependent                 information in gestures to formulate spatially specific
measures: recall accuracy on the secondary memory tasks,              conceptual models of speaker meaning (Wu & Coulson,
picture classification accuracy on the discourse                      2007). For instance, if a speaker says, “green parrot, fairly
comprehension task, and faster reaction times on the                  large,” while indicating in gesture the bird’s size and
discourse comprehension task. Because there was greater               location (perched on his forearm), listeners find it easier to
overlap between the processing demands of the discourse               comprehend a pictorial depiction of a green parrot perched
comprehension task and the visuo-spatial load task,                   on a forearm relative to a green parrot in a different
congruency effects were less pronounced when participants             location, such as a cage (Wu & Coulson, 2010).
were tasked with remembering visuo-spatial information.                  Grounded theories of language have advanced the view
   Because all participants performed both concurrent tasks,          that mental simulations of this type are part of every day
observed results are less amenable to explanation via                 language comprehension and reasoning. Unremarkable
domain general models of WM that emphasize the role of                sentences such as, “The ranger saw the eagle in the sky,”
executive attention in these phenomena. Domain general                have been shown to prompt faster categorization and
models suggest performance on the primary task depends on             naming of a matching picture probe depicting an eagle in
participants’ ability to switch fluidly between the tasks, and        flight than a mismatched probe depicting an eagle in a nest
to suppress information that might interfere with a correct           (Zwaan, Stanfield, & Yaxley, 2002), as would be expected
response. Assuming the secondary tasks were matched for               if listeners were mentally simulating visualizable aspects of
difficulty, such models incorrectly predict similar sized             the sentence’s meaning.
congruency effects with both verbal (digits) and visuo-                  Likewise, in tasks such as feature generation and property
spatial (dots) memory loads.                                          verification, participants’ responses have been shown to be
   Accordingly, it is critical to establish that the two              modulated by the implied perspective from which the cue is
concurrent load tasks placed similar demands on executive             presented (see Barsalou, 2008 for a review). For example,
functions. In the present study, this is somewhat difficult to        participants generate internal features such as seeds much
conclusively establish because, while reaction times on the           more frequently in response to objects whose internal
primary task were faster with visuo-spatial than verbal               structure is visible (e.g. half watermelon) than occluded
loads, accuracy rates on the secondary recall tasks were              (e.g. watermelon) (Wu & Barsalou, 2009). When prompted
greater for verbal than visuo-spatial loads. The observed             to conceptualize objects from either an internal perspective
speed-accuracy trade-off is consistent with our suggestion            (driving a car) or an external one (washing a car), adults
that visuo-spatial and verbal load affect speech-gesture              have also been shown to categorize parts of the object more
integration processes differently, but makes it difficult to          rapidly when they agree with the cued perspective (e.g.
evaluate whether one task is generally more demanding than            steering wheel and door handle for internal and external
the other.                                                            perspectives, respectively) (Borghi, Glenberg, and Kaschak,
   We find the suggestion that the visuo-spatial WM task              2004).
was more difficult than the verbal WM task rather unlikely               In light of findings such as these, gestures may be viewed
in view of previous work in our laboratory. Wu & Coulson              as material prompts or scaffolding that can enhance mental
(2014) used these same visuo-spatial and verbal load tasks            simulation processes regularly performed by listeners.
in a dual task paradigm in which the primary task involved            Indeed, Hostetter & Alibali (2008) suggest that the
searching for a target letter in an array of distractors (viz., a     production of gestures is the bodily manifestation of
visual search task). The visual search task has previously            sensorimotor simulation processes that underlie the
been used in this way to compare the demands of concurrent            speakers’ conceptualization of their messages. Here we
load tasks by evaluating how search time increases with               suggest the comprehension of gestures also activates
increasing numbers of distractors, with the slope of this set-        sensorimotor aspects of conceptual structure relevant for
size function serving as an index of the difficulty of the            understanding the speaker’s message.
secondary task (Treisman & Gelade, 1980). Critically, Wu                 In sum, results of the present study suggest visuo-spatial
& Coulson (2014) found similar slopes for the distractor set-         WM resources are needed to fully benefit from the
size function in both concurrent tasks, suggesting they place         information in iconic gestures. This discovery is consistent
similar demands on executive function.                                with the idea that co-speech iconic gestures promote image-
                                                                      based simulations of the meaning of an utterance, at least
                                                                  2677

for the descriptions of concrete objects and actions
employed in the present study. Given that iconic gestures
depict visual and spatial properties such as shape, size, and
relative position, it is perhaps relatively unsurprising that
listeners recruit visuo-spatial resources to relate information
conveyed in speech to visual information conveyed in the
accompanying gestures. One critical issue for future
research is whether such findings extend to the gestures
accompanying more abstract topics.
                    Acknowledgments
This work was supported by a McNair Fellowship to BC,
and an NSF grant to SC (#BCS-0843946).
                         References
Barsalou, L. W. (2008). Grounded Cognition. Annual
   Review of Psychology, 59, 617-645.
Borghi, A. M., Glenberg, A. M., & Kaschak, M. P. (2004).
   Putting words in perspective. Memory and Cognition,
   32(6), 863-873.
Daneman, M., & Carpenter, P. A. (1980). Individual
   differences in working memory and reading. Journal of
   Verbal Learning and Verbal Behavior, 19(4), 450–466.
Engle, R. W. (2002). Working memory capacity as
   executive attention. Current directions in psychological
   science, 11(1), 19-23.
Hostetter, A. B., & Alibali, M. W. (2008). Visible
   embodiment: Gestures as simulated action. Psychonomic
   bulletin & review, 15(3), 495-514.
Kendon, Adam. (2004). Gesture: Visible action as
   utterance. Cambridge University Press.
Milner, B. (1971). Interhemispheric differences in the
   localization of psychological processes in man. British
   Medical Bulletin, 27, 272–277.
Treisman, A. M., & Gelade, G. (1980). A feature-integration
   theory of attention. Cognitive psychology, 12(1), 97-136.
Wu, L. L., & Barsalou, L. W. (2009). Perceptual simulation
   in conceptual combination: Evidence from property
   generation. Acta psychologica, 132(2), 173-189.
Wu, Y. C., & Coulson, S. (2007). How iconic gestures
   enhance communication: An ERP study. Brain and
   Language, 101(3), 234-245.
Wu, Y. C., & Coulson, S. (2010). Gestures modulate speech
   processing early in utterances. NeuroReport, 21(7), 522-
   526.
Wu, Y. C., & Coulson, S. (2011). Are depictive gestures
   like pictures? Commonalities and differences in semantic
   processing. Brain and language, 119(3), 184-195.
Wu, Y. C., & Coulson, S. (2014). Co-speech iconic gestures
   and visuo-spatial working memory. Acta psychologica,
   153, 39-50.
Zwaan, R. A., Stanfield, R. A., & Yaxley, R. H. (2002).
   Language comprehenders mentally represent the shapes
   of objects. Psychological science, 13(2), 168-171.
                                                                2678

