                        The Role of Prosody and Gaze in Turn-End Anticipation
                                            Chiara Gambi (cgambi@exseed.ed.ac.uk)
                                               Department of Psychology, 7 George Square
                                                         Edinburgh, EH8 9JZ U.K.
                                  Torsten Kai Jachmann (jachmann@coli.uni-saarland.de)
                                           Department of Computational Linguistics, Campus
                                                          Saarbruecken, Germany
                                          Maria Staudte (masta@coli.uni-saarland.de)
                                           Department of Computational Linguistics, Campus
                                                          Saarbruecken, Germany
                              Abstract                                  interlocutor’s turn and the start of another interlocutor’s
   How do listeners integrate multiple sources of information in        turn) in the original conversations.
   order to accurately anticipate turn endings? In two                     Crucially, when lexico-semantic content was made
   experiments using synthesised speech and a virtual agent we          unintelligible (via low-pass filtering), participants
   examined the role of verbal and gaze information in a turn-          performed significantly worse. When the pitch contour was
   end anticipation task. Listeners were as good at anticipating        flattened, however, participants performed equally well. The
   the synthesised voice as they were with human speakers               importance of lexico-semantic content was confirmed by
   (Experiment 1). However, the direction and timing of the
   agent’s gaze had little influence on their accuracy
                                                                        Magyari and De Ruiter (2012), who found that turns with
   (Experiment 2). Overall, these findings support the idea that        more positive bias are less predictable. Finally, Riest,
   anticipation of turn ends relies primarily, but not exclusively,     Jorschick, and De Ruiter (2015) showed that listeners can
   on verbal content.                                                   still anticipate turn endings when closed class words are
   Keywords: turn-taking; prediction; pitch; gaze; virtual agent.       made unintelligible, but not when open class words are.
                                                                           In sum, there is substantial evidence that lexico-semantic
                          Introduction                                  information matters for turn end anticipation but De Ruiter
                                                                        et al.’s (2006) claim that prosody is not necessary is still
Turn-taking is a fundamental component of human                         controversial. While the original finding that flattened pitch
interactions (Levinson, 2006; Sacks, Schegloff, & Jefferson,            does not impair turn-end anticipation was confirmed for
1974). Yet, the understanding of the cognitive mechanisms               German adults (Keitel, Prinz, Friederici, von Hofsten, &
underlying turn-taking is in its infancy (Magyari,                      Daum, 2013), the same study revealed some benefit from
Bastiaansen, De Ruiter, & Levinson, 2014), and so are the               the presence of natural intonation for children. Moreover, all
attempts to implement human-like turn-taking in artificial              of these studies investigated one aspect of prosody, namely
dialogue systems (DeVault, Sagae, & Traum, 2011). Most                  pitch. It is not clear whether other suprasegmental features,
notably, we lack clear experimental data on the question of             such as speech rate, location and duration of pauses, and
how interlocutors combine linguistic information (i.e.,                 presence of lengthening on some syllables (Gravano &
syntax and semantics) with suprasegmental information                   Hirschberg, 2011) are important for turn-end anticipation. In
(i.e., prosody) and with visual information (i.e., gaze) to             fact, some experimental (e.g., Cutler & Pearson, 1986;
manage turn-taking. To fill this gap, we conducted two turn-            Hjalmarsson, 2011) and corpus findings (Gravano &
end anticipation experiments.                                           Hirschberg, 2011) suggest a role for pitch, whereas results
                                                                        for phrase-final lengthening are less clear-cut (Gravano &
Lexico-Semantic and Prosodic Cues                                       Hirschberg, 2011; Hjalmarssson, 2011). Therefore, the first
De Ruiter, Enfield, and Mitterer (2006) pioneered the use of            aim of our study (Experiment 1) was to replicate De Ruiter
the task we also employed in our study. They asked Dutch                et al.’s original finding, using the same turn-end anticipation
listeners to try and anticipate the precise end of turns                task, but with a different set of turns extracted from
extracted from a real conversation. Participants did so with            spontaneous (German) conversations.
great accuracy.
   Indeed, the distribution of bias (i.e., the time off-set             Gaze Cues
between the participants’ response and the end of the turn)             In face-to-face interaction, gaze has been identified as an
in this task resembled very closely the distribution of inter-          important cue for holding and yielding turns. Kendon (1967)
turn intervals (i.e., the time off-set between the end of one           analysed the behaviour of seven pairs of interlocutors and
                                                                    764

found that the speaker typically looked away from the                precise timing of gaze cues with respect to the end of the
listener at the beginning of a ‘long’ turn (>5 sec.) and were        turn itself. Moreover, and no less importantly, no study has
increasingly more likely to look towards the listener as she         yet investigated whether human participants are able to
approached the end of her turn.                                      accurately anticipate the end of turns when they listen to
   Kendon’s seminal observations received some                       synthesised voice and perceive gaze cues produced by a
experimental support in subsequent studies (Torres et al.,           virtual agent. This was the fourth and final aim of our study
1997; Edlund & Beskow, 2009; Bavelas et al., 2000;                   (Experiment 2).
Hjalmarsson & Oertel, 2012). Moreover, in a recent study
(Skantze et al., 2014) a robot used syntactic completeness                           Experiment 1: Prosody
and filled pauses to invite or avoid feedback from its human         In this experiment, German speakers attempted to anticipate
interlocutors. Most interestingly, the robot either displayed        the precise end of turns. As in De Ruiter et al. (2006), we
random gaze behaviour, gaze behaviour consistent with                presented turns either in their original version (NAT)
Kendon’s observations, or was hidden behind a paper board.           extracted from a corpus of conversational German, with flat
The face-to-face setting enhanced the effect of the other            intonation (NOPITCH), or with unintelligible content but
(verbal) turn-taking cues.                                           preserved intonation (NOWORDS). In addition, we
   To our knowledge, the study by Skantze et al. (2014) is so        presented the same turns in a synthesised voice (SYNTH).
far the only one to combine lexico-syntactic and gaze                The synthesised turns were automatically generated using a
information for detecting turn endings. However, they did            text-to-speech synthesiser (MARY TTS; Schröder &
not vary the timing of the agent’s gaze cues, and they did           Trouvain, 2003).
not report the timing of user’s feedback. While these authors          On the basis of De Ruiter et al. (2006) and Hjalmarsoon
where more interested in whether the user would provide              (2011) we hypothesised that (1) participants would more
feedback or not, the second aim of our study (Experiment 2)          accurately anticipate the end of turns in the NAT,
was to test whether varying the timing of the agent’s gaze           NOPITCH, and SYNTH conditions than in the NOWORDS
would induce human listeners to expect the turn to end               condition, (2) they would be as accurate in the NOPITCH as
earlier or later.                                                    in the NAT condition, and (3) also as accurate in the
                                                                     SYNTH as in the NAT (and in the NO PITCH) conditions.
Detecting the End of Virtual Agents’ Turns
Clarifying the role of suprasegmental features and gaze in           Methods
turn-end anticipation is important also with respect to              Twenty-four native speakers of German took part. They
improving an artificial agent’s ability to participate in            were each paid 5 euros and reported no language or auditory
smooth turn taking with the user (Hjalmarsson, 2011).                impairments. Ninety-six turns were extracted from the Kiel
   Hjalmarsson (2011) used Expros (Gustafson & Edlund,               Corpus of Spontaneous Speech (Kohler, 1996). This corpus
2008) to produce a synthesised version of real                       contains 6 conversations amongst pairs of German native
conversational turns and found that participants could               speakers who were discussing scenes from the popular TV
accurately decide whether the synthesised speaker was                series Lindenstraße. Speakers could not see one another.
going to yield or keep the turn; indeed, they were as good as        Following De Ruiter et al. (2006), we chose only turns that
when listening to natural turns. This result is striking, but it     were at least 5 words long, and that were produced by
must be noted that the synthesised versions were very                speakers of both genders (female, 57 turns; male, 39 turns).
closely matched on all prosodic features to the original             One third of the selected turns was annotated in the corpus
recordings, including fundamental frequency, intensity,              as a smooth transition (smooth), one third was followed by
timing, and even laughter and breathing. The third aim of            a silent pause longer than 100 ms (pause), and the
our study (Experiment 1) was to further test whether a               remaining third ended with an overlap longer than 100 ms
synthesised voice could afford the same accuracy in turn             (overlap) between the interlocutors (see Table 1 for
end anticipation as a human voice, despite differences in            summary statistics on turn duration). These selection criteria
fundamental frequency and timing, and the absence of extra-          served to ensure a good range of predictability (in
linguistic features like laughter and breathing. In this way,        Expriment 2 we also explored whether turn type interacted
we also made sure that our synthesized turns would be                with our gaze manipulation; see below).
processed similarly to natural turns by human participants,             NAT turns were the original turns extracted from the
which was a pre-condition for adding the gaze manipulation           corpus (interlocutors were recorded on separate channels, so
in Experiment 2.                                                     any backchannels were not included). NOPITCH turns were
   We know that an avatar’s or a robot’s gaze behaviour can          resynthesised using Praat (Boersma & Weenink, 2014) with
affect the turn-taking style of a naïve participant (Edlund, &       constant pitch equal to the mean pitch of the original
Beskow, 2009: Skantze et al., 2014). In those studies,               recording (using PSOLA resynthesis). NOWORDS turns
however, the authors employed relatively coarse-grained              were created in Praat by low-pass filtering the original at
manipulations. Crucially, no study has yet manipulated the           500 Hz.
                                                                 765

   Table 1: Turn Duration by Turn Type and Condition (ms).            Participants listened to the turns over headphones. A 500-
                                                                    ms fixation cross preceded each trial. The screen turned red
                 NAT, NOPITCH, NOWORDS                              to mark the start of the turn. Playback was stopped as soon
                                    Turn Type                       as the participant gave a response to avoid learning effects;
       Measure                                                      after a 1500-ms inter-trial interval (ITI), a new trial began.
                          smooth      overlap      pause            Instructions emphasised that participants should press the
       Mean duration      3325        4380         4377             response button as soon as they expected the interlocutor to
       Min duration       1007        1261         1173             stop, so that the button would be pressed exactly at the
       Max duration       7365        9720         9433
                                                                    turn’s end (rather than waiting for turn end and then
                             SYNTH
                                                                    pressing the button, cf. De Ruiter et al., 2006). A session
                                    Turn Type
                                                                    lasted about 15 minutes.
       Measure
                          smooth      overlap      pause
       Mean duration      4398        6186         5789             Results
       Min duration       1365        2475         1675             Bias is the time offset between the button press and the end
       Max duration       8780        12650        11650            of the turn. Positive bias indicates the participant pressed the
                                                                    button after the end of the turn; negative bias indicates they
   SYNTH turns had the same content as the originals                pressed the button before the turn was over. The closer the
(including repetitions and disfluencies, but not laughter and       bias to zero, the more accurate the response. Outliers with a
breathing). Their prosody was initially produced by MARY,           bias higher than 9000 ms in absolute value (0.3 % of the
which uses prosodic boundaries (specified in GToBi) to              data) were discarded. See Table 2 for results.
define pitch contours, accents, and phrase-final lengthening.
Boundary locations are determined by basic prosody rules                 Table 2: Mean bias (SE) in ms by Condition in Exp 1.
(see Schröder and Trouvain, 2003 for details) and were
manually adjusted, if needed, to match the original turns’                      Condition            Mean         SE
pitch contour or pauses made by the speaker. Individual                         NAT                  -315         106
words were also manually accented if necessary.                                 NOPITCH              -146         117
Fundamental frequency and timing (see Table 1) of SYNTH                         NOWORDS              -460         141
turns still differed substantially from the originals. The                      SYNTH                -524         115
amplitude of all turns was normalised to minimise
differences in intensity between conditions (an example is            Bias is strongly negatively correlated with the duration of
available at http://dx.doi.org/10.7488/ds/234).                     a turn (De Ruiter et al., 2006). Since SYNTH turns were
   We created four lists using a Latin Square design, so that       considerably longer than the other versions (Table 1), we
                                                                    regressed bias on duration, and looked at the effect of our
     Figure 1: The three main postures of Embr in the AVERT condition. From left to right: Mutual gaze - Gaze to upper
                                        left - Averted gaze to the right towards turn end.
each participant heard any given turn only once, but across         manipulations on the residuals of this regression to factor
participants each turn was presented in every condition             out variance purely due to differences in duration between
(NAT, NOPITCH, NOWORDS, SYNTH). Presentation was                    conditions. We used linear-mixed effects models with
blocked by condition and block order counterbalanced                maximal random structure (Barr et al., 2013) and defined 3
across participants. Within a block, presentation order was         planned contrasts to test our hypotheses. Lexico-semantic
individually randomised using E-Prime 2.0 (Schneider,               compared all conditions with intact content against
Eschman, & Zuccolotto, 2002)                                        NOWORDS to test the role of lexico-semantic information.
                                                                    Prosody compared the NOPITCH to the NAT condition to
                                                                766

test the role of pitch information. Agent compared the             when information in only one modality (speech) was
NOPITCH and NAT conditions to the SYNTH condition, to              available to them.
test whether participants would perform as accurately with a
synthesised voice as with a human voice. We report                 Methods
estimates, Wald t tests, and profile-likelihood 95%                Forty native speakers of German were paid 5 euros each to
confidence intervals (CI) for fixed effects.1 We also report       take part. None of them had taken part in Experiment 1.
likelihood-ratio tests based on model comparison to assess         They reported no language, auditory or visual impairment.
the overall effect of our manipulation.                               We selected the subset of 56 turns pre-tested in
   Overall, Condition did not improve model fit (χ2(3)=6.31,       Experiment 1 that were sufficiently long to allow our gaze
p<.1). However, we found that bias was larger in the               manipulation (average bias in Experiment 1: -778 ms for the
NOWORDS condition than in all other conditions (B=273,             SYNTH version, -491 ms for the NAT version). Fifteen
SE=133, t=2.06, [5;546]), indicating that intact lexico-           turns ended with a smooth transition in the original
semantic information allows for more accurate (i.e., closer        conversation (smooth), twenty-three were followed by a
to zero) turn-end anticipation. In addition, there were no         silent gap (pause), and eighteen ended with an overlap
differences between NO PITCH and NAT (B=160, SE=110,               between speakers (overlap).
t=1.45, [-163;497]), nor between these two conditions and             Four video clips were generated for each turn, one for
the SYNTH condition (B=-154, SE=150, t=-1.03, [-353                each gaze condition (NEUT,NAT,AVERT,EARLY), using
;48]).                                                             the EMBR framework (see http://dx.doi.org/10.7488/ds/234
                                                                   for an example). We counterbalanced across turns whether
                   Experiment 2: Gaze                              the initial gaze movement away from the listener was to the
In this experiment, the synthesized turns from Experiment 1        right or to the left of the screen. We used transcriptions of
were uttered by a virtual agent (EMBR; Heloir & Kipp               the turns to obtain appropriate lip movements for the agent.
2009) and accompanied by mutual and/or averted gaze.               Pauses were added to these transcriptions at those points
Specifically, the agent looked towards the listener as it          where they appeared in the SYNTH turns (see Experiment
started the turn. It then either maintained this listener-         1). In a second stage, the SYNTH turn was superimposed on
directed gaze throughout the turn (NEUT), or averted its           the video. Synchronisation with the agent’s lip movements
gaze during speaking before looking back at the listener           was ensured and gaze movements were aligned with the
towards the end of the turn. The timing of this turn-final         content of the audio file as requested by our gaze
listener gaze occurred either at what we consider the              manipulation. This two-step procedure was necessary
‘natural’ or optimal time point (NAT, about 600ms prior to         because the SYNTH turns from Experiment 1 were obtained
turn end, as roughly observed in Kendon, 1967) or                  using a different (and more flexible) synthesizer (MARY)
substantially earlier (EARLY, about 1600ms prior to turn           than the one integrated within the EMBR framework.
end). Natural gaze was further contrasted with a gaze cue             Each movie clip started with the agent looking towards
that had the same timing but remained averted (AVERT;              the participant for one second before starting to speak. The
Figure 1). Thus, the gaze cue manipulation affected both           clips ended approximately one second after turn end. Bias
timing and direction. This served to investigate whether           was computed from the turn end rather than the end of the
listener-directed speaker gaze needs to occur in a specific        movie clip. The duration of the clips reached from a
time window prior to turn end in order to be a reliable and        minimum of 4200ms to 14400ms with a mean duration of
efficient predictor for listeners, and/or whether gaze needs       7904ms. This includes one second of silence in the
to be directed towards the listener at all.                        beginning of each video and the afore-mentioned silence
   In addition, we tested whether the effect of gaze would         after the turn. Overlap turns were on average longer (8490
differ depending on Turn type. In the original conversation,       ms) than pause (7584 ms) or smooth (7691 ms) turns.
participants could not see one another. We hypothesised the        NAT and AVERT gaze cues appeared on average 569 ms
virtual agent’s gaze would mostly affect the anticipation of       before turn end (range: 166-1000 ms), while EARLY gaze
turns that ended with an overlap or a gap, that is turns in        cues were on average 1593 ms before turn end (range: 1200-
which interlocutors did not achieve a smooth transition            2133 ms). Four lists were created using a Latin square
                                                                   design as in Experiment 1. Presentation order was fully
                                                                   randomised, individually for each participant using E-Prime
   1
     CI were computed using the profile() function in R.           2.0. Participants watched the videos while listening to the
When the CI could not be computed for the full random              turns presented over speakers. Each trial was preceded by a
structure, we simplified the random structure. Fixed effects       fixation cross that remained on screen for 2000 ms and
estimates in simplified models were very close to those in         followed by a 2000-ms ITI. Video playback stopped as soon
the full models. Likelihood ratio tests for individual planned     as the participant gave a response to avoid learning effects.
contrasts also confirmed the reported results.                     Every 18 trials participants paused for a short break. In total
                                                                   a session lasted about 20 minutes.
                                                               767

Results
Outliers higher than 5000 ms in absolute value (1.47% of
the data) were discarded. Statistical analyses followed the
same criteria as in Experiment 1. Turn duration was the
same across conditions, so it was not necessary to regress it
out. Three orthogonal contrasts were defined for the factor
Gaze type. Gaze shift compared the NEUT condition against
the conditions containing gaze shifts (NAT, EARLY and
AVERT). Gaze direction compared the AVERT condition,
in which the agent kept looking away from the participant,
to the NAT and EARLY conditions, in which the agent
established mutual gaze with the listener towards the end of
the turn. Finally, gaze timing compared the NAT to the
EARLY condition. For the factor Turn type, we defined two
orthogonal contrasts: overlap compared overlap turns to the            Figure 2: Mean bias (SE) in ms by Gaze and Turn type in
other two types; gap compared pause to smooth turns.                                        Experiment 2
   Across gaze types, the bias in Experiment 2 was closer to
zero than in the pre-test (Table 3). Perhaps the mere                 However, it is possible that timing information (such as
presence of visual information about the agent, and the            the location and duration of pauses) is also necessary, in
agent’s lip movements, improved participants’ accuracy.            combination with content, for accurate turn end anticipation,
There were no differences between Gaze type conditions             since this information was preserved in both the flat pitch
(χ2(3)=4.41, p=.22; all |t|<1).                                    and the synthesised turns. Future studies using MARY could
   Overall, the Gaze type by Turn type interaction did not         test this hypothesis by modifying the location of pauses.
contribute to model fit (χ2(6)=10.81, p<.1). However, the             Overall, Experiment 1 replicated De Ruiter et al.’s (2006)
presence of a gaze shift influenced the bias for overlap           findings for our materials, and confirmed and extended
turns more than it did for smooth or pause turns (gaze shift       Hjalmarsson’s (2011) finding that turn end detection is
* overlap interaction: B=-392, SE=121, t=-3.25, [-665;-            possible for an artificial voice, at least when they are
151]; see Figure 2). Importantly, this difference was not          matched on prosodic contour and location and duration of
driven by differences in duration between turn types, as           pauses. It also served as a pre-test for the materials used in
duration did not interact with Gaze type (χ2(3)=3.18, p=.37;       Experiment 2.
all |t|<1.7).                                                         In Experiment 2, we introduced a virtual agent and
   We then analysed each turn type separately, Gaze type           manipulated the presence of gaze shifts, their direction, and
had no effect for either smooth or pause (all |t|<1). Instead,     timing. Surprisingly, direction and timing had little effect on
Gaze type influenced bias for overlap turns. Particularly,         the accuracy with which listeners anticipated turn endings,
gaze direction (B=-83, SE=134, t=-.62, [-467;203]) and             though the trends were in the expected direction: On the
timing (B=-69, SE=142, t=-.48, [-464;206]) did not matter,         basis of Kendon’s (1967) observations and Skantze et al.‘s
but the mere presence of a gaze shift brought bias closer to       (2014) findings, one would have expected listeners to
zero than when the agent looked straight at the listener           interpret an averted gaze as an indication that the agent was
throughout the turn (B=354, SE=127, t=2.78, [111;584]).            not done speaking, which should have led to a shift towards
                                                                   more positive bias in this condition. In addition, we
      Table 3: Mean bias (SE) in ms by Gaze type in Exp. 2.        expected gaze timing to affect anticipation, so that an early
                                                                   listener-directed gaze should have led to a shift towards
              Gaze type         Mean        SE                     more negative bias.
              NEUT              -211        104                       It is possible that participants did not interpret gaze cues
              NAT               -147        89                     in this way because they did not engage in a conversation
              EARLY             -178        90                     with the agent. However, previous research has established
              AVERT             -62         107                    that the turn end anticipation task reflects turn-taking
                                                                   behaviour in real conversations (De Ruiter et al., 2006). In
         General Discussion and Conclusion                         addition, in all conditions (but NEUT) the number of head
In Experiment 1, listeners were more accurate in                   movements was the same. Participants might have taken the
anticipating turn ends when they had access to the lexico-         movement itself, or its initiation, as the cue rather than gaze
semantic content of the turns, but their performance was not       direction.
impaired when the pitch contour was flattened or re-created           Alternatively, our findings could be taken to suggest that
using a text-to-speech synthesiser. This confirms that             gaze cues are not so relevant for the accurate (i.e., timely)
linguistic content is more important than intonation.              anticipation of turn endings as they are for the decision
                                                               768

whether the current speaker will keep or yield the turn. One       diphone voices. In Proceedings of Perception and
possibility is that other sources of information are primarily     Interactive Technologies for Speech-Based Systems (pp.
used to estimate the right time for a potential turn switch,       293-296). Berlin/Heidelberg: Springer.
whereas gaze is only used as a secondary cue to help decide           Heloir, A., & Kipp, M. (2009). EMBR - A realtime
whether to take the turn or not when linguistic content            animation engine for interactive embodied agents. In Proc.
indicates that a potential switch is upcoming (see De Ruiter       of the 9th Int’l Conference on Intelligent Virtual Agents.
et al., 2006 for similar reasoning about intonation).              Berlin Heidelberg: Springer.
   Tentative support for this idea comes from our finding             Hjalmarsson, A. (2011). The additive effect of turn-taking
that the end of overlapped turns was anticipated more              cues in human and synthetic voice. Speech Communication,
accurately when the agent averted its gaze than when it kept       53 (1), 23-35.
looking at the participant throughout the turn (in the NEUT           Hjalmarsson, A., & Oertel, C. (2012). Gaze direction as a
condition). If overlapped turns contain early potential turn       back-channel inviting cue in dialogue. In IVA 2012
transition points, averted gaze might make participants less       Workshop on Realtime Conversational Virtual Agents.
likely to think the speaker is about to yield the turn at an          Keitel, A., Prinz, W., Friederici, A., Hofsten, C., & Daum,
early stage.                                                       M. (2013). Perception of conversations: The importance of
   In sum, our results support the assumption that prosody is      semantics and intonation in children’s development. Journal
less relevant for detecting a turn’s end than lexico-semantic      of Experimental Child Psychology, 116 (2), 264-277.
information. Timing and direction of speaker gaze as                  Kendon, A. (1967). Some functions of gaze-direction in
observed by Kendon (1967) do not per se improve accuracy.          social interaction. Acta Psychologica, 26, 22-63.
                                                                      Kohler, K. (1996). Labelled data bank of spoken standard
                    Acknowledgments                                German: The Kiel corpus of read/spontaneous speech. In K.
This work was funded by the Cluster of Excellence                  J. Kohler (Ed.), Proceedings of the Fourth International
``Multimodal Computing and Interaction" of the German              Conference on Spoken Language Processing (pp. 1938-
Excellence Initiative. We would like to thank Jeanin Jügler        1941).
for her help with Praat scripting.                                    Levinson, S. (2006). Roots of human sociality. In N.
                                                                   Enfield, & S. Levinson (Eds.), Culture, cognition and
                          References                               human interaction. Oxford: Berg Publishers.
   Barr, D., Levy, R., Scheepers, C., & Tily, H. (2013).              Magyari, L., & De Ruiter, J. (2012). Prediction of turn-
Random effects structure for confirmatory hypothesis               ends based on anticipation of upcoming words. Frontiers in
testing: Keep it maximal. Journal of Memory and                    psychology, 3, doi: 10.3389/fpsyg.2012.00376.
Language, 68 (3), 255-278.                                            Magyari, L., Bastiaansen, M., De Ruiter, J., & Levinson,
   Bavelas, J., Coates, L., & Johnson, T. (2002). Listener         S. (2014). Early anticipation lies behind the speed of
responses as a collaborative process: The role of gaze.            response in conversation. Journal of Cognitive
Journal of Communication, 52 (3), 566-580.                         Neuroscience, 26 (11), 2530-2539.
   Boersma, P., & Weenink, D. (2014). Praat: doing                    Riest, C., Jorschick, A., & De Ruiter, J. (2015).
phonetics by computer [Computer program]. Version                  Anticipation in turn-taking: Mechanisms and information
5.3.73.      Retrieved       April     21,     2014,     from      sources.      Frontiers      in     Psychology,      6,    doi:
http://www.praat.org/                                              10.3389/fpsyg.2015.00089.
   Cutler, A., & Pearson, M. (1986). On the analysis of               Sacks, H., Schegloff, E., & Jefferson, G. (1974). A
prosodic turn-taking cues. In C. Johns-Lewis (Ed.),                simplest systematics for the organization of turn-taking for
Intonation in discourse. London: Croom Helm                        conversation. Language, 4 (1), 696-735.
   De Ruiter, J. P., Mitterer, H., & Enfield, N. J. (2006).           Schneider, W., Eschman, A., & Zuccolotto, A. (2002). E-
Projecting the end of a speaker's turn: A cognitive                Prime User’s Guide. Pittsburgh: Psychology Software Tools
cornerstone of conversation. Language, 82 (3), 515-535.            Inc.
   DeVault, D., Sagae, K., & Traum, D. (2011). Incremental            Schröder, M., & Trouvain, J. (2003). The German text-to-
interpretation and prediction of utterance meaning for             speech synthesis system MARY: A tool for research,
interactive dialogue. Dialogue & Discourse , 2 (1), 143-170.       development and teaching. Int. Journal of Speech
   Edlund, J., & Beskow, J. (2009). Mushypeek: A                   Technology, 6, 365-377.
framework for online investigation of audiovisual dialogue            Skantze, G., Hjalmarsson, A., & Oertel, C. (2014). Turn-
phenomena. Language and Speech, 52 (2-3), 351-367.                 taking, feedback and joint attention in situated human-robot
   Gravano, A., & Hirschberg, J. (2011). Turn-taking cues in       interaction. Speech Communication, 65, 50-66 .
task-oriented dialogue. Computer Speech & Language, 25                Torres, O., Cassell, J., & Prevost, S. (1997). Modeling
(3), 601-634.                                                      gaze behavior as a function of discourse structure. First
   Gustafson, J., & Edlund, J. (2008). Expros: A toolkit for       International       Workshop         on      Human-Computer
exploratory experimentation with prosody in customized             Conversations.
                                                               769

