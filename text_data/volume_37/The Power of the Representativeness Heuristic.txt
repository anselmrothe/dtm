                              The Power of the Representativeness Heuristic
                                        Sudeep Bhatia (s.bhatia@warwick.ac.uk)
                                       Behavioral Science Group, University of Warwick
                                                   Coventry, United Kingdom
                            Abstract                                heuristic judgment have emphasized the fact that these
                                                                    heuristics lead to irrational biases, such as logical and
  We present a computational model of the
                                                                    probabilistic fallacies and violations of the tenets of
  representativeness heuristic. This model is trained on
                                                                    economic rationality (Gilovich et al., 2002; Kahneman &
  the entire English language Wikipedia corpus, and is
                                                                    Tversky, 1973; Tversky & Kahneman, 1974, 1983). Other
  able to use representativeness to answer questions
                                                                    approaches have, however, stressed the usefulness of
  spanning a very large domain of knowledge. Our
                                                                    heuristics: they are easy to apply and can generate accurate
  trained model mimics human behavior by generating
                                                                    responses across a variety of settings. In other words, they
  the probabilistic fallacies associated with the
                                                                    are adaptively rational (Gigerenzer & Todd, 1999). This
  representativeness heuristic. It also, however, achieves
                                                                    debate is partially a product of the issue discussed above.
  a high rate of accuracy on unstructured judgment
                                                                    The absence of formal models for important heuristics has
  problems, obtained from large quiz databases and from
                                                                    made it impossible to test the accuracy of these heuristics in
  the popular game show Who Wants to be a
                                                                    novel decision domains.
  Millionaire?. Our results show how highly simplistic
                                                                        We attempt to address the above two issues with regards
  cognitive processes, known to be responsible for some
                                                                    to the representativeness heuristic- one of the most
  of the most robust and pervasive judgment biases, can
                                                                    prominent judgment strategies in decision making research,
  be used to generate the type of flexible, sophisticated,
                                                                    and a cornerstone of Kahneman and Tversky’s heuristics
  high-level cognition observed in human decision
                                                                    and biases framework (Gilovich et al., 2002; Tversky &
  makers.
                                                                    Kahneman, 1974). We begin by specifying a computational
  Keywords: Heuristic judgment, Representativeness,                 model that formalizes the cognitive processes assumed to be
  Conjunction fallacy, Adaptive rationality, Latent                 involved in generating judgments using this heuristic. These
  semantic analysis                                                 processes operate on similarity, assessed through latent
                                                                    semantic analysis (Landauer & Dumais, 1997), and are
                        Introduction                                nearly identical to processes used to understand similarity-
    Human judgment and decision making is guided by the             based cognition in lower level domains. We then train our
use of heuristics. Heuristics are short cuts for solving            model on the entire English language Wikipedia dataset, in
problems. They specify simple strategies for accessing and          order to allow it to judge the similarity, or
manipulating information, and are often able to provide             representativeness, of various everyday objects and their
quick and effortless responses in everyday judgment tasks           descriptions. The result is a general model of heuristic
(Gigerenzer & Todd, 1999; Gilovich et al., 2002; Tversky &          judgment that is able to use representativeness to provide
Kahneman, 1974).                                                    responses across a wide array of decision problems.
    Despite the long history of heuristics research in                  We apply our model to choice problems used in prior
psychology and cognitive science, there are two aspects of          experiments on the representativeness heuristic. We find
heuristic processing that are still the topic of considerable       that the model is able to mimic human judgments on a
debate. Firstly, it is not clear how some heuristics, such as       number of classical tasks, such as the Linda problem
the representativeness heuristic (Kahneman & Tversky,               (Tversky & Kahneman, 1983). Specifically the model
1973), can be formally defined. Although many scholars              generates similarity-based conjunction fallacies, which are
have specified the main properties of this heuristic, others        typically attributed to the representativeness heuristic. After
have criticized these specifications for being too imprecise,       verifying that the model provides a satisfactory model of the
and for not being able to provide clear, quantitative               biases generated by the representativeness heuristic, we test
predictions regarding human judgment (e.g. Gigerenzer,              the accuracy of the model in novel judgment tasks.
1991). It is certainly the case that there are currently no         Particularly, we apply the model to a series of multiple
formal models that are able to take in as inputs the judgment       choice trivia problems. These problems are obtained from
problems offered to the decision maker, and produce as              the Who Wants to be a Millionaire? game show, and from a
outputs the predictions of the representativeness heuristic         popular online geography quiz database. Overall, we find
(or for that matter, other similar heuristics) for these            that the model is able to achieve an accuracy rate of 40-50%
problems (but see e.g. Jenny et al., 2014; Tenenbaum &              for four-option multiple choice problems, which is almost
Griffiths, 2001).                                                   twice the accuracy of a random-choice model. Although this
    Secondly it is not clear whether the use of heuristics like     is far from perfect, it nonetheless showcases the power of
the representativeness heuristic should be considered               judgments from representativeness. The mechanisms that
detrimental for the decision maker. Some approaches to              violate the fundamental laws of probability are also able to
                                                                232

use a rich and complex information database to solve                of natural language descriptions. One such tool is latent
difficult and highly unstructured decision problems about an        semantic analysis (LSA), which judges words to be similar
extremely wide range of topics. This suggests that                  in meaning if they occur in similar pieces of text (Landauer
heuristics, such as representativeness, do not only lead to         & Dumais, 1997). Formally LSA involves performing a
biases in judgment: They may also be responsible for the            singular value decomposition on a matrix of word counts
types of quick, accurate and flexible judgments observed in         per text in the text corpus on which the LSA model is being
human decision makers.                                              trained. The singular value decomposition uncovers the
                                                                    latent dimensions that characterize the structure of word
                            A Model                                 concurrence in the different texts. Two phrases,
                                                                    descriptions, or texts are judged to be similar by LSA if
The Representativeness Heuristic                                    their component words are characterized by the same latent
     In their classic 1974 paper, Tversky and Kahneman              dimensions, that is, if the cosine of the angle of their vector-
described the representativeness heuristic as a way to              word count representations on these latent dimensions is
answer questions of the following type: What is the                 small.
probability that A belongs to/originates from/generates B?              LSA has a very appealing cognitive representation.
According to Tversky and Kahneman, decision makers do               Particularly, an LSA model can be represented as a locally-
not consider probabilistic or logical relationships between A       coded three-layer neural network, with the outer layers
and B when answering these types of questions. Rather they          corresponding to the texts in the corpus and the individual
make their judgment based on whether A is representative            words contained in the corpus respectively, and the middle
of, that is, similar to, B. Similarity is an important feature      layer corresponding to the latent dimensions that describe
of cognition (Medin et al., 1993), and judgments using              the structure of the corpus. Similarity is judged based on the
similarity can be made with relative ease. Indeed Tversky           overlap of activation on this hidden layer. As
and Kahneman found that the representativeness heuristic            backpropagation has been shown to asymptotically
could predict human responses in a range of decision                implement singular value decomposition (Saxe et al., 2013),
problems of the above type, including problems in which             the LSA model can be trained using standard connectionist
the heuristic generated an incorrect response (see also             techniques.
Kahneman & Tversky, 1973; Tversky & Kahneman, 1983).
    Since Tversky and Kahneman’s groundbreaking work, a             Formal Model
number of researchers have established the ubiquity of the
representativeness heuristic and the biases that it generates           LSA has been applied across wide variety of theoretical
(Gilovich et al., 2002). Indeed, the representativeness             and applied domains (Landauer et al., 2013). Here we use it
heuristic is the best-known and most-studied heuristic to           to study knowledge representation and manipulation in
emerge from Tversky and Kahneman’s heuristic and biases             high-level judgment tasks typically answered using the
framework. Despite this, this heuristic has not yet been            representativeness heuristic. Particularly we train our model
formally modeled: We do not have a computational or                 on the entire English language Wikipedia corpus to recover
mathematical specification of the representativeness                1000 latent dimensions. Each article in this corpus is
heuristic that can provide precise predictions for the types of     considered to be a separate text, and two words are judged
questions outlined in the first paragraph of this section. This     to be semantically or conceptually related if they co-occur in
is understandable. These types of questions can span a very         the same Wikipedia article. Thus our analysis amounts to
large domain, and specifying a model that is able to apply          performing a singular value decomposition of the word co-
the representativeness heuristic almost universally seems to        occurrence matrix across the Wikipedia corpus. Due to
be a highly complex task. That said, the absence of a formal        computational limitations we consider only 300,000 unique
model impedes theoretical development. By not being able            word stems in our analysis (stems that are present in
to specify the representativeness heuristic’s predicted             moderate frequency on Wikipedia). Also, prior to
responses in an apriori manner, we lose the ability to apply        performing the singular value decomposition we apply a tf-
the heuristic in new settings. These sorts of tests cannot only     idf weighting scheme to the matrix of word counts. The
examine the descriptive power of the representativeness             final LSA model uses 300,000 word stems across
heuristic (that is, its ability to explain human behavior) but      approximately 3.2 million Wikipedia articles. Our analysis
also the desirability of this heuristic as a judgment strategy.     is performed with the aid of the Gensim toolbox (Řehůřek &
                                                                    Sojka, 2010). An outline of the model is provided in Figure
                                                                    1.
Latent Semantic Analysis                                                The article topics in Wikipedia correspond to the objects
    In this paper we provide a solution to this problem.            in the world that may be the topic of a judgment, the words
Representativeness relies fundamentally on similarity, and          used in these articles correspond to the descriptions of the
similarity is a topic that has received attention not only from     different objects, and the 1000 latent dimensions capture the
psychologists, but also from computer scientists and related        conceptual structure of the objects described in Wikipedia
researchers. There are, by now, a number of tools that can          articles. Due to the scope of the Wikipedia corpus, our
be used to establish the semantic and conceptual relatedness        model can be seen as encoding a low-dimensional
                                                                233

representation of the structure of an extremely large domain                   impossible that Linda is a feminist bank teller but not a bank
of knowledge, and using assessments of similarity on this                      teller.
low-dimensional representation to make judgments from                              The representativeness-based model that we propose in
representativeness. Implicit in this exercise is that the                      this paper is able to make the same mistakes as decision
assumption that the conceptual structure of human                              makers, and thus is more likely to believe that Linda is a
knowledge (which guides human judgments of                                     feminist bank teller and not a bank teller. Indeed, when we
representativeness) resembles that of the knowledge                            give our trained model the above question, it rates feminist
obtained from Wikipedia.                                                       bank teller as having a representativeness score of 0.031 to
                                                                               the description of Linda but bank teller as having a
                                                                               representativeness score of only 0.003. If the probability of
                                                                               selecting one response over another is given by the Luce
                                                                               choice rule, which applies a logistic transform to the
                                                                               difference between the representativeness scores of the two
                                                                               response options, then, like human decision makers, our
                                                                               model would be more likely to give the incorrect response
                                                                               in this question.
                                                                                   The Linda problem asks decision makers to judge
                                                                               whether a description A (Linda) is more likely to be B (bank
                                                                               teller) or B and C (bank teller and feminist). This problem is
                                                                               designed to elicit the conjunction fallacy, and is able to do
Figure 1: Outlines of LSA model trained on the Wikipedia corpus. Note
that activation can flow in both directions. A representativeness score is     so especially well when C is more similar to A then B. The
generated based on activation overlap on the middle layer.                     conjunction fallacy weakens when both B and C are highly
                                                                               similar to A. Thus if asked to judge whether Linda is a
     It is easy to see now how our model can be used to                        social worker or a feminist social worker, decision makers
generate responses to questions of the type: what is the                       are less likely to incorrectly choose feminist social worker
probability that A belongs to/originates from/generates B?                     as their response, relative to when they are given the bank
A and B are either individual words (usually nouns), or                        teller version of the problem (though a majority of
extended descriptions, composed of a set of words. Using                       participants still make the conjunction fallacy) (Shafir et al.,
the structure of word co-occurrence Wikipedia, the model is                    1990). Our proposed model mimics this pattern, and
able to quantify the conceptual similarity between A and B.                    ascribes social worker a representativeness score of 0.050
This similarity is, in essence, a representativeness score for                 and feminist social worker a representativeness score of
A and B, and can be used in the place of an actual                             0.065. This is a difference of only 0.015, less than 0.028,
probability judgment when answering the above question.                        generated above. Subsequently our model is less likely to
This technique can then be applied by the model to provide                     make a conjunction fallacy in the social worker version of
responses in closed-end multiple-choice questions, where                       the Linda problem compared to the bank teller version of
the response option with the highest similarity to the text in                 the problem.
the question is selected as the model’s answer.                                    Shafir et al. (1990) do not only show how the
                                                                               conjunction fallacy depends on the similarity between the
                  The Conjunction Fallacy                                      various components of a judgment problem. They also
     The representativeness heuristic substitutes similarity for               provide a more conclusive demonstration of the conjunction
more complex probabilistic and logical relationships. This                     fallacy by replicating it in 28 different problems. The word
can lead to judgment fallacies in settings where response                      stems in 22 out of the 28 problems are present in the
options that are highly similar to the object that is the topic                300,000 word stems that our model was trained on,
of the judgment, cannot be more likely to be correct than                      implying that our model can be tested on these 22 problems.
their competitors. Consider, for example, the famous Linda                     Overall, the model made fallacies in 67% of the problems in
problem (Tversky & Kahneman, 1983). In this problem                            which fallacies were observed in decision makers, and there
decision makers are given the following description: “Linda                    was a correlation of 0.29 between the conjunction fallacies
is 31 years old, single, outspoken and very bright. She                        generated by our model and those generated by the human
majored in philosophy. As a student, she was deeply                            participants in Shafir et al.
concerned with issues of discrimination and social justice,
and also participated in anti-nuclear demonstrations.” They                                    Testing Model Accuracy
are then asked whether she is more likely to be a bank teller                  Factual Judgments
or a feminist bank teller. Decision makers typically believe
                                                                                   The model is capable of answering more than just the
that Linda is more likely to be a feminist bank teller than a
                                                                               description based probability questions outlined in the
bank teller, despite the fact that the set of all feminist bank
                                                                               above section. It can also make general factual judgments
tellers is a subset of the set of bank tellers, making it
                                                                               regarding a wide array of topics and presentation formats.
                                                                               The model makes these judgments based on the similarity
                                                                           234

between the text used in a question and the various response        website has been posting multiple-choice quizzes since
options offered to the decision maker. In essence it applies        1997, and describes itself as “the Internet’s best geography
the representativeness heuristic on the mental                      quiz”. As of 2014, there were over 200 geography quizzes
representations of the objects and events that are the focus        on the website. These quizzes offer five multiple choice
of the judgment.                                                    questions, with four responses each. Importantly for our
    For example, we asked the model “what is the capital of         purpose, they are in the public domain and are easy to
Kenya?”, and offer it a choice between A: Tanzania, B:              access, and cover a diverse array of geography topics.
Nairobi, C: Kampala, and D: Mombasa. The model                           We used these questions to test the accuracy of the
produced a representativeness score for the four response           model in making factual judgments, in a manner similar to
options based on their similarity with the words in the             the Kenya capital question outlined in the above section.
question, and chose the option with the highest score. In this      Particularly, each question was decomposed in to five
case, the correct response, response B, was chosen. Since           pieces of text: the question text and the four response texts.
Nairobi is the capital of Kenya, the word “Nairobi” occurs          The conceptual similarity between the words in the four
very frequently with the words “Kenya” and “capital” in the         responses and the words in the question, as assessed by the
Wikipedia corpus. Thus the trained model judges “Nairobi”           model, was then use to generate a representativeness score
to be most conceptually similar to the words in the question        for each of the four responses. The response with the highest
text, and assigns it a high representativeness score of 0.94.       score was selected as the model’s final answer.
Note that Tanzania is a neighboring country of Kenya but is              Note that some of the quiz questions that the model was
not a capital city, Kampala is a capital city, but not of           applied to involved choosing a response that did not satisfy
Kenya, and Mombasa is a city in Kenya but is not its                a particular condition. For example, one of the questions in
capital. Thus though these responses are considered                 the geography quiz database asked which of a set of four
somewhat similar to the text in the question (with scores of        countries did not border the Gulf of Aqaba. Responses to
0.79, 0.69 and 0.89 respectively), they are nonetheless less        these types of questions were generated based on the lowest
similar than the correct response.                                  representativeness score. Thus response options whose text
    Using this approach we can now test the general ability         was least similar to the text in the question were chosen by
of the representativeness heuristic to provide accurate             the model for these questions. There were 85 questions in
factual judgments in more general settings. Examining this          the geography dataset that had this property. Also note that
is important. It can tell us whether the cognitive                  there were some 345 questions in the geography dataset
mechanisms responsible for the conjunction fallacy are              whose correct responses were composed entirely of word
beneficial for decision makers, that is, whether they are           stems absent from our model’s memory (i.e. word stems not
adaptively rational. If they are rational in this manner then       part of the 300,000 stems that the model was trained on). As
the use of the representativeness heuristic can be justified,       it is impossible for the model to make responses for these
despite its tendency to systematically violate the laws of          questions, they are excluded from subsequent analysis. This
probability. If these strategies are not adaptively rational        leaves a total of 836 questions for testing our model. .
then we would be forced to ask why people continue to use
this heuristic to make choices, and whether or not
representativeness even plays a role in most everyday
decisions.
    Finding the representativeness heuristic is adaptively
rational may also shed light on how sophisticated behavior
can emerge from basic cognitive processes. Despite
operating on an almost universal domain of knowledge, the
model outlined in this paper is highly simplistic. It uses only
similarity --that is, overlap in activation-- to generate
responses, and can be implemented in the most basic type of
neural network. Indeed it is this simplicity that makes the
model computationally tractable: it would be impossible to
train a more complex judgment model on such a rich data
                                                                    Figure 1: Accuracy of responses in the Geography Quiz and WWTBAM
set. If the representativeness heuristic does manage to attain      datasets, as a function of the rank ascribed to them by the model. Note that
a high level of accuracy in general factual judgments, then it      a random model would generate an accuracy of 25%. Error bars represent
could present a part of the solution to one of the most             95% confidence intervals.
fundamental questions in cognitive science.
                                                                         We found that the model achieved fairly high accuracy
                                                                    rates. Particularly, the model was able to give the correct
Geography Quizzes
                                                                    response 49.81% of the time, and was able to select the
    We first test the ability of the model to provide accurate      correct response as one of its top two choices 69.79% of the
responses using a set of geography quizzes obtained from            time. Both of these are statistically different from accuracy
the website About.com. The geography portal of this                 rates of 25% and 50%, which are what would be expected if
                                                                235

the model was choosing randomly (p < 0.01 using a                             The popularity of WWTBAM has spanned a number of
binomial test). Figure 1 outlines the accuracy of the model               fan-sites. One of these is wwtbam.com, where viewers post
responses. The bars represent the proportion of the times the             transcripts of the US game show’s numerous episodes. We
model’s most favored, second favored, third favored, and                  scraped 359 show transcripts from wwtbam.com, starting
least favored responses were the correct responses.                       from 2007 (the earliest transcripts available on the website)
    We also examined the settings in which the model was                  and going up to 2010 (when the show’s rules were
most likely to give a correct response. Particularly we                   changed). These transcripts generated a total of 2502
defined a new variable, discriminability, which was equal to              different questions that were used on the US television
the difference in the representativeness score of the most                version of the WWTBAM game show.
favored response relative to the average representativeness                  As with the geography quizzes discussed above, each
score of the remaining three responses. The discriminability              question was decomposed in to five pieces of text: the
of a problem captures the degree to which the HLM’s                       question text and the four response texts, with the
favored response in the problem stands out relative to its                conceptual similarity between the words in the four
competitors, and can be seen as a measure of the intuitive                responses and the words in the question being used to
strength of the model’s favored response for the problem.                 generate a representativeness score for each of the four
                                                                          responses. Additionally, as above, many of the questions
                                                                          used on this show involved choosing a response that did not
                                                                          satisfy some condition. Questions of this form were
                                                                          answered by selecting the response with the lowest
                                                                          representativeness score. Finally, a total of 305 questions in
                                                                          the WWTBAM had correct responses that were composed
                                                                          entirely of word stems absent from our model’s memory.
                                                                          These questions are not used in the subsequent analysis.
                                                                          This leaves a total of 2197 questions for testing our model.
                                                                             Overall, we found that the model was able to provide the
                                                                          correct response 42.01% of the time, and was able to select
                                                                          the correct response as one of its top two choices 64.51% of
                                                                          the time. Although the accuracy of the model is a bit worse
                                                                          on this dataset, relative to the geography quiz dataset, it
Figure 2: Accuracy of model responses in the Geography Quiz and           nonetheless far higher than that generated by a perfectly
WWTBAM questions, by discriminability quantile. Note that a random        random model which would choose each response with a
model would generate an accuracy of 25% for all quantiles. Error bars     25% chance (p < 0.01 using a binomial test). The proportion
represent 95% confidence intervals.
                                                                          of the times the model’s most favored, second favored, third
                                                                          favored, and least favored responses were the correct
    We regressed the choice of the correct option in a
                                                                          responses, are shown in Figure 1.
problem on the discriminability of that problem to see if an
                                                                              Once again we considered the discriminability of the
increase in the intuitive strength of the most favored
                                                                          model’s favored response in each question. As above, this
response led to a higher accuracy in the quiz problems. Our
                                                                          variable is defined as the difference in the
regression revealed a significantly positive coefficient (β =
                                                                          representativeness score of the most favored response
2.29, z = 5.56, 95% CI = [1.48, 3.11], p < 0.01), indicating
                                                                          relative to the average representativeness score of the
that model is more likely to be correct in problems where
                                                                          remaining three responses. We regressed the choice of the
the intuitive strength of the favored response is higher.
                                                                          correct option on the discriminability of the problem and
Figure 2 describes the average model accuracy for quiz
                                                                          found a significantly positive coefficient (β = 1.90, z = 5.88,
problems in each quantile of the discriminability
                                                                          95% CI = [1.26, 2.53], p < 0.01), indicating that an increase
distribution. Thus we can see that the model achieved an
                                                                          in the intuitive strength of the most favored response leads
accuracy of about 60% for the problems that were above the
                                                                          to a higher accuracy in the WWTBAM dataset. Figure 2
75th percentile in terms of their discriminability, compared
                                                                          describes the average accuracy of the model for problems in
to the rest of the dataset.
                                                                          each quantile of the discriminability distribution.
                                                                              Finally, we were able to examine whether the model was
Who Wants to be a Millionaire?                                            more likely to make correct responses in easier questions.
    We also tested the ability of the model to provide                    Each WWTBAM question in the US television version of
accurate responses in a more general domain: one involving                the game show is accompanied a monetary value, and
trivia questions on the popular television game show Who                  questions with a lower monetary value are typically easier.
Wants to be a Millionaire? (WWTBAM). WWTBAM is a                          We found that the model had a roughly equal success rate
game show that offers contestants four-option multiple-                   for questions of all monetary values, indicating that the
choice questions spanning a very large range of topics,                   accuracy of the representativeness heuristic does not
including history, current affairs, and popular culture.
                                                                      236

typically vary with the difficulty of the problems that it is        thus make representativeness-based judgments for an
applied to.                                                          extremely diverse range of judgment problems. This model
                                                                     is, in essence, a simulation of human judgments of
              Discussion and Conclusion                              representativeness that is able to both mimic human-like
    The representativeness heuristic is perhaps the best             errors but also answer difficult, unstructured judgment
known and most studied heuristic in decision making                  questions with relatively high accuracy. Its ability to do this
research. The fallacies it generates are robust and                  represents a heightened degree of formalism and theoretical
systematic, and have, over the past four decades, shed light         rigor in decision modelling, and illustrates how the insights
on an important limitation of human judgment. In this paper          from multiple sub-fields within psychology can be
we have presented a formal model of the representativeness           combined in order to build a new class of powerful, flexible,
heuristic and have shown that it can both mimic human                domain-general models of everyday judgment.
behavior by generating conjunction fallacies, and generate
accurate responses in a wide array of factual judgment                                        References
problems. The adaptive rationality of our model of                   Anderson, J. R., & Schooler, L. J. (1991). Reflections of the
representativeness explains why people are likely to use this            environment in memory. Psychological Science, 2(6).
heuristic despite the biases that it generates, and                  Gigerenzer, G. (1991). How to make cognitive illusions
additionally, how they are able to achieve relatively high               disappear: Beyond “heuristics and biases”. European
accuracy when making everyday judgments.                                 Review of Social Psychology, 2(1).
    The model of representativeness that we have proposed            Gigerenzer, G., & Todd, P. M. (1999). Simple Heuristics
relies fundamentally on stored representations in memory.                that Make us Smart. Oxford University Press.
Memory processes have been known to code information in              Gilovich, T., Griffin, D., & Kahneman, D. (Eds.). (2002).
a manner that reflects the structure of the environment, and             Heuristics and Biases: The Psychology of Intuitive
one that is beneficial to the decision maker (Anderson &                 Judgment. Cambridge University Press.
Schooler, 1991). These insights have led to the generation           Goldstein, D. G., & Gigerenzer, G. (2002). Models of
of heuristics that are able to make judgments based on                   ecological rationality: the recognition heuristic.
assessments of recognition and familiarity (Goldstein &                  Psychological Review, 109(1)
Gigerenzer, 2002). Our paper complements this work by                Kahneman, D., & Frederick, S. (2002). Representativeness
studying heuristics that use similarity assessments on                   revisited: Attribute substitution in intuitive judgment.
semantic memory. The ability to process semantic similarity              Heuristics and Biases: The Psychology of Intuitive
is an important feature of human cognition, and similarity               Judgment. Cambridge University Press.
more generally forms one of the central theoretical                  Kahneman, D., & Tversky, A. (1973). On the psychology of
constructs in cognitive psychology (Medin et al., 1993). We              prediction. Psychological Review, 80(4).
show that this important construct can provide accurate but          Landauer, T. K., & Dumais, S. T. (1997). A solution to
flexible judgments across a very large range of topics.                  Plato's problem: The latent semantic analysis theory of
    The results in this paper also shed light on the settings in         acquisition, induction, and representation of knowledge.
which similarity-based judgment processes are able to                    Psychological Review, 104(2).
obtain the highest accuracy. Particularly we found that our          Landauer, T. K., McNamara, D. S., Dennis, S., & Kintsch,
model was most likely to give a correct response when only               W. (Eds.). (2013). Handbook of Latent Semantic
one option was strongly supported by the representativeness              Analysis. Psychology Press.
heuristic, that is, when the intuitive strength of the model’s       Medin, D. L., Goldstone, R. L., & Gentner, D. (1993).
favored response was highest. It may be the case that                    Respects for similarity. Psychological Review, 100, 254.
decision makers use the representativeness heuristic to make         Řehůřek, R., & Sojka, P. (2010). Software framework for
judgments in these settings, but recruit higher-level                    topic modelling with large corpora. Proceedings of the
deliberative      processes    in     settings    where      the         LREC 2010 Workshop on New Challenges for NLP
representativeness heuristic supports multiple options or                Frameworks.
doesn’t support any option. Such a strategy would be able to         Saxe, A. M., McClelland, J. L., & Ganguli, S. (2013).
achieve high accuracy rates without unnecessarily                        Learning hierarchical category structure in deep neural
sacrificing speed and effort. Indeed the use of this strategy            networks. Proceedings of the 35th Annual Meeting of the
would be compatible with a dual-systems framework that                   Cognitive Science Society.
stresses the primacy of intuitive heuristic processes over           Shafir, E. B., Smith, E. E., & Osherson, D. N. (1990).
deliberate controlled processes (see e.g. Kahneman &                     Typicality and reasoning fallacies. Memory &
Frederick, 2002).                                                        Cognition, 18(3).
    Finally note that the model proposed in this paper differs       Tversky, A., & Kahneman, D. (1974). Judgment under
greatly from previous heuristic models. It not only                      uncertainty: Heuristics and biases. Science, 185(4157)
formalizes the mechanisms responsible for the                        Tversky, A., & Kahneman, D. (1983). Extensional versus
representativeness heuristic, but trains these mechanisms on             intuitive reasoning: The conjunction fallacy in
a very large knowledge database, Wikipedia. The model can                probability judgment. Psychological Review, 90(4), 293.
                                                                 237

