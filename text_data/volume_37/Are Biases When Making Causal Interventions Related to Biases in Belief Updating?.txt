                       Are Biases When Making Causal Interventions Related to
                                                 Biases in Belief Updating?
                                                  Anna Coenen and Todd M. Gureckis
                          Department of Psychology, NYU, 6 Washington Place, New York, NY 10003 USA
                                                 {anna.coenen, todd.gureckis}@nyu.edu
                              Abstract                                  exposes the deeper relationship between intervention deci-
                                                                        sions/hypothesis testing and belief updating which has re-
   People often make decisions with the goal of gaining informa-        mained somewhat ambiguous in past research.
   tion which can help reduce their uncertainty. However, recent
   work has suggested that people sometimes do not select the               In the next section we will illustrate how biased belief up-
   most diagnostic information queries available to them. A crit-       dating might give rise to positive hypothesis testing. Then, we
   ical aspect of information search decisions is evaluating how        will describe two experiments that test whether or not people
   obtaining a piece of information will alter a learner’s beliefs
   (e.g., a piece of information that is redundant with what is al-     are biased in how they update their beliefs about causal struc-
   ready known is useless). This suggests a close relationship          tures, and if so, whether that bias influences their intervention
   between information seeking decisions on one hand, and be-           strategy.
   lief updating on the other. This paper explores the deeper re-
   lationship between these two constructs in a causal interven-
   tion learning task. We find that patterns in belief updating bi-     Information search & belief updating
   ases are predictive of decision making patterns in tasks where       Note that historically, confirmatory behavior has been iden-
   people must make interventions learn about the structure of a        tified in both information search and information evaluation
   causal system.
                                                                        (or belief-updating). For example, people seem to actively
   Keywords: information search; causal interventions; causal
   learning; hypothesis testing                                         seek positive evidence for individual hypotheses (e.g., when
                                                                        they selectively research websites supporting their viewpoint
                                                                        rather than seeking opposing ideas). In addition, people also
                          Introduction                                  interpret evidence in a way that gives more weight to posi-
A growing body of work has explored how people use inter-               tive rather than negative outcomes (Nickerson, 1998; Klay-
ventions to learn about causal structures in their environment          man, 1995). For example, upon passively hearing of a politi-
(Bramley et al., in press; Coenen et al., 2014; Steyvers et al.,        cian’s new budget proposal, people might focus on aspects
2003). An example of an intervention would be to take a vi-             that support their hypothesis about the general motivations of
tamin in the morning to see how it makes you feel, or tapping           the politician. However, the link between these two different
on a button in a video game to see what happens. Critically,            notions of “confirmation bias” is often unclear.
interventions are frequently made to gain information about                 To illustrate how these two behaviors might be connected
the underlying causal structure of world.                               with each other and how belief-updating in particular can in-
   The calculus of causal Bayesian Networks and information             fluence a learner’s intervention strategy, consider the equa-
theory can yield precise normative predictions for the most             tion of Expected Information Gain (EIG). EIG is one of the
diagnostic interventions to help a learner figure out a causal          most prominent models for human decision making during
structure (Pearl, 2000; Murphy, 2001). However, in previous             information search, including causal intervention learning
work (Coenen et al., 2014), we found that people do not al-             (Steyvers et al., 2003; Nelson, 2005; Markant & Gureckis,
ways choose the most diagnostic interventions predicted by              2012; Oaksford & Chater, 1994).
such theories. Instead, they frequently intervened on vari-                 In a causal setting, the model calculates the relative infor-
ables that would potentially lead to a lot of predicted effects         mativeness of different interventions that a person could make
in at least one hypothesized structure, but without necessar-           on a causal system. Thus, the model is primarily a decision
ily distinguishing it from others. We called this tendency a            making model, where the goal is to obtain useful informa-
“positive-testing strategy” (PTS), because its desire to “make          tion. Formally, the model assumes that the learner’s hypothe-
expected effects happen” mimics the classic finding in the              sis space, G, consists of a set of possible underlying causal
rule learning literature that people often ask questions that           graphs. For a learner trying to minimize their uncertainty
are likely to yield “yes” answers under a given hypothesis              about G (i.e., discern which graph or set of graphs is most
(Wason, 1960; Klayman & Ha, 1989).                                      likely) the model calculates a score, EIG(a) for each possi-
   What motivates participants to make positive tests instead           ble action or intervention a, taking into account all possible
of maximizing information during causal structure learning              intervention outcomes, Y :
(or hypothesis testing in general)? This article explores one
possible explanation of this behavior: It is possible that learn-                                                              1
ers do try to maximize the information of their interven-                  EIG(a) = H(G) − ∑ P(y|a) ∑ P(g|a, y)log                    (1)
                                                                                               y∈Y        g∈G              P(g|a, y)
tions but errors in the way that people update their beliefs
draw them astray from optimal behavior. This hypothesis                 where H(G) refers to the Shannon entropy over the posterior
                                                                    411

of the hypothesis space and P(g|a, y) is obtained using             A Non-diagnostic intervention         B Diagnostic intervention
                                                                       chosen by many participants           avoided by most participants
Bayes’ rule: P(y|g, a)P(g)/P(y|a). The dependency of this
equation on P(g|a, y) highlights how the EIG equation always           Hypotheses:        Likely outcome:    Hypotheses:        Likely outcomes:
involves an explicit belief updating step. Intuitively, EIG                 n2                                    n2
evaluates an action by imagining how different outcomes as a          n1           n3                       n1           n3
result of that action would change the learner’s belief. Thus,             n2                                     n2
according to the model, belief updating is fundamental to            n1           n3                        n1           n3
judging the information value of an action or decision. The         Intervention choices:                 Intervention choices:
goal of this paper is to explore if this intrinsic relationship
holds for human reasoners.
                                                                     n1 n2 n3                              n1 n2 n3
Potential updating biases and their impact on decision
making. It is interesting to consider the ways that incorrect       Figure 1: Example intervention problems with choice data from
belief updating would alter causal intervention decisions. Let      Experiment 1 in Coenen et al. (2014). Participants were presented
us momentarily take it as given that people use the Equation 1      with two possible wiring diagrams (shown under “Hypotheses”) and
                                                                    were asked to make an intervention on the system to determine the
to evaluate the informativeness of an intervention. How could       correct causal structure. The height of the black bars under “Inter-
it be that their choices appear suboptimal?                         vention choices” show the frequency by which different elements of
                                                                    the causal system were intervened on by participants. For example,
   One possibility is that people may be biased in how they         in panel A, no participants selected node n1, but people were split
                                                                    between n2 and n3.
assess P(y|g, a), the likelihood for an outcome to occur after
an intervention on a specific graph. Specifically, they might
assign higher likelihoods to outcomes that activate larger por-
tions of a graph. Such a tendency would be in line with previ-      to one another. Interventions activated a component which
ous work showing that people are more strongly affected by          in turn (might) activate other components. Participants’ task
positive rather than negative evidence when evaluating hy-          was to intervene on different chip components in order to
potheses (for a summary, see Klayman, 1995). If outcome             learn the true wiring diagram.
likelihoods are higher for positive observations (e.g. full ac-
tivation of a graph), EIG will also be higher for interventions         In our previous study, we found that participants chose in-
that lead to those observations.                                    terventions that have low EIG if these queries offer the possi-
                                                                    bility of activating a full causal graph. For instance, in Figure
   As another possibility, learners may also deviate from a         1A many participants chose to intervene on the root node,
normative account in how they incorporate the prior proba-          n2, of both graphs, which most frequently led to confound-
bility of an intervention outcome, P(y|a). Previous work has        ing evidence of all nodes turning on. This behavior could
shown that people often exhibit a tendency to disproportion-        have been caused by the two types of updating biases de-
ately evaluate hypotheses based on their likelihood of pro-         scribed in the previous section. That is, if participants ig-
ducing an event or outcome alone, irrespective of its proba-        nore the fact that the same outcome be produced by both
bility of occurring under alternative hypotheses (Kahneman          hypothesized graphs (neglect of P(y|a)) and they give more
& Tversky, 1973, 1972; Doherty et al., 1979). In this case, if      weight to positive outcomes (increase of P(y|g, a) if a graph
learners decrease or ignore P(y|a), they will be more likely        is completely activated), intervening on n2 becomes an at-
to choose interventions that are not actually diagnostic, be-       tractive option because it can produce all predicted effects
cause the same outcome is predicted by multiple graphs. In          in either graph. Learners might think that the confounding
that case, they might take an outcome to be supportive of one       “all-on” outcome actually provides strong evidence for one
of the graphs, while ignoring that it’s equally well supported      of the graphs (which may be chosen randomly, or based on a
by an alternative one.                                              learner’s prior preference).
   In summary, different biases in belief updating could,               We also found that by choosing interventions with ex-
according to the theory, alter decision making strategies even      pected positive outcomes, participants often forgo queries
if people otherwise perfectly followed the basic (normative)        that have very high EIG, such as portrayed in Fig 1B. Here,
tenets of Equation 1.                                               intervening on n2 has the potential of discriminating between
                                                                    the two graphs, but does not offer a chance to see either of
Explaining intervention data. To make this discussion               them be completely turned “on”, because the outcome would
more concrete, we will describe two examples of biased in-          either be a half-activated chain graph or nothing happening
tervention strategies from our past findings (Coenen et al.,        whatsoever. If people weigh positive evidence higher than
2014). In this previous study participants were presented with      negative (or less positive) evidence then perhaps both of these
a virtual “computer chip” made up of various components. In         outcomes would be deemed less informative than they actu-
addition, they were provided with two possible wiring dia-          ally are, which could explain why most participants chose one
grams that could detail how the components were connected           of the other two interventions, n1 or n3.
                                                                412

Overview of the present study
The two experiments reported in this paper attempt to as-
                                                                                                                                                What type of chip
sess the relationship between belief updating and intervention                                                                                         was this?
choice. In particular, we assumed that there are individual
differences in belief updating that might explain variation in
decision strategies.
                                                                                                                                             Def. Left    n.s.  Def. Right
   In order to quantify difference in belief updating, in Exper-
                                                                       Beginning: All nodes Click to intervene on States of other components      Estimate posterior
iment 1 we created a causal learning task where people were            are “off”            instructed node       update
instructed to make interventions on a causal system and to
subsequently rate the posterior belief about the correct graph.       Figure 2: Schematic procedure for the instructed intervention tri-
Trials were constructed to be revealing about biases towards          als. Participants were asked to intervene (click on) the node with the
                                                                      yellow outline and subsequently observed the outcome of their in-
the overweighting of positive but non-diagnostic evidence             tervention (other nodes turning on or remaining turned off). Using a
compared to less positive (or negative) diagnostic evidence.          slider, they then gave their posterior estimate about which hypothe-
   In Experiment 2 we attempted to establish a link between           sized graph was more likely to underlie the chip they just intervened
                                                                      on.
updating strategies and intervention choice strategies. In ad-
dition to the instructed trials designed to assess belief updat-
ing, participants also had to make a range of self-selected in-       For each chip, they were given two possible arrow diagrams
terventions. Using model-based analyses we quantified the             that illustrated the two hypothesized causal graphs that ex-
tendency of those choices to conform to either information-           plain the working of a chip (see Figure 2). They were then
maximizing interventions (in line with EIG) or PTS interven-          instructed to turn on one specific “component” (node) on the
tions and related these scores to the estimates made in the           chip by clicking on it and observe the outcome (other com-
belief updating phase of the task.                                    ponents also turning on or remaining turned off). Next, they
                                                                      were asked to rate which chip diagram was an accurate de-
                       Experiment 1                                   scription of the chip they just tested. They gave their answer
Participants                                                          using a continuous slider with three labels on the left, middle,
Sixty-one US-based participants were recruited via Amazon             and right (“definitely Type 1”, “not sure”, “definitely Type
Mechanical Turk. They were paid $2 for participating in the           2”).
study.                                                                     Before starting the task they were explicitly told that causal
                                                                      links between components only worked 80% of the time and
Stimuli                                                               that components could only be turned on by each other or an
The same set of 20 causal intervention problems (10 critical          intervention, but not by any other background causes. Partici-
trials, and 10 control trials) were given to each participants.       pants had to accurately pass a short quiz about the task before
Each problem consisted of two causal hypotheses (three-node           being allowed to proceed to the main part of the experiment.
graphs), a prescribed intervention (node), and the outcome
                                                                      Results & Discussion
of that intervention (which nodes turned “on” as a conse-
quence). The critical trials were specifically designed to re-        Figure 3 shows histograms of participants’ posterior esti-
veal any belief updating bias that we hypothesized to under-          mates after each intervention/outcome trial. The red dot indi-
lie positive hypothesis testing, that is, they were interventions     cates the true posterior probability of the graphs derived using
in which the outcome was either diagnostic but without ac-            Bayes’ rule and the correct outcome likelihoods of the two
tivating any graph completely (like in Figure 1B), or it was          graphs given each intervention. The red arrows in the critical
non-diagnostic, but showing all expected outcomes of at least         trials indicates the direction in which one would expect par-
one graph (like in Figure 1A). The control trials were either         ticipants to be biased based on our predictions outlined above.
diagnostic and showing a graph activated completely or non-           We would like to particularly guide the reader’s attention to
diagnostic and without any full graph’s activity. Thus, they          three findings.
did not pose the same conflict between diagnosticity and pos-              First, especially on the control trials participants’ estimates
itive outcomes.                                                       track the true posterior probabilities of the graphs well, that
   The two trial types were randomly interspersed without the         is, the highest density of choices is typically found at or very
knowledge of the participants. When causal graphs were pre-           close to the red dots in the plot. This shows that generally
sented on the screen the order of nodes was always random-            participants understood the task and were able to evaluate in-
ized and they were also randomly placed in three out of five          tervention outcomes correctly.
positions on the screen.                                                   Second, the mapping between true and estimated probabil-
                                                                      ity is less pronounced on the critical trials (see panel A). Here,
Procedure                                                             participants’ estimates are often skewed in the direction of the
Participants were told that they had to test a series of com-         red arrow, that is, in line with the above predictions about up-
puter chips in a chip factory to figure out how they worked.          dating biases. Without discussing every single deviation in
                                                                  413

detail, estimates on the objectively non-diagnostic trials (i.e.          A: Critical Trials
those with a posterior probability of 0.5) in the first four tri-
als from the top are particularly noteworthy. Here, the sys-           1
tematic deviation from the true posterior cannot be due to a
tendency towards indifference (probability of 0.5). Consider           2
for example trial no. 2, in which many participants strongly
endorsed the One-Link graph on the left, even though the ev-           3
idence equally supports the alternative Common Effect graph
on the right. Again, the reason we suspect this deviation hap-         4
pens is that participants place too much emphasis on the fact
that they can observe all possible activity predicted by the
                                                                       5
One-Link structure, but not of the Common Effect.
   Thirdly, another interesting deviation from the true poste-
rior is found on the very first trial type, in which all compo-        6
nents are turned on after an intervention on the middle node,
which is the root of both a Chain and a Common Cause graph.            7
As discussed earlier, this root node intervention is one that
many participants actually chose in a previous experiment              8
(see Figure 1A) and this finding might be able to help explain
why: Participants may have thought that they can actually              9
learn something from the all-on outcome. It is puzzling, how-
ever, that participants mainly endorsed the Common Cause
structure rather than the Chain, since the outcome provides            10
equal positive evidence for both. One could speculate that
the immediacy of the Common Cause links in connection to                  B: Control trials
the root node may have contributed to this tendency, but ulti-
mately this finding requires further investigation. In any case,
this result demonstrates a relatively strong violation of opti-
mal belief updating.
   In sum, we find that participants do exhibit a tendency
to erroneously change their probability estimates away from
indifference if one or both of the structures are completely
activated through an intervention. They also do not change
their beliefs enough if a diagnostic outcome is not activating
a complete graph. However, this bias is by no means found to
be equally strong in all trials and participants’ estimates were
much more accurate in the control trials, showing that gen-
erally people’s updating process tracks the correct posterior
probability of the graphs.
                        Experiment 2
Having found that participants show greater deviations from
optimal belief-updating when diagnosticity and positive out-
comes of individual graphs were at odds with each other, the
second experiment aimed to find out whether the tendency to
show this bias is at all related to people’s intervention strat-
egy. Since we argue above that biased belief-updating might
                                                                                     0       0.25       0.5       0.75      1
be the reason that people often conduct positive tests rather
than maximally diagnostic ones, we predict that participants
                                                                      Figure 3: Histograms of participants’ probability estimates. Each
with biased belief updating should be more likely to conduct          row represents one trial type in which two causal hypotheses were
positive tests.                                                       compared. Crosses indicate nodes that participants were instructed
                                                                      to intervene on (turn the nodes “on”). Grayed out nodes remained
   To test this, we added a free intervention task to the ex-         “off” after the intervention, the remaining nodes were also observed
periment which participants completed either before or after          to be “on”. Red dots in the critical trials indicate the posterior graph
a series of instructed interventions. The goal was to quantify        probability according to accurate Bayesian belief updating. Red ar-
                                                                      rows indicate the predicted direction of positive outcome bias.
both a participant’s intervention strategy and their belief up-
                                                                  414

dating bias to investigate if there exists a connection between                               A                                                                        B
                                                                                                          Free trials first    Instructed trials first                                     Free trials first   Instructed trials first
the two.                                                                                          0.6
                                                                            Error on control trials                                                      Positive outcome bias
                                                                                                                                                                                 0.10
Participants                                                                                      0.4
                                                                                                                                                                                 0.05
121 US-based participants were recruited via Amazon Me-                                                                                                                          0.00
                                                                                                  0.2
chanical Turk. They were paid $2 for participating in the                                                                                                                    -0.05
study.
                                                                                                  0.0                                                                        -0.10
                                                                                                        low θ        high θ    low θ          high θ                                    low θ        high θ    low θ           high θ
Stimuli
In the instructed intervention phase, participants saw the same             Figure 4: Updating error and positive outcome bias by strategy
20 trial types as in Experiment 1 with one small change. The                weight and task order. Low-θ participants were better fit by a posi-
                                                                            tive testing strategy and high-θ participants by the EIG model.
two trials in which the predicted bias was bi-directional (tri-
als 1 and 3 in Figure 3) were replaced with trials that had a
unidirectional predicted bias. This was done to make it eas-                estimation, we regressed this directional deviation on the av-
ier to quantify updating biases specifically in one direction               erage absolute deviation in the control trials (see Figure 3B)
as pertaining to our predictions, without confounding it with               and used the residuals as a measure of positive-outcome bias.
general noisiness in participants’ use of the slider, for exam-                 For brevity’s sake, we will only report two analyses that re-
ple.                                                                        late the binary strategy weight with the the quality of belief-
   In the free intervention phase, participants were given 20               updating. Figure 4 shows how the two groups of participants
intervention problems that were used in a previous set of ex-               (low-θ and high-θ) compare in terms of overall error (aver-
periments reported in (Coenen et al., 2014, see Figure 2), and              age absolute deviation from the true posterior in the control
were used to characterize people’s intervention strategies on               trials) and on the positive-outcome bias measure (residuals
a continuum between positive testing (PTS) and information                  after controlling for overall error). The plots are split by the
maximization (EIG).                                                         order of the instructed and free intervention tasks, which was
                                                                            counterbalanced between participants.
Procedure
                                                                                Note that there exists a significant relationship between
The procedure was identical to that in Experiment 1 except                  strategy weight and error on the control trials, t(119) = 4.84,
that in the free intervention trials participants were instructed           p < .001. Participants with more discriminatory interven-
to choose freely which node to intervene on. Again, there was               tion choices (more in line with EIG), also made more accu-
no feedback about the correct structure at the end of a trial.              rate probability estimates than participants better fit by a PTS
                                                                            strategy.
Results & Discussion                                                            The relationship between strategy weight and positive-
To quantify people’s intervention strategies we used the                    outcome bias, on the other hand, is much weaker. Overall,
method developed and reported in Coenen et al. (2014) which                 it is still significantly negative, so that bias is lower for high-
results in a strategy weight θ that indicates the degree to                 θ participants, t(119) = 2.34, p = .02, but the effect seems
which a participant’s interventions are in line with the EIG                driven by participants in the group that received the free in-
strategy of information search (θ = 1) compared to a con-                   tervention task first.
firmatory PTS strategy (θ = 0). In comparison to our own                        One caveat of this analysis is the way in which the positive-
previous work on intervention strategies, the current experi-               outcome bias is defined. In an effort to isolate it from a
ment yielded a larger portion of PTS-interventions and fewer                participant’s general tendency to make errors on the poste-
participants that were strong EIG users (as a rough indication,             rior estimates, it is possible that some relevant variation may
only 30% of participants were fit with θ > .5, compared with                have been lost. For example in people who are both biased
47% in our previous study). Due to the unequal distribution                 and noisy, removing the noise component may have made it
of participants’ best-fitting θ values we use a median split to             look as if they showed no bias at all. Taken together with
divide participants into two equal groups of low-θ and high-                the lack of high-θ participants, the last analysis need to be
θ for the analyses reported below, bearing in mind that the                 treated with some caution and should be backed up by further
high-θ group contained many participants from the middle of                 experiments.
the distribution, however.
   To quantify each participant’s tendency to commit the up-                                                                  General Discussion
dating error we hypothesized and found in Experiment 1, we                  In this paper we explored how people update their beliefs af-
first computed the average deviation of participants’ proba-                ter performing causal interventions and observing their out-
bility estimates from the true posterior in the hypothesized di-            come. Having previously found that participants often per-
rection on the critical trials (i.e. in the direction of the arrows         form interventions that can cause positive outcomes in indi-
in Figure 3A). Because this deviation score will be higher if               vidual graphs, we predicted that this may be due to a tendency
a participant is generally noisy in their posterior probability             to treat these outcomes as particularly informative (whether
                                                                      415

or not they actually are).                                          Acknowledgments This work was supported by grant number BCS-
   Several findings from these experiments stand out.               1255538 from the National Science Foundation, the John Templeton
   First, it is important to note that participants were often      Foundation “Varieties of Understanding” project, and a John S. Mc-
very good at updating their beliefs in a normative fashion,         Donnell Foundation Scholar Award.
particularly when diagnosticity and outcome positivity (i.e.
the degree to which outcomes involve all effects predicted
                                                                                                References
                                                                    Bramley, N. R., Lagnado, D. A., & Speekenbrink, M. (in press).
by individual graphs) were not in conflict. This finding ties          Conservative forgetful scholars - how people learn causal struc-
in with earlier work demonstrating that people are effective           ture through sequences of interventions. Journal of Experimental
causal learners who understand the basic mechanism of an               Psychology: Learning, Memory, and Cognition.
intervention (see e.g., Lagnado & Sloman, 2004; Hagmayer            Coenen, A., Rehder, B., & Gureckis, T. (2014). Decisions to in-
                                                                       tervene on causal systems are adaptively selected. In P. Bello,
et al., 2007; Bramley et al., in press).                               M. Guarini, McShane, & B. Scassellati (Eds.), Proceedings of the
   However, Experiment 1 showed that there was a greater               36th annual conference of the cognitive science society. Austin,
                                                                       TX.
tendency to deviate from the true posterior probabilities when
                                                                    Doherty, M. E., Mynatt, C. R., Tweney, R. D., & Schiavo, M. D.
diagnosticity and outcome-positivity were at odds. On those            (1979). Pseudodiagnosticity. Acta psychologica, 43(2), 111–121.
trials, we found considerable deviation from optimal belief-        Hagmayer, Y., Sloman, S. A., Lagnado, D. A., & Waldmann, M. R.
updating in participants’ posterior probability estimates. In          (2007). Causal reasoning through intervention. Causal learning:
particular, participants often endorsed graphs more strongly           Psychology, philosophy, and computation, 86–100.
                                                                    Kahneman, D., & Tversky, A. (1972). Subjective probability: A
than they should if all of their predicted effects could be ob-        judgment of representativeness. Cognitive psychology, 3(3), 430–
served. This shows that people are not purely engaged in               454.
Bayesian belief-updating when observing intervention out-           Kahneman, D., & Tversky, A. (1973). On the psychology of predic-
comes. Instead, they may sometimes be influenced by the de-            tion. Psychological review, 80(4), 237.
gree to which outcomes reflect a fully activated causal struc-      Klayman, J. (1995). Varieties of confirmation bias. Psychology of
                                                                       learning and motivation, 32, 385–418.
ture, while ignoring the question whether or not an outcome         Klayman, J., & Ha, Y.-w. (1989). Hypothesis testing in rule dis-
actually discriminates between structures.                             covery: Strategy, structure, and content. Journal of Experimental
   Experiment 2 further showed that people who conduct                 Psychology: Learning, Memory, and Cognition, 15(4), 596.
                                                                    Lagnado, D. A., & Sloman, S. (2004). The advantage of timely inter-
more positive tests when choosing interventions were more              vention. Journal of Experimental Psychology: Learning, Mem-
likely to commit belief-updating errors in general. Thus there         ory, and Cognition, 30(4), 856.
appears to be a relationship between people’s intervention          Markant, D., & Gureckis, T. M. (2012). Does the utility of in-
strategy and their subsequent ability to learn from these in-          formation influence sampling behavior? In Proceedings of the
                                                                       34th annual conference of the cognitive science society. austin,
terventions. Whether or not this relationship is specific to           tx: Cognitive science society.
the positive-outcome updating error as we hypothesized, and         Murphy, K. P. (2001). Active learning of causal bayes net struc-
which was found in Experiment 1, remains an open question.             ture. Technical Report. Department of Computer Science, U.C.
Although Experiment 2 found a significant relationship be-             Berkeley..
                                                                    Nelson, J. D. (2005). Finding useful questions: on bayesian diag-
tween strategy and positive-outcome bias overall, it was a rel-        nosticity, probability, impact, and information gain. Psychologi-
atively weak one.                                                      cal review, 112(4), 979.
   As we pointed out, the data in Experiment 2 had some             Nickerson, R. S. (1998). Confirmation bias: A ubiquitous phe-
                                                                       nomenon in many guises. Review of General Psychology, 2(2),
undesirable properties, such as a lack of variability in par-          175.
ticipants’ intervention strategies, with a much larger number       Oaksford, M., & Chater, N. (1994). A rational analysis of the selec-
leaning towards positive testing, rather than discriminatory           tion task as optimal data selection. Psychological Review, 101(4),
search. It also proved challenging to disentangle the general          608.
tendency to commit updating errors with the specific type of        Pearl, J. (2000). Causality: models, reasoning and inference
                                                                       (Vol. 29). Cambridge Univ Press.
bias that we intended to isolate. Future work should there-         Steyvers, M., Tenenbaum, J. B., Wagenmakers, E.-J., & Blum, B.
fore aim to find a better method to distinguish the two. Con-          (2003). Inferring causal networks from observations and inter-
cretely, we suggest a follow-up experiment with a stronger             ventions. Cognitive science, 27(3), 453–489.
manipulation, such as training participants on how to evalu-        Wason, P. C. (1960). On the failure to eliminate hypotheses in a
                                                                       conceptual task. Quarterly journal of experimental psychology,
ate intervention outcomes and test whether that has an effect          12(3), 129–140.
on subsequent intervention decisions. Such a manipulation
would be able to show a more direct link between these two
aspects of intervention learning.
   In sum, we believe that these studies offer a first attempt
to study how people update their beliefs about causal sys-
tems from intervention data and the experiments reported
here show some noteworthy patterns of errors that affect par-
ticipants in this process. Future research is needed to clarify
exactly how causal learning and hypothesis-testing interact.
                                                                416

