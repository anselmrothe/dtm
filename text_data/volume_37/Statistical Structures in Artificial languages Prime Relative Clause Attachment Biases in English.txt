        Statistical Structures in Artificial languages Prime Relative Clause Attachment
                                                          Biases in English
              Felix Hao Wanga, Mythili Menonb, Elsi Kaiserb {wang970, mythilim, emkaiser} @usc.edu
      a
        Department of Psychology, bDepartment of Linguistics, University of Southern California, Los Angeles, CA, 90089
                              Abstract                                  letter) and then are asked to describe a picture where a
   The phenomenon of syntactic priming is well studied in the
                                                                        soccer player is giving a ball to a boy, they are more likely
   literature, but the mechanisms behind it are still under debate.     to say The soccer player gave the boy a ball rather than The
   In this study, we trained English-speaking participants in           soccer player gave a ball to the boy. In general, reading or
   artificial language sequences with dependencies that are either      producing sentences of one type can prime the production
   adjacent or non-adjacent. The participants then wrote                and comprehension of sentences with the same structure.
   completions to relative clause (RC) fragments. We found that         Structural priming occurs even if the lexical items in the
   participants who learn non-adjacent dependencies in the              prime sentence and the target sentence are different, and
   artificial language, exhibit a bias to write high-attachment
   (non-adjacent) continuations for RCs, when compared to               thus cannot be attributed to lexical repetition (e.g., Corley &
   participants in a control condition who exhibit low-attachment       Scheepers, 2002; Pickering & Branigan, 1998; Branigan,
   (adjacent) biases in RCs. The implications for theories of           Pickering & Cleland, 2000).
   syntactic priming and its relations to implicit learning are            There are two theoretical accounts for structural priming:
   discussed.                                                           the Lingering Activation account and the Implicit Learning
   Keywords: implicit learning; syntactic priming; relative             account. The “lingering activation” account (Pickering &
   clause attachment bias; non-adjacent dependencies                    Branigan, 1998) suggests that people are using the same
                                                                        structures repeatedly because the activation for the
                          Introduction                                  structures lingers in the language production system. This
Although the phenomenon of syntactic priming has been                   account predicts that when structures leave activations
very well studied in the literature, the exact processes                lingering, these activations are more likely to be reused.
behind priming are still unclear. We build on insights from             Furthermore, since there is also lingering activation of
research in child language development and adult sentence               lexical items, priming with the same lexical item with the
processing regarding the representation of abstract                     same syntactic structure will yield stronger priming (‘lexical
                                                                        boost’). Crucially, because activation – of lexical items as
dependencies in language and other cognitive domains (e.g.
                                                                        well as syntactic structures – is assumed to decay over time,
Gomez, 2002; Scheepers, Sturt, Martin, Myachykov,
                                                                        this account predicts priming effects should diminish
Teevan & Vizkupova, 2011). We explore whether an
                                                                        relatively rapidly with time. The “implicit learning account”
abstract relation represented through word-level statistical
                                                                        (Bock & Griffin, 2000; Chang, Dell & Bock, 2006) suggest
regularities in an artificial language can prime the
                                                                        that syntactic priming does not require (and usually does not
attachment biases of relative clauses. Specifically, we
                                                                        involve) any explicit awareness on the part of the
explore the question whether adjacent and non-adjacent
                                                                        participants that they are reusing structures. In the classic
structures derived from statistics can prime the low versus
                                                                        structural priming paradigm, exposure to the structures of
high attachment preferences during the production of
                                                                        interest is covert in that participants are not aware that
English relative clauses.
                                                                        certain sentences are primes while others are fillers. As a
                                                                        whole, these observations suggest that adapting to the
Structural priming
                                                                        structures in question is not a conscious choice, i.e. priming
Structural priming refers to the observation that people are
                                                                        is an implicit process.
more likely to reuse syntactic structures that they have
                                                                           Hartsuiker, Bernolet, Schoonbaert, Speybroeck &
already used (e.g. Bock, 1986; Bock, 1989). Researchers
                                                                        Vanderelst (2008) suggest that both the “implicit learning”
have demonstrated structural priming with different
                                                                        and “lingering activation” accounts are partially right.
syntactic structures, including verb phrase structures
                                                                        Hartsuiker et al. monitored the timing course of syntactic
(Pickering & Branigan, 1998) and relative clause attachment
                                                                        priming, using stimuli triggering priming from the same
(Mitchell, Cuetos, Corley & Brysbaert, 1995; Scheepers,
                                                                        verb or different verbs. Between trials, the timing between
2003). In the classic paradigm (Bock, 1986), participants
                                                                        the exposure to a structure (prime) and the production of the
read sentences and were asked to describe semantically
                                                                        target sentence was varied. Hartsuiker et al. discovered that
unrelated pictures. The question is whether their structural
                                                                        there is indeed a larger priming effect when both prime and
choices in the descriptions are influenced by the structure of
                                                                        target use the same verb (“lexical boost”). Furthermore, this
the sentences they had previously read. For example, if
                                                                        effect decays with time, consistent with the predictions of
participants have read a sentence like “The teacher sent the
                                                                        the “lingering activation” account. Given that our design did
girl a letter” (recipient girl mentioned before direct object
                                                                        not use any English verbs to achieve the priming effect, our
                                                                    2607

results validates the implicit learning account for the              (NP1). If there are more high-attachment sentences
phenomenon when syntactic structures get reused without              produced, we call this a high-attachment bias, and vice
having the same lexical items. However, it does not speak to         versa. The high attachment completions are instances of
the lingering activation account. We agree with Hartsuiker           non-adjacency whereas the low attachment completions are
et al. that these two accounts are not mutually exclusive.           adjacency. In English, the default preference for attachment
                                                                     completions is low attachment, i.e. participants tend to
Artificial language paradigm                                         attach ambiguous relative clauses to the lower NP (e.g.
To study syntactic priming without the influence from                Cuetos and Mitchell, 1988).
lexical items, we decided to use an artificial language                 As pointed out by Scheepers (2003), the distinction
paradigm. Artificial language can provide adjacent and non-          between high and low in relative clause attachment bias has
adjacent dependencies, which are structural and can be               to do with syntactic sequencing. The syntactic rules used to
learned.                                                             generate these representations are the same, and the only
   In order to demonstrate implicit learning, researchers have       exception is that in low attachment, the relative clause is
used the artificial language paradigm (e.g., Saffran, Newport        modifying the noun immediately preceding it, whereas in
& Aslin, 1996; Gomez, 2002). In an artificial language,              high attachment, the relative clause is modifying the noun
people can learn statistical patterns in nonsense words (e.g.        non-adjacently preceding it. In our opinion, this provides a
voy glaik fex, choon glaik jub). Participants can readily learn      striking analogy to artificial language dependencies, because
these structures, in the absence of any semantic information.        artificial language provides combinatorial properties where
Constructed with nonsense words, these linguistic materials          words are corresponding to other words, according to some
only convey distributional patterns. Furthermore, statistical        combinatorial pattern. The only potential issue is the grain
learning goes beyond the specific items (words or syllables)         size of sequencing (word vs. phrase level). However, there
being learned (Thiessen, Kronstein & Hufnagle, 2013;                 is previous research suggesting that grain size may not
Mintz, Wang & Li, 2014). According to Thiessen et al.                matter to a large extent (Melinger & Dobel, 2005).
2013, statistical learning initially gathers statistics about the
input presented to learner and uses this information to learn        Aims of this work
and infer patterns. Under this view, the representations that        In this study, we test whether structural representations
learners generate from artificial language input have been           arising from distributional information can prime relative
argued to be abstract and structural.                                clause completions. If relative clause attachment biases
                                                                     come from representations that are completely different
Adjacency and non-adjacency                                          from distributional dependencies, exposure to any artificial
Two key concepts relevant for structural representations are         language with only distributional properties will not result
the notions of adjacency and non-adjacency. Starting with            in any changes in the completion of relative clauses. On the
the seminal study of Saffran, Newport & Aslin (1996), there          other hand, if relative clause attachment biases come from
is a large body of work showing that adults and children can         representations that are shared with sequential
learn adjacent relations from continuous streams of                  representations from an artificial language, the relative
syllables. More recent artificial language work (Gomez               clause bias is predicted to change as a result of learning
2002; Maye & Gomez, 2005) demonstrated that adults and               structures that are different from the default.
children are also able to learn non-adjacent dependencies               To this end, we primed participants with an artificial
between words.                                                       language which conveyed structures that are consistent with
                                                                     our prediction. In this experiment, we will test this
Relative clauses                                                     hypothesis with English.
The notions of adjacency and non-adjacency are also
relevant in the domain of syntax, for example in the                                           Experiment
representation of relative clauses. In English sentences with
                                                                     In this experiment, we explore the effect of statistical
the structure NP1 of NP2 who (e.g., Jessica visited the
                                                                     structures from an artificial language on participants’
doctors of the supermodel who), the following relative
                                                                     completions of ambiguous relative clauses fragments. Our
clause completions (eg. who lived in Los Angeles) can
                                                                     experiment has a learning phase and a testing phase.
potentially attach to either one of the NPs. In high
attachment completions, the following relative clause
                                                                     Methods
attaches back to the higher NP1 (eg. the doctors lived in Los
Angeles). In the low attachment completions, the relative            Participants
clause attaches back to the lower NP2 (eg. the supermodel            A total of 50 adult native English speakers participated.
lived in Los Angeles).                                               Given the four conditions described below, there were 20
   In our experiment, participants are asked to complete             participants in the critical non-adjacent dependency
sentence fragments ending in ‘who’. Thus, they can                   condition, 10 in the control condition, and 10 in each of the
complete the sentence fragment modifying either the                  two adjacent dependency conditions.
immediately adjacent noun (NP2), or the non-adjacent noun
                                                                 2608

Stimuli                                                           NPs were definite animate nouns, preceded by the definite
First, we describe the stimuli used in the training phase of      article. The NPs were controlled for number. Half of the
the experiment. In the training phase, we used artificial         sentences had NP1-singular and NP2-plural (e.g. the doctor
words, similar to the stimuli used in Gomez (2002)’s non-         of the supermodels) and the other had the opposite
adjacent dependency experiment. A female American                 configuration (e.g. the doctors of the supermodel). This
English speaker read and recorded these nonsense words in         facilitates coding because number marking on the verb
a sound isolated room. The speaker pronounced the stimuli         usually disambiguates (e.g. …was happy vs. …were happy).
one word at a time. We digitally spliced the recordings into      All verbs in the target fragments (e.g. counted) were non-
individual word files that began at the onset of each word.       implicit causality (non-IC verbs), chosen in order to avoid
Word files generated from this procedure are all shorter than     verb semantic bias. Fillers were non-ambiguous English
0.8 seconds, and silences were added to make each word            sentence fragments of similar length. Each participant
files 0.8 seconds long. This allowed us to concatenate word       completed the same 18 target sentences and 18 filler
files into sentences with words occurring every 0.8 seconds.      sentences. The fillers do not involve relative clauses, and are
Between each artificial sentence, there was also a 0.8 second     comprised of a range of sentence types. They are open to a
pause in between, to signal the start and the end of each         range of reasonable continuations, and do not follow a
‘sentence’.                                                       particular structure.
   Similar to Gomez (2002), each sentence is made of 3
words, which differ in terms of their distributional              Design and Procedure
properties, between the 4 conditions of the experiment. We        There are two phases to the experiment, the training phase
used monosyllabic words (for eg. voy, nud, choon, glaik,          and the testing phase. During the training phase, participants
blit, ghire, ghen, sowch, dess, fex, dap, jub). In the non-       listened to sequences in the artificial language and in the test
adjacent dependency condition (AiXCi), words at the               phase, participants either answered an artificial language
beginning and the end always co-occurred. Three different         question, or completed a sentence fragment.
pairs of words co-occured as A words or C words, while a             The training phase consisted of a simple artificial
total of 6 different words were used as X words at the            language learning task. In this phase, participants listened to
intermediate position. Thus, we had a total of 18 unique          an artificial language according to the condition that they
trigrams. The correspondence between A words and C                were in. To briefly reiterate, there were 4 between-subject
words were counterbalanced between subjects, such that the        conditions: the AiXCi condition (Non-adjacent dependency
wrong correspondence in one condition is correct in the           condition), the AiCiX and XAiCi conditions (adjacent
other condition, and vice versa. In the adjacent dependency       dependency condition), and the control condition where
condition, the X words were moved to the front (XAiCi             about equal numbers of adjacent and non-adjacent
condition) or to the back (AiCiX condition), such that the        dependencies exist in the 18 trigrams used. In between
dependency is adjacent. In the control condition, 18 unique       trials, participants were also asked the question “What was
word trigrams were created such that there were same              the last word you heard?” with 2 words to choose from.
numbers of adjacent or non-adjacent dependencies in these         Participants then pressed a key to indicate their choice. This
trigrams.                                                         question was presented every few minutes, in order to keep
   We also created sentence fragments for participants to         them alert during this task. The training phase lasted about
complete in the testing phase. There were 2 kinds of              20 minutes.
sentence fragments: targets and fillers. All target sentence         The test phase immediately followed the training phase.
fragments are similar to example (1), where NP1 the doctors       Before the test phase started, we reminded participants of
and NP2 the supermodel are connected by the preposition           the two types of tasks: questions about the artificial
‘of’ and are followed by the relative pronoun ‘who’.              language and sentence fragments for them to complete. Half
(Targets were constructed using stimuli used by Rohde,            of all the test trials were questions about the artificial
Levy & Kehler, 2011. We made sure that none of our verbs          language (36 trials), and the other half were sentence
had strong implicit causality biases, using Hartshorne and        completions (36 trials). The artificial language portion
Snedeker (2012).                                                  consisted of trigrams that are composed in the same fashion
   (1)    John met [the doctors]NP1 of [the supermodel]NP2        as in the training phase. Three words at a pace of 0.8 second
          [who invented a vaccine]RC.                             per word were presented to the participant, and then a
   The participants’ task was to write a completion for the       question appeared on the screen: “Did you hear this in the
sentence. We analyzed the completions for whether the             training phase or not?” Across the testing session, there
relative clause modifies NP1 (e.g. the doctors who invented       were 36 test items, half of which are targets (trigrams from
a vaccine) or NP2 (e.g. the supermodel invented a vaccine).       the artificial language), and the other half foils (trigrams not
Relative clauses that modify NP1 are called high                  in the artificial language). The foils in the AXC, ACX, XAC
attachments and relative clauses that modify NP2 are called       conditions are such that the correspondence in terms of the
low attachments.                                                  dependency is incorrect (AiXCk, k~=i). The foils in the
   In targets, the subject of the sentence was always a proper    control conditions are reversed strings from the training
name (equal numbers of male and female names). The two
                                                              2609

trigrams. For sentence completion trials, half of the sentence    Now, we turn to the priming results. As mentioned, the
fragments were target and half were foils.                        outcome is a binary response for high/low attachment, with
   The trials were block pseudo-randomized in the following       others were coded as missing. The sentences coded as
way. The two types of trials that were critical were the          missing included tiny proportions of continuations where
relative clause target sentence completions and artificial        the participant entered continuations that are syntactically
language questions that are from the language. The relative       incorrect, as well as those that are semantically completely
clause target sentence completions are always preceded            ambiguous with regard to attachment. These sentences were
from an artificial language item from the language, that is,      missing at random, and a Goodness of Fit test showed that
participants are supposed to answer, “Yes” to the artificial      there are no in-between condition differences in terms of the
language question. We mixed these trials with all the other       amount of data missing (p=0.09). In a mixed-effects logistic
trials in a randomized order within 3 blocks. The testing         regression model that predicts the proportion of completion
phase lasted between 15 to 30 minutes, and the whole              being high attachment (coded as 1) vs. low attachment
experiment was done under an hour.                                (coded as 0), the artificial language learning condition was
                                                                  specified as the fixed effects while holding subjects and
Coding                                                            items as random effects. The general model fit was
We coded only the target sentences. The coding of the             indicated by the Wald chi-squared test, which yields a p-
sentences resulted in three types: high attachment (HA), low      value smaller than 0.001.
attachment (LA), and ambiguous. For the logistic regression          Our main results show that when comparing between
model, HA was coded as 1 and LA was coded as 0, and               conditions, we find that the non-adjacent dependency
ambiguous was treated as missing. Coding was done with            condition is significantly different from the control
mostly syntactic considerations, given that the two NPs in        condition, while the adjacent dependency conditions are not.
our sentences are different in terms of number, so the verb       In other words, as can be seen in Figure 1 (below), we see
from the continuation in the relative clause shows overt          that although in the control condition, the participants are
morphological agreement with the NPs. If verb number did          biased to produce more low attachment completions (55%),
not disambiguate (e.g. went, asked), semantic cues were           in the non-adjacent dependency condition (AiXCi) the
used to decide high attachment (e.g. Emily worked with the        number of low attachment completions is significantly
mother of the children who just got tenure) from low              lower (37%). In the adjacency conditions (AiCiX, XAiCi),
attachment (Chris counted the fans of the singer who just         the low attachment completions are not significantly
finished the encore). If both verb marking and semantic cues      different from the control condition (52 % for AiCiX, 48%
were unclear, the sentence was coded as ambiguous.                for XAiCi). Moreover, in the non-adjacency condition, there
    The continuations were double coded by two native             is an overall bias for high attachment completions (42 %).
English speakers, who exhibited >99% agreement. (The              These results are in Table 2, and we plot out the proportions
remaining <1% of the items were resolved by discussion).          of sentence completions in each artificial language condition
                                                                  in Figure 1.
Training Phase Results
In all conditions, participants were able to correctly endorse              Table 2. Result of logistic regression for priming
correct items in the artificial language and rejected foils
above chance. For each of the four conditions, we ran a               Cond.       Manipulation      β         Z           p-value
mixed-effects logistic regression, with respect to                    AXC         Non-Adjacent      0.951     4.38        <0.001***
participants’ responses in the testing phase (Table 1). The           ACX         Adjacent          0.229     0.89        0.372
responses included both the target artificial language items          XAC         Adjacent          0.25      1.00        0.318
and the foil items. In the regression, subjects were specified
as random effect with no fixed effects. This way, the co-         Sorted by artificial language manipulation type for
efficient of the intercept indicates a comparison with chance     Experiment 1, as compared to the control condition.
(Jaeger, 2008), and we report the co-efficient (β) with the
associated z and p-values.                                          0.6	  
                                                                    0.5	  
    Table 1. Artificial language learning test phase results
                      compared to chance                            0.4	  
                                                                    0.3	                                                      HA	  
            Condition     β       Z      p-value
            AXC           0.82    2.76   0.006 **                   0.2	                                                      LA	  
            ACX           2.14    3.78   <0.001 ***
                                                                    0.1	  
            XAC           0.281   0.99   0.32
            Control       0.637   4.94   <0.001 ***                   0	  
                                                                                AXC	     ACX	      XAC	    control	  
Priming results: RC Completion patterns
                                                              2610

    Figure 1. Proportions of sentence completions in each        condition than in the control condition. We find this result
                  artificial language condition                  that participants reuse the structure from the artificial
                                                                 language to the participants’ native language very similar to
   Since the non-adjacent dependency condition is changing       the phenomenon of syntactic priming, This result has
participants’ performance, we ran more tests to examine the      interesting theoretical implications, as we discuss in the next
patterns of data in this condition closely. Two further          section.
analyses investigate the specific relationship between
participants’ item-level judgment about artificial language                           General Discussion
tests and their tendencies to complete a target sentence with
                                                                 We conducted an experiment where we provided structures
a high attachment continuation. Table 3 (below) details the
                                                                 for people to learn in an artificial language task, and we
numbers of yes/no responses for the artificial language item
                                                                 tested how these structures change the biases in relative
immediately before the completion of the target sentence
                                                                 clause attachment in natural language. In doing so, we
completions.
                                                                 provide the first demonstration that implicit learning of
                                                                 structures changes the bias in relative clause attachment,
  Table 3. Completing high-attachment RC and answering
                                                                 providing empirical evidence for the link between the two
         correctly to the AXC question preceding it.
                                                                 processes, structural learning and sentence production.
                                                                    We used the artificial grammar learning paradigm in this
Response                High attachment       Low attachment     study to induce implicit learning. Different language
Yes (correctly)         105                   96                 learning tasks require different kinds of learning
No                      40                    48                 mechanisms and it is important to choose the right task to
                                                                 induce implicit learning. Unlike learning the meaning of
Table 3 shows this non-existent relationship in the non-         lexical items, which is dependent on the explicit learning
adjacent condition. Fisher’s exact yields p=0.798, ns.           system (Trueswell et al, 2013; Wang & Mintz, in revision),
                                                                 learning grammars from an artificial language stream uses
   Figure 2 demonstrate the relationship at the participant      an implicit learning process (e.g., Ullman 2004). For these
level, correlating general performance on artificial language    reasons, we chose the artificial language learning task that
tasks and the proportion of high attachment completions.         yield abstract structural representations.
Both of these analyses show no apparent relations between           This study allows us to characterize syntactic priming as
the two. We come back to this point in the discussion.           implicit learning using an experimental approach. Previous
                                                                 work (Chang, Dell & Bock, 2006) used a connectionist
                                                                 model to specify how the process of implicit learning
                                                                 happens. In their model, it is assumed that reading sentences
                                                                 of a particular structure changes the weights over that
                                                                 structure such that the bias for that structure increases. This
                                                                 was in turn used to demonstrate, in production, why
                                                                 syntactic priming occurs. This model provides a
                                                                 computational account of how implicit learning happens and
                                                                 how it influences syntactic behaviors. Our approach
                                                                 provides an empirical validation for this computational
                                                                 account, in that we directly measure the result of implicit
      Figure 2. Participant level artificial language task       learning via assessing outcomes of artificial language
  performance and high attachment completion proportions         learning. Our data provide a causal link between implicit
                            per subject.                         learning and syntactic priming. This can explain the
                                                                 presence of syntactic priming only when the artificial
The correlation between (i) correctly remembering specific       language with the combinatorial properties (non-adjacent)
word-level (Ai with Ci) correspondences and (ii) a bias          that are different from default biases (adjacent) which lead
towards producing non-adjacent dependencies is weak (-           to preference for non-adjacent attachment in RC
0.053) and non-significant (p= 0.82).                            completion.
                                                                    Once the structural representation is learned from the
Summary                                                          artificial language, the artificial language tests suggest that it
In this experiment, we studied attachment biases in the          does not matter whether participants are aware of the
completion of relative clause fragments in English. We           particular dependencies at the lexical level. The canonical
observe a main effect of artificial language condition.          way of assessing artificial grammar learning task (asking
Specifically, the non-adjacent dependency condition              yes/no questions for one string at a time) requires explicit
changes the attachment bias significantly. On average,           reflection of whether strings are grammatical or not, which
participants produced 18.6% more high attachment relative        is not the best way to probe implicit representations. Future
clause completions in the non-adjacent artificial language       work should use a more implicit measure of artificial
                                                             2611

language learning to observe more subtle effects. In our data     Hartsuiker, Bernolet, Schoonbaert, Speybroeck &
at least, we observe a zero correlation between the                 Vanderelst (2008). Syntactic priming persists while the
performance in the ‘explicit’ artificial language task and the      lexical boost decays: Evidence from written and spoken
sentence completion task. We take this as an indication that        dialogue. Journal of Memory and Language 58 (2), 214-
the learning of the abstract patterns results in implicit           238.
representations (Fiser & Aslin, 2001; Saffran, Newport,           Jaeger, T. Florian (2008). Categorical Data Analysis: Away
Aslin, Tunick & Barrueco, 1997).                                    from ANOVAs (transformation or not) and towards Logit
  We have a few future directions from this work. We are            Mixed Models. Journal of Memory and Language, 59,
interested in investigating how to assess implicit                  434-446.
representations better and find a correlation between             Melinger, A., & Dobel, C. (2005). Lexically-driven
implicit learning measures with priming. Also, we are               syntactic priming. Cognition, 98(1), B11-B20.
interested in the generalizability of the current finding with    Mitchell, D. C., Cuetos, F., Corley, M. M. B., & Brysbaert,
regard to language (English, in the present study) to a             M. (1995). Exposure-based models of human parsing:
different language. Preliminary work with Spanish suggests          evidence for the use of course-grained (non-lexical)
that the priming effect is present for Spanish speakers as          statistical records. Journal of Psycholinguistic Research,
well. In the Spanish data, we collected data for second             24, 469-488.
language background, confirming that the priming effect is        Mintz, T. H., Wang, F. H., & Li, J. (2014). Word
not a result of sampling bias. Future work with implicit            categorization from distributional information: Frames
learning processes in domains other than language                   confer more than the sum of their (Bigram) parts.
processing are also underway to assess the domain                   Cognitive Psychology, 75, 1-27.
generality of syntactic priming.                                  Pickering, M. J., & Branigan, H. P. (1998). The
                                                                    representation of verbs: Evidence from syntactic priming
                        References                                  in language production. Journal of Memory and
                                                                    Language, 39(4), 633-651.
Bock, J. K. (1986). Syntactic persistence in language             Rohde, H., Levy, R., & Kehler, A. (2011). Anticipating
  production. Cognitive psychology, 18(2), 355-387.                 explanations in relative clause processing. Cognition,
Bock, K. (1989). Closed-class immanence in sentence                 118(3), 339-358.
  production. Cognition, 31, 163–186.                             Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).
Bock, K., & Griffin, Z. M. (2000). The persistence of               Statistical learning by 8-month-old infants. Science,
  structural priming: Transient activation or implicit              274(5294), 1926-1928.
  learning? Journal of Experimental Psychology: General,          Saffran, J. R., Newport, E. L., Aslin, R. N., Tunick, R. A., &
  129, 177-192.                                                     Barrueco, S. (1997). Incidental language learning:
Branigan, H.P., Pickering, M.J. and Cleland, A.A. (2000)            Listening (and learning) out of the corner of your ear.
  Syntactic priming in written production: evidence for             Psychological Science, 8(2), 101-105.
  rapid decay. Psychonomic Bulletin & Review. B13-B25.            Scheepers, C. (2003). Syntactic priming of relative clause
Chang, F., Dell, G. S., & Bock, J. K. (2006). Becoming              attachments: Persistence of structural configuration in
  syntactic. Psychological Review, 113, 234–272.                    sentence production. Cognition, 89(2), 179-205.
Corley, M and Scheepers, C. 2002. Syntactic Priming in            Scheepers, C., Sturt, P, Martin, C.J, Myachykov, A, Teevan,
  English Sentence Production: Categorical and Latency              K, Vizkupova, I. (2011). Structural Priming Across
  Evidence from an Internet-Based Study. Psychonomic                Cognitive Domains: From Simple Arithmetic to Relative-
  Bulletin & Review 9 (1), 126-131.                                 Clause Attachment. Psychological Science 22: 1319-
Cuetos, F., & Mitchell, D. C. (1988). Cross-linguistic              1326.
  differences in parsing: Restrictions on the use of the Late     Thiessen, E. D., Kronstein, A. T., & Hufnagle, D. G. (2013).
  Closure strategy in Spanish. Cognition, 30(1), 73-105.            The extraction and integration framework: A two-process
Fiser, J., & Aslin, R. N. (2001). Unsupervised statistical          account of statistical learning. Psychological Bulletin,
  learning of higher-order spatial structures from visual           139(4), 792-814.
  scenes. Psychological Science, 12(6), 499-504.                  Trueswell, J.C., Medina, T.N., Hafri, A. & Gleitman, L.R.
Gómez, R. L. (2002). Variability and detection of invariant         (2013). Propose but verify: Fast mapping meets cross-
  structure. Psychological Science, 13(5), 431-436.                 situational word learning. Cognitive Psychology, 66 (1),
Gómez, R., & Maye, J. (2005). The developmental                     126-156.
  trajectory of nonadjacent dependency learning. Infancy,         Wang and Mintz (in revision). Characterizing the Difference
  7(2), 183-206.                                                    Between Learning about Adjacent and Non-adjacent
Hartshorne, J. K., & Snedeker, J. (2013). Verb argument             Dependencies.
  structure predicts implicit causality: The advantages of        Ullman, M.T. (2004). Contributions of Memory Circuits to
  finer-grained semantics. Language and Cognitive                   Language: The declarative/procedural model. Cognition,
  Processes, 28(10), 1474-1508.                                     92 (1), 231-270.
                                                              2612

