            The Impact of Granularity on Worked Examples and Problem Solving
                                Guojing Zhou, Thomas W. Price, Collin Lynch, Tiffany Barnes, Min Chi
                                                       Department of Computer Science
                                                        North Carolina State University
                                            {gzhou3,twprice,cflynch,tmbarnes,mchi}@ncsu.edu
                               Abstract                                  loop makes problem or task level decisions, such as decid-
                                                                         ing which problem or example to provide next, while the in-
   In this paper, we explore the impact of two types of instruc-
   tional interventions, worked examples and problem solving, at         ner loop governs step level decisions during problem solving.
   two levels of granularity: problems and steps. This study drew        In the educational literature, the term “step” often refers to
   on an existing Intelligent Tutoring System (ITS) for Probabil-        the application of a major domain principle or equation, such
   ity called Pyrenees and involved 266 students who were ran-
   domly assigned to five conditions. All students experienced           as Newton’s Third Law of Thermodynamics, during problem
   the same procedure, studied the same training problems in the         solving. Solving a whole problem generally involves carry-
   same order, and used the same ITS. The conditions differed            ing out many individual steps in a logical order. Based on
   only in how the training problems were presented. Our re-
   sults show that when the domain content and required steps are        this two-loop structure, we further divide the prior research
   strictly equivalent, different granularities of pedagogical deci-     into two levels of granularity: problem level and step level.
   sions can significantly impact students’ time on task. More           Research on the impact of step level decisions has gener-
   specifically, the fine-grained step level decisions can have a
   stronger pedagogical impact than the problem-level ones.              ally been focused on the impact of faded worked examples
   Keywords: worked example, problem solving, faded worked               (FWEs). FWEs interleave problem solving with step-level
   example, granularity                                                  examples within a problem. In the remainder of this section
                                                                         we will describe prior work on WEs vs. PS at both levels of
                           Introduction                                  granularity and we will focus on two types of outcome mea-
A great deal of research has investigated the different impacts          sures: learning performance and time on task.
of worked examples (WE) and problem solving (PS) on stu-
                                                                         Problem Level Decisions
dent learning (Sweller & Cooper, 1985; McLaren, Lim, &
Koedinger, 2008; McLaren & Isotani, 2011; McLaren, van                   McLaren and colleagues compared problem-level WE-PS
Gog, Ganoe, Yaron, & Karabinos, 2014; Renkl, Atkinson,                   pairs with PS-only (McLaren et al., 2008). Every student was
Maier, & Staley, 2002; Schwonke et al., 2009; Najar, Mitro-              given a total of 10 training problems. Students in the PS-only
vic, & McLaren, 2014; Salden, Aleven, Schwonke, & Renkl,                 condition were required to solve every problem while stu-
2010). In PS students are given tasks to complete either inde-           dents in the WE-PS condition were given 5 example-problem
pendently or with assistance while in WE, students are given             pairs. Each pair consisted of an initial worked example prob-
detailed solutions. When comparing WE to PS, we often                    lem followed by tutored problem solving. They found no sig-
need to control for content. Sweller and Cooper, for exam-               nificant difference in learning performance between the two
ple, compared the learning effects of WE-PS pairs with PS-               conditions, however the WE-PS group spent significantly less
only (Sweller & Cooper, 1985). In the WE-PS condition,                   time than the PS group.
students studied a worked example and then solved a prac-                   McLaren and his colleagues found similar results in two
tice problem. Their results showed that the WE-PS condition              subsequent studies (McLaren & Isotani, 2011; McLaren et
not only learned significantly more but spent significantly less         al., 2014). In the former, the authors compared three condi-
time than the PS-only condition. However, it is possible that            tions: WE, PS and WE-PS pairs, in the domain of high school
the primary benefit of the WE-PS training was that students              chemistry. All students were given 10 identical problems.
received additional domain content that was not given to the             Students in the PS group were required to solve each prob-
PS-only ones. Therefore, in this paper we will focus on re-              lem in an ITS. Students in the WE group viewed them as ex-
search that controlled for learning content across the condi-            amples, and students in the WE-PS group alternated worked
tions.                                                                   examples with problem solving. As before, the authors found
   Several techniques have been employed to control for                  no significant differences among the three groups in terms of
learning content. One approach is to use a tutor such as an In-          learning gains but the WE group spent significantly less time
telligent Tutoring System (ITS). ITSs are generally designed             than the other two conditions; and no significant time on task
to give students on-demand hints, and to give immediate or               difference was found between the PS and WE-PS conditions.
delayed feedback on submitted solutions. In this paper we                   In a follow-up study, conducted in the domain of high
will focus on comparisons between in-tutor WE and tutor-                 school stoichiometry, McLaren and colleagues compared four
assisted PS, and we will explicitly state when this is not the           conditions: WE, tutored PS, untutored PS, and Erroneous Ex-
case.                                                                    amples (McLaren et al., 2014). Students in the Erroneous
   Tutoring in domains such as math and science can be                   Examples condition were given incorrect worked examples
viewed as a two-loop procedure (Vanlehn, 2006). The outer                containing between 1 and 4 errors and were tasked with cor-
                                                                     2817

recting them. Again the authors found no significant differ-         pairs. It has also been shown that the former may require
ences among the conditions in terms of learning gains, and as        significantly less time than either of the latter two.
before the WE students spent significantly less time than the
other groups. More specifically, for time on task they found         Our Approach
that: WE < Erroneous Examples < untutored PS < tutored               In this study, we compared five conditions:
PS. In fact, the WE students took only 30% of the total time
that the tutored PS students did. M = 19.8, SD = 5.8 and            1. Worked Examples (WE): where the tutor guides the stu-
M = 62.4, SD = 17.2 respectively.                                       dent through a complete solution.
   The advantages of worked examples were also demon-
strated in another study in the domain of electrical circuits       2. Problem Solving (PS): where the student is required to
(Van Gog, Kester, & Paas, 2011). The authors of that study              solve each problem with the assistance of an ITS.
compared four conditions: WE, WE-PS pairs, PS-WE pairs
                                                                    3. Faded Worked Examples (FWE): where problem solving
(problem-solving followed by an example problem), and PS
                                                                        steps are interspersed with step-level worked examples.
only. They found that the WE and WE-PS students signifi-
cantly outperformed the other two groups, and found no sig-         4. WE/PS: where students receive both WE and PS problems.
nificant differences was found among four conditions in terms
of time on task.                                                    5. ALL: where students receive WE, FWE and PS problems.
   In short, prior research has shown that problem-level
worked examples can be as or more effective than prob-                  Most of the prior research focused on comparing the ef-
lem solving or alternating problems with examples, and the           fectiveness of two or three conditions. To our knowledge, no
former can take significantly less time than the latter two          prior study has compared all five conditions directly, espe-
(Sweller & Cooper, 1985; McLaren et al., 2008; McLaren               cially WE vs. FWE.
& Isotani, 2011; McLaren et al., 2014; Renkl et al., 2002;              For the WE/PS, FWE and ALL conditions, there are many
Schwonke et al., 2009).                                              ways to make problem-level decisions, such as when to pro-
                                                                     vide a WE, PS or FWE. For FWEs, there are also step-
Step Level Decisions                                                 level decisions, such as whether to provide the next step as
With respect to step level decisions, the results from previ-        a worked example or as a problem solving task. Pedagogical
ous research are mixed. For example, Renkl et al. compared           strategies are policies used to decide the next system action
WE-PS pairs with FWE using a fixed fading policy (Renkl et           when there are multiple actions available.
al., 2002). For FWEs with a fixed fading policy, the study de-          Generally speaking, prior research studying problem-level
signer predefined which steps to give as examples and which          decisions employed fixed pedagogical policies: either WE-
steps to task students with solving. The number of examples          PS (a worked example first followed by problem solving) or
and tasks provided was equal in both conditions. They found          PS-WE. Studies of step-level decisions generally used a fixed
that a FWE with the fixed fading policy significantly outper-        fading policy or an adaptive fading policy. In the former case
formed WE-PS pairs. No significant difference was found              the order of steps was pre-specified and did not adapt to the
between the two groups on time on task.                              students’ learning experience. For adaptive fading policies,
   Schwonke et al. compared FWE with a fixed fading policy           such decisions are made based upon a real time evaluation of
to tutored PS (Schwonke et al., 2009). Over the course of two        the student’s mastery of the subject knowledge. For exam-
studies, they found no significant difference in terms of learn-     ple, a student may be asked to solve a step until he/she has
ing outcomes between the two conditions, however the FWE             demonstrated mastery of the knowledge involved in it. Note
group spent significantly less time than tutored PS group.           that in prior studies both fixed fading policies and adaptive
   Najar and colleagues (Najar et al., 2014) compared FWE            fading policies have been defined by hand-coded rules.
with an adaptive fading policy to WE-PS pairs. They found               We have previously investigated the application of data-
that the FWE condition significantly outperformed the WE-            driven methodologies to induce pedagogical policies directly
PS condition in terms of their learning outcomes and the for-        from student-system interaction data (Chi, Jordan, & Van-
mer also spent significantly less time on task than the latter.      Lehn, 2014; M. Chi, VanLehn, Litman, & Jordan, 2012,
   Finally, Salden et al. compared three conditions: FWE             2011). In those studies we applied Reinforcement Learn-
with a fixed fading policy, FWE with an adaptive fading pol-         ing (RL) to induce the policies directly from an exploratory
icy, and PS-only (Salden et al., 2010). With respect to learn-       corpus. The exploratory corpus was collected by having the
ing outcomes, they found that FWE with the adaptive fading           ITS make random decisions when interacting with students.
policy outperformed FWE with the fixed fading policy, which          In our prior work (M. Chi et al., 2012, 2011), we used the
in turn outperformed PS-only. They found no significant time         induced pedagogical policies to decide when to provide an
on task differences among the groups.                                example step and when to require students to solve it them-
   In short, for step-level worked examples, while the results       selves. We found that when students were all given the same
have been generally mixed, it has been shown that FWE with           FWEs, RL-induced policies significantly improved students’
effective fading policies can outperform either PS or WE-PS          learning gains compared to poor pedagogical policies and
                                                                 2818

random decisions. On the other hand, we also found that stu-
dents can still learn from these FWEs even with poor poli-
cies. This was likely due to the content exposure and avail-
able practice opportunities. In post-hoc comparisons, differ-
ent versions of “poor" faded policies were compared, and no
significant difference was found between them either in terms
of learning outcomes or time on task.
   In this study, we will investigate the impact of pedagogi-
cal policies on learning across two different granularities of
decisions. For the purposes of this study we used a random
pedagogical policy on both problem-level and step-level deci-
sions. By making random decisions, we expect the number of
example steps to be equivalent among the FWE, WE/PS, and
ALL conditions. We are interested in investigating the impact
                                                                                     Figure 1: The Pyrenees tutor’s interface.
of random pedagogical decisions on student learning across
FWE, WE/PS, and ALL conditions, and how they will differ
from the WE and PS-only groups. Therefore that content will               significant differences among five groups: χ2 (4, N = 266) =
be strictly controlled to be the same across conditions.                  4.12, p = 0.39.
   We will examine students’ performance on a pre- and post-
test, as well as their time on task. In light of prior research,          Probability Tutor
we expect that there will be no significant learning difference
among the five conditions, since the system is making ran-                The ITS involved in this study is called Pyrenees, a web-
dom decisions on the WE/PS, FWE and ALL conditions. For                   based ITS for probability. Pyrenees teaches students 10 major
time on task, given the number of steps that students need to             principles of probability, such as the Complement Theorem
complete, we expect: W E < W E/PS = FW E = ALL < PS.                      and Bayes’ Rule. Prior studies have shown that Pyrenees
                                                                          is effective and have compared it to Andes, another well-
                              Methods                                     evaluated ITS (Vanlehn et al., 2005). Pyrenees has outper-
                                                                          formed Andes in both physics (VanLehn et al., 2004) and
Participants                                                              probability (Chi & Vanlehn, 2007; Chi & VanLehn, 2007).
The study was conducted in two sections of the Discrete                   This improvement was observed in part because Pyrenees
Mathematics for Computer Science course offered at North                  teaches students domain-general problem-solving strategies,
Carolina State University in the Fall of 2014. 266 under-                 which draw students’ attention to the conditions under which
graduate students were assigned to complete the task as one               each domain principle is applicable. The differences were
of their regular homework assignments during the last two                 apparent on all types of test problems: simple/complex prob-
weeks of the class.                                                       lems and isomorphic/non-isomorphic problems, and the ef-
                                                                          fects were large, with Cohen’s d=1.17 for overall post-test
Conditions                                                                scores.
The participants were randomly distributed into five condi-                  Figure 1 shows the interface of Pyrenees, which is divided
tions. We used balanced random assignment stratified by                   into multiple windows. In the dialog window, Pyrenees can
course section and performance on a prior class exam. The                 provide messages to the student, such as explaining a worked
group sizes were as follows: N = 31 for WE1 , N = 58 for                  example step, or prompting them to complete the next step.
WE/PS, N = 59 for FWE, N = 59 for ALL, and N = 59 for                     The student can enter responses below such as writing an
PS.                                                                       equation or giving the answer to a multiple-choice question.
   Due in part to a holiday break, preparations for final exams,          Any variables or equations that are defined through this pro-
and length of the experiment, only 163 students completed                 cess are displayed on left side of the screen for reference.
the experiment. Four students were excluded from our subse-               Once students submit an answer, Pyrenees provides immedi-
quent analysis because they performed perfectly on the prob-              ate feedback on whether or not it was correct.
ability pre-test. The remaining 159 students were distributed                In addition to providing immediate feedback, Pyrenees
as follows: N = 21 for WE, N = 38 for WE/PS, N = 37 for                   can also provide on-demand hints, either explaining what is
FWE, N = 34 for ALL, and N = 29 for PS.                                   wrong with an incorrect step or prompting the student with
   We performed a χ2 test of independence to examine the                  what they should do next. Because Pyrenees requires stu-
relation between completion rate and condition. We found no               dents to follow the Target Variable Strategy, it knows exactly
                                                                          what step the student should be doing next, so it gives spe-
    1 Note that a smaller portion of students were assigned to the WE
                                                                          cific hints. In Pyrenees, help was provided via a sequence
condition. This is because another purpose of this study was to col-
lect exploratory data in order to apply RL to induce adaptive peda-       of increasingly specific hints. The last hint in the sequence,
gogical policies.                                                         the bottom-out hint, tells the student exactly what to do. For
                                                                      2819

this study, Pyrenees had three basic modes. In the WE or PS           would get a score of 0.8. The One-point-per-principle rubric
modes, each step was performed either by the tutor or student         in turn gave a point for each correct principle application. All
throughout the problem. In the FWE mode, there was a 50%              of the tests were graded in a double-blind manner by a single
chance at each step for either the student or the tutor to solve      experienced grader. The results presented below were based
the step.                                                             upon the partial-credit rubric but the same results hold for the
                                                                      other two. For comparison purposes, all test scores were nor-
Procedure                                                             malized to the range of [0,1].
The study was organized into four phases: 1) pre-training, 2)
pre-test, 3) training on Pyrenees, and 4) post-test.                                               Results
    During pre-training, all students studied the domain prin-        The conditions were balanced in terms of students’ incoming
ciples through a probability textbook. They read a general            competence. Prior to the intervention in Phase 3 we found no
description of each principle, reviewed some examples of it,          significant differences among the five conditions according to
and solved some single- and multiple-principle problems. Af-          a range of measures. These measures include (1) the probabil-
ter solving each problem, the student’s answer was marked             ity pre-test with respect to students’ test scores on three types
in green if it was correct and red if incorrect. They were            of problems: single-principle, multiple-principle, and overall
also shown an expert solution at the same time. If the stu-           across all 3 scoring rubrics; and (2) the students’ performance
dents failed to solve a single-principle problem then they were       during probability pre-training on all three types of problems.
asked to solve an isomorphic one; this process was repeated           Thus, despite attrition, the conditions remained balanced in
until they either failed three times or succeeded once. The           terms of incoming competence. We will now compare stu-
students had only one chance to solve each multiple-principle         dents’ learning performance in the post-test and training time
problem and were not asked to solve an isomorphic problem             across the five conditions. We discuss each comparison in
if their answer was incorrect.                                        turn.
    The students then took a pre-test which contained 14 prob-
lems. They were not given feedback on their answers, nor              Learning Performance
were they allowed to go back to earlier questions, (this was          A repeated measures analysis using test type (pre-test vs. iso-
also true of the post-test).                                          morphic post-test) as a factor and test score as the dependent
    During phase 3, students in all five conditions received the      measure showed that there was a main effect for test type
same 12 problems in the same order on Pyrenees. Each main             F(4, 154) = 118.59, p < 0.0001. On the isomorphic ques-
domain principle was applied at least twice. The minimal              tions, all five groups of students scored significantly higher on
number of steps needed to solve each training problem ranged          the post-test than on the pre-test, F(1, 20) = 8.75, p < 0.009
from 20 to 50. Such steps included variable definitions, prin-        for WE, F(1, 37) = 25.66, p < 0.001 for WE/PS, F(1, 36) =
ciple applications, and equation solving. The number of do-           29.34, p < 0.001 for FWE, F(1, 33) = 20.61, p < 0.001 for
main principles required to solve each problem ranged from            ALL, and F(1, 28) = 55.04, p < 0.001 for PS. Therefore all
3 to 11. The problems were given as PS, WE or FWE, based              five conditions made significant gains from pre- to post-test.
upon the students’ experimental condition. All students could         This suggests that the basic practices and problems, domain
access the corresponding pre-training textbook.                       exposure, and interactivity of Pyrenees might help students
    Finally, all students took a post-test which had 20 prob-         to learn even when the problem- and step-level decisions are
lems in total. 14 of the problems were isomorphic to the              made randomly.
pre-test problems given in phase 2. The remainder were non-              Table 1 compares the pre-test, isomorphic post-test and
isomorphic multiple-principle problems.                               overall post-test scores among the five conditions. The sec-
    The only procedural differences among the five conditions         ond column in Table 1 lists the number of students in each
occurred within Pyrenees when the system chose whether to             condition who completed the study. The third, fourth, and
provide a worked example problem, example step, or to re-             fifth columns list the mean and SD for the pre-test, isomor-
quire the student to engage in problem-solving. Apart from            phic post-test (14 isomorphic questions), and overall post-test
this behavioral difference the system was identical for each          scores. Overall, no significant differences were found among
student.
Grading criteria
                                                                                    Table 1: Test scores across conditions.
The test problems required students to derive an answer by
writing and solving one or more equations. We used three                Cond        # Stud    pre-test      Iso Post      Overall Post
scoring rubrics: binary, partial credit, and one-point-per-             WE          21        .687(.160)    .789(.187)    .650(.197)
principle. Under the binary rubric, a solution was worth 1              WE/PS       38        .658(.165)    .774(.130)    .630(.167)
point if it was completely correct or 0 if not. Under the partial       FWE         37        .625(.134)    .736(.159)    .588(.145)
credit rubric, each problem score was defined by the propor-            ALL         34        .664(.181)    .803(.136)    .651(.159)
tion of correct principle applications evident in the solution.         PS          29        .618(.155)    .802(.118)    .645(.139)
A student who correctly applied 4 of 5 possible principles
                                                                  2820

the five conditions on any of the learning outcome mea-                              Discussion and Conclusion
sures: F(4, 154) = 0.871, p = 0.483 (pre-test), F(4, 154) =
                                                                      In this study, we used an ITS called Pyrenees to compare five
1.25, p = 0.29 for (isomorphic post-test questions); and
                                                                      tutorial conditions: WE, PS, FWE, WE/PS, and ALL. For the
F(4, 154) = 0.98, p = 0.42 (overall post-test).
                                                                      WE/PS, FWE, ALL conditions, the tutor used a random pol-
   We also compared the adjusted post-test and NLG scores             icy to decide when to give students a worked example prob-
across all five conditions. The adjusted post-test scores were        lem (or example step) or to ask them to solve the problem
compared via an ANCOVA with the corresponding pre-test                (or step). Our results showed that all five conditions learned
score used as a covariate. The NLG score measures the stu-            significantly after training on Pyrenees, and no significant dif-
dents’ learning gains irrespective of their incoming compe-           ference was found on all of our learning measures including
tence: NLG = post−pre
                 1−pre . Here 1 is the maximum score. Again,          the pre-test, isomorphic post-test, and overall post-test scores.
no significant difference was found among the conditions.                This happened despite the fact that the pedagogical strate-
                                                                      gies employed for the WE/PS, FWE, and ALL conditions
Training Time                                                         were random and thus were rather ineffective. They did not
                                                                      adapt to the students and thus may not have been able to make
Table 2 shows the average amount of total training time (in           a positive impact on students’ performance beyond the base-
minutes) students spent on Pyrenees for each condition. A             line provided by content exposure. Here the basic practices
one-way ANOVA showed significant differences among the                and problems, domain exposure, and interactivity of Pyrenees
five groups: F(4, 154) = 26.91, p = 0.000.                            set a minimum bar for students’ learning that the pedagogical
   Subsequent pairwise t-tests showed that the WE condition           strategies, however poor, could not undercut. This lack of a
spent significantly less time than the others: t(57) = −5.22,         significant difference among the five conditions supports our
p < 0.001, d = 1.33 (WE/PS); t(56) = −6.22, p < 0.001, d =            hypothesis and is consistent with results from prior studies
1.95 (FWE); t(53) = −6.26, p < 0.001, d = 1.70 (ALL); and             (M. Chi et al., 2012, 2011).
t(48) = −8.93, p < 0.001, d = 2.55 (PS).                                 Previously, we found that students’ learning performance
   Similarly, we found that the WE/PS condition spent signif-         could be improved by employing effective pedagogical strate-
icantly less time than FWE, ALL and PS conditions: t(73) =            gies (M. Chi et al., 2012, 2011). However, in that study no
−2.77, p < 0.008, d = 0.64 (FWE); t(70) = −2.49, p <                  significant difference was found in terms of time on task be-
0.016, d = 0.58 (ALL); t(65) = −6.96, p < 0.001, d = 1.67             tween the students trained on the system with effective peda-
(PS) respectively.                                                    gogical policies and those with ineffective pedagogical poli-
                                                                      cies. In this study, we showed that different granularities of
   Finally, while we found no significant time on task differ-
                                                                      pedagogical decisions can make a significant difference in
ences between the FWE and ALL conditions, (t(69) = 0.395,
                                                                      students’ time on task.
p = .69, d = 0.09). They both took significantly less time than
the PS condition: t(64) = −3.60, p = .001, d = 0.89 (FWE);               Much of the prior research has shown that WE can be as
t(61) = −4.14, p < .001, d = 1.04 (ALL) respectively.                 effective as tutored PS but the former often take significantly
                                                                      less time than the latter. One potential explanation for this
   Overall, with respect to time on task. we found that: W E <        time difference is that the students in the PS condition have to
W E/PS < FW E = ALL < PS. In fact, the WE group only                  do more work. Given that the same amount of work was ex-
took around 43% as much training time as FWE and 32%                  pected for students in the WE/PS, FWE, and ALL conditions,
as much as PS but reached the same learning gains as other            we hypothesized that: W E/PS = FW E = ALL. However, our
conditions.                                                           results suggest that for time on task, W E/PS < FW E = ALL.
   Finally, we conducted a one-way ANCOVA to determine if             WE/PS spent significantly less time than both FWE and ALL.
there was any statistically significant differences among the            There are many possible explanations for why the FWE
five groups on their overall post-test scores. We used both the       group took longer time than WE/PS group. Since both
pre-test score and total training time as covariates; no signifi-     WE/PS and FWE groups get the same random decisions, we
cant difference was found: F(4, 152) = 1.18, p = 0.32.                hypothesize that the granularity of the decision must there-
                                                                      fore play an important role. Solving a problem in domains
                                                                      such as probability consists of applying domain principles in
                                                                      a valid logical order. Students’ later steps are directly de-
              Table 2: Time on task per condition.
                                                                      pendant upon what they have done previously. This partial
           Cond       # Student     Time (in minutes)                 dependence may force students in the FWE condition to pay
           WE         21            47.96 (39.27)                     more attention to not only tutor-solved steps but also what
           WE/PS      38            92.23 (25.79)                     their own steps.
           FWE        37            112.80 (37.50)                       Additionally, Pyrenees’ instructional methods may explain
           ALL        34            109.48 (32.85)                    some of the extra time taken by the FWE condition compared
           PS         29            146.40 (37.88)                    with WE/PS condition. If the tutor solves a problem in a
                                                                      way that is unexpected to the student, the student will require
                                                                  2821

extra time to process the tutor’s intentions and continue its         research. In Proceedings of the 30th annual conference of
progress. These tutor-solved steps may act as constraints on          the cognitive science society (pp. 2176–2181).
the student’s problem solving process. There are many pos-          McLaren, B. M., van Gog, T., Ganoe, C., Yaron, D., & Kara-
sible strategies for solving a problem, and Pyrenees uses one         binos, M. (2014). Exploring the assistance dilemma: Com-
specific strategy which may not be intuitive for the student.         paring instructional support in examples and problems. In
Thus these solved steps may lead students onto a different so-        Intelligent tutoring systems (pp. 354–361).
lution path which is outside of their expectations. We are cur-     Najar, A. S., Mitrovic, A., & McLaren, B. M. (2014). Adap-
rently in the process of analyzing our log files to determine         tive support versus alternating worked examples and tu-
why this occurred. Why did the same random pedagogical                tored problems: Which leads to better learning? In User
policy improve efficiency when applied at the problem level           modeling, adaptation, and personalization (pp. 171–182).
more than at the step level?                                          Springer.
   Our results from this study suggested that step-level de-        M. Chi, VanLehn, K., Litman, D. J., & Jordan, P. W. (2011).
cisions are more sensitive to ineffective pedagogical strate-         Empirically evaluating the application of reinforcement
gies than problem level decisions. With random decisions,             learning to the induction of effective and adaptive pedagog-
the FWE group not only failed to learn more than WE/PS,               ical strategies. User Model. User-Adapt. Interact., 21(1-2),
they also spent significantly more time.                              137-180.
   Overall, this study suggests that different granularities        M. Chi, VanLehn, K., Litman, D. J., & Jordan, P. W. (2012).
of pedagogical decisions can have a significant impact on             An evaluation of pedagogical tutorial tactics for a natural
students’ time on task. The fine-grained interaction steps can        language tutoring system: A reinforcement learning ap-
have a strong pedagogical impact. Our ultimate goal is to             proach. International Journal of Artificial Intelligence in
apply RL to induce effective pedagogical policies, at both the        Education..
problem and step levels, directly from our dataset. This raises     Renkl, A., Atkinson, R. K., Maier, U. H., & Staley, R. (2002).
an interesting question: with effective pedagogical strategies,       From example study to problem solving: Smooth transi-
will there be a difference in time on task and learning among         tions help learning. The Journal of Experimental Educa-
the five conditions? This is an promising question for future         tion, 70(4), 293–315.
research.                                                           Salden, R. J., Aleven, V., Schwonke, R., & Renkl, A. (2010).
                                                                      The expertise reversal effect and worked examples in tu-
Acknowledgements                                                      tored problem solving. Instructional Science, 38(3), 289–
This work is supported by the National Science Foundation             307.
award #1432156. We would also like to thank the anonymous           Schwonke, R., Renkl, A., Krieg, C., Wittwer, J., Aleven, V.,
reviewers for their valuable feedback.                                & Salden, R. (2009). The worked-example effect: Not an
                                                                      artefact of lousy control conditions. Computers in Human
                          References                                  Behavior, 25(2), 258–266.
                                                                    Sweller, J., & Cooper, G. A. (1985). The use of worked
Chi, M., Jordan, P. W., & VanLehn, K. (2014). When                    examples as a substitute for problem solving in learning
  is tutorial dialogue more effective than step-based                 algebra. Cognition and Instruction, 2(1), 59–89.
  tutoring?      In Intelligent tutoring systems - 12th inter-      Van Gog, T., Kester, L., & Paas, F. (2011). Effects of worked
  national conference, ITS 2014, honolulu, hi, usa, june              examples, example-problem, and problem-example pairs
  5-9, 2014. proceedings (pp. 210–219). Retrieved from                on novices’ learning. Contemporary Educational Psychol-
  http://dx.doi.org/10.1007/978-3-319-07221-02 5                      ogy, 36(3), 212–218.
  doi: 10.1007/978-3-319-07221-02 5                                 Vanlehn, K. (2006). The behavior of tutoring systems. In-
Chi, M., & Vanlehn, K. (2007). Accelerated future learn-              ternational journal of artificial intelligence in education,
  ing via explicit instruction of a problem solving strategy.         16(3), 227–265.
  FRONTIERS IN ARTIFICIAL INTELLIGENCE AND AP-                      VanLehn, K., Bhembe, D., Chi, M., Lynch, C., Schulze, K.,
  PLICATIONS, 158, 409.                                               Shelby, R., . . . Wintersgill, M. (2004). Implicit versus
Chi, M., & VanLehn, K. (2007). The impact of explicit strat-          explicit learning of strategies in a non-procedural cognitive
  egy instruction on problem-solving behaviors across intel-          skill. In Intelligent tutoring systems (pp. 521–530).
  ligent tutoring systems. In Proceedings of the 29th annual        Vanlehn, K., Lynch, C., Schulze, K., Shapiro, J. A., Shelby,
  conference of the cognitive science society, nashville, ten-        R., Taylor, L., . . . Wintersgill, M. (2005). The andes
  nessee (pp. 167–172).                                               physics tutoring system: Lessons learned. International
McLaren, B. M., & Isotani, S. (2011). When is it best to              Journal of Artificial Intelligence in Education, 15(3), 147–
  learn with all worked examples? In Artificial intelligence          204.
  in education (pp. 222–229).
McLaren, B. M., Lim, S.-J., & Koedinger, K. R. (2008).
  When and how often should worked examples be given to
  students? new results and a summary of the current state of
                                                                2822

