                 Why do you ask? Good questions provoke informative answers.
                     Robert X. D. Hawkins, Andreas Stuhlmüller, Judith Degen, Noah D. Goodman
                                               {rxdh,astu,jdegen,ngoodman}@stanford.edu
                                                Department of Psychology, 450 Serra Mall
                                                          Stanford, CA 94305 USA
                              Abstract                                   “where are you?” that permit answers at many levels of ab-
                                                                         straction (Potts, 2012). While most of this work has focused
   What makes a question useful? What makes an answer appro-             on answerer behavior, it suggests that the question itself is
   priate? In this paper, we formulate a family of increasingly
   sophisticated models of question-answer behavior within the           important in prompting a relevant answer.
   Rational Speech Act framework. We compare these models                   Recent work on Rational Speech Act (RSA) models (Frank
   based on three different pieces of evidence: first, we demon-
   strate how our answerer models capture a classic effect in psy-       & Goodman, 2012; Goodman & Stuhlmüller, 2013) has
   cholinguistics showing that an answerer’s level of informative-       mathematically formalized pragmatic language understand-
   ness varies with the inferred questioner goal, while keeping          ing as a form of recursive Bayesian inference, where listeners
   the question constant. Second, we jointly test the questioner
   and answerer components of our model based on empirical ev-           reason about speakers who choose utterances that maximize
   idence from a question-answer reasoning game. Third, we ex-           information gained by an imagined listener. In this paper
   amine a special case of this game to further distinguish among        we extend the RSA framework to address simple question-
   the questioner models. We find that sophisticated pragmatic
   reasoning is needed to account for some of the data. People           answer dialogs. The immediate challenge in doing so is that
   can use questions to provide cues to the answerer about their         the speaker utility in RSA is based on direct information pro-
   interest, and can select answers that are informative about in-       vided by an utterance—since questions don’t provide direct
   ferred interests.
                                                                         information, we must say what utility they do have.
   Keywords: language understanding; pragmatics; Bayesian                   We suggest, following Van Rooy (2003), that the value of
   models; questions; answers
                                                                         a question is the extent to which it can be expected to elicit
                                                                         information relevant to the questioner later in the dialogue.
                          Introduction                                   More specifically, for the questioner, the value of a question
   Q:“Are you gonna eat that?” A:“Go ahead.”                             is the expected information gained about her interests, given
                                                                         the set of likely answers it may provoke. This diverges from
In this (real life) example, Q strategically chooses a question          regular RSA in that the value of a question depends on infor-
that differs from her true interest, avoiding an impolite ques-          mation gained by the speaker (rather than listener), and that
tion, yet manages to signal to A what her interests are; A in            this information comes later in the (very short) conversation.
turn reasons beyond the overt question and provides an an-                  To fully specify this questioner we need a model of the
swer that addresses Q’s interests. This subtle interplay raises          answerer, which can serve as both the model assumed by a
two questions for formal models of language: What makes a                questioner, and as a model of answer behavior itself. We ex-
question useful? What makes an answer appropriate?                       plore three, increasingly sophisticated, answerer models. The
   A number of studies in psycholinguistics have provided                simplest answerer provides a literal answer to the question
evidence that answerers are both sensitive to a questioner’s             (without attempting to be informative); the explicit answerer
goals and attempt to be informative with respect to those                attempts to be informative with respect to the explicit ques-
goals. For instance, in the classic study of Clark (1979), re-           tion asked (without inferring the questioner’s underlying in-
searchers called liquor merchants and opened the conversa-               terests); the pragmatic answerer infers the most likely true
tion with one of two sentences to set context: “I want to buy            interests of the questioner, and then informatively addresses
some bourbon” (the uninformative condition) or “I’ve got $5              those interests. The latter model extends RSA to reason about
to spend” (the five dollar condition). They then asked, “Does            the topic of conversation, as proposed by Kao, Wu, Bergen,
a fifth of Jim Beam cost more than $5?” Merchants gave a lit-            and Goodman (2014) to explain hyperbole; it goes beyond
eral yes/no answer significantly more often in the latter condi-         previous work by using the explicit question as a (potentially
tion than the former, where an exact price was more common.              indirect) cue to this topic.
   When provided with the five dollar context, the merchant                 The rest of this paper is structured as follows. First, we lay
inferred that the questioner’s goal was literally to find out            out the details of our question-answer models. We show that
whether or not they could afford the whiskey, hence a sim-               the pragmatic answerer model can select different answers
ple ‘yes’ sufficed. In the uninformative context, however, the           to a question depending on context, as in Clark (1979), de-
merchant inferred that the questioner’s goal was just to buy             scribed above. We then use a communication game paradigm
whiskey, so the exact price was the most relevant response               that allows us to manipulate goals, potential questions, and
(Clark, 1979). Context and questioner goals have also been               potential answers, testing the predictions of the different
implicated in accounts of answers to identification questions            models. We close with a brief discussion of related models
like “who is X?” (Boër & Lycan, 1975), and to questions like            and future directions.
                                                                     878

  A Rational Speech Act model of question and                                  We next describe three different answerer models; the
                      answer behavior                                       questioner could assume any one of them, leading to three
                                                                            corresponding versions of the questioner model. All answer-
How should a questioner choose between questions? We start
                                                                            ers take a question q ∈ Q and a true world state w∗ ∈ W as
by assuming that the questioner aims to learn information rel-
                                                                            input and return a distribution over answers a ∈ A . The lit-
evant to a private goal. In order to choose a question that re-
                                                                            eral answerer simply chooses answers by trading off prior
sults in useful information, the questioner reasons about how
                                                                            answer probability and how well a question-answer pair con-
the answerer would respond, given different possible states of
                                                                            veys the true state of the world to an interpreter:
the world; she selects a question that results in an answer that
tends to provide goal-relevant information.                                                   P(a|q, w∗ ) ∝ P(a)P(w∗ |q, a)
    More formally, suppose there is a set of world states W ,
a set of possible goals G , a set of possible questions Q ,                 For a fixed question, this is equivalent to the speaker in pre-
and a set of possible answers A . These sets are taken to                   vious RSA models. The question enters only in specifying
be in common ground between the questioner and the an-                      the literal meaning of an answer. The explicit answerer ad-
swerer. An informational goal g ∈ G is a projection func-                   ditionally evaluates answers with respect to how well they
tion that maps a world state to a particular feature or set of              address the explicit question q:
features that the questioner cares about; this is similar to the
notion of a question-under-discussion (Roberts, 1996). We                                     P(a|q, w∗ ) ∝ P(a)Pq (w∗ |q, a)
will use the notation Pg (w) to indicate the probability P̂(g(w))
of the g-relevant
         R
                   aspect of w under the projected distribution                The pragmatic answerer also evaluates answers with re-
P̂(v) = W δv=g(w) P(w)dw.                                                   spect to how well they address the informational goal, but
    The questioner takes a goal g ∈ G as input and returns a                doesn’t take the question’s explicit meaning at face value. In-
distribution over questions q ∈ Q :                                         stead, the pragmatic answerer reasons about which goals g are
                                             ∗ ) k P (w))                   likely given that a question q was asked, and chooses answers
           P(q|g) ∝ eEP(w∗ ) [DKL (Pg (w|q,w        g    ]−C(q)
                                                                            that are good on average:
It trades off the cost of asking a question, C(q), and expected                         P(a|q, w∗ ) ∝ p(a)
information gain. The cost likely depends on question length,
                                                                                                            ∑ P(g|q)Pg (w∗ |q, a)
                                                                                                           g∈G
among other factors. Information gain is measured as the
Kullback-Leibler divergence between the prior distribution                  Reasoning backwards from questions to goals is a simple
over g-relevant worlds, Pg (w), and the posterior distribution              Bayesian inversion of the (explicit) questioner using a prior
one would expect after asking a question q whose answer re-                 on goals:
flected true world state w∗ :                                                                     P(g|q) ∝ P(q|g)P(g)
            Pg (w|q, w∗ ) =   ∑ Pg (w|q, a)P(a|q, w∗ )                         For all of the questioner and answerer models, we can vary
                             a∈A                                            how strongly optimizing they are—that is, to what extent they
This distribution has two components: First, it depends on                  are sampling from the distributions defined above, and to
P(a|q, w∗ ), a model of the answerer which we will explore                  what extent they deterministically choose the most likely ele-
shortly. Second, it depends on (the goal projection of)                     ment. For any such distribution over utterances, we introduce
P(w|q, a), an ‘interpreter’ that specifies the likelihood as-               an optimality parameter α and transform it by P0 (x) ∝ P(x)α .
signed to different worlds given question and answer pairs.                    This concludes our specification of the model space, giv-
    To define the interpreter function, which all agents use to             ing a set of three answerers and three corresponding ques-
compute the literal interpretation of a question-answer pair,               tioners that reason about them. We have implemented these
we must assign questions a semantic meaning. We assume                      models in WebPPL, a probabilistic programming language
that a question is an informational goal that projects from                 (Goodman & Stuhlmüller, electronic). The model predictions
worlds to the answer set A . This is equivalent to the more                 shown throughout the rest of the paper are computed using
common partition semantics of Groenendijk and Stokhof                       this implementation.
(1984), as can be seen by considering the pre-image of such
a projection; an answer picks out an element of the partition
                                                                                         Whiskey pricing: a case study
via q−1 (a). The interpreter constrains the prior on worlds to              Our model can provide different—sometimes over- or under-
the subset of its support that is consistent with the semantics             informative—answers to the same explicit question, depend-
of a question-answer pair1 :                                                ing on context. To illustrate, we model Clark’s (1979)
                                                                            whiskey study. Recall that liquor merchants were more likely
                    P(w|q, a) ∝ P(w)δq(w)=a                                 to give over-informative answers (specifying exact price) to
    1 We should also have a semantic evaluation function that maps          the question “Does a fifth of Jim Beam cost more than $5?”
an answer utterance to its value in A . For clarity we assume this is a     in the uninformative context (“I want to buy some bourbon”)
trivial mapping and suppress it.                                            than in the five dollar context (“I’ve got $5 to spend”).
                                                                        879

   Our world state is a pair of the whiskey’s price ($1, $2, . . . ,
$10) and a Boolean indicating whether the merchant takes                                                     animal
credit cards. There are three possible goals: learning the price
of whiskey, learning whether the price is greater than $5, and                                        pet
learning whether the merchant takes credit cards. Note that
the credit card question was not in the original study, but re-                              dog
flects the important fact that there exist alternative reasons for
calling a liquor store aside from price-related questions. The
set of answers includes exact prices as well as “yes” and “no”,                        d1           d2                    b1
with lower cost for “yes” and “no” than the price statements.
   We model the context sentence as affecting the answerer’s
goal prior. We assume that there is a fixed 40% probability
of the credit card goal, with the remaining 60% split between            Figure 1: Stimulus hierarchy used in Exp. 1. The goal space
the two price-related goals. When the context is “I’d like to            and answer space contained the four leaves. The question
buy some whiskey,” we assume that the split is even. When it             space, however, was restricted to the highlighted nodes, pro-
is “I only have $5 to spend,” we assume that it is 9:1 in favor          ceeding up the hierarchy, allowing for indirect questions.
of learning whether the price is greater than $5.
Results When the question is “Do you take credit cards?”,                question, chosen from a restricted set of options, and the an-
the pragmatic answerer prefers to give the accurate Boolean              swerer responded by revealing the object behind a single gate.
answer (with probability .76 and .78, weakly depending on                This restriction was motivated by one of the key features of
context), with no preferential treatment for any of the numeric          our opening example: when the most direct question (“can I
answers. When the question is “Does Jim Beam cost more                   eat your food?”) is suppressed due to politeness, utterance
than $5?”, the correct Boolean answer is still the most proba-           length, complexity, or some other intervening factor, ques-
ble choice, but more weakly (at probability .44 and .49). Crit-          tioners must rely instead on an indirect question.
ically, there is a context-dependence for answers to this ques-
                                                                            This set of restricted options was critical to distinguishing
tion: when prefaced with “I’d like to buy some whiskey.”, the
                                                                         between the pragmatic and explicit variants of our model. If
correct exact price answer is favored more strongly (at proba-
                                                                         all questions were equally available, both our ‘explicit’ and
bility .18) than when the context is “I only have $5 to spend.”
                                                                         ‘pragmatic’ questioner models would prefer the most direct
(probability .11). By contrast, the explicit answerer (which
                                                                         one. To see how they make different predictions in the pres-
has no natural way to account for context) does not make dif-
                                                                         ence of restrictions, suppose ‘poodle?’ was not available the
ferential predictions in the two situations.
                                                                         questioner. If the questioner asked about a ‘dog?’, the poo-
   This suggests that our pragmatic answerer is consistent
                                                                         dle and dalmatian would be considered equally good options
with human behavior in psychologically interesting situa-
                                                                         by an explicit answerer because they are both dogs. How-
tions, passing a first, qualitative, test. However, we have not
                                                                         ever, the pragmatic answerer could reason that if the ques-
yet shown that the questioner behavior matches that of hu-
                                                                         tioner was truly interested in the location of the dalmatian, he
mans. Indeed, the questioner has been largely neglected in
                                                                         would have asked about the dalmatian. Because he didn’t, he
studies of answering (but see, e.g., Potts, 2012), even though,
                                                                         must be interested in the other valid response that he lacks a
as our opening example illustrates, the choice of question is
                                                                         direct question for: the poodle.
important for understanding answers. In the next section we
introduce an experimental paradigm that allows us to jointly             Participants We recruited 125 participants from Amazon’s
explore quantitative behavior of both questioners and answer-            Mechanical Turk to participate in this task. Eleven partici-
ers.                                                                     pants were excluded due to self-reported confusion about the
                                                                         task instructions or due to being non-native English speakers.
   Exp. 1: Hierarchical questions and answers                            Stimuli & Procedure In terms of our model specification,
In order to simultaneously test how questioners choose ques-             the world space W was the set of 4! = 24 possible assign-
tions when faced with a particular goal and how answerers re-            ments of four objects to four gates. The goal space G was the
spond under uncertainty about this goal, we used a guessing-             set of four objects that the questioner could be trying to find
game task played by two players: a questioner and an an-                 (the leaves of the tree in Fig. 1). The answer space A was the
swerer. In this game, 4 animals (a dalmatian, a poodle, a                set of four gates that the answerer could reveal. The restricted
cat, and a whale) were hidden behind 4 gates. These ani-                 question space Q contained the set of highlighted nodes in the
mals corresponded to different levels in a class hierarchy (see          hierarchy: ‘dalmatian?’, ‘dog?’, ‘pet?’, and ‘animal?’.
Fig. 1). The questioner received a private goal of finding one              Each participant provided responses for four trials in the
of the objects (e.g. ‘find the poodle’), and the answerer (but           role of the questioner (corresponding to the four goals), and
not the questioner) knew the location of each object. Before             four trials in the role of the answerer (corresponding to the
choosing a gate, the questioner asked the answerer a single              four possible questions). In the questioner block, players
                                                                     880

                                 Pragmatic_Questioner                                                                                 Pragmatic_Answerer
                      goal: dalmatian                          goal: poodle                                             utterance: dalmatian                             utterance: dog
                                                                                                                 1.00
               0.8                                                                                               0.75
                                                                                                                 0.50
               0.4
                                                                                                                 0.25
               0.0                                                                                               0.00                                                                                             src
                                                                                                            prob
                                                                                           src
            prob
                                                                                                                             utterance: pet                            utterance: animal                             empirical
                     goal: siamese cat                              goal: whale               empirical          1.00
                                                                                              model                                                                                                                  model
                                                                                                                 0.75
               0.8
                                                                                                                 0.50
               0.4
                                                                                                                 0.25
               0.0                                                                                               0.00
                     dalmatian                          dalmatian                                                         dalmatian             siamese cat            dalmatian            siamese cat
                                  dog   pet    animal                 dog   pet   animal                                               poodle                  whale               poodle                 whale
                                              response                                                                                                        response
Figure 2: Exp. 1 results, compared with the predictions of the best-performing model for questioner (left) and answerer (right).
The explicit and pragmatic questioner models do not make different predictions in this task, but the pragmatic answerer better
accounts for the qualitative patterns in the response data than the explicit answerer.
were presented with a private goal from G , like “find the                                                      and about the whale when asked about an ‘animal’,
poodle!” and were prompted to select a question from a                                                          χ2 (3) = 121, p < .001. Note that, under an explicit interpre-
drop-down menu containing elements of Q that would best                                                         tation of the question, revealing the dalmatian and the poo-
help them find it. In the answerer block, players were shown                                                    dle would both be perfectly acceptable answers to a question
which items were behind which gates and were told that the                                                      about a ‘dog’, but answerers strongly prefer to give the lo-
other player had asked a particular question from Q . They                                                      cation of the poodle. In the next section, we compare these
were prompted to select a gate from a drop-down menu that                                                       results to the predictions of our family of models (Fig. 3).
would be most helpful for the questioner, keeping in mind his                                                   Model comparison Each model was run with uniform prior
or her constraints. (To minimize learning effects, question-                                                    probability over worlds, goals, questions, and answers, and
ers did not receive answers and neither role saw the outcome                                                    with equal cost for all utterances. For each model, a single
of the game.) In order to collect responses for all elements                                                    optimality parameter, which applied to all agents as described
of G and Q , the order of the questioner and answerer blocks                                                    above, was fit to maximize correlation with the data.
was randomly assigned for each participant, and the order of
                                                                                                                   We can rule out both the literal answerer and literal ques-
stimuli within these blocks was also randomized2 .
                                                                                                                tioner. The literal answerer yields a uniform distribution over
Results Results for the questioner role are shown along-                                                        the four answers. This has consequences for the correspond-
side model predictions in Fig. 2 (left). We find that ques-                                                     ing literal questioner model: when this questioner reasons
tioners systematically prefer to ask different questions given                                                  about which question would generate the most helpful answer
different goals, even as those questions become more indi-                                                      from the literal answerer, it finds no differences in response
rect. χ2 tests over each of the four response distributions                                                     probabilities, and therefore has no preference for which ques-
show a significant divergence from uniform. Questioners                                                         tion to ask. The predictions of these model, plotted against
preferentially ask about the ‘dalmatian’ given the dalmatian                                                    our empirical results, are shown in the left-hand column of
goal, χ2 (3) = 137, p < .001, about the ‘dog’ given the poo-                                                    Fig. 3.
dle goal, χ2 (3) = 152, p < .001, about the ‘pet’ given the
                                                                                                                   The two remaining questioner models make roughly the
cat goal, χ2 (3) = 120, p < .001, and about the ‘animal’ when
                                                                                                                same predictions for this task, and we are not able to distin-
given the whale goal, χ2 (3) = 150, p < .001.
                                                                                                                guish them on the basis of these data. We found a model-data
   Results for the answerer role are shown in Fig. 2 (right).                                                   correlation of r = 0.96 for the explicit questioner and corre-
Answerers are highly sensitive to the constraints of the ques-                                                  lation of r = 0.99 for the pragmatic questioner. Although the
tioner, giving information about the dalmatian when asked                                                       pragmatic model has a slightly better fit, the two models only
about a ‘dalmatian’, χ2 (3) = 281, p < .001, about the poo-                                                     differ slightly in the magnitude of predictions, not in qualita-
dle when asked about a ‘dog’, χ2 (3) = 137, p < .001, about                                                     tively important ways such as the rank ordering of response.
the cat when asked about a ‘pet’, χ2 (3) = 57, p < .001,                                                        The pragmatic questioner model’s predictions for each re-
   2 The experiment is online at http://cocolab.stanford.edu/                                                   sponse distribution are shown in Fig. 2 (left). Although the
cogsci2015/Q and A/experiment1/experiment1.html                                                                 magnitude of its predictions are not in perfect alignment with
                                                                                                          881

                                                                                                                                              sented above. Ten participants were excluded on the basis of
                                                         Questioners                                                                          having a non-English native language, or reporting confusion
                                         lit                         explicit                              pragmatic                          about the instructions.
                        1.00
                                                                                                                                              Stimuli & Procedure The procedure was the same as be-
                        0.75
                                                                                                                                              fore with some changes to the stimuli. The world space W
                                     ●                                                 ●●                                        ●●
                                     ●
                                     ●                                             ●        ●                                    ●●
                        0.50                                                                                                                  consisted of possible assignments of the three pets to three
                                                                                                                                              gates. The possible goals G were the dalmatian and poodle
Empirical probability
                        0.25                   r = NA                         r = 0.96                          r = 0.99
                                     ●
                                     ●
                                     ●
                                     ●
                                     ●
                                     ●
                                                         ●
                                                          ●● ●
                                                         ● ●
                                                                 ●
                                                                                                ●
                                                                                                ●
                                                                                                ●
                                                                                                ●
                                                                                                ●
                                                                                                 ●
                                                                                                                                              (not the cat). The possible questions G were ‘dalmatian?’ or
                                     ●
                                     ●                   ●●                                     ●
                                                                                                ●
                                                                                                ●
                        0.00
                                     ●
                                     ●
                                     ●                   ● ●●                                   ●
                                                                                                ●
                                                                                                ●
                                                                                                                                              ‘cat?’. The possible answers A were the three gates. Each
                                                                                                                                              participant was given the two goals in a random order3 .
                                                              Answerers
                                         lit                         explicit                              pragmatic                          Results When the goal was to find the dalmatian, partici-
                        1.00         ●                                                      ●                                ●
                                                                                                                                              pants were significantly more likely to ask about the dalma-
                        0.75         ●                           ●       ●                                           ●       ●
                                                                                                                                              tian than the cat, χ2 (1) = 12, p < 0.001. When the goal was
                                     ●                               ●                                                   ●                    to find the poodle, participants were marginally more likely to
                        0.50
                                                                                                                                              ask about the cat than the dalmatian, χ2 (1) = 3.6, p = 0.058.
                        0.25         ●
                                     ●
                                     ●
                                               r = NA              ●
                                                                 ● ●
                                                                         ●
                                                                               r = 0.8          ●
                                                                                                ●
                                                                                                       ●
                                                                                                           ●
                                                                                                                r = 0.95                      When looking only at the first of the two trials, the dalmatian
                                                                                                                                              result held, χ2 (1) = 14.4, p < 0.001, but participants’ prefer-
                                     ●
                                     ●                    ●      ●                              ● ●
                                     ●                           ●                                ●
                                     ●                   ●
                                                         ●●                                     ●● ●
                        0.00         ●                    ●                                        ●
                               0.0        0.5
                                                        1.0
                                                                             0.5
                                                                                            1.0
                                                                                                               0.5                1.0
                                                                                                                                              ence for asking about the cat disappeared, χ2 (1) = 0.07, p =
                                                        0.0                                 0.0
                                                Model predicted probability                                                                   0.79. These results are shown in Fig. 4.
                                                                                                                                              Model comparison The explicit questioner predicts that
Figure 3: Full space of models, and their correlations with the
                                                                                                                                              participants should have no preference for a question given
data from Exp. 1. Questioner models in the first row reason
                                                                                                                                              the ‘poodle’ goal, since an explicit answerer would be equally
about the answerers directly below them, and the pragmatic
                                                                                                                                              unlikely to give the desired answer for both. The pragmatic
answerer reasons about the explicit questioner.
                                                                                                                                              questioner model, however, predicts that participants should
                                                                                                                                              prefer to ask about the cat. This is because the (internal) prag-
the magnitude of the empirical data (because it is strongly                                                                                   matic answerer would reason that if the questioner was inter-
optimizing), it captures most of the interesting qualitative pat-                                                                             ested in the dalmatian, they would ask about the dalmatian; if
terns of the data, particularly the modal responses.                                                                                          they didn’t, they must be interested in the other possible goal.
   The pragmatic answerer provides a much better fit to the                                                                                      It is again unclear which questioner model is best. Overall,
data than the explicit answerer: a model-data correlation of                                                                                  the response distribution matches the predictions of the prag-
r = 0.8 for the explicit answerer and r = 0.95 for the prag-                                                                                  matic model: questioners prefer to ask about the cat. How-
matic answerer. Only the pragmatic answerer can account                                                                                       ever, participants don’t show this behavior if we look at only
for essential qualitative features of the response data. For                                                                                  the first trial. This could be due to a number of reasons. In-
example, the explicit answerer predicts that participants will                                                                                terestingly, the pragmatic model predicts a more explicit-like
be equally likely to show the ‘dalmatian,’ ‘poodle,’ and ‘cat’                                                                                response distribution if the questioner does not take into ac-
when asked about a pet. Instead, the data show a significant                                                                                  count the constraint on possible goals: if participants thought
preference for revealing the cat, leaving ‘dalmatian’ and ‘poo-                                                                               the poodle was the only goal (counter to the instructions),
dle’ at the same level as the other alternative. The pragmatic                                                                                then asking about the dog would be consistent with the prag-
answerer correctly predicts this pattern (see Fig. 2 (right)).                                                                                matic model as well. It is possible that participants only
Even more dramatically, the explicit answerer predicts a uni-                                                                                 fully-processed the alternative (dalmatian) goal if they had
form distribution over responses to the ‘animal?’ question.                                                                                   first done the trial where that was the goal.
However, the empirical distribution was significantly differ-
ent from uniform. Thus, the pragmatic answerer is necessary
                                                                                                                                                                 General discussion
to account for these data.
   These data provide strong evidence for a pragmatic an-                                                                                     Perhaps the most important formal advance of the models
swerer, but are more equivocal with respect to the explicit                                                                                   considered here is to move the Rational Speech Act frame-
and pragmatic questioner. Because the two models did not                                                                                      work beyond interpretation of single utterances (in context),
make significantly different predictions for this experiment                                                                                  to consider the dynamics of simple dialogs (albeit consist-
(and both work quite well), we ran a follow-up study on a                                                                                     ing of a single question and its answer). Doing so requires
special case of the guessing-game paradigm in which the ex-                                                                                   replacing the immediate motive to convey true information
plicit and pragmatic questioners make different predictions.                                                                                  with the more distant motive to provoke useful information
                                                                                                                                              from one’s interlocutor. On the answerer side, sophisticated
            Exp. 2: A Critical Test of Questioner Models
Participants We recruited 50 participants to participate                                                                                         3 The experiment is online at http://cocolab.stanford.edu/
only in the questioner scenario of the guessing game pre-                                                                                     cogsci2015/Q and A/experiment2/experiment2.html
                                                                                                                                        882

              Exp 2 Results (Pooled)                               Exp 2 Results (split)                              & Moll, 2005). Given simple motion cues, for example, we
                 goal: dalmatian goal: poodle                      goal: dalmatian   goal: poodle
                                                            1.00                                                      are able to reliably discern high-level goals such as chas-
          0.75
                                                            0.75                                                      ing, fighting, courting, or playing (Barrett, Todd, Miller, &
 Proportion                                        Proportion
          0.50                                                                                       trial
                                                                                                                      Blythe, 2005; Heider & Simmel, 1944). Experiments in
                                                            0.50                                       first
                                                                                                       second         psycholinguistics have shown that this expertise extends to
          0.25                                              0.25                                                      speech acts. Behind every question lies a goal or intention.
          0.00                                              0.00
                                                                                                                      This could be an intention to obtain an explicit piece of infor-
                   cat dalmatian   cat dalmatian                     cat dalmatian   cat dalmatian                    mation (“Where can I get a newspaper?”), signal some com-
                          response                                          response
                                                                                                                      mon ground (“Did you see the game last night?”), test the an-
Figure 4: The overall response distribution in Exp. 2 (left)                                                          swerer’s knowledge (“If I add these numbers together, what
and the same distribution split into first- and second-trial data                                                     do I get?”), politely request the audience to take some ac-
(right).                                                                                                              tion (“Could you pass the salt?”), or just to make open-ended
                                                                                                                      small talk (“How was your weekend?”). These wildly dif-
inference was required to account for the implicit interests                                                          ferent intentions seem to warrant different kinds of answers.
of the questioner. This provides a useful connection to cur-                                                          By formalizing the computational process by which answer-
rent game-theoretic and decision-theoretic models (Vogel,                                                             ers infer these different intentions, our model framework pro-
Bodoia, Potts, & Jurafsky, 2013; Van Rooy, 2003), which                                                               vides a unifying way to accommodate this diversity.
also emphasize the importance of goals and speaker beliefs
in communication but emphasize less the complex interplay                                                                                 Acknowledgements
of inference between questioner and answerer.                                                                         This work was supported by ONR grants N00014-13-1-0788 and
                                                                                                                      N00014-13-1-0287, and a James S. McDonnell Foundation Scholar
   We have presented evidence that answerer behavior is best                                                          Award to NDG. RXDH was supported by the National Science
described by a pragmatic model that does reason about ques-                                                           Foundation Graduate Research Fellowship under Grant No. DGE-
tioner intentions, using the question utterance as a signal.                                                          114747.
The superiority of pragmatic answerer predictions over the
other answerer models was robust. Questioner behavior in
                                                                                                                                                References
                                                                                                                      Barrett, H. C., Todd, P. M., Miller, G. F., & Blythe, P. W. (2005).
Exp. 2, however, seemed to be much more dependent on                                                                    Accurate judgments of intention from motion cues alone: A cross-
experience. In another version of Exp. 1, we did not em-                                                                cultural study. Evolution and Human Behavior, 26(4), 313–331.
phasize certain aspects of the game in the instructions, such                                                         Boër, S. E., & Lycan, W. G. (1975). Knowing who. Philosophical
                                                                                                                        Studies, 28(5), 299–344.
as the fact that the answerer knows about the restricted an-                                                          Clark, H. H. (1979). Responding to indirect speech acts. Cognitive
swer set, which might prompt perspective-taking. Our data                                                               psychology, 11(4), 430–477.
in this pilot experiment appeared to contain a mixture of ex-                                                         Frank, M. C., & Goodman, N. D. (2012). Predicting pragmatic
                                                                                                                        reasoning in language games. Science, 336, 998.
plicit and pragmatic answerers and questioners (though other                                                          Goodman, N. D., & Stuhlmüller, A. (2013). Knowledge and im-
confounds were present in this version). Overall, it will be                                                            plicature: Modeling language understanding as social cognition.
important to explore the mixture of explicit- and pragmatic-                                                            Topics in cognitive science, 5(1), 173–184.
                                                                                                                      Goodman, N. D., & Stuhlmüller, A. (electronic). The design and im-
questioning across a larger range of situations: these issues                                                           plementation of probabilistic programming languages. Retrieved
may be a product of our artificial game paradigm, or they may                                                           2015/1/16, from http://dippl.org
be reflective of real tendencies in language use, raising novel                                                       Groenendijk, J., & Stokhof, M. (1984). On the semantics of ques-
                                                                                                                        tions and the pragmatics of answers. Varieties of formal seman-
questions about audience design in question-answer behavior.                                                            tics, 3, 143–170.
   While the artificiality of our question-answer game may                                                            Heider, F., & Simmel, M. (1944). An experimental study of apparent
distance the behavior of participants from the natural use of                                                           behavior. The American Journal of Psychology, 243–259.
                                                                                                                      Kao, J. T., Wu, J. Y., Bergen, L., & Goodman, N. D. (2014). Nonlit-
language, there are also some benefits to this design. In par-                                                          eral understanding of number words. Proceedings of the National
ticular, it is easy in this setting to control the exact space                                                          Academy of Sciences, 111(33), 12002–12007.
of questions, goals, and answers. While the restrictions on                                                           Potts, C. (2012). Goal-driven answers in the cards dialogue cor-
                                                                                                                        pus. In Proceedings of the 30th west coast conference on formal
question space may seem peculiar, it is directly motivated by                                                           linguistics (pp. 1–20).
conversational scenarios in everyday usage which feature re-                                                          Roberts, C. (1996). Information structure in discourse: Towards
strictions on the set of things one can ask about, due to polite-                                                       an integrated formal theory of pragmatics. Working Papers in
                                                                                                                        Linguistics-Ohio State University Department of Linguistics, 91–
ness, salience, time cost, and other factors. In future work, we                                                        136.
will explore the extent to which the proposed model can scale                                                         Tomasello, M., Carpenter, M., Call, J., Behne, T., & Moll, H. (2005).
up to real-time, multiplayer games, extended dialogues, and                                                             Understanding and sharing intentions: The origins of cultural
                                                                                                                        cognition. Behavioral and brain sciences, 28(05), 675–691.
other more naturalistic language settings. To deal with dia-                                                          Van Rooy, R. (2003). Questioning to resolve decision problems.
logues lasting longer than a single exchange, for instance, we                                                          Linguistics and Philosophy, 26(6), 727–763.
must specify the way in which the contributions of questioner                                                         Vogel, A., Bodoia, M., Potts, C., & Jurafsky, D. (2013). Emer-
                                                                                                                        gence of gricean maxims from multi-agent decision theory. In
and answerer affect the context in which later utterances op-                                                           Human language technologies: The 2013 annual conference of
erate.                                                                                                                  the north american chapter of the association for computational
   Humans are experts at inferring the intentions of other                                                              linguistics (pp. 1072–1081). Stroudsburg, PA: Association for
                                                                                                                        Computational Linguistics.
agents from their actions (Tomasello, Carpenter, Call, Behne,
                                                                                                                883

