   The naïve utility calculus: Joint inferences about the costs and rewards of actions
       Julian Jara-Ettinger (jjara@mit.edu), Laura E. Schulz (lschulz@mit.edu) & Joshua B. Tenenbaum
                                                            (jbt@mit.edu)
                                             Department of Brain and Cognitive Sciences
                                Massachusetts Institute of Technology, Cambridge, MA 02139 USA
                             Abstract                                   actions (e.g., walk left, right, etc). With this formulation, it
   The understanding that agents have goals, and the ability to
                                                                        is possible to determine the sequence of actions that
   infer them, is fundamental in social cognition. However,             maximize an agent’s utility as efficiently as possible. Using
   much of our social understanding goes beyond goal                    MDPs as a model for how agents act, goal inference can be
   attribution. Drawing on both behavioral studies throughout           formalized as inferring the unobservable utility function that
   development, and on the limitations of past models, we               is guiding the agent’s actions. These models predict with
   propose that humans have a naïve utility calculus to reason          high quantitative accuracy how adults infer goals in simple
   about the costs and rewards underlying agents’ goals. We             scenarios (Baker, et. al., 2009; 2011; Jara-Ettinger et al.,
   show that the naïve utility calculus model, embedded in a
   Bayesian framework, can jointly infer the costs and rewards          2012).
   of agents navigating in complex scenarios. Using this model
   we test humans’ ability to make quantitative cost-reward             Social reasoning beyond goal attribution
   inferences in scenarios with various sources of costs and               Despite the success of these models, the power of these
   rewards. Our results suggest the naïve utility calculus model        inferences is limited.
   fits human inferences better than simple goal inference
   models.                                                                Explanatory limitations To illustrate why, consider a
                                                                        simple example. A man is walking and reaches a fork on the
   Keywords: Bayesian modeling; Inverse planning; Naïve                 road. The left path leads to a lake where he can swim, and
   Utility Calculus; Social Cognition; Theory of Mind                   the right path leads to his house. The man stops for a second
                                                                        and then takes the right path. The man’s goal is immediately
                         Introduction                                   revealed after his first step, as he’s taking an efficient path
Understanding that agents move to complete goals is at the              towards his house and an inefficient path towards the lake.
heart of our social abilities and already at work in infancy            However, this inference only tells us what the man is trying
(Woodward, Sommerville, & Guajardo, 2001). In addition                  to achieve, but not why. The man may be going home
to knowing that agents have goals, we also have                         because he doesn’t like swimming, because he cannot swim,
expectations about how agents complete them.                            because he’s too tired, or too hungry.
Developmental evidence suggests that humans expect                         Models that infer the utility function will treat all the
agents to act efficiently (Scott & Baillargeon, 2013; Gergely           above explanations as being roughly equivalent, as they all
& Csibra, 2003). This assumption, known as the principle of             reduce to a utility function with a higher value for being
efficiency, enables humans to infer unobservable goals from             home than for going swimming. Intuitively, however, each
observable behavior. The logic of this inference can be                 statement tells us more about the man’s psychological state
described and formalized using Bayesian inference, where                and provides some insight into why swimming had a low
the probability that an agent has goal G given that they took           utility. That is, rather than only reasoning about high
actions A is given by                                                   utilities and associating them with goals, we are also
                                                                        sensitive to the costs and rewards underlying these utilities.
                     p(G | A) ∝ L(A | G)p(G).                   (1)
                                                                           Predictive limitations Following on the past example,
Here, L(A | G) is the likelihood that the agent would take              after the man arrives to his house, the predictive power of
actions A if she had goal G, and p(G) is the prior belief               goal inference vanishes. We don’t know what the man will
                                                                        do next, or even if he will have the same goal in the future.
that the agent goal G. The principle of efficiency determines           However, each explanation above boosts our predictive
the likelihood function: The more efficiently the actions A             power. Knowing the costs and rewards underlying the
complete the goal G, the higher their likelihood (And                   man’s goal allows us to reason about how his utilities may
therefore the higher the posterior probability that the agent           change over time. A tired man might choose to go
has that goal).                                                         swimming after taking a nap; an incompetent swimmer will
  This kind of inference, called inverse planning, was                  not.
formally modeled by Baker, Saxe, & Tenenbaum (2009),
using Markov Decision Processes (MDPs). In the MDP                         Inferential limitations Desires might be in direct conflict
framework, the environment is modeled as a set of states,               with each other (e.g., wanting to a cookie and wanting to
each with an associated utility (that can be positive or                lose weight), they might be too costly to obtain (e.g., buying
negative), which the agent can navigate by taking different             a new car), or we may not know how to complete them
                                                                    974

(e.g., wanting world peace) (Moses, 2003). As such, agents                                U(S, A) = R(S) − C(A)                     (2)
have to compromise and tradeoff their true desires to choose
a goal. Therefore, goals aren’t always aligned with agents’          The higher a goal’s utility, the more likely the agent will
true preferences. This makes it critical to distinguish              pursue it. Despite the simplicity, decomposing utilities into
between high utility states (what an agent wants to do at the        costs and rewards has powerful implications. Plans with
moment) and high reward states (what an agent intrinsically          high rewards and medium costs (e.g., doing something
likes). If your friend buys coffee next door you won’t infer         because you truly want it) are now different from plans with
that she likes it better than the coffee sold across town, but       low rewards but even lower costs (e.g., doing something
if she goes all the way across town, you’ll be confident she         simply because it is convenient). Conversely, plans with low
likes it better than the coffee from the local shop.                 rewards and medium costs (e.g., foregoing something
                                                                     because you don’t want it) are now different from plans
  Practical limitations Standard goal attribution accounts           with high rewards and even higher costs (e.g., foregoing
assume that costs are identical for all agents. However, this        something because it’s too costly). However, the exact costs
is not the case. Consider this common scenario: Anne and             for different actions and the rewards for reaching different
Bob arrive to check-in at the airport and find that the entry        states vary across agents and are partially unobservable.
is an empty zigzag pathway. Anne, who is six-years-old,              Thus, for an observer to have the advantage of representing
takes her most efficient path towards the counter: ducking           an agent’s costs and rewards, they need to be able to infer
under the divisions. At the same time, Bob, who is 6’ tall,          them.
takes his most efficient path towards the counter, by                  Despite the qualitative evidence for a naïve utility calculus
zigzagging through the path. If we assumed that both agents          early in development (Jara-Ettinger et al., 2014; 2015), the
were acting efficiently with respect to the same objective           exact nature of these inferences, and the precision to which
costs we might infer that Bob is changing his goal at every          humans can make them, are open questions.
bend in the zigzag path. Thus, to infer goals we need to
understand that costs vary across agents, and we need to be                         Computational framework
able to infer them.
                                                                     To test people’s ability to jointly infer an agent’s costs and
                 The naïve utility calculus                          rewards, we implemented the naïve utility calculus model
   In light of these limitations, our intuitive theory must also     and a main alternative basic goal inference model (based on
include some understanding of how costs and rewards                  Baker, et. al., 2009). In addition, to get better insight into
jointly influence people’s behavior. Recent developmental            how each difference between the two models affects the
evidence suggest that we assume that agents estimate the             cost-reward inferences, we implemented three additional
costs and rewards associated with a goal, and chose what to          intermediate models.
do based on the difference of these two values: the utility.1
   Preschoolers understand that costs and rewards vary               Naïve Utility Calculus model sketch
across agents, and that these two determine the agent’s
                                                                     This model is a direct extension of past goal-inference
utility, and thus their goals. Using this understanding, five-
                                                                     models (Baker, et al., 2009). However, rather than inferring
and six-year-olds can use knowledge about an agent’s costs
                                                                     the agent’s utility function, we take the inference further and
to infer their rewards, and, conversely, knowledge about an
                                                                     decompose the utility function into the underlying costs and
agent’s rewards to infer their costs (Jara-Ettinger, Gweon,
                                                                     rewards. This joint cost-reward inference can be seamlessly
Tenenbaum, & Schulz, 2015). At an even earlier age, two
                                                                     adapted into the inverse planning framework, where the
year-olds can estimate an agent’s motivation to help using
                                                                     probability that an agent who took actions A has cost
information about their costs (Jara-Ettinger, Tenenbaum, &
                                                                     function C and reward function R is given by Bayes’ rule:
Schulz,2015): When a competent and an incompetent agent
refuse to help, toddlers infer that the competent agent was
more likely to be unmotivated.                                                       p(C, R | A) ∝ L(A | C, R)p(C, R) .             (3)
   Intuitively, cost-reward tradeoffs happen in our everyday
lives. We want to call our relatives but postpone it for weeks       Here, the likelihood that the agent takes actions A given
because we don’t have time; we want to go to that nice               their costs and rewards C and R is determined by the
restaurant downtown but end up going to the less desirable           resulting utility function (Equation 2). That is, this model
one near our house because it’s closer, and we skip the best         performs Bayesian inference over a generative planning
rides at theme parks because were not up for waiting in line.        model (formalized as a Markov Decision Process; See
Formally, the utility for taking a sequence of actions A to          Baker, et al., 2009 for a detailed explanation of inverse
reach state S is given by                                            planning through MDPs) by combining the cost and reward
                                                                     function to generate the utility function. Critically, the
                                                                     model understands that costs depend on the type of action
                                                                     (some actions are more costly than others) and on the agent
   1
     These types of models have been extensively studied as a        (different agents incur different costs), and, similarly, that
theory for how humans produce behavior (Gilboa, 2010), but less
                                                                 975

the rewards depend on the outcome (some outcomes are                 a)                b)    Naïve Utility
                                                                                               Calculus
                                                                                                                    Pure goal
                                                                                                                    inference        To illustrate how the
more rewarding than others) and on the agent (different                                    5
                                                                                           4
                                                                                              Cost inference
                                                                                                              1.00
                                                                                                                    Cost inference
                                                                                                                                    naïve utility calculus
agents place different rewards on the outcomes).                                                                                    model and the simple
                                                                                                              0.75
                                                                                           3
                                                                                                              0.50
                                                                                           2
                                                                                                              0.25
                                                                                                                                    goal-inference model
                                                                                           1
                                                                                           0                  0.00
                                                                                             Straight Curved       Straight Curved
  Simple goal inference alternative model As the main                                     15
                                                                                             Reward inference
                                                                                                                10
                                                                                                                   Reward inference
                                                                                                                                    differ, consider the
alternative we implemented a simple goal-inference model                                                                            sample path shown in
                                                                                          10
                                                                                           5                     5
based on Baker, et al., (2009). Like the naïve utility calculus                            0
                                                                                              Straight Curved
                                                                                                                 0
                                                                                                                   Straight Curved  Figure 1a. An agent is
                                                                                              Goal prediction       Goal prediction
model, this model infers the unobservable utility function.                             1.00
                                                                                        0.75
                                                                                                              1.00
                                                                                                              0.75
                                                                                                                                    travelling from south
However, rather than inferring an agent’s costs, it assumes                             0.50
                                                                                        0.25
                                                                                                              0.50
                                                                                                              0.25                  to north, where he can
that all agents incur the same costs, independent of the                                0.00
                                                                                             Straight Curved
                                                                                                              0.00
                                                                                                                   Straight Curved  pick up either, or
action they take. Thus, this model is unable to infer agents’       Figure 1. a) An agent moves from south to                       both, of the fruits.
                                                                    north towards two fruits. In the orange
costs functions or to use them to infer the magnitude of the        path, the agent moved in a straight line,
                                                                                                                                    The terrain consists of
rewards.                                                            while in the black path the agent                               dense     jungle    (in
                                                                    circumvented the water. b) naïve utility                        green), water (in
Intermediate accounts                                               calculus and simple goal inferences. Bars                       blue), and mountains
                                                                    are color coded in accordance with the
  Competence inference model This model extends the                 map.
                                                                                                                                    (in brown). Figure 1b
simple goal inference alternative model by allowing the                                                                             shows       the    two
costs to vary across agents. That is, this model assumes that       model’s inferences for two potential paths. In the straight
agents incur a fixed cost for taking any action. However, it        path (orange line) the agent travelled up north in a straight
allows different agents to have different cost constants (their     line, crossing the water. In the curved path (black line), the
competence). As such, it understands that some agents may           agent travelled up north circumventing the water. As the top
forego a high reward if the costs they would have to incur          row shows (Figure 1b), for the naïve utility calculus model,
are too high. The difference between this model and the             the straight path implies that the agent doesn’t mind
simple goal inference model quantifies the advantage an             crossing water, and the curved path implies that he dislikes
observer obtains by understanding that some agents are              water. In contrast, the simple goal-inference model is unable
broadly more competent than others.                                 to consider these differences. The second row shows each
                                                                    model’s inferred reward functions. When the agent takes a
  Motivation inference model This model is the                      straight path, both models infer that he probably likes both
complement of the competence inference model. As in the             fruits. However, when the agent takes the curved path, the
naïve utility calculus model, this model assumes that the           naïve utility calculus model now infers that the agent prefers
cost for travelling depends on both the specific agent and          grapes, while the simple goal inference model does not.
the specific terrain. However, rather than inferring a              This is consistent with the predictions about the agent’s
separate reward value for each object, this model assumes           future actions (last row). Once again, the simple goal-
that all objects have a constant reward value. Nevertheless,        inference model makes similar predictions for both paths. In
the model allows this value to vary across agents.                  contrast, the naïve utility calculus model infers that the
Intuitively, the model attempts to explain agents’ behavior         agent is more likely to pick up the grapes when it observes
by inferring their full cost function, and an overall level of      the curved path, but not when it observes the straight path.
motivation to complete goals. This model allows us to test if       Although simple, this example highlights how joint cost-
people’s inferences can be explained by simply considering          reward inferences help overcome the limitations raised in
an agent’s overall motivation to navigate the world and the         the past section. The naïve utility calculus can infer why the
cost they incur for navigating different types of terrains.         agent circumvented the water, and it can use this knowledge
                                                                    to predict what the agent will do next. In contrast, the pure
  Competence-motivation inference model This last                   goal-inference model interprets all actions as attempts to
model assumes that agents’ behavior is determined by two            reach the fruits through the shortest possible path.
parameters: their overall competence and motivation. That
is, the model assumes that each agent incurs a cost c                                                   Experiment
whenever it takes an action (regardless of the terrain) and             To test people’s ability to perform precise cost-reward
obtains a reward r whenever it collects an object (regardless       inferences, we designed a simple experiment where
of which object it collects). Although these two values are         participants were asked to infer the abilities and preferences
fixed for each agent, the model infers their specific value for     of different agents navigating a grid world (as a static
different agents. This model, compared with the naïve utility       image) with three types of terrains and two types of objects.
calculus model enables us to quantify the inferential gain
from giving the cost and reward functions more flexibility          Design
by allowing them to vary as a function of the objects and the       The stimuli consisted of an 8x6 grid world with jungle,
terrains.                                                           water, and mud (See Figure 2 for examples). Each stimulus
                                                                    contained the agent’s starting point (which could be any of
                                                                    the four red squares shown in the examples in Figure 2), the
                                                                976

end point (always located in the top left spot), two targets        times in the object condition. Participants first completed a
(located in any of the three possible locations shown in            tutorial and a brief questionnaire to ensure they understood
Figure 2; the apple and grape images were randomized                the task. Participants who responded one or more question
across trials), and the agent’s path. To generate the test          incorrectly were automatically redirected to the beginning of
stimulus we first ran 12,000 simulations (1,000 in each of          the tutorial. Participants who responded all questions
the 12 possible worlds) of agents with random costs and             correctly were given access to the test stage. In each trial,
rewards navigating the world (Cost and reward values were           participants saw a test path on the left side of the screen
sampled from exponential distributions with parameters 0.1          (See Figure 2 for examples; all images were static) and five
and 10, respectively; these parameters were set qualitatively       slidebars on the right side of the screen. The first three
to ensure the simulations produced a wide range of paths).          slidebars asked about the agent’s ability to navigate through
These simulations generated 189 unique paths. To reduce             each type of terrain (ranging from “Extremely exhausting”
the stimuli size we first calculated each path’s recoverability     to “Extremely easy”, with “average” in the middle) and the
score, defined as the residual sum of squares (RSS) between         last two slidebars asked about the agent’s strength of
the true parameters and the parameters inferred through             preference for each fruit, or about their motivation to help
Bayesian inference over the generative model (taking the            each stranded agent, depending on the condition (ranging
posterior’s expected value). Thus, paths with low                   from “Not at all” to “A lot” with no text in the middle).
recoverability indices had enough information for a rational
observer to infer the underlying costs and rewards. Next, we        Results
calculated a discrepancy score for each alternative model,
defined as the RSS between the naïve utility calculus
predictions and the alternative model’s predictions. Stimuli
were reduced by removing all paths with a recoverability
index greater than one, and then by selecting the 30 paths
with the highest discrepancy score for each alternative
model. The resulting 120 paths (30 for each of the four               2.5
                                                                        2
alternative models) reduced to 42 paths after removing                1.5
                                                                        1
                                                                      0.5
duplicates. These 42 paths were thus ensured to contain                 0
                                                                     −0.5
enough information for observers to be able to make cost              −1
                                                                     −1.5
reward inferences (because they had a low recoverability
index), and a high likelihood of helping us disambiguate
between models (because they had a high discrepancy
score). For each of the 42 paths we created an object
version, where the map contained two fruits the protagonist           2.5
could collect (See Figure 2), and a social version, where the
                                                                        2
                                                                      1.5
                                                                        1
map contained two agents the protagonist could help (The              0.5
                                                                        0
stimuli was otherwise identical). This allows us to test if          −0.5
                                                                      −1
                                                                     −1.5
humans make different cost-reward inferences when
reasoning about social (helping someone) and non-social
goals (collecting food). For instance, humans may infer a
separate reward for each outcome in non-social goals (as the
naïve utility calculus model does), but only an overall level         2.5
of prosociality when reasoning about social goals (as the               2
                                                                      1.5
                                                                                                                                        Average          Starting
                                                                                                                                        human judgments  points
motivation inference model does).                                       1
                                                                      0.5                                                               Model prediction
                                                                                                                                                         Target
                                                                                                                                                         locations
                                                                        0
                                                                     −0.5
                                                                      −1
Participants                                                         −1.5
                                                                          Mud Jungle Water Grapes Apples Mud Jungle Water Grapes Apples
80 U.S. residents (as determined by their IP address) were          Figure 2. Example stimuli showing different starting points, object
recruited and tested through Amazon’s Mechanical Turk               arrangements, and paths. Grey bars show average human judgments (z-
platform (Mean age = 38.59 years. Min=19 years, max=68              scored per participant) with 95% confidence intervals. Teal bars show
                                                                    naïve utility calculus predictions.
years).
                                                                    As predicted, participants’ average judgments were highly
Procedure
                                                                    similar in the social and the object conditions (r=0.95; 95%
Participants were randomly assigned to the object (N=40             CI: 0.93-0.97)2, suggesting that people use the same type of
participants) or the social (N=40 participants) condition. In       reasoning when inferring an agent’s social or non-social
order to keep the experiment short, each participant only
completed half (21) of the trials. These trials were selected
by performing random splits, guaranteeing that each path                2
                                                                          All reported confidence intervals were obtained through a
was rated exactly 20 times in the social condition and 20
                                                                    basic non-parametric bootstrap.
                                                                977

rewards. In light of this, all further analyses were performed                                                                                                                                     motivation parameter. Thus, this correlation difference
using the merged judgments from both conditions.                                                                                                                                                   (0.22; 95% CI: 0.09-0.34) suggests that inferring the reward
 Figure 2 shows example paths with the naïve utility                                                                                                                                               function also helps recover the costs with more precision.
calculus inferences and the average human judgments.                                                                                                                                               The competence inference and the competence-motivation
Although the model qualitatively matched human                                                                                                                                                     inference models both had correlations close to zero (r=-
judgments, there were also high discrepancies. For example,                                                                                                                                        0.04 and -0.01, respectively. The 95% CI for both models
in the path on the bottom left of Figure 2, humans inferred                                                                                                                                        was between -0.20 and 0.16), suggesting that humans do not
that the agent had a high reward for picking up both objects                                                                                                                                       treat costs as being uniform for each agent. Last, the simple
(or helping both agents). In contrast, the model inferred a                                                                                                                                        goal inference alternative model makes no cost predictions
high reward for the first target the agent reached and a                                                                                                                                           and is thus incomparable on the cost dimension.
substantially lower reward for the second object, as it was                                                                                                                                                                                                     Individual model correlations
conveniently located on the agent’s path towards the exit                                                                                                                                                         0.9
                                                                                                                                                                                                                        Naïve utility
state (the top left of the map). This same path illustrates how                                                                                                                                                          calculus       ●●
                                                                                                                                                                                                                                             ●●●
                                                                                                                                                                                                                                                   ●●
the naïve utility calculus model showed more sensitivity to
                                                                                                                                                                                                                                                        ●●●●
                                                                                                                                                                                                                                                               ●●●●●●
                                                                                                                                                                                                                                                                          ●●
                                                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                                                                   ●●●●●●
                                                                                                                                                                                                                                                                                            ●●●●●
costs than humans did. At the beginning of the path the                                                                                                                                                                                                                                             ●●●●●●●
                                                                                                                                                                                                                                                                                                              ●●●●●
                                                                                                                                                                                                                                                                                                                      ●●●●●
                                                                                                                                                                                                                                                                                                                            ●●●●
                                                                                                                                                                                                                                                                                                                                    ●●●●
                                                                                                                                                                                                                  0.6
agent travelled north and moved two squares across the
                                                                                                                                                                                                                                                                                                                                            ●●
                                                                                                                                                                                                                           Goal                 ● ●●
                                                                                                                                                                                                                                                 ●                 ● ●                ● ●                          ●
                                                                                                                                                                                                                                                                                                                                               ●●●
                                                                                                                                                                                                                                                                                                                                                     ●●●
                                                                                                                                                                                                                                                                                                                                                          ●
                                                                                                                                                                                                                                                                                                                                                                                    ●
                                                                                                                                                                                                                        inference       ●                     ●●
                                                                                                                                                                                                                                                                         ●●●                      ●
                                                                                                                                                                                                                                                                                                      ●●
                                                                                                                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                                                                                                                                            ●●
                                                                                                                                                                                                                                                                                                                                                              ●●          ●
jungle before diving into the water. The model took this as
                                                                                                                                                                                                                                            ●            ●●            ●● ●                                                  ●                                   ●●●
                                                                                                                                                                                                                                                               ●                 ●         ●                           ●                   ●●              ●           ●●
                                                                                                                                                                                                                                                       ●●●                    ●             ●            ●                     ● ●                                         ●
                                                                                                                                                                                                                                                                                         ●    ●●                                       ●    ●                             ● ●
                                                                                                                                                                                                                                             ●                                 ●    ●                       ● ● ●
                                                                                                                                                                                                                                                   ●                           ●                                         ●               ●
                                                                                                                                                                                                                                                               ●●                     ●●
                                                                                                                                                                                                                        Motivation
strong evidence that the agent prefers navigating through the
                                                                                                                                                                                                                                                       ●                                                                                                                      ●
                                                                                                                                                                                                                                                         ●                             ●                        ●●                                              ●           ● ●●
                                                                                                                                                                                                                                                                     ●                  ●     ● ● ● ● ●●             ●                                 ●
                                                                                                                                                                                                                                                             ●         ●●●                                                         ●
                                                                                                                                                                                                                         inference           ● ●                                               ● ● ●                                                                ●●
                                                                                                                                                                                                                                                                   ●                                                     ● ●● ●         ●     ● ●●  ●●●
                                                                                                                                                                                                   Correlation
                                                                                                                                                                                                                                        ● ●                                                     ●             ●    ●
                                                                                                                                                                                                                                          ●                                                               ●                                                   ●                  ●
jungle relative to the other terrains, but humans did not.                                                                                                                                                                                                                   ●           ●●                                   ● ●●●             ●
                                                                                                                                                                                                                                                                                                                                                ●        ●            ●●      ●● ●
                                                                                                                                                                                                                                                 ●         ●                                                                                                      ●
                                                                                                                                                                                                                        Competence             ●   ●       ●     ●      ●                                 ●● ●                            ●●                 ●
                                                                                                                                                                                                                                                                                                            ● ●●                      ●              ●                ●     ●
                                                                                                                                                                                                                                        ●●● ● ●●         ●        ●●● ●          ●●
                                                                                                                                                                                                                                                                                       ● ● ● ●
                                                                                                                                                                                                                                                                                                                       ●
                                                                                                                                                                                                                                                                                                                               ●●         ●       ●             ●         ●
                                                                                                                                                                                                                                                               ●               ●●● ●                   ●                 ●                               ●      ●
                                                                                                                                                                                                                  0.3     inference                                                                                                   ●● ●●                       ●
                                                                                                                                                                                                                                                                                                                                                                      ●            ●
                                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                                                                                                    ●●
                                                                                                                                                                                                                                                                                                                       ●                             ●●             ● ●      ●
                                                                                                                                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                       ●     ●                       ●                                                           ●                         ●     ●
                                                                                                                                                                                                                                                                                  ●         ●          ●                   ●                                ●
                                                                                                                                                                                                                                                                            ●                                                                             ● ●●                  ●
                                                                                                                                                                                                                                                                                   ●                     ● ● ●                                        ●
                                                                           Cost−Reward scatterplots                                                                                                                                     ●
                                                                                                                                                                                                                                                ●
                                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                                         ●
                                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                                                 ●           ●
                                                                                                                                                                                                                                                                                          ●        ●
                                                                                                                                                                                                                                                                                                     ●    ●
                                                                                                                                                                                                                                                                                                            ●
                                                                                                                                                                                                                                                                                                                            ●
                                                                                                                                                                                                                                                                                                                                  ● ●●●
                                                                                                                                                                                                                                                                                                                                               ●
                                                                                                                                                                                                                                                                                                                                                 ●
                                                                                                                                                                                                                                                                                                                                                ● ●        ●      ●
                                                                                                                                                                                                                                                                                                                                                                    ●
                                                                                                                                                                                                                                                                                                                                                                        ●        ●
                                                                                                                                                                                                                                                                                                ●                                                                              ●     ●
                                                                                                                                                                                                                                            ● ●                                                          ● ●●             ●
                                                         Cost                                                                           Reward                                                                                               ●
                                                                                                                                                                                                                                                                   ●
                                                                                                                                                                                                                                                                     ●
                                                                                                                                                                                                                                                                       ●
                                                                                                                                                                                                                                                                                ●
                                                                                                                                                                                                                                                                                              ●
                                                                                                                                                                                                                                                                                                                  ●
                                                                                                                                                                                                                                                                                                                               ● ●●
                                                                                                                                                                                                                                                                                                                                              ●         ●
                                                                                                                                                                                                                                                                                                                                                        ●●
                                                                                                                                                                                                                                                                                                                                                              ●              ●       ●
                                                                                                                                                                                                                                                                                                     ●          ●    ●                    ●        ●                                 ●
                                                                                                                                                                                                                                                                                    ●    ● ●        ● ●                                                     ●     ●
                                                                    ●                                                                                                                                                                                                                                               ● ●
                                                                                                                                                                                                                                                                         ●                                                                                      ●           ● ●
                                                  ●  ●             ●                                                                                                                                                                                       ●●                                                              ●                                        ●
                                         ●●       ●●                 ●                                                        ●●●●                                                                                                        ●       ●●                                                                                                                                  ●
                    1                      ●
                                           ●
                                                   ●
                                                       ●●                                               ●●        ●●● ●●●
                                                                                                                          ●● ●●
                                                                                                                           ●    ●     ●
                                                                                                                                     ●●                                                                                                                                               ●●          ●                                                                       ●
                                                                                                                                                                     Naïve utility
                                                     ●●                                                                  ●●
                                                                                                                        ●●
                                                                                                                         ●            ●●                                                                                                                                                                      ●      ●       ●                       ●
                               ● ●     ●●●     ●●●●● ●● ●
                                                  ●                ●                                    ●           ● ●●● ●
                                                                                                                          ●        ●                                                                                                                                       ●
                                     ●●
                                     ●  ●● ●●●
                                             ●●● ●● ●                                                                   ● ●                                                                                                                                                                                                                                                          ●●
                                   ● ●● ● ●●    ● ●●                                                                        ●                                                                                                                          ●
                    0     ●● ●          ●●● ●●
                                             ●
                                              ●       ●                ●
                                                                                                                                                                                                                  0.0   Competence-motivation                                                                                                                           ●
                                                                                                                                                                      calculus
                                                                                                                                                                                                                                                                                                                                              ●
                        ●
                        ●
                        ●●●●● ● ●●● ●● ●                                                                                                                                                                                                                                                                                                                                           ●
                        ●●
                           ●●
                           ●● ●
                             ●
                                 ●
                            ● ● ●● ●
                                           ●
                                       ●● ● ●
                                             ●  ●                                                   ●
                                                                                                    ●●
                                                                                                    ●
                                                                                                    ●
                                                                                                      ●
                                                                                                      ●●
                                                                                                       ●●
                                                                                                                                                                                                                             inference                                                                                                                                                 ●
                                                                                                      ●
                                                                                                      ●
                        ● ●
                           ●●      ● ●
                                        ●                                                           ●
                                                                                                    ●●
                                                                                                    ●
                                                                                                    ● ●●
                                                                                                       ●                                                                                                                                                                                                                                                                          ●
                   −1    ●●●●●●
                              ●
                              ●        ●
                                                                                                    ●
                                                                                                    ●●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●                                                                                                                                                                                                                                                                                 ●
                            ●● ● ●    ●
                                                                                                                                                                                                                                                                                                                                                                                      ●
                    2
                                                                                                                                                                           Goal inference
                                          ●                                                                                                                                                                                                                                                                                                                                           ●
                                          ●
                                          ●
                                          ●                                                                                ● ●
                    1                     ●                                                                      ● ●● ● ●● ●
                                                                                                                     ●●
                                          ●
                                          ●
                                                                                                            ●●
                                                                                                       ● ● ●●
                                                                                                        ●     ●●
                                                                                                              ● ●
                                                                                                                ●
                                                                                                                ●●●       ● ●●                           ●
                                          ●
                                          ●                                                                 ●●     ●
                                          ●
                                          ●
                                          ●                                                                     ●● ●                                                                                             −0.3
                                          ●
                                          ●
                    0                     ●
                                          ●
                                          ●
                                          ●                                                                                                                                                                                         0                                         20                              40                                60                                    80
                                          ●
                                          ●                                                         ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                          ●
                                          ●                                                         ●● ●●
                                                                                                      ●●
                   −1
                                          ●
                                          ●
                                          ●
                                          ●
                                          ●
                                          ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                    ●
                                                                                                     ●
                                                                                                     ●
                                                                                                     ●
                                                                                                     ●●
                                                                                                     ●
                                                                                                     ● ●                                                                                                                                                                                Participants
                                          ●
                                          ●
                                          ●
                                                                                                                                                                                                   Figure 4. Individual model correlations with each participant. 93.75% of
 Human judgments
                                                     ●
                                                                                                                                                                                                   participants correlated best with the naïve utility calculus model. The x-axis
                                            ● ●                            ●
                          ●●                       ●                                                                          ●● ●● ●
                                                                                                                                                                     Competence
                    1      ●
                           ●
                           ●●
                             ●
                               ●         ● ●●            ●
                                                                                                        ●●
                                                                                                        ●         ●●
                                                                                                                  ●      ●
                                                                                                                         ●
                                                                                                                         ●
                                                                                                                           ●●
                                                                                                                           ●●
                                                                                                                          ●●●●
                                                                                                                              ● ●●
                                                                                                                                   ●
                                                                                                                                         ●●●
                                                                                                                                             ●
                          ●
                          ●
                          ●●●
                           ●              ●● ●   ●●
                                                ●●●                         ●                                      ●     ●  ●
                                            ●●●●● ●● ●                     ●                                               ● ●
                                                                                                                                                                                                   shows all 80 participants. The y-axis shows each participant’s correlation
                             ●              ●                                                                              ●
                          ●●●●           ● ● ●           ●
                                                         ●
                             ●              ●● ●●●●
                    0     ●●
                                                                                                                                                                      inference
                          ●●●●            ● ●●
                          ●
                          ●●●                   ●●●
                                                                                                                                                                                                   with each model. Participants are sorted by their correlation with the naïve
                                           ●●     ●                        ●                        ●
                                                                                                    ●●
                          ● ●●
                           ●              ●●
                                           ● ●●    ●                                                ● ●
                                                                                                      ●
                                                                                                      ●●
                           ●●                   ●                                                   ●●
                                                                                                    ● ●
                                                                                                      ●●
                                                                                                       ●
                          ●●               ●● ●
                                           ●                                                        ●
                                                                                                    ●
                                                                                                    ● ●
                                                                                                      ●●
                   −1      ●●●●                 ●●
                                                         ●                                          ●
                                                                                                    ●
                                                                                                    ●●
                                                                                                    ●
                                                                                                    ●
                                                                                                      ●
                                         ● ●         ●
                                                         ●
                                                         ●                 ●●
                                                                                                                                                                                                   utility calculus model. All model predictions were obtained prior to data
                                                                                                                                                                     Competence-motivation
                                                                                                                                                                                                   collection and no individual parameters were fit.
                                     ●
                                   ● ●
                                   ●●● ●                      ●                ●                                     ●
                                                                                                                     ●                             ●●
                    1              ●
                                   ●
                                   ●●
                                     ●●
                                       ●
                                       ●                                                              ●
                                                                                                      ●
                                                                                                      ●
                                                                                                                ●●●
                                                                                                                ●●
                                                                                                                ●  ●
                                                                                                                   ●
                                                                                                                     ●                           ● ●●
                                                                                                                                                    ●
                                   ●
                                   ●●
                                    ●
                                    ●●
                                     ●                       ●●
                                                             ●                                        ●
                                                                                                      ●         ●●●●                                 ●
                                    ●
                                    ● ●●                     ●                                                    ●
                                   ●●
                                    ● ●●●                    ●●                                             ●
                                                                                                            ●
                                   ●
                                   ●●●●●
                                     ●                                         ●
                                    ● ● ●                    ●
                                                             ●●                    ●
                    0              ●
                                   ●
                                        ●
                                                                                                                                                                                                     On the reward dimension, the naïve utility calculus model
                                   ●●●  ●
                                                                                                                                                                          inference
                                   ●
                                   ●
                                   ●●●                       ●●●
                                    ●●
                                    ●                                                                   ●   ●
                                   ●●
                                    ●●
                                     ●●●●                      ●                                        ● ●
                                   ●
                                    ●●                                                                  ● ●●
                                                                                                       ●●   ●● ●
                                   ●●●●                      ●                                        ●
                                                                                                      ●
                                                                                                      ●●● ●
                                                                                                        ● ●●
                                   ●  ●                                                               ●●
                                                                                                      ●●●
                                                                                                        ● ●
                                                                                                          ●●● ●
                   −1              ●●                                          ●
                                                                                                                                                                                                   showed the highest correlation (r=0.88; 05% CI: 0.83-0.93),
                                     ● ●
                                    ●●                                                                         ●
                                       ●●                                          ●
                                   ●                                               ●
                                   ●●●
                    1           ●
                                ● ● ●●
                                ●
                                 ●      ●● ● ●
                                                        ●
                                                         ●
                                                          ●
                                                            ●
                                                                                                ●
                                                                                                            ●● ●●● ● ●
                                                                                                           ●●
                                                                                                          ●●●●●
                                                                                                                                         ●
                                                                                                                                         ●                       ●
                                                                                                                                                                                                   but it was not reliably higher than the competence inference
                                                       ●                                               ●●
                                                                                                       ●  ●
                                                                                                          ●
                                                                                                         ●●● ●●                                                  ●
                                                                                                                                                                     Motivation
                                                                                                            ●●
                                                                                                                                                                                                   model (r=0.87; 95% CI: 0.82-0.93) or the simple goal
                               ●
                               ●●●●● ●   ●●
                                       ● ●
                                        ● ●     ●● ●● ● ● ●                                                 ●
                                                                                                                   ●
                                   ●
                                   ●●● ●       ●
                                               ●     ●  ●                              ●                ● ●
                                  ● ● ●● ●  ●    ●
                                                   ●
                                ● ●●●●  ●
                                        ●            ●
                    0           ●
                                ●●
                                                                                                                                                                     inference
                               ●
                               ●● ●●●               ● ●
                                                                                                                                                                                                   inference model (r=0.82; 0.74-0.90) (95% CI difference
                               ●●
                               ● ●
                                 ●●●●                                                                    ● ●●
                               ●●●●          ●                                                              ●
                                  ●●
                                  ●  ●                                                                  ● ●  ●● ●
                               ●●    ●                                                                 ●●
                                                                                                        ● ●●●
                                  ●
                                  ●
                                  ●
                                  ● ●●                                                                 ●
                                                                                                       ●
                                                                                                       ●
                                                                                                       ●●●●
                                                                                                        ●
                                                                                                        ● ●
                   −1          ●●● ●
                                   ●
                                   ●                                                                   ●●●●
                                                                                                          ●●●
                                                                                                            ● ●
                                                                                                            ●
                                                                                                            ●
                                ● ●●
                                ●                                                                              ●
                                                                                                                                                                                                   between naïve utility calculus and competence inference and
                                ●
                               ●●●
                                ●
                                          0                    2                           4                      0                     2                    4
                                                                                           Model prediction                                                                                        simple goal inference: -0.07-0.09 and -0.03-0.16,
Figure 3. Scatterplot of model predictions (z-scored) compared to average                                                                                                                          respectively). The motivation inference and motivation-
human judgments. The x-axis shows the model predictions and y-axis                                                                                                                                 competence inferences performed considerably worse
shows the human (z-scored per participant) average judgments. The left
column shows the cost inferences (three points per path) and the right
                                                                                                                                                                                                   (r=0.34 and 0.42, respectively; 95% CI: 0.44-0.68 and 0.32-
column shows the reward inferences (two points per path). Each row shows                                                                                                                           0.57, respectively). Thus, our paradigm did not reveal any
a different model.                                                                                                                                                                                 significant improvement in the ability to infer rewards by
                                                                                                                                                                                                   simultaneously inferring costs.
  We next performed a quantitative model comparison by                                                                                                                                               Last, we examined participants’ individual performance by
calculating each model’s correlation with human cost and                                                                                                                                           calculating their correlation with each model (See Figure 4).
reward inferences (See Figure 3). To do this, each                                                                                                                                                 Because both cost and reward inferences were z-scored for
participant’s data was standardized (z-scored) and then                                                                                                                                            participants and each model, we were able to calculate a
averaged. Similarly, each model’s predictions were                                                                                                                                                 joint cost-reward correlation score. All participants were
standardized (z-scored). On the cost dimension, the naïve                                                                                                                                          correlated with the predictions generated from the model
utility calculus correlated the highest with human judgments                                                                                                                                       prior to data collection and no parameters were fit to
(r=0.72; 95% CI: 0.65-0.79), followed by the motivation                                                                                                                                            individual participants. On average, participants had a
inference model (r=0.50; 95% CI: 0.40-0.61). The naïve                                                                                                                                             correlation of 0.624 (95% CI: 0.60-0.66) with the naïve
utility calculus inferred the full reward function while the                                                                                                                                       utility calculus model. Furthermore, 93.75% of participants
motivation inference model only inferred a single
                                                                                                                                                                                             978

(N=75) showed the highest correlation with this model.                Importantly, participants performed identically in the
Three out of the remaining five participants (6.25%)                object and the social conditions. This suggests that humans
correlated better with the goal inference model and the other       use the same kinds of inferences to reason about social
two participants correlated better with the motivation              goals. Having found overall support for human’s naïve
inference model (See Figure 4). This suggests that, although        utility calculus, in future work we can bring this quantitative
the naïve utility calculus model did not fit human inferences       paradigm to study how humans make social and moral
perfectly, it nevertheless clearly outperformed all other           evaluations. Behavioral work suggests that the same kinds
models at a global and individual level.                            of inferences influence our social evaluations (Jara-Ettinger,
                                                                    Kim, Muentener, & Schulz, 2014; Jara-Ettinger,
                         Discussion                                 Tenenbaum, & Schulz, 2015). As such, models of people’s
Here we proposed that the ability to reason about the costs         quantitative cost-reward inferences may help us understand
and rewards underlying rational action is crucial for social        the precise computations underlying our social evaluations
reasoning. Inspired by developmental studies (Jara-Ettinger         and moral judgments.
et al., 2015; Jara-Ettinger, Nate, Muentener, & Schulz,
2014) we implemented a formal model of the naïve utility                                 Acknowledgments
calculus and tested its performance against human                   We thank Samantha Floyd for useful comments and
inferences.                                                         discussions. This material is based upon work supported by
  Overall, the naïve utility calculus model outperformed the        the Center for Brains, Minds, and Machines (CBMM),
simple pure goal inference model as well as intermediate            funded by NSF-STC award CCF-1231216, and by the
models both at a global level (averaging the responses of all       Simons Center for the Social Brain.
participants) and at an individual level (correlating model
predictions with individual participants). Importantly, the                                   References
naïve utility calculus was able to infer the cost function in a
                                                                    Baker, C. L., Saxe, R., & Tenenbaum, J. B. (2009). Action
quantitatively similar way to human’s inferences (See
                                                                      understanding as inverse planning. Cognition.
Figure 3), which no other model was able to do. However,
                                                                    Baker, C. L., Saxe, R. R., & Tenenbaum, J. B. (2011).
we also found unexpected results.
                                                                      Bayesian theory of mind: Modeling joint belief-desire
  First, although the naïve utility calculus made better cost
                                                                      attribution. In Proceedings of the thirty-second annual
inferences compared to the other models, its reward
                                                                      conference of the cognitive science society (pp. 2469-
inferences were matched by the simple goal-inference and
                                                                      2474).
the competence inference models. Thus, we failed to find
                                                                    Gergely, G., & Csibra, G. (2003). Teleological reasoning in
evidence that the ability to infer an agent’s costs helps to
                                                                      infancy: The naıve theory of rational action. Trends in
infer rewards with more precision. However, a closer look at
                                                                      cognitive sciences, 7(7), 287-292.
the data (See Figure 3) suggests that, although the models
                                                                    Gilboa, I. (2010). Rational choice. MIT Press.
showed a high numerical reward correlation, none of the
                                                                    Jara-Ettinger, J., Baker, C. L., & Tenenbaum, J. B. (2012).
models was able to predict human judgments with high
                                                                      Learning what is where from social observations.
accuracy. Critically, humans’ reward inferences were
                                                                      In Proceedings of the Thirty-Fourth Annual Conference
bimodal, with participants mostly inferring that the agents’
                                                                      of the Cognitive Science Society (pp. 515-520).
rewards took the highest possible value, or no value at all.
                                                                    Jara-Ettinger, J., Kim, N., Muentener, P., & Schulz, L. E.
In contrast, the naïve utility calculus model made graded
                                                                      (2014) Running to do evil: Costs incurred by perpetrators
predictions. One possibility is that humans were judging
                                                                      affect moral judgment. In Proceedings of the Thirty-Sixth
whether the agent placed a reward on the outcome or not,
                                                                      Annual Conference of the Cognitive Science Society.
rather than inferring its exact magnitude. Further work is
                                                                    Jara-Ettinger, J., Tenenbaum, J. B., & Schulz, L. E. (2015).
needed to determine if this effect is task specific or if it
                                                                      Not so innocent: Toddlers’ inferences about costs and
fundamentally reflects how humans make reward
                                                                      culpability. Psychological Science.
inferences.
                                                                    Jara-Ettinger, J., Gweon, H., Tenenbaum, J. B., & Schulz,
  In addition, our experiment only used complete paths.
                                                                      L. E. (2015). Children’s understanding of the costs and
However, as Figure 1 shows, a significant advantage of
                                                                      rewards underlying rational action. Cognition.
jointly inferring the costs and rewards comes into play
                                                                    Moses, L. J. (2003). Some thoughts on ascribing complex
before the agent has completed their goal. Models that don’t
                                                                      intentional concepts to young children. Intentions and
take into account an agent’s costs assume the agent is
                                                                      intentionality: Foundations of social cognition, 69-83.
always taking the shortest path towards their goal (which
                                                                    Scott, R. M., & Baillargeon, R. (2013). Do infants really
may not necessarily be the most efficient; see Figure 1) and
                                                                      expect agents to act efficiently? A critical test of the
thus can make incorrect inferences. As such, it is possible
                                                                      rationality principle. Psychological science.
that the naïve utility calculus model would outperform the
                                                                    Woodward, A. L., Sommerville, J. A., & Guajardo, J. J.
other models when making reward inferences in incomplete
                                                                      (2001). How infants make sense of intentional
paths.
                                                                      action. Intentions and intentionality: Foundations of
                                                                      social cognition, 149-169.
                                                                979

