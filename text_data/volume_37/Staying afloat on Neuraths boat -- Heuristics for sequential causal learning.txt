       Staying afloat on Neurath’s boat – Heuristics for sequential causal learning
                  Neil R. Bramley1 (neil.bramley@ucl.ac.uk), Peter Dayan2 (dayan@gatsby.ucl.ac.uk),
                                             David A. Lagnado1 (d.lagnado@ucl.ac.uk)
                    1 Department     of Experimental Psychology, UCL, 26 Bedford Way, London, WC1H 0DS, UK
             2 Gatsby   Computational Neuroscience Unit, UCL, Alexandra House, 17 Queen Square, WC1N 3AR, UK
                               Abstract                                  erative connections. We adopt Cheng’s power PC (1997)
   Causal models are key to flexible and efficient exploitation          parametrization for which the probability that a variable takes
   of the environment. However, learning causal structure is             the value 1 is a noisy-OR combination of the power or
   hard, with massive spaces of possible models, hard-to-compute         strength S of any active causes in the model, together with
   marginals and the need to integrate diverse evidence over many
   instances. We report on two experiments in which participants         an omnipresent background cause B that is exogenous to the
   learnt about probabilistic causal systems involving three and         model. S and B are assumed to be the same for all connec-
   four variables from sequences of interventions. Participants          tions and components, and there is no other latent variable
   were broadly successful, albeit exhibiting sequential depen-
   dence and floundering under high background noise. We cap-            (although see Buchanan, Tenenbaum, & Sobel, 2010).
   ture their behavior with a simple model, based on the “Neu-
   rath’s ship” metaphor for scientific progress, that neither main-     Optimal structure learning
   tains a probability distribution, nor computes exact likelihoods.     The likelihood of a datum (a complete observation, or the
   “We are like sailors who on the open sea must reconstruct             outcome of an intervention) d given a noisy-or parametrized
their ship but are never able to start afresh from the bottom.           causal model m over variables X, with strength and back-
Where a beam is taken away a new one must at once be put                 ground parameters S and B is
there, and for this the rest of the ship is used as support.”                             P(d|m, S, B) = ∏x∈X P(dx |d pa(x) , S, B)            (1)
(Quine, 1969, p3)                                                                                                                ∑y∈pa(x) dy
                                                                              P(dx = 1|d pa(x) , S, B) = 1 − (1 − B)(1 − S)                    (2)
                           Introduction
It is tremendously hard to learn causal models. Even in ap-                 where pa(x) denotes the parents of variable x in the causal
parently simple circumstances, it is necessary to cope with              model. We can thus compute the posterior probability of
a huge diversity of complex, noisy and probabilistic interac-            model m ∈ M over a set of models M given a prior P(M) and
tions, and thus to integrate, often painfully, over extended ex-         observations D. We can condition on S and B if known:
perience. Optimal reasoning with distributional causal beliefs                                       P(D|m, S, B)P(m|S, B)
places substantial demands on inference and storage. Nev-                  P(m|D, S, B) =                                                      (3)
                                                                                                ∑m0 ∈M P(D|m0 , S, B)P(m0 |S, B)
ertheless, in several studies (Bramley, Lagnado, & Speeken-
brink, 2014; Coenen, Rehder, & Gureckis, 2014; Lagnado                   or else marginalize over their possible values
& Sloman, 2004, 2006; Steyvers, 2003) it has been shown                                        R
that people can learn successfully from interventional data                                     S,B P(D|m, S, B)p(S, B)P(m) dS dB
in probabilistic scenarios. Existing experiments have largely              P(m|D) =               R
                                                                                                               0                   0
                                                                                                                                               (4)
                                                                                          ∑m0 ∈M    S,B P(D|m , S, B)p(S, B)P(m ) dS       dB
been confined to small structures, small data and semi-
determinism, thus limiting the computational demands and                    If data arrive sequentially, we can either integrate them at
the need for heuristics or approximations. Here, we report on            the end, or update our beliefs sequentially, taking the current
two experiments designed to tax learning more severely, with             posterior as the new prior P(M) for the next datum1 .
a broad range of structures, long sequences of data points,
and substantial noise (Experiment 1) whose level and nature              Scope for approximation
participants have to infer as they learn (Experiment 2). We              Learning is hard because the number of possible graphs
thereby examine how people deviate from rational norms, and              grows rapidly with the number of components (3, 4 and 5-
explore what this can tell us about their psychological pro-             variable problems have 25, 543, 29281 respectively) and there
cesses.                                                                  is no known closed form update for densities over S and B in
                                                                         noisy-OR models. To understand how people might mitigate
Representing causal structure                                            this computational explosion, we take inspiration from ma-
We adopt a ubiquitous framework for formalizing models                   chine learning.
of causal structure – the parametrized directed acyclic graph
(Pearl, 2000). Arrows represent causal connections; and pa-              Approximating with a few hypotheses One common ap-
rameters encode the influence of parents (the source of an               proximation is based on a manageable number of individual
arrow) on children (the arrow’s target). Such graphs can                 hypotheses, or particles (Liu & Chen, 1998), with weights
represent continuous variables and any forms of causal rela-                 1 For the present, we ignore the related question of active learning
tionship; here we focus on binary {0, 1} variables and gen-              – i.e., the efficient selection of interventions. See the discussion.
                                                                     262

corresponding to their relative likelihoods. Sophisticated           structs: the dissimilarity between bt−1 and a potential new bt ,
reweighting and resampling schemes allow particle filters im-        and the suitability of that bt for capturing dt . We quantified
pressive fidelity.                                                   dissimilarity in two ways. One is simple difference Eb∗t bt−1 ,
   In rodent learning (Courville & Daw, 2007), and human             which is 1 iff bt is non-identical to bt−1 and 0 otherwise. The
categorisation (Sanborn, Griffiths, & Navarro, 2010) and bi-         second is the Edit distance Ebt bt−1 , which counts the num-
nary decision making (Vul, Goodman, Griffiths, & Tenen-              ber of edits (additions, subtractions, reversals of links) going
baum, 2009), it has been proposed that people’s beliefs ac-          from bt−1 to bt (ranging from 0 to 6 for a 4 variable problem).
tually behave more like a single particle, capturing why indi-          We quantified the suitabilities via two approximate likeli-
viduals often exhibit fluctuating and sub-optimal judgements,        hoods. One, Lbt (dt ), is the correct noisy-OR likelihood un-
whereas group-level posteriors are smooth.                           der a prospective new belief bt . The second, explanatory
                                                                     inAdequacy Abt (dt ), just counts the number of component
Local search A related simplification is to edit these parti-
                                                                     states that the prospective model fails to explain.
cle hypotheses only locally – for instance adding, subtracting
                                                                        We considered the eight viable combinations of these
and reversing individual connections to one’s current causal
                                                                     constructs (singletons labeled E, E ∗ , L, A; pairs labeled
structure in searching for changes that make the model more
                                                                     E ∗ L, E ∗ A, EL, EA). Each model can be taken to generate a
likely (Cooper & Herskovits, 1992). This is approximate
                                                                     likelihood for a subject’s choices based on a softmax proba-
since the complex dependencies between the connections im-
                                                                     bility that the model assigns to a choice of bt . For instance,
ply that one cannot guarantee to be able to learn each one
                                                                     for EA, this probability is
separately (although see Fernbach & Sloman, 2009).
Prior assumptions People might also exploit simplifying                                         exp(Ebt bt−1 θ1 + Abt (dt )θ2 )
                                                                                     P(bt ) =                                                (5)
priors, for instance, expecting causal connections to be strong                               ∑ exp(Ebt bt−1 θ1 + Abt (dt )θ2 )
(high Strength) and sparse (low Background noise) (Lu,
                                                                        with parameters θ1 and θ2 that can be fit to maximize the
Yuille, Liljeholm, Cheng, & Holyoak, 2008), and structures
                                                                     likelihood. For the moment, we assume that subjects search
to be “well designed” (Bramley, Gerstenberg, & Lagnado,
                                                                     over all possible edits; how they actually perform this search
2014), lacking redundant connections, or unconnected com-
                                                                     is an important question for the future.
ponents. These would be sensible, since causal models sim-
plify inference only to the extent that their structure reduces
                                                                                                               a
                                                                                                               A     E: 0
the number of relata per variable. Mayrhofer and Wald-                                                               A: 2 (b,c)
mann (2011) suggest that people might favor determinis-                                                     b
                                                                                                            B     c Cost: 0 + 2 = 2
                                                                                                                  C
tic causal structures, accommodating noisy data by assum-                                                      a
                                                                                                               A
                                                                                     a
                                                                                     A            +                  E: 1 (+a→b)
ing that causal connections are occasionally “broken”. Their                                                         A: 0
study assumed an absence of background noise; but one could                                                 b
                                                                                                            B     c Cost: 1 + 0 = 1
                                                                                                                  C
                                                                                 b
                                                                                 B        c
                                                                                          C
imagine an equivalent accommodation treating inexplicable                                                      a
                                                                                                               A
                                                                                                                     E: 3 (+a→b, +a→c, -b→c)
events as being ‘miraculous’. This suggests the heuristic                       Old belief    Evidence               A: 0
proxy for likelihood judgments for a model as a simple count                       (bt-1)        (dt)       b
                                                                                                            B     c Cost: 3 + 0 = 3
                                                                                                                  C
                                                                                                          Prospective new beliefs (bt)
of the number of variables lacking explanation.
                                                                     Figure 1: A simple structure change model. The learner encounters
A class of simple structural change models                           data that are not well explained by their model so they search for a
                                                                     local change that improves it. By balancing the edit-cost E against
The resulting picture of a heuristic causal learner is remi-         reduced inability to explain the latest outcome A, they opt to add a
                                                                     connection a → b.
niscent of Neurath and Quine’s (1969) metaphor for theory
change in science. Here, the theorist is cast as relying on
their theory to stay afloat, without the privilege of a dry-         Experimental rationale
dock to make major improvements. At most local changes               To explore these approximations, we considered sequential
to patch leaks and to improve the theory are possible, without       structure learning in appropriately difficult problems. If sub-
the whole space of possibilities ever being considered.              jects really maintain only a single causal belief and make lo-
   Similarly, we propose that causal learners might: (1) main-       cal edits, we expect sequential dependence, and a tendency to
tain only a single causal model (a single particle) bt−1 at time     get stuck in local optima. If they forget old evidence, relying
t − 1; (2) search for local improvements (adding, subtract-          on the current structure itself, we expect to observe recency
ing, reorienting edges) in order to (3) (approximately) max-         effects whereby participants may return to judgments previ-
imize the number of aspects of the new data dt for which             ously rejected. Finally, if they rely on generic priors we ex-
their model can account (Figure 1). Iterating this proce-            pect to see better performance when the true causal structure
dure leads to reasonable, though sub-optimal, causal structure       is conformant.
judgments without either representing more than one causal              We therefore designed two online studies based on the
model or remembering old evidence.                                   paradigm used in Bramley, Lagnado and Speekenbrink
   We parametrized a whole class of such models via two con-         (2014) (demo at ucl.ac.uk/lagnado-lab/el/ns15a). Participants
                                                                 263

interacted with a series of probabilistic causal systems involv-      Participants were incentivized to report their best guess about
ing 3-4 variables, repeatedly selecting interventions (or tests)      the structure, through receipt of a 10¢ bonus for each causal
to perform in which any number of the variables were either           relation (or non-relation) correctly registered at randomly se-
fixed on or off, while the remainder were left free to vary.          lected time points throughout the task.
The tests people chose, along with the true underlying causal            Participants completed instructions familiarizing them
model, S and B, jointly determined the data they saw. We sys-         with the task interface; the interpretation of arrows as (prob-
tematically varied the number of connections between com-             abilistic) causal connections; the incentives for judgment ac-
ponents in the problem set, along with S and B.                       curacy; and the level of S and B in their condition. To train
                                                                      participants on S and B, they were shown first 10 unconnected
                        Experiment 1                                  components and forced to test them 5 times. The frequency
In Experiment 1, we restricted ourselves to the effects of “ex-       with which the components activated reflected the true back-
pected” uncertainty (Yu & Dayan, 2003) by training subjects           ground noise level. Then, they were shown a set of two-
explicitly on the true prevailing values of B and S.                  component causal systems where component “A” was a cause
                                                                      of “B”, and were forced to test these systems 5 times by fix-
Methods                                                               ing component “A” on. This indicated that the frequency with
Participants We recruited 150 participants (85 male,                  which “B” activated reflected the level of S combined with
mean±SD age 35 ± 10 from MTurk, split randomly between                the background noise they had already learned (e.g. 76% of
9 conditions (group size 16.7 ± 3.4). They were paid $1.50            the time in condition 9).
and received a bonus of 10c per correctly identified con-                After completing the instructions and correctly answering
nection on a randomly chosen test for each problem (max=              comprehension checks, participants solved a practice prob-
$6.00, mean±SD $3.68 ± .75). The task took an average of              lem drawn from the five three-variable problems. They then
41 ± 20 minutes.                                                      faced the 10 test problems in random order, with randomly
Design We included five 3-variable and five 4-variable                orientated unlabeled components. They were given six tests
problems (see Figure 2). Within these, we varied the sparse-          per three variable problem and eight tests per four variable
ness of the causal connections, ranging between a single con-         problem. After the final test for each problem they received
nection (devices 1; 6) to fully connected structures (5; 10).         feedback telling them the true connections.
We included problems exemplifying three key types of causal           Results
structure: forks (diverging connections), chains (sequential
                                                                      Performance by condition We expected the quality of par-
connections) and colliders (converging connections).
                                                                      ticipants’ judgments to be bracketed by those of a random ( 31
   There were three different levels of causal strength S ∈
                                                                      per link, given the three possibilities) and a Bayes-optimal
[1, .85, .6] and three different levels of background noise B ∈
                                                                      observer. For the latter, we calculated the posterior distribu-
[0, .15, .4] making 3 × 3 = 9 between-subjects conditions. For
                                                                      tions over the task using Bayesian integration based on the
instance, in condition 1 (S = 1; B = 0) the causal systems were
                                                                      outcomes the participants actually observed, calculating the
perfectly deterministic, with nothing activating without being
                                                                      likelihoods using the true causal strength S and background
intervened on, or caused by, an active parent, and connections
                                                                      noise B, assuming a uniform prior at the start of each problem.
never failing to cause their effects. Meanwhile, in condition 9,
                                                                      By reporting the MAP structure (guessing in the event of ties)
(S = 0.6; B = 0.4) the outcomes were very noisy, with proba-
                                                                      participants could have achieved accuracies ranging between
bility .4 that a variable with no active parents would activate,
                                                                      .84 ± 0.14 in condition 2 and .55 ± 0.09) in the nosiest condi-
compared to a probability 1 − (1 − .6)(1 − .4) = 0.76 for a
                                                                      tion, 9 (see Figure 3, blue circles). Optimal learning predicts
variable with one active parent.
                                                                      differences by condition, with a considerable reduction in ac-
Procedure The causal systems were represented as grey                 curacy going from no to high background noise, and a more
circles on a white background. Participants were told that the        moderate reduction going from perfectly strong to highly un-
circles were components of a causal system of binary vari-            reliable causal connections.
ables, but were not given any further cover story. Initially, all        Participants significantly outperformed chance in all nine
components were inactive and no connection was marked be-             conditions (all p values < .05 for t-tests comparing to 13 ).
tween them. Participants performed tests by clicking on the           However they underperformed the Bayes-optimal observer
components, setting them at one of three states “fixed on”,           (t-test p values < .05) in all conditions bar condition 2 S =
“fixed off” and “free-to-vary”, then clicking “test” and ob-          0.85, B = 0 (p=0.07). Like the optimal observer, participants
serving what happened to the “free to vary” components as a           became less accurate as noise increased, with a main effect
result. The observations were of temporary activity (graph-           of Background noise F(2, 147) = 6.34, η2 = 0.07, p = 0.002
ically activated components would turn green and wobble).             with lower performances for B = 0.1,t(147) = −2.23, p =
After each test, participants registered their best guess about       0.03 and B = 0.4,t(147) = −3.5p < .001 compared to B = 0,
the underlying structure. They did this by clicking between           but no main effect of Strength F(2, 147) = 1.2, p = 0.3.
the components to select either no connection, or a clockwise            Participants marked more causal connections per problem
or anti-clockwise connection, (represented as black arrows).          than the optimal learner, mean±SD estimates 2.93±1.4 com-
                                                                  264

pared to 2.75 ± 1.4, t(2998) = 3.5, p = 0.0005. The true                                      a) Problem set experiment 1
                                                                            1.             2.                  3.                4.          5.
proportion was 2.6. The number of connections participants                          A             A                       A             A           A
marked on average was affected by both B and S, going from                        C   B         C       B           C       B        C     B     C    B
2.78 ± 1.5 for B = 0 to 3.14 ± 1.4 for B = 0.4, and 2.77                    6.             7.                  8.               9.           10.
                                                                                 A    B         A       B           A       B        A     B     A    B
(SD=1.4) for S = 0.6 to 3.01 (SD=1.4) for S = 1.
Performance by problem Average accuracy on three vari-                           D    C         D       C           D       C        D     C     D    C
able problems was fractionally higher than on four vari-                       b) Participants’ averaged final judgments Experiment 1
able problems .55 ± 0.34 compared to .52 ± 0.29, t(1463) =                  1.      A      2.     A            3.         A      4.     A    5.     A
2.0, p = 0.04, and tests were completed marginally quicker
                                                                                  C   B         C       B           C       B        C     B     C    B
with medians 12.3s and 14.6s. Due to the unrestricted tim-
                                                                            6.             7.                  8.               9.           10.
ing of the study, test times were highly positively skewed.                       A   B         A       B           A       B        A     B     A    B
Therefore, we tested for a difference between medians by
                                                                                  D   C         D       C           D       C        D     C     D    C
permutation test (Higgins, 2004), finding it significant p <
.0001. However, there was no main effect of the number of                                           0.0    0.2        0.4   0.6 0.8    1.0
connections on judgement accuracy F(1, 1498) − 2.1, η2 =                                                  Proportion selected
0.001, p = 0.14.                                                                        c) Averaged posteriors Experiment 1
                                                                               1.             2.                  3.                4.          5.
   There was a significant main effect of device type                               A             A                       A             A           A
F(5, 1444) = 2.91, η2 = 0.007, p = 0.02 (see Figure 2). Ac-                       C   B         C       B           C       B        C     B     C    B
curacy was lowest for chains (devices 3; 8) 0.49 ± 0.28, and                   6.             7.                  8.                9.          10.
highest for colliders 0.57 ± 0.30 (4; 9). Taking the chain                        A   B         A       B           A       B        A     B     A    B
as treatment group, the main effect of device was driven by                       D   C         D       C           D       C        D     C     D    C
higher accuracy on colliders (4; 9) t(1497) = 3.2; p = 0.001,
and marginally higher performance on singly- (1; 6) and                                             0.0    0.2        0.4   0.6 0.8    1.0
                                                                                                    Average posterior probability
fully-connected (5; 10) structures.
Changing judgements Comparing participants’ sequences              Figure 2: a) The problems faced by participants. b) Weighted
of structure judgments indicates that they shift markedly less     average final judgments by participants. Darker arrows indicate
                                                                   that a larger proportion of participants marked this link in their fi-
frequently than the optimal observer, changing an average of       nal model. c) Bayes-optimal marginal probability of each edge in
0.94 ± 1.3 connections after each test compared with 1.78 ±        P(M|d1:T , S, B), averaged over participants.
1.5, χ2 (6) = 1920, p < .0001 (see Figure 3b)
                         Discussion                                with ties broken randomly. This matches more closely the
                                                                   subjects’ performances per condition, and also their patterns
Participants identified causal connections above chance even       of sequential judgment edits.
in the most complex and noisy situations we tested. Nev-
ertheless, they were systematically less accurate than they                                               Modeling
could have been. This is hardly surprising given the consid-       To test the models more formally, we fit the likelihoods of
erable complexity of the inferences, and invites comparison        the various combinations, as in the example of equation 5, to
with the heuristics discussed earlier. That response times do      the judgments bt=1:T of all participants, for all problems. We
not increase greatly going from three- to four-variable prob-      expect the resulting θ parameters to be such that lower dis-
lems argues against explicit Bayesian-like calculations, as        similarities and fewer explanatory inadequacies lead to more
these grow at least O(2N ) with increasing number of vari-         probable selection. Judgments at t = 0 were assumed to be
ables N. Nevertheless, that the ensemble behavior across all       an unconnected causal model, but starting evaluation at t = 1,
participants resembles the (averaged) posteriors (Figure 2)        when a judgment was already in place, produces comparable
is in line with the idea that individuals’ judgments can be        results.
plausibly thought of as individual particles. The strong se-          We also considered two baseline models.                                           One is
quential dependence in judgments argues firmly against their       a a parameter-free model that assumes each judgment
representing the whole distribution. Finally, systematic over-     is a random draw from all possible causal models
connecting, especially for high B, fits with subjects’ failing     p(bt = m) = Unif (M) (leading to a probability 31 for
to compute the exact likelihoods even when they know the           each link). The other model is a variant of the Bayes-optimal
parameters, but rather relying on more generic or heuristic        model that allows decision noise to corrupt choices from the
approximations.                                                    true posterior at t, P(M|D, S, B)t . For this, we considered
   As a hint that the heuristic models discussed above might                                               exp(P(M|D, S, B)t θ1 )
                                                                                    P(bt |D) =                                                             (6)
therefore offer a better model of the subjects’ behavior, the                                        ∑m∈M exp(P(m|D, S, B)t θ1 )
green dots in figure 3 show the case of EA with θ1 = θ2 → ∞         controlled again by an inverse temperature parameter θ1 .
(so that the MAP structure is chosen at each iteration), and          Separately, we estimated maximum likelihood S∗ and B∗
                                                               265

                                                                                                                                                                                       0.0                                                                      0.8
                                                                                                                                                                                                          0               1       2               3
                                                                                                                                                                                                                                                                0.4
                                                                                                                                                                                       Edit distance between consecutive judgements
                                                                                                                                                                                                                                                                0.0
                                  Participant Final Accuracy Experiment 1
                 a)                       Final accuracy Exp 1                                        b)                        Three           structures
                                                                                                                                      componentproblems                                        Four component structures
                                                                                                                                                                                                                                                          c)             0      0.15   0.4
                                                                                                                                                                                                                                                                       Best fitting S and B
                            1.0      ●
                                                   ●
                                                                                                                                   3-component                                                  4-component problems
                                         ●
                                                                  ●            ●                                      0.8                                                              0.8                      Three component structures
                                                                                                                                                                                                                                                                0.8
                                         ●
                            0.8              ●
                                                                                                                                                                                                          0.8
                                                                                                                                                                                       0.6                                                                     0.4S*
                                                   ●
                                                                                                       Proportion
                                     ●       ●                        ●
                                                                  ●                 ●
                                                                                                                                                                          Proportion
                                                                                    ●                                                                                                                     0.6
      Accuracy
                            0.6                                                              ●
                                                                                                                                                                                             Proportion
                                                                               ●
                 Accuracy
                                                                                                       Proportion
                                                                      ●
                                                                                                                                                                                       0.4                                                                             Actual
                                                                                                                                                                         Proportion
                                                                                             ●
                                                                                                                                                                                                          0.4                                                   0.0
                                                                                                                                     ●            ●                                                                   ●       ●
                                                                                                     0.2 0.4 0.6                                           ●                                                                          ●
                            0.4                                                                                                                                                        0.2          ●     0.2
                                                                                                                                                                                                                ●         ●   ●
                                                                                                                                                                                                                                                                         1      0.85   0.6
                                                                                                                                                                                                                                  ●           ●
                                                                                                                                                                     ●                                    0.0                             ●
                                                                                                                                                                                       0.0                                                            ●         0.8
                            0.2                                                                                       0.0                                                                                             0       1       2       3
                                                                            Participant Final Accuracy Experiment 1
                                                                                                                                     0  1         2       3              0 Edit1distance
                                                                                                                                                                                      2 between  4           6
                                                                                                                                                                                                       5 judgements
                                                                                                                                                                                            3 consecutive
                            0.0                                                                                                                                                                                                                                  B*
                                                                                                                                                                                                                                                               0.4
                                                                      1.0      ●                                                       Edit distance                                  Edit distance
                                                                                                 ●                      Benchmark
                                    S=1   S=.6    S=1   S=.6                  S=1
                                                                                    ●
                                                                                     S=.6                             Edit distance between consecutive judgements
                                                                                                                      ● Bayesian
                                                                                                                                                                 Edit distance  between     consecutive   judgements
                                                                                  ●
                                                                                                        ●                  ●                                                                                        Four component structures
                                       B=0          B=.15             0.8        B=.4●                                  Neurath's ship                                                                                                                          0.0
                                                                               ●         ●
                                                                                                 ●
                                                                                                        ●         ●     Chance●                                                                           0.8
                                                  Condition                                                                                                                                                                                                              0      0.15   0.4
                                                   Condition                                                                     ●
                                                       Accuracy
                                                                      0.6                                         ●         ●
                                                                                                                                Four● component structures
                                                                                                                                         ●
                                                                                                                                                                                                          0.6
Figure 3: a) Mean final accuracy with standard errors. White circle: benchmark (greedy expected information gain maximizing) Bayesian                                                        Proportion
                                                                                                                                                                                                          0.4
                                                                      0.4                                                                                                                                                                                       0.8
                                                                                                                      0.8
learner. Blue circles: Bayesian learner that maximizes over the posterior after seeing participants’ ●    ●    ● interventions.
                                                                                                                   ●   ●
                                                                                                                            ●
                                                                                                                                          Green triangles: “Neurath’s                                     0.2
                                                                      0.2                                             0.6
ship” simulation simply minimizing number of edits E and failures to explain A. Red squares: random ●guessing. b) Bars show average                                                                       0.0                                                   0.4
                                                                                                     Proportion
                                                                                                     0    1    2   3   4
number of edits (additions, subtractions or reversals of connections) between all t and t+1 judgments,
                                                                      0.0                                             0.4
                                                                                                                         as5 compared
                                                                                                                                  6
                                                                                                                                             toActual
                                                                                                                                                 Bayesian, “Neurath’s
ship” and random choice simulations.S=1 c)S=.6
                                           Boxplot
                                               S=1 S=.6 S=1 fitting
                                                    of best  S=.6   S∗ and B∗ parameters assuming         learners soft-maximised over P(M|D, S∗ , B∗ ).
                                                                                             Edit distance between consecutive judgements                                                                                                                       0.0
                                                                                   B=0               B=.15                                                                                                                                                               1      0.85   0.6
                                                                                                                      0.2       B=.4
                                                                                                                                 ●           ●    ●    ●   ●
parameters for participants assuming Equation
                                       Condition 6.                                                                   0.0
                                                                                                                                                                 ●
                                                                                                                                                                     ●                                                        Experiment 2
Fitting the models Altogether we fit 9 different0 (fixed    1    2 ef-
                                                                     3   4     5    6
                                                                              The fact that many participants are well captured by the
fects) models separately to each of the 150 participants.      Mod-
                                               Edit distance between consecutive judgements
                                                                              model that relies on heuristic likelihoods suggests that peo-
els were fit using maximum likelihood as implemented by R’s                   ple will still be able to learn causal models well even if they
optim function, and compared using their BIC scores to ac-                    do not know S and B parameters explicitly. We therefore
commodate their different numbers of parameters. Results                      designed a second experiment (demo at ucl.ac.uk/lagnado-
are detailed in Table 1.                                                      lab/el/ns15b) to test this effect. Furthermore, by asking sub-
                                                                                                                                                                 jects to re-register every link after every new test, we fixed
Table 1: Experiment 1 - Models fitted to individuals’ judgments by
maximum likelihood. McFadden’s pseudo-R2 is reported, alongside                                                                                                  a potential shortcoming of Experiment 1, in which the iner-
BIC, median soft-maximization weighting parameter estimates θs.                                                                                                  tia in judgments might have arisen from subjects’ response
N best fit according to BIC, and average final judgment accuracy for                                                                                             laziness (i.e., not being bothered to change links) rather than
those best fit.
                                                                                                                                                                 inferential heuristics.
 Model                                   BIC                 Rsq               θ1                θ2                         N fit                Accuracy Participants          111 UCL undergraduates (mean±SD age
 Baseline                                104535              0                                                              0                                    18.7 ± 0.9, 22 male) took part in Experiment 2 as part of a
 P(M|D, S, B)                            91629               0.13              8                                            0
 L                                       97532               0.07                                2.9                        0                                    course. They were incentivized as previously, but this time
 A                                       98152               0.07                                -1                         1                    .33             with the opportunity to win Amazon vouchers rather than
 E∗                                      80406               0.24              -4.3                                         1                    .33             money directly. They were split randomly into 8 conditions
 E                                       58892               0.44              -2.2                                         35                   .33
 E∗ L                                    73047               0.31              -4.6              3                          1                    .49             mean size 13.8 ± 3.4.
 E∗ A                                    74202               0.3               -4.4              -1.1                       1                    .31
 EL                                      51146               0.52              -2.4              4                          60                   .63             Design and procedure Experiment 2 used the same task in-
 EA                                      51665               0.52              -2.4              -1.3                       51                   .56             terface as Experiment 1, but focused just on the three variable
                                                                                                                                                                 problems. There were two background noise conditions B ∈
Model fit results and discussion                                                                                                                                 [.1, .25] and two causal strength conditions S ∈ [.9, .75]. How-
                                                                                                                                                                 ever, unlike in Experiment 1, participants were not trained on
These results show that the large majority of participants are
                                                                                                                                                                 these parameters, but only told that: “the connections do not
best described by variants of the structural change model
                                                                                                                                                                 always work”, and “sometimes components can activate by
of causal judgment that simply balances judgment inertia
                                                                                                                                                                 chance”.
against a desire to accommodate the latest evidence. Partic-
ipants were split fairly evenly between being better captured                                                                                                       To assess the influence of laziness, we examined two re-
by the true likelihoods L compared to the simple explanatory                                                                                                     porting conditions between subjects: remain and disappear.
inadequacy A proxy. Furthermore, estimated S∗ and B∗ val-                                                                                                        In the remain condition, judgments stayed on the screen into
ues were less variable over conditions than the true values                                                                                                      the next test, so participants did not have to change anything if
and stronger and sparser on average (Figure 3c), in line with                                                                                                    they wanted to register the same judgement at t as at t − 1. In
the idea that participants relied on simplifying assumptions                                                                                                     the disappear condition, the previous judgment disappeared
over trained likelihoods. No participant was best described                                                                                                      as soon as participants entered a new test. They then had
by soft-maximising over the Bayesian posterior. Participants                                                                                                     explicitly to select what they wanted for every connection
with average accuracy levels at chance were predominantly                                                                                                        after each test.2 At the end of the task, people were asked
best captured by the E only model, indicating that their judg-                                                                                                   to estimate, in 100 tries how often: “components turn on by
ments were sequentially dependent but did not meaningfully                                                                                                       themselves?” (B) and “how often do the causal connections
reflect the data. The better fit for models using edit distance
                                                                                                                                                                     2 We
E rather than E ∗ suggests that participants do not just stick                                                                                                            also elicited additional judgments about expected outcomes
                                                                                                                                                                 of interventions, confidence in individual connections and ’helpful-
with the same model, but rather tend to make local, rather                                                                                                       ness’ of each outcome; however we do not report on these here for
than drastic, changes.                                                                                                                                           space reasons.
                                                                                                                                                           266

work?”(S).                                                                 Second, while participants’ judgments showed high se-
                                                                        quential dependence, they did occasionally change their
Results and modeling                                                    model abruptly. The theory of unexpected uncertainty (Yu
Performance in Experiment 2 was comparable to the 3-                    & Dayan, 2003), and substantial work on changepoint tasks
variable problems in Experiment 1. For example, mean±SD                 (Speekenbrink & Shanks, 2010) are associated with the no-
accuracy in Experiment 2, [B = 0.1, S = 0.75] was .63 ± 0.27            tion that people will sometimes “start over” if they are hav-
and [B = 0.25, S = 0.75] was .58 ± 0.31 while Experiment 1              ing consistently poor predictions from their existing model
condition 5 [B = 0.15, S = 0.85] was .60±0.33. This suggests            (Lakatos, 1976). Experiments in which the underlying struc-
that people can make reasonable structure judgments with-               ture changes over time would provide pointers.
out knowledge of exact parameters. Supporting these con-                   Finally, we did not examine the selection of interventions,
clusions – participants’ final judgments of S and B suffered            but only how to learn from them. Participants’ interventions
bias and variance: for B = {.1; .25} the mean±SD estimates              were far from perfectly efficient – in 100 simulations of the
were {.37 ± .24; .48 ± .20} respectively; for S = {.9, .75},            task, an active learning algorithm that selects interventions
mean±SD estimates were {.75 ± .21; .64 ± .23}.                          greedily to minimize its expected uncertainty over the space
   As with Experiment 1, participants were affected by higher           of possible structures, and updates beliefs optimally, achieves
levels of background noise B t(108) = 2.7, p = 0.008, but not           considerably higher final accuracy (mean 0.81, see white cir-
the reliability of the links themselves S t(106) = 0.88, p =            cles in Figure 3) compared with what could be achieved given
0.37, and there was no difference in performance between                the data participants actually saw (mean 0.69). This also
the two judgment elicitation conditions t(108) = 0.67, p =              raises further important questions.
0.50. Analysis of variance revealed an effect of condition
on final judgment accuracy F(7, 103) = 2.87, η2 = 0.16, p =             Acknowledgements PD was supported by the Gatsby
0.008 with a significant interaction between S and judgment             Charitable Foundation.
type, with a .21 additional drop in accuracy going from S=0.9
                                                                                                            References
to S=0.75 in the disappear condition compared to the remain             Bramley, N. R., Gerstenberg, T., & Lagnado, D. A. (2014). The order of things: Infer-
condition.                                                                 ring causal structure from temporal patterns. In P. Bello, M. Guarini, M. McShane,
                                                                           & B. Scassellati (Eds.), Proceedings of the 34th annual conference of the cognitive
   To check if the structure change model in Experiment 1                  science society (p. 236-242). Austin, TX: Cognitive Science Society.
                                                                        Bramley, N. R., Lagnado, D. A., & Speekenbrink, M. (2014). Forgetful conserva-
was driven by lazy reporting, we fit the models as before3 .               tive scholars - how people learn causal structure through interventions. Journal of
We found that once again the large majority of participants                Experimental Psychology: Learning, Memory and Cognition.
                                                                        Buchanan, D. W., Tenenbaum, J. B., & Sobel, D. M. (2010). Edge replacement and
were fit by variants of the structural change model, both when             nonindependence in causation. In Proceedings of the 32nd annual conference of the
                                                                           cognitive science society (pp. 919–924).
judgments remain (47/53) and when they disappear (48/58),               Cheng, P. W. (1997). From covariation to causation: A causal power theory. Psycho-
this time with a larger proportion better fit by EL than EA                logical Review, 104, 367-405.
                                                                        Coenen, A., Rehder, B., & Gureckis, T. (2014). Decisions to intervene on causal systems
(32/47 for remain and 32/48 for disappear conditions), sug-                are adaptively selected. In P. Bello, M. Guarini, M. McShane, & B. Scassellati
                                                                           (Eds.), Proceedings of the 34th annual conference of the cognitive science society.
gesting some sensitivity to the noisy-or aspect of the likeli-             Austin, TX: Cognitive Science Society.
hoods at least for three variable problems. 5/53 and 10/53 in           Cooper, G. F., & Herskovits, E. (1992). A Bayesian method for the induction of proba-
                                                                           bilistic networks from data. Machine learning, 9(4), 309–347.
the remain and disappear conditions respectively were best fit          Courville, A. C., & Daw, N. D. (2007). The rat as particle filter. In Advances in neural
                                                                           information processing systems (pp. 369–376).
by the model based on the Bayesian posterior P(D|M).                    Fernbach, P. M., & Sloman, S. A. (2009). Causal learning with local computations.
                                                                           Journal of experimental psychology: Learning, memory, and cognition, 35(3), 678.
                                                                        Higgins, J. J. (2004). An introduction to modern nonparametric statistics. Brooks/Cole
                     General Discussion                                    Pacific Grove, CA.
                                                                        Lagnado, D. A., & Sloman, S. (2004). The advantage of timely intervention. Journal
In sum, people were able to learn complex causal models,                   of Experimental Psychology: Learning, Memory & Cognition, 30, 856–876.
but exhibited strong sequential dependence and variability              Lagnado, D. A., & Sloman, S. A. (2006). Time as a guide to cause. Journal of experi-
                                                                           mental psychology. Learning, memory, and cognition, 32(3), 451–60.
in their judgments. These patterns were well-captured by a              Lakatos, I. (1976). Falsification and the methodology of scientific research programmes.
                                                                           In Can theories be refuted? (pp. 205–259). Springer.
heuristic model, inspired by “Neurath’s ship”, that maintains           Liu, J. S., & Chen, R. (1998). Sequential monte carlo methods for dynamic systems.
                                                                           Journal of the American statistical association, 93(443), 1032–1044.
a single model, and attempts to account for incoming evi-               Lu, H., Yuille, A. L., Liljeholm, M., Cheng, P. W., & Holyoak, K. J. (2008). Bayesian
dence by making local changes. However, we have not yet                    generic priors for causal learning. Psychological review, 115(4), 955.
                                                                        Mayrhofer, R., & Waldmann, M. R. (2011). Heuristics in covariation-based induction of
provided a plausible process model for the local search.                   causal models: Sufficiency and necessity priors. In Proceedings of the 33rd annual
                                                                           conference of the cognitive science society (pp. 3110–3115).
   The model is still too simple in at least three respects. First,     Pearl, J. (2000). Causality. New York: Cambridge University Press (2nd edition).
it assumes no memory of past evidence beyond the insuffi-               Quine, W. v. O. (1969). Word and object. MIT press.
                                                                        Sanborn, A. N., Griffiths, T. L., & Navarro, D. J. (2010). Rational approximations to
cient statistic of the current causal model. It is likely that             rational models: alternative algorithms for category learning. Psychological review,
                                                                           117(4), 1144.
subjects can remember some past experience, and combine                 Speekenbrink, M., & Shanks, D. R. (2010). Learning in a changing environment.
it with the current datum when updating their beliefs. Of                  Journal of Experimental Psychology: General, 139(2), 266.
                                                                        Steyvers, M. (2003, June). Inferring causal networks from observations and interven-
course, outside the lab setting, it is unlikely that our expe-             tions. Cognitive Science, 27(3), 453–489.
                                                                        Vul, E., Goodman, N. D., Griffiths, T. L., & Tenenbaum, J. B. (2009). One and done?
rience relevant to single causal models is adequately contigu-             optimal decisions from very few samples. In Proceedings of the 31st annual confer-
ous for this to be very useful in practice.                                ence of the cognitive science society (Vol. 1, pp. 66–72).
                                                                        Yu, A., & Dayan, P. (2003). Expected and unexpected uncertainty: ACh and NE in the
    3 For P(D|M) we used importance sampling with 20,000 particles         neocortex. Advances in neural information processing systems, 173–180.
to marginalize over S and B, updating a density for each over the
course of the 36 trials in the task.
                                                                    267

