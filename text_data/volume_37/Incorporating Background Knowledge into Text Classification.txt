                  Incorporating Background Knowledge into Text Classification
                       Reihane Boghrati, Justin Garten, Aleksandra Litvinova, Morteza Dehghani
                                               boghrati, jgarten, alitvino, mdehghan@usc.edu
                                                       University of Southern California
                                                         Los Angeles, CA 90089 USA
                               Abstract                                    humans living in warmer areas, a robin might be a typical
   It has been shown that prior knowledge and information are              member of the category ‘birds‘, whereas for Eskimos a pen-
   organized according to categories, and that also background             guin might be a more typical member of the same category.
   knowledge plays an important role in classification. The pur-           Besides studying the way certain objects are assigned to cate-
   pose of this study is first, to investigate the relationship be-
   tween background knowledge and text classification, and sec-            gories, investigating how categories are organized yields rel-
   ond, to incorporate this relationship in a computational model.         evant information about the structural organization of knowl-
   Our behavioral results demonstrate that participants with ac-           edge in the human mind. An experiment conducted by Rosch,
   cess to background knowledge (experts), overall performed
   significantly better than those without access to this knowledge        Mervis, Gray, Johnson, and Boyes-Braem (1976), asked sub-
   (novices). More importantly, we show that experts rely more             jects to list features common to most objects from the cate-
   on relational features than surface features, an aspect that bag-       gories ‘furniture‘, ‘table‘ and ‘kitchen table‘, in order to in-
   of-words methods fail to capture. We then propose a compu-
   tational model for text classification which incorporates back-         vestigate whether a certain level of a category is more preva-
   ground knowledge. This model is built upon vector-based rep-            lent than another level. On average participants named 3 fea-
   resentation methods and achieves significantly more accurate            tures from the global level ‘furniture‘, 9 features from the
   results over other models that were tested.
                                                                           basic level ‘table‘ and 10.3 features from the specific level
   Keywords: text classification; background knowledge; dis-
   tributed representation; similarity                                     ‘kitchen table‘. Based on those results Rosch et al. (1976)
                                                                           argued that the basic category level is, from a psychological
                           Introduction                                    perspective, the most informative level, since the global level
The fcat taht radeers are slitl albe to uansdrnetd tihs txet,              provides relatively less information (3 vs. 9) and the spe-
aoughlth it is is far form benig galarlmticmy cecorrt, iull-               cific level only marginally more information than the basic
startes how peoicerptn, cetagotizroain and unedranstding is                level. More recent approaches to knowledge categorization
ienfueldcd by piror kowlndgee. Previous research on the or-                focus on the relationships between concepts and categories.
ganization of knowledge in the human mind has proposed                     Rottman, Gentner and Goldwater (2012) examined the classi-
that knowledge is saved in form of concepts and organized                  fication differences between novices and experts in the phys-
according to categories (Smith, 1995). However, how cer-                   ical sciences. In their experiment, students were asked to
tain categories are formed, and according to which criteria                sort descriptions of real-world phenomena varying in causal
humans place objects into categories, has been a challenge                 structures (e.g. common cause vs. causal chain) and in con-
for cognitive science. The first intuitive approach that comes             tent domain (engineering vs. biology). Their results showed
to mind, categorizing objects according to their superordinate             that novices in physical sciences sorted descriptions based
definition, leads to a huge bag of miscellaneous words, since              on the content domain, whereas experts sorted those descrip-
it is for example not so easy to define what makes a bird a                tions according to their causal structure, thereby emphasiz-
bird. Some birds can fly, others have wings, but cannot fly                ing the importance of causal relationships in knowledge or-
(e.g. penguins) and some animals can fly but are not birds                 ganization. Moreover, in a series of studies, Bang, Medin
(e.g. bats). The underlying difficulty is that not all mem-                and Atran (2007) demonstrated the role of culture and expe-
bers of a category share the same features. Although, not all              rience in categorization-based reasoning, essentially arguing
members share the same features, Wittgenstein (1953) noted                 that “what people think about can affect how they think”.
that members of a category still resemble each other in some                  Given the vast amount of available data and increasing
way, which led to the emergence of the prototype approach to               computational power, our study aims to further investigate the
categorization. Rosch (1973) proposed that membership of a                 principles of human categorization of text, in order to inform
category is defined by the comparison of the object to the pro-            machine learning methods in the domain of natural language
totype of the category, where the prototype represents a blend             processing. More precisely we are interested in the differ-
of the most common category members. According to Rosch                    ent text classification patterns between novices and experts.
(1973), an object that closely resembles the prototype image               Based on previous research by Rottman et al. (2012), we
of a category will be more likely to be classified according to            hypothesize that novices categorize similar text according to
that category than an object that has only little resemblance.             surface features, whereas experts classify similar text accord-
However, this theory cannot explain why a Pomeranian dog,                  ing to deeper relational features. In other words, we assume
that actually has more resemblance with a cat than a dog, is               that the background knowledge of experts allows them to take
nevertheless categorized as a dog. Furthermore, a typical rep-             into account more relational features for the classification of
resentation of a category strongly depends on context. For                 similar texts, whereas novices are forced to rely on surface
                                                                       244

features of the content.                                                An army colonel and his new wife are coming to visit their
   We begin by discussing our behavioral experiment which               relatives, who live in a small apartment complex. Mom wants
                                                                        to make sure that they get the best treatment possible, and ar-
investigates the role of background knowledge in text clas-             ranges for a big feast. The mother is stressing because she is
sification. Next, we summarize recent developments in dis-              poorer and wants to impress the colonel. The father is a cinema
tributed representations of text. Then we describe our com-             projectionist and tries to create fun for the guests. They have
                                                                        little food for a banquet, which stresses mom even more. Her
putational model and our second experiment. Finally, we dis-            little son goes to steal food but the shop owner finds out and
cuss the shortcomings of the model and future work.                     kick he and his friend out, later on he feels sympathetic and
                                                                        brings the food for mom. They live around a bunch of neigh-
                        Experiment 1                                    bors including an old lady with chickens, a pharmacology stu-
                                                                        dent studying for an exam the next day, a couple that argues,
The goal of the first study is to explore the role of background        and some other people. There’s a lot of yelling and chaos, but
                                                                        everybody will come together and help mom to cook for din-
knowledge in text classification with a behavioral experiment.          ner, and somehow, everything works out. At the end colonel
The result of this experiment will guide our computational              and his new wife want to leave, and mom secretly wants them
modeling work in the next section. In both experiments, we              to leave, but every time they try to leave, everybody asks them
                                                                        to stay, just because it is the polite thing to do. Accidentally
are interested in the classification of movie reviews.                  mom doesnt feel good, and they take her to hospital. When
   In this study, we examine how a group of participants with           they come back, they each go to their room, turn off the lights
no background knowledge about a set of movies (novices)                 and sleep.
differ from those who have access to more relational knowl-
edge about the movies (experts). Based on previous findings          Figure 1: Example of one of the training articles read by par-
(Rottman et al., 2012), our assumption is that the existence         ticipants in the expert condition
of background knowledge would allow experts to perform
more accurate classifications, as they base their classification
more on relational features compared to novices, who might
                                                                     movie but because they point to different aspects of the
only be able to categorize according to surface differences. In
                                                                     movie, and use different words to describe it, the features
other words, we expect that access to background knowledge
                                                                     tend to be different. The second category was the oppo-
would result in classification based on relational features, and
                                                                     site: both the surface features and relational features of the
incorporating this finding into computational models would
                                                                     reviews were the same. Although the reviews might have de-
increase classification performance.
                                                                     scribed different movies, but they used a number of similar
Method We designed a simple task in which participants               and shared words and relations. The other two categories had
were asked to decide whether a set of movie reviews belonged         either surface features in common or relational features.
to the same movie or not. In order to make sure none of              Participants 152 participants located in the US were re-
the participants had seen the movies they were being tested          cruited from Amazon Mechanical Turk. 76 participants were
on, we chose a set of foreign language movies and reviews            randomly assigned in the novice condition and 76 in the ex-
not belonging to mainstream blockbusters. Participants were          pert condition. After making sure that none of the subjects are
divided into two groups: novices and experts. Prior to per-          familiar with the movies, participants in the expert condition
forming the classification task, participants in the expert con-     first had to read a summary about each movie before complet-
dition, read full-length articles containing the storyline, plot     ing the survey, whereas participants in the novice condition
and highlights of each movie. Further, after reading each arti-      were immediately directed to the survey, without receiving
cle, they were asked a few questions about the article to make       background knowledge on the movies.
sure that they had actually read the article. An example of the
articles we used is given in figure 1.                               Results Overall, participants in the expert condition were
                                                                     able to make significantly more correct classifications than
   Next, for each question, participants were asked to se-
                                                                     participants in the novice condition t(142)=3.44, p=0.0008.
lect all of the reviews that they thought belong to the same
                                                                     In other words, experts made fewer errors in classifying
movie. Overall, participants were tested on reviews from four
                                                                     movie reviews.
movies. Each question, had exactly two out of three options
that matched the same movie. A sample of the classification             Specifically, experts answered those questions which had
tasks is shown in figure 2.                                          similar surface features for all three reviews significantly bet-
   We systematically varied the type of similarity between the       ter than novices t(133)=3.13, p=0.002. This observation sug-
movie reviews, where the reviews either matched in surface           gests that novices, who rely on surface features can easily
similarity, in structural similarity, or in both. Apparent fea-      be distracted by common words shared among the reviews.
tures regarding a movie such as the cast members or filming          On the other hand, experts who look for deeper features and
locations were considered as surface features, while details         do not rely only on surface features, were more successful in
such as the relation between the actors or inferences made           picking the reviews which belonged to the same movie.
from the plot were categorized as relational features.                  Experts, however, did not essentially do better on the ques-
   In the group where both surface and relational features           tions where relational features were shared among reviews
were different, although the reviews might describe the same         t(148)=0.83, p=0.4. This result shows that when reviews have
                                                                 245

   Question: From the reviews below, please select all the re-            guage processing (Bengio, Courville, & Vincent, 2013;
   views which you think are about the same movie. (It can                Mikolov, 2012; Socher, Bauer, Manning, & Ng, 2013) and
   be two, three, or none of them) (Different relational fea-
   tures/Similar surface features)                                        cognitive modeling (Serre, Oliva, & Poggio, 2007).
   1- (LEILA) The sound and the visuals aren’t groundbreaking,               In this process, a number of approaches, new and old, have
   but it gets the job done. There are occasional funny parts stuck       been explored for the generation of these representations. On
   in there (especially with the main role’s uncle). The movie
   gives one a good glimpse of upper middle-class society in Iran.        the neural network side, modern algorithmic improvements
   2- (MUM’s GUEST) In this movie, the director has shown an              (Krizhevsky, Sutskever, & Hinton, 2012) have been com-
   Iranian little society with its all humors. You could find in this     bined with a range of training approaches in systems such
   movie, one social stratum of Iranian people, all have their own
   problems, and how they live together.                                  as Word2Vec (Mikolov, Chen, Corrado, & Dean, 2013). Ap-
   3- (MUM’s GUEST) This movie is both a social comedy and a              proaches based on building and then reducing the dimension-
   love letter to cinema. Mum’s husband is a cinema projection-           ality of large co-occurrence matrices such as Latent Semantic
   ist in Iran who, together with his colleagues in a memorable
   scene, recite music and dialog from classic films.                     Analysis (LSA) (Deerwester, Dumais, Landauer, Furnas, &
                                                                          Harshman, 1990) have received renewed attention. And tech-
                                                                          niques from topic modeling such as Latent Dirichlet Alloca-
Figure 2: Example of one of the questions answered by par-                tion (LDA) (Blei, Ng, & Jordan, 2003) have been explored
ticipants in the two groups                                               for the creation of distributed representations.
                                                                             As techniques for the generation of individual word rep-
                                                                          resentations have matured, focus has increasingly shifted to-
common relational features, experts, who are looking for re-              wards composing these representations to capture the mean-
lational features, are distracted with the similarity of the fea-         ing of larger pieces of text. This has proved particularly im-
tures and cannot predict accurately.                                      portant in application areas such as sentiment analysis (Pang
Discussion Comparing the two groups, our results indicate                 & Lee, 2008) where handling issues like negation is criti-
that overall people who had read articles about the movies,               cal. A number of approaches have been explored to com-
performed significantly better than our novice group. More                positionality including additive compositionality (Mikolov,
importantly, analyzing based on type of similarity revealed               Sutskever, Chen, Corrado, & Dean, 2013) recursive deep net-
that this higher performance was due to the ability to cat-               works (Socher, Perelygin, et al., 2013), and matrix-vector
egorize based on relational features, and not due common                  representations (Socher, Huval, Manning, & Ng, 2012).
words and shared surface features. In the questions in which                 We focus here on a particular line of work which combines
all three reviews had similar relational features, there was no           word and context information through the usage of distribu-
significant difference between experts and novices.                       tional representations for context. In particular, we look at the
   Our finding demonstrates how access to some textual                    Paragraph Vector (Le & Mikolov, 2014) method which simul-
knowledge can affect classification in subsequent tasks.                  taneously learns representations for words and larger textual
Moreover, it shows that simply relying on surface features                contexts (generically: “paragraphs“). Words are represented
cannot help us distinguish between items which have rela-                 as columns in a matrix W and paragraphs as columns in a ma-
tional commonalities, but do not share the same words. In                 trix D. Given a sequence of words, the model either averages
other words, this experiment provides an explanation why                  or concatenates the previous window of words with the local
simple bag-of-words approaches to text classification may not             paragraph vector (Figure 3a). The resulting vector is used as
only fail to capture human approaches to simple text classi-              the input to a hierarchical softmax classifier (Morin & Ben-
fication tasks, but also how poorly they would perform when               gio, 2005) which predicts the next word in the sequence. The
obvious relational features exist between the groups.                     paragraph and word vectors are trained with stochastic gra-
                                                                          dient descent using backpropagation (Rumelhart, Hinton, &
                Distributed Representations                               Williams, 1986).
                                                                             A variant of this model was released (Mikolov, 2014)
Representation of conceptual knowledge has been a key chal-
                                                                          which combined the use of context vectors with the base
lenge for the development of cognitive models. One major
                                                                          code for the Word2Vec program. This allowed the usage of
approach to this issue has come in the form of distributed
                                                                          the Skip-gram model for learning the word representations
representations, where words or concepts are represented in
                                                                          and the replacement of the hierarchical softmax with nega-
the form of n-dimensional vectors. This approach has been
                                                                          tive sampling (Goldberg & Levy, 2014). These changes led
used extensively in connectionist models starting with Par-
                                                                          to slight overall improvements in system performance.
allel Distributed Processing (McClelland, Rumelhart, Group,
et al., 1986) where distributed representations fit naturally as
corresponding to the weights of nodes in the neural networks
                                                                                                  Experiment 2
(whether as inputs, outputs, or in hidden layers).                        Computational text classification has been widely studied
   In part driven by the resurgence of neural networks in re-             from both semantical and syntactical aspects. In some classi-
cent years, distributed representations have seen widespread              fication settings, instead of using a training dataset, the mod-
adoption with applications across the fields of natural lan-              els rely on predefined set of features or words (Sagi & De-
                                                                      246

hghani, 2014). Even though, this might be considered a first         movie. For the first setting, this was achieved by only calcu-
step towards incorporating background knowledge into text            lating the cosine similarity of the reviews against one another,
classification, here we take a step further. As demonstrated in      and if the similarity score was above a threshold, then the
the first experiment, background knowledge can have a major          model categorized them as belonging to the same movie. In
role in classification. The goal of our modeling effort is to        the second setting, it also needed to determine the most sim-
investigate how background knowledge can get incorporated            ilar article to each of the movie reviews (based on the cosine
into vector-based models of words representation, and to in-         similarity of their vector representations). This setting pre-
vestigate whether or not incorporating such knowledge can            dicted whether two reviews are about the same movie, based
result in more accurate classifications.                             on both their individual cosine similarity to one another and
                                                                     the movies they were mapped to.
Our Model As discussed previously, Word2Vec and para-
graph vector algorithms both use neural networks to train vec-
                                                                        For our model, we generated the vector representation of
tor representation of words and documents, treating all inputs
                                                                     the articles separately using paragraph vector method. These
(words and documents) similarly. In order to examine our hy-
                                                                     article vectors were used as matrix B in our model to provide
pothesis, we designed a modified version of these systems, al-
                                                                     background knowledge. We then ran our model by using the
lowing them to integrate background knowledge, and as a re-
                                                                     corpus of reviews along with the fixed article vectors. Similar
sult demonstrate improvements on the classification task. We
                                                                     to the second setting of the baseline model, the most similar
extend the Mikolov (2014) variation of the Paragraph Vec-
                                                                     movie to a review was determined by calculating the cosine
tor approach by adding an additional input vector represent-
                                                                     similarity of the review vectors with the article vectors. The
ing background knowledge. Background knowledge vectors
                                                                     model made a decision about whether two reviews belong to
are stored as columns in a new matrix B (Figure 3c), simi-
                                                                     the same movie based on the cosine similarity of the review
lar to the matrices D and W for document and word repre-
                                                                     vectors and the movies they were mapped to.
sentations. Matrix B and D are similar in the way they are           Result Table 1 shows the results of our experiment. Accu-
represented, with the difference being that, unlike matrix D,        racy was measured by calculating how many times the model
matrix B is static and does not change throughout the training       made the correct classification, i.e. it correctly predicted that
process. In other words, matrix B is present in the training         the two first reviews were about the same movie and were
of document and words vectors and it influences their vector         different from the third review. As shown in this table, clas-
representation, without being affected itself in this stage. Ma-     sifying text with no background knowledge (baseline, first
trix B can be thought of as a filter (or biasing lens), through      setting) reached to an accuracy of 32%. Adding the text
which new information gets interpreted based on background           of the articles to the reviews (baseline, second setting) in-
knowledge.                                                           creased the performance to 35%. Our model, achieved an
                                                                     accuracy of 41%, which is significantly higher than the sec-
Method To show the effectiveness of this method, and in-
                                                                     ond model(X 2 = 399, p < 0.001) and also the first baseline
vestigate whether it can model our behavioral results, we ex-
                                                                     (X 2 = 343, p < 0.001).
amined the performance of two different baseline word2vec
models and compared their results to our modified version
discussed above. We used 929 movie reviews from 30 dif-
ferent movies which were collected from Stanford Treebank                                                                 Proposed
corpus (Maas et al., 2011) as data for this experiment.                 Method       Chance     Baseline1     Baselin2
                                                                                                                           Model
   The experiment was designed to be similar to our behav-             Accuracy        20%        31%           35%         41%
ioral study. Each question had three reviews and the task
for the model was to predict which of the three reviews are                           Table 1: Computational Results
about the same movie. For each question, two of the reviews
were selected from one movie, and one review was selected
from another movie. Similar to the behavioral experiment,            Discussion The implications of this experiment are two
the model had the option to pick two of them, all or none of         fold: 1. Our results demonstrate that background knowledge
them.                                                                can significantly improve text classification 2. Simple bag-of-
   For the baseline models we used paragraph vector method           words techniques for incorporating knowledge may not work
to generate the vector representation of the reviews. In the         as well, and may lack cognitive plausibility. Even though our
first baseline setting (Figure 3a), only the reviews themselves      model has access to the same amount of information (text) as
were used for training. In the second setting (Figure 3b), we        the baseline model in the second setting, it significantly out-
used the reviews in addition to full-length articles about each      performed it. Specifically, we argue that background knowl-
movie for training the vectors. For this purpose, the text of        edge is treated differently than regular words used in a docu-
the articles were concatenated to the reviews, and fed to para-      ment, and should be used as an interpretive lens, rather than
graph vector method. In both of these settings, the models           similar to other documents. In our model the effect of back-
had to predict which of three reviews were related to the same       ground knowledge was fixed and present during the whole
                                                                     document vector training.
                                                                 247

                                   W                                                                     W
                    D        W           W       W                                         D         W       W         W
                            Reviews                                                         Reviews+Articles
                (a) Baseline, first setting framework.                                (b) Baseline, second setting framework.
                                               W                                              W
                                D         W       W       W             B         D       W        W        W
                                          Articles                                     Reviews
                                                             (c) Proposed model.
Figure 3: The three different evaluated vector models. 3.a: Paragraph vector model which receives the reviews as input and
trains the vector representation of each document. 3.b: A revised version of 3.a where the input to the neural network are the
reviews which are concatenated with their related movie articles. 3.c: Our proposed model, where the vector representation of
each article is calculated (left side of 3.c) and it is then provided to the right-side framework. Matrix B, which is a representative
of background knowledge, is fixed during the training process and is used to a biasing factor for the vector representation of the
reviews.
                          Conclusion                                     model would improve text classification accuracy. The task
                                                                         was to predict which of the three reviews were about the same
Using two experiments, we demonstrated a significant im-
                                                                         movie based on the cosine similarity of the document vec-
provement in text classification as a result of introducing
                                                                         tors. The results indicated that providing textual background
background knowledge. Specifically, we demonstrated: (1)
                                                                         knowledge to the computational model improves the accu-
improvement in text classification accuracy of human partic-
                                                                         racy of text classification. We built our model by adding the
ipants that were trained with some background knowledge
                                                                         background knowledge as a fixed vector to the neural net-
compared to novices, (2) the effect of incorporating back-
                                                                         work which was present during the document vector training
ground knowledge to a vector-based representation model.
                                                                         process. Our results indicate that our model achieved sig-
   In the first experiment, we asked participants to answer
                                                                         nificantly higher accuracy compared to the two first settings.
four text classification questions, in which experts, who
                                                                         This observation demonstrates that background knowledge
were trained to have some background knowledge about the
                                                                         should not be treated as simple bag-of-words, but it rather
movies, performed significantly better on classifying movie
                                                                         should be used as an interpretive lens through which other
reviews compared to novices. This indicates that when peo-
                                                                         texts get trained.
ple have textual prior information in a particular domain, they
can perform more accurate classifications. Furthermore, an-                 A particular application of our model could be culturally-
alyzing the results based on the similarity of relational and            specific text classification. Our model could potentially be
surface features throughout the reviews, we demonstrated that            used to investigate the role of cultural knowledge in text com-
when reviews shared common words and surface features, ex-               prehension and classification. Our prior work demonstrates
perts were able to select the reviews which belonged to the              that some cultural differences are evident even in how chil-
same movie based on their relational features. This proves               dren’s story books are written by different authors (Dehghani
the hypothesis that experts are able to identify deeper layers           et al., 2013). Our proposed model can be used to further in-
of similarity among reviews, while novices focus on surface              vestigate such differences.
features.                                                                   One limitation of this model is that it lacks a mechanism
   In the second experiment, we examined if incorporat-                  to form background knowledge or to update existing back-
ing background knowledge to a vector-based representation                ground knowledge. If this knowledge needs to be changed, or
                                                                     248

if it is context dependent, we would need to manually feed the       and their compositionality. In Advances in neural informa-
system with the newly fixed vectors representing background          tion processing systems (pp. 3111–3119).
knowledge. One way to address is to use delayed-updateting         Morin, F., & Bengio, Y. (2005). Hierarchical probabilistic
rather than fixed vectors.                                           neural network language model. In Aistats (Vol. 5, pp. 246–
                                                                     252).
                            References                             Pang, B., & Lee, L. (2008). Opinion mining and sentiment
                                                                     analysis. Foundations and trends in information retrieval,
Bang, M., Medin, D. L., & Atran, S. (2007). Cultural mosaics         2(1-2), 1–135.
   and mental models of nature. Proceedings of the National        Rosch, E., Mervis, C. B., Gray, W. D., Johnson, D. M., &
   Academy of Sciences, 104(35), 13868–13874.                        Boyes-Braem, P. (1976). Basic objects in natural cate-
Bengio, Y., Courville, A., & Vincent, P. (2013). Represen-           gories. Cognitive psychology, 8(3), 382–439.
   tation learning: A review and new perspectives. Pattern         Rosch, E. H. (1973). Natural categories. Cognitive psychol-
   Analysis and Machine Intelligence, IEEE Transactions on,          ogy, 4(3), 328–350.
   35(8), 1798–1828.                                               Rottman, B. M., Gentner, D., & Goldwater, M. B. (2012).
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirich-       Causal systems categories: Differences in novice and ex-
   let allocation. the Journal of machine Learning research,         pert categorization of causal phenomena. Cognitive sci-
   3, 993–1022.                                                      ence, 36(5), 919–932.
Deerwester, S. C., Dumais, S. T., Landauer, T. K., Furnas,         Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986).
   G. W., & Harshman, R. A. (1990). Indexing by latent               Learning representations by back-propagating errors. Na-
   semantic analysis. JAsIs, 41(6), 391–407.                         ture, 323, 533–536.
Dehghani, M., Bang, M., Medin, D., Marin, A., Leddon, E.,          Sagi, E., & Dehghani, M. (2014). Measuring moral rhetoric
   & Waxman, S. (2013). Epistemologies in the text of chil-          in text. Social Science Computer Review, 32(2), 132–144.
   dren’s books: Native-and non-native-authored books. In-         Serre, T., Oliva, A., & Poggio, T. (2007). A feedforward
   ternational Journal of Science Education, 35(13), 2133–           architecture accounts for rapid categorization. Proceedings
   2151.                                                             of the National Academy of Sciences, 104(15), 6424–6429.
Goldberg, Y., & Levy, O. (2014). word2vec explained: de-           Smith, E. E. (1995). Concepts and categorization.
   riving mikolov et al.’s negative-sampling word-embedding        Socher, R., Bauer, J., Manning, C. D., & Ng, A. Y. (2013).
   method. arXiv preprint arXiv:1402.3722.                           Parsing with compositional vector grammars. In In pro-
Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Im-           ceedings of the acl conference.
   agenet classification with deep convolutional neural net-       Socher, R., Huval, B., Manning, C. D., & Ng, A. Y. (2012).
   works. In Advances in neural information processing sys-          Semantic compositionality through recursive matrix-vector
   tems (pp. 1097–1105).                                             spaces. In Proceedings of the 2012 joint conference on em-
                                                                     pirical methods in natural language processing and com-
Le, Q. V., & Mikolov, T. (2014). Distributed repre-
                                                                     putational natural language learning (pp. 1201–1211).
   sentations of sentences and documents. arXiv preprint
                                                                   Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning,
   arXiv:1405.4053.
                                                                     C. D., Ng, A. Y., & Potts, C. (2013). Recursive deep models
Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., &
                                                                     for semantic compositionality over a sentiment treebank.
   Potts, C. (2011). Learning word vectors for sentiment anal-
                                                                     In Proceedings of the conference on empirical methods in
   ysis. In Proceedings of the 49th annual meeting of the as-
                                                                     natural language processing (emnlp) (Vol. 1631, p. 1642).
   sociation for computational linguistics: Human language
                                                                   Wittgenstein, L. (1953). Philosophical investigations. basil &
   technologies-volume 1 (pp. 142–150).
                                                                     blackwell. OxfordWittgensteinPhilosophical investigations
McClelland, J. L., Rumelhart, D. E., Group, P. R., et al.            Basil1953.
   (1986). Parallel distributed processing. Explorations in
   the microstructure of cognition, 2.
Mikolov, T. (2012). Statistical language models based on
   neural networks. Presentation at Google, Mountain View,
   2nd April.
Mikolov, T.           (2014).     Word2vec toolkit discussion
   board.          https://groups.google.com/d/topic/word2vec-
   toolkit/Q49FIrNOQRo/discussion.            (Last Accessed:
   2015-01-29)
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Ef-
   ficient estimation of word representations in vector space.
   arXiv preprint arXiv:1301.3781.
Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean,
   J. (2013). Distributed representations of words and phrases
                                                               249

