         Gaze is not Enough: Computational Analysis of Infant’s Head
    Movement Measures the Developing Response to Social Interaction
                                Lars Schillingmann (lars@ams.eng.osaka-u.ac.jp)
           Graduate School of Engineering, Osaka University, 2-1 Yamadaoka, Suita, Osaka, 565-0871 Japan
                                      Joseph M. Burling (jmburling@uh.edu)
         Department of Psychology, University of Houston, 126 Heyne Building Houston, TX 77204-5022 USA
                                         Hanako Yoshida (yoshida@uh.edu)
         Department of Psychology, University of Houston, 126 Heyne Building Houston, TX 77204-5022 USA
                                   Yukie Nagai (yukie@ams.eng.osaka-u.ac.jp)
           Graduate School of Engineering, Osaka University, 2-1 Yamadaoka, Suita, Osaka, 565-0871 Japan
                           Abstract
   Infant eye gaze is frequently studied because of its rel-
   evance as an indicator of early attention and learning.
   However, the coupling of eye gaze with an individual’s
   head motion is often overlooked. This paper analyzes
   how head motion develops within a social interaction
   context. To measure this interaction, we developed an
   approach that can estimate infant head motion from
   ego perspective recordings as they are typically provided
   by eye-tracking systems. Our method is able to quan-
   tify infant head motion from existing social interaction
   recordings even if the head was not explicitly tracked.
  Therefore, data from longitudinal studies that has been
   collected over the years can be reanalyzed in more detail.
  We applied our method to an existing longitudinal study         Figure 1: Visualization tool displaying a history of frames
   of parent infant interaction and found that infants’ head      with corrected horizontal and vertical camera motion.
   motion in response to social interaction shows a devel-
   opmental trend. Furthermore, our results indicate that
   this trend is less visible within gaze data alone. This
   suggests that head motion is an important element for          also performing large shifts in head orientation in a short
   understanding and measuring infants’ behavior during           amount of time. For example, during gaze switching be-
   parent-child interactions.                                     tween the caretaker’s face and an object. Eye gaze alone
   Keywords: head motion; gaze; computational analysis;           is not sufficient to reach this flexibility in all situations.
   parent infant interaction                                     What we do not yet know is how social interactions be-
                                                                  tween the parent and infant play a role in facilitating
                       Introduction                               the development of head movements. In this paper, we
Head control is important developmental milestone for             investigate how the development of these kinds of head
human infants. We move our head when we track ob-                 movements emerges from specific social referencing con-
jects and must be able to coordinate it with our body             texts of parents naming and acting on objects. We use a
when reaching and grasping. The development of such               corpus that was a part of a lager project conducted by
capabilities can be seen in the first few months of in-           Yoshida and Burling (2013). Infants from 6 to 24 months
fancy where infants’ head movement patterns change                of age play with their mother who shows toys and objects
and become more controlled around 3 months of age (de             from a predefined set. This allows analyzing infant head
Lima-Alvarez, Tudella, van der Kamp, & Savelsbergh,               motion while differentiating interaction conditions—for
2014). When 6-month old infants follow a target, on               example, when the parent is holding the object.
average their head moves nearly as much as the object                Like a number of observation studies aiming to track
does (Jonsson & Von Hofsten, 2003). Furthermore, head             children’s attention, this data set includes measurements
control is an important factor in the development of              of infants’ gaze by using a head-mounted eye-tracking sys-
reaching to provide a stable support for gazing at the            tem, but does not contain instrumentation for detecting
target (Bertenthal & von Hofsten, 1998).                          head position. The present study specifically considers
   Head movements are also relevant for social communi-           this limitation. A trivial solution would be to conduct
cation. For children it is crucial to be able to follow their     another study and include additional sensors or a track-
caretaker’s social references. This ability does not only         ing system to record the infants head pose. However,
require following objects by eye movements alone, but             longitudinal studies are time and resource intensive. Fur-
                                                              2104

                                                                     Head Motion Extraction
                                                                       Head Camera                    Eye-Tracking
                                                                         Video Data                       Data
                                                                       Cropping and
                                                                         Calibration
                                                                         Global Motion
                                                                           Estimation
                                                                      (ffmpeg + vidstab)
Figure 2: Debug visualization of the vid.stab library                      Global Motion Vectors      Visualization
(Martius, 2014) showing blocks with sufficient contrast
and estimated vectors.                                               Gaze and Head
                                                                     Motion Processing
thermore, some tracking systems can induce additional                 Interaction Condition        Smoothing and Selection
                                                                            Annotation           of Frames for Each Condition
difficulties in conducting a study, as they might distract
infants. A common option to solve this problem is to
rely on third person view recordings of the infant and                              Average Head             Average Gaze
                                                                                       Activity                  Activity
to apply video-based tracking methods (Delaherche et
al., 2012). However, third person view recordings, if not
taken from an ideal perspective, can contain segments           Figure 3: Process of estimating head motion and calcu-
where the tracking target is occluded. Another problem          lating the average head and gaze activity.
is that low resolution and the absence of markers can pose
difficulties for accurate head tracking. Therefore, we will     OpenCV methods (Bradski, 2000). The calibration infor-
propose a method that is able to directly extract head          mation is obtained from a separately recorded calibration
movements from a head mounted eye-tracking system.              pattern.
The current approach also enables previously collected          Global Motion Estimation The child centered view
data to be reanalyzed using this new method. Usually,           recorded by the eye-tracking device reflects head motion
head mounted eye-tracking systems record an ego per-            during infant head rotations. Assuming an infant does not
spective video which is subsequently used to overlay the        change location, the global motion from frame to frame
tracking data, so it can be understood where the person         provides an estimation of the horizontal and vertical shift
was looking. Head movements can be estimated from a             due to head rotation. Stabilizing a shaky video requires
head mounted camera by using optical flow to find shifts        frame-by-frame estimation of global motion to shift each
between subsequent frames. Similar techniques have              frame to compensate the shaking motion accordingly.
already been applied in analyzing differences between           Open-source software can be used for solving this problem.
parent and infant visual experiences (Raudies, Gilmore,        We used the vid.stab library (Martius, 2014) that can be
Kretch, Franchak, & Adolph, 2012). We will demonstrate          used by FFmpeg (FFmpeg, 2014) to motion compensate
how open source video stabilization software can be used        shaky video. Usually the main task of the library is to
to estimate head motion from ego perspective recordings.        estimate global motion transformations in a first pass
   In summary, this paper will address the following ques-      and then apply them in a second pass to render a new
tions. Does infant head motion change over the course of        deshaked video. For our purpose, we use the library’s
development under different interaction conditions? Can         debug output to retrieve the global motion vectors. The
this trend also be found on gaze data alone? How can we         advantage of using a video stabilization library is that
measure head motion from ego perspective recordings?            the implementation is already tuned to the task of global
                                                                motion estimation. The vid.stab library uses several
Head Motion Extraction Based on Video                           heuristics to minimize noise due to low contrast areas
              Stabilization Techniques                          and moving elements in the video. The basic approach
                                                                relies on block matching. First, a coarse-grained motion
In the following sections, we describe our method of            search using a large block size is performed. Subsequently,
estimating children’s head motion from head-mounted             the search is refined towards local motion by using smaller
camera recordings. The process is depicted in Figure 3.         blocks (see Figure 2). The global motion is estimated by
Cropping and Calibration Before the videos were                 finding a transformation that minimizes the error to the
processed we cropped and calibrated the video data to           local motion fields. Outliers that potentially correspond
remove black borders and lens distortion using standard         to moving objects are excluded. A possible limitation
                                                            2105

                                                                       mx
                                                                           my
                                                                                  gy
                                                                                     gx
Figure 4: Exemplary third person view of the experimen-        Figure 5: Schematic visualization of gaze and motion
tal setting.                                                   vector components.
of this approach is the limited search width. Thus, very       vectors by taking the first derivative before smoothing. To
fast head rotations cannot be captured. Another problem        measure the development of infant’s head motion activity
can be local object movement that covers most of the           we define a measurement that will be used to summarize
camera’s viewing angle. In this case, object motion might      each trial under the different annotated conditions. We
be incorrectly registered as global motion.                    use the Euclidean norm to calculate the magnitude of each
                                                               motion vector m ~ per frame at time step t (see Figure 5).
Visualization To verify that the head motions were             The average head motion activity (HMA) per trial is the
correctly estimated, we developed our own visualization        mean of these magnitudes:
and analysis tool which projects each video frame into an
egocentric view using the estimated global motion infor-                                N q
                                                                                     1 X              2         2
mation (see Figure 1). In contrast to the standard video                   HMA =              mx (t) + my (t)           (1)
                                                                                     N t=1
deshaking approach, we specifically aimed to project a
low-resolution frame onto a larger surface to maintain the
frame’s original resolution. Thus, the tool reads video           Each infant’s average gaze activity (GA) is measured
frames and displaces them according to their global mo-        analogously based on the gaze shift vector ~g (see Fig-
tion into a high-resolution frame. Rotations are ignored       ure 5):
                                                                                        N q
due to their relatively low accuracy. Furthermore, the                               1 X            2         2
                                                                              GA =            gx (t) + gy (t)           (2)
tool integrates the gaze data into this view. With this                             N t=1
tool, we verified if the head motions were correctly es-
timated. The accuracy is locally sufficient to render a           If the number of frames matching a certain condition is
scene as in Figure 1 which extends the camera’s field          below 100 the corresponding average activity is excluded
of view by overlaying the current frame over the past          from the analysis due to lack of sufficient samples.
renderings. Since the approach cannot measure the ab-
solute head position, small errors accumulate over time.
                                                                                        Corpus
Therefore, this method is more useful to analyze head         We used 21 sessions from data collected by Yoshida and
motion dynamics instead of absolute positions. A more          Burling (2013). Infants from 6 to 24 months of age play
detailed quantitative evaluation will be an important          with their mother with the goal of learning the names
step to further develop the method but is omitted at this      of objects (see Figure 4). The mother has access to a
point.                                                         predefined set of objects where she uses toys of her choice
                                                               based on the current word to be learned by the children,
     Gaze and Head Motion Processing                           which is given by audio instruction. The mother is free to
                                                               choose any of the objects at any point during the session,
In this part we use the head motion vectors (m)
                                              ~ that were      and is instructed to interact as naturally as possible. The
extracted in the previous step and calculate the average       child is wearing a Positive Science eye tracker, which
head activity. The average gaze activity is calculated         records eye gaze and a video from the child’s perspective.
based on gaze vectors (~g ) from the eye tracking data.        The method described in this paper operates on this
Furthermore, an annotation is used to select frames that       video data. Furthermore, the corpus is annotated frame-
belong to different interaction conditions (see Figure 3).     by-frame providing a coding of the ongoing action. In
Both head motion and eye-tracking data is smoothed             this work, we focus on frames falling under the following
by fitting cubic splines to suppress high-frequency noise      conditions, which we define as social conditions: (1) the
using the R software (R Development Core Team, 2011).          infant is looking at the mothers face; (2) the mother is
The gaze coordinates are converted to relative gaze shift      holding a toy; (3) the mother is naming a toy.
                                                           2106

Table 1: Regression analysis results for the relationship       The only significant correlation can be found for the con-
between head activity and age                                   dition that the parent is naming a toy. The linear model
                                                                for the condition that parents are not naming a toy was
Condition                    R2    F               p
                                                                not significant. To further analyze the estimated linear
Parent Holding Toy           0.32  F(1,19)=8.92    0.01  **     models, we use the R2 statistic to compare how much of
Parent Not Holding Toy       0.01  F(1,19)=0.28    0.60         the variance of the underlying data is expressed by each
Child Gazing at Parent       0.24  F(1,17)=5.28    0.03  *      linear model. A large difference in the goodness of fit
Child Not Gazing at Parent   0.05  F(1,19)=1.01    0.33
                                                                was found when comparing the R2 values (see Figure 9),
Parent Naming Toy            0.26  F(1,16)=5.72    0.03  *
                                                                suggesting that this developmental trend depends on the
Parent Not Naming Toys       0.01  F(1,19)=0.24    0.63
                                                                social interaction condition. This difference is not visi-
                                                                ble for when the parent-holding-toy condition and the
                                                                child-gazing-at-parent condition.
Table 2: Regression analysis results for the relationship
between gaze motion and age                                        In general, several outliers are visible (see Figure 8).
                                                                Although, a minimum number of 100 frames matching
Condition                     R2    F               p           the condition is required for the mean activity to be
                                                                included in each linear model these outliers are caused to
Parent Holding Toy            0.16  F(1,19)=3.57    0.07
                                                                a relatively low number of frames matching the condition.
Parent Not Holding Toy        0.15  F(1,19)=3.45    0.08
Child Gazing at Parent        0.14  F(1,17)=2.71    0.12
                                                                In the child is gazing at the parent condition, the larger
Child Not Gazing at Parent    0.09  F(1,19)=1.90    0.18
                                                                gaze activity values can be caused by children only quickly
Parent Naming Toy             0.34  F(1,16)=8.25    0.01  *     looking to the mother and back.
Parent Not Naming Toys        0.05  F(1,19)=0.96    0.34           In Figure 6, a difference in head activity, if parents are
                                                                holding a toy, is visible for very young infants around 6
                                                                months of age. The head activity is lower compared to
   For each condition the complementary non-matching            the condition where parents are not holding a toy. We
condition is named non-social condition. The non-social         interpret this is due to scaffolding that parents perform
conditions include frames where the mother is not inter-        by holding the object directly in front of the child. This
acting with the child (e.g., putting a toy away).               effect is not visible for gaze activity (see Figure 8).
          Regression Analysis Results                                                   Discussion
To test for a developmental trend in head activity, linear      In the present work, we used developmental data con-
models for the infant’s age were estimated for each social      cerning children’s visual experiences. We proposed a new
and non-social condition (see Table 1). The individual          alternative method using video stabilization techniques
models are visualized in Figure 6. In this figure each chart    to extract commonly missing information such as head
displays the relationship of age and average head activity      movement from this data. New methods for studying
per subject on frames within a given condition. The gray        development using head-mounted eye-tracking have been
area indicates a 95% confidence interval of the regression      gradually emerging over time (Franchak, Kretch, Soska,
line. All three conditions show significant correlations        & Adolph, 2011; Kretch & Adolph, 2014). Our method
suggesting that head activity plays an increasing role in       can provide additional detail and new ways of analyzing
social interactions as infants develop. For the conditions      these data. An important use-case is the reanalysis of
that children look at the mothers face and the mother is        existing longitudinal studies where repeating the study is
naming a toy the correlations were significant. A strongly      costly. Our visualization module can also contribute to
significant correlation was found for the condition that        the analysis of eye gaze, since it helps to determine gaze
infants look at the toy. A comparison of each model’s           locations outside the currently recorded frame. Further-
R2 value (see Figure 7) shows that given parents hold a         more, our approach is flexible, since it does not depend
toy, the relation between age and activity can be best          on the availability of unoccluded third person perspective
explained by a linear model. We were unable to show             recordings. The current limitations are the estimation
a significant linear relationship between age and head          of rapid head rotations and visual field covering object
activity for the non-social conditions. This suggests that      movements without enough peripheral view. However,
this developmental trend depends on social interaction          their practical impact is minor.
contexts, which supports our initial hypothesis.                   The regression analysis of head motions and eye gaze
   To test for a developmental trend in gaze activity, lin-     linked to social interaction conditions revealed significant
ear models for the infant’s age were estimated given each       developmental trends for both head activity and gaze.
condition, including models for the non-social conditions       Head motions and eye gaze for non-social conditions did
(see Table 2). The individual models are visualized in          not exhibit any significant developmental trends. This
Figure 8 along with the average gaze activity per subject.      supports our hypothesis that both gaze and head activity
                                                            2107

                                            Parent Holding Toy                                Parent Not Holding Toy                                                                Parent Holding Toy                       Parent Not Holding Toy
                          7
                                                                                                                                                                 12.5
  Average Head Activity                                                                                                                  Average Gaze Activity
                          6
                                                                                                                                                                 10.0
                          5
                                                                                                                                                                  7.5
                          4
                          3                                                                                                                                       5.0
                          2
                                                                                                                                                                  2.5
                                    6       9        12    15    18    21     24     6         9    12   15    18      21   24                                              6       9    12    15   18   21   24       6      9    12   15    18    21   24
                                                                        Age in Months                                                                                                                     Age in Months
                                                Child Gazing at Parent                       Child Not Gazing at Parent                                                         Child Gazing at Parent                     Child Not Gazing at Parent
                          10.0
  Average Head Activity
                                                                                                                                                                 60
                                                                                                                                         Average Gaze Activity
                              7.5
                                                                                                                                                                 40
                              5.0
                                                                                                                                                                 20
                              2.5
                                                                                                                                                                  0
                                        6        9    12    15    18    21     24        6      9   12    15   18      21   24                                          6       9       12    15    18   21   24       6     9    12    15   18    21    24
                                                                            Age in Months                                                                                                                 Age in Months
                                            Parent Naming Toy                                Parent Not Naming Toy                                                               Parent Naming Toy                          Parent Not Naming Toy
                          6
  Average Head Activity                                                                                                                  Average Gaze Activity
                          5
                                                                                                                                                                 10
                          4
                          3
                                                                                                                                                                  5
                          2
                          1
                                    6       9        12    15    18    21     24     6         9    12   15    18      21   24                                          6       9       12    15    18   21   24       6     9    12    15   18    21    24
                                                                        Age in Months                                                                                                                     Age in Months
Figure 6: Relationship of age and average head activity                                                                              Figure 8: Relationship of age and average gaze activity
per subject on frames falling under the given conditions.                                                                            per subject on frames falling under the given conditions.
The gray area indicates a 95% confidence interval of the                                                                             The gray area indicates a 95% confidence interval of the
regression line.                                                                                                                     regression line.
                   0.3
                                                                                                                                                          0.3
                   0.2                                                                                                  match                                                                                                                         match
                                                                                                                                                          0.2
 R²                                                                                                                         yes          R²                                                                                                              yes
                                                                                                                            no                                                                                                                           no
                   0.1                                                                                                                                    0.1
                   0.0                                                                                                                                    0.0
                                    Parent Holding Toy            Parent Naming Toy Child Gazing at Parent                                                              Parent Naming Toy           Parent Holding Toy Child Gazing at Parent
Figure 7: Comparison of R2 for all head activity models.                                                                             Figure 9: Comparison of R2 for all gaze activity models.
Match = yes / no indicates the result for frames matching                                                                            Match = yes/no indicates the result for frames matching
/ not matching the condition.                                                                                                        / not matching the condition.
                                                                                                                                  2108

undergo developmental changes during social interactions.       University of Houston’s Grants to Enhance and Advance
However, eye gaze activity only shows a significant and         Research (GEAR) program. We especially want to
social context specific trend when the parent was naming        extend our gratitude to the families who participated in
an object, an event that is relatively short. In contrast,      the original study.
the most significant trend for head activity was found
when parents hold an object, which is a comparably longer                              References
event. This suggests that eye gaze is coupled with social       Bertenthal, B., & von Hofsten, C. (1998, March). Eye,
contexts when they require immediate attention. Head              Head and Trunk Control: The Foundation for Manual
activity is required when children want to attend to a            Development. Neuroscience & Biobehavioral Reviews,
wider visual space. Parents might adapt to the children’s         22 (4), 515–520.
increased motor capabilities and expand the space they          Bradski, G. (2000). The OpenCV Library. Dr. Dobb’s
use for their interplay. Thus, head activity reflects a           Journal of Software Tools.
property that is present for longer durations in social         Delaherche, E., Chetouani, M., Mahdhaoui, A., Saint-
interactions. These differences in the development of             Georges, C., Viaux, S., & Cohen, D. (2012, July). Inter-
head and gaze activity highlight that gaze analysis alone         personal Synchrony: A Survey of Evaluation Methods
is incomplete in reflecting infants’ developing response to       across Disciplines. IEEE Transactions on Affective
social referencing contexts.                                      Computing, 3 (3), 349–365.
   Furthermore, different attention shift patterns can be       de Lima-Alvarez, C. D., Tudella, E., van der Kamp,
found in parent-child social interactions. For example,           J., & Savelsbergh, G. J. P. (2014, January). Early
parents initiative in moving an object might create a             development of head movements between birth and 4
bottom-up visual cue the child reacts to. In contrast,            months of age: a longitudinal study. Journal of motor
child’s initiative might originate from intentional playing       behavior , 46 (6), 415–22.
with toys and thus result in top-down attention shifts.         Doshi, A., & Trivedi, M. M. (2012, January). Head
Doshi and Trivedi (2012) showed that bottom-up vi-                and eye gaze dynamics during visual attention shifts
sual cues result in different eye-head movement latencies         in complex environments. Journal of vision, 12 (2).
compared to top-down initiated attention shifts. Thus,          FFmpeg. (2014). Retrieved from ffmpeg.org
additional analysis of head movements has the potential         Franchak, J. M., Kretch, K. S., Soska, K. C., & Adolph,
to identify different types of social interaction patterns        K. E. (2011, January). Head-mounted eye tracking: a
automatically. Gaze analysis alone might not be sufficient        new method to describe infant looking. Child develop-
to analyze these patterns.                                        ment, 82 (6), 1738–50.
   The present attempt not only indicates the potential         Jonsson, B., & Von Hofsten, C. (2003). Infants’ ability
early psychological significance of head motion, but it           to track and reach for temporarily occluded objects.
may also provide a new insight into how early head                Developmental Science, 6 , 86–99.
motion can offer systematic cues for caregivers. Parents        Kretch, K. S., & Adolph, K. E. (2014). Active vision in
tend to respond to infants’ attention, gesture, and facial        passive locomotion: real-world free viewing in infants
affect, in timely manner. Responses to these cues can             and adults. Developmental Science, 1–15.
foster early learning but we know little how parents do so.     Martius, G.             (2014).      vid.stab - Video
Thus, further developing and applying this new approach           stabilization     library.          Retrieved     from
to the domain of development of social cognition could            github.com/georgmartius/vid.stab
help to understand the underlying mechanism of parental         R Development Core Team. (2011). R: A Language
responsiveness within parent-infant interactions.                 and Environment for Statistical Computing. Vienna,
   Using our new analysis method, we were successfully            Austria. Retrieved from http://www.r-project.org
able to extract head motion and to measure head activity.       Raudies, F., Gilmore, R. O., Kretch, K. S., Franchak,
Based on the results we showed that head activity in              J. M., & Adolph, K. E. (2012). Understanding the
addition to gaze activity robustly reflects important de-         development of motion processing by characterizing
velopmental trends that indicate possible links to social         optic flow experienced by infants and their mothers.
cognition.                                                        IEEE International Conference on Development and
                                                                  Learning and Epigenetic Robotics, ICDL 2012 .
                  Acknowledgments                               Yoshida, H., & Burling, J. M. (2013). An Embodied
                                                                  Perspective of Early Language Exposure. In M. Knauff,
This work has been supported in part by MEXT                      M. Pauen, N. Sebanz, & I. Wachsmuth (Eds.), Pro-
KAKENHI “Constructive Developmental Science”                      ceedings of the 35th annual conference of the cognitive
(24119003). The data used for the present analysis is             science society (pp. 1635–1640). Austin, TX: Cognitive
part of a project founded by the National Institutes              Science Society.
of Health grant (R01 HD058620), Foundation for
Child Development: Young Scholars Program, and the
                                                            2109

