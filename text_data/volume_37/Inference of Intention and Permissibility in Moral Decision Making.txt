              Inference of Intention and Permissibility in Moral Decision Making
                   Max Kleiman-Weiner1 (maxkw@mit.edu), Tobias Gerstenberg1 (tger@mit.edu),
                Sydney Levine2 (levine@ruccs.rutgers.edu) & Joshua B. Tenenbaum1 (jbt@mit.edu)
                   1 Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA 02139
                              2 Center for Cognitive Science, Rutgers University, Piscataway, NJ 08854
                             Abstract                                             P1-P5!            P1-P5!              P6!   P1-P5!
   The actions of a rational agent reveal information about its                           P6!
   mental states. These inferred mental states, particularly the
   agent’s intentions, play an important role in the evaluation of
   moral permissibility. While previous computational models                                                P6!
   have shown that beliefs and desires can be inferred from be-                                                              A2!
   havior under the assumption of rational action they have crit-
   ically lacked a third mental state, intentions. In this work, we                  A1!               A1!               A1!
   develop a novel formalism for intentions and show how they
   can be inferred as counterfactual contrasts over influence dia-
   grams. This model is used to quantitatively explain judgments
                                                                                    (a)!               (b)!              (c)!
   about intention and moral permissibility in classic and novel
   trolley problems.                                                    Figure 1: Schematic representation of trolley track geometries: (a)
                                                                        side track, (b) loop track and (c) side-side track.
   Keywords: moral judgment; social cognition; intention; the-
   ory of mind; influence diagrams; counterfactuals.                    between intentions and outcomes is complicated by the fact
                          Introduction                                  that it is possible to do the right thing for the wrong reasons
                                                                        (Scanlon, 2009).
Our actions often have multiple effects, whether it’s creating             Here we investigate a novel computational representation
a small amount of pollution in order to pick up groceries or            for reasoning about other people’s intentions based on coun-
making trade-offs between civilian deaths and military objec-           terfactual contrasts defined over influence diagrams. This
tives during a war. Did the general try to achieve the military         model can distinguish between intended outcomes and un-
objective even at the cost of civilian lives or did his plan use        intended side effects as well as represent the future-oriented
civilian deaths in order to demoralize the enemy? The ability           aspect of intentions as plans (Bratman, 1987). We use this
to distinguish between the effects an agent intended versus             model of intention inference as an input into a computational
those that were side-effects are critical in general for social         model of moral permissibility and test how well the model ex-
cognition and in particular for assigning responsibility and            plains both well-studied and novel trolley dilemmas. Before
assessing moral permissibility. Our goal here is to understand          describing our computational model, we motivate the model
these processes in computational terms.                                 with some examples.
   Reasoning about the intentions of other agents relies on
                                                                        Side track and loop track The canonical examples for the
theory of mind, the capacity to infer an agent’s underlying
                                                                        role of intention in moral permissibility judgments are the
mental states such as beliefs and desires from her actions.
                                                                        side track and loop track (Thomson, 1985). The side track,
Recently, a lot of progress in computational modeling of the-
                                                                        shown in Figure 1a is a scenario where an out-of-control trol-
ory of mind has been made by formalizing lay intuitions that
                                                                        ley is heading towards five people. An agent is standing near
other agents act as rational actors who maximize expected
                                                                        a switch (A1 ) which will turn the trolley from the main track
utility subject to their beliefs. A Bayesian observer can then
                                                                        with five people on it (P1 -P5 ) to a side track with one person
invert the agent’s planning process and reason about the like-
                                                                        (P6 ). The loop track, shown in Figure 1b has a loop instead
lihood of certain beliefs and desires given the agent’s actions
                                                                        of a split such that the trolley will continue on and hit the five
(Baker, Saxe, & Tenenbaum, 2009; Jern & Kemp, 2011).
                                                                        unless it hits the man on the looping track which would cause
   Although most computational accounts of theory of mind               the train to stop. Consider that in each of the situations, the
have focused on desires and beliefs, intentions are a third             agent throws the switch.
mental state thought to be particularly useful. Intentions can
                                                                           Empirically, throwing the switch in the loop track is judged
be thought of as plans of action that an agent commits to,
                                                                        less morally permissible than the side track (Mikhail, 2007).
chosen in order to bring about its desires given its beliefs
                                                                        Explanations of this finding usually draw on the agent’s in-
about the causal structure of the world (Bratman, 1987; Malle
                                                                        tention. In the side track, the agent neither intends the hitting
& Knobe, 1997). It is hypothesized that the ability to rea-
                                                                        nor killing of the man on the side track while in the loop track
son about and with the intentions of others is one the key
                                                                        the agent does intend for the trolley to hit the man on the loop
factors that enables the sophistication of human social be-
                                                                        but not his death.
havior (Tomasello, 2014). They are also an important input
into the evaluation of moral permissibility such as the doc-            Side-side track Following Bratman (1987), future-oriented
trine of double effect’s requirement against intending harm             planning is an important aspect of intention. To probe this as-
(Mikhail, 2007; Cushman, 2013; Waldmann, Nagel, & Wieg-                 pect of intention in permissibility we developed a novel track
mann, 2012; Crockett, 2013; Greene, 2014). The relationship             geometry which requires inference over the full plan rather
                                                                    1123

than just a single action. As shown in Figure 1c, the side-side          the actions the decision-making agent needs to take to maxi-
track scenario is similar to the side track except that the side         mize her expected utility. We show how the ID and the policy
track has an additional side track with its own switch (A2 ).            can be used together to compute foreseen outcomes: the most
Consider a situation in which there is one person on the main            likely outcome of the agent’s policy. Using a counterfactual
track, five people on the side track and no one on the side-side         criterion, we refine the foreseen outcomes into a subset of
track. If the trolley is going down the side track, unless the           outcomes that are intended.
agent throws the second switch directing the trolley down the               Overall, we aim to capture that intentions: (1) are partial
side-side track, the trolley will continue and hit the people on         plans with means-ends correspondence, (2) predict the ex-
the side track.                                                          pected effects of actions, (3) can distinguish between out-
   We hypothesize that throwing the first switch is intuitively          comes that the agent is committed to bring about and those
morally permissible. How can this be explained even though               that are side-effects, (4) are future-oriented, (5) give reasons
the trolley is now heading towards the five people? Since in-            for action and are hence inputs to further practical reasoning
tentions are forward-directed, they include the agent’s inten-           such as moral permissibility (Bratman, 1987). Indeed, one
tion to throw the second switch, saving all the lives. Only if           practical reason for the centrality of intentions in folk psy-
the agent doesn’t intend to throw the second switch does the             chology is that knowing an agent’s intentions allows one to
action become impermissible. This case motivates the central             predict how the agent will behave and why.
role of planning in our computational model. It is insufficient             We then show how an observer with uncertainty about the
to consider intentions as merely directed towards the effects            desires and norms of the agent can rationally update his be-
of a single action but rather the effects of the entire plan need        liefs about the agent by inverting the planning process us-
to be taken into consideration.                                          ing Bayes’ rule, and finally, can use these inferences to make
Joint inferences: norms, desires and intentions Infer-                   judgments about moral permissibility.
ences about the intentions of an agent are often intertwined             Influence diagrams
with inferences about the agent’s desires and the social norms
to which those desires conform. We contrast a side track                 Our notation follows Koller and Friedman (2009). An influ-
dilemma that has one anonymous person on the main track                  ence diagram ID is a directed acyclic graph over three types
and two anonymous people on the side track with a dilemma                of nodes: state nodes (depicted as circles, X ), decision nodes
we call brother track where the agent’s brother is on the main           (depicted as rectangles, D ), and utility nodes (depicted as di-
track and there are two anonymous people on the side track.              amonds, U ). Directed edges between nodes determine causal
   In the first dilemma participants rate throwing the switch            dependencies. State and utility nodes take values that are a
to be highly impermissible (as shown below) while in brother             function of the structural equations and depend on the values
track, participants rate throwing the switch to be permissible.          of their parents, while the value of decision nodes are chosen
When the agent throws the switch in the first case, partici-             by the decision making agent such that expected total utility is
pants infer that the agent intended to kill the two people. In           maximized. Let σ∗ be the policy that maximizes the expected
brother track, participants infer that the agent is following a          total utility of ID:
norm to value loved ones more and doesn’t intend to kill the                                  σ∗ = arg max EU[IDσ ]
                                                                                                       σ
two people on the side track. In a variant of brother track, the
brother is on the side-track and two anonymous people are on             where EU[IDσ ] is the expected total utility of following policy
the main track. If the agent throws the switch, we may infer             σ in ID. Each policy σ, is a setting of the decision nodes to
that the agent followed a norm that all lives should be valued           a chosen value. To calculate expected utility for a policy, let
equally, or. . . she might not value all lives equally, she just in-     ζ be an outcome, the setting of each of the state, utility and
tended to kill her brother! To infer the intended consequences           decision nodes in ID to a value. For a node Z ∈ ID, ζZ is
and judge moral permissibility thus requires jointly inferring           the value of node Z in outcome ζ. Thus the expected utility
the agent’s desires and the norms that guided their actions.             of policy σ can be calculated by averaging the total utility of
                                                                         an outcome U(ζ), weighted by the likelihood of that outcome
                Computational Framework                                  under the policy P(ζ|IDσ ) for each possible outcome:
Our computational approach has two parts. The first is a com-
putational account of intention inference and the second uses                               EU[IDσ ] = ∑ P(ζ|IDσ )U(ζ)
                                                                                                        ζ
this account to model permissibility judgments. The model
is presented to capture the real-world richness of intentional                                U(ζ) =    ∑ ζV
planning and has greater generality than is needed for our ex-                                         V ∈U
amples.                                                                                    P(ζ|IDσ ) =  ∏ P(X|PaX , σ)
   Our representation of intentions is based on influence di-                                          X∈X
agrams (ID). Influence diagrams are similar to Bayes nets                where PaX are the parents of node X. Thus the ID represen-
and were used previously to capture reasoning about what                 tation concisely factors the agent’s decision problem into in-
other agents know and want during decision-making (Jern &                dividual states, decisions, sources of utility and the structural
Kemp, 2011). Solving an ID yields an optimal policy (σ∗ ):               equations that define the dependence relations between them.
                                                                     1124

Defaults are encoded by requiring any policy that changes the           Definition 2. An intention I is a subset of nodes and their
value of a decision node away from its default value to incur           corresponding values such that the following conditions are
a small utility cost (not shown in figures).                            satisfied:
   See Figure 2a for an influence diagram representation of            1. Nodes in I take on values foreseen under σ∗ .
the side track dilemma shown in Figure 1a. The only decision
in the policy is the choice to throw the switch A1 . This action       2. Let ID\I be a counterfactual influence diagram that is ID
determines whether the trolley goes down the left track (TL )              with the nodes in I removed. I are intended if σ∗\I =        6 σ∗ ,
track or right track (TR ) which determines which people are               i.e., the optimal policy for ID\I is different from the optimal
hit and killed affecting the decision maker’s utility.                     policy for the original influence diagram ID.
                                                                       3. The sets of nodes in I are a minimal subset, i.e., there are
Intention
                                                                           no smaller subsets of intended nodes, which when removed
We now build on the ID representation to first extract the best            would also satisfy 2.
foreseen outcomes of the optimal policy and then refine the
                                                                           The intention I for the side track is shown in Figure 2c
best foreseen outcomes into an intention which excludes out-
                                                                        by the nodes and values highlighted in gray. The decision to
comes that were unintended.
                                                                        throw the switch does not depend on the values for hitting and
Definition 1. The best foreseen outcome F is the outcome                killing the person on the side track (P6 ) and the loss of util-
with the highest expected utility that can be foreseen by the           ity that resulted. Even if those nodes were removed from the
agent acting under the optimal policy:                                  influence diagram the agent would have still acted the same.
                  F = arg max U(ζ)P(ζ|IDσ∗ )                            Thus those nodes are side effects of the action. In contrast,
                           ζ                                            if the nodes that correspond to the states and utility of the
   F captures all the consequences that the agent can opti-             people on the main track were removed, the agent would not
mistically foresee happening as a result of her policy but does         have thrown the switch. Since the policy with the nodes re-
not include any backup plans or other types of conditional              moved is not equal to the policy for the full ID, those nodes
contingent plans. The decision to choose only a single fore-            and their values are treated as intended. We only consider the
seen state is motivated by efficient planning algorithms which          removal of nodes. However, capturing other aspects of in-
plan only on likely states and replan if necessary rather than          tention may require counterfactual perturbations to the utility
directly planning for every contingency (Platt, Tedrake, Kael-          values rather than removal (Gerstenberg, Goodman, Lagnado,
bling, & Lozano-Perez, 2010). Specifically, if we assume that           & Tenenbaum, 2015).
number of lives maps to utility, the foreseen effects of throw-            Our representation of intentions as counterfactuals over in-
ing the switch in side track are that the 5 people on the main          fluence diagrams satisfies the five aspects of intentions we
track will not be hit by the trolley and live, generating 5 utility     aimed to capture: (1) I is a partial plan than contains future
while the person on the side track will get hit by the trolley          expected actions, (2) the outcomes in I are the expected result
and die generating -1 utility for the decision-maker. This is           of the plan, (3) I distinguishes between intended outcomes
shown in Figure 2b where each node is assigned to its fore-             the agent is committed to bring about and side effects, (4) I
seen value (shown in bold) under the policy of throwing the             contains future-oriented policy information, (5) the nodes and
switch.
   While foreseen outcomes optimistically describe the con-
sequences of an action and are brought about “intentionally”,                                      U1-U5:       U6: !     U1-U5:        U6: !
                                                                            U1-U5!       U6!
                                                                                                      5!        -1!         5!           -1!
not all foreseen consequences are intended by the decision
maker (Bratman, 1987). Analogously in causal reasoning,                    Kill P1-                Kill P1-  Kill P6?    Kill P1-    Kill P6?
                                                                                      Kill P6?!
not all of the factors which influence an outcome are judged                 P5? !                P5? No!     Yes!       P5? No!       Yes!
by human participants to be causes of an observed outcome.
                                                                           Hit P1-                 Hit P1-   Hit P6?      Hit P1-     Hit P6?
This has led to the development of computational models of                             Hit P6? !
                                                                             P5? !                P5? No!     Yes!       P5? No!       Yes!
actual causation which try to model the commonsense no-
tion of causality through counterfactual reasoning (Halpern                 TL or                   TL or                 TL or
                                                                             TR? !                TR? TR!                TR? TR!
& Pearl, 2005). This formalism has successfully captured
aspects of empirical attribution of responsibility (Lagnado,              Throw A1? !
                                                                                                 Throw A1?              Throw A1?
Gerstenberg, & Zultan, 2013; Sloman, Fernbach, & Ewing,                                             Yes !                  Yes !
                                                                             (a)!                    (b)!                  (c)!
2012). We propose that a similar model can distinguish an
agent’s intended outcomes from foreseen outcomes. Specifi-              Figure 2: An influence diagram (ID) representation of intention. (a)
cally, intended outcomes are the subset of foreseen outcomes            The ID for the side track decision dilemma. (b) The foreseen out-
that the choice of the optimal policy (σ∗ ) counterfactually de-        comes F. Each node is set to the best value possible under the policy
                                                                        of throwing the switch (shown in bold). (c) The intention I is shaded
pends upon. We generalize Halpern and Pearl (2005) to de-               in gray. Like the foreseen outcome, each node is set to its most likely
cision problems where outcomes are the policies determined              value under the policy, however only the nodes shaded in gray and
by planning:                                                            their values are intended by the agent.
                                                                    1125

  Norms!        Desires!                                                  mous person. Let norm be true when the agent follows the
                           Figure 3: Joint inference of intentions, de-   norm that loved ones should matter more which is true with
    U1-U5:        U6: !    sires and norms. The nodes in the beige        prior probability αnorm . If norm is true and the person on track
       5!          -1!     box correspond to the influence diagram        T is the agent’s brother, then the brother is counted as equal to
                           the agent is planning over. The nodes
   Kill P1-     Kill P6?                                                  an αbro number of anonymous people and otherwise treated
   P5? No!       Yes!      outside the box represent the observer’s
                           uncertainty over the agent’s desires and       the same as a single anonymous person. Finally, as is com-
    Hit P1-     Hit P6?    norms. The observer can use this prior to
   P5? No!       Yes!                                                     mon in discrete choice, we include independent multiplica-
                           infer the agent’s intention (gray) from the
    TL or                  observation of a single action (black).        tive exponential noise eT for each track which captures other
   TR? TR!                                                                unmodeled sources of variation including perceptual and val-
  Throw A1?                                                               uation errors. Thus DT = nT kT eT for anonymous people and
     Yes !
                                                                          brother when the norm is not followed and DT = αbro kT eT
values in I give the reasons for the action. Thus I is a com-             when the norm to value loved ones more is true. While only
pressed representation of the actions an agent plans to make              sketched here, these variables specify the structure of the ob-
and their intended effects.                                               server’s beliefs about the decision-making agent’s desires.
Joint inference of norms, desires and intentions                          Moral Permissibility
Inference of intention through the ID requires knowledge of
                                                                          Finally, we use the inference of intentions to model moral
the agent’s desires and beliefs. However, observers often only
                                                                          permissibility. The trolley problem and its variants are well-
know these desires and beliefs with uncertainty such as in the
                                                                          studied for probing the cognitive processes that generate
brother track examples in the introduction. The structure of
                                                                          moral permissibility judgments. However, without a model
these priors gives the observer an expressive theory of mind,
                                                                          of graded intention it was not previously possible to quantita-
capable of representing agents with both good and evil desires
                                                                          tively model these judgments. We consider three models: one
or adherence to different norms. The observer’s beliefs about
                                                                          based on intentions, one based on differences in the number
the agent’s desires are modeled by introducing uncertainty
                                                                          of people who died and who survived, and a linear combina-
over the parameterization of the utility nodes. This uncer-
                                                                          tion of the two.
tainty induces a probability measure over IDs (shown in Fig-
ure 3) and since each ID has an intention under rational plan-               Let per be the probability of finding the agent’s action
ning, it also induces a probability measure over intentions.              morally permissible. The first model only considers the
Given observation of an agent’s action(s) A, an observer can              agent’s inferred intention to predict permissibility judgments.
rationally update his belief about the agent’s intentions I, de-          The more likely the agent is inferred to have an intention to
sires D and norms N using Bayes rule:                                     harm the more likely the action is judged to be impermissible:
           P(I, D, N|A) = P(A|I)P(I|D, N)P(D, N)/P(A)                               perintention = logit−1 (1 − P(Iharm = Yes|A))
   Since P(A) cannot be analytically calculated we used re-               where P(Iharm = Yes|A) is the probability that the agent is
jection sampling to draw samples from P(I, D, N|A). We first              inferred to have intended to harm someone given that they
sample from the desire and norm distribution of the observer              took action A. The transform logit−1 (x) = (1 + exp(−α1 (x −
P(D, N) which defines an influence diagram IDD,N . Planning               α2 )))−1 with parameters α1 = 7 and α2 = 0.7 scale the in-
in this ID yields P(I|D, N). If the intended action is the same           tention judgments onto permissibility. We compare this to
as the observed action A we keep the sample which is a joint              a model that predicts moral permissibility judgments based
distribution over the intention, desires and norms. If the in-            only on the number of lives killed and saved:
tended action is not A, the sample is discarded and the pro-                                   perutility = logit−1 (∆lives )
cesses is repeated.
   In order to quantitatively predict observer’s judgments of             where ∆lives is the expected difference between the number of
P(I, D, N|A) we must specify the structure of P(D, N), the                lives saved and the number of lives lost and the logit param-
distribution over how the agent values the lives of the peo-              eters α1 = 0.3 and α2 = 0 scale ∆lives onto the unit interval.
ple on the tracks. Let DT be the utility to the decision maker            Finally we consider a full model that weighs both intentions
of the nT people on track T not being killed. If kT = −1 then             and the difference between number of lives saved and lost:
the agent wants to kill the people on track T , if not, kT = 1.                     perfull = w ∗ perintention + (1 − w) ∗ perutility
kT is negative for all T with probability αb which means the
agent wants to kill as many as possible. Otherwise, kT = −1                                Experiment and Results
for each track independently with probability αk .
   When making decisions about brothers (or other loved                   We test the predictions of the model for the three examples
ones) we hypothesize that the decision-making agent might                 from the introduction. For the first two we consider only qual-
apply one of two norms: all lives should be valued equally,               itative phenomena from the published literature. For the third
or loved ones should be valued more. This norm determines                 we conducted a large scale behavioral study varying the loca-
whether a brother is valued to the agent more than an anony-              tion, number and identity of the people on the tracks.
                                                                      1126

           U1-U5:       U6: !                   U1-U5: !               it (this excludes 2v5 and 5v2) yielding a total of 11 track
             5!         -1!                        0!                  configurations. The tracks are presented in the format XvY
                                     U6: 1!                            where X and Y are the number of people on the main and
                                                Kill P1-
          Kill P1-    Kill P6?                                         side track respectively or are a ‘B’ if it’s the agent’s brother.
                                                P5? No!
          P5? No !     Yes!         Kill P6?                           100 participants were recruited via Amazon Mechanical Turk
                                      No !      Hit P1-                using psiTurk (McDonnell et al., 2012). On each trial, partic-
          Hit P1-     Hit P6?                   P5? No!
          P5? No!      Yes!         Hit P6?                            ipants read a standard story about the trolley dilemma based
                                      No !      TL, TR,                on those in Mikhail (2007) but with the identity and number
           TL or                                Ø? TR!                 of people varied to reflect the track configuration. After read-
           TR?                       TL or
            TR!                     TR? TR!    Throw A2?               ing the story, participants were asked to answer the following
                                                 Yes !                 questions with “yes” or “no”: “Was it morally permissible for
         Throw A1?                 Throw A1?
           Yes !                     Yes !                             Hank to throw switch?”, “Did Hank throw the switch in or-
            (a)!                      (b)!                             der to kill his brother/the man/the two men/the five men on
Figure 4: Influence diagram for the (a) loop track and (b) side-side   the side track”, “Did Hank throw the switch in order to not
track with the intention shaded in gray and the action in black.       kill his brother/the man/the two men/the five men on the main
Side track and loop track As demonstrated before (see                  track?” and then used a slider to answer “Hank most likely
Figure 2c), the model correctly predicts that hitting and              believes:” where the edges of the slider were “all lives should
killing the man on the side track is unintended. In contrast, for      be valued equally” and “only loved ones should be valued”.
the loop track, when the man on the loop is hit but not killed,        This data was collected as part of a larger experiment where
the policy remains unchanged, so the model predicts that the           the agent either throws or does not throw the switch. Here we
killing of the man is unintended. However, the model predicts          only present the data for when the agent threw the switch.
that hitting the man on the loop is intended since it is required      Results Figure 5 shows the averaged participant responses
to stop the trolley from hitting the 5 on the main track. Thus         for moral permissibility. The following trends are apparent:
due to this difference in causal structure, the agent in loop          (1) the more lives saved and less lives killed the more per-
track intends to hit but not kill the man on the loop. Indeed          missible the action; (2) killing the brother was seen as less
throwing the switch in loop track is found to be less permis-          permissible compared to killing an anonymous person for a
sible than throwing the switch in side track. Given that ∆lives        given number of lives saved; (3) saving the brother became
is the same in both conditions suggests that the intention to          less permissible as the number of lives sacrificed grew. Fig-
harm in the loop track case could account for this difference          ure 6 shows the averaged participant data for the intention to
as has been suggested in the literature (Mikhail, 2007).               kill those on the side track and intention to not kill those on
Side-Side Track In the side-side track, the model predicts             the main track. In all configurations, participants were more
that if the agent throws the first switch, her intention is to         likely to infer that the participant acted in order to save rather
also throw the second switch so that the trolley goes down             than kill even though the action had both effects. This re-
the side-side track and kills nobody. The model further pre-           flects the low prior probability on the agent desiring any of
dicts that both saving the person on the main track and the            the people’s deaths. The intention to kill was inferred to be
5 people on the side track are intended since in both cases            greatest when ∆lives ≤ 0 and when the agent switched the trol-
they were counterfactually relevant to the policy: if the person       ley onto the track with the brother. The intention to not kill
on the main track wasn’t there, the agent wouldn’t throw the           those on the main track (right plot) followed a similar trend
first switch. If the people on the side track weren’t there, the       corresponding roughly to the inverse of the intent to kill judg-
agent wouldn’t have thrown the second switch (since throw-             ments.
ing switches has a small action cost associated with it).                 Figure 7 shows the averaged participant responses for the
   The role of intention in evaluating permissibility is clear         agent’s relative belief between the two norms: “All lives
here even though it plays a different role than in the loop                                  1.00                                            Data               Utility only
track. The ∆lives can only be calculated under the agent’s                                                                                   Full model         Intention only
future-oriented plan. Thus the intention captures a key as-
                                                                       Morally permissible
                                                                                             0.75
pect of the permissibility by requiring an inference over fu-
ture actions rather than through understanding which effects                                 0.50
are intended and which are side-effects.
Joint inference: desire and intentions                                                       0.25
Experiment To investigate the ability of participants to
                                                                                             0.00
jointly infer the desires of the agent and her intention, we                                        5v1   5vB   2v1   2vB   1v1    1vB     Bv1    1v2     Bv2    1v5     Bv5
                                                                                                                            Track configuration
consider a set of tracks with the same track geometry as in
                                                                       Figure 5: Averaged participant responses for whether throwing the
Figure 1a but on each track there were either 1, 2 or 5 anony-         switch was morally permissible. 5vB means 5 people on the main
mous people or the agent’s brother. We considered all per-             track and the brother on the side track. Error bars in all figures show
mutations that had at least one track with a single person on          a bootstrapped 95% confidence interval.
                                                                   1127

                                                                                                                                Intention to not kill those on main track
                                                          1.00
                  Intention to kill those on side track
                                                                                                                        Data
                                                                                                                        Model
                                                          0.75
                                                          0.50
                                                          0.25
                                                          0.00
                                                                 5v1 5vB 2v1 2vB         1v1 1vB Bv1 1v2 Bv2 1v5 Bv5                                                        5v1 5vB 2v1 2vB    1v1 1vB Bv1 1v2 Bv2 1v5 Bv5
                                                                                      Track configuration                                                                                     Track configuration
 Figure 6: Averaged participant responses for whether the agent threw the switch in order to kill the people on the side track (left) or not kill
 the people on the main track (right). 5vB means 5 people on the main track and the brother on the side track.
 should be valued equally” and “Only loved ones should be                                                                                   and moral permissibility judgments which correspond well to
 valued”. When the brother is saved, participants inferred that                                                                             human judgments. The model also applies to many more situ-
 the agent is following the loved ones norm. When the brother                                                                               ations than we could address in this paper. In future work, we
 is killed, participants infer that the agent is following the all                                                                          intend to test other aspects of the model through behavioral
 lives equal norm. The more anonymous people killed, the                                                                                    experiments on trolley dilemmas like the side-side track and
 stronger the inference for the norm to treat loved ones spe-                                                                               others where beliefs might be uncertain. We will also apply
 cially.                                                                                                                                    our model of intention inference to both non-trolley moral
 Model Predictions The predictions of the computa-                                                                                          dilemmas and non-moral domains such as games and other
 tional model with parameters αk = 0.05, αb = 0.1, αnorm =                                                                                  social interactions (Tomasello, 2014).
 0.55, αbro = 30, w = 0.8 are shown in the above plots. Over-                                                                               Acknowledgments MKW was supported by a Hertz Foundation
 all, the model fits the data with R = 0.97 and captured the                                                                                Fellowship and NSF-GRFP. TG and JBT were supported by the Cen-
 main trends described in the previous section. Several of                                                                                  ter for Brains, Minds and Machines (CBMM), funded by NSF STC
 these free parameters do not significantly affect the quanti-                                                                              award CCF-1231216 and by an ONR grant N00014-13-1-0333. SL
 tative model fit although we include them since they are in-                                                                               was supported by a DOD NDSEG.
 terpretable and intuitive: there was a low prior probability
 that the agent wanted to kill people and a high prior probabil-                                                                                                                               References
                                                                                                                                            Baker, C. L., Saxe, R., & Tenenbaum, J. B. (2009). Action understanding as inverse
 ity of endorsing the loved ones norm. A reduced model that                                                                                    planning. Cognition, 113(3), 329–349.
 only includes 3 of the above 5 parameters (αb = 0.15, αnorm =                                                                              Bratman, M. (1987). Intention, plans, and practical reason.
                                                                                                                                            Cohen, P. R., & Levesque, H. J. (1990). Intention is choice with commitment. Artificial
 0.55, αbro = 30) fit with R = 0.95.                                                                                                           intelligence, 42(2), 213–261.
                                                                                                                                            Crockett, M. J. (2013). Models of morality. Trends in cognitive sciences, 17(8), 363–
                                                                                 Discussion                                                    366.
                                                                                                                                            Cushman, F. (2013). Action, outcome, and value a dual-system framework for morality.
 We developed a novel model for intention inference based on                                                                                   Personality and social psychology review, 17(3), 273–292.
                                                                                                                                            Gerstenberg, T., Goodman, N. D., Lagnado, D. A., & Tenenbaum, J. B. (2015). How,
 counterfactual contrasts over influence diagrams. While we                                                                                    whether, why: Causal judgments as counterfactual contrasts. In Proceedings of the
                                                                                                                                               37th annual conference of the cognitive science society.
 are not the first to give a computational account of intention                                                                             Greene, J. (2014). Moral tribes: emotion, reason and the gap between us and them.
                                                                                                                                               Atlantic Books Ltd.
 (see e.g., Cohen and Levesque (1990)), our model is the first                                                                              Halpern, J. Y., & Pearl, J. (2005). Causes and explanations: A structural-model ap-
 probabilistic model based on inverse rational planning that                                                                                   proach. part i: Causes. The British journal for the philosophy of science, 56(4),
                                                                                                                                               843–887.
 can distinguish between outcomes an agent intended and side                                                                                Jern, A., & Kemp, C. (2011). Capturing mental state reasoning with influence diagrams.
                                                                                                                                               In Proceedings of the thirty-third annual conference of the cognitive science society.
 effects that were merely foreseen. Our model makes quantita-                                                                               Koller, D., & Friedman, N. (2009). Probabilistic graphical models: principles and
 tive predictions about both the intentions underlying actions                                                                                 techniques. MIT press.
                                                                                                                                            Lagnado, D. A., Gerstenberg, T., & Zultan, R. (2013). Causal responsibility and coun-
                                    1.00                                                                                                       terfactuals. Cognitive science, 37(6), 1036–1073.
Norm = Only loved ones are valued
                                                                   Data                                                                     Malle, B. F., & Knobe, J. (1997). The folk concept of intentionality. Journal of Exper-
                                                                   Model                                                                       imental Social Psychology, 33(2), 101–121.
                                    0.75                                                                                                    McDonnell, J., Martin, J., Markant, D., Coenen, A., Rich, A., & Gureckis, T. (2012).
                                                                                                                                               psiturk.
                                                                                                                                            Mikhail, J. (2007). Universal moral grammar: Theory, evidence and the future. Trends
                                                                                                                                               in cognitive sciences, 11(4), 143–152.
                                    0.50                                                                                                    Platt, R., Tedrake, R., Kaelbling, L., & Lozano-Perez, T. (2010, June). Belief space
                                                                                                                                               planning assuming maximum likelihood observations. In Proceedings of robotics:
                                                                                                                                               Science and systems. Zaragoza, Spain.
                                    0.25                                                                                                    Scanlon, T. M. (2009). Moral dimensions. Harvard University Press.
                                                                                                                                            Sloman, S. A., Fernbach, P. M., & Ewing, S. (2012). A causal model of intentionality
                                                                                                                                               judgment. Mind & Language, 27(2), 154–180.
                                    0.00                                                                                                    Thomson, J. J. (1985). The trolley problem. Yale Law Journal, 94, 1395–1415.
                                                                 5vB       2vB     1vB           Bv1        Bv2   Bv5                       Tomasello, M. (2014). A natural history of human thinking. Harvard University Press.
                                                                                   Track configuration                                      Waldmann, M. R., Nagel, J., & Wiegmann, A. (2012). Moral judgment. The Oxford
                                                                                                                                               handbook of thinking and reasoning, 364–389.
 Figure 7: Averaged participant responses for whether the agent most
 likely believes “all lives should be valued equally” (coded 0) or
 “only loved ones should be valued” (coded 1).
                                                                                                                          1128

