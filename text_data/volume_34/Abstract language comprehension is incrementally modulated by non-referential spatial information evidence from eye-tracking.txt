UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Abstract language comprehension is incrementally modulated by non-referential spatial
information: evidence from eye-tracking
Permalink
https://escholarship.org/uc/item/33166352
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Guerra, Ernesto
Knoeferle, Pia
Publication Date
2012-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

    Abstract language comprehension is incrementally modulated by non-referential
                                  spatial information: evidence from eye-tracking
                                         Ernesto Guerra (ernesto.guerra@uni-bielefeld.de)
                                           Pia Knoeferle (knoeferl@cit-ec.uni-bielefeld.de)
                                Cognitive Interaction Technology Excellence Cluster, Bielefeld University,
                                                Morgenbreede 39, 33615, Bielefeld, Germany.
                                Abstract                                 2011; Huettig & McQueen, 2007). Visual context not only
   Research on situated language processing has examined how
                                                                         affects spoken language comprehension rapidly, but also
   visually depicted objects or concrete action events inform the        sentence comprehension during reading. Evidence from
   comprehension of concrete sentences. By contrast, much less           picture-sentence verification has revealed rapid visual
   is known about how abstract sentence comprehension                    context effects for concrete visual stimuli (e.g., red dots)
   interacts with non-linguistic visual information. Moreover,           and sentence content (e.g., The dots are red, see Clark &
   while non-linguistic information can rapidly inform language          Chase, 1972; also Gough, 1965; Knoeferle, Urbach, &
   comprehension when it is related to sentence content through          Kutas, 2011; Underwood, Jebbet, & Roberts, 2004).
   reference or lexical-semantic associations, it is unclear to
   which extent this is the case when the visual context is ‘non-           However, most of these studies have concentrated on
   referential’ (i.e., not related to the sentence through reference     sentences about concrete objects and events. While evidence
   or lexical semantic associations). We conducted two eye-              suggests that visual context can rapidly and incrementally
   tracking reading experiments to address these two open                inform comprehension of concrete spoken and written
   issues. In both experiments, reading times were shorter when          sentences, it is unclear to which extent non-linguistic visual
   sentences about conceptually similar abstract ideas were              context information can influence the processing of abstract
   preceded by objects (words-on-cards in Experiment 1 and
                                                                         language rapidly and incrementally. In examining situated
   blank playing cards in Experiment 2) that were depicted close
   together (vs. far apart); and when sentences about                    language comprehension, most visual world studies have
   conceptually dissimilar abstract ideas were preceded by               further relied on a referential linking hypothesis (e.g., a
   objects that were depicted far apart (vs. close together). This       noun referencing an object or a verb an action). By contrast,
   happened rapidly (first-pass reading times) and incrementally         it’s unclear whether visually presented information can
   (as the sentence unfolded). Thus, (a) comprehension of                influence sentence comprehension when there is no overt
   abstract language can be modulated by non-linguistic visual           referential or lexical-semantic link with sentence content.
   information (spatial distance between depicted objects) at the
   sentence level, and (b) online language comprehension can be
   informed by visual context even in the absence of an overt                 Spatial Distance and Semantic Similarity
   referential or lexical-semantic link.                                 Conceptual metaphor theory proposes that abstract meaning
   Keywords: semantic interpretation; spatial information; non-          is grounded in physical experience through metaphorical
   referential visual context; eye tracking.                             mapping (Lakoff & Johnson, 1999). Similarity, for instance,
                                                                         would be grounded in the physical experience of spatial
                            Introduction                                 distance. Recent behavioral studies have provided first
Studies in the ‘visual world paradigm’ have contributed                  evidence for a link between spatial distance and similarity.
extensively to our understanding of how non-linguistic                   In one study, two visually presented abstract words (e.g.,
visual information affects sentence comprehension (e.g.,                 loyalty and boredom) were judged to be more similar when
syntactic disambiguation: Tanenhaus et al., 1995; semantic               they were presented close together (vs. far apart), but more
interpretation: Sedivy et al., 1999). In ‘visual world studies’,         dissimilar when they were presented far apart (vs. close
listener’s eye movements are tracked during comprehension                together, Casasanto, 2008). In another, similarity-judgment
of a spoken sentence that describes a given visual                       task (on whether two squares on a screen had similar colors
environment. Findings from such studies have shown that                  or not) speeded decision times were shorter when similarly-
visual presentation of objects or concrete action events can             colored squares were presented close to each other (vs. far
facilitate incremental structural disambiguation (e.g.,                  apart), and when differently-colored squares were presented
Tanenhaus et al., 1995; Knoeferle, Crocker, Scheepers, &                 far apart (vs. close to each other, Boot & Pecher, 2010).
Pickering, 2005); that language can rapidly guide visual                 These rating and response time effects support the view that
attention to semantically relevant objects as evidenced by               there is a relationship of some sort between spatial
anticipatory eye-movements (e.g., Altmann & Kamide                       information (the distance between two stimuli) and semantic
1999; Kamide, Scheepers, & Altmann, 2003, Kamide,                        and visual similarity.
Altmann, & Haywood, 2003); and that distractor objects are
inspected more often when they are semantically related (vs.
unrelated) to a target word (e.g., Huettig & Altmann, 2005,
                                                                     1620

          Accounting for situated language                         similarity or dissimilarity between abstract nouns (Table 1).
                      comprehension                                After reading the sentence and judging its veracity, they saw
                                                                   a picture and verified whether it was the same as the one
The nature and time course of spatial distance effects on          that they had inspected before the reading task.
cognitive, and in particular, language comprehension                  If spatial distance between the cards can modulate the
processes, however, remains unclear. In summary, we have           interpretation of semantic similarity, we should see this
identified several open issues in research on the interaction      reflected in reading times. To the extent that the existing
between non-linguistic visual information and language             findings on spatial distance effects (Boot & Pecher, 2010;
comprehension, which we conceptualize as two research              Casasanto, 2008) generalize to language comprehension we
questions: (1) Can non-linguistic information rapidly and          should see faster reading times for similarity-conveying
incrementally modulate the semantic interpretation of              sentences when the preceding words-on-cards are close
abstract sentences? (2) Can non-linguistic visual                  together (vs. far apart), and for dissimilarity-conveying
information modulate language comprehension even in the            sentences when the words-on-cards are far apart (vs. close
absence of referential or lexical-semantic links?                  together). Moreover, if effects of spatial distance are
   Addressing these and other questions is important to            incremental, we should see them at the adjective region of
advance accounts of situated language comprehension (e.g.,         the sentence (see Table 1 for examples) since this is when
the Coordinated Interplay Account, CIA, Knoeferle &                similarity relations are made explicit and could thus be
Crocker, 2006; Knoeferle & Crocker, 2007). The CIA                 related to spatial distance from the recent visual context. In
accommodates visual context effects during spoken                  principle, effects could appear even earlier, namely at the
language comprehension. It consists of three informationally       second noun phrase, since semantic similarity could become
and temporally dependent stages. A first stage                     available as soon as the two abstract nouns are integrated.
accommodates the processes of incremental sentence                 Finally, to the extent that these effects are immediate, we
comprehension that are the focus of traditional sentence           should observe them in first-pass reading times.
processing accounts. A second stage describes utterance-
mediated shifts in (visual) attention. ‘Scene integration’,        Method
finally, integrates the linguistic and scene input and informs
interpretation based on visual representations. The CIA            Participants Thirty-two native speakers of German (mean
makes no assumptions regarding the modular status of either        age: 23.6; range 19-33) with normal or corrected-to-normal
the linguistic or visual processes involved. Rather, it            vision participated in the experiment for a compensation of
outlines the interaction of utterance interpretation, (visual)     6 Euro. None of them had been exposed to a second
attention and scene information.                                   language before age 6, and all gave informed consent.
   The CIA has been derived from eye-tracking findings on
                                                                   Materials and Design We created 48 sentences1, each of
the comprehension of concrete sentences in non-linguistic
                                                                   which had two versions. In one version the sentence
visual contexts. The rapid and incremental time course with
                                                                   expressed similarity between two abstract nouns, and in the
which information in visual context interacts with spoken
                                                                   other version it expressed dissimilarity between two abstract
language comprehension appears to generalize to reading
                                                                   nouns (see Table 1 for examples). In addition, we created
when there is a referential link between visual context and
                                                                   visual contexts using commercial graphics programs. The
sentence meaning (see Knoeferle et al., 2011 for evidence).
Knowing whether rapid and incremental visual context               visual context showed two playing cards each of which
effects are also observed when there is no referential link        presented an abstract word (see Fig. 1). Card depictions did
and when sentences are abstract, would be important for            not change between items but the words on the cards did.
extending the account and refining its language-context            The words on the cards always appeared as the first and
                                                                   second noun phrase in the sentence. The two visual contexts
linking mechanism. Based on the close time locking of
                                                                   and the two sentences made up an item.
visual context effects and language comprehension in the
                                                                      A 2x2 within-subjects Latin square experimental design
CIA, we would expect to see spatial distance effects emerge
                                                                   was implemented with two factors (spatial distance and
time-locked to when information about semantic similarity
                                                                   semantic similarity), each with two levels (close vs. far,
becomes available in the sentence. The present research
                                                                   similar vs. different, respectively). Combinations of the two
addressed the two research questions (1) and (2) in two eye-
                                                                   factors and levels resulted in four experimental conditions:
tracking reading experiments. The studies examined
whether, and if so with which time course, spatial distance        cards far apart vs. close together with a similarity-conveying
effects on semantic similarity processing occur during             sentence; and cards far apart vs. close together with a
comprehension of abstract sentences.                               dissimilarity-conveying sentence (see Table 1).
                                                                      We constructed 96 filler sentences. All of them were
                                                                   grammatical and semantically legal German sentences.
                       Experiment 1
                                                                   However, 72 of them described unrealistic situations (e.g.,
In Experiment 1, participants inspected a visual context that
depicted words on cards either close together or far apart
(Fig. 1). Then they read a sentence that was either about          1
                                                                     One item was removed due to an error in the order of presentation
                                                                   of words.
                                                               1621

‘a presentation without good rhetoric should be given more                    Table 1: Example of visual contexts, corresponding
often’), and the other 24 described plausible situations (e.g.,                      sentences, and the resulting condition.
‘on the tram, passengers show their ticket to the inspector’).
All filler sentences were preceded by cards in different                 Picture      Sentence type                          Condition
positions on the screen (e.g., in the upper left and lower
                                                                         Fig.1A       (1) FriedenNP1 undcoord KriegNP2       Far-
right corner) and most of them were blank (N=72). Twenty-                                                                    Dissimilar
four filler sentences, however, had cards with words on                               sindVP1 bestimmtADV verschiedenADJ,
them. There were in addition 14 practice trials. A list                               das verrietVP2 der AnthropologeNP3.    Close-
                                                                         Fig.1B
consisted of 144 trials (48 experimental and 96 fillers trials),                                                             Dissimilar
which were all pseudo-randomized in four lists. Each list                Fig.1C       (2) KampfNP1 undcoord. KriegNP2        Far-
contained only one version of every item. There was at least                                                                 Similar
                                                                                      sindVP1 freilichADV entsprechendADJ,
one filler trial in between two items.
                                                                         Fig.1D       das verrietVP2 der AnthropologeNP3.    Close-
                                                                                                                             Similar
                                                                        Translation: (1) ‘PeaceNP1 andcoord. warNP2 areVP1 certainlyADV
                                                                        differentADJ, suggestedVP2 the anthropologistNP3.’ (2) ‘BattleNP1
                                                                        andcoord. warNP2 areVP1 surelyADV similarADJ, suggestedVP2 the
                                                                        anthropologistNP3’.
                                                                        Data Analysis Log-transformed reading times were
                                                                        analyzed using a linear mixed effect regression (LMER),
                                                                        including in a single step main and interaction effects of the
                                                                        factors. We implemented full models with random
                                                                        intercepts for participants and items, and fixed effect
                                                                        random slopes and their interactions for both random
                                                                        intercepts. We analyzed the second noun phrase (NP2) and
                                                                        the adjective region (ADJ), where we should see spatial
                                                                        distance effects on semantic interpretation if those occur
                                                                        time-locked to when semantic similarity between the first
                                                                        two noun phrases becomes available during reading (see
                                                                        Table 1). We further analyzed the VP2 and NP3 regions to
                                                                        see if any spatial distance effects also occur at subsequent
Figure 1: Example visual contexts for the sentences in Table 1          regions of the sentence. In these regions we examined three
(Experiment 1). The cards moved from the center of the screen           eye-tracking reading measures; first-pass reading (the
either far apart (A, C) or close to each other (B, D). After two        duration of all fixations from first entering an interest area
seconds, cards turned around (as represented by the semi-circular       and prior to moving to another interest area), regression path
arrow) and presented two abstract words. The words were either
                                                                        duration (the time from first entering a region until moving
semantically dissimilar (e.g., Frieden [‘Peace’] and Krieg [‘War’],
(A) and (B)) or similar (e.g., Kampf [‘Battle’] and Krieg [‘War’],
                                                                        past that region to the right; unlike first-pass reading time,
(C) and (D)).                                                           this measure includes reading time following regressions
                                                                        out of the region), and total reading times (the duration of
Procedure Upon arrival in the laboratory, participants                  all fixations in a given region, see, e.g., Rayner, 1998).
received information about the study. After that they were
calibrated using a 9-point calibration procedure. Then they             Results
completed 14 practice trials. After practice, the experiment            For the ADJ region, a similarity main effect was observed
began. Each trial was presented as a three-step task. First,            across all measures; reading times were shorter for
participants saw a visual context for six seconds, with two             sentences expressing similarity compared to those
playing cards in different positions. For half of the trials in         expressing dissimilarity (all t-values > 2). We also observed
the experiment (i.e., 24 filler and all experimental trials),           a reliable interaction between spatial distance and semantic
cards turned around after two seconds, each showing a word              similarity in first-pass times for the ADJ region (t-value = -
for four seconds. For the other half of the trials, cards turned        2.04, see Fig. 2): first-pass times were shorter when
and showed a blank front for 500 ms. After inspecting the               similarity-conveying sentences were preceded by cards-
visual context participants read a sentence (see Table 1).              with-words presented close to each other (vs. far apart). By
They were instructed to try to understand the sentence and              contrast, first-pass times for sentences that expressed
to judge its veracity (by pressing either a “yes” or a “no”             dissimilarity were shorter when they were preceded by
button). For the ensuing picture verification, participants             cards-with-words presented far apart (vs. close to each
saw a picture of two cards, and verified (by pressing                   other). No interaction effects were observed in other
“yes”/“no” buttons) whether they were identical with the                measures. Both VP2 and NP3 regions showed reliable
two cards they had seen before the sentence.
                                                                    1622

interaction effect in first-pass reading times and NP3 also in          before sentence reading were blank. Seeing the noun
total reading times. These interaction effects were similar as          phrases on the cards in Experiment 1 could permit
for the ADJ region. For the NP2 region, neither main effects            participants to integrate similarity of the nouns with spatial
nor interaction effects involving the manipulated factors               information even before sentence reading. If so, this could
were observed in any gaze measure.                                      facilitate and speed up any effects of spatial distance during
                                                                        reading. Using blank cards in Experiment 2 permitted us to
                                                                        see to which extent the effects of spatial distance on
                                                                        sentence reading in Experiment 1 depended upon the
                                                                        repetition of sentential noun phrases on the cards.
                                                                        Method
                                                                        Participants Thirty-two further native speaker of German
                                                                        with normal or corrected-to-normal vision (mean age: 24.4;
                                                                        range 20-31) participated in the experiment for a
                                                                        compensation of 6 Euro. All gave informed consent.
                                                                        Materials, Design, Procedure and Data Analysis The
                                                                        experimental design, procedure and data analysis were the
                                                                        same as in Experiment 1. The visual context, however, was
                                                                        modified. While participants in Experiment 1 saw cards-
                                                                        with-words for four seconds, participants in Experiment 2
Figure 2: Log-transformed mean first-pass reading time (with error      saw blank cards for three seconds. In both experiments,
bars plotting the standard error of the mean) for the ADJ region as
                                                                        however, visual context presentation duration was the same
a function of sentence type and spatial distance between cards-
with-words in Experiment 1.                                             (six seconds). We delayed card turning by one second in
                                                                        Experiment 2, since participants did not have to read any
Discussion                                                              words.
In Experiment 1, we presented participants with a visual                Results
context for which the distance between cards-with-words,
was manipulated. Cards were either presented close together             At the NP2 region we observed a similarity main effect,
or far apart, and they were followed by a sentence that either          such that sentences that expressed similarity had shorter
expressed similarity or dissimilarity of abstract nouns. We             first-pass times, compared to sentences that expressed
observed spatial distance effects on reading times as a                 dissimilarity (t-values = 2.04). Moreover, analyses of first-
function of the semantic content of the sentence. These                 pass times confirmed a reliable interaction between spatial
results suggest that non-linguistic information from the                distance and semantic similarity (t-value = -2.07). Figure 3
visual context (spatial distance) can modulate interpretation           shows the interaction pattern in Experiment 2.
of abstract language (semantic similarity) during online
sentence comprehension. Crucially, spatial distance effects
on semantic interpretation appeared both rapidly (first-pass)
and incrementally (at the ADJ region).
   Results from Experiment 1, inform our first research
question (whether abstract semantic interpretation can be
rapidly and incrementally modulated by non-linguistic
information). However, since the visual context for critical
items was related to the following sentence through words
on the cards, it is possible that effects of spatial distance on
semantic similarity interpretation were mediated by, or even
depended upon, that link. To address this concern and to
answer our second research question (can non-linguistic
visual information modulate language comprehension even
in the absence of referential or lexical-semantic links?),
Experiment 2 relies on the same design and presentation but             Figure 3: Log-transformed mean first-pass reading times (with
the cards did not show any words and remained blank.                    error bars plotting the standard error of the mean) for the NP2
                                                                        region as a function of sentence type and spatial distance between
                                                                        cards in Experiment 2.
                         Experiment 2
Experiment 2 was identical to Experiment 1 but instead of                  First-pass times for sentences that expressed similarity
presenting words on cards, the cards that participants saw              were shorter when preceded by blank cards close to each
                                                                    1623

other (vs. far apart), while reading times for sentences that       different, suggested the anthropologist’ were shorter when a
expressed dissimilarity were shorter when preceded by               preceding display showed cards-with-words far apart (vs.
blank cards far apart (vs. close to each other). No other           close together).
interaction effects were observed in other measures in this           Overall, thus, non-linguistic information can rapidly and
region.                                                             incrementally influence semantic interpretation of abstract
   Unlike in Experiment 1, a main effect of similarity              language. These results extend existing similarity-judgment
appeared in regression path duration at the ADJ region, but         and response-times results (Boot & Pecher 2010; Casasanto
no interaction effects were observed for that region. For the       2008), and clarify that non-linguistic information (i.e.,
subsequent VP2 region, a marginal interaction effect                spatial distance) can modulate language comprehension and
emerged (t-value = -1.84), with a similar pattern to that at        not just similarity judgments and ratings. In this regard, our
the NP2 region in Experiment 2 and the ADJ region in                results are compatible with theories of embodied cognition
Experiment 1. Main effects of spatial distance and similarity       that attribute an important role to perceptual information in
were observed in regression path duration for the NP3               language processing (see Lakoff & Johnson 1999). They
region, but no interaction effect was found.                        also extend findings that suggest abstract language can be
                                                                    related to visual context through lexical-semantic
Discussion                                                          associations. Duñabeitía et al. (2009) showed that listeners
In Experiment 2, we manipulated the distance between                rapidly inspected objects (e.g., a nose) that were associated
objects that did not have any overt relation to the semantic        with abstract words (e.g., Spanish olor, ‘smell’). What the
meaning of the ensuing sentence. The visual context can             present findings add is the insight that visual context can in
thus be described as non-referential in its relationship to the     turn influence abstract language comprehension, and that its
sentence. Moreover, spatial distance between cards was              effects are mediated via subtle mappings between the
irrelevant for performing the comprehension task (sentence          semantic similarity of nouns and object distance.
veracity judgments). Yet, we still found rapid and                    The present findings also have important implications for
incremental interaction effects between spatial distance and        processing accounts of situated language (e.g., the CIA,
the interpretation of semantic similarity, as reflected in          Knoeferle & Crocker, 2006, 2007). Consider how concrete
reading times. These findings provide strong support for the        language is related to visual context in the CIA. The
role of non-referential spatial information in abstract             emerging interpretation guides (visual) attention to relevant
language comprehension.                                             information in visual context or working memory. As
                                                                    people process a sentential verb, they engage in a search for
                   General Discussion                               a matching action either in the immediate environment or in
                                                                    their working memory. When they have found a matching
In research on situated language processing, abstract
                                                                    action, verb and action are co-indexed and action
language comprehension has received substantially less
                                                                    information      can    inform     sentence     interpretation.
attention than concrete language. While results from visual
                                                                    Comprehenders can further develop expectations about
world paradigms have shown that non-linguistic information
                                                                    referents based on lexical-semantic associations between the
can rapidly and incrementally modulate comprehension of
                                                                    verb and objects in context.
sentences that relate to objects and events (through
                                                                      The present findings corroborate and extend the
referential or associative links), it was unclear whether this
                                                                    referential and associative linking mechanism of the
effect would generalize to abstract sentences.
                                                                    Coordinated Interplay Account. First, the spatial distance
   We assessed this open issue in two eye-tracking-reading
                                                                    effects occurred not anywhere during reading but they first
experiments. Experiment 1 provided evidence that spatial
                                                                    emerged at sentence regions that contained information
information (distance between words depicted on cards) can
                                                                    about semantic similarity in both experiments. This was as
rapidly and incrementally influence semantic interpretation
                                                                    expected based on the CIA’s close time lock between when
of abstract sentences. First-pass times at the adjective and
                                                                    the utterance identifies relevant visual context information,
subsequent regions of sentences such as ‘battle and war are
                                                                    and when that context information impacts sentence
surely similar, suggested the anthropologist’ were shorter
                                                                    interpretation. What the present results add is the insight
when a preceding display showed cards-with-words close
                                                                    that this closely temporally coordinated interplay extends to
together (vs. far apart). Since objects in the visual context
                                                                    non-referential visual context effects (Experiment 2) and
were still related to the sentence in Experiment 1 (through
                                                                    abstract language comprehension (Experiments 1 and 2).
words on cards), Experiment 2 examined whether the rapid
                                                                    Future research will examine the subtle differences in the
spatial distance effects from Experiment 1 extend to a
                                                                    time course of spatial-distance effects in Experiment 1
situation in which the visual context (playing cards) was
                                                                    (ADJ, NP2) compared with Experiment 2 (NP2, VP2).
entirely unrelated to the sentence. When cards remained
                                                                      The findings moreover emphasize the necessity of
blank rather than showing words (Experiment 2), we
                                                                    assuming a fine-grained linking of linguistic and visual
observed rapid and incremental effects of spatial distance on
                                                                    information during language comprehension. As semantic
reading times as a function of the meaning of the sentences.
                                                                    similarity is computed during comprehension, it is
First-pass times at the second noun phrase and at the second
                                                                    reconciled with representations of spatial distance between
verb in sentences such as ‘peace and war are certainly
                                                                1624

objects that were neither mentioned in the sentence nor            language-mediated visual search. Journal of Memory and
relevant for the sentence judgment task. This ties in with         Language, 54, 460-482.
other recent results. Kreysa and Knoeferle (2011) observed       Kamide, Y., Altmann, G. T. M., & Haywood, S. L. (2003).
rapid visual context effects (of a speaker’s gaze and head         The time-course of prediction in incremental sentence
movements) on spoken language comprehension, and this              processing: Evidence from anticipatory eye movements.
despite the fact that the speaker was never explicitly             Journal of Memory and Language, 49, 133-156.
referenced to and that comprehenders hardly inspected the        Kamide, Y., Scheepers, C., & Altmann, G. T. M. (2003).
speaker during comprehension. Clearly, explicit reference is       Integration of syntactic and semantic information in
not necessary for incremental visual context effects.              predictive processing: cross-linguistic evidence from
   Together the present and other recent findings argue for        German and English. Journal of Psycholinguistic
highly active visual context effects on language                   Research, 32, 37-55.
comprehension and highlight the need for multiple                Knoeferle, P., & Crocker, M. W. (2006). The coordinated
(referential and non-referential) mechanisms in informing          interplay of scene, utterance, and world knowledge:
language comprehension through non-linguistic visual               evidence from eye tracking. Cognitive Science, 30, 481-
information.                                                       529.
                                                                 Knoeferle, P., & Crocker, M. W. (2007). The influence of
                   Acknowledgments                                 recent scene events on spoken comprehension: Evidence
This research was funded by the Cognitive Interaction              from eye movements. Journal of Memory and Language,
Technology Excellence Cluster (German research                     57, 519-543.
foundation, DFG) and by a PhD scholarship awarded to EG          Knoeferle, P., Crocker, M. W., Scheepers, C., & Pickering,
by the Ministry of Education, Government of Chile. The             M. J. (2005). The influence of the immediate visual
authors want to thank Maria Nella Carminati for advice with        context on incremental thematic role-assignment:
the analyses, and the members of the Language and                  evidence from eye-movements in depicted events.
Cognition Lab (CITEC, University of Bielefeld) for their           Cognition, 95, 95-127.
valuable comments on the reported research.                      Knoeferle, P., Urbach, T. P., & Kutas, M. (2011).
                                                                   Comprehending how visual context influences
                                                                   incremental sentence processing: Insights from ERPs and
                        References                                 picture-sentence verification. Psychophysiology, 48, 495-
Altmann, G. T. M., & Kamide, Y. (1999). Incremental                506.
   interpretation at verbs: restricting the domain of            Kreysa, H., & Knoeferle, P. (2011). Effects of speaker gaze
   subsequent reference. Cognition, 73, 247-264.                   on spoken language comprehension: Task matters. In L.
Boot, I. and Pecher, D (2010). Similarity is closeness:            Carlson, C. Hölscher, & T. Shipley (Eds.), Proceedings of
   metaphorical mapping in a conceptual task. Quarterly            the 33rd Annual Conference of the Cognitive Science
   Journal of Experimental Psychology, 63, 942-954.                Society (pp. 1557-62). Austin, TX: Cognitive Science
Casasanto, D. (2008) Similarity and proximity: When does           Society.
   close in space mean close in mind. Memory and                 Lakoff, G., & Johnson, M. (1999) Philosophy in the flesh:
   Cognition, 36, 1047-1056.                                       The embodied mind and its challenge to western thought.
Clark, H. H., & Chase, W. G. (1972). On the process of             University of Chicago Press.
   comparing sentences against pictures. Cognitive               Rayner, K. (1998). Eye movements in reading and
   Psychology, 3, 472–517.                                         information processing: 20 years of research.
Duñabeitia, J. A., Avilés, A., Afonso, O., Scheepers, C., &        Psychological Bulletin, 124, 372-422.
   Carreiras, M. (2009). Qualitative differences in the          Sedivy, J. C., Tanenhaus, M. K., Chambers, C. G., &
   representation of abstract versus concrete words: evidence      Carlson, G. N. (1999). Achieving incremental semantic
   from the visual-world paradigm. Cognition, 110, 284-292.        interpretation    through     contextual   representation.
Gough, P. B. (1965). Grammatical transformations and               Cognition, 71, 109-147.
   speed of understanding. Journal of Verbal Learning &          Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K.
   Verbal Behavior, 4, 107–111.                                    M., & Sedivy, J. C. (1995). Integration of visual and
Huettig, F., & Altmann, G. T. M. (2005). Word meaning              linguistic information in spoken language comprehension.
   and the control of eye fixation: semantic competitor            Science, 268, 1632-1634.
   effects and the visual world paradigm. Cognition, 96,         Underwood, G., Jebbett, L., & Roberts, K. (2004).
   B23-32.                                                         Inspecting pictures for information to verify a sentence:
Huettig, F., & Altmann, G. T. M. (2011). Looking at                Eye movements in general encoding and in focused
   anything that is green when hearing “frog”: how object          search. The Quarterly Journal of Experimental
   surface colour and stored object colour knowledge               Psychology, 56, 165–182.
   influence language-mediated overt attention. Quarterly
   Journal of Experimental Psychology, 64, 122-145.
Huettig, F., & McQueen, J. M. (2007). The tug of war
   between phonological, semantic, and shape information in
                                                             1625

