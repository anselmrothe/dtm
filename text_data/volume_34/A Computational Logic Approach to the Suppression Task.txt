UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Logic Approach to the Suppression Task

Permalink
https://escholarship.org/uc/item/2sd6d61q

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Dietz, Emmanuelle-Anna
Holldobler, Steffan
Ragni, Marco

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Computational Logic Approach to the Suppression Task
Emmanuelle-Anna Dietz and Steffen Hölldobler ({dietz,sh}@iccl.tu-dresden.de)
International Center for Computation Logic, TU Dresden
D-01062 Dresden, Germany

Marco Ragni (ragni@cognition.uni-freiburg.de)
Center for Cognitive Science, Friedrichstraße 50
D-79098 Freiburg, Germany
Table 1: The suppression task (Byrne, 1989) and used abbreviations. Subjects received conditionals A, B or C and facts
E, E,L or L and had to draw inferences.

Abstract
A novel approach to human conditional reasoning based on the
three-valued Łukasiewicz logic is presented. We will demonstrate that the Łukasiewicz logic overcomes problems the sofar proposed Fitting logic has in reasoning with the suppression task. While adequately solving the suppression task, the
approach gives rise to a number of open questions concerning
the use of Łukasiewicz logic, unique fixed points, completion
versus weak completion, explanations, negation, and sceptical
versus credulous approaches in human reasoning.

A
B
C
E
E
L
L

Keywords: Łukasiewicz logic; computational logic; suppression task; human reasoning.

Introduction
An interesting study is the suppression task, in which Byrne
(1989) has shown that graduate students with no previous exposure to formal logic did suppress previously drawn conclusions when additional information became available. Interestingly, in some instances the previously drawn conclusions
were valid whereas in other instances the conclusions were
invalid with respect to classical two-valued logic. Consider
the following example: If she has an essay to finish then she
will study late in the library and She has an essay to finish.
Then most subjects (96%) conclude: She will study late in
the library. If subjects, however, receive an additional conditional: If the library stays open she will study late in the library then only 38% of the subjects conclude: She will study
late in the library. This shows, that, although the conclusion
is still correct, the conclusion is suppressed by an additional
conditional. This is an excellent example for human capability to draw non-monotonic inferences.
Table 1 shows the abbreviations that will be used throughout the paper, whereas Table 2 gives an account of the findings of Byrne (1989). As we are using a formal language,
propositions like “She will go to the library” (abbreviated L)
will be represented by propositional variables like l, with the
intended interpretation that if l is true (>), then “She will go
to the library”. Taking a naive propositional approach, we can
represent A by the implication e ← l, where the propositional
variables e and l represent the facts E and L, respectively, and
so on.
It is straightforward to see that classical two-valued logic
cannot model the suppression task adequately: Applying the
classical logical consequence operator to some instances of
the suppression task (like A, C, E) yields qualitatively wrong
answers, due to the monotonic nature of the classical logic.

If she has an essay to finish
then she will study late in the library.
If she has a textbook to read
then she will study late in the library.
If the library stays open
she will study late in the library.
She has an essay to finish.
She does not have an essay to finish.
She will study late in the library.
She will not study late in the library.

Table 2: The drawn conclusions in the experiment of Byrne.
Conditional(s)

Fact

Experimental Findings

A
A, B
A, C

E
E
E

96% of subjects conclude L.
96% of subjects conclude L.
38% of subjects conclude L.

A
A, B
A, C

E
E
E

46% of subjects conclude L.
4% of subjects conclude L.
63% of subjects conclude L.

A
A, B
A, C

L
L
L

53% of subjects conclude E.
16% of subjects conclude E.
55% of subjects conclude E.

A
A, B
A, C

L
L
L

69% of subjects conclude E.
69% of subjects conclude E.
44% of subjects conclude E.

Consequently, at least a non-monotonic operator is needed.
As argued by Stenning and van Lambalgen (2008)1 human
reasoning should be modeled by, first, reasoning towards an
appropriate representation and, second, by reasoning with respect to this representation. As appropriate representation
Stenning and van Lambalgen propose logic programs under
completion semantics based on the three-valued logic used
by Fitting (1985), which itself is based on the three-valued
Kleene (1952) logic.
Unfortunately, some technical claims made by Stenning
and van Lambalgen (2008) are wrong concerning their second step. Hölldobler and Kencana Ramli (2009b) have shown
that the three-valued logic proposed by Fitting is inadequate
for the suppression task. Somewhat surprisingly, the suppression task can be adequately modeled if the three-valued
1 There is an earlier publication (Stenning & van Lambalgen,
2005), but Michiel van Lambalgen advised us to refer to their textbook.

1500

Łukasiewicz (1920) logic is used. The paper gives an account
of this finding and discusses a variety of consequences of this
new logic and some open questions.

Łukasiewicz semantics. Finally, we add abduction to the approach and show that sceptical reasoning is needed in order
to model the suppression task adequately.

Adequacy

Three-Valued Logics

Computational approaches to explain human reasoning
should be cognitively adequate. Usually, the concept of adequacy is measured by distinguishing between conceptual and
inferential adequacy (Strube, 1996). In our context, a system
is conceptually adequate if it appropriately represents human
knowledge. Inferential adequacy measures whether the computations behave similarly to human reasoning. It is common
in Cognitive Science to evaluate theories by performing reasoning experiments on subjects. For instance, Knauff (1999)
investigates which kind of information humans use when representing and remembering spatial arrangements in Allen’s
interval calculus. In Computer Science, one commonly used
hypothesis is, that if computational models are biologically
plausible then they should also behave similar to the biological brain (Herrmann & Ohl, 2009). However, until now there
are no implemented models which easily process computations given a large amounts of data or efficiently deal with
incomplete information. These aspects are fundamental for
elementary reasoning processes. In this paper, we evaluate
the inferential adequacy of our computational logic approach
by examining that our approach gives the same answers as
subjects in the suppression task experiments.

A Computational Logic Approach
Stenning and van Lambalgen (2008) have proposed to use
logic programs under completion semantics and based on a
three-valued logic to model the suppression task. In particular, they suggest that human reasoning is modeled by, first,
reasoning towards an appropriate representation or logical
form (conceptual adequacy) and, second, reasoning with respect to this representation (inferential adequacy).
In the following we introduce three-valued logics and, in
particular, the Łukasiewicz logic. As the chosen representation are logic programs, such programs are introduced next
together with their (weak) completion. We adopt the reasoning step towards an appropriate logical form from Stenning
and van Lambalgen (2008). Thereafter, we discuss threevalued models for logic programs under the Łukasiewicz semantics and, in particular, the model intersection property
which entails the existence of least models. We show that
the conclusions drawn with respect to these least models correspond to the findings in (Byrne, 1989) and conclude that
the derived logic programs under Łukasiewicz semantics are
inferentially adequate for the suppression task.
In order to investigate inferential adequacy we consider the
semantic operator associated with logic programs as defined
by Stenning and van Lambalgen (2008). For each program
P , this operator admits a least fixed point, which is equal to
the least Łukasiewicz model of P . At this point we are able
to discuss the technical problems in (Stenning & van Lambalgen, 2008), while showing that they do not occur if we use

Three-valued logics were introduced by Łukasiewicz (1920).
Table 3 gives the truth tables for different three-valued logics. The symbols >, ⊥, and U denote true, false, and unknown, respectively. For instance, if F is mapped to ⊥ and G
is mapped to > then their conjunction (F ∧ G) is mapped to ⊥
and their disjunction (F ∨ G) is mapped to >. By introducing
Table 3: The three-valued logics
F

F

F

G

∧

∨

←L

↔L

←K

↔S

>
⊥
U

⊥
>
U

>
>
>

>
⊥
U

>
⊥
U

>
>
>

>
>
>

>
⊥
U

>
>
>

>
⊥
⊥

⊥
⊥
⊥

>
⊥
U

⊥
⊥
⊥

>
⊥
U

⊥
>
U

⊥
>
U

⊥
>
U

⊥
>
⊥

U
U
U

>
⊥
U

U
⊥
U

>
U
U

U
>
>

U
U
>

U
>
U

⊥
⊥
>

a third truth value, there are various options to define the truth
tables for the connectives. For example, Kleene (1952) introduced an implication (←K ), whose truth table is identical to
the Łukasiewicz implication (←L ) except in the cases where
precondition and conclusion are both mapped to U: In this
case, the implication itself is mapped to U by Kleene, but to
> by Łukasiewicz. The set of connectives under Łukasiewicz
semantics is {¬, ∧, ∨, ←L , ↔L }. Kleene also introduced a
so-called strong equivalence, where the truth value > is assigned to F ↔S G if F and G are assigned to identical truth
values, and ⊥ is assigned otherwise. Fitting (1985) combined the truth tables for ¬, ∨, ∧ from Łukasiewicz with
the Kleene implication and strong equivalence for investigations within Logic Programming. We will call this combination the Fitting semantics where the set of connectives
is {¬, ∧, ∨, ←K , ↔S }2 . Stenning and van Lambalgen (2008)
use Fitting semantics without giving a reason for this particular choice.

Logic Programs
A logic program is a finite set of expressions of the form
A ← B1 ∧ . . . ∧ Bn ,

(1)

where n ≥ 1, A is an atom, and each Bi , 1 ≤ i ≤ n, is either
a literal, >, or ⊥. A is called head and B1 ∧ . . . ∧ Bn is called
body of the clause (1). A clause of the form A ← > is called
positive fact, whereas a clause of the form A ← ⊥ is called
negative fact. In the sequel, P shall denote a logic program.
Consider the following transformation for a given P :
2 We believe that Fitting had termination analysis of logic programs in his mind when he selected this particular logic.

1501

1. All clauses with the same head A ← Body1 , A ← Body2 , . . .
are replaced by A ← Body1 ∨ Body2 ∨ . . ..
2. If an atom A is not the head of any clause in P (and, thus,
is undefined in P ) then add A ← ⊥.
3. All occurrences of ← are replaced by ↔.
The resulting set is called completion of P (c P ). If step 2 is
omitted, then the resulting set is called weak completion of P
(wc P ). Consider P = {p ← q}, then c P = {p ↔ q, q ↔ ⊥}.
c P entails that p and q are mapped to ⊥. Reasoning with respect to the completion of a logic program is non-monotonic.
For instance, if P 0 = P ∪ {q ← >}, then c P 0 entails that p
and q are mapped to >. The process of weak completion can
be associated with the human interpretation of conditionals as
biconditionals (Evans, Newstead & Byrne, 1993).

Table 4: A summary of the computational logic approach to
the suppression task (Part 1).

Reasoning Towards an Appropriate Logical Form
Stenning and van Lambalgen (2008) have argued that the first
step in modeling human reasoning is reasoning towards an
appropriate logical form. In particular, they argue that conditionals shall not be encoded by implications straight away but
rather by licenses for implications. For example, the conditional A should be encoded by the clause l ← e ∧ ab1 , where
ab1 is an abnormality predicate which expresses that something abnormal is known. In other words, l holds if e holds
and nothing abnormal is known.
We think that Stenning and van Lambalgen (2008) adequately model the representational part of the suppression
task and adopt this reasoning step. Our focus is on the inferential aspect of their approach. In the first two columns of
Table 4 the programs obtained for the first six examples of
the suppression task are depicted. For instance, in PACE we
have that She will study late in the library if either She has an
essay to finish and Nothing abnormal (ab1 ) is known or She
has a textbook to read and Nothing abnormal (ab3 ) is known.
The predicates ab1 , ab2 and ab3 represent different kinds of
abnormality. For instance, ab1 is true when The library does
not stay open and ab3 is true when She does not have an essay
to finish.

Three-Valued Models for Logic Programs
A (three-valued) interpretation is a mapping from a propositional language to the set {>, ⊥, U} of truth values. It
is quite common to represent interpretations by tuples of
the form hI > , I ⊥ i, where I > contains all atoms which are
mapped to >, I ⊥ contains all atoms which are mapped to ⊥,
/ and all atoms which occur neither in I > nor
I > ∩ I ⊥ = 0,
⊥
in I are mapped to U. Let P be a program and I an interpretation. I is a (three-valued) model under Łukasiewicz
semantics for P (I |=L P ) if and only if each clause occurring in P is mapped to > using the truth table depicted in
Table 3. Likewise, |=F can be defined with respect to the Fitting semantics. For instance, consider P = {p ← q}. Then
under Łukasiewicz semantics we have three different mod/ h0,
/ {p, q}i and h0,
/ 0i.
/ Under Fitting semantics
els h{p, q}, 0i,
only the first two interpretations are models, because if p and
q are mapped to U then p ← q ∈ P is mapped to U as well.

P

clauses

wc P

lm L wc P

Byrne

PAE

l ← e ∧ ab1
ab1 ← ⊥
e←>

l ↔ e ∧ ab1
ab1 ↔ ⊥
e↔>

h{e, l}, {ab1 }i

96%
L

PABE

l ← e ∧ ab1
l ← t ∧ ab2
ab1 ← ⊥
ab2 ← ⊥
e←>

l ↔ (e ∧ ab1 )
∨ (t ∧ ab2 )
ab1 ↔ ⊥
ab2 ↔ ⊥
e↔>

h{e, l}, {ab1 , ab2 }i

96%
L

PACE

l ← e ∧ ab1
l ← o ∧ ab3
ab1 ← o
ab3 ← e
e←>

l ↔ (e ∧ ab1 )
∨ (o ∧ ab3 )
ab1 ↔ o
ab3 ↔ e
e↔>

h{e}, {ab3 }i

38%
L

PAE

l ← e ∧ ab1
ab1 ← ⊥
e←⊥

l ↔ e ∧ ab1
ab1 ↔ ⊥
e↔⊥

/ {e, l, ab1 }i
h0,

46%
L

PABE

l ← e ∧ ab1
l ← t ∧ ab2
ab1 ← ⊥
ab2 ← ⊥
e←⊥

l ↔ (e ∧ ab1 )
∨ (t ∧ ab2 )
ab1 ↔ ⊥
ab2 ↔ ⊥
e↔⊥

/ {e, ab1 , ab2 }i
h0,

4%
L

PACE

l ← e ∧ ab1
l ← o ∧ ab3
ab1 ← o
ab3 ← e
e←⊥

l ↔ (e ∧ ab1 )
∨ (o ∧ ab3 )
ab1 ↔ o
ab3 ↔ e
e↔⊥

h{ab3 }, {e, l}i

63%
L

Reasoning with Respect to Least Models
In order to identify the desired model of a certain program,
we reason with respect to their least models. Least models are
guaranteed to exist if the model intersection property holds:
∩{I | I |=L P } |=L P ,
∩{I | I |=L wc P } |=L wc P .
In Hölldobler and Kencana Ramli (2009b) it was shown that
the model intersection property holds for (weakly completed)
programs under Łukasiewicz semantics. The model intersection property for programs does not hold under Fitting seman/ and
tics. Consider again P = {p ← q}, then both, h{p, q}, 0i
/ {p, q}i, are models for P , whereas their intersection h0,
/ 0i
/
h0,
is not a model for P under Fitting semantics.
The third column of Table 4 shows the weak completions
of the programs encoding the first six examples of the suppression task. Column 4 in Table 4 depicts the corresponding
least models where lm L denotes the least model of its argument under Łukasiewicz semantics. The last column shows
the results of the suppression task. Specifically we find that

1502

lm L wc PAE
lm L wc PABE
lm L wc PACE
lm L wc PAE
lm L wc PABE
lm L wc PACE

=
=
=
=
=
=

h{e, l}, {ab1 }i
h{e, l}, {ab1 , ab2 }i
h{e}, {ab3 }i
/ {e, l, ab1 }i
h0,
/ {e, ab1 , ab2 }i
h0,
h{ab3 }, {e, l}i

|=L
|=L
6|=L
|=L
6|=L
|=L

l
l
l ∨l
l
l ∨l
l

where 6|=L means that a given formula cannot be concluded.
Our approach coincides with the seemingly favored results of
the suppression task and thus appears to be adequate.

Computing Least Models
In Computational Logic, least models are usually computed
as least fixed points of appropriate semantic operators (see,
e.g., Apt & Emden, 1982). Stenning and van Lambalgen (2008) devised such an operator for programs discussed
herein: Let I be an interpretation in ΦP (I) = hJ > , J ⊥ i, where
J > = {A | there exists A ← body ∈ P with I(body) = true},
J ⊥ = {A | there exists A ← body ∈ P and
for all A ← body ∈ P we find I(body) = f alse}.
As shown in Hölldobler and Kencana Ramli (2009b) for any
P , the least fixed point of ΦP is identical to lm 3L wc P and can
be computed by iterating ΦP starting with the empty interpretation. The following example shows how the least model of
/ 0i:
/
PACE is computed starting with interpretation I0 = h0,
I1
I2

/
= ΦPACE (I0 ) = h{e}, 0i
= ΦPACE (I1 ) = h{e}, {ab3 }i = ΦPACE (I2 )

where I2 is the least fixed point of ΦPACE . This is not a model
under Fitting semantics because the clause l ← o ∧ ab3 ∈
PACE is mapped to U and not to > such as under Łukasiewicz
semantics. This is a counter example for Lemma 4(1.) in
Stenning and van Lambalgen (2008) which states that the
least fixed point of the ΦP operator under Fitting semantics is the minimal model of P . Another statement made by
Stenning and van Lambalgen (2008), Lemma 4(3.) states,
that all models of c P are fixed points of ΦP and every fixed
point is a model. Consider the completion of ΦPABE , then t is
mapped to ⊥ and therefore l is mapped to ⊥ as well. How/ {e, ab1 , ab2 }i where t and l
ever, its least fixed point is h0,
are undefined. This example also shows that reasoning under Fitting semantics and with respect to the completion of a
program is not adequate as only 4% conclude L in this case.

processes can best be described as abductive, that is, a plausible explanation is computed given some observation. Following Kakas, Kowalski, and Toni (1993) we consider an abductive framework consisting of a program P as knowledge base,
a set A of abducibles consisting of the (positive and negative)
facts for each undefined predicate symbol in P ,4 and the logical consequence relation |=lmwc
, where P |=lmwc
F if and only
L
L
if lm 3L wc P (F) = > for the formula F. As observations we
consider literals.
Let hP , A , |=lmwc
i be an abductive framework and O an
L
observation. O is explained by E if and only if E ⊆ A ,
P ∪ E is satisfiable, and P ∪ E |=lmwc
O . Usually, minimal
L
explanations are preferred. In case there exist several minimal explanations, then two forms of reasoning can be distinguished. F follows sceptically from program P and observation O (P , O |=s F) if and only if O can be explained
and for all minimal explanations E we find P ∪ E |=lmwc
O,
L
whereas F follows credulously from P and O (P , O |=c F)
if and only if there exists a minimal explanation E such that
P ∪ E |=lmwc
O .5 For instance, consider the following two
L
programs under sceptical reasoning:
1. PAB where O = l: A = {e ← >, e ← ⊥,t ← >,t ← ⊥}
/ {ab1 , ab2 }i. There are two minimal
and lm 3L wc PAB = h0,
explanations with either {e ← >} and {t ← >}. Thus, we
cannot conclude whether She has an essay to finish or not.
2. PAC where O = l: A = {e ← >, e ← ⊥, o ← >, o ← ⊥}
/ 0i.
/ There is only one minimal exand lm 3L wc PAC = h0,
planation {e ← >, o ← >} and thus She has an essay to
finish.
Table 5 depicts the programs, the observations and the minimal explanations for the second part of the suppression task
in the second, third, and fourth column, respectively. The second last column shows the least model of the weak completion of the union of the program and the minimal explanation
under the Łukasiewicz semantics and the final one shows the
results of the suppression task. If we reason sceptically with
respect to these least models, then we obtain

PA , l |=s e,
PAB , l 6|=s e,
PAC , l |=s e,

Unique Fixed Point
As mentioned in the previous subsection, the least fixed point
of the operator ΦP can be computed by iterating ΦP starting with the empty interpretation. However, if the operator is a contraction then by the Banach Contraction Theorem
(Banach, 1922) the operator has a unique fixed point which
can be computed by iterating the operator starting with an arbitrary interpretation. As shown in Hölldobler and Kencana
Ramli (2009a), ΦP is a contraction if P is acyclic3 . All programs shown in Table 4 are acyclic.

Abduction

which are adequate answers if compared to the seemingly favored results of the suppression task. One should observe that
a credulous agent concludes e from P = PAB and O = l, which
according to Byrne (1989) only 16% of the subjects did.

Open Questions
Łukasiewicz Logic
This logic was selected because the technical bugs in
Stenning and van Lambalgen (2008) can be solved by switching from Fitting to Łukasiewicz semantics. In particular, the

The second part of the suppression task deals with the affirmation of the consequent and modus tollens. These reasoning
3 A program P

PA , l |=s e,
PAB , l |=s e,
PAC , l 6|=s e,

is acyclic if there exists a numbering for all propositional variables such that for all clauses in P the value of the head
is strictly larger than the value of the literals in the body.

4 Recall that A is undefined in P if and only if P does not contain
a clause of the form A ← Body.
5 See (Hölldobler, Philipp, & Wernhard, 2011) for more details.

1503

Table 5: A summary of the computational logic approach to
the suppression task (Part 2). The cases P = PAB , O = l and
P = PAC , O = l have two minimal extensions.

P

clauses

O

E

lm L wc (P ∪ E )

Byrne

PA

l ← e ∧ ab1
ab1 ← ⊥

l

e←>

h{e, l}, {ab1 }i

53%
E

PAB

l ← e ∧ ab1
l ← t ∧ ab2
ab1 ← ⊥
ab2 ← ⊥

l

e←>

h{e, l}, {ab1 , ab2 }i

16%
E

t ←>

h{l,t}, {ab1 , ab2 }i

PAC

l ← e ∧ ab1
l ← o ∧ ab3
ab1 ← o
ab3 ← e

l

e←>
o←>

h{e, l, o}, {ab1 , ab3 }i

55%
E

PA

l ← e ∧ ab1
ab1 ← ⊥

l

e←⊥

/ {e, l, ab1 }i
h0,

69%
E

PAB

l ← e ∧ ab1
l ← t ∧ ab2
ab1 ← ⊥
ab2 ← ⊥

l

e←⊥
t ←⊥

/ {e, l,t, ab1 , ab2 }i
h0,

69%
E

PAC

l ← e ∧ ab1
l ← o ∧ ab3
ab1 ← o
ab3 ← e

l

e←⊥

h{ab3 }, {e, l}i

44%
E

o←⊥

h{ab1 }, {l, o}i

puted so far.

Completion versus Weak Completion
The program PABE served as an example to illustrate that
completion is inadequate for the suppression task whereas
weak completion is adequate. Likewise, Hölldobler et al.
(2011) have shown in a detailed study that the programs mentioned in Table 5 together with their minimal explanations
must be weakly completed in order to adequately model the
suppression task, whereas completion does not. Are there
other human reasoning episodes which support the claim that
weak completion is adequate? Even if so, the problem remains to explicitly add negative facts (in the reasoning step
towards an appropriate logical form) for those predicates,
which should be mapped to ⊥ like ab1 in the program PAE .

Sceptical versus Credulous Reasoning
The case of program P = PAB and observation O = l in Ta-

model intersection property holds under Łukasiewicz semantics. Hence, for each program P a least model does exist
which can be computed as least fixed point of the associated
semantic operator ΦP . Moreover, a rigorous study has revealed that the suppression task can be adequately modeled
under Łukasiewicz semantics, whereas this does not hold for
Fitting semantics. Nevertheless, the main question of whether
Łukasiewicz logic is adequate for human reasoning is still
open. For example, in the Łukasiewicz logic the Deduction
Theorem does not hold 6 . Hence, it would be interesting to
see how humans deal with the deduction theorem. Can other
typical human reasoning problems like the Wason (1968) selection task be adequately modeled under Łukasiewicz semantics?

Unique Fixed Point
For each program P shown in Table 4 the operator ΦP is a
contraction. Thus, there is a unique fixed point, which can be
computed by iterating ΦP on some initial interpretation. Consequently, if in the suppression task subjects are influenced
towards some initial non-empty interpretation, their performance should not differ provided that they have enough time
to compute the least fixed point; it should differ, however, if
they are interrupted before the least fixed point is computed
and asked to reason with respect to the interpretation com6 A logic satisfies the Deduction Theorem if for any finite set
of formulae Φ = {φ1 , φ2 , ..., φn } and any formula ψ the following
holds: Φ |= ψ if and only if |= (φ1 ∧ φ2 ∧ · · · ∧ φn ) → ψ.

ble 5 shows that agents must reason sceptically in order to
adequately model this case. Whereas this is a striking case
for sceptical reasoning, the case P = PAC and O = l is less
convincing. A sceptical agent will not conclude e, whereas
a credulous agent will conclude e. Compared to the corresponding case (A,C, L) shown in Table 2, 44% of the subjects
conclude E. Unfortunately, Byrne (1989) (and related publications that we are aware of) gives no account of the distribution of the answers given by those subjects who did not
conclude E. Hence, at the moment we can argue in favor of a
sceptical agent (the majority of the subjects did not conclude
E), but – given the complete distribution – it may be the case
that one can argue in favor of a credulous agent (there are
more subjects concluding E than subjects concluding E and
subjects answering “I don’t know”).

Explanations
The approach presented in this paper is based on minimal explanations. Although, there are findings corroborating the human preference of minimal explanations (over non-minimal
ones) (Ormerod, Manktelow, & Jones, 1993) – this holds only
partially (Johnson-Laird, Girotto, & Legrenzi, 2004). Computational models of abduction typically generate explanations iteratively such that minimal explanations are generated
first. How are minimal explanations computed by humans?
What happens if there are more than one minimal explanation?

Negation
In the presented approach positive information is preferred
over negative one. Consider, for example, the program P =
/ and,
{q ← >, q ← ⊥}. The least model of wc P is h{q}, 0i
hence, an agent reasoning with respect to this model will conclude q. Is this consistent with human reasoning? The presented approach could be extended to include integrity constraints like ⊥ ← q. Any model for a program containing such
an integrity constraint must map q to ⊥. Is this adequate for
human reasoning? If so, under which conditions shall such

1504

integrity constraints be added within the reasoning step towards an appropriate logical form?

Connectionist Realization
As shown in (Hölldobler & Kencana Ramli, 2009c), the computation of the least fixed point of the semantic operator ΦP
associated with a program P can be realized within the coremethod (Bader, Hitzler, Hölldobler, & Witzel, 2007). In this
connectionist realization, ΦP is computed by a feed-forward
network, whose output units are recurrently connected to the
input units. Whereas this network is trainable by backpropagation and, thus, ΦP can be learned by experience, there is no
evidence whatsoever that backpropagation is biological plausible. The approach can be extended to handle abduction following (Garcez, Gabbay, Ray, & Woods, 2007). However, in
this setting, explanations are generated in a fixed, hard-wired
sequence, which does not seem to be plausible either.

Summary
We have presented an adequate computational logic approach
for the suppression task. It is based on weakly completed
logic programs under Łukasiewicz semantics. Such programs
admit least models which can be computed by iterating an appropriate semantic operator. Reasoning is performed with respect to the least models. The approach is extended by sceptical reasoning within an abductive framework. Moreover,
it can be realized in a connectionist setting. The approach
has been carefully tested against alternatives like completed
logic programs, Fitting semantics, and credulous reasoning,
but none of these variations was found to be adequate.

Acknowledgments
Many thanks to Bertram Fronhöfer, Caroline Dewi Puspa
Kencana Ramli, Tobias Philipp, and Christoph Wernhard.

References
Apt, K., & Emden, M. van. (1982). Contributions to the
theory of logic programming. J. of the ACM, 29, 841-862.
Bader, S., Hitzler, P., Hölldobler, S., & Witzel, A. (2007).
The core method: Connectionist model generation for
first-order logic programs. In B. Hammer & P. Hitzler (Eds.), Perspectives of neural-symbolic integration
(Vol. 77, p. 205-232). Berlin, Heidelberg: Springer.
Banach, S. (1922). Sur les opérations dans les ensembles
abstraits et leur application aux équations intégrales. Fund.
Math., 3, 133-181.
Byrne, R. (1989). Suppressing valid inferences with conditionals. Cognition, 31, 61-83.
Evans, J.S.B.T., Newstead, S.E., & Byrne, R.M.J. (1993).
Human reasoning: The psychology of deduction. Hillsdale,
NJ England: Lawrence Erlbaum Associates.
Fitting, M. (1985). A Kripke–Kleene semantics for logic
programs. Journal of Logic Programming, 2(4), 295-312.
Garcez, A. d’Avila, Gabbay, D., Ray, O., & Woods, J. (2007).
Abductive reasoning in neural-symbolic learning systems.
TOPOI, 26, 37-49.

Herrmann, C. S., & Ohl, F. W. (2009). Cognitive adequacy in brain-like intelligence. In B. Sendhoff, E. Körner,
O. Sporns, H. Ritter, & K. Doya (Eds.), Creating BrainLike Intelligence. Springer.
Hölldobler, S., & Kencana Ramli, C. D. P. (2009a). Contraction properties of a semantic operator for human reasoning. In L. Li & K. K. Yen (Eds.), Proceedings of the
fifth international conference on information (p. 228-231).
International Information Institute.
Hölldobler, S., & Kencana Ramli, C. D. P. (2009b). Logic
programs under three-valued Łukasiewicz’s semantics. In
P. M. Hill & D. S. Warren (Eds.), Logic programming (Vol.
5649, p. 464-478). Springer Berlin Heidelberg.
Hölldobler, S., & Kencana Ramli, C. D. P. (2009c). Logics and networks for human reasoning. In C. Alippi,
M. M. Polycarpou, C. G. Panayiotou, & G. Ellinasetal
(Eds.), Artificial neural networks – ICANN (Vol. 5769,
p. 85-94). Springer Berlin Heidelberg.
Hölldobler, S., Philipp, T., & Wernhard, C. (2011). An
abductive model for human reasoning.
In Proceedingth tenth international symposium on logical formalizations of commonsense reasoning. (commonsensereasoning.org/2011/proceedings.html)
Johnson-Laird, P., Girotto, V., & Legrenzi, P. (2004). Reasoning from inconsistency to consistency. Psychological
Review, 111(3), 640–661.
Kakas, A. C., Kowalski, R. A., & Toni, F. (1993). Abductive
Logic Programming. Journal of Logic and Computation,
2(6), 719-770.
Kleene, S. (1952). Introduction to metamathematics. NorthHolland.
Knauff, M. (1999). The cognitive adequacy of Allen’s interval calculus for qualitative spatial representation and reasoning. Spatial Cognition and Computation, 1, 261–290.
Łukasiewicz, J. (1920). O logice trójwartościowej. Ruch
Filozoficzny, 5, 169-171.
(English translation: On
Three-Valued Logic. In: Jan Łukasiewicz Selected Works.
(L. Borkowski, ed.), North Holland, 87-88, 1990.)
Ormerod, T., Manktelow, K., & Jones, G. (1993). Reasoning
with three types of conditional: Biases and mental models.
Quarterly Journal of Experimental Psychology.
Stenning, K., & Lambalgen, M. van. (2005). Semantic interpretation as computation in nonmonotonic logic: The real
meaning of the suppression task. Cognitive Science, 29(6),
919-960.
Stenning, K., & Lambalgen, M. van. (2008). Human reasoning and cognitive science. MIT Press.
Strube, G. (1996). Wörterbuch der Kognitionswissenschaft.
Klett-Cotta.
Wason, P. (1968). Reasoning about a rule. The Quarterly
Journal of Experimental Psychology, 20, 273-281.

1505

