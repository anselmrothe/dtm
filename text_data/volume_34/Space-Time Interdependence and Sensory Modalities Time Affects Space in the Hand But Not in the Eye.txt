UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Space-Time Interdependence and Sensory Modalities: Time Affects Space in the Hand But
Not in the Eye

Permalink
https://escholarship.org/uc/item/7zk07749

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Cai, Zhenguang
Connell, Louise

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Space-Time Interdependence and Sensory Modalities: Time Affects Space in the
Hand But Not in the Eye
Zhenguang G. Cai (zhenguangcai@gmail.com)
Louise Connell (louise.connell@manchester.ac.uk)
School of Psychological Sciences, University of Manchester, Coupland 1, Oxford Road
Manchester, M13 9PL, UK
Abstract

2007), and with a longer line than a shorter one (Casasanto
& Boroditsky, 2008).
There are two alternative accounts of the relationship
between time and space representations. According to the
spatial metaphor account, people employ spatial metaphors
in thinking or talking about time such that they use their
concrete spatial experience to support their understanding
of abstract time processing (Boroditsky, 2000; Gibbs, 2006;
Lakoff & Johnson, 1980, 1999). The temporal relation of
two events can be expressed metaphorically as a relation
between two locations in space (e.g., tomorrow is ahead of
yesterday). Similarly, a temporal duration can be
metaphorically envisioned as the distance from a spatial
location representing the onset of the duration and a spatial
location representing the offset of the duration. Critically,
the spatial metaphor account assumes that time and space
remain two separate representational systems with an
asymmetric mapping between them: concurrent spatial
information should always affect its dependent domain of
time to a greater extent than concurrent temporal
information can affect space (Casasanto & Boroditsky,
2008; Casasanto, Fotakopoulou, & Boroditsky, 2010;
Merritt, Casasanto, & Brannon, 2010).
Alternatively, according to the spatial representation
account of time, temporal and spatial information are
processed in a common neural substrate and share
representational and attentional resources. Time is closely
related to space in action and perception (e.g., Walsh,
2003): space and time are often coordinated in action and
correspond to each other in movement (e.g., things travel a
certain distance in a certain time). Thus, temporal duration
and spatial distance may share a representational format
(e.g., Locke, 1689/1995), such that two events are separated
by a particular duration in the same way that two locations
are separated by a particular distance. Some stronger
versions of spatial representation theories have argued that
time, space and number all share a common magnitude
representation (Burr, Ross, Binda & Morrone, 2010; Walsh,
2003), but a weaker version of the spatial representation
theory of time does not necessarily require the magnitude
assumption. Critically, rather than comprising separate
representational domains, time and space occupy an
overlapping temporo-spatial representation that may be
affected by concurrent temporal or spatial information.
Since the same representation can subserve both temporal
and spatial processing, the spatial representation account
thus differs from the spatial metaphor account in allowing

Time and space are intimately related, but what is the real
nature of this relationship? Is time mapped metaphorically
onto space, or do the two domains share a common
representational format? In the present paper, participants
touched (but could not see) physical sticks while listening to
an auditory note. Judgements of stick length were affected by
concurrent note duration, but not vice versa. When
participants were allowed to see as well as touch the sticks,
however, the effects reversed. These findings run counter to
the spatial metaphor account of time, which claims that
effects of space on time should always be stronger than those
of time on space. Rather, our findings support the spatial
representation account, in which time and space share a
common neural substrate that may be affected by concurrent
temporal or spatial information, depending on the perceptual
acuity of the modality used to perceive space.
Keywords: Time; space; representation; haptic perception;
visual perception; sensory dominance; metaphor

Though our immediate perception of the world is limited to
our senses such as vision and hearing, we use these senses
to perceive and represent other dimensions of the world
besides colours and sounds. For instance, we can perceive
the spatial information of an object (e.g., its length, height
and size) by looking at it or touching it. How we perceive
and represent more abstract domains such as time, however,
has been a perennial philosophical question. Many
researchers have suggested that abstract domains are
grounded to some extent in more familiar concrete domains
that we develop through sensorimotor experience (e.g.,
Barsalou & Wiemer-Hastings, 2005; Gibbs, 2006; Lakoff &
Johnson, 1980, 1999). Time, for example, can be
understood through the domain of space, as reflected in our
use of language. Speakers of English often talk about time
in spatial terms (e.g., a long/short time) and sometimes
space in temporal terms (e.g., I am 5 minutes from the
airport). A range of studies has provided evidence that
these linguistic expressions reflect a deeper conceptual
bridge between time and space. For example, people
perceive the passage of time either as if they are moving in
space towards the future, or as if the future is moving
towards them (e.g., Boroditsky & Ramscar, 2002; McGlone
& Harding, 1998). Other studies have shown that space
affects the perception of temporal durations such that
people experience longer subjective time when they
imagine themselves inside a larger scale model of a room
than inside a smaller one (DeLong, 1981), with a larger
square than a smaller one (Xuan, Zhang, He, & Chen,

168

the effects of time on space to be as strong as or stronger
than the effects of space on time, depending on factors we
describe below.
Empirical evidence has thus far favoured the spatial
metaphor account, with the strongest evidence coming from
studies showing apparently robust asymmetric effects of
space on time in nonlinguistic paradigms. For example,
Casasanto and Boroditsky (2008; see also Casasanto et al.,
2010) showed participants a horizontal line onscreen and
then asked them to reproduce either the length of the line or
its duration of presentation. They found that people's
estimates of the line’s duration increased as a function of its
length, but that estimates of length remained unaffected by
the duration of the line onscreen. Furthermore, the same
pattern emerged whether the line was static or grew to its
full length, when the line was replaced with a moving dot,
or when a concurrent auditory note provided an additional
source of temporal information. A later variant of this
nonlinguistic task, where participants categorised the length
or duration of a line as long or short according to learned
standards, did find an effect of time on space (Merritt et al.,
2010), but since this effect was smaller than that of space
on time, the asymmetric hypothesis of the spatial metaphor
account was supported.
The above studies all use the visual modality to present
spatial information. However, spatial representations are
not themselves visual, and are rather handled by a
multimodal or supramodal system that draws perceptual
input from visual, haptic, or auditory modalities (or even
from linguistic descriptions) in order to create a common
spatial representation (Bryant, 1992; Giudice, Betty, &
Loomis, 2011; Lacey, Campbell & Sathian, 2007). Visual
perception has the best spatial acuity (i.e., the sharpest or
most detailed resolution) of all human perceptual
modalities, and so spatial representations resulting from
vision have a level of specificity that is not found in spatial
representations resulting from other perception. Therefore,
the asymmetric effects of space on time found by Casasanto
and colleagues may be due to the high spatial acuity from
vision being relatively impervious to distortion rather than
to an asymmetric mapping between domains.
In the present paper, we examined the interaction of time
and space using touch rather than vision. Participants
perceived spatial information regarding the length of a stick
via haptic (i.e., tactile and proprioceptive) perception while
concurrently perceiving a note for a particular duration. As
in Casasanto and Boroditsky (2008), participants attended
to both the spatial length and temporal duration in each trial
and then reproduced either length or duration. If the spatial
metaphor account is correct, any effects of time on spatial
judgements should be substantially weaker than the usual
effects of space on temporal judgements. In contrast, if the
spatial representation account is correct, then whether time
affects space depends on the relative acuity of spatial
representations. Though space can be perceived either
visually or haptically, research has suggested that hapticspatial representations are more prone to distortion than

those of vision (e.g., Lederman, Klatsky & Barber, 1985);
hence, we predicted that haptic space would be susceptible
to interference from concurrent temporal information.
Furthermore, since haptic-spatial representations are less
acute than visuo-spatial representations (e.g., Schultz &
Petersik, 1994), they may not be able to distort time as
visuo-spatial representations do. Thus, when spatial
information relies on touch, we expected the effect of time
on space to be substantially stronger than the effects of
space on time.

Experiment 1
In this study, people were presented with a stick that they
could touch but not see, so information regarding spatial
length was haptically (but not visually) perceived while
hearing a concurrent note for a particular duration. We then
asked participants to reproduce either the spatial length of
the stick by holding their hands apart (still with no visual
feedback) or the temporal duration of the note by holding
down a button. Following the spatial representation
account, we expected concurrent temporal duration to affect
the reproduction of spatial length, but for spatial concurrent
information to have limited or no effects at all on the
reproduction of duration.

Method
Participants Thirty-two right-handed native speakers of
English were recruited from the University of Manchester
community (30 women, mean age = 19.2; two were later
excluded from data analysis; see below). They all had
normal or corrected-to-normal vision and had no hearing
impairments. Participants received £5 or course credits for
their participation.
Materials Eight rigid, hollow plastic sticks (ca. 16 mm in
diameter) were divided into varying lengths (100 – 450 mm
in steps of 50 mm). Eight sine waveform notes of 440 Hz
were created in varying durations (1000 – 4500 ms in steps
of 500 ms) with Audacity (Version 1.2.6). Crossing stick
lengths with note durations, we created 64 stick-note
stimulus sets. Each stimulus set was then combined with a
length or duration reproduction task and divided into two
stimulus lists, such that if a stimulus set occurred in List 1
with a length task, it occurred in List 2 with a duration task
(i.e., task was counterbalanced across stick length and note
duration). Each list thus had 32 stick-note pairs, half with a
length task and the other half with a duration task.
Procedure Each participant was individually tested in a
cubicle. The participant sat at a table with a response
button box on his or her lap, and placed the hands and
forearms through the gap at the bottom of a barrier, with a
cape fastened around the neck to block all visual access to
the hands and arms (see Figure 1). During the testing
procedure, the experimenter (first author) sat at right angles
to the participant and had a box to one side containing the
eight sticks. The experiment was run with Superlab 4.0,

169

with the order of trials individually randomized per
participant. In each trial, the experimenter placed the
relevant stick (as designated by the experimental
programme) on the table and the participant pressed against
the ends of the stick with index fingers; at point of contact,
the experimenter pressed a key to begin playing the note.
When the note stopped, the participant let go of the stick
and withdrew the hands to the base of the barrier (i.e., to
disrupt hand positioning so stick length was not passively
preserved between the index fingers). The experimenter
then returned the stick to the box and verbally instructed
which judgement the participant was to make (as designated
by the experimental programme). When the experimenter
said “Time”, the participant held down a button on the
response box (located on the lap) for the same duration as
the note. When the experimenter said “Length”, the
participant reached forward (until they touched a board held
up by the experimenter) and indicated the length of the stick
between the index fingers; the experimenter then removed
the board and took a photograph of the hands' position
using a fixed camera. Use of the board (at location 'X' in
Figure 1) ensured that the participants' hands were at a fixed
distance from the camera. The photographs were taken at a
resolution that allowed distance discrimination finer than 1
mm. Each participant performed a practice session of 4
trials before the real experiment, and the whole procedure
lasted about 30 minutes.

right index fingertips; distance was calculated as the
difference between x-coordinates. For reliability analysis,
the second author blind-coded a random 12% sample of
pictures: agreement between coders was very high (r =
.999) and accurate to within 1 mm distance. All references
to length are in mm.
Design & Analysis We excluded failed trials in which the
participant did not proceed as instructed (e.g., wrong key
presses; missed trials), and then removed outliers more than
2.5 SDs away from the mean for each length or duration
condition. The data trimming resulted in the exclusion of
less than 2% of either the length or duration trials.
Following the criterion in Casasanto and Boroditsky (2008,
p. 581), two participants who did poorly in either the length
or duration judgements (i.e., when the regression coefficient
fell below 0.5 in either the regression of reproduced
durations with note duration or reproduced lengths with
stick length) were excluded from the analysis.1 We then
used linear mixed effects (LME) modelling to analyse
condition means for each participant (e.g., average
reproduced duration per participant was regressed on each
different stick length). The final model always included the
fixed effect; the random effects always included the
participant intercept.2 Regression coefficients are reported
as unstandardised βvalues with standard errors.

Results and discussion
Reproduced length was significantly affected by
experienced duration, β = 0.0033, SE = 0.0015, t(209) =
2.27, p = .024, but reproduced duration was unaffected by
stick length, β = 0.113, SE = 0.114, t(209) = 0.99, p =
.324. Sticks that were accompanied by a longer duration
note were judged to be longer in length, and sticks
accompanied by a shorter duration note were judged to be
shorter in length (see Figure 2). People's judgements of
spatial distance perceived through touch were influenced by
their temporal experience, but not vice versa. Both spatial
and temporal estimates were highly accurate: reproduced
durations were well predicted by actual note duration, β =
0.771, SE = 0.014, t(209) = 53.56, p < .0001, and
reproduced lengths were well predicted by actual stick
length, β = 0.818, SE = 0.011, t(209) = 76.20, p < .0001.
The results of the experiment support the spatial
representation rather than spatial metaphor account of time.
When space is haptically perceived, it does not affect time
perception; instead, time interferes with the perception of
haptic space. Our findings stand in direct contrast to those
of previous studies that found visual space influenced time
but not the other around (Casasanto & Boroditsky, 2008;
Casasanto et al., 2010; Merritt et al., 2010). These

Figure 1: Schematic of the experimental setup: 'X' marks
the location of both haptic perception and reproduction of
length. The cape and barrier (both opaque) were used in
Experiment 1 to block visual access to spatial information,
and were absent in Experiment 2 to allow access.
Measures Duration reproductions in milliseconds were
measured from onset to release of the response button).
Length reproductions were measured by the first author
from digital photographs by presenting each picture
(condition-blind) and clicking on the centre of the left and

1

The inclusion of these two participants did not change the
statistical pattern of the results in this experiment.
2
The random subject slope did not significantly contribute to
the model fit in any of the LME analyses; thus, we did not include
it as a random effect.

170

discrepancies can be attributed to the different acuities of
spatial representations in different modalities, as hapticspatial representations (as in our Experiment 1) are of lower
acuity than visuo-spatial representations (as in previous
studies), and hence are prone to distortion by temporospatial information to a greater extent. Such an account then
predicts that if space is visually perceived , the effects in
Experiment 1 will be reversed. That is, highly acute visual
perception of the stick will affect participants’ time
judgement, but spatiotemporal information will not be
powerful enough to affect the vivid visuo-spatial memory in
the length task. We test this hypothesis in Experiment 2.

temporal judgements but not vice versa (i.e., a restoration of
the usual asymmetric effect of space on time).

Method
Participants Twenty-six participants were recruited as in
Experiment 1 (22 women, mean age = 19.3; six were later
excluded from data analysis; see below).
Materials As per Experiment 1.
Procedure The procedure was the same as in Experiment
1, except 1) the cape and barrier were removed (see Figure
1) so that participants could see the stick as well as touch it,
and see their hands when reproducing length; and 2) the
stick was presented at jittered transverse positions in order
to discourage participants from using the visual cues of the
desk (e.g., distance from side edge) when reproducing the
length of the stick.
Measures As per Experiment 1. Double-coding of 15% of
the lengths shows very high agreement between the two
coders (r > .999) and accurate to within 1 mm distance.
Design & Analysis The same data trimming method as in
Experiment 1 resulted in the removal of less than 2% of
either the length or duration trials. Six participants were
excluded according to the exclusion criterion adopted in
Experiment 1.3

Results and discussion
Reproduced length was unaffected by experienced duration,
β = 0.0016, SE = 0.0016, t(139) = 0.98, p = .329, but
reproduced duration was significantly affected by stick
length, β = 0.325, SE = 0.133, t(139) = 2.44, p = .016.
Actual durations that were accompanied by shorter sticks
were judged to take less time than durations that were
accompanied by longer sticks (see Figure 3). People's
judgements of time were influenced by their visual-haptic
perception of spatial distance, but not vice versa. Both
spatial and temporal estimates were again highly accurate:
reproduced durations were well predicted by actual
duration, β = 0.773, SE = 0.017, t(139) = 43.72, p < .0001,
and reproduced lengths were well predicted by actual
length, β = 0.739, SE = 0.010, t(139) = 70.71, p < .0001.
Results in Experiment 2 thus demonstrated that when
space was perceived in vision, the effects in Experiment 1
were reversed; that is, visual space influenced time but not
the other way round, just as found in previous studies by
Casasanto and colleagues. As predicted by the spatial
representation account of time, the ability of time to affect
space depends on the relative acuity of spatial
representations.

Figure 2: Effects of time on space for haptic perception in
Experiment 1 (A), with no corresponding effects of space
on time (B). Error bars show one SE. R2 fit is for graphed
means.

Experiment 2
This study used the same paradigm as Experiment 1 with
one exception: people were allowed to see as well as touch
the stick, so information regarding spatial length was both
haptically and visually perceived. Since the visual modality
tends to be dominant in perception (e.g., participants tend to
report only visual perception when a visual stimulus is
simultaneously presented with a auditory or haptic stimulus:
Colavita, 1974; Hartcher-O’Brien et al., 2008), we expected
the high spatial acuity of vision in Experiment 2 to affect

3

Again, the inclusion of these 6 participants did not change the
statistical pattern in the experiment.

171

direction.
The spatial representation account thus allows for a twoway interdependence between time and space, which is
mediated by the acuity of the sensory modality in which
space is perceived. Highly sharp and stable visuo-spatial
representations exert a strong influence on time judgements
and are relatively impervious to temporal interference,
while more distortable haptic-spatial representations are not
acute enough to influence time and instead are prone to
interference from temporal information. This spatial
representation account is also consistent with the findings
of Merritt et al. (2010), who found symmetric effects
between space and time in rhesus monkeys but not in
humans. Merritt et al argued that one explanation for the
discrepancy between humans and monkeys is that human
language facilitates the use of metaphoric mappings in
spatial representations of time thinking; monkeys, lacking
space-time metaphors, also lack asymmetric mappings
between the domains. However, it is possible for human
language to facilitate greater precision in visuo-spatial tasks
without recourse to time-space metaphoric mappings. In
their paradigm, Merritt and colleagues required participants
to memorise two standard reference lines: one short (6 cm)
and one long (24 cm). When later presented with another
line, monkeys had only their visuo-spatial memory of the
reference lines to help them decide if this new line was long
or short, whereas humans also had a verbal numeric label
available for what constituted long or short. Previous work
has shown that availability of verbal numerical labels
enhance accuracy in dot estimation tasks (Izard & Dehaene,
2008; Pica, Lemer, Izard, & Dehaene, 2004), and that
verbal shadowing disrupts spatial memory in adults so that
they show behaviour patterns similar to young children and
rats (Hermer-Vasquez, Spelke, & Katnelson, 1999). It is
therefore possible that availability of number words helped
to preserve spatial acuity of the reference lines in humans
(thus rendering spatial memory less susceptible to temporal
interference), whereas lack of number words in monkeys
allowed their spatial memory of the reference lines to be
distorted by temporo-spatial information.
It should be noted that space-time interdependence may
arise from other shared dimensions such as quantity or
magnitude, on which space and time are closely
interconnected (e.g., more space travelled in more time). In
other words, the underlying representation of both space
and time (and number) may be magnitude-based (Burr et
al., 2010; Walsh, 2003), which therefore gives rise to the
interdependence between space and time. Though such an
account is compatible with our data, it would require that
magnitude information from haptic space be less acute than
magnitude information from visual space, an assumption
that has yet to be tested. The spatial representation account
of time that we put forward here can explain the current
effects in terms of differential perceptual acuity without
positing a magnitude system.
Finally, our study has implications beyond space-time
interdependence. It suggests that previous findings of

Figure 3: No effects of time on space for visuo-haptic
perception in Experiment 2 (A), with instead effects of
space on time (B). Error bars show one SE. R2 fit is for
graphed means.

General discussion
Two experiments revealed a double-disassociation of time
and space effects according to sensory modality: time
influenced haptic space but not the other way around, and
visual space influenced time but not the other way round.
The latter findings are in line with previous observations
that time perception is subject to spatial interference
(Casasanto & Boroditsky, 2008; DeLong, 1981; Xuan et al.,
2007). However, when space is perceived haptically,
concurrent spatial information fails to affect time
perception; on the contrary, the perception of haptic space
is influenced by concurrent temporal information. Such
findings are, to our best knowledge, the first clear
demonstration of a “reverse” asymmetry between space and
time, i.e., time affects space to a greater extent than space
affects time. This reverse asymmetry is therefore
inconsistent with the spatial metaphoric mapping account of
time representation (Casasanto & Boroditsky, 2008;
Casasanto et al., 2010; Merritt et al., 2010), according to
which space should always have a greater effect on time
than time on space, as temporal perception metaphorically
employs spatial representations. Instead, our findings are
more consistent with the spatial representation account,
according to which space and time share a common
representation that is subject to interference from either

172

space-time asymmetry have more to do with differential
acuity in perceiving space than the use of linguistic
metaphor extending into nonlinguistic thought, thus casting
considerable doubt on space-time asymmetric as evidence
for the effects of language on thought (e.g., Boroditsky,
2000; Whorf, 1956). Furthermore, previous research has
shown that visuo-spatial and haptic-spatial information are
functionally equivalent (e.g., Guidice, et al, 2011), therefore
suggesting a common storage (e.g., Lacey et al., 2007). Our
findings lend further support to such a conclusion. That is,
in order for time to interact with both haptic space and
visual space, spatial information in these different
modalities should be encoded in the same format.
In conclusion, the present experiments show that time is
not asymmetrically dependent on space, and hence offer
evidence against the spatial metaphor account of time
representation. Rather, time and space share a common
spatial representation: time affects spatial information that
emerges from relatively low-acuity perceptual modalities
like touch, and time is affected by spatial information from
relatively high-acuity perceptual modalities like vision.

Giudice, N. A., Betty, M. R., & Loomis, J. M. (2011).
Functional equivalence of spatial images from
touch and vision: Evidence from spatial updating
in blind and sighted individuals. Journal of
Experimental Psychology: Learning Memory and
Cognition, 37, 621-634.
Hartcher-O'Brien, J., Gallace, A., Krings, B., Koppen, C., &
Spence, C. (2008). When vision 'extinguishes'
touch in neurologically-normal people: Extending
the
Colavita
visual
dominance
effect.
Experimental Brain Research, 186, 643-658.
Hermer-Vazquez, L., Spelke, E. S., & Katsnelson, A. S.
(1999). Sources of flexibility in human cognition:
Dual-task studies of space and language. Cognitive
Psychology, 39, 3-36.
Izard, V., & Dehaene, S. (2008). Calibrating the mental
number line. Cognition, 106, 1221–1247.
Lacey, S., Campbell, C., & Sathian, K. (2007). Vision and
touch: multiple or multisensory representations of
objects? Perception, 36, 1513–1521.
Lakoff, G., & Johnson, M. (1980). Metaphors We Live By.
Chicago and London: The University of Chicago
Press.
Lakoff, G., & Johnson, M. (1999). Philosophy in the flesh:
The embodied mind and its challenge to western
thought. Chicago: University of Chicago Press.
Lederman, S. J., Klatzky, R. L. & Barber, P. (1985).
Spatial and movement-based heuristics for
encoding pattern information through touch.
Journal of Experimental Psychology: General, 114,
33-49.
Locke, J. (1689/1995). An essay concerning human
understanding. Amherst: Promethius Books.
McGlone, M. S., & Harding, J. L. (1998). Back (or
forward?) to the future: The role of perspective in
temporal language comprehension. Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 24, 1211–1223.
Merritt, D. J., Casasanto, D., & Brannon, E. M. (2010). Do
monkeys think in metaphors? Representations of
space and time in monkeys and humans.
Cognition, 117, 191-202.
Pica, P., Lemer, C., Izard, V., & Dehaene, S. (2004). Exact
and approximate arithmetic in an Amazonian
indigene group. Science, 306, 499-503.
Schultz, L. M. & Petersik, J. T. (1994). Visual-haptic
relations in a two-dimensional size matching task.
Perceptual and Motor Skills, 78, 395-402.
Walsh, V. (2003). A theory of magnitude: common cortical
metrics of time, space and quantity. Trends in
Cognitive Sciences, 7, 483-488.
Whorf, B. (1956). Language, Thought, and Reality: selected
writings of Benjamin Lee Whorf, ed. J.B. Carroll.
Cambridge, MA: MIT Press.
Xuan, B., Zhang, D., He, S., & Chen, X. (2007). Larger
stimuli are judged to last longer. Journal of Vision,
7, 1-5.

Acknowledgments
This work was supported by a research project grant from
the Leverhulme Trust (F/00 120/CA).

References
Barsalou, L. W., & Wiemer-Hastings, K. (2005). Situating
abstract concepts. In D. Pecher & R. A. Zwaan
(Eds.), Grounding cognition: The role of
perception and action in memory, language, and
thought. New York: Cambridge University Press.
Boroditsky,
L.
(2000).
Metaphoric
Structuring:
Understanding time through spatial metaphors.
Cognition, 75, 1-28.
Boroditsky, L., & Ramscar, M. (2002). The roles of body
and mind in abstract thought. Psychological
Science, 13, 185–189.
Bryant, D. J. (1992). A spatial representation system in
humans. Psycoloquy, 3(16), space 1.
Burr, D. C., Ross, J., Binda, P., & Morrone, M. C. (2010).
Saccades compress space, time and number.
Trends in Cognitive Sciences, 14, 528-533.
Casasanto, D., & Boroditsky, L. (2008). Time in the mind:
Using space to think about time. Cognition, 106,
579–593.
Casasanto, D., Fotakopoulou, O., & Boroditsky, L. (2010).
Space and Time in the Child's Mind: Evidence for
a Cross-Dimensional Asymmetry. Cognitive
Science, 34, 387-405.
Colavita, F. B. (1974). Human sensory dominance.
Perception & Psychophysics, 16, 409-412.
DeLong, A. J. (1981). Phenomenological space-time:
toward an experiential relativity. Science, 213,
681-683.
Gibbs, R. (2006). Embodiment and cognitive science. New
York: Cambridge University Press.

173

