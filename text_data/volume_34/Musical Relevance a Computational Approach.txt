UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Musical Relevance: a Computational Approach

Permalink
https://escholarship.org/uc/item/77q9d3rf

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Acotto, Edoardo
Radicioni, Daniele

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Musical Relevance: a Computational Approach
Edoardo Acotto (acotto@di.unito.it)
Università di Torino - Dipartimento di Informatica, Corso Svizzera 185
10149, Torino ITALY

Daniele P. Radicioni (radicion@di.unito.it)
Università di Torino - Dipartimento di Informatica, Corso Svizzera 185
10149, Torino ITALY
Abstract
This study is a first attempt at formalizing the concept of Musical Relevance from a cognitive and computational perspective.
We elaborate on Sperber and Wilson’s Relevance Theory, and
extend it to account for musical cognition, involving both listening and understanding. Our claim is that the application of
the concept of Cognitive Relevance to music would permit us
to partially explain hearers’ behavior and composers’ choices.
A computational model of Musical Relevance could also contribute to the formulation of a general computational theory of
musical cognition. In turn, formulating an algorithm to compute Musical Relevance can shed light on the computational
nature of the broader cognitive principle of relevance. We propose to unify Relevance Theory with the Generative Theory
of Tonal Music, in order to compute Musical Relevance. We
started implementing a system to test the proposed approach
over simple examples and report about the results in a preliminary experimentation.
Keywords: Relevance Theory; Computational Approach; A
Generative Theory of Tonal Music; Tonal Pitch Space.

Introduction
The Relevance Theory was initially formulated as cognitivepragmatic theory of communication (Sperber & Wilson,
1986); lately it has been viewed and developed as a general
theory of human cognition (Wilson & Sperber, 2004; Carruthers, 2006). The relevance of an input to an individual (or
a cognitive system) is defined as the ratio between the cognitive effect and the processing effort. In the authors words:
“a.) Other things being equal, the greater the positive
cognitive effects achieved by processing an input, the
greater the relevance of the input to the individual at that
time. b.) Other things being equal, the greater the processing effort expended, the lower the relevance of the
input to the individual at that time.”
An input is relevant for a cognitive agent in a given context when it can be related with the information registered in
memory and accessible, and when this relation yields a “positive cognitive effect”.1 Relevance of an input is a continuous
(non-categorical) variable. The concept is comparative and
non quantitative: e.g., “x is more relevant than y, for P in the
context C”.2 The greater the cognitive effects are, the greater
1 “A positive cognitive effect is a worthwhile difference to the
individual’s representation of the world: a true conclusion, for example. False conclusions are not worth having. They are cognitive
effects, but not positive ones” (Wilson & Sperber, 2004).
2 On the comparative/quantitative notion of relevance, and on
Carnap’s distinction of comparative and quantitative concepts,
see (Sperber & Wilson, 1986).

the relevance of a given input is (ceteris paribus); on the other
side, the smaller is the processing effort, the greater is the relevance of a given input (ceteris paribus).
It is a matter of fact that Relevance Theory has a lot of opponents. For example, in a footnote Jerry Fodor let us know
that according to his opinion a Relevance Theory doesn’t even
exist: “As for a theory of relevance, saying that if we had one
it would solve the frame problem is as pointless as saying that
if we solved the frame problem, that would give us a theory of
relevance: Both are true, of course, because ‘assessing relevance’ and ‘framing’ are two terms for the same thing. [. . . ] If
cognition is to attain true beliefs with any efficiency, it’s got
to be the case both that what’s importantly relevant is generally in the frame, and that what’s not importantly relevant
generally isn’t. Maybe meeting these conditions is tractable
within the assumptions of Classical theories, but I don’t know
of any current proposal for a cognitive architecture, Classical
or otherwise, that seems likely to tract it” (Fodor, 2000, p.
114). Fodor takes correctly Sperber and Wilson’s theory as a
semantic-pragmatic theory of linguistic comprehension, and
he poses the question of how a cognitive system can attain
true beliefs in an efficient way. However, if we conceive that
Relevance Theory can be a general theory of (human) cognition, we have to remark that not all mental representations
have a truth-based semantics, and mental representations of
music seem to be a good candidate for representation without
truth value (Acotto, 2011 (in press)). So, the efficiency of the
cognitive system faced with non-semantic representations has
to be analyzed with different criteria than those that Fodor has
in mind.
One chief problem with Relevance Theory is the difficulty
to formalize it: however, in a restricted and formal domain
like music, this seems to be possible and psychologically
plausible. Modeling musical relevance we have to shift from
a “subjective” concept of relevance to an “objective” one: instead of modeling the musical relevance for a given individual
in a given context, we’ll model the relevance for an idealized
listener familiar with the Western tonal music idiom. That
is, we are presently concerned with a restricted subset of all
possible music.
In their original formulation of Relevance Theory Sperber
and Wilson (1986) do not propose any method for calculating
relevance, so we had to provide relevance with a quantitative
counterpart to design a computational model. This is a key
contribution of the present work.

1248

The formulation of an algorithm to compute Musical Relevance would lead to improve the general computational
nature of the cognitive principle of relevance: “Human
cognition tends to be geared to the maximization of relevance” (Wilson & Sperber, 2004). If Relevance Theory is
empirically plausible, and if the musical mind yields a kind
of thought comparable with other forms of mental life, Relevance Theory can apply to the musical thinking as well.
In order to explore such hypothesis, we propose to put together Relevance Theory and Lerdahl and Jackendoff’s Generative Theory of Tonal Music, GTTM (Lerdahl & Jackendoff, 1983).3
The GTTM describes the musical comprehension of a
hearer familiar with the Western tonal idiom. It postulates
the existence of mental representations of music, structured
on five levels: first the musical surface, than two horizontal structures (meter and grouping), and finally two hierarchical structures, the time-span reduction and the prolongational reduction, which can be formalized as binary branching
trees (Hamanaka, Hirata, & Tojo, 2006). Generative Theory
of Tonal Music finds in Lerdahl’s Tonal Pitch Space theory
a partial readjustment (Lerdahl, 2001), especially concerning
the formalization and the quantification of the musical dimensions.
Although other musicological theories exist that are related to musical salience (e.g., by Deliège (1996)), we chose
the notion of relevance by Sperber and Wilson because it
seemed to be more naturally suited to a computational implementation. A major assumption is that it allows formalizing and quantifying musical relevance via the computation of
the musical cognitive effect and of the processing effort. We
presently do not explore the connections of our work with
related investigations of a notion similar to Musical Relevance and grounded on information theory (Conklin & Witten, 1995; Pearce, Conklin, & Wiggins, 2004): we defer to
future work the exploration on such links.
The paper is structured as follows: we first qualify Musical
Relevance as the ratio between the cognitive effect and the
processing effort, and explore both cognitive (musical) effect
and (musical) processing efforts. We then provide an example
to show how such concepts fit to the musical context. Then a
preliminary experimentation is illustrated, and the results are
reported and discussed. Finally we conclude by pointing out
present limitations and future works.

Computing Musical Effect
According to Relevance Theory, in order to be more relevant
than another, a music excerpt has to offer a greater cognitive/emotional effect than another one requiring the same pro3 It

is noteworthy that Musical Relevance model is not directly
committed to the GTTM for computing the effect and the effort.
E.g., we could employ different theories descending from (Meyer,
1956), such as (Narmour, 1990, 1992) and (Huron, 2006). However, Narmour’s Implication/Realization theory does not account for
the hierarchical structure (i.e., binary branching tree) of music perception (Margulis, 2005, p. 688), and the same holds for Huron’s
Expectation theory.

cessing effort; alternatively, a musical excerpt has to require a
minor processing effort than another one that yields the same
effect. The Musical Relevance (MR) is defined as the ratio between the Musical Effect (ME) and Processing Effort (PE):
that is, MR = ME/PE.
GTTM individuates three types of tonal tension: surface, sequential and hierarchical tension. Some experimental
tests have been carried out, confirming that sequential tension is not sufficient to represent the effective musical understanding, and that hearers perceive hierarchical tension
as well (Lerdahl & Krumhansl, 2007). The Musical Effect
yielded by the tonal tension is complemented by the tonal attraction:4 in other words, the “forces” that constitute musical
effect are both tensional and attractive. In order to calculate the musical effect some rules can be applied, that were
devised as Tonal Pitch Space Rules (Lerdahl, 2001). The following rules can be used to compute the musical effect.
Surface tension rule
Tdiss (y) = scale degree + inversion + non harmonic tones
(1)
where the tension score of the target chord y is computed
as the sum of three elements scale degree, inversion and
non harmonic tones. scale degree is 1 if 3∧ or 5∧ is present
in the melodic voice, 0 otherwise; inversion is 2 if 3∧ or 5∧ in
the bass, 0 otherwise; non-harmonic tone is 3 if a pitch class
is a diatonic non-chord tone, 4 if it is a chromatic non-chord
tone, 0 otherwise.
Sequential tension rule
Tseq (y) = δ(x prec → y) + Tdiss (y)

(2)

where y is the target chord, x prec is the chord that immediately
precedes y in the sequence, Tseq (y) is the tension associated
with y, and δ(x prec → y) is the distance from x prec to y.
Hierarchical tension rule
Tloc (y) = δ(xdom → y) + Tdiss (y);
Tglob (y) = Tloc (y) + Tinh (xdom )

(3)

where y is the target chord, xdom is the chord that directly
dominates the prolongational tree; Tloc (y) is the local tension
associated to y; δ(xdom → y) is the distance from xdom to y;
Tglob (y) is the global tension associated to y; Tinh (xdom ) is the
sum of the values of the distances inherited by the chords that
dominate xdom .
Melodic attraction rule
α(p1 → p2 ) =

as2 1
·
as1 n2

(4)

where p1 and p2 are pitches, with p1 6= p2 ; α(p1 → p2 ) is the
attraction of p1 to p2 ; as1 is the anchoring strength of p1 and
4 The model by Lerdahl and Krumhansl is a quantitative theory
of tonal tension made out of four components: “1. A representation
of hierarchical (prolongational) event structure. 2. A model of tonal
pitch space and all distances within it. 3. A treatment of surface
(largely psychoacoustic) dissonance. 4. A model of voice-leading
(melodic) attractions” (Lerdahl & Krumhansl, 2007).

1249

as2 is the anchoring strength of p2 in the current configuration of the basic space; n is the number of semitone intervals
between p1 and p2 .5
Harmonic attraction rule
αrvl (C1 → C2 )
δ(C1 → C2 )

αrh (C1 → C2 ) = c ·

(5)

of the GTTM, Katz and Pesetsky observe that in the GTTM
time-span trees the more relevant information is the hierarchical distance from the root of the tree (see Figure 1). This
distance is measured through a Root Distance (RD) number:
“The RD number of an event e in a structure K, RD(e), is the
number of nodes that nonreflexively
dominate the maximal
-19projection of E (i.e. eP) in K” (Katz & Pesetsky, 2009).

b. Linguist's style
where αrh (C1 → C2 ) is the harmonic attraction of C1 toward
10P
C2 ; the constant c = 10; αrh (C1 → C2 ) is the sum of the attrac10
tion of the leading voices for all the voices in C1 ; δ(C1 → C2 )
1P
is the distance of C1 a C2 , with C1 6= C2 .
9P
Such rules have found an experimental corroboration
1
5P
6P
in (Lerdahl & Krumhansl, 2007). We
-18- assume that these rules
1
6
represent a good approximation of the musical effect in the
1
2P
3P
4P
5
6
7P 8P
9
10
Common
practice
in
linguistics,
on
the
other
hand,
indicates
the
head
of
a
constituent
C
by
a
overall computation of musical relevance.
label written at C. A constituent whose head is H is called a projection of H, and is conventionally
ForH'sake
of simplicity
andbybecause
of theofgreater
complexlabeled
("H-bar")
if it is dominated
another projection
H; and HP
otherwise. HP is called the
maximal
projectionin
andthis
H' is called
intermediate
projection ofwith
H. H itself
is sometimes called the
ity
of music,
paperan we
are concerned
melodic
1
2 3
4
5
6
7 8
9
10
zero-level projection of H.13 In the tree (6), T' is therefore an intermediate projection of T, while TP
music
only.
Even
though
this
is
a
clear
simplification,
and
Conversely, a syntactic derivation for a sentence like (5), for which the common-practice linguist's
is its maximal projection.
diagram is (6), can equally well be represented with a GTTM-style diagram as in (16):
it is the first step of a more complete and complex model,
Figure
The constituent structure in (10) will thus be represented with the (a) diagrams in (11)-(14) in 2: Structure of the toy melody in the standard linguisour
present
work
allows
us
to
make
experimental
tests
and
to
(16) GTTM-style tree corresponding to (6)
linguist's notation, and with the (b) diagrams in GTTM notation.:
tic
notation.
compute a musical relevance score for simple melodies.

(11) X heads ; Z heads 
a.
ZP
b.

(12) X heads  and 

a.
XP
Computing Processing
Effort

b.

The reinterpretation of Lerdahl and Jackendoff’s theory is
made
within the framework of generative linguistics, where
XP
X'
Concerning
the PE, no methods to calculate
it are given nor
the conceptD of N“projection”
a central role: “A conT
V D plays
N
X
Y
Y Z
X
Z in (Lerdahl,
X
Y Z
suggested
in Z(Lerdahl X& Jackendoff,
1983)Y nor
the girl
willis read
the called
book a projection of H, and is
stituent whose
head
H is
2001).
Nevertheless, following GTTM
we can surely identify
(13) Y heads ; Z heads 
(14) Y heads  and 
conventionally
labeled
H 0 (‘H-bar’)
if it isand
dominated
by inanThough the mapping
between
GTTM-style diagrams
common practice
linguistics is
a.
ZP
b. dimension of
a. the PE
YP represented
b.
a vertical,
hierarchical,
by
straightforward
(and perhaps
obvious
our presentation),
difference between
other
projection
of H;
andeven
HPwithout
otherwise.
HP the
is notational
called the
GTTM and linguistic practice has some
significance nonetheless, we believe. Variations in the notation
the binary
branching trees of the musical
structure. Against
YP
Y'
maximal
projection
and can
H 0 influence
is called
intermediate
projecwith which one
expresses a theory
one'san
thinking
about the actual
topics under
the “concatenationism” hypothesis (Davies, 2011), musical
investigation.
Even
when
different
sorts
of diagrams
represent
exactly the same
information (as is the
tion
of
H.
H
itself
is
sometimes
called
the
zero-level
projecX
Y Z
X Y
Z
X
Y Z
X
Y Z
case
here),
the
differences
among
them
may
reflect
and
reinforce
differing
working
hypotheses or
surface is not enough to understand music, and the structural
tion
of H”.
Askinds
it isofshowed
Figure
the linguistics
hunches
about the
phenomenainone
expects 2,
to model.
Differences ofnotation
this sort between GTTM
Example (15a) of
shows
a PR structure
toy melody
in GTTM
while (15b) conveys the
properties
a melody
areforaa key
element
fornotation,
its understandandsame
common
practice intranslation
linguistics ariseof
in two
domains:
the relevance
of 6projection level
allows
a graphic
theimportant
structure
of the
GTTM.
information in linguist's format. The head of each node formed by Merge (i.e. each non-terminal
node,
and
the amount of information that project from terminal nodes to the constituents that they head.
ing.
We
can
then
assume
that
at
least
a
great
portion
of
the
PE
what linguists mean by "phrase") is identified here for convenience by numbering the chords fromWe
left will take into consideration the RD number of each
to right.
The question
of how thesethe
nodes
are actually properties
labeled will be of
taken
up in
section 6.
is
involved
in detecting
structural
the
heard
4.3 Projection level in PR
sound
event as a part of the PE (we increase by 1 the RD
melody.
(15) PR structure for a toy melody
Although
can shall
certainlymeasure
distinguish among
zero-level
projections,
numbers).
So,onewe
the PE
by using
the intermediate
rules of projections
a. GTTM style
and maximal projection (i.e. H, H' and HP) even using GTTM notation, the explicit labeling of these
time-span
reduction
formulated
in
GTTM.
nodes in standard linguistic diagrams reflects the fact that the distinctions among these three levels of
projection is believed to be linguistically significant. In particular, a variety of independent phenomena
of language
are sensitive
to the
distinction between maximal and non-maximal projections, while other
An
example
with
melody
phenomena care about the distinction between zero-level and non-zero-level projections. For example,

1

2 3

4

5

6

7

8

9

it is maximal and
that may undergo
the process
of syntactic
movement (also
Searching
forzero-level
a first projections
implementation
of our
model,
we focus
initially on the case of the melodies, in particular the leading
voice of the toy melody, and illustrated in Figure 3.
Since we are considering a melody, we only make use
of the melodic attraction rule (please refer to Equation 4),
since the other rules are concerned with events where multiple notes are present at a time.

10

Music effect Since melodic attraction is between each two
Figure
represented
13 Written1:
as Hº,Structure
a notation thatofwethe
do nottoy
adoptmelody
here, to avoid
confusion within
the the
use of the degree
musical events, an attraction number is not referred to a single
sign in music
theory to indicate
a diminished
triad.
GTTM
notation,
by Katz
and Pesetsky
(2009).
How to compute the binary branching trees that represent
the hierarchical musical structure? In their reinterpretation
5 In our implementation we adopted a correction to handle the
case of repeated notes, with p1 = p2 , that otherwise would produce
a division by zero. Since the underlying rationale is that in case of
repeated notes the ratio n12 should approach 1, we presently set the
value of n to 0.9.

6 “Variations in the notation with which one expresses a theory
can influence one’s thinking about the actual topics under investigation. Even when different sorts of diagrams represent exactly the
same information (as is the case here), the differences among them
may reflect and reinforce differing working hypotheses or hunches
about the kinds of phenomena one expects to model. Differences of
this sort between GTTM and common practice in linguistics arise
in two important domains: the relevance of projection level and the
amount of information that project from terminal nodes to the constituents that they head.” (Katz & Pesetsky, 2009)

1250

Piano

" "
# 43 " "

$!

""" "

$!

Piano

Piano

# #
$ 43 # #

a b c d

TIME-SPANPiano
REDUCTION

e

### #

!"

f g h

j

i

Robert Schumann (1810-1856)
Opus 68 N°5

! ! ! !! ! " ! ! ! ! ! ! ! ! ! ! !! ! " ! ! ! ! !! ! !
!
# $

# # "!
# # # "!
$ 43 #

Piano

Piano

a b c

d

! 43 # "

#"

a

! 43 # "

e f g

Figure 6: Excerpt from the “Petit pièce” from the Opus 68
n.5 by R. Schumann.

h

#"

#"

b

c

d

#"

#"

#"

is between two events, we’ll calculate the average PE of each
couple of notes, and then we’ll calculate the relevance (the
ratio between ME and PE) of the passage from one musical
event to another.

Experimental Assessment

Figure 4: The three levels of the toy melody time-span reductions.
pitch, but represents a transition between two adjacent pitches
x and y. The attraction values (i.e. the musical effect) between
each two notes in the toy melody are as follows:
α(C → D)
α(D → E)
α(E → F)
α(F → G)
α(G → A)
α(A → B)
α(B → C)
α(C → D)
α(D → C)

=
=
=
=
=
=
=
=
=

0.125
0.375
0.667
0.375
0.007
0.25
2.0
0.125
0.5

!
!
! %! $ # !" ! ! ! % ! ! ! ! ! )
!
* %!

Figure 5: Excerpt
from
the laPiano
Sonata in C minor (KV.
Album
pour
jeunesse
457) by W.A. Mozart.
------

Figure 3: The leading voice of the toy melody.

!"

! ! ! ! ! ! ! ! ! !%! ! )
'
( ' ' & * ! ! ! $#"

In order to provide the proposed approach with an experimental assessment, we devised the following experimental
setting.
We implemented a system that computes the Musical effect
(ME) component in the equation MR = ME/PE. We studied
how the computed musical effect differs by varying two simple melodies.
A core hypothesis of the experimentation is that melodies
by historical composers maximize ME, and MR as well.7
Let us consider the cognitive constraints by Lerdahl (1988),
that postulates that ‘good’ music is composed according to
the cognitive
nature
human2.14.2—www.lilypond.org
mind/brain. By following this
Music
engravingof
by LilyPond
theoretical framework we stipulate that the original melodies
from historical composers have higher ME than ‘experimental’ variations composed by ourselves.
Music engraving
by LilyPond
2.14.2—www.lilypond.org
In this setting,
we expect
the
system to compute lower ME
for our variations; also, we expect it to be able to distinguish
between grammatical and ‘ungrammatical’ variations, by assigning lower scores to ungrammatical ones.

Processing Effort In order to calculate the PE, we compute
the RD numbers by following the binary branching tree: for
Experimental setting We selected the music excerpts illuseach pair of events the PE will be the average of the two
trated in Figures 5 and 6. Such pieces were chosen in order
RD numbers (augmented by a unit). To compute processing
to capture (and test the system in) two widely different exeffort implies the possiblity to automatically “reduce” a given
perimental conditions. In particular, they can be thought of
Music engraving
by LilyPond
melody to its more fundamental
schema,
asLilyPond
it 2.14.2—www.lilypond.org
is shown
in
Music
engraving
by
2.14.2—www.lilypond.org
as two paradigmatic examples of themes opposite in spirit.
Figure 4.
The first one is rather percussive and jumps over the main
This kind of reduction relies on a set of “preference rules”.
degrees of the C minor key. On the other side, the second
However, these are not easily implemented because if there
one is a typical cantabile theme: it is more regular under a
are cases where multiple rules areMusic
triggered
at bythe
same2.14.2—www.lilypond.org
time,
engraving
LilyPond
rhythmic viewpoint, and the melody mostly moves stepwise.
unfortunately in the GTTM no criteria are proposed to resolve
7 In accord with the given definition, music relevance (MR) grows
such conflicts. Deepening the computation of the PE component of MR will be one major focus of future work.
–ceteris paribus– as the music effect (ME) grows, and vice versa
Music engraving by LilyPond 2.14.2—www.lilypond.org
it decreases

–ceteris paribus– as the processing effort (PE) grows.

Since we added new events by interleaving existing events with new
Musical Relevance We can now calculate the musical releones, this makes the input more complex. Then we know in advance
vance of the transition from one event to another in a melody
that new nodes will produce further levels to the reduction tree, thus
(without considering, for the moment,
the relevance of simiincreasing the PE component. That is, we know a priori that by inMusic engraving by LilyPond 2.14.2—www.lilypond.org
larity). As each note has a value of PE, but the attraction value
creasing PE and by decreasing ME, the final MR will result reduced.

1251

Also, if we compare the original excerpts (Figure 5 and 6),
the system accounts for the greater ‘dramatical’ salience of
Mozart’s excerpt (which is a first theme of a C minor sonate).
Schumann’s excerpt is a simple piece: its value results perhaps from the balance between its simple effect and its structural simplicity.

Table 1: The Musical Effect scores for the six considered
pieces.
Excerpt
Score
Mozart excerpt
0.4259
Mozart Var 1
0.3888
Mozart Var 2
0.3267
Schumann excerpt 0.3182
Schumann Var 1
0.2460
Schumann Var 2
0.1877

Conclusions

Therefore, different musical aspects are accounted for by the
considered excerpts.
We then elaborated two variations for each excerpt (Figure 7). In both cases the first variation (indicated as Var 1 in
Figure 7-a) and 7-b)) is only slightly different from the original excerpt. As regards as the second variation, the Mozart
excerpt has been modified in a ungrammatical fashion (see
Var 2 in Figure 7-a)), whilst Schumann excerpt has been modified through the insertion of musically plausible notes that
transform it into a rhythmically regular arpeggio (see Var 2 in
Figure 7-b)).
The implemented system takes in input the excerpts encoded as MIDI files, and computes the associated musical effect –through the formula in Equation (4)– as the sum of the
melodic attraction between each two music events:

 excerpt.length−1  as
1
i+1
·
∑i=1
asi
n2

MEexcerpt = 
excerpt.length
By adding new notes we expected a reduction in the musical effect. Furthermore, since the second variation of each
input excerpt was more different from each ‘original’ source,
we expected to observe a decrease in the musical effect and,
relatedly, in musical relevance.
Results In accord with our intuition, the implemented system computed the maximum ME scores for the original excerpts, reduced scores for each first variation, and the lowest
scores for both second variations. The final figures are reported in Table 1.8 Provided that this experimentation represents only the very first step towards a psychological validation (that would require considering in how far the results approach human responses), the results seem to corroborate Lerdahl’s hypothesis. Tonal music is governed by an
attraction-based syntax. This sort of attraction, which is maximally exploited by composers and which is maximal in the
original music excerpts, is at least partly grasped by the proposed model. Further work is needed to investigate whether
and how classical western tradition as a whole ‘incorporates’
a criterion to maximize the Musical Effect (independently of
the associated processing effort).
8 The

material employed in the experimentation (MIDI files,
printable scores and Lilypond sources) along with the results file
is available at the URL
http://www.di.unito.it/˜radicion/datasets/cogsci12/ .

The paper illustrates a modeling attempt, and an initial implementation of a complex phenomenon such as relevanceguided music understanding. The presented implementation
only accounts for the musical effect; coping with the computation of the processing effort is left for future work.
Due to such limitation we considered for experimentation
only melodies with differing surface, but with similar underlying structures. Notwithstanding this limitation, the preliminary experimentation provided some evidence that the musical effect captures meaningful aspects of Western tonal music.
Another relevant point for completing the Musical Relevance model involves dealing with musical similarity. Similarities and repetitions in music are a frequent and important
structural phenomenon. They affect important musical features like style (Meyer, 1989), but they permit also to affirm
that without similarity there would be no music, since similarity is a center of gravity for perception and comprehension (Cambouropoulos, 2009). Similarities and repetitions
influence musical effect, and therefore they have impact on
the cognitive relevance of a piece of music. The relevance of
a musical event E2 should be a function both of the relevance
of the similar event E1 , and of the relevance of E2 as taken in
isolation. The similarity increases the relevance of a musical
event; otherwise, similarities should be avoided for the risk
to diminish the relevance effect. Starting from existent systems for computing musical similarity (Meredith, Lemström,
& Wiggins, 2002; Radicioni & Botta, 2006), in future works
we will focus on detecting similar patterns in music pieces.

Acknowledgments
This work has been partly supported by the project
Speak2Home. We are grateful to two anonymous reviewers
for their valuable advices that helped to substantially improve
the work, and to Jelle Gerbrandy for discussions on some subtle aspects of the paper.

References
Acotto, E. (2011 (in press)). Mental Representations of Music in Cognitive Science. In Proceedings of the Italian Cognitive Science Society (AISC) Conference.
Cambouropoulos, E. (2009). How similar is similar? Musicae Scientiae, Discussion Forum 4B, 7–24.
Carruthers, P. (2006). The Architecture of the Mind. Oxford:
Oxford University Press.
Conklin, D., & Witten, I. H. (1995). Multiple Viewpoint Systems for Music Prediction. Journal of New Music Research,
24(1), 51–73.

1252

Var 1
5

%
$%%

a)
Var 2
5

%
$%%

%
$%%& ! ! ! !
!

! (!

%
$%%& '
'

#!

!

! ! (!

! ! ! "# ! ! ! ! ! ! ! !
'
! !
"# ! ! ! !
(
'

!

!

! ! ( ) ! ! ! ! ! ! ! "!
*
! ! "!
#!
! "! !

!
( ) ! ! ! "!
#!
*

! #! "!

!

(! ! )

! ! ! !
!

)

#! ! "!

! !

!

+

Album pour la jeunesse
------

Robert Schumann (1810-1856)
Opus 68 N°5

Var 1
5

b)

! ! ! ! ! " ! !! !! !! ! ! # ! !! !! !! !! !!! ! " !! !! ! ! ! ! !
" ' la jeunesse!
#$ $%%% & !
! (! ! )
!Album pour
! ! !
------

!! ! !
! !! !! (!! ! "!# !!' ! !! ! ! "( ! ! ! !
!
!
%
(
!
!
() * ! ! ! ! !
!$# %!$% &
' ! ! "!
Var 2
54
! ! ! ! ! ! ! ! ! !) !! !! !" " ! ! !! ! ! !
%! !
#! (
#! !
$#% % ! !
*
! "! !
#
!
'
%
$%%

! ! ! !Opus 68 N°5
! !
)
"
!
!! ! ! !! #!! ! !! ! !
"!

Robert Schumann (1810-1856)

!! ! ! ! !
! ! !! !+ !
# ! "!!

Figure 7: a) variations of the Mozart excerpt; b) variations of the Schumann excerpt.
Davies, S. (2011). Musical Understandings: And Other EsPerception, 22(4), 663–714.
says on the Philosophy of Music. Oxford, UK: Oxford UniMeredith, D., Lemström, K., & Wiggins, G. (2002). Algoversity Press.
rithm for discovering repeated patterns in multidimensional
representations of polyphonic music. Journal of New MuDeliège, I. (1996, October). Cue Abstraction as a Component
sic Research, 31(4), 321–345.
of Categorisation Processes in Music Listening. PsycholMeyer, L. (1956). Emotion and meaning in music. Chicago,
ogy of Music, 24(2), 131–156.
USA: Chicago University Press.
Fodor, J. (2000). The Mind Doesn’t Work That Way: The
Meyer, L. (1989). Style and Music. Chicago: Chicago UniScope and Limits of Computational Psychology. CamMusic engraving by LilyPond 2.14.2—www.lilypond.org
versity Press.
bridge: MIT Press.
Narmour,
E. (1990). The analysis and cognition of basic
Hamanaka, M., Hirata, K., & Tojo, S. (2006). Implementing
melodic
structures. Chicago, USA: University of Chicago
“A Generative Theory of Tonal Music’’. Journal of New
Press.
Music Research, 35(4), 249–277.
Narmour, E. (1992). The analysis and cognition of melodic
Huron, D. (2006). Sweet anticipation. music and the psycholcomplexity. Chicago, USA: Chicago University Press.
ogy of expectation. Cambridge: MIT Press.
Pearce,
M., Conklin, D., & Wiggins, G. A. (2004). Methods
Katz, J., & Pesetsky, D. (2009). The Music
Identity
Theengraving
by LilyPond 2.14.2—www.lilypond.org
for
Combining
Statistical Models of Music. In Computer
sis for Language and Music.
draft available at
Music
Modeling
and Retrieval: Second International Symhttp://ling.auf.net/lingBuzz/000959.
posium, CMMR 2004 (pp. 295–312).
Lerdahl, F. (1988). Generative Processes in Music: The PsyRadicioni, D. P., & Botta, M. (2006). A Methodological
chology of Performance, Improvisation, and Composition.
Contribution to Music Sequences Analysis. In F. Esposito
In J. Sloboda (Ed.), (pp. 231–59). Oxford University Press.
& Z. W. Ras (Eds.), Foundations of Intelligent Systems (pp.
MusicOxford
engravingUniby LilyPond 2.14.2—www.lilypond.org
Lerdahl, F. (2001). Tonal pitch space. Oxford:
409–418). Berlin: Springer-Verlag.
versity Press.
Sperber, D., & Wilson, D. (1986). Relevance. CommunicaLerdahl, F., & Jackendoff, R. (1983). A generative theory of
tion and Cognition. Oxford: Blackwell.
Music engraving by LilyPond 2.14.2—www.lilypond.org
tonal music. Cambridge: MIT Press.
Wilson,
D., & Sperber, D. (2004). Handbook of Pragmatics.
Music engraving by LilyPond
2.14.2—www.lilypond.org
Lerdahl, F., & Krumhansl, C. L. (2007). Modeling tonal
In G. Ward & L. Horn (Eds.), (chap. Relevance Theory).
tension. Music Perception, 24, 329–366.
Oxford: Blackwell.
Margulis, E. (2005). A Model of Melodic Expectation. Music
Music engraving by LilyPond 2.14.2—www.lilypond.org

1253

