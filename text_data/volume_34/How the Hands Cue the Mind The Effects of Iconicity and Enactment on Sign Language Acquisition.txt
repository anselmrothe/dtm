UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How the Hands Cue the Mind: The Effects of Iconicity and Enactment on Sign Language
Acquisition

Permalink
https://escholarship.org/uc/item/64r2r1m6

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Author
Morett, Laura

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

How the Hands Cue the Mind:
The Effects of Iconicity and Enactment on Sign Language Acquisition
Laura M. Morett (morett@pitt.edu)
Department of Psychology, University of Pittsburgh
210 S. Bouquet Street, Pittsburgh, PA 15260 USA
Abstract

embodied cognition posit that representations of language
are inherently perceptual, and are encoded and retrieved via
the body’s sensorimotor system (Barsalou, 1999). 4Thus,
these theories would predict that enacting signs—especially
those that are iconic—allows sign language learners to tap
directly into these perceptually-based representations,
thereby facilitating their recall and comprehension. If the
motor system does contribute significantly to sign language
acquisition, learners should recall iconic signs better than
non-iconic signs due to the isomorphism between the
visuospatial properties of motor representations of signs and
their referents.

Iconicity is a powerful cue to symbolic meaning. However, it
is unclear from previous research whether language learners
benefit from iconicity. Prior research indicates that the motor
system supports language acquisition, suggesting that
iconicity expressed via this modality may be particularly
salient. The present study investigates the effects of iconicity
and enactment on the acquisition of American Sign Language
by hearing adults. The results reveal that enactment enhances
sign learning in general, but fail to show that iconic signs are
learned more effectively than non-iconic signs. As such, they
indicate that the motor system—but not iconicity—plays a
key role in sign language acquisition.

Iconicity and Language Acquisition

Keywords: Second language acquisition, sign language,
mental imagery, embodied cognition.

Introduction
Sign language is the only type of natural language that is
comprehended and produced exclusively in the visuospatial
modality. Given that the visuospatial modality allows for
greater isomorphism between symbols and their referents
than the auditory modality, it follows that sign language
should be more iconic than spoken language, and there is
evidence that this is indeed the case (McNeill, 2005;
O’Brien, 1999). Thus, although hearing speakers are
accustomed to processing language in the auditory modality,
they may be able to take advantage of this iconicity to
expedite their learning of sign language. If iconicity plays a
pivotal role in sign language acquisition, learners should be
able to acquire sign languages more quickly and effectively
than they learn spoken languages. Moreover, learners should
be able to learn iconic signs and expressions more
efficiently than lexical items that are not iconic.
Unlike spoken language, which is articulated primarily
with the mouth and vocal tract, sign language is articulated
with the hands and body. As such, another factor that may
play an integral role in the acquisition of sign language is
the engagement of the motor system. Theories of

Meaningful hand movements, including gestures and signs,
vary on the basis of several qualities, including
conventionalization, semiosis, and relationship to speech. In
order to show how different types of hand movements relate
to one another on the basis of these characteristics, Adam
Kendon and David McNeill (1992) developed a continuum,
which is illustrated below in Figure 1. At one extreme of the
continuum lies sign language, which is highly
conventionalized, segmented and analytic, and occurs in lieu
of speech. At the opposite extreme lies gesticulation, which
is unconventionalized, global and synthetic, and occurs
concurrently with speech. Although iconicity is not plotted
on this continuum, it can be inferred that, due to its global
and synthetic (i.e., holistic) nature, gesticulation is highly
iconic, whereas sign is the least iconic of the hand motions.
It is important to note that iconicity varies within and
between sign languages. Much of this variation can be
explained by ontogenetic development. There is evidence
that the home sign of individual deaf children as well as
pidgin sign languages created by communities of deaf
children are generally more iconic than conventionalized
sign languages (Kendon, 1980; Senghas, Kita, & Özyürek,
2004). Moreover, even within highly-conventionalized sign

Figure 1: Kendon’s continuum, as characterized by McNeill (2005).

2043

languages, recently-coined signs are more iconic than signs
that have been in the language longer (Frishberg, 1975).
This is likely the case because signs are initially based on
referents’ affordances, which become obfuscated through
inter-generational transmission of signs.
Obviously, it is quite plausible that iconicity may
facilitate the acquisition of signs, due to its isomorphism
with the visuospatial properties of the referent.
Nevertheless, research has failed to provide conclusive
evidence that children learn iconic signs more readily than
they learn arbitrary signs. One study of the acquisition of
American Sign Language (ASL) by congenitally deaf
children showed that only 30% of these children’s first 10
signs are iconic, and that this number increases to only 34%
at 18 mos. (Orlansky & Bonvillian, 1984). Another study
(Miller, 1987) showed that 3-year-old hearing children
unfamiliar with ASL were unable to reliably select the
correct referent of iconic signs on the Peabody Picture
Vocabulary Test, a standardized, forced-choice measure of
vocabulary development (L. M. Dunn & Dunn, 1997).
Taken together, these findings suggest that both deaf and
hearing children are unable to use signs’ iconicity to
associate them with their referents, thereby facilitating sign
language acquisition.
Related work examining gesture comprehension has
provided insight into the question of why young children are
unable to associate iconic hand movements with their
referents. One study showed that, by 26 months of age,
children were able to associate iconic gestures with objects
with similar affordances, even though they were unable to
do so at 14 mos. of age (Namy, 2008). Another, more recent
study demonstrated that 4-year-olds were better able than 2year-olds to learn object labels associated with iconic
gestures, but that both age groups learned object labels
associated with arbitrary gestures at a comparable rate
(Marentette & Nicoladis, 2011). Although this study also
showed that 4-year-old children treated iconic gesture as an
action associate rather than a label, 2-year-olds were not
tested. The seeming inconsistency between the results of
these two studies can be explained by the fact that the
objects’ affordances were demonstrated to children in the
earlier study, but not the more recent study. Thus, this work
demonstrates that children who were able to effectively
associate iconic gestures with corresponding objects
understand the relationship between them, allowing these
children to use gesture as an embodied aid in word learning.
To date, no published research has examined whether the
iconicity of sign language facilitates its acquisition by adult
learners. However, there is evidence that adults unfamiliar
with sign language can effectively guess the meanings of
highly iconic signs, even when their referents are
metaphorical (O’Brien, 1999). Work has also shown that
adults are able to learn words from a novel spoken language
accompanied by representative iconic gestures more
effectively than words presented as speech only or words
accompanied by non-representative iconic gestures (Allen,

1995; Kelly, McDevitt, & Esch, 2009). Given that adults
understand the correspondences between object affordances
and iconic hand movements—including signs—it follows
that they should be better able to learn highly iconic signs
than arbitrary signs.

Enactment and Language Acquisition
Aside from being more iconic than spoken language, sign
language is also more embodied than spoken language.
Because the hands and parts of the body other than the vocal
tract and face play a larger role in sign language than in
spoken language, sign language engages the motor system
to a greater degree than spoken language. This engagement
of the motor system likely produces memory traces that are
richer and more multimodal than those produced by spoken
language, providing learners with additional recall cues.
Research examining recall of spoken language has
provided evidence that engagement of the motor system
during language processing enhances memory encoding and
retrieval. For example, when presented with a series of
instructions, adults recall more spoken instructions when
they act them out than when they repeat them aloud
(Svensson & Nilsson, 1989). Moreover, adults are more
likely to recall spoken instructions for tasks that they have
enacted for a longer time period (30 s.) than those that they
have enacted for a brief time period (5 s.) (Cohen & Bryant,
1991), indicating that greater engagement of the motor
system produces richer, more robust memories. A separate
line of research has provided evidence that adults are more
likely to produce sought-after words during speech
disfluencies when they gesture than when they keep their
hands still (Frick-Horbury, 2002; Frick-Horbury &
Guttentag, 1998), indicating that gesture facilitates lexical
access. Taken together, the results of all of this work
suggests that the enactment of meaningful hand motions
during language processing allows speakers to tap into their
semantic representations more effectively, thereby
promoting language encoding and recall.
There is also evidence that the motor system plays a key
role in language acquisition. To this end, research has
revealed a tight relationship between motor and language
milestones in childhood, demonstrating that the onset of
babbling is accompanied by repetitive motor movements
(Iverson & Fagan, 2004), and that the transition to two-word
speech is accompanied by gesture-word combinations
(Capirci, Iverson, Pizzuto, & Volterra, 1996). Furthermore,
several studies have shown that children are able to express
symbolic meaning via hand motions before speech
(Acredolo & Goodwyn, 1988; Bonvillian, Orlansky, &
Novack, 1983; Iverson & Goldin-Meadow, 2005), and that
children’s iconic gesture production predicts their
vocabulary development (Rowe & Goldin-Meadow, 2009a,
2009b; Rowe, Özçalışkan, & Goldin-Meadow, 2008).
Finally, there is evidence that school-aged children are
better able to learn the meanings of novel words from both

2044

Figure 2: ASL signs and English words used in study, listed by sign type.
their native language and unfamiliar second languages when
they enact iconic gestures representing the words’ meanings
(Tellier, 2005, 2008).
It is important to note that the facilitatory effects of
enactment observed in most studies discussed above stem
from a combination of embodied action and mental imagery.
Furthermore, there is experimental evidence that learning
techniques incorporating mental imagery enhance second
language vocabulary acquisition (Atkinson, 1975; Atkinson
& Raugh, 1975). Aside from investigating the effects of
iconicity and enactment on sign language acquisition, a
secondary goal of the current study was to disambiguate the
roles that embodied action and mental imagery play in sign
enactment. As such, the study included conditions that were
designed to elicit mental imagery and embodied action in
combination, only mental imagery, only embodied action,
and neither mental imagery nor embodied action.
To date, no published research has investigated whether
enactment facilitates the acquisition of signed second
languages by adults. On the basis of previous research, it
was predicted that the enactment condition would result in
ASL sign acquisition superior to that observed under the
other conditions. This prediction stems from enactment’s
incorporation of both mental imagery and embodied action,
and its resulting engagement of both the visuospatial and
motor systems.

Method
Participants
Undergraduate students were recruited from the participant
pool at the University of Pittsburgh, and received partial
course credit in return for participation. All recruited
individuals were fluent English speakers1 and confirmed
that they had no knowledge of American Sign Language
(ASL) prior to the experiment. Additionally, all recruited
individuals had normal hearing and normal or corrected-tonormal vision. 6 individuals were eliminated due to
technical difficulties or failure to return for all three
sessions, resulting in a final sample of 29 participants (age:
M = 20.79, SD = 1.65; sex: 11 males; 18 females).

Stimuli
Twenty ASL signs and their English glosses were used as
stimuli for this research (see Figure 2). Each sign was
classifiable into one of the following three types: Iconic,
metaphorical, or arbitrary. Iconic signs depicted their
1

Participants were not required to be native English speakers in
order to participate, given that the English glosses of the signs
were common words, and should thus be comprehensible to nonnative undergraduate students, whose proficiency must be
sufficient to comprehend academic English.

2045

referent holistically or metonymically (e.g., pantomiming
hammering for hammer); metaphorical signs represented the
source domain of the conceptual metaphor structuring their
referent (e.g., cupped hands moving forward three times, as
if conveying an entity of information from the signer to the
listener, for to teach); and arbitrary signs bore no structural
resemblance to their referent (e.g., two fingers from both
hands taping one another repeatedly for name). The
distinctions between these sign types were supported by
empirical data collected from a separate group of
participants unfamiliar with ASL (O’Brien, 1999), ensuring
that they were applicable to the target population of the
current study.
A female native signer of ASL was video recorded
demonstrating the twenty signs used in this study. The
signer was unaware of the goals of the study. Video footage
of each sign was segmented and trimmed, yielding stimuli
averaging 2.5 s. in duration. Additionally, ambient audio
captured during video recording was expunged from the
footage, yielding silent stimuli.

Procedure
This experiment consisted of three sessions, the first of
which included both a learning and test phase, and the
second and third of which included only a test phase. In
learning trials, participants were presented with video of a
randomly-selected sign (~2500 ms.), and after a 1000 ms.
interstimulus interval, were presented simultaneously with
the corresponding English gloss as text and audio (2500
ms.). After one additional repetition of this sequence of
events, participants performed one of four actions. For
words presented in the enactment condition, participants
enacted the sign with their own hands; as such, this
condition included both mental imagery and embodied
action. For words presented in the imagery condition,
participants closed their eyes and visualized the sign’s
referent in their mind’s eye without moving their hands; as
such, this condition included mental imagery, but not
embodied action. For words presented in the motion
condition, participants made an X-shaped motion with their
dominant hand three times; as such, this condition included
embodied action but not mental imagery. For words
presented in the comprehension condition, the learning
sequence was repeated one additional time, and participants
were not explicitly told to do anything; as such, this
condition did not include either mental imagery or
embodied action. Within each experimental session, each
sign was randomly assigned to one of these four conditions
in a within-participants design, such that five signs were
presented in each condition for each participant. The
learning phase consisted of 3 blocks comprising 20 trials
apiece (one for each sign), yielding a total of 60 learning
trials altogether.
Following the learning phase in the first session,
participants were given a 5-minute break, and then
completed the test phase. In test trials, upon being presented
with English glosses as text and audio, participants were

asked to produce the corresponding ASL sign. Participants
were instructed to try to recall the sign as best they could,
but were told that they could say “skip” to move on if they
could not recall a sign. During test trials, participants’
signing was recorded by a video camera set approximately
45° to the left of their central viewing point. The test phase
consisted of one block of 20 trials (one for each sign).
Overall, the first experimental session lasted about 30
minutes.
In order to examine how long-term recall of signs varied
by condition, participants returned to the lab for two followup sessions held one week and four weeks after the first
session. In each of these sessions, participants completed the
test phase in the manner described above. Each of the
follow-up sessions lasted approximately 10 min. apiece.

Results
Sign recall was quantified using a binary coding scheme (1
= correct; 0 = incorrect/skipped). Total number of signs
recalled correctly for each participant and condition were
converted into proportions, in order to control for
unscorable responses caused by technical errors in running
the recall task (which accounted for less than 5% of the
data). In order for a sign to be coded as correct, it must have
been performed using the same hand (dominant/nondominant, as specified per participant on a postexperimental questionnaire), and must have had the same
hand shape and movements as the correct ASL sign, as
modeled by the signer.
To address the question of whether learning condition
affects sign recall, proportional data were submitted to
repeated measures ANOVAs, using participant and sign as
fixed factors. These analyses revealed significant main
effects of learning condition, Fpp(3, 87) = 7.16, p < .001, ηp2
= .29; Fsign(3, 45) = 14.07, p < .001, ηp2 = .48, and recall
interval, Fpp(1, 29) = 10.99, p = .004, ηp2 = .38; Fsign(1, 15) =
18.16, p = .001, ηp2 = .55, but failed to reveal a significant
condition-by-interval interaction, Fpp > 1; Fsign > 1; see
Figure 3. Bonferroni-corrected post-hoc analyses showed
greater recall accuracy for signs learned via enactment than
via mental imagery (p = .04), motion (p = .06), and

2046

Figure 3: Percent of signs produced correctly by learning
condition and recall interval (error bars represent SE).

Table 1: Mean number of signs produced correctly by sign
type and recall interval.

Sign type
Iconic
Metaphorical
Arbitrary

5 min.
.74 (.36)
.78 (.24)
.60 (.26)

Recall interval
1 week
.66 (.24)
.55 (.24)
.56 (.28)

4 weeks
.62 (.28)
.50 (.29)
.44 (.27)

comprehension (p = .05), as well as greater recall accuracy
after an interval of 5 minutes than 1 week (p < .01) and 4
weeks (p < .001). These results indicate that enactment
facilitates the acquisition of novel signs by hearing adult
learners unfamiliar with sign language across both short and
long learning-test intervals.
To address the question of whether iconicity affects the
learning and recall of ASL signs, sign type (iconic,
metaphorical, arbitrary) was entered into a repeated
measures ANOVA, using sign as a fixed factor. This
analysis failed to reveal a main effect of sign category on
recall, F(1, 17) = 1.13, p = .35, ηp2 = .12; see Table 1. This
result indicates that, similar to deaf children, hearing adult
learners do not benefit significantly from iconicity when
learning novel signs.

Discussion
The current study investigated the roles of iconicity and
enactment on the acquisition of ASL signs by hearing adult
L2 learners. The results revealed that enactment facilitated
sign learning more effectively than visualization of sign
referents, performance of meaningless hand movements, or
simple sign comprehension. However, the results failed to
demonstrate that iconic signs are learned more effectively
than arbitrary signs. Considered as a whole, these results
suggest that enactment enhances ASL sign recall and
production in hearing learners through the creation of
motorically-rich lexical traces.
Unfortunately, the results of the current study do not
provide insight into why adult L2 learners fail to benefit
from the iconicity inherent in some signs, and in sign
language in general. One possible explanation is that, like
children, adults go through a developmental stage in the
initial stages of language learning in which they are unable
to associate the visuospatial properties of iconic signs with
the affordances of their referents. Although adults are
generally familiar with the affordances of common objects,
it is possible that this inability to associate them with their
corresponding signs derives from insufficient linguistic
context, rather than from insufficient domain-general
knowledge, which has been proposed to explain children’s
insensitivity to iconicity. When learning their first set of
signs, adults unfamiliar with ASL are unable to relate their
semantic and phonological properties to other similar signs,
which may negate their ability to recognize iconicity.
Alternatively, hearing adults’ experience with spoken
languages, in which iconicity is sparse, may lead them to

assume that language is not iconic, causing them to ignore
any physical correspondences between signs and their
referents. Finally, the novelty of processing language in the
visuospatial modality may place a heavy cognitive load on
adult L2 learners unfamiliar with sign language, negating
any benefits that iconicity may have bestowed. Needless to
say, future research is necessary to test between these
possibilities and to clarify the cause of this null effect.
The advantage produced by enactment of signs during
learning indicates that the motor system plays a key role in
L2 lexical acquisition, particularly for sign language. Of
note, only meaningful motion (i.e., sign enactment)—not
arbitrary motion (i.e., X-shaped motions)—enhanced sign
acquisition. This result is consistent with embodied theories
of cognition, which maintain that the mental representations
underlying language derive from meaningful interactions
between our bodies and the world (Barsalou, 1999). It is
also consistent with work showing that meaningless
repetitive motion can disrupt the formation of visuospatial
representations (Vandierendonck, Kemps, Fastame, &
Szmalec, 2004). The observation that enactment is more
effective at promoting sign learning than visualization of
referents via mental imagery indicates that meaningful
engagement of the motor system results in richer, more
robust mental representations of signs, which are more
likely to be retrieved successfully, particularly by
inexperienced learners.
In conclusion, the results of this study demonstrate that
adult L2 learners can take advantage of enactment, but not
iconicity, to facilitate their acquisition of sign language. As
such, they indicate that the hands cue the mind in sign
language acquisition, rather than vice versa, demonstrating
the power and depth of the body’s cognitive capacity in
relation to the acquisition of a novel second language.

Acknowledgements
This research was supported by a National Defense Science
and Engineering Graduate Fellowship and the Perlino
Award to Laura M. Morett. The author thanks Ray Gibbs
and Brian MacWhinney for helpful discussion.

References
Acredolo, L., & Goodwyn, S. (1988). Symbolic gesturing in
normal infants. Child Development, 59(2), 450–466.
Allen, L. Q. (1995). The effects of emblematic gestures on
the development and access of mental representations of
French expressions. The Modern Language Journal,
79(4), 521–529.
Atkinson, R. C. (1975). Mnemotechnics in second-language
learning. American Psychologist, 30(8), 821–828.
doi:10.1037/h0077029
Atkinson, R. C., & Raugh, M. R. (1975). An application of
the mnemonic keyword method to the acquisition of a
Russian vocabulary. Journal of Experimental Psychology:
Human Learning and Memory, 1, 126–133.
doi:10.1037/0278-7393.1.2.126

2047

Barsalou, L. W. (1999). Perceptual symbol systems.
Behavioral and Brain Sciences, 22(04), 577–660. doi:null
Bonvillian, J. D., Orlansky, M. D., & Novack, L. L. (1983).
Developmental Milestones: Sign Language Acquisition
and Motor Development. Child Development, 54(6),
1435–1445. doi:10.2307/1129806
Capirci, O., Iverson, J. M., Pizzuto, E., & Volterra, V.
(1996). Communicative gestures and the transition to twoword speech. Journal of Child Language, 23, 645–73.
Cohen, R. L., & Bryant, S. (1991). The role of duration in
memory and metamemory of enacted instructions (SPTs).
Psychological research, 53(3), 183–187.
Dunn, L. M., & Dunn, L. (1997). Peabody picture
vocabulary test-III (PPVT-III). Circle Pines, MN:
American Guidance Service.
Frick-Horbury, D. (2002). The use of hand gestures as selfgenerated cues for recall of verbally associated targets.
The American Journal of Psychology, 115(1), 1–20.
doi:10.2307/1423671
Frick-Horbury, D., & Guttentag, R. E. (1998). The effects of
restricting hand gesture production on lexical retrieval
and free recall. The American Journal of Psychology,
111(1), 43–62.
Frishberg, N. (1975). Arbitrariness and Iconicity: Historical
Change in American Sign Language. Language, 51(3),
696–719. doi:10.2307/412894
Iverson, J. M., & Fagan, M. K. (2004). Infant Vocal–Motor
Coordination: Precursor to the Gesture–Speech System?
Child Development, 75(4), 1053–1066.
doi:10.1111/j.1467-8624.2004.00725.x
Iverson, J. M., & Goldin-Meadow, S. (2005). Gesture paves
the way for language development. Psychological
Science, 16(5), 367 –371. doi:10.1111/j.09567976.2005.01542.x
Kelly, S. D., McDevitt, T., & Esch, M. (2009). Brief
training with co-speech gesture lends a hand to word
learning in a foreign language. Language and Cognitive
Processes, 24, 313–334.
doi:10.1080/01690960802365567
Kendon, A. (1980). A description of a deaf-mute sign
language from the Enga Province of Papua New Guinea
with some comparative discussion. Semiotica, 32(1-2),
81–118.
Marentette, P., & Nicoladis, E. (2011). Preschoolers’
interpretations of gesture: Label or action associate?
Cognition.
McNeill, D. (1992). Hand and mind. University of Chicago
Press.
McNeill, D. (2005). Gesture and thought. Chicago:
University of Chicago Press.
Miller, M. S. (1987). Sign iconicity: Single-sign receptive
vocabulary skills of nonsigning hearing preschoolers.
Journal of Communication Disorders, 20(5), 359–365.
doi:10.1016/0021-9924(87)90024-4
Namy, L. L. (2008). Recognition of iconicity doesn’t come
for free. Developmental Science, 11(6), 841–846.

Orlansky, M. D., & Bonvillian, J. D. (1984). The Role of
Iconicity in Early Sign Language Acquisition. J Speech
Hear Disord, 49(3), 287–292.
O’Brien, J. (1999). Metaphoricity in the Signs of American
Sign Language. Metaphor and Symbol, 14(3), 159–177.
doi:10.1207/S15327868MS140301
Rowe, M. L., & Goldin-Meadow, S. (2009a). Early gesture
selectively predicts later language learning.
Developmental Science, 12(1), 182–187.
Rowe, M. L., & Goldin-Meadow, S. (2009b). Differences in
early gesture explain SES disparities in child vocabulary
size at school entry. Science, 323(5916), 951–953.
doi:10.1126/science.1167025
Rowe, M. L., Özçalışkan, Ş., & Goldin-Meadow, S. (2008).
Learning words by hand: Gesture’s role in predicting
vocabulary development. First language, 28(2), 182–199.
Senghas, A., Kita, S., & Özyürek, A. (2004). Children
creating core properties of language: Evidence from an
emerging sign language in Nicaragua. Science,
305(5691), 1779.
Svensson, T., & Nilsson, L. G. (1989). The relationship
between recognition and cued recall in memory of
enacted and nonenacted information. Psychological
research, 51(4), 194–200.
Tellier, M. (2005). How do teacher’s gestures help young
children in second language acquisition? Text presented
at the International Society of Gesture Studies, Lyon,
France. Retrieved from http://gesture-lyon2005.enslyon.fr/article.php3?id_article=253
Tellier, M. (2008). The effect of gestures on second
language memorisation by young children. Gesture, 8,
219–235.
Vandierendonck, A., Kemps, E., Fastame, M. C., &
Szmalec, A. (2004). Working memory components of the
Corsi blocks task. British Journal of Psychology, 95(1),
57–79. doi:10.1348/000712604322779460

2048

