UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning of motor maps from perception: a dimensionality reduction approach
Permalink
https://escholarship.org/uc/item/1w76r80k
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Awasthi, Ankit
Sharma, Sadbodh
Mukerjee, Amitabha
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

   Learning of motor maps from perception: a dimensionality reduction approach
           Ankit Awasthi, Sadbodh Sharma, Amitabha Mukerjee (aawasthi, sadbodh, amit@cse.iitk.ac.in)
                                    Department of Computer Science and Engineering, IIT Kanpur
                              Abstract                                    However, the exact mechanisms by which the complex
   The role of perception in sighted infant motor development is
                                                                       high-dimensional visual stimulus is used for motor control
   well-established, but what are the processes by which an in-        of the arm, remain unclear. While there have been many
   fant manages to handle the complex high-dimensional visual          computational studies of different aspects of motor devel-
   input? Clearly, the input has to be modeled in terms of low-        opment, several involving robots with embodied cameras
   dimensional codes so that plans may be made in a more ab-
   stract space. While a number of computational studies have          (Beltrán-González, 2005; Hoffmann, Schenck, & Moller,
   investigated the question of motor control, the question of how     2005), such works usually address the question of manag-
   the input dimensionality is reduced for motor control purposes      ing the complexity and dimensionality reduction only periph-
   remains unexplored. In this work we propose a mapping where
   starting from eye-centered input, we organize the perceptual        erally (Jordan & Wolpert, 1999). A particularly interesting
   images in a lower-dimensional space so that perceptually sim-       approach was the modeling of reaching and grasping via neu-
   ilar arm poses remain closer. In low-noise situations, we find      ral networks (Kuperstein, 1991), and a related attempt to map
   that the dimensionality of this discovered lower-dimensional
   embedding matches the degrees-of-freedom of the motion.             the workspace using self-organizing maps (Saxon & Muker-
   We further show how complex reaching and obstacle avoid-            jee, 1990). However, these works do not deal directly with
   ance motions may be learned on this lower-dimensional motor         image models.
   space. The computational study suggests a possible mecha-
   nism for models in psychology that argue for high orders of            On the other hand, another body of work in robot motion
   dimensionality reduction in moving from task space to spe-          planning attempts to construct paths through a workspace that
   cific action.
   Keywords: motor development, perception-action models, di-          are optimal in various senses of reducing path length, kine-
   mensionality reduction, reach learning                              matic smoothness, dynamic smoothness, energy costs, etc. A
                                                                       class of efficient methods are based on sampling the motion
                          Introduction                                 space, which may also be rather high-dimensional, though
That the apparently random arm movements by neonates may               of the order of tens, not thousands as in the image space.
have a role in terms of learning visuo-motor control is a posi-        Such stochastic approaches include probabilistic roadmaps
tion that has gained strength in recent years (A. Van der Meer,        or branching trees of possible paths through the free space.
Weel, & Lee, 1995; Adolph & Berger, 2006). Visual control              However, these algorithms, some of which also have cogni-
of arm movement is evident almost immediately after birth,             tive ramifications, work primarily with inputs defined directly
when neonates appear to struggle with artificial handicaps to          in the workspace, and do not work on the image space as the
keep their arm in the field of view, such as when small weights        input (Choset, 2005).
are tied to their arms, or when they appear to be purposefully            The objective of this work is then to try to develop a model
keeping their arms within a narrow beam of light (A. van der           that would reflect motor properties in an embedding derived
Meer, 1997).                                                           purely from the visual space. Thus, we consider the mech-
   The emphasis on motor development over the last few                 anisms by which the system may observe certain similari-
decades, arising from the linkage between perception and               ties between perceived arm configurations to construct a local
action that has driven new theories of dynamic cogni-                  neighbourhood of visual configurations. These local neigh-
tion (Thelen, Smith, Lewkowicz, & Lickliter, 1994), has fur-           bourhoods are presumed to lie on a low-dimensional surface
ther highlighted this connection. Indeed, there is evidence to         in the very high-dimensional image space. In the ISOMAP
suggest that the very representation of action has some re-            algorithm being used here (Tenenbaum, Silva, & Langford,
lation to mental imagery which may provides the prospec-               2000), these local neighbourhoods are assumed to be linear in
tive structure for organizing motions (Caeyenberghs, Wilson,           the dimensionality of the manifold, and they are then “com-
Van Roon, Swinnen, & Smits-Engelsman, 2009). Studies on                posed” to construct the global relations between distant arm
monkeys report that a large majority of neurons implicated             configurations. For the purposes of the demonstration we
in the reach planning area in the posterior parietal cortex,           have used a simulated two degree of freedom arm.
encode location in eye-centred coordinates (Batista, Buneo,
Snyder, & Andersen, 1999). In addition, nearly half the neu-           Reach planning and obstacle shifts
rons in the ventral premotor area - thought to be implicated           The input consists of a large number of images showing the
in visual grasp planning - are responsive to eye-centered im-          arm in random poses in its workpace. These images are then
age data (Mushiake, Tanatsugu, & Tanji, 1997). It is thought           mapped to a lower-dimensional manifold. We shall use the
that the eye-centric neural computations work together with            term visuo-motor map and low-dimensional embedding for
other body-centric and arm-centric systems (Graziano, 2011)            this image to low-dimensional map. Note that the variables
but much of the planning is thought to invoke eye-centered or          in the low-dimensional map are just mathematical abstrac-
visual images of the arm.                                              tions that emerge from the computation and are not based on
                                                                   1296

                                                                     the models become increasingly accurate.
                                                                        We demonstrate the dimensionality reduction process - part
                                                                     (a) - on three domains - images of a simulated two-link pla-
                                                                     nar arm moving to various positions in its workspace, a hu-
                                                                     manoid robot moving its arm along a straight line, and two
                                                                     coordinated planar arms moving a box. A two-dimensional
                                                                     interpolation is shown to work well for the first situation (two
                                                                     degree of freedom in the arm). For the other two situations,
                                                                     we find that one dimension is enough. For motion planning
                                                                     (part b), and obstacle avoidance (c), we restrict ourselves to
                                                                     only the first simulated arm - the two degree of freedom sim-
                                                                     ulation of the upper and lower limbs.
                                                                        For motion planning, both initial and desired configura-
                                                                     tions, as well as obstacles, if any, are known only in the visual
                                                                     space. The initial and target images are is mapped to the man-
                                                                     ifold embedding using the out-of-sample mapping - i.e. they
                                                                     are interpolated based on the “nearest” images and the same
                                                                     interpolation is applied to the embedded points. Now, a map-
                                                                     ping to the goal can be discovered in terms of edges in the
                                                                     graph, which actually constitute a roadmap, but in the visuo-
                                                                     mootor space and not in the usual configuration space of robot
                                                                     motion planning. The problem of having the visuomotor map
                                                                     represent obstacles is quite challenging, since some obstacles
                                                                     (such as the own body) may be permanent, but in most sit-
                                                                     uations other constraints would arise in the workspace. As
                                                                     the obstacle positions shift with respect to the arm, must it re-
                                                                     learn the visuo-motor embedding every time? This is indeed
Figure 1: Image data from (a) two-degree of freedom pla-
                                                                     what happens to most robot-motion planning algorithms, and
nar arm,(b) humanoid robot nao moving one arm along a
                                                                     handling dynamic obstacles remains a considerable challenge
linear trajectory. The residual variance error in the lower-
                                                                     in robotics. In our case, we assume that our map is a base map
dimensional space after ISOMAP, versus the dimensionality
                                                                     of the maximal free space, constructed in the absence of all
of the embedding is shown below. Left: planar arm (2-DOF).
                                                                     movable obstacles. This results in an embedding from which
Right: humanoid robot nao moving arm in straight line (1-
                                                                     nodes can be deleted if a obstacle is introduced to a region of
DOF); errors are noisy, 1̃0−5 ).
                                                                     the image space which was otherwise occupied by an arm in
                                                                     one of the data points. Such situations are handled by mark-
prior knowledge about any physical variable. Thus, we use            ing as blocked the non-free nodes of the graph in the lower-
no knowledge of the kinematics or geometry of the arm, ex-           dimensional space. To start with therefore, we consider full
cept the initial image data. Despite this paucity of supervisory     rotations for each of the two joints of our simple 2-DOF arm,
knowledge, we are able to identify the number of degrees of          and images are randomly sampled across this entire 360×360
freedom (two) of the motion system, and also a set of (two)          degree rotation range.
parameters that can be controlled to move the arm to different          As obstacles are introduced into the workspace, the system
configurations within its workspace. We also show that these         marks those nodes of the graph that visually overlap with the
parameters can be easily mapped to physical variables such           obstacle as blocked, and motions are restricted to the remain-
as joint angles.                                                     ing “free” parts. Of course, this method assumes that if two
   The visuo-motor map is obtained as a graph embedded in            nodes are in free space, the path between them is also free,
the lower-dimensional space, each node is mapped to an im-           which is not true for the non-linear mapping space. However,
age in the much higher-dimensional image space. The struc-           considering how densely sampled the image space of a limb
ture of the graph is shared between both the original image          in daily use is for an organism, we may argue that in real situ-
space as well as the lower-dimensional embedding space. In           ations, the visuomotor map will have a dense mapping so that
the following, we shall consider a) constructing such a map          this assumption is far more likely to hold.
(with no prior knowledge about the physics of the arm), b)              An additional characteristic of the learning process reflects
using it to map a path from a source to a target in the absence      increasing accuracy in the visuo-motor map. As the system
of obstacles, and c) map obstacles that may impinge on the           encounters more and more motions in the visual space, the
path, and plan trajectories that may avoid it. A further aspect      graph becomes more dense, and the accuracy of plans im-
is that with increasingly dense samples in the image space,          proves. This may also contribute to the observations of in-
                                                                 1297

creasing fluency in infant motions, though much of it is also        be chosen so as to minimize the error in these geodesic dis-
due to development in the musculatory system.                        tances. This is the residual error which is reported in the
                                                                     graphs in figure 1c. If there is a sharp drop in the error at
                Dimensionality Reduction                             some value of the dimension used, then one assumes that this
                                                                     dimension is a good estimate for the dimensionality of the
We consider a computational system exposed to a large num-
                                                                     underlying manifold. In some cases (e.g. for the Nao robot
ber of images reflecting different motor configurations of its
                                                                     images), all the errors are less than 10−5 - this implies that the
arms. At the same time, it has muscle sensations of how the
                                                                     error is already very low at dimension one, so d=1 is a good
arm motion is executed. In this work, we focus primarily on
                                                                     estimate for its dimensionality.
the visual input space. We first observe that the data there,
captured here in terms of a set of large images, constitute an
extremely high dimensional image space. Every pixel may
be considered to be independent, so that a 800 x 800 image
(figure. 1(a)), is a point in a 64000 dimensional space. That
is each image is one point out of N 64000 , where N is the num-
ber of values a pixel can take. Clearly, the system needs to
reduce the complexity of this data drastically. In the biolog-
ical system, this is achieved by a combination of neural data
compaction processes starting in the retina, as well as a num-
ber of learned responses that eventually result in responses in
the pre-motor areas, primarily in the posterior-parietal cortex
(PPC) (Batista et al., 1999). Here we consider a computa-
tional model for construcing a lower-dimensional manifold
from the image data.
   Many approahes have been tried for dimensionality re-
duction. One class of approaches assume that the underly-
ing manifold from which the observations are drawn is lin-
ear. Linear dimensionality reduction methods include lin-
ear methods such as Principal Component Analysis or Multi-
dimensional Scaling (Bishop, 2006). On the other hand, non-          Figure 2: Two-dimensional embeddings generated by
linear dimensionality reduction assumes that the data is drawn       ISOMAP.Top Left: map from 50 robot images. Top Right:
from a manifold - a surface that is mappable everywhere to a         map from 2000 images showing variation of θ1 along the
disk in a euclidean space of much lower-dimension. Such              manifold. Bottom: map in 3d showing a cross-section with
NLDR algorithms include include Isomap, Locally-Linear               θ1 kept constant and θ2 varying. Note that the topology of the
Embedding (LLE), Local Tangent Space Alignment, etc. (Lee            embedding actually reflects the topology of the θ1, θ2 space -
& Verleysen, 2007). In this work, we have used the ISOMAP            in that the theta1 variation occurs along the ring(top right fig-
algorithm, which attempts to preserve geodesic distances in          ure), while the θ2 variation is approximately radial(bottom).
the lower-dimensional mapping.                                       Note that the 50-case also captures the cyclic nature of θ1,
                                                                     though the resolution is poor. This suggests the torus topol-
Isomap on the image space                                            ogy of the θ1, θ2 space.
To see how the ISOMAP algorithm is applied to our image
space, we observe that a continuous motion will result in a
sequence of images that lie along a one-dimensional curve in         Out of sample points
the image space. This is because images from successive in-          A significant difficulty with non-linear dimensionality ap-
stants in time are likely to be very similar, and extending this     proaches is that these models are not very good for mapping
similarity locally would result in a 1-manifold. This applies        novel (unseen) data points. In order to overcome this very
to complex real images (figure. 1b) Now, let us consider a           significant difficulty, some approaches such as the Locality
two-degree of freedom arm For the two-degree of However, it          Preserving Projections (LPP) (Lee & Verleysen, 2007). Here
turns out that all such one-dimensional trajectories in the im-      a linear mapping is constructed based on a quadratic function
age space are found to lie on a surface, which is everywhere         that attempts to preserve some aspects of the non-linear data.
mappable to a disk in the euclidean plane (R2 ). Thus, all these     However, the inverse mapping (from lower dimension to the
images lie on a curve 2-dimensional manifold in the image            original space) in such systems is poor, and we have restricted
space (figure. 1). Distances between configurations can be           ourselves to true non-linear models.
thought of as distances between the shortest paths (geodesics)          In order to solve the out of sample interpolation problem,
that lie on this manifold. The Isomap essentially solves an op-      we have borrowed an idea from Locally-Linear Embedding,
timization problem where the lower-dimensional points are to         where a local approximation can be constructed for novel
                                                                 1298

points based on a weighted linear approximation in the im-
age space. Now, the same weights are used in the lower-
dimensional space to obtain a mapping for the point in that
space. Indeed, in the LLE, the fact that these weights re-
main the same in the lower-dimensional space is the con-
straint that is the basis for its optimization. The underlying
assumption is that locally, the nearest neighbours around the
novel point may be approximated by a linear surface in both
the image space and the target space. While the Isomap algo-
rithm is premised on a somewhat different (global geodesic)
constraing, the locally linear approximation is not too far off
for the isomap, especially if the sampling is dense. Thus, this
method is here adopted to our isomap data; though it is only
approximate, the method appears to work well in practice.
   Thus, the objective of this work is to use visual input that
is as general as possible, but to show that for certain func-
tional situations, it can lead to much reduced dimensionali-
ties. Thus, here, the very fact that it reflects different con-
figurations of the same physical arm restricts its variation
in the image space. Although we have experimented with                Figure 3: ISOMAP embedding (torus) with points with a
several other dimensionality reduction techniques, we report          sampling of images. The base angle (what we call θ1)
here only the results based on ISOMAP. The approach is to             changes along the circumference of the torus and θ2 along
first reduce the dimensions of the visual input and then use          the radius of the torus.
this compact representation to do path planning in the pres-
ence of obstacles. Also, we show that a simple mapping can
be learnt between the low dimensional embedding generated             learn a mapping directly from the sensory input(image space)
by ISOMAP and the motor signals and thus effectively elim-            to motor signals(θ space) (see figure 4)
inating the problem mentioned above.
                 Visuo-Motor embedding
We conducted the following experiments on 100 x 100 im-
ages of a robot. For our experiments, we assumed that the
robot is free to move all around - that is there are no restrci-
tions on θ1 and θ2, i.e, 0 ≤ θ1 ≤ 360, 0 ≤ θ2 ≤ 360. The
lower dimensionality embedding generated by the Isomap, as
shown in figure 3 , is the visuo-motor embedding since it cap-
tures motor signals using visual data and both can be arrived         Figure 4: Comparision of the performance of neural network
at using the embedding.                                               when learnt from high dimensional images(left) and low di-
                                                                      mensional embedding(right) to θ1, θ2 for the two-link manip-
Mapping Visuo-Motor Embedding to Motor Signals                        ulator.
In this experiment,we illustrate that the ISOMAP not only
reduces the number of dimensionality optimally, but this re-
duction is not arbitrary and geometry of the embedding cap-           Mapping Obstacles to Visuo-Motor Embedding
tures important insights into parameterization of the data -
θ1, θ2(figure 3). In order to further substantiate this point         Given an obstacle, we mark all the points which are blocked
we show that there exists simple mapping from the embed-              by the obstacle as colliding and others as collision free config-
ding to motor signals - (θ1, θ2). We used a 1-hidden layer(10         urations (this can be checked very easily in the image space)
hidden units) feed forward neural network with linear output          resulting a set of collision free points in which the path can
to learn the mapping with small errors. Moreover the pa-              be planned. An important adavantage of this method is that
rameters governing the data - θ1, θ2, can be seen as motor            it avoids recomputation of the embedding and obstacle map-
signals given to manipulate the robot. Note that, once a path         ping for each obstacle separately. The set of collision free
is found in the embedding space, such a mapping is required           points can be easily updated in the event of a moving obsta-
to realize it in real i.e, generating the actual motor signals to     cle (figure 5), new obstacles appearing in the workspace, and
traverse the path. While there exists a simple mapping from           old obstalces going away. This also preserves the topology of
the emebdding space to the motor signals, it is very hard to          the embedding.
                                                                  1299

Figure 5: Robot and obstacle configurations and corresponding mapping to embedding space. The set of collision free points
can be easily updated for a moving obstacle as shown. Moreover, if a previously free path becomes obstructed due to movement
of an obstacle or apperance of a new obstacle, a new path can be easily be planned with the updated set of collision free points.
Blue points here are the set of collision free points and green points the set of colliding points. Red color shows the points along
the path from the initial configuration to final configuration
Path Planning in Visuo-Motor Embedding                                    other along the thickness, then these capture some aspects
Once we have the embedding points and a set of collision free             of the variation (R: θ1 , θ2
points we can plan a path between any pair of start and end            • any node in the graph associated with two variables is
points, using any of the graph search algorithms. In case, the            mapped to the image space, and any image used in the
start or end point is not in the embedding, a nearby point is             original input is mapped to a node. (R: forward and inverse
found in the embedding and then path planning is done be-                 kinematics)
tween those points. One of the important observations is that
a shortest path query in the graph, results in a path which            • the space of these variables is connected with edges that
avoids any redundant movements which is consistent with                   denote nearest neighbours. (R: there is a roadmap
how a human would do if presented with same planning task.
In other words, the shortest path in the embedding space cor-          • given any images for the start and end positions, it is pos-
responds to least changes to parameters - θ1, θ2. (see fig-               sible to find a path connecting them using these edges. (R:
ure 6) Moreover, as an obstacle changes its position in the               roadmap-based path planning)
workspace, the obstructed points can be removed as visually
                                                                       • given an obstacle, the system can determine which config-
percieved and a new path can be planned avoiding the obsta-
                                                                          urations hit the obstacle in the image space. The corre-
cle.
                                                                          sponding nodes are removed in the manifold graph. (R: the
                                                                          C-space map of an obstacle).
              Learning a representation?
We have shown that this process, starting from a set of im-            • given an obstacle and a start and goal image, a path can be
ages and no other information, is able to discover a number               found via those edges not incident on any of the obstacle
of facts. We present these facts, which we call a naive repre-            nodes. (R: C-space obstacle avoidance).
sentation, presenting in parentheses what a robotics text may
                                                                       .
call an analog for these.
                                                                          The above analogies are of course very coarse. Only the
• a two dimensional manifold obtains then best reduction in            topology is really preserved; none of the metric properties
   residual error. (Robotics: it has two degrees of freedom            are guaranteed to hold; thus the path obtained may not be
                                                                       very short. Nonetheless, considering that no prior knowl-
• the structure of the low-dimensional 2-D manifold is that            edge of any kind was used in constructing this motor map,
   of a torus, so it is cyclic in both dimensions, i.e. it is a as     the above naive representation is surely an impressive anal-
   S1 × §1 topology. (R: it is an S1 × §1 topology)                    ogy to present models of robotics.
                                                                          Note however, that the system, in using these routines, need
• if we associate two variables with these 2 DOFs, we may              not be “conscious” that it is using such a representation - it
   have one go around the torus in the main direction, and the         just has to be able to use it effectively.
                                                                   1300

   A final note on the precision of the process. We note that       Hoffmann, H., Schenck, W., & Moller, R. (2005). Learning
the space need not be sampled uniformly, as was done here.            visuomotor transformations for gaze-control and grasping.
In many situations, certain configurations would be occurring         Biological Cybernetics, 93(2), 119–130.
more frequently, and there would higher accuracies would            Jordan, M., & Wolpert, D. (1999). Computational motor
hold in these part of the space (as in the rough diagram of           control. The cognitive neurosciences, 601.
the 50-torus earlier). This is also true of animals and humans,     Kuperstein, M. (1991). Infant neural controller for adaptive
where more frequently executed actions are much more pre-             sensory-motor coordination. Neural Networks, 4(2), 131–
cise.                                                                 145.
                                                                    Lee, J., & Verleysen, M. (2007). Nonlinear dimensionality
                         Conclusion                                   reduction. Springer.
In this work, we have demonstrated that although visual input       Meer, A. van der. (1997). Keeping the arm in the limelight:
is extremely high-dimensional, the data lies on a nonlinear           advanced visual control of arm movements in neonates. Eu-
manifold that is much lower dimensional. The dimension-               ropean Journal of Paediatric Neurology, 1(4), 103–108.
ality of this manifold, and its structure, reveals much about       Meer, A. Van der, Weel, F. Van der, & Lee, D. (1995). The
the problem domain and may be called a naive representa-              functional significance of arm movements in neonates. Sci-
tion. We also propose an approximate mechanism for han-               ence, 267(5198), 693.
dling out-of-sample data in the NLDR algorithm - first, by          Meer, v. d. W. F. R. . L. D. N. van der, A. L. H. (1996).
constructing the manifold for the entire workspace and then           Lifting weights in neonates: Developing visual control of
deleting points, as opposed to trying to construct a new man-         reaching. Scandinavian journal of psychology, 37(4), 424–
ifold for every workspace. This (figure ) also explains the           436.
fact that during the early stages of motor learning, the res-       Mushiake, H., Tanatsugu, Y., & Tanji, J. (1997). Neuronal
olution of the map is poor, and this may also contribute to           activity in the ventral part of premotor cortex during target-
some aspects of the jerky movements demonstrated in early             reach movement is modulated by direction of gaze. Journal
infancy. As the system populates the visual space with more           of neurophysiology, 78(1), 567–571.
data points, the resulting surface becomes smoother and per-        Oztop, E., Bradley, N., & Arbib, M. (2004). Infant grasp
mits fluent motions.                                                  learning: a computational model. Experimental Brain Re-
                                                                      search, 158(4), 480–503.
   Is there cognitive evidence that such a method is actually
                                                                    Saxon, J., & Mukerjee, A. (1990). Learning the motion
implemented in the cortex? It is perhaps too early to comment
                                                                      map of a robot arm with neural networks. In Neural net-
on this. We can only point to a clear role for eye-centered
                                                                      works, 1990., 1990 ijcnn international joint conference on
coordinates in the reach planning process, and suggest that
                                                                      (pp. 777–782).
such a representation, involving “nearby” images from the
                                                                    Tenenbaum, J. B., Silva, V. de, & Langford, J. C. (2000). A
image space, may constitute at least a plausible model for
                                                                      global geometric framework for nonlinear dimensionality
part of the computation involved in reach planning.
                                                                      reduction. Science, 290(5500), 2319.
                         References                                 Thelen, E. (2000). Motor development as foundation and
                                                                      future of developmental psychology. International Journal
Adolph, K., & Berger, S. (2006). Motor development. In                of Behavioral Development, 24(4), 385–397.
   Handbook of child psychology.                                    Thelen, E., Smith, L., Lewkowicz, D., & Lickliter, R. (1994).
Batista, A., Buneo, C., Snyder, L., & Andersen, R.                    A dynamic systems approach to the development of cogni-
   (1999). Reach plans in eye-centered coordinates. Science,          tion and action. MIT Press.
   285(5425), 257.                                                  Von Hofsten, C. (2004). An action perspective on motor
Beltrán-González, C. (2005). Toward predictive robotics: the        development. Trends in cognitive sciences, 8(6), 266–272.
   role of vision and prediction on the development of active
   systems. Unpublished doctoral dissertation.
Bishop, C. (2006). Pattern recognition and machine learning.
   Springer.
Caeyenberghs, K., Wilson, P., Van Roon, D., Swinnen, S.,
   & Smits-Engelsman, B. (2009). Increasing convergence
   between imagined and executed movement across devel-
   opment: evidence for the emergence of movement repre-
   sentations. Developmental science, 12(3), 474–483.
Choset, H. (2005). Principles of robot motion: theory, algo-
   rithms, and implementation. The MIT Press.
Graziano, M. (2011). Is reaching eye-centered, body-
   centered, hand-centered, or a combination? Reviews in
   the Neurosciences, 12(2), 175–186.
                                                                1301

