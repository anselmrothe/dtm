UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cognitive Biases in a Geospatial Intelligence Analysis Task: An ACT-R Model
Permalink
https://escholarship.org/uc/item/9c97q1b4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Paik, Jaehyon
Pirolli, Peter
Lebiere, Christian
et al.
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

      Cognitive Biases in a Geospatial Intelligence Analysis Task: An ACT-R Model
                          Jaehyon Paik (jpaik@parc.com), Peter L. Pirolli (pirolli@parc.com)
                                                        Palo Alto Research Center
                                               3333 Coyote Hill Rd., Palo Alto, CA 94304
        Christian Lebiere (cl@andrew.cmu.edu), Matthew Rutledge-Taylor (mattrt@andrew.cmu.edu)
                                          Carnegie Mellon University, Psychology Department
                                               5000 Forbes Avenue, Pittsburgh, PA 15218
                             Abstract                                  SOCINT (socio-cultural intelligence), and SIGACT (attack
  An ACT-R model of sensemaking in a geospatial intelligence
                                                                       intelligence).
  task was developed based on Instance-Based Learning Theory
  (IBLT). The model (a) maintains hypotheses about the
  probability of attacks by insurgent groups, (b) seeks new
  information based on those hypotheses, and (c) updates
  hypotheses based on new evidence. The model provides a
  functional account of how these sensemaking processes are
  carried out in a cognitive architecture, and model performance
  can be compared to normative (Bayesian) standards.
  Simulations exhibit two well-known cognitive biases that are
  frequently identified as problems in intelligence analysis: (1)
  anchoring in the weighting of new evidence and (2)
  confirmation bias in seeking new information.
   Keywords: ACT-R, cognitive biases, sensemaking
                         Introduction                                        Figure 1: The screen shot of the geospatial task. The
Sensemaking (Klein, Moon, & Hoffman, 2006a, 2006b;                     letters (A, B, C, D) indicate the center of the group location,
Pirolli & Card, 2005; Russell, Stefik, Pirolli, & Card, 1993)            and â€˜1â€™ surrounded by a box indicates the attack location.
is a concept that has been used frequently in studies of
intelligence analysis. The term suggests an active seeking                The task begins with a given attack location (SIGACT)
and processing of information to achieve understanding.                along with group centers (HUMINT), A, B, C, and D
Sensemaking involves a set of processes aimed at seeking               representing the center of activity for four possible insurgent
and filtering information, plus a set of processes that                groups. The first step is to report probabilities of attack by
develop representational schemas (frames) that best fit the            each group [A%, B%, C%, D%] based on the SIGACT and
available evidence and provide a basis for understanding the           HUMINT (see Table 1)1. After that, the task is to iteratively
data. In this paper we present the cognitive model of basic            choose among the four remaining INT layers (Table 1), up
sensemaking processes for an intelligence analysis task. A             to a total of three INTs (layers), one at a time, in any order.
major concern in the intelligence community is the impact              Each INT layer provides unique evidence. Specifically,
of cognitive biases on the accuracy of analyses (Heuer,                IMINT can reveal whether an attack happened on a
1999). We present simulation results that exhibit anchoring            government or military building, MOVINT provides
bias in the evaluation of new evidence and confirmation                evidence whether an attack occurred in dense or sparse
bias in seeking evidence.                                              traffic, SIGINT indicates electronic â€œchatterâ€ or â€œsilenceâ€
                                                                       by different groups, and SOCINT indicates the group whose
                    The Geospatial Task                                region the attack happened. At each stage, the selection of a
                                                                       particular INT provides evidence that can be used to update
The geospatial task (Figure 1) is one of a set of challenge            the probability distribution over the hypotheses about the
tasks developed as part of the IARPA ICArUS program to                 responsibility of the four groups in producing the given
drive the development of integrated neurocognitive models              attack. The rules specifying how evidence ought to update
of sensemaking. This specific task required reasoning based            these probabilities is given in the PROBS rules in Table 1.
on a set of rules concerning the relation of observed                  After the last stage of INT selection, the task is to allocate
evidence to the likelihood of attack by four different groups.         resources (troops) to prevent further attacks.
A layered geospatial map is presented on a computer screen,
with different layers presenting different forms of
intelligence (INTs). The INTs include HUMINT (human
intelligence), IMINT (image intelligence), MOVINT                         1
                                                                            The new version of the task will provide the initial
(movement intelligence), SIGINT (signal intelligence),
                                                                       probabilities based on HUMINT
                                                                   2168

    Table 1: Probabilistic rules provided to user for inferring                   and not seek (or discount) those that support an
             beliefs about group attack likelihoods.                              opposite conclusion or belief (Wickens & Hollands,
                                                                                  2000). The seeking of information considered
     INTS                               PROBS                                     supportive of favored beliefs (Nickerson, 1998).
                 If a group attacks, then the relative likelihood of      Studies (Cheikes, Brown, Lehner, & Adelman, 2004;
  HUMINT         attack decreases as the distance from the group          Convertino, Billman, Pirolli, Massar, & Shrager, 2008;
                 center increases.                                        Tolcott, Marvin, & Lehner, 1989) have found evidence of
                 If A or B attack then the attack is four times as        confirmation bias in tasks involving intelligence analysis,
    IMINT        likely to occur on a Government versus Military          and there is a common assumption that many intelligence
                 building. If C or D attack then vice versa.              failures are the result of confirmation bias in particular
                 If A or C attack then the attack is four times as        (Chorev, 1996; Grabo & Goldman, 2004; Heuer Jr, 1999).
  MOVINT         likely to occur in dense versus sparse traffic. If B
                 or D attack then vice versa.                             Biases in the Geospatial Task
                 If SIGINT on a group reports chatter, then attack        The geospatial task might elicit anchoring and confirmation
                 by that group is seven times as likely as attack by      biases at multiple points in the process. Anchoring bias in
                 each other group
   SIGINT
                 If SIGINT on a group reports silence, then attack
                                                                          weighing evidence might be found when participants revise
                 by that group is one-third as likely as attack by        their belief probabilities after selecting and interpreting a
                 each other group.                                        particular INT. The estimates of belief probabilities that
                 If a group attacks then that group is twice as           were set prior to the new INT evidence could act as an
   SOCINT                                                                 anchor, and the revised (posterior) belief probabilities could
                 likely to attack in its own versus other region.
                                                                          be insufficiently adjusted to reflect the new INT (i.e., when
         Anchoring and Confirmation Biases                                compared to some normative standard).
                                                                             Confirmation bias in weighing evidence can also be found
Anchoring and confirmation biases have a long history of                  in the hypothesis adjustment process. When applying a
study in cognitive psychology and the intelligence                        particular INT, such as IMINT (which supports multiple
communities (Heuer Jr, 1999; Klayman, 1995; Klayman &
                                                                          hypotheses), participants may only apply the adjustment to
Ha, 1987; Nickerson, 1998; Tversky & Kahneman, 1974;
                                                                          the preferred hypothesis while neglecting other groups also
Wason, 1960). Process models of these biases, especially in
                                                                          supported by evidence, or weight the evidence too strongly
complex tasks, remain largely unexplored. In this paper we
                                                                          in favor of the preferred hypothesis.
develop cognitively plausible process model of the
                                                                             Finding confirmation bias in seeking evidence in the task
geospatial task in the ACT-R architecture. We then compare                is somewhat more difficult since most INTS apply equally
this ACT-R model against a rational Bayesian model of the                 to all hypotheses. We used the SIGINT layer to identify this
task to examine evidence of anchoring and confirmation                    kind of bias because a single hypothesis has to be selected
biases.                                                                   for that layer. SIGINT provides considerable gains to the
                                                                          selected hypothesis when chatter is detected (7 times more
Anchoring Bias and Anchoring and Adjustment                               likely), so participants could get significant certainty.
Heuristic                                                                 However, it loses considerable weight (3 times less likely)
Anchoring is a cognitive bias that occurs when individuals                when silence is detected. Thus, a decision to choose the
establish some belief based on some initial evidence, and                 SIGINT layer too early (before a specific group has
then overly rely on this initial decision in their weighting of           dominates the other in terms of relative likelihood) might be
new evidence (Tversky & Kahneman, 1974). Human beings                     interpreted as confirmation bias in evidence seeking.
tend to anchor on some estimate or hypothesis and
subsequent estimates tend to be adjustments that are                                      The ACT-R architecture
influenced by the initial anchor pointâ€”they tend to behave                   ACT-R (Anderson et al., 2004; Anderson & Lebiere,
as if they have an anchoring+adjustment heuristic.                        1998) is a cognitive architecture that includes a declarative
Adjustments tend to be insufficient in the sense that they                memory module that stores and retrieves information and a
overweight the initial estimates and underweight new
                                                                          procedural module that coordinates the flow of information.
evidence.
                                                                          Declarative knowledge in ACT-R is represented formally as
                                                                          chunks of information (Miller, 1956; Simon, 1974). Chunks
Confirmation Bias
                                                                          are recalled from long-term declarative memory by an
Confirmation bias is typically defined as (for a survey, see              activation based retrieval process. Activation spreads from
Nickerson, 1998):                                                         the current focus of attention, including goals, through
  â€¢ The interpretation of evidence in ways that are partial               associations among chunks in declarative memory. The
        to existing beliefs, expectations, or a hypothesis in             spread of activation from one cognitive structure to another
        hand (Nickerson, 1998)                                            is determined by attentional weights on the associations
  â€¢ The tendency for people to seek information and cues                  among chunks. These weights determine the rate of
        that confirm the tentatively held hypothesis or belief,           activation flow among chunks. Partial matching is a
                                                                      2169

mechanism that allows for chunks in declarative memory              In Figure 2, the information gain for seeing an attack on a
that do not perfectly match a retrieval request to be               government building is .4 and an attack on a military
retrieved. Blending is a memory retrieval mechanism that            building is .09. The expected information gain is calculated
allows all chunks in declarative memory that match or               by weighting each of the possible outcomes of information
partially match a retrieval request to blend together to create     gain by the probability of obtaining that outcome. Thus, the
a new chunk representing an aggregate response (Lebiere,            expected information gain for selecting the IMINT layer is
1999).                                                              (.56)(.4) + (.44)(.09) = .26
   Production rules are used to represent procedural                   Our rational model computed the expected information
knowledge in ACT-R. That is, they specify how to apply              gain for all layers at each stage. The rational choices were
cognitive skill (know-how) in the current context, and how          compared to the selections made by ACT-R to identify
to retrieve and modify information in other modules. In             biases.
ACT-R, each production rule has conditions that specify
structures that are matched in limited-capacity buffers
corresponding to information from the external world or
other internal modules. Each production rule has actions
that specify changes to be made to the buffers or requested
functions in the associated modules.
    The Rational Model versus ACT-R Model
We developed an ACT-R model to perform the geospatial                   Figure 2: An example of the rational Bayesian hypothesis
task, as well as a rational (Bayesian) model as a normative                     estimates for an IMINT layer selection.
benchmark. The ACT-R model implemented a version of
instance-based learning theory (Gonzalez, Lerch, & Lebiere,         The ACT-R Model
2003), and the rational model employs a standard Bayesian           We assume that an average person is not able to compute
approach for updating belief and selecting new evidence             the expected information gain of all possible layers, because
(INTs) based on an expected information gain metric.                it involves substantial amounts of computation. We
                                                                    considered two cognitively plausible alternatives to develop
The Rational Model                                                  an ACT-R model.
From the PROBS rules discussed in table 1, we can extract           â€¢ Difference reduction heuristics. One cognitively plausible
specifications of the likelihoods of evidence, P(e|h), where e         way to reduce complexity is to assume that people use a
is evidence (e.g., â€œchatterâ€) and h is a hypothesis (â€œgroup A          heuristic such as hill climbing to evaluate moves. Rather
attacksâ€). Bayes rule can be applied to compute the                    than focus on maximizing expected information gain, hill-
posterior likelihood of h given specific evidence e and prior          climbing analysis could focus on achieving states that are
probabilities P(h)                                                     closer to an ideal goal state (i.e., in this case, a state in
                                ð‘ƒ ð‘’ â„Ž ð‘ƒ(â„Ž)                             which the attacks are unambiguously caused by Group A,
                   ð‘ƒ â„Žð‘’ =                                              or Group B, etc.). This would require some heuristic for
                                 ! ð‘ƒ ð‘’ ð‘– ð‘ƒ(ð‘–)
where i iterates over all hypotheses.                                  evaluating differences (distances) from the goal state.
   For instance, in Figure 2, we assume some HUMINT data            â€¢ Memory-based move evaluation. It is well known in the
has been processed, a probability has been assigned to each            field of naturalistic decision making that experts
of the hypotheses, and the goal is to evaluate the choice of           invariably rely on vast amounts of declarative memory
an IMINT layer. The outcomes represent the estimates of                experience and well-practiced cognitive skill (Klein,
government and military building attacks given the current             1998). We assume that participants store move outcomes
hypotheses strengths. The posteriors are the updated                   in declarative memory, and that blended retrievals based
probability distributions according to the outcomes.                   on current states and possible moves can produce a
   The choice of INT layers can be evaluated by their effects          blended retrieval of outcomes to those moves. This would
on expected information gain (Austerweil & Griffiths,                  be a weighted smoothing of gains that had been made by
2011). Information gain is defined as the reduction in                 similar moves in the past. Although not precisely
entropy measured over the hypothesis probabilities that                equivalent to the computation of rational expected
occur by acquiring additional evidence. Information gain is            information gains (a weighting over the gains achieved by
specified as                                                           possible layer selection outcomes), blending over memory
                 ð¼ðº ð·, ð‘’ = ð» ð· âˆ’ ð»(ð·|ð‘’)                                of past INT outcomes and gains should produce similar
where H(D) is the entropy of the distribution of probabilities         effects.
over hypotheses, and         H(D|e) is the entropy of the              Our ACT-R model of the geospatial task explored some
distribution of posterior probabilities after some evidence e       plausible difference reduction heuristics in a memory-based
has been discovered.                                                move evaluation framework. The following weighted
                                                                    distance function assumes that the goal is to achieve
            ð» ð·|ð‘’ = âˆ’           ð‘ƒ ð· ð‘’ ð‘™ð‘œð‘”! ð‘ƒ(ð·|ð‘’)
                              !                                     certainty on one of the hypotheses (i.e., pi =1).
                                                                2170

                                     ð‘! (1 âˆ’ ð‘! )                       problems, and, most relevant here, a skew toward
                        !âˆˆ!!"#$!!"!"
                                                                        underestimating answers, as is common in anchoring and
   We assume that the model relies on the use of declarative            adjustment processes.
chunks that represent hypothetical past experiences of                     This approach was leveraged in the current model to
selecting INT layers. This is intended to capture a                     account for how the PROBS rules (from table 1) are
hypothesized learning process whereby participants have                 interpreted and applied to estimate the effects of the rules on
attended to a current probability distribution, chosen a layer,         the relative probabilities that the groups are responsible for
revised their estimates of the hypotheses, and assessed the             the attack under examination. The ACT-R modelâ€™s memory
utility of the layer selection they just made. For instance, if         was populated with a range of facts consisting of triplets: an
a participant had experienced two situations in which they              initial probability, an adjustment factor, and the resulting
had assessed a probability distribution [.4 .2 .2 .2] and               probability. These chunks are derived from the PROBS
selected an IMINT layer, and had experienced a                          rules shown in Table 1. For example, if the attack is found
â€œgovernment buildingâ€ attack one time and a â€œmilitary                   to occur on of road with dense traffic, the MOVINT rule
buildingâ€ attack a second time (See figure 2). The model                specifies that groups A and C are 4 times as likely to have
assumes the two chunks in its declarative memory.                       been responsible. When a layer of information is made
                                                                        available to the model, it adjusts the current set of
   (exp1                                 (exp2                          probabilities by retrieving the relevant chunks and replacing
          isa layer-choice                        isa layer-choice      the prior probabilities with the posteriors representing in the
          prior-a 0.4                             prior-a 0.4           retrieved chunks. The results of this chunk based rule
          prior-b 0.2                             prior-b 0.2           interpretation were then averaged over a thousand runs,
          prior-c 0.2                             prior-c 0.2           given the variations in answers resulting from activation
          prior-d 0.2                             prior-d 0.2           noise in the retrieval process. When provided with ratio
          layer IMINT                             layer IMINT
                                                                        similarities between probabilities (and factors), the primary
          outcomes government                     outcomes military
          utility 0.58)                           utility 0.69)         effect is an underestimation of the adjusted probability for
                                                                        much of the probability range.
where the utilities are computed by the weighted distance
metric.                                                                                         Assessment
   At a future layer selection point, a production rule will            Biases can be defined as deviations from some norm
request a blended/partial matching retrieval from declarative           (Jonathan D. Nelson, 2005; J.D. Nelson, McKenzie,
memory like below:                                                      Cottrell, & Sejnowski, 2010). In conjunction with producing
                                                                        the geospatial challenge tasks, the IARPA ICArUS program
   +blending>                                                           has developed metrics for assessing cognitive biases.
          isa layer-choice                                              Anchoring bias or confirmation bias in weighing evidence is
          prior-a 0.45                                                  assessed by a negative entropy metric, N and confirmation
          prior-b 0.15                                                  bias in seeking information is assessed using a task-specific
          prior-c 0.15                                                  confirmation metric, C.
          prior-d 0.25
          layer IMINT                                                   Anchoring bias metric
          utility =utility                                              Negative entropy is defined as
                                                                                           ð‘ = (ð»!"# âˆ’ ð»)/ð»!"#
   This retrieval will partially match against the experience           where H is the entropy of the distribution of probabilities
chunks above, and will blend across the stored utilities for            over hypotheses and Hmax is the maximum possible entropy.
all experienced IMINT outcomes (i.e., both government and               N increases with the certainty in a hypothesis (i.e., the
military building experiences in the past) to produce a kind            â€œpeakinessâ€ of the distribution). At a given stage of
of â€œexpectedâ€ utility to match the =utility request.                    updating belief probabilities [A%, B%, C%, D%] given
                                                                        some new INT evidence, we may assess the negative
Hypothesis Probability Updating                                         entropy, NACT-R, of the belief probabilities in ACT-R, and
Lebiere (1999) proposed a model of cognitive arithmetic                 the negative entropy of the rational model, NRational. If NACT-R
that used retrieval of arithmetic facts to generate estimates           > NRational then the ACT-R model is exhibiting a
of answers without explicit computations. The cognitive                 confirmation bias in weighing evidence â€“ i.e., over-
arithmetic model uses partial matching to retrieve facts                weighting evidence that confirms the most likely
related to the problem, and uses the blending mechanism to              hypothesis. Conversely, if NACT-R < NRational then the ACT-R
merge them together to issue an aggregate estimated answer.             model is exhibiting the anchoring bias.
The model reproduced a number of characteristics of the
distribution of errors in elementary school children,                   Confirmation bias metric
including both table and non-table errors, error gradients              Confirmation bias in seeking evidence, is assessed by the
around the correct answer, higher correct percentage for tie            fraction, C, of SIGINT choices requested about the
                                                                    2171

insurgent group that has been assigned highest probability                         4. Note that the number of alternative choices varies within
of being the attackers.                                                            a task: The task begins with seven alternatives (IMINT,
      ð‘ð‘œ. ð‘œð‘“ Â ð‘†ð¼ðºð¼ð‘ð‘‡ Â ð‘â„Žð‘œð‘–ð‘ð‘’ð‘  Â ð‘œð‘› Â ð‘¡â„Žð‘’ Â â„Žð‘–ð‘”â„Žð‘’ð‘ ð‘¡ Â ð‘ƒð‘Ÿð‘œð‘. ð‘”ð‘Ÿð‘œð‘¢ð‘ Â                      MOVINT, SOCINT, and four SIGINTs) available, and
ð¶=                                                                                 depending on the selection of the layer, the alternatives
                  ð‘‡ð‘œð‘¡ð‘Žð‘™ Â ð‘›ð‘œ. ð‘œð‘“ Â ð‘†ð¼ðºð¼ð‘ð‘‡ Â ð‘â„Žð‘œð‘–ð‘ð‘’ð‘ 
  SIGINT provides considerable weight when â€œchatterâ€ is                            decrease within each trial.
detected, so selection of SIGINT for the highest probability
group is interpreted as being confirmatory. It is assumed                               Table 2: The results of the confirmation bias in seeking
that if C > .5 then the model exhibits confirmation bias in                                          evidence for both models.
seeking evidence (random choice strategy be C = .25).
                                                                                                                       SIGINT on the                   Total No. of
                                                                                                                                                                          Fraction
                            Results and Discussion                                                                   highest prob. group                SIGINT
Each model was used to simulate 30,000 layer selections in                         ACT-R Model                               6,191                         9,044            .68
10,000 tasks. By using metrics that we explained in the
previous section, we could identify that the ACT-R model
exhibits anchoring and confirmation biases while                                                                                       Rational Rank
conducting the task.
                                                                                                          6000
Anchoring bias in weighing evidence
                                                                                                          5000
In the geospatial task, the ACT-R model revises its
probability distribution over hypotheses after each layer                                                 4000
selection, and this can be compared against the probability
                                                                                              Frequency   3000
distribution of the rational model. As can be seen in figure
3, the ACT-R model is most often showing lower negative                                                   2000
entropy than the rational model (NACT-R < NRational). In other
words, rather than showing a confirmation bias it is                                                      1000
exhibiting a form of anchoring bias.
                                                                                                          0
                                                                                                                 1       2         3         4         5     6        7
                                        All Layer Selections
                                                                                                                                           Rank
                     7000
                     6000
                                                                                         Figure 4: Frequency of the ACT-R model selecting the
                                                                                       rational choice of Rank n (Rank 1 is the optimal choice).
                     5000
                     4000
                                                                                      Table 3 shows a confusion matrix that indicates the
         Frequency
                                                                                   proportion of times the ACT-R model makes the same
                     3000                                                          choice as the rational model. Although the ACT-R model
                     2000
                                                                                   agrees with the rational model at a level well above chance,
                                                                                   it often differs from the rational. The rational model
                     1000                                                          scarcely selects SOCINT layer (3 times among 30000),
                     0
                                                                                   because the expected information gain for SOCINT is
                                 -0.5               0.0                   0.5
                                                                                   relatively low.
                                 Model NegEntropy - Rational NegEntropy
                                                                                          Table 3: Confusion matrix of the ACT-R model and
                                                                                                  rational model for layer selection.
  Figure 3: Difference negative entropy between the ACT-
  R model and rational model after each layer selections.                                                                                        Rational Choice
Confirmation bias in seeking evidence                                                                                     IMINT           MOVINT           SIGINT         SOCINT
                                                                                                 IMINT                       75%             15%              4%           0%
We analyzed the fraction of SIGINT choices for which the
model requests SIGINT on the group with the highest                                ACT-R        MOVINT                       18%             79%              4%           66%
probability. The result of the fraction for the ACT-R model                        Choice             SIGINT                 4%                  3%          91%           0%
is presented in table 2. The fraction of the model is greater                                       SOCINT                   3%                  3%           1%           33%
than .5, so the ACT-R model is exhibiting confirmation bias
in seeking evidence according to the C metric.                                       Note that there is some interaction between the anchoring
   We also analyzed how the INT layers selected by the                             bias in evidence weighing and any biases that might emerge
ACT-R model compared to the rational choice based on the                           in choosing layers. If the ACT-R models (or participants)
expected information gain. The result is presented in figure                       under-weight evidence and believe in a â€œless peakyâ€
                                                                                2172

probability distribution over hypotheses, then that can affect     Heuer Jr, R. J. (1999). Psychology of intelligence analysis:
how far they believe that the current state or next state is         Center for the Study of Intelligence, Central Intelligence
from the goal, or how much more uncertainty can be                   Agency (Washington, DC).
reduced by a given layer choice. Biases in beliefs about the       Heuer, R. J. (1999). Psychology of Intelligence Analysis.
current situation will impact evidence-gathering choices.            Washington, D.C.: Center for the Study of Intelligence.
   The ACT-R model exhibits confirmation bias when                 Klayman, J. (1995). Varieties of confirmation bias.
evaluated against the ICArUS task-specific norm, C, which            Psychology of learning and motivation, 32, 385-418.
measures the propensity to use SIGINT to confirm the               Klayman, J., & Ha, Y. W. (1987). Confirmation,
strongest current hypothesis. However, the selection of INT          disconfirmation, and information in hypothesis testing.
layers is generally highly consistent with the rational norm         Psychological review, 94(2), 211-228.
of seeking evidence that will produce the highest expected         Klein, G. (1998). Sources of power: How people make
information gain. This illustrates how the notion of â€œbiasâ€ is       decisions. Cambridge, MA: MIT Press.
dependent on the choice of norm, and how such norms do             Klein, G., Moon, B., & Hoffman, R. R. (2006a). Making
not always agree, especially in the case of â€œconfirmation            sense of sensemaking 1: Alternative perspectives. IEEE
biasâ€ (Jonathan D. Nelson, 2005). It has been shown                  Intelligent Systems, 21(4), 70-73.
(Austerweil & Griffiths, 2011) that confirmatory strategies        Klein, G., Moon, B., & Hoffman, R. R. (2006b). Making
are rational for a large class of tasks and people appear to         sense of sensemaking 2: A macrocognitive model. IEEE
approximate choices based on expected information gain.              Intelligent Systems, 21(5), 88-92.
                                                                   Lebiere, C. (1999). The dynamics of cognition: An ACT-R
                    Acknowledgments                                  model of cognitive arithmetic. Kognitionswissenschaft, 8,
This work is supported by the Intelligence Advanced                  5-19.
Research Projects Activity (IARPA) via Department of the           Miller, G. A. (1956). The magical number seven plus or
Interior (DOI) contract number D10PC20021. The U.S.                  minus two: Some limits on our capacity for processing
Government is authorized to reproduce and distribute                 information. Psychological Review, 63, 81-97.
reprints for Governmental purposes notwithstanding any             Nelson, J. D. (2005). Finding Useful Questions: On
copyright annotation thereon. The views and conclusions              Bayesian Diagnosticity, Probability, Impact, and
contained hereon are those of the authors and should not be          Information Gain. Psychological Review, 112(4), 979-
interpreted as necessarily representing the official policies        999. doi: 10.1037/0033-295x.112.4.979
or endorsements, either expressed or implied, of IARPA,            Nelson, J. D., McKenzie, C. R. M., Cottrell, G. W., &
DOI, or the U.S. Government.                                         Sejnowski, T. J. (2010). Experience Matters.
                                                                     Psychological science, 21(7), 960-969.
                                                                   Nickerson, R. S. (1998). Confirmation bias: A ubiquitous
                         References                                  phenomenon in many guises. Review of General
Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S.,            Psychology, 2(2), 175.
   Lebiere, C., & Qin, Y. (2004). An integrated theory of the      Pirolli, P., & Card, S. K. (2005). The sensemaking process
   mind. Psychological Review, 111(4), 1036-1060.                    and leverage points for analyst technology. Paper
Anderson, J. R., & Lebiere, C. (1998). The atomic                    presented at the 2005 International Conference on
   components of thought. Mahwah, NJ: Erlbaum.                       Intelligence Analysis, McLean, VA.
Austerweil, J. L., & Griffiths, T. L. (2011). Seeking              Russell, D. M., Stefik, M. J., Pirolli, P., & Card, S. K.
   confirmation is rational for deterministic hypotheses.            (1993). The cost structure of sensemaking. Paper
   Cognitive Science, 55(3), 499-526.                                presented at the INTERCHI '93 Conference on Human
Cheikes, B. A., Brown, M. J., Lehner, P. E., & Adelman, L.           Factors in Computing Systems, Amsterdam.
   (2004). Confirmation bias in complex analyses MITRE             Simon, H. A. (1974). How big is a chunk? Science, 183,
   Center for Integrated Intelligence Systems. Bedford: MA:          482-488.
   MITRE.                                                          Tolcott, M. A., Marvin, F. F., & Lehner, P. E. (1989).
Chorev, M. (1996). Surprise Attack. The Case of the Yom-             Expert decision-making in evolving situations. IEEE
   Kippur War. Fort McNair: WA: The industrial College of            Transactions on Systems, Man and Cybernetics, , 19(3),
   the Armed Forces.                                                 606-615.
Convertino, G., Billman, D., Pirolli, P., Massar, J., &            Tversky, A., & Kahneman, D. (1974). Judgment under
   Shrager, J. (2008). The CACHE Study: Group Effects in             uncertainty: Heuristics and biases. Science, 185, 1124-
   Computer-Supported Collaborative Analysis. Computer               1131.
   Supported Cooperative Work (CSCW), 17(4), 353-393.              Wason, P. C. (1960). On the failure to eliminate hypotheses
Gonzalez, C., Lerch, J. F., & Lebiere, C. (2003). Instance-          in a conceptual task. Quarterly journal of experimental
   based learning in dynamic decision making. Cognitive              psychology, 12(3), 129-140.
   Science, 27, 591-635.                                           Wickens, C. D., & Hollands, J. G. (2000). Engineering
Grabo, C. M., & Goldman, J. (2004). Anticipating surprise:           psychology and human performance (3rd ed.). Prentice-
   Analysis for strategic warning. Washington, D.C.: Joint           Hall: Upper Saddle River, NJ.
   Military Inelligence College.
                                                               2173

