UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Viewing and performing actions can change what you see
Permalink
https://escholarship.org/uc/item/9tc9x8c2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Dils, Alexia Toskos
Flusberg, Stephen
Boroditsky, Lera
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                        Viewing and performing actions can change what you see
                                           Alexia Toskos Dils (atoskos@stanford.edu)
                                            Stephen J. Flusberg (sflus@stanford.edu)
                                               Lera Boroditsky (lera@stanford.edu)
                                            Stanford University, Department of Psychology
                                Jordan Hall, 450 Serra Mall, Building 420, Stanford, CA 94305 USA
                             Abstract                                  participants made a left or right-handed button press to
Previous research has demonstrated a tight link between object
                                                                       indicate whether an image of an object on the screen was
perception and action: viewing an object primes the action             upright or inverted. The objects were chosen to have a clear
needed to interact with it, while priming an action can affect the     right or left-handed affordance (e.g., a frying pan with a
speed and accuracy with which we perceive the object.                  handle oriented to the left affords a left-handed grasp).
However, it is not yet known whether motor information can             Participants responded faster and made fewer errors when
qualitatively change what object we actually perceive. We              their responding hand was congruent with the (task-
investigated this issue by having participants view or perform an      irrelevant) affordance of the object on the screen.
action before viewing an ambiguous object. Results showed
that viewing an action (a picture of a hand displaying a power or         Additional work has found that the relationship between
precision grasp) biased participants to interpret the ambiguous        motor actions and object perception is functional and not
object as congruent with the action prime (Experiments 1 and           merely epiphenomenal. For example, Borghi et al. (2007)
2). Conversely, performing an action (moving small or large            found that participants were faster to respond a picture of an
balls from one tray to another) biased participants to interpret       object when it was preceded by a picture of a hand
the object as incongruent with the motor action. Together, these       displaying an action that was congruent with the object.
results suggest viewing and performing actions can actually
                                                                       The authors concluded that visually priming an action
change what we see.
                                                                       facilitates object recognition (see also Helbig et al., 2006,
Keywords: Object perception; Action; Embodiment
                                                                       Witt & Brockmole, in press). This suggests that preventing
                                                                       someone from engaging in an action should impair object
                          Background                                   recognition in a parallel fashion. Indeed, Witt et al. (2010)
Can our actions influence how we perceive the world and                showed that participants were slower and less accurate when
affect the very contents of our visual awareness? Though               responding to a picture of a tool if the handle in the picture
perception and action have traditionally been studied                  was oriented towards the participant’s hand that was busy
independently in the cognitive sciences, in our everyday               squeezing a rubber ball.
experience of the world they are dynamically linked. For                  Taken together, these studies suggest that motor
example, many of the objects we look at are also the objects           information can play a significant role in object perception
we grasp and manipulate. More generally, our movements                 by affecting the speed and accuracy with which we perceive
and actions in the environment alter what perceptual                   an object. However, it is unclear just how deeply motor
information we have access to, and these changes in                    information can penetrate into our visual perception of
perceptual stimulation consequently influence how we                   objects. For instance, can viewing or performing a
traverse our surroundings and what actions we choose to                particular action qualitatively affect this perceptual process
take. For reasons such as these, ecologically orientated               and change what object we actually see?
psychologists have argued that we perceive the world in                   We investigated this possibility across three experiments.
terms of how it affords action (Gibson, 1979).                         In Experiments 1 and 2, participants first viewed an image
   In recent years, researchers have gathered evidence in              of a hand depicting a particular action (one of two specific
support of this view, showing tight links between perception           grasp types). They then saw an image of an ambiguous
and action across a wide range of cognitive and behavioral             object and had to indicate what they perceived it to be.
tasks (e.g., Witt & Proffitt, 2005; Bhalla & Proffitt, 1999;           Participants were biased to interpret the object as congruent
Witt, Proffitt, & Epstein, 2004). Other researchers have               with the action prime.
examined the role that motor actions play in object                       What cognitive mechanisms might underlie this effect?
perception (e.g., Borghi et al., 2007; Bub et al., 2008; Chao          One possibility is that viewing the hand action prime led
& Martin, 2000; Helbig, Graf, & Kiefer, 2006; Tucker &                 participants to imagine or simulate performing that action
Ellis, 1998, 2001; Witt & Brockmole, in press; Witt,                   themselves (Parsons, 1987; Rizzolatti & Craighero, 2004).
Kemmerer, Linkenauger, & Culham, 2010). For example,                   Then, when they viewed the ambiguous image, participants
Tucker and Ellis conducted a series of studies to test                 saw the object they were prepared to interact with because
whether people automatically generate a motor                          of this active motor state (Hommel et al., 2001). On this
representation in response to the visual presentation of an            view, perceived events and planned actions share a common
object, even when there is no intention to act on the object           representational medium to the extent that they share
(Tucker & Ellis, 1998; 2001).               In one experiment,         common (abstract) features. Alternatively, this effect may
                                                                   2451

have simply been a result of purely visual or semantic
priming due to the association between certain grasp types               One of the four hand images was randomly selected for
and certain objects.                                                  each participant and displayed on the screen for three
   To distinguish these possibilities, in Experiment 3                seconds. Next, the ambiguous object drawing was displayed
participants engaged in an actual manual motor action                 at 56% the size of the hand for three seconds. The left/right
(moving small or large balls from one tray to another) while          orientation of the drawing was counterbalanced across
naming pictures displayed on a computer screen, including             participants. After this, participants were asked to identify
the ambiguous object used in Experiment 2. A visual                   the object in the line drawing that they had just seen. They
priming account would predict that performing an action               were then asked to identify whether the hand they had seen
should have no effect on this task as long as participants            was a left or right hand. Finally, they were asked if they had
cannot see their own hands as they engage in the action. A            any additional interpretation of the object and indicated
semantic priming account would predict that no matter how             whether they were left-handed, right-handed, or
the action concept is activated (e.g. viewing an action,              ambidextrous.
talking about an action, performing an action), the results
should yield the same facilitation effect observed in                 Results
Experiments 1-2. Conversely, the common coding approach               The data from 179 participants were removed from analysis
would predict that performing an action should actually               because they failed to respond to the test questions
interfere with a participant’s ability to perceive an action-         appropriately (e.g., did not provide an interpretation of the
congruent object, which will therefore lead them to perceive          ambiguous object), because they took the survey more than
an action-incongruent object (Hommel et al., 2001). In this           once, or because they responded incorrectly to the question
study, participants were actually biased to interpret the             of whether the hand prime they saw was a left or right hand.
object as incongruent with the motor action they performed.           This last question was used as manipulation check to ensure
This suggests that viewing and performing actions are                 that participants were looking at and paying attention to the
supported by the same underlying representations.                     experimental stimuli.
                                                                         Testing for effects of grasp type. For the remaining 636
                        Experiment 1                                  participants, we coded their initial ambiguous object
Can viewing an action change what object we see?                      interpretation as congruent if it matched the hand prime they
                                                                      saw (i.e., power grasp hand and flashlight interpretation or
Methods                                                               precision grasp hand and bolt/screw interpretation).
Participants 815 individuals were recruited to participate in         Responses were coded as incongruent if they did not match
this study through the amazon.com Mechanical Turk                     the hand prime (i.e., power grasp hand and bolt/screw
website in exchange for payment.                                      interpretation or precision grasp hand and flashlight
                                                                      interpretation).      19 participants came up with both
Stimuli & Procedure The stimuli for this experiment                   interpretations for the ambiguous object and were therefore
consisted of four photographs of hands and an ambiguous               removed from further analysis.
object line drawing created by the authors (Figure 1). The               Of the 617 participants in this final set of data, nearly
four hand photographs showed either left or right hands in            61% (N=374) gave congruent responses, while 39%
either a power or precision grasp. Pilot testing suggested            (N=243) gave incongruent responses (Figure 2). A chi-
that the ambiguous object could be interpreted as an object           square goodness of fit test revealed that this difference was
that afforded a power grasp (flashlight) or as an object that         highly significant, χ2 = 27.4, p < 0.0001.
afforded a precision grasp (screw/bolt). The drawing could
also be interpreted as an object that afforded a right-handed
functional grasp (e.g., the flashlight as oriented in Figure 1)
or as an object that afforded a left-handed functional grasp
(e.g., the screw/bolt as oriented in Figure 1).
                                                                         Figure 2. Results from Experiment 1, showing proportion of
                                                                          congruent and incongruent object interpretations. Error bars
                                                                                 represent the standard error of the proportion.
  Figure 1. In Experiment 1, participants viewed one of the four         One possible explanation for these results is that our study
 hand images on the left, and then viewed the ambiguous object on     design was transparent and therefore our participants simply
                              the right.
                                                                  2452

told us what they thought we wanted to hear. If our results                        perception. In Experiment 1, we also tested whether
were caused by this demand characteristic, then participants                       priming an action with a right or left hand, irrespective of
presumably perceived both interpretations for the                                  whether it displayed a power or precision grasp, would
ambiguous object and selected the interpretation they                              influence whether people perceived a leftward or rightward-
believed would make us happy. We tried to account for this                         facing object. We also reasoned that action simulations
possibility by asking participants if they had any additional                      might be constrained by the idiosyncrasies of an
interpretation of the object as one of our follow-up                               individual’s own motor system, so we tested whether the
questions. In fact, 126 of our 617 participants provided                           handedness of each participant, irrespective of the action
additional interpretations of the object.                     Among the            prime, caused them to see a leftward or rightward-facing
remaining 490 participants who only perceived one object                           object. In our task, neither the laterality of the action prime
interpretation, the results mirrored our previous analysis:                        nor the handedness of the participant affected what the
nearly 61% (N=297) gave congruent responses, while 39%                             ambiguous object appeared to be.
(N=193) gave incongruent responses. A chi-square                                      Why might the type of grasp displayed by a hand affect
goodness of fit test revealed that this difference was highly                      object perception, but not the laterality of the grasp or
significant, χ2 = 21.7, p < 0.0001.                                                handedness of the participant? Perhaps some features of
   Testing for effects of orientation. We also asked whether                       actions become privileged over others because they are
the laterality of the action prime or participants’ own                            more reliably associated with specific objects. Whether an
handedness biased perception of the ambiguous object. To                           object requires a power or precision grasp, for example,
test these possibilities, participants’ interpretations were                       depends largely on the object’s size, and for artifacts like
coded as leftward if they saw the object whose handle (i.e.,                       flashlights and bolts, size is relatively constant across
the head of the “bolt” or the barrel of the “flashlight”)                          instances. The hand we use to grasp these objects, however,
pointed to the left, and rightward if they saw the object                          varies considerably depending on what we intend to do with
whose handle pointed to the right. Neither the laterality of                       the object and what else our hands are busy doing. By
the action prime (51% congruent, N=249; 49% incongruent,                           pitting various features of manual action against one
N=241; χ2 = 0.1, p > 0.5), nor the handedness of the                               another, we might have limited the likelihood that weaker
participant (51% congruent, N=238; 49% incongruent,                                effects of laterality and handedness would materialize.
N=237; χ2 < 0.01, p > 0.5), predicted whether subjects made                        Exploring this possibility with objects that are ambiguous
a leftward or rightward interpretation of the object.                              on one dimension only is the subject of future work.
                                                                                      It is also worth noting that the object we used in
Discussion                                                                         Experiment 1 was a tool under all possible interpretations,
                                                                                   which might further limit our ability to generalize the effects
In this experiment we asked whether viewing an action
                                                                                   of viewing actions to all graspable objects. Would the
would influence what participants saw when they looked at
                                                                                   patterns we found in Experiment 1 with the flashlight/bolt
an ambiguous object. We found that when participants were
                                                                                   image extend to graspable objects whose primary
primed with a hand displaying a power grasp they were
                                                                                   affordance is related to eating and not grasping (e.g., fruit)?
more likely to interpret an ambiguous drawing as an object
                                                                                   Furthermore, the flashlight/bolt image remains an abstract,
that required a power grasp (flashlight). Conversely, when
                                                                                   ambiguous, unrealistic line drawing. Would a photorealistic
they were primed with a hand displaying a precision grasp,
                                                                                   image in which the ambiguity of the object was less obvious
they were more likely to interpret the drawing as an object
                                                                                   show similar effects from viewing actions? To test these
that required a precision grasp (screw/bolt). These results
                                                                                   possibilities, we replicated this study in Experiment 2 using
remained even after we removed participants who provided
                                                                                   a photorealistic image of an object that could either be seen
multiple interpretations of the ambiguous object, which
                                                                                   as an apple or a cherry.
helps to rule out an explanation based on demand
characteristics. These findings suggest that viewing an
action can qualitatively affect our perception of an object.1                                             Experiment 2
   However, manual actions are complex, and grasp type is                          In Experiment 1 we found that viewing an action influenced
just one dimension out of many that might affect object                            what participants saw when they looked at an ambiguous
                                                                                   object. However, it remains unclear whether these results
1
                                                                                   will generalize to more realistic-looking objects that are not
  The results of Experiment 1 replicate a pilot version of this study reported
                                                                                   in the tool category. To address this issue, we created a new
at an earlier meeting of the Cognitive Science Society conference
(Flusberg, Toskos Dils, & Boroditsky, 2010). Though the main effect in             ambiguous object, the photorealistic image depicted in
that study was nearly the same as in Experiment 1, the nature of the               Figure 3 that can be interpreted as an apple (power grasp
ambiguous object we used (a line drawing that could be perceived as a              affordance) or a cherry (precision grasp affordance). We
football or a nut) limited how we could interpret the results. First, this
                                                                                   then replicated Experiment 1 using this new object.
object elicited much more varied interpretations than the stimuli used in the
present set of studies, suggesting that it may have been perceived as an
extremely abstract figure rather than a concrete object. Second, a greater         Methods
proportion of participants had multiple interpretations of the object than we
see in the present study.
                                                                               2453

Participants 353 individuals were recruited to participate in         demonstrate that viewing an action can qualitatively change
this study through the amazon.com Mechanical Turk                     how people perceive an object.
website in exchange for payment.
Stimuli & Procedure The stimuli and procedure for this
experiment were identical to Experiment 1, with the
exception of the ambiguous object, which was the
cherry/apple picture depicted in Figure 3 presented at 29%
the size of the hand.
                                                                         Figure 4. Results from Experiment 2, showing proportion of
                                                                         congruent and incongruent object interpretations. Error bars
                                                                                represent the standard error of the proportion.
                                                                        What cognitive mechanisms might underlie this effect?
 Figure 3. The ambiguous object created for Experiment 2. It can
    be interpreted as an apple, which affords a power grasp, or a
                                                                      One possibility is that the hand action prime led participants
               cherry, which affords a precision grasp.               to simulate performing that action themselves (Parsons,
                                                                      1987; Rizzolatti & Craighero, 2004). Then, when shown the
Results                                                               ambiguous image, participants saw the object they were
                                                                      prepared to interact with because of this active motor state
The data from 22 participants were removed from analysis
                                                                      (Hommel et al., 2001). On this view, perceived events and
because they failed to respond to the test questions
                                                                      planned actions share a common representational medium to
appropriately, because they took the survey more than once,
                                                                      the extent that they share common (abstract) features.
or because they responded incorrectly to the question of
                                                                      Alternatively, this effect may have simply been a result of
whether the hand prime they saw was a left or right hand.
                                                                      visual or semantic priming due to associations between
For the remaining 335 participants, we coded their initial
                                                                      grasp types and objects. Importantly, these accounts make
ambiguous object interpretation in the same way we did in
                                                                      three distinct predictions about how performing an action
Experiment 1. Four participants came up with both
                                                                      when participants cannot see their hands should affect
interpretations for the ambiguous object and were therefore
                                                                      object perception. A visual priming account would predict
removed from further analysis.
                                                                      that performing an action should have no effect on this task
   Of the 331 participants in this final set of data, 58%
                                                                      as long as participants cannot see their own hands as they
(N=192) gave congruent responses, while 42% (N=139)
                                                                      engage in the action. A semantic priming account would
gave incongruent responses (Figure 4). A chi-square
                                                                      predict that no matter how the action concept is activated
goodness of fit test revealed that this difference was highly
                                                                      (e.g. viewing an action, talking about an action, performing
significant, χ2 = 8.16, p < 0.005. Once again, we used
                                                                      an action), the results should yield the same facilitation
responses to our follow-up question to help rule out a                effect observed in Experiments 1-2. Conversely, the
demand characteristic account of these results. 110                   common coding approach would predict that performing an
participants provided additional interpretations of the object.       action should actually interfere with a participant’s ability to
Among the remaining 221 participants who only perceived               perceive an action-congruent object, which will therefore
one object interpretation, the results mirrored our previous          lead them to perceive an action-incongruent object
analysis. Nearly 62% (N=136) gave congruent responses,                (Hommel et al., 2001). Experiment 3 was designed to
while 38% (N=85) gave incongruent responses. A chi-                   differentiate among these possibilities by having
square goodness of fit test revealed that this difference was         participants perform a manual motor action while they
highly significant, χ2 = 11.32, p < 0.001. The pattern of             observed the ambiguous object used in Experiment 2.
results produced by the cherry/apple in Experiment 2 did
not differ reliably from the pattern produced by the
                                                                                             Experiment 3
flashlight/bolt from Experiment 1, χ2 = 0.03, p > 0.5.
                                                                      Can performing an action change what you see in the same
Discussion                                                            way that observing an action does?
The results of Experiment 2 replicated what we found in
Experiment 1 using a photorealistic ambiguous object that
was in a very different category from the tool image used in
the previous study. Taken together, these experiments
                                                                  2454

Methods                                                                object used in Experiment 2. The pictures were presented in
Participants 102 individuals were recruited to participate in          the same order for all participants.
this experiment from the Stanford community in exchange
for course credit or five dollars.                                     Results
                                                                       The results from 2 participants were removed because they
Stimuli & Procedure When participants entered the lab,                 failed to complete the experimental task (i.e., they did not
they were told they would be partaking in a study of                   name every picture that appeared on the screen).
multitasking. They were then seated at a desk and                          For the remaining 100 participants, we coded their
positioned with their head in a chin rest facing a computer            response to the final picture (the ambiguous cherry/apple) as
screen (Apple iMac, 20” monitor). At this point they were              congruent if it matched the action they were performing
given detailed instructions for how to proceed in the task.            (moving tennis balls and said apple, or moving bouncy balls
    The motor action participants performed consisted of               and said cherry), and incongruent if it did not match the
picking up and moving balls located in a tray underneath the           action they were performing (moving tennis balls and said
desk they were seated at (Figure 5). Participants picked up            cherry, or moving bouncy balls and said apple). 21
one ball in each hand from the lower tray and moved them               participants said both cherry and apple and were therefore
simultaneously to the upper tray whenever they heard a beep            removed from further analysis.
coming from the computer. The apparatus was designed so                    Of the 79 participants in this final set of data, 33%
that balls placed in the upper tray would fall back down into          (N=26) gave congruent responses, while 67% (N=53) gave
the lower tray. Importantly, with their heads in the chinrest,         incongruent responses (Figure 6). A chi-square goodness of
participants could not see this action as they performed it.           fit test revealed that this difference was highly significant,
Half of the participants were randomly assigned to pick up             χ2 = 8.56, p < 0.005. This pattern differed reliably from the
tennis balls, which require a power grasp action, while the            patterns observed in Experiment 1, (χ2 = 20.87, p < 0.0001),
remaining participants picked up small bouncy balls, which             and Experiment 2, χ2 = 18.06, p < 0.0001.
require a precision grasp action.
                                                                           Figure 6. Results from Experiment 3, showing proportion of
                                                                           congruent and incongruent object interpretations. Error bars
                                                                                  represent the standard error of the proportion.
                                                                       Discussion
   Figure 5. The laboratory setup used for Experiment 3. Half of
                                                                       In this experiment we asked whether performing an action
participants moved bouncy balls in each hand (upper-right) while
the remaining participants moved tennis balls in each hand (lower-     would influence what participants saw when they looked at
right).                                                                an ambiguous object. We found that when participants
                                                                       engaged in power grasp action (moving tennis balls in each
    When the experiment began, the screen was black. A                 hand), they were biased to perceive an ambiguous object
beep was played every 1.25 seconds, and each time it played            that was incongruent with that action (i.e., a cherry, which
participants engaged in the ball moving action. After 12.5             affords a precision grasp). Similarly, when they engaged in
seconds, pictures started appearing on the screen one by               precision grasp action (moving small bouncy balls in each
one, each one remaining on the screen for 2 seconds, with              hand), they were also biased to perceive an ambiguous
an inter-stimulus interval of 500 milliseconds. While these            object that was incongruent with that action (an apple,
pictures were appearing, the beeps kept playing at a rate of           which affords a power grasp).
one every 1.25 seconds (twice per image).                                 Therefore, it seems that performing an action can change
    Participants were instructed to name aloud the image on            what people see when they look at an ambiguous object, and
the screen as quickly as possible. There were 12 images in             the direction of the effect suggests that it arises from
all, and the first 11 depicted objects or scenes that did not          overlapping representations between perception and action.
afford a particular manual grasp action (e.g., beach, house,           Indeed, as predicted by the common coding account (and
etc.). The final image was the ambiguous cherry/apple                  not by visual or semantic priming mechanisms), the specific
                                                                       pattern of results in Experiment 3 shows the opposite
                                                                   2455

pattern from what we observed in Experiments 1 and 2                                         References
(when participants simply observed an action). In those
                                                                    Bhalla, M. & Proffitt, D. R. (1999). Visual-motor
experiments, viewing an action resulted in a priming effect,
                                                                      recalibration in geographical slant perception. JEP:
such that participants were biased to perceive an object that
                                                                      Human Perception and Performance, 25, 1076-1096.
was congruent with the action they observed.                 In
                                                                    Borghi, A.M., Bonfiglioli, C., Lugli, L, Ricciardelli, P.,
Experiment 3, on the other hand, performing an action
                                                                      Rubichi, S., Nicoletti, R. (2007). Are visual stimuli
resulted in an interference effect, such that participants were
                                                                      sufficient to evoke motor information? Studies with hand
biased to perceive an object that was incongruent with the
                                                                      primes. Neuroscience Letters, 411(1), 17-21.
action they were engaged in.
                                                                    Bub, D. N., Masson, M. E. J., & Cree, G. S. (2008).
   However, there is one key difference between the
                                                                      Evocation of functional and volumetric gestural
experiments that may also have contributed to these
                                                                      knowledge by objects and words. Cognition, 106, 27-58.
divergent results. While participants in Experiments 1 and 2
                                                                    Cattaneo, L., Barchiesi, G., Tabarelli, D., Arfeller, C., Sato,
only observed a single visual hand prime, participants in
                                                                      M. & Glenberg, A.M. (2011). One’s motor performance
Experiment 3 engaged in a repetitive series of manual
                                                                      predictably modulates the understanding of others’
actions, moving balls from one tray to another 34 times.
                                                                      actions through adaptation of premotor visuo-motor
Behavioral repetition of this sort has been known to cause
                                                                      neurons. Social Cognitive & Affective Neuroscience,
adaptation effects such that performance on a subsequent
                                                                      6(3), 301-310.
task is biased in the opposite direction of repeated behavior
                                                                    Chao, L. L. & Martin, A. (2000) Representation of
(e.g., Cattaneo et al., 2011). We are currently working on a
                                                                        manipulable man-made objects in the dorsal stream.
new series of laboratory studies designed to tease apart the
                                                                        Neuroimage, 12, 478-484.
different possible mechanisms that may underlie the
                                                                    Flusberg., S. J., Toskos Dils, A., & Boroditsky, L. (2010).
divergent patterns of results observed in these experiments.
                                                                      Motor affordances in object perception. In S. Ohlsson &
                                                                      R. Catrambone (Eds.), Proceedings of the 32nd Annual
                   General Discussion                                 Conference of the Cognitive Science Society (pp. 2105-
We began this paper by asking whether viewing or                      2110). Austin, TX: Cognitive Science Society.
performing an action could qualitatively affect how people          Gibson, J. J. (1979). The ecological approach to visual
perceive an object. That is, does our current motor state             perception. Lawrence Earlbaum: Hillsdale, NJ.
change how we see the world?                                        Helbig, H. B., Graf, M., & Kiefer, M. (2006). The role of
   In Experiments 1 and 2, participants first viewed an action        action representations in visual object recognition,
hand prime and then viewed an ambiguous object. They                  Experimental Brain Research, 107(2), 221-228.
were biased to perceive the object as congruent with the            Hommel, B., Müsseler, J., Aschersleben, G., & Prinz, W.
preceding hand image. When the hand prime displayed a                 (2001). The theory of event coding (TEC): A framework
power grasp, participants were more likely to see an object           for perception and action planning. Behavioral and Brain
that afforded such a grasp, like a flashlight or an apple.            Sciences, 24, 840-937.
When the hand prime displayed a precision grasp,                    Parsons, L. M. (1987). Imagined spatial transformation of
participants were more likely to see a bolt or cherry, which          one’s body. JEP: General, 19, 178-241.
afford the same grasp type. In Experiment 3, participants           Rizzolatti, G. & Craighero, L. (2004). The mirror-neuron
performed a manual motor action while they interpreted the            system. Annual Reviews Neuroscience, 27, 169-192.
ambiguous object. When they were picking up tennis balls,           Tucker, M. & Ellis, R. (1998). On the relations between
which afford a power grasp, they were more likely to see an           seen objects and components of potential actions. JEP:
object that afforded a precision grasp (i.e., cherry).                Human Perception and Performance, 24(3), 830-846.
Similarly, when they were picking up small bouncy balls,            Tucker, M. & Ellis, R. (2001). The potentiation of grasp
which afford a precision grasp, they were more likely to see          types during visual object categorization. Visual
an object that afforded a power grasp (i.e., apple).                  Cognition, 8(6), 769-800.
   These results demonstrate that viewing or performing an          Witt, J. K., & Brockmole, J. R. (in press). Action alters
action can in fact qualitatively change what an object is             object identification: Wielding a gun increases the bias to
perceived to be, and the pattern of results across                    see guns. JEP: Human Perception and Peformance.
experiments suggests that this shift is subserved by shared         Witt, J. K., Kemmerer, D., Linkenauger, S. A., & Culham,
representations between perception and action.                        J. (2010). A functional role for motor simulation in
                                                                      naming tools. Psychological Science, 21, 1215-1219.
                    Acknowledgments                                 Witt, J. K. & Proffitt, D. R. (2005). See the ball, hit the ball;
The authors would like to thank Laura Malkiewich for                  Apparent ball size is correlated with batting average.
creating our cherple stimulus and help with earlier versions          Psychological Science, 16, 937-939.
of these studies. We would also like to thank all members           Witt, J.K., Proffitt, D.R., & Epstein, W. (2004). Perceiving
of the Cognation Lab. This research was supported by a                distance: A role of effort and intent. Perception, 33, 577-
McDonnell scholars grant & NSF BCS #1058119 to LB.                    590.
                                                                2456

