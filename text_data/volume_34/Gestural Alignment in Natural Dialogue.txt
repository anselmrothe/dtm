UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Gestural Alignment in Natural Dialogue
Permalink
https://escholarship.org/uc/item/73z0q063
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Bergmann, Kirsten
Kopp, Stefan
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                        Gestural Alignment in Natural Dialogue
                                     Kirsten Bergmann (kirsten.bergmann@uni-bielefeld.de)
                                             Stefan Kopp (skopp@techfak.uni-bielefeld.de)
                      Faculty of Technology, Center of Excellence “Cognitive Interaction Technology” (CITEC)
                                Collaborative Research Center “Alignment in Communication” (SFB 673)
                                   Bielefeld University, P.O. Box 100 131, D-33501 Bielefeld, Germany
                               Abstract                                     other, e.g., in posture, body movements like foot shaking,
                                                                            mannerism, or facial expressions (cf. Chartrand and Bargh
   A well-known phenomenon in natural interaction is that speak-
   ers adapt their linguistic and nonverbal behaviors. Research on          (1999); Lakin and Chartrand (2003)). This kind of mimicry
   gestural alignment is, however, still in its early stages based          is assumed to be largely non-conscious and automatic, being
   on evidence from experimental settings. This paper provides a            mediated by perception-action links that involve the own mo-
   first systematic study of gesture form convergence based on a
   large sample of naturalistic dialogue data. We found evidence            tor system in the perception of others actions (Dijksterhuis
   for gestural alignment, but not all form features of co-speech           & Bargh, 2001). Only recently, researchers have started to
   gestures are subject to this effect. In a detailed analysis of those     look at whether speakers also align in their co-speech ges-
   sensitive features we further address questions of how gestural
   alignment depends on the temporal distance between gestures,             tures, i.e., the spontaneous and meaningful hand movements
   and whether intra-speaker or inter-speaker influences on ges-            that accompany speech. Such gestures stand out as they are
   ture form are stronger.                                                  very closely linked to the speech they accompany, in both
   Keywords: Alignment, co-speech gestures, natural interaction             content and timing (McNeill, 1992). Investigating whether
                                                                            speakers align in and via their gestures can thus help, first, to
                           Introduction                                     understand what shapes these gestures and, second, to shed
Co-speech gesturing is an integral part of human communi-                   light on the role of interpersonal coordination in dialogical
cation, but it is not well understood why and how gestures                  communication.
take on their particular physical form. This holds especially               "Uhm, a u-shaped building"                               "Okay"
for iconic gestures that apparently communicate by virtue of
iconicity, i.e., through a correspondence between their form
and geometrical or spatial properties of what they refer to.
Empirical studies, however, revealed that similarity with the
referent cannot fully account for all occurrences of iconic
gesture use (Kopp, Tepper, Ferriman, Striegnitz, & Cassell,
2007). Findings also indicate that a gesture’s form is in-
fluenced by other contextual constraints such as discourse                  Figure 1: Example of alignment of two successive gestures
(Holler & Stevens, 2007) or the linguistic context (Kita &                  (left: router’s assertion; right: follower’s acknowledgement).
Özyürek, 2003). In addition there are considerable differ-
ences in how speakers gesture, partly assumed to be due to                     In this paper we present results from the first large-scale
different cognitive abilities (Hostetter & Alibali, 2007).                  investigation of gestural alignment in natural dialogue. Fig. 1
   In addition to intra-speaker sensitivities, co-speech gestur-            shows an example, in which some properties of the first
ing in dialogue may also be influenced by the gestures of                   gesture (left) are being mimicked (e.g., handshape, trajec-
the interlocutor. A large body of work has demonstrated                     tory) while others are not (e.g. relative movement direction).
inter-personal sensitivities in verbal and nonverbal behavior               This suggests a feature-based, multi-level analysis of gestural
in natural social interaction, leading often to coordination                alignment. We will thereby focus on the form-based aspects
and alignment between interlocutors (cf. (Kopp, 2010)). For                 of gestural alignment here. In the next section we review the
example, linguistic coordination has been reported with re-                 few existing studies that have looked at occurrences of form
spect to words, phrase structures, speech rate, tones of voice,             convergence in co-speech gestures, so far. Then we present
speech rhythms, etc. (cf. Chartrand, Maddux, and Lakin                      the corpus data and the approach taken to investigate the phe-
(2005); Branigan, Pickering, Pearson, and McLean (2010)).                   nomenon of gestural alignment in it, and present results of
Pickering and Garrod (2004) ascribed this linguistic align-                 three analyses meant to answer the following questions: (1)
ment largely to an automatic priming of interlocutors lexical,              Is there gestural alignment, compared against a baseline, and
syntactic, or semantic representations and a percolation of ac-             are there differences between different form features of a ges-
tivation between adjacent representational levels. Others, e.g.             ture? (2) What is stronger, the influence of the interlocutor’s
(Brennan & Clark, 1996), suggested that speakers strategi-                  gestures or of one’s own previous gesturing? (3) How does
cally design utterances for an addressee and thereby prefer                 gestural alignment depend on (temporal) distance between
previously used (grounded) constructions. Regarding nonver-                 the gestures? Finally, we discuss our findings in light of these
bal behavior, interactants can likewise be found to mimic each              questions and draw conclusions.
                                                                        1326

                        Related Work                                                        Present Study
                                                                     We have conducted statistical analyses on a large data cor-
Based on initial evidence by Kimbara (2006), who reported            pus of spontaneous speech and gesture in dialogue (SaGA
a couple of examples of gesture form convergence among in-           corpus (Lücking, Bergmann, Hahn, Kopp, & Rieser, 2010)).
terlocutors, some recent studies addressed the phenomena of          With these analyses we aimed for a systematic investigation
gestural alignment (in this context often termed ‘mimicry’)          of gesture form convergence going beyond previous studies
more deeply. Parrill and Kimbara (2006) investigated the             in several respects. First of all, our corpus provides a detailed
question to what extent observing mimicry affects people’s           coding of the gestures’ physical form including handshapes,
behavior. They found that participants who observed mimicry          palm and finger orientation, wrist movement, and position.
in a video-recorded interaction were subsequently more likely        This allows for addressing the degree to which single ges-
to reproduce the mimicked behavior in their own descriptions,        ture form features are sensitive to influences of an interlocu-
whereby a gesture was assessed as a reproduction if it corre-        tor’s gestures, instead of considering the “same overall form”
sponded with the stimulus gesture in handshape, motion and           (Holler & Wilkin, 2011), one particular form feature only
location.                                                            (Kimbara, 2008), or the sum of several form features (Parrill
                                                                     & Kimbara, 2006). Second, some of the above mentioned
   In a similar setting, Mol, Krahmer, Maes, and Swerts              experimental studies manipulated the visibility between in-
(2012) provided evidence for the alignment of handshapes             teractants to create a baseline for gestural alignment occur-
in co-speech gestures: Participants who saw a speaker in a           ring by chance. Investigating natural dialogues allows for an
video stimulus using gestures with a particular handshape            alternative baseline by creating artificial dialogues, as previ-
were more likely to produce gestures with these handshapes           ously done in corpus analyses of linguistic alignment (Howes
later on, while retelling the story. This evidence is, however,      et al., 2010); for details see sect. ‘Control Data’. Third, a
limited to a particular kind of gestures (‘path gestures’ in         characterizing feature for alignment in speech corpora is that
directions), distinguishing between two different handshape          the repetition probability is increased immediately after the
classes (index finger extended vs. more than one finger ex-          prime and decreases toward the global mean with greater dis-
tended). Mol et al. further addressed the role of meaning            tances between prime and target (Reitter, 2008). A corpus
in this context. They found that gesture forms were only re-         analysis on extended dialogue allows to address this issue for
peated across speakers if they had occurred in a meaningful          gestural alignment, too. Fourth, we are able to investigate
context as expressed in concurrent speech. It is concluded           the contingencies involved in gestural alignment. Pickering
that gesture form adaptation resembles adaptation in speech,         and Garrod (2004) suggested to treat alignment not only as an
rather than it being an instance of automated motor mimicry.         inter-subjective phenomenon (‘other-alignment’), but also in-
   Kimbara (2008) studied triadic interaction with two co-           tra-subjectively (‘self-alignment’). Given the fact that the use
narrators providing a joint narration to a third person, while       of co-speech gestures is subject to major inter-individual dif-
manipulating the mutual visibility between co-narrators.             ferences (Hostetter & Alibali, 2007), the relationship between
Greater convergence in one gesture form feature (handshape)          self- and other-alignment is important to assess the strength
was found when participants could see each other. However,           of inter-speaker gesture form convergence. Finally, the above
in this setting the two narrators were required to provide a co-     mentioned studies have in common that they are limited to
herent description for the recipient which might enhance the         gestural alignment in repeated references to the same refer-
likability for gesture form convergence. Holler and Wilkin           ent. Analyzing a large data sample allows to study the degree
(2011) showed that gesture mimicry also occurs in face-to-           of gesture adaptation on a level of gesture form beyond the
face dialogue. In repeated references to the same figure-like        connection to specific referent objects, allowing to delineate
stimuli, participants were found to be more likely to use simi-      grounding and mere motor resonances. In the following, we
lar gestures when they could see each other (vs. a non-visible       will briefly describe the corpus and explain how we framed
condition). Holler & Wilkin concluded that gestures seem to          the problem of detecting and measuring alignment between
play an active role in the process of grounding, because the         gestures occurring in dialogue.
vast majority of mimicked gestures occurred in phrases de-
voted to the presentation or acceptance of information.
                                                                     Data Corpus The SaGA corpus consists of 25 dyads (21
   In sum, existing studies lend considerable evidence that a        female, 29 male participants) engaged in a spatial commu-
speaker’s gesture use is influenced by others’ gestures. How-        nication task combining direction-giving and sight descrip-
ever, this quantitative empirical evidence is limited to exper-      tion. This task required participants to convey the shape of
imental settings with video-based stimuli or elicited repeated       objects and the spatial relations between them. The stimu-
references–an caveat often put forward against studies in lin-       lus was an artificial town presented in a Virtual Reality en-
guistic alignment (cf. Howes, Healey, and Purver (2010)).            vironment, affording experimental control for the content of
To date, there is no analysis of gestural alignment based on a       speaker messages. After taking a “bus ride” through the town,
large sample of naturalistic dialogue data. The present study        a router explained the route to an unknown and naı̈ve fol-
aims to close this gap.                                              lower. In total, the SaGA corpus consists of 280 minutes of
                                                                 1327

video material containing 4449 iconic/deictic gestures. All                            Control Data A common problem in studies on behavioral
dialogues are completely and systematically annotated based                            coordination is to lay down a baseline of how much coordi-
on an annotation grid, tested and refined using multi-coder                            nation can occur simply by chance, regardless of any contin-
agreement tests; for details see Lücking et al. (2010). Each                          gencies between primes and targets. Adopting the approach
gesture is demarcated by the beginning and end of the expres-                          of Howes et al. (2010) in their corpus analyses of lexical and
sive, so-called ‘stroke’ phase. The gesture’s form during the                          syntactic alignment in speech, we created ‘fake’ dialogues
stroke phase, as far as relevant here, is annotated in terms of                        by re-combining the gestures of two speakers from originally
the following distinct form features: (1) H ANDEDNESS: one-                            different dialogues. This is done in an interleaved fashion,
handed (either left- or right-handed), or two-handed gestures;                         i.e., the whole sequence of gestures produced by one par-
(2) H ANDSHAPE: ASL-based coding of hand configurations                                ticular direction-giver is kept, but merged with the complete
like ASL-B, ASL-C, etc. + modifiers (e.g. bent, loose); (3)                            gesture sequence produced by a different direction-follower.
PALM - AND F INGER O RIENTATION: up, down, sideways,                                   This way we created 25 control dialogues with randomly cho-
towards body, away + combinations and sequences; and (4)                               sen participants while respectively maintaining the partici-
W RIST M OVEMENT T YPE: static, linear, or curved + se-                                pants’ role (direction giver vs. direction follower). As a mat-
quences. A further important and characterizing feature of an                          ter of course, although the total number of gestures remains
iconic gesture is the more general R EPRESENTATION T ECH -                             the same, this results in a different number of prime-target
NIQUE (e.g. Kendon (2004)). For the spatial domain of the                              pairs in the control data set with regard to CONTINGENCY
SaGA dialogues, the following set of techniques proved to                              TYPE: 16523 self-pairs and 2407 other-pairs.
be adequate: indexing, placing (as if putting a virtual object
somewhere), shaping (as if sculpting a 3D shape), drawing (as
if sketching a 2D outline), and posturing (using the hand/arm                          Metric Considering gestural alignment necessitates to de-
as a model for something).                                                             fine a metric estimating the similarity between prime and tar-
                                                                                       get gesture. Since we want to be able to assess alignment
                                                                                       even at the level of single features of a gesture, we define a
Prime-target Pairs From 4449 iconic/deictic gestures in                                metric for each particular gesture feature. To make results
the SaGA corpus, a total of 17130 prime-target pairs1 were                             comparable with each other, we employ a binary metric for
extracted. Figure 2 exemplifies the possible alignment-                                all variables: it scores 1 if prime and target gesture are identi-
relevant influences between different prime-target pairs that                          cal in a particular gesture feature, and 0 otherwise. For some
can occur in dialogue. Each of these pairs is characterized by                         features this definition can be applied straightforwardly (e.g.
a distance D IST between prime and target gesture, taken to                            H ANDEDNESS: one-handed vs. two-handed), for others it is
be the number of other gesture occurrences in-between plus                             reasonable to allow some minor variation between prime and
1. Each prime-target pair is further characterized by a CON -                          target gesture. Palm and finger orientation, for instance, are
TINGENCY TYPE : whether prime and target gestures are pro-                             coded as combinations of five basic values (up, down, side-
duced by the same speaker (‘self-pair’) or by different speak-                         ways, towards, away). That is, a palm orientation of ‘down’
ers (‘other-pair’), respectively. In the SaGA corpus there are                         and an orientation of ‘down/away’ would count as a mis-
17362 self-pairs and 3993 other-pairs.                                                 match although the actual difference in palm orientation is
                                                                                       45◦ which can be regarded a slight deviation given the natu-
                                                                                       ral fuzziness of human gesture use. Accordingly, the binary
                 G1
                                               Self                                    metric is applied to the gesture features as follows, whereby
  Speaker A                                       Dist=3             G4
                    F1...Fn                                             F1...Fn        for features which allow sequential coding the final segment
                     Other
                                              Other
                                                  Dist=2              Other
                                                                                       of the prime’s value and the first segment of the target’s value
                            Dist=1                                          Dist=1     are considered:
  Speaker B                        G2                      G3
                                      F1...Fn                 F1...Fn
                                               Self
                                                    Dist=1
                                                                                       • R EPRESENTATION T ECHNIQUE and H ANDEDNESS: A
                                                                                          score of 1 is given only if the values for prime and target
Figure 2: Possible alignment influences between gestures:                                 gesture are identical, 0 otherwise.
Speaker A produces two gestures (G1, G4), while speaker B
makes two gestures (G2, G3) in-between. Gestures are char-                             • H ANDSHAPE: Any modifiers of ASL handshapes like
acterized by features (F1 . . . Fn ) and can influence each other                         ‘spread’ or ‘loose’ are omitted, i.e. ‘ASL-B-spread’ and
both within a speaker (‘self’) and across speakers (‘other’),                             ‘ASL-B-loose-spread’ both fall into the basic category
where the relation’s distance (D IST) is determined by the oc-                            ‘ASL-B’. A score of 1 is given only if prime and target are
currences of gestures in-between.                                                         identical in this basic category for both hands, 0 otherwise.
                                                                                       • PALM AND F INGER O RIENTATION: A score of 1 is given
    1 We  employ the term ‘prime-target pair’ in lack of a better one.                    if prime and target match in at least one part of the annota-
This is not to imply that alignment is due to priming.                                    tion value for both hands, 0 otherwise.
                                                                                   1328

• W RIST M OVEMENT T YPE: A score of 1 is given if prime              like (G1,G2). The total number of pairs amounts to N=4317
   and target are identical or – in case of a two-handed gesture      (3738 self-pairs, and 579 other-pairs). Again we employ a
   with different movement types – if the value for one hand          one-way analysis of variance, exact means and standard de-
   is identical with the other gesture’s value, 0 otherwise.          viations are given in Table 2.
                                                                          For all variables under consideration the analysis reveals
                                                                      significant main effects: R EPRESENTATION T ECHNIQUE
                             Results
                                                                      (F(1,4315) = 25.05, p < .001), H ANDSHAPE (F(1,4315) = 51.86,
Is there gestural alignment in dialogue? This analysis                p < .001), H ANDEDNESS (F(1,4315) = 39.38, p < .001),
aims to show whether gesture use in real dialogues shows              PALM O RIENTATION (F(1,4315) = 67.95, p < .001). These
reliably more other-alignment than would occur by chance.             effects are due to the fact that mean similarity of prime and
To this end, we compare similarity scores in real vs. control         target are higher for self-pairs than in other-pairs. That is, the
dialogues for each gesture feature with a one-way analysis            alignment between gestures is reliably stronger within speak-
of variance for each of the gesture features. We only con-            ers than it is across speakers.
sider prime-target pairs with D IST=1 here, since it is more
likely that alignment occurs in consecutive gestures than in
more distant pairs. With regard to Figure 2 this means that           Table 2: Mean similarity of gesture features for self- and
we take prime-target pairs like (G1,G2) or (G3,G4) into ac-           other-speaker pairs (standard deviations in parentheses).
count (N=950 pairs; 579 from the original data, and 371 from                                        Self              Other
control dialogues). Exact means and standard deviations are              Representation Technique   .41 (.49)         .31 (.46)
                                                                         Handedness                 .79 (.40)         .68 (.46)
given in Table 1.                                                        Handshape                  .53 (.50)         .37 (.48)
                                                                         Palm Orientation           .67 (.47)         .49 (.50)
   For R EPRESENTATION T ECHNIQUE (F(1,948) = 24.61, p <
.001), H ANDSHAPE (F(1,948) = 17.92, p < .001), and PALM
O RIENTATION (F(1,948) = 6.65, p = .01), there is a reliable
difference between the two groups such that the mean simi-            Effect of temporal distance on other-alignment? To elu-
larity in control dialogues is significantly lower than in real       cidate how gestural alignment is affected by temporal dis-
dialogues. For H ANDEDNESS (F(1,948) = 3.47, p = .063) the            tance, we analyze how the similarity score depends on the
analysis marginally fails to reach significance, but by trend         distance between prime and target gestures. For this analysis
the mean similarity in control dialogues is significantly lower       we consider other-pairs of distance 1-4. In Figure 2 examples
than in real dialogues. For F INGER O RIENTATION (F(1,948) =          of other-pairs with D IST=1 would be (G1,G2) or (G3,G4),
.16, p = .69) and W RIST M OVEMENT T YPE (F(1,948) = .06,             examples of an other-pair with D IST=2 are (1,3) or (2,4). We
p = .94) the analysis shows no significant main effect be-            employ a one-way analysis of variance for the dependent vari-
tween real and control data.                                          able S IMILARITY and the independent variable D IST. A to-
   This means that there exists other-alignment in gesture use,       tal of 3081 primed-target pairs is analyzed (N(D IST=1)=579,
but not all gesture features are subject to this effect. Only for     N(D IST=2)=758, N(D IST=3)=843, N(D IST=4)=901).
the features R EPRESENTATION T ECHNIQUE, H ANDSHAPE,                      For R EPRESENTATION T ECHNIQUE there is a main ef-
PALM O RIENTATION, and H ANDEDNESS the mean similar-                  fect of DIST and similarity score F(3,3077) = 6.22, p < .001):
ity of prime and target is higher as to be expected by chance.        the similarity score is smaller the greater the distance be-
We continue with these features to a finer analysis.                  tween prime and target. This is due to significant differ-
                                                                      ences between prime-target pairs with DIST=1 and others
Table 1: Mean similarity of gesture features for real and con-        (D IST=2: t(1335) = 1.96, p = .05; DIST=3: t(1420) = 2.51,
trol dialogues (standard deviations in parentheses).                  p = .012; DIST=4: t(1478) = 4.30, p < .001), as well as be-
                                                                      tween distances 2 and 4 (t(1657) = 2.40, p = .017). Like-
                              Real               Control              wise, for H ANDSHAPE the similarity scores decrease signif-
  Representation Technique    .31 (.37)          .16 (.46)
  Handedness                  .68 (.47)          .62 (.49)            icantly with increasing distance between prime and target
  Handshape                   .37 (.48)          .24 (.43)
  Palm Orientation            .49 (.50)          .41 (.50)            DIST (F(3,3077) = 7.10, p < .001). This is due to the fact
  Finger Orientation          .61 (.49)          .60 (.49)            that the similarity of prime-target pairs with DIST=1 is higher
  Wrist Movement Type         .40 (.49)          .40 (.49)
                                                                      than for prime-target pairs with higher distances (DIST=2:
                                                                      t(1335) = 2.63, p = .09; DIST=3: t(1420) = 3.37, p = .001;
                                                                      DIST =4: t(1478) = 4.51, p < .001). In contrast, for H ANDED -
Self- vs.         Other-Alignment? To compare the effects             NESS (F(3,3077) = .045, p = .99), and PALM O RIENTATION
of self- and other-alignment, we now investigate the dif-             (F(3,3077) = .41, p = .75) there is no main effect of distance
ference between prime-target pairs in the same speaker                between prime and target gesture.
(C ONTINGENCY T YPE = ’self’) vs. prime-target pairs with                 That is, the more gestures occur between prime and target,
different speakers (C ONTINGENCY T YPE = ’other’). We                 the smaller is their similarity with respect to R EPRESENTA -
only consider adjacent prime-target pairs with D IST=1 (for           TION T ECHNIQUE and H ANDSHAPE, which is corroborated
instance, in Figure 2 self-pairs like (G2,G3) with other-pairs        when checking the actual temporal distances in milliseconds.
                                                                  1329

By contrast, the similarity score remains more or less constant         2012). Our results here suggest that those features, like hand-
for the features H ANDEDNESS and PALM O RIENTATION.                     shape, are also more amenable to inter-personal coordination,
                                                                        while the communicatively more significant features tend to
Table 3: Mean similarity for varying distances between prime            be more resistant. This suggests a notion of gestural align-
and target gesture (standard deviations in parentheses).                ment as adaptation within the degrees of freedom available
                                                                        under given communicative constraints.
                            DIST =1   DIST =2   DIST =3   DIST =4
   Representation Technique .31 (.46) .26 (.44) .25 (.43) .21 (.41)         Existing cognitive models of speech and gesture produc-
   Handedness               .68 (.47) .67 (.47) .68 (.47) .67 (.47)     tion lack an account of other-alignment. However, our find-
   Handshape                .37 (.48) .30 (.46) .29 (.45) .26 (.44)
   Palm Orientation         .49 (.50) .49 (.50) .48 (.50) .47 (.50)     ings suggest a row of implications for such models. At first
                                                                        it is important to note that our analysis of gestural alignment
                                                                        at the level of different features supports a view that a ges-
   Together with results from the first analysis that revealed
                                                                        ture is not produced as a whole, but in different steps that can
highest F-scores for the former two features in comparison
                                                                        exert influences over the constitution of different features of
with control data, this provides the following picture: For
                                                                        a gesture. We thus hypothesize that different gesture form
R EPRESENTATION T ECHNIQUE and H ANDSHAPE there is a
                                                                        features are determined at different points in time with other-
strong other-alignment effect which decreases with greater
                                                                        alignment arising potentially from high-level mechanisms in
distances from the prime gesture. For H ANDEDNESS and
                                                                        terms of full grounding, i.e. signaling established links be-
PALM O RIENTATION there is a rather weak difference when
                                                                        tween form and meaning, as well as low-level mechanisms
comparing original and control data and the effect is more
                                                                        of priming or motor resonance (Montgomery, Isenberg, &
or less constant. In other words, there seems to be a general
                                                                        Haxby, 2007). That is, such a model provides (at least) two
(weak) tendency to produce gestures with a certain amount of
                                                                        routes than could mediate alignment. However, our find-
similarity in these two features, but this is not biased by the
                                                                        ing that communicatively significant features are less affected
other’s directly preceding gesture use.
                                                                        by alignment may be a consequence of a hypothesized more
                            Discussion                                  “ego-centric” nature of early, high-level stages of the produc-
                                                                        tion process, which may be more concerned with the neces-
In this paper we reported results from the first fine-grained
                                                                        sary, communicatively intended functions and less with cor-
and systematic analysis of alignment in co-speech (iconic)
                                                                        rective or audience-design functions (Keysar & Henly, 2002).
gesturing in natural direction-giving dyads. What did we
                                                                        Lower-level processes, on the other hand, involve connected
find? First, there is significant gestural alignment in dia-
                                                                        sensory and motor processes which have been shown to be
logue. That is, a speaker’s use of co-speech gestures is af-
                                                                        effective also in gesture (Montgomery et al., 2007) and have
fected by the other’s gestures in the dialogue. Remarkably,
                                                                        often been assumed to mediate interpersonal coordination.
not all gesture features seem to be equally sensitive, with
                                                                        Our empirical findings suggest that the sensorimotor route is
W RIST M OVEMENT and F INGER O RIENTATION being most
                                                                        particularly effective. To further distinguish between the two
resistant. Second, alignment effects are significantly stronger
                                                                        routes, we are concerned with measuring the degree of form
within speakers than across speakers. That is, a speaker’s
                                                                        similarity in relation to referent similarity in ongoing work.
gestures influence each other more than the gestures the inter-
locutor performs, albeit the effectiveness of other-alignment.              Our observation of strong self-alignment effects may be
Third, regarding the relation between the strength of other-            explained by a strong role of internal priming or caching in
alignment and the prime-target distance, a multi-faceted pic-           the cognitive speech-gesture production process. This con-
ture emerges: alignment in handshape or representation tech-            forms hypotheses of self-routinization or expert performance
nique becomes weaker with greater distances, while align-               effects, which state that over repeated encounters with a par-
ment in handedness and palm orientation remain constant.                ticular problem, memory traces build up that directly map
   These findings can shed new light on iconic co-speech ges-           a problem stimulus to a solution (e.g., Logan (1988)). It is
tures, as well as the cognitive processes underlying their pro-         important to note, however, that gesture use also seems to
duction in dialogue. To start with, how can we make sense               be subject to adaptations taking place in extended dialogue
of the heterogeneity of feature-based gestural alignment? A             with repeated references. Such processes have been found,
closer look at the role of gestural representation techniques           e.g., to lead to considerable reduction of the complexity of
might be informative. Each of these techniques is character-            speech and gestures (Hoetjes, Koolen, Goudbeek, Krahmer,
ized by a specific pattern of how meaning is depicted. For ex-          & Swerts, 2011). That is, gestures can become simpler or less
ample, in drawing gestures as in Figure 1 it is the wrist trajec-       precise over repeated uses when referring to the same entity.
tory that conveys most of the intended meaning, while in in-            Further research is needed to elucidate how different mech-
dexing or placing gestures the position of the hands is of ma-          anisms and driving forces (e.g., alignment through repetition
jor importance to convey meaning. That is, some features can            vs. simplification through reduction) compete and interact
be considered more communicatively significant than others.             with each other.
Indeed, variation within the less significant features has also             With all these raised questions, we think that computa-
been reported to reflect individual gesturing style (Bergmann,          tional simulation can provide a valuable tool to test whether
                                                                    1330

different kinds of cognitive mechanisms result in the effects      Kendon, A. (2004). Gesture—visible action as utterance.
we observe empirically. We have developed a computational            Cambridge University Press.
model for speech and gesture production in previous work           Keysar, B., & Henly, A. (2002). Speakers’ overestimation of
(Kopp, Bergmann, & Wachsmuth, 2008). Opening this to the             their effectiveness. Psychological Science, 13, 207–212.
effects of dialogical interaction, e.g. endowing it with per-      Kimbara, I. (2006). On gestural mimicry. Gesture, 6, 39–61.
ceptive abilities, will enable us to complement this empirical     Kimbara, I. (2008). Gesture form convergence in joint de-
work with computational studies.                                     scription. Journal of Nonverbal Behavior, 32, 123–131.
                                                                   Kita, S., & Özyürek, A. (2003). What does cross-linguistic
                    Acknowledgments                                  variation in semantic coordination of speech and gesture
This research is partially supported by the Deutsche                 reveal?: Evidence for an interface representation of spatial
Forschungsgemeinschaft (DFG) in the Collaborative Re-                thinking and speaking. Journal of Memory and Language,
search Center 673 “Alignment in Communication” and the               48, 16–32.
Center of Excellence in “Cognitive Interaction Technology”         Kopp, S. (2010). Social resonance and embodied coordi-
(CITEC).                                                             nation in face-to-face conversation with artificial interlocu-
                                                                     tors. Speech Communication, 52, 587–597.
                          References                               Kopp, S., Bergmann, K., & Wachsmuth, I.                  (2008).
                                                                     Multimodal communication from multimodal thinking—
Bergmann, K. (2012). The production of co-speech iconic              towards an integrated model of speech and gesture produc-
  gestures: Empirical study and computational simulation             tion. Semantic Computing, 2(1), 115–136.
  with virtual agents. PhD Thesis: Bielefeld University.           Kopp, S., Tepper, P., Ferriman, K., Striegnitz, K., & Cassell,
Branigan, H., Pickering, M., Pearson, J., & McLean, J.               J. (2007). Trading spaces: How humans and humanoids use
  (2010). Linguistic alignment between humans and com-               speech and gesture to give directions. In Conversational
  puters. Journal of Pragmatics, 42, 2355—2368.                      informatics (pp. 133–160). New York: John Wiley.
Brennan, S., & Clark, H. (1996). Lexical choice and concep-        Lakin, J., & Chartrand, T. (2003). Using nonconscious be-
  tual pacts in conversation. Journal of Experimental Psy-           havioral mimicry to create affiliation and rapport. Psycho-
  chology, 22(6), 1482—1493.                                         logical Science, 14, 334—339.
Chartrand, T., & Bargh, J. (1999). The chameleon effect: The       Logan, G. D. (1988). Toward an instance theory of automa-
  perception-behavior link and social interaction. Journal of        tization. Psychological Review, 95, 492–527.
  Personality and Social Psychology, 76, 893–910.                  Lücking, A., Bergmann, K., Hahn, F., Kopp, S., & Rieser, H.
Chartrand, T., Maddux, W., & Lakin, J. (2005). Beyond the            (2010). The Bielefeld Speech and Gesture Alignment cor-
  perception-behavior link: The ubiquitous utility and moti-         pus (SaGA). In Proceedings of the LREC 2010 workshop
  vational moderators of unconscious mimicry. In R. Hassin,          on multimodal corpora.
  J. Uleman, & J. Bargh (Eds.), The new unconscious (pp.           McNeill, D. (1992). Hand and mind—What gestures reveal
  334—361). New York: Oxford University Press.                       about thought. Chicago: University of Chicago Press.
Dijksterhuis, A., & Bargh, J. (2001). The perception-              Mol, L., Krahmer, E., Maes, A., & Swerts, M. (2012). Adap-
  behavior expressway: Automatic effects of social percep-           tation in gesture: Converging hands or converging minds?
  tion on social behavior. Advances in Experimental Social           Journal of Memory and Language, 66, 249–264.
  Psychology, 33, 1–40.                                            Montgomery, K., Isenberg, N., & Haxby, J. (2007). Commu-
Hoetjes, M., Koolen, R., Goudbeek, M., Krahmer, E., &                nicative hand gestures and object-directed hand movements
  Swerts, M. (2011). Greebles greeble greeb: On reduc-               activated the mirror neuron system. Social Cognitive and
  tion in speech and gesture in repeated references. In Proc.        Effective Neuroscience, 2(2), 114-122.
  of the 33rd annual conference of the cognitive society.          Parrill, F., & Kimbara, I. (2006). Seeing and hearing dou-
Holler, J., & Stevens, R. (2007). An experimental investi-           ble: The influence of mimicry in speech and gesture on
  gation into the effect of common ground on how speakers            observers. Journal of Nonverbal Behavior, 30, 157–166.
  use gesture and speech to represent size information in ref-     Pickering, M., & Garrod, S. (2004). Toward a mechanistic
  erential communication. Journal of Language and Social             psychology of dialogue. Behavioral and Brain Sciences,
  Psychology, 26, 4–27.                                              27, 169–226.
Holler, J., & Wilkin, K. (2011). Co-speech gesture mimicry         Reitter, D. (2008). Context effects in language production:
  in the process of collaborative referring during face-to-face      Models of syntactic priming in dialogue corpora. PhD The-
  dialogue. Journal of Nonverbal Behavior, 35, 133–153.              sis: University of Edinburgh.
Hostetter, A., & Alibali, M. (2007). Raise your hand if you’re
  spatial—relations between verbal and spatial skills and ges-
  ture production. Gesture, 7, 73–95.
Howes, C., Healey, P., & Purver, M. (2010). Tracking lexical
  and syntactic alignment in conversation. In Proc. of the
  32nd annual conference of the cognitive science society.
                                                               1331

