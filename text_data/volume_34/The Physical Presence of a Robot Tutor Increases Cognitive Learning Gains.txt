UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Physical Presence of a Robot Tutor Increases Cognitive Learning Gains
Permalink
https://escholarship.org/uc/item/7ck0p200
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Leyzberg, Daniel
Spaulding, Samuel
Toneva, Mariya
et al.
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                     The Physical Presence of a Robot Tutor
                                         Increases Cognitive Learning Gains
                                          Daniel Leyzberg (daniel.leyzberg@yale.edu)
                                        Samuel Spaulding (samuel.spaulding@yale.edu)
                                            Mariya Toneva (mariya.toneva@yale.edu)
                                                Brian Scassellati (scaz@cs.yale.edu)
                                           Department of Computer Science, Yale University
                                              51 Prospect St., New Haven, CT 06511, USA
                              Abstract                                  and a simulated on-screen robot-like character. Tapus, Tapus,
                                                                        and Mataric (2009) found that individuals suffering from cog-
   We present the results of a 100 participant study on the role
   of a robot’s physical presence in a robot tutoring task. Partic-     nitive impairment and/or Alzheimer’s disease reported being
   ipants were asked to solve a set of puzzles while being pro-         more engaged with a robot treatment than a similar on-screen
   vided occasional gameplay advice by a robot tutor. Each par-         agent treatment.
   ticipant was assigned one of five conditions: (1) no advice,
   (2) robot providing randomized advice, (3) voice of the robot           Kiesler, Powers, Fussell, and Torrey (2008) used task-
   providing personalized advice, (4) video representation of the       performance measures to find that participants who received
   robot providing personalized advice, or (5) physically-present       health advice from a physically-present robot were more
   robot providing personalized advice. We assess the tutor’s ef-
   fectiveness by the time it takes participants to complete the        likely to choose a healthy snack than participants who re-
   puzzles. Participants in the robot providing personalized ad-        ceived the same information in robot-video or on-screen
   vice group solved most puzzles faster on average and improved        agent conditions. In Bainbridge, Hart, Kim, and Scassellati
   their same-puzzle solving time significantly more than partic-
   ipants in any other group. Our study is the first to assess the      (2008), a physically-present robot yielded significantly more
   effect of the physical presence of a robot in an automated tu-       compliance to its commands than a video representation of
   toring interaction. We conclude that physical embodiment can         the same robot.
   produce measurable learning gains.
                                                                           No previous work has investigated whether learning out-
   Keywords: Robotics; Computer Science; Tutoring
                                                                        comes are affected by a robot’s physical presence. The closest
                                                                        related work is in Intelligent Tutoring Systems (ITSś), which
                          Introduction                                  are educational computer programs that produce individual-
What kinds of human-robot interactions benefit from the                 ized lessons, advice, and questions usually in a workbook-
physical embodiment of a robot? For human-robot interac-                style or quiz-style environment (Nkambou, Bourdeau, &
tions that require manipulating the physical world, a physical          Psyché, 2010). A parallel notion of embodiment called
robot is a necessity, but for those interactions where physi-           “the persona effect” exists in ITS research. (See Dehn and
cal embodiment is optional, when is an embodied robot more              Van Mulken (2000) for an overview.) The persona effect is
useful than an on-screen agent?                                         the impact, if any, that an on-screen character has on students
   In this study, we explore the differences in task perfor-            using an ITS. The majority of research on the persona ef-
mance of participants engaged in a cognitive learning task in           fect has shown no significant learning gains produced by on-
which a robot acts as a tutor. Participants were asked to play          screen agents, although many studies note that students find
a puzzle game while receiving strategy advice from either: a            an ITS with an on-screen more engaging than one without
physically-present robot, a video of the same robot, its disem-         (Moundridou & Virvou, 2002).
bodied voice, a robot giving randomized advice, or no agent                Our study is the first to assess the effect of the physical
at all. We use the resulting data to draw conclusions about the         presence of a robot in an automated tutoring interaction. We
effect of embodiment in robot tutoring tasks.                           use the task-performance measure of puzzle solving time in
   Previous work has investigated the social influence of a             this work as well as several self-report measures.
robot’s embodiment. Does a robot engender more trust,
more compliance, more engagement, or more motivation by                                         Methodology
its physical presence, more so than an on-screen agent or
a video representation of a robot would? Such questions                 Participants
have been explored via two methodologies: self-report mea-              There were 100 participants in this study, between 18 and 40
sures and task-performance measures. Using self-report mea-             years of age. The study was conducted in New Haven, Con-
sures, Kidd and Breazeal (2004) found that a physically-                necticut. Most participants were undergraduate and graduate
present robot was perceived as more enjoyable, more cred-               students of Yale University. Each participant was assigned
ible, and more informative than an on-screen character in a             to one of five groups: (1) no lessons, (2) randomized lessons
block-moving task. In Wainer, Feil-Seifer, Shell, and Mataric           from a physically-present robot, (3) personalized lessons from
(2007), an embodied robot was rated as more attentive and               a disembodied voice, (4) personalized lessons from a video
more helpful than both a video representation of the robot              representation of the robot, and (5) personalized lessons from
                                                                    1882

                      (a) Sample nonogram puzzle, blank.                       (b) Sample nonogram puzzle, solved.
Figure 1: A sample nonogram puzzle. The objective of nonograms is, starting with a blank board (see left figure), to find a
pattern of shaded boxes on the board such that the number of consecutively shaded boxes in each row and column appear as
specified, in length and order, by the numbers that are printed to the left of each row and above each column (see right figure).
For a more detailed explanation see the Domain section.
a physically-present robot. There were approximately 20 par-         specified, in length and order, by the numbers that are printed
ticipants in each group. Exclusion criteria for participants         to the left of each row and above each column. (See Figures
were lack of English fluency or prior academic experience            1(a) and 1(b) for a sample puzzle and solution.) For instance,
with robotics or artificial intelligence.                            a row marked as “4 2” must have 4 adjacent shaded boxes,
                                                                     followed by 2 adjacent shaded boxes—in that order, with no
Apparatus                                                            other boxes shaded, and with at least one empty box between
In this experiment, participants were asked to solve a series        the sets of adjacent shaded boxes. We refer to these contigu-
of logic puzzles. In the four experimental conditions with a         ous sets of shaded boxes as “stretches” in this paper. For
tutor, the tutor interrupted participants several times per puz-     instance, the row described above requires two stretches, one
zle to deliver puzzle-solving strategy lessons. The lessons          of length 4, the other of length 2. One solves the puzzle when
themselves were pre-recorded audio and synchronized visual           one finds a pattern of blank and shaded boxes such that all of
aids, between 21 and 47 seconds in length, that explained and        the requirements for each row and column are satisfied.
gave examples of the use of a single puzzle-solving strategy.           In a typical puzzle, one cannot solve many rows or columns
In the experimental conditions with personalized lessons, the        independently. One must infer the contents of parts of rows
order of the lessons was determined by a skill assessment al-        or columns and use previous inferences as the basis of sub-
gorithm that identified skills in which participants were weak;      sequent inferences. To that end, when a player has reasoned
see the Skills & Lessons section. In the randomized lessons          that in some box or boxes there should not be shading, they
condition, the tutor chose a random lesson among the same            can mark such boxes with an ‘X’ for reference.
ones used in the personalized lessons conditions, such that it          We created a full-screen nonograms computer program that
was immediately applicable to the current state of the game-         participants used via mouse and keyboard. The user interface
board. We compare the puzzle solving time performance be-            provided a timer and a count of how many lessons (called
tween participants in these groups to evaluate the effect of the     “hints” in the interface) the participant had received and how
robot’s physical presence on the effectiveness of the tutoring.      many they would receive; see Figure 2.
Domain To minimize the influence of prior experience, we                Participants were asked to play four puzzles on ten-by-ten
chose a test domain to which participants likely had little pre-     grids with a time limit of fifteen minutes per puzzle. The puz-
vious exposure: a grid-based fill-in-the-blanks puzzle game          zles themselves were the same across all participants. The
called “nonograms” (or “nonogram puzzles”) that resemble             fourth puzzle used the same board as the first, although dis-
crossword puzzles or Sudoku. Nonogram puzzles are a diffi-           guised in the fourth puzzle by rotating the board 90◦ (such
cult cognitive task, one that requires several layers of logical     that the column stretch requirements were swapped with row
inferences to complete. Solving a nonogram puzzle of arbi-           stretch requirements). This means that the first puzzle and the
trary size is an NP-complete problem (Nagao, Ueda, Ueda,             last puzzle are of the exact same difficulty and require knowl-
Sato, & Watanabe, 1996), meaning that no efficient computa-          edge of the exact same set of skills to solve. This manipu-
tional solution is known.                                            lation enables us to make within-subjects comparisons about
   The objective of nonograms is, starting with a blank board,       the extent to which each participant improved their skills over
to shade in boxes on the board such that the number of con-          the course of their participation in the study. There was no in-
secutively shaded boxes in each row and column appear as             dication that any participant was aware of this manipulation.
                                                                 1883

 (a) Experiment apparatus in the no lessons   (b) Experiment apparatus in the personal-     (c) Experiment apparatus in the random-
 condition and the personalized lessons       ized lessons from a video representation of   ized lessons from a physically-present robot
 from a disembodied voice condition.          the robot condition.                          condition and the personalized lessons
                                                                                            from an embodied robot condition.
                                            Figure 2: Experiment apparatus by condition.
Skills & Lessons In the four conditions with lessons, the tu-           (of 100). The user interface displayed the number of lessons
tor interrupted the participant three times per puzzle, paused          remaining for each puzzle at all times.
the puzzle, and delivered a short lesson about nonograms.                  In the personalized lesson conditions the lessons were cho-
The lessons ranged from 21 seconds to 47 seconds in length              sen based on a skill assessment algorithm. For each skill,
and consisted of a voice recording and a set of animations              a weighted sum was calculated internally consisting of: (1)
presented on screen during the lesson as well as a set of coor-         the number of recent demonstrations of that skill (weighted
dinated robot motions specific to each lesson.                          positively) and (2) the number of recent gameboard states
    When beginning a lesson the tutor would turn to face the            in which a skill could have been applied but no action was
participant (in the video and physically-present robot condi-           taken (weighted negatively). These assessments were up-
tions) and say “I have an idea that might help you,” or “Here’s         dated for each skill separately throughout the game, and the
another hint for you.” During the lesson, the tutor bounced             skill with the lowest assessment that was applicable to the
subtly and looked back at the screen whenever, in the course            current gameboard was the skill for which a lesson was se-
of the lesson, it would make reference to the example pre-              lected. In this way, participants in the personalized lesson
sented on screen. For instance, when in the audio of the les-           conditions received lessons based on their individual perfor-
son the robot would say “Like in this example...” or “As you            mance on the puzzles.
see here...,” the robot would turn briefly to the screen and then          Alternatively, in the randomized lesson condition, lessons
back to the participant.                                                were chosen among the same ten lessons at random each time,
    Ten nonogram puzzle-solving skills were identified based            such that the lesson chosen could be applied to the current
on the subjective experience of the authors; they are not uni-          state of the gameboard. This ensures that although the lessons
versally identified skills or rules for nonograms. Each skill is        were randomized, they would provide actionable information
a set of row or column states in which one can logically fill in        every time.
some of the remaining empty boxes. For example, a stretch of            Robot The robot we used, Keepon, is a small yellow
length 9 can fit in a blank row or column of 10 boxes in only           snowman-shaped robot; see Figure 2(c). Keepon has previ-
two ways. Either it fills the first box and 8 more, or it fills         ously been used as an emotive non-threatening communica-
those same middle 8 boxes and the last box. In either case,             tion tool (Kozima, Nakagawa, & Yasuda, 2005; Leyzberg,
the middle 8 boxes are shaded. One of the ten skills in this            Avrunin, Liu, & Scassellati, 2011).
experiment is that, for an empty row or column with just one               The robot operated in one of three modes. First, it refereed
stretch requirement of n where n > 5, the middle (2n − 10)              the puzzle game: it welcomed participants when they started,
boxes are shaded. See Figure 3 for examples and explana-                told them when they had finished or when they had run out of
tions of this skill and two others.                                     time, and told them when the experiment was over. Second, it
    There was one recorded lesson for each skill. Three lessons         “observed” the board during gameplay: the robot frequently
were delivered per puzzle, for each of four puzzles. The num-           turned its head to face the location of the mouse cursor. Third,
ber of lessons was constant for all participants regardless of          it delivered short gameplay lessons three times per puzzle: it
how long they needed to finish the puzzle. Lessons were trig-           “spoke” to the participant by turning to face him or her and
gered either when a participant made no moves for 45 seconds            “bouncing” its body subtly while playing one of several pre-
or as he or she filled the 25th , 50th or 75th box on the board         recorded spoken messages. If a lesson needed to be repeated,
                                                                   1884

the robot would first apologize for repeating itself (i.e., “I’m
sorry to repeat this hint but I think it might help.”).
   To simplify the potential perception problems inherent in
real-world measurements, the robot in this study received per-
fect knowledge of the state of the game. We did not use a
robotic vision system to detect state changes.                               (a) In this row, there must be one long stretch. By the
                                                                             process of elimination one can infer that this stretch must
Procedure                                                                    occupy at least the middle six boxes, no matter where in
Participants were first asked to watch a five-minute instruc-                the row it is placed.
tional video and read a two-page instruction manual describ-
ing the rules of nonograms and how to use the computer in-
terface. In the video and in the text, participants were encour-
aged to use logical reasoning to make moves in the puzzle
rather than making moves by guessing. Potential questions
about the rules of the puzzle game were answered by the ex-
perimenter after the instructions.                                           (b) In this row, the first box is already shaded. Given
   During the experiment, participants were alone in a room                  that, and that the first stretch must be 3 boxes long, one
                                                                             can infer that the first three boxes must be shaded and the
with the computer, the robot in conditions including the robot,              fourth must be crossed out.
and a video camera positioned behind them; see Figure 2.
Participants would choose when they were ready to start each
new puzzle; each round would end either when the partici-
pant solved the puzzle or when fifteen minutes had elapsed,
whichever happened first.
   After the conclusion of the final puzzle, participants were
asked to complete a survey consisting of five Likert-scale
                                                                            (c) In this row, there is only one short stretch and some
questions with open-ended follow-up questions for each. The                 boxes are already shaded. One can infer that regardless
questions were designed to assess whether the lessons were                  of where that one stretch is placed, it cannot occupy the
helpful, clear, and influential, as well as the user’s perceptions          first two or the last two boxes in that row.
of the robot. We asked participants to rate: how relevant the
                                                                       Figure 3: Examples of nonograms skills. Displayed are the
lessons were, how much the lessons influenced their game-
                                                                       contents of a row before and after each skill is applied. Al-
play, how well participants understood the lessons, and how
                                                                       though only rows are shown here, all nonograms skills apply
“smart/intelligent” and “distracting/annoying” they perceived
                                                                       to columns as well.
the robot to be.
                            Results                                    mean solving time in the robot group (M = 7.6 minutes, SD =
This study investigates the role of physical embodiment in a           3.1) is significantly better than in the video group (M =
robot tutoring system. The behavioral measure is the time in           8.7 minutes, SD = 2.4), t(36) = 0.03, and in the voice group
which participants were able to solve each of the four puzzles.        (M = 9.1 minutes, SD = 3.0) as well, t(36) = 0.02. These
For the purposes of calculating a mean, puzzles in which par-          data indicate that the robot’s physical presence made a signif-
ticipants ran out of time were evaluated as having solved the          icant learning impact on participants greater than that of an
puzzle when time ran out, fifteen minutes from the start of            disembodied voice and a video representation of a robot.
each puzzle. This occurred in 12.4% of all puzzles.                       In this experiment, the first and fourth puzzles were 90◦
                                                                       rotated variations of the same board. Thus they required ex-
                  Table 1: Mean Solving Time                           actly the same skills to solve and the difference in their solv-
                                                                       ing time is a measure of the participants’ acquired knowledge
             Puzzle 1      Puzzle 2       Puzzle 3       Puzzle 4      over the course of the study. Participants in the robot condi-
  None     13.6 ± 2.2     13.0 ± 2.3     12.3 ± 2.5     11.6 ± 2.7     tion improved (M = 5.8 minutes, SD = 3.5) their same-puzzle
  Rand.    13.8 ± 1.4     12.5 ± 2.0     11.4 ± 2.3     10.3 ± 2.9     solving time significantly more than those in both the video
  Voice    12.6 ± 2.4     10.7 ± 2.7     10.3 ± 3.3     9.1 ± 3.0      condition (M = 3.9 minutes, SD = 2.3), t(36) = 0.048 and
  Video    12.8 ± 2.1     11.1 ± 2.6      9.9 ± 2.6     8.7 ± 2.4      voice condition, (M = 3.4 minutes, SD = 3.5), t(36) = 0.04;
  Robot    12.7 ± 2.6     10.0 ± 3.5      9.4 ± 3.0     7.6 ± 3.1      see Figure 4(b). This data indicates that participants who re-
                                                                       ceived lessons from the robot learned more effectively than
   Participants in the robot group performed better, on av-            those who received only voice- or video-based lessons.
erage, on the second, third, and four puzzles than partici-               Survey results verify the following manipulation: par-
pants in any other group. See Table 1 for means and stan-              ticipants in the three personalized advice conditions rated
dard deviations and see Figure 4(a). In the forth puzzle, the          the lessons significantly more relevant (M = 6.0, SD = 1.4)
                                                                   1885

  (a) Mean solving time per puzzle. Participants in the robot condi-       (b) Mean improvement in solving time between puzzles #1 and #4.
  tion solved each puzzle faster than participants in any other condi-     These two puzzles were variations of the same gameboard, dis-
  tion. In the fourth puzzle, significantly faster (p ≤ 0.03). See Table   guised in the fourth puzzle by a 90◦ rotation. Participants in the
  1 for means and standard deviations.                                     robot condition improved their solving time significantly more than
                                                                           those in any other condition (p < 0.05).
Figure 4: Behavioral measure results: (a) participants who received personalized lessons from an embodied robot solved every
puzzle puzzle faster on average, the fourth significantly so (p ≤ 0.03) than participants in all other conditions; see Table 1. (b)
robot condition participants also improved on their same puzzle solving time significantly higher more than participants in all
other conditions (p < 0.05).
than participants in the randomized advice condition (M =                   ceived authority than an on-screen agent. Earlier work in
3.9, SD = 1.1), t(33) < 0.001. There was no significant dif-                this area indicates that people are more likely to comply with
ference in how highly participants rated their understand-                  commands given by a physically-present robot than an on-
ing of the lessons between groups: (M = 6.0, SD = 1.4)                      screen video of the same robot (Bainbridge et al., 2008). Em-
in the random condition,(M = 6.6, SD = 1.2) in the voice                    bodiment may cause participants to take the robot tutor’s ad-
condition, (M = 6.6, SD = 1.5) in the video condition, and                  vice more seriously. We are accustomed to receiving lessons
(6.4, SD = 1.2) robot condition; see Figure 5. These data in-               from teachers and authority figures who have physical bodies.
dicate that whatever social effect physical embodiment has on               Perhaps a robot’s physical presence increases its authority or
this interaction, it does not influence the participants’ percep-           social standing.
tion of their understanding of the lessons, despite the fact that              Participants, however, did not report having significantly
the behavioral measure indicates better learning in the robot               more difficulty understanding the lessons in any of the three
condition.                                                                  advice conditions. In fact, all four groups rated their level
                                                                            of understanding of the lessons fairly highly (M = 6.3, SD =
                            Discussion                                      1.3); see Figure 5(b). This may indicate that the embodiment
Our results indicate that a physically-present robot tutor pro-             effect is so subtle that the participants did not notice its effect
duces better learning gains than on-screen or voice-only tu-                on their learning.
tors. Further work is needed to identify the underlying social                 Another social factor is the potentially increased sense
factors and mechanisms that cause this effect.                              of peer pressure during the performance of the task itself.
    One such factor may be the novelty of the stimulus. Robots              The distinction between physically-present robot and on-
are an uncommon stimulus in the present day; we may expect                  screen agent may parallel the way we perform tasks when
participants to be more attentive to the agent in the physically-           we think of ourselves as alone rather than in view of another
present condition. However, novelty can also be a distraction.              person. In person-person interactions, social presence can
The physical presence of the robot during the game may di-                  lead to significantly worsened task performance, especially
vert the participant’s attention from the puzzle solving task.              in cognitively-demanding tasks (Short, 1976). More work is
More work is needed to identify what effect, if any, a robot’s              needed to compare the potential effect of peer pressure caused
novelty has on interactions such as these.                                  by a physically-present robot tutor to the peer pressure ex-
    Physical presence may imbue the robot with more per-                    erted by a human tutor who observes as participants perform
                                                                        1886

     (a) Participants in the three personalized  (b) There is no significant difference be-  (c) Participants in the robot condition
     advice conditions rated the lessons as sig- tween groups in self-report of level of un- rated the robot as significantly less “an-
     nificantly more relevant than those in the  derstanding of the lessons.                 noying/distracting” than those in the
     random condition, p < 0.001.                                                            other personalized advice conditions,
                                                                                              p < 0.01.
                       Figure 5: Results of self-report questionnaire measures completed after the interaction.
cognitively-demanding tasks.                                             Dehn, D., & Van Mulken, S. (2000). The impact of animated
   Social presence effects may also be responsible for the                 interface agents: a review of empirical research. Interna-
survey result in which participants in the physically-present              tional Journal of Human-Computer Studies, 52(1), 1–22.
robot condition rated the robot (M = 4.7, SD = 1.8) as sig-              Kidd, C., & Breazeal, C. (2004). Effect of a robot on user
nificantly less “annoying/distracting” than participants in the            perceptions. Intelligent Robots and Systems, 2004.(IROS
other advice conditions (M = 6.1, SD = 1.3), t(33) < 0.01;                 2004). Proceedings. 2004 IEEE/RSJ International Confer-
see Figure 5(c). This may indicate that physical embodiment                ence on, 4, 3559–3564.
produces a significantly greater sense of social acceptance              Kiesler, S., Powers, A., Fussell, S., & Torrey, C. (2008).
than an on-screen agent does.                                              Anthropomorphic interactions with a robot and robot-like
   Participants in the robot condition became better puzzle                agent. Social Cognition, 26(2), 169–181.
solvers than those in the other conditions. Further research             Kozima, H., Nakagawa, C., & Yasuda, Y. (2005). Interac-
is needed to identify the underlying social factors that con-              tive robots for communication-care: a case-study in autism
tribute to this empirically-observed effect.                               therapy. IEEE International Symposium on Robot and Hu-
                                                                           man Interactive Communication, 341 - 346.
                           Conclusion                                    Leyzberg, D., Avrunin, E., Liu, J., & Scassellati, B. (2011).
This study investigates the role of physical embodiment of a               Robots that express emotion elicit better human teaching.
robot tutor in a cognitive skill learning task. Participants who           6th International Conference on Human-Robot Interaction,
received personalized lessons from a physically-present robot              347–354.
outperformed participants who received the same kind of ad-              Moundridou, M., & Virvou, M. (2002). Evaluating the per-
vice from a video representation of the same robot as well                 sona effect of an interface agent in a tutoring system. Jour-
as participants who received the same kind of advice from a                nal of Computer Assisted Learning, 18(3), 253–261.
disembodied voice on the last three puzzles. Participants in             Nagao, T., Ueda, N., Ueda, N., Sato, C. P. T., & Watanabe,
the robot condition also improved their same-puzzle solving                C. P. O. (1996). Np-completeness results for nonogram via
time significantly more than those in any other group, which               parsimonious reductions (Tech. Rep.). Tokyo Institute of
is a direct measure of learning gains over the course of the               Technology.
experiment. From these data we conclude that physical em-                Nkambou, R., Bourdeau, J., & Psyché, V. (2010). Build-
bodiment can yield measurable learning gains in robot tutor                ing intelligent tutoring systems: An overview. Advances in
interactions.                                                              Intelligent Tutoring Systems, 361–375.
                                                                         Short, W. E. . C. B., J. (1976). The social psychology of
                     Acknowledgments                                       telecommunications. London, England.
This material is based upon work supported by grants                     Tapus, A., Tapus, C., & Mataric, M. (2009). The role of
from the National Science Foundation under contracts No.                   physical embodiment of a therapist robot for individuals
1139078, No. 1117801, and No. 0835767.                                     with cognitive impairments. Robot and Human Interactive
                                                                           Communication, 2009. RO-MAN 2009. The 18th IEEE In-
                           References                                      ternational Symposium on, 103–107.
Bainbridge, W., Hart, J., Kim, E., & Scassellati, B. (2008).             Wainer, J., Feil-Seifer, D. J., Shell, D. A., & Mataric, M. J.
   The effect of presence on human-robot interaction. Robot                (2007). Embodiment and human-robot interaction: A task-
   and Human Interactive Communication, 2008. RO-MAN                       based perspective. IEEE Proceedings of the International
   2008. The 17th IEEE International Symposium on, 701–                    Workshop on Robot and Human Interactive Communica-
   706.                                                                    tion, 872-877.
                                                                    1887

