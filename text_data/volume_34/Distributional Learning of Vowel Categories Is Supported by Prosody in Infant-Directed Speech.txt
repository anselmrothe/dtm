UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Distributional Learning of Vowel Categories Is Supported by Prosody in Infant-Directed
Speech
Permalink
https://escholarship.org/uc/item/7pt904fz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Adriaans, Frans
Swingley, Daniel
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

          Distributional Learning of Vowel Categories is Supported by Prosody in
                                                   Infant-Directed Speech
        Frans Adriaans (adriaans@psych.upenn.edu) and Daniel Swingley (swingley@psych.upenn.edu)
              Department of Psychology and Institute for Research in Cognitive Science, University of Pennsylvania
                                    3401 Walnut Street, Suite 400A, Philadelphia, PA 19104, USA
                              Abstract                                have used approximations of infant-directed speech tokens
                                                                      as input to computational procedures (such as multivariate
   Infants’ acquisition of phonetic categories involves a dis-
   tributional learning mechanism that operates on acoustic           Gaussian mixture models) that succeed in learning vowel cat-
   dimensions of the input. However, natural infant-directed          egories, suggesting that distributional learning could be fea-
   speech shows large degrees of phonetic variability, and the        sible for infants (de Boer & Kuhl, 2003; McMurray, Aslin,
   resulting overlap between categories suggests that category
   learning based on distributional clustering may not be feasible    & Toscano, 2009; Vallabha, McClelland, Pons, Werker, &
   without constraints on the learning process, or exploitation       Amano, 2007).
   of other sources of information. The present study examines
   whether mothers’ prosodic modifications within infant-                 Some caution is appropriate in interpreting these findings.
   directed speech help the distributional learning of vowel          Studies that show the usefulness of distributional cues for
   categories. Specifically, we hypothesize that ‘motherese’          category learning have, in large part, been based on analy-
   provides the infant with a subset of high-quality learning
   tokens that improve category learning. In an analysis of           ses (and simulations) of vowel tokens that were elicited in
   vowel tokens taken from natural mother-infant interactions,        a laboratory setting, and that occurred in a small number
   we found that prosody can be used to distinguish high-quality      of words or nonwords. It is possible that maternal speech
   tokens (with expanded formant frequencies) from low-quality
   tokens in the input. Moreover, in simulations of distributional    under these conditions is different from maternal speech in
   learning we found that models trained on this small set of         quotidian home contexts. Analyses of natural, unscripted
   high-quality tokens provide better classification than models      infant-directed speech recordings show that vowel distribu-
   trained on the complete set of tokens. Taken together, these
   findings show that distributional learning of vowel categories     tions are highly variable, and that overlap between categories
   can be improved by attributing importance to tokens that are       poses a substantial problem for distributional category learn-
   prosodically prominent in the input. The prosodic properties       ing (Swingley, 2009). One possibility suggested by this result
   of motherese might thus be a helpful cue for infants in
   supporting phonetic category learning.                             is that infants’ learning of phonetic categories is guided by ad-
                                                                      ditional sources of information, such as the emerging lexicon
   Keywords:       Infant-directed speech; phonetic category          (Feldman, Griffiths, & Morgan, 2009; Swingley, 2009).
   learning; prosody; computational modeling.
                                                                          Another possibility, explored here, is that infants are able
                          Introduction                                to succeed in category learning because they have a bias to
Infants in the first year of life develop knowledge of the            attend to some tokens more than to others, and that these
phonetic categories that make up the consonants and vow-              salient tokens are clearer instances of their categories. If so,
els of their native language (e.g., Werker & Tees, 1984).             the difficulty of distributional category learning is overesti-
The early age at which this takes place rules out learning            mated by considering the whole mass of experienced speech
accounts in which semantic contrast in phonologically sim-            sounds. This notion is indirectly supported by studies show-
ilar words drives most category learning. As a result, it is          ing that infants prefer “motherese” speech over adult-directed
assumed that infants learn phonetic categories using an im-           speech. Across different languages motherese is character-
plicit statistical clustering process that relies on separation of    ized by acoustic exaggeration, including higher overall pitch,
the categories in perceptual space. Indeed, 6- and 8-month-           greater intonation contours, and longer durations (Fernald et
old infants have been found to form representations of two            al., 1989; Grieser & Kuhl, 1988; Kuhl et al., 1997). These
distinct categories (e.g., /d/ and /t/) when exposed to an            properties have been found to modulate infants’ attention, and
artificially generated bimodal distribution on a distinguish-         possibly facilitate language learning by enhancing infants’
ing acoustic dimension, but not when exposed to a unimodal            speech discrimination skills (Fernald & Kuhl, 1987; Karzon,
distribution (Maye, Werker, & Gerken, 2002; Maye, Weiss,              1985; Liu, Kuhl, & Tsao, 2003; Trainor & Desjardins, 2002).
& Aslin, 2008; see also Cristià, McGuire, Seidl, & Francis,              It remains to be demonstrated that motherese effectively
2011). Further evidence for the plausibility of distributional        guides the infant’s attention to those vowel tokens that are
learning of phonetic category structure comes from analyses           most useful for category learning. Computational models that
of infant-directed speech. Mothers appear to provide their in-        aim to explain category learning are typically fit to isolated,
fants with acoustic cues that support distributional learning         equally weighted vowel tokens (de Boer & Kuhl, 2003; Val-
of phonetic categories (Werker et al., 2007). In particular,          labha et al., 2007). Such models overlook prosodic context
infant-directed speech is characterized by expansion of the           which might make certain vowel tokens more attractive than
F1-F2 vowel formant space, which could enhance the separa-            others, and which thus potentially affects the learnability of
bility of vowel categories (Kuhl et al., 1997). Several studies       vowel categories.
                                                                   72

   The current study examines the relation between prosodic        Euclidean distance of each token to the center of the mother’s
exaggeration and vowel learning from infant-directed speech.       vowel space (Bradlow, Torretta, & Pisoni, 1996). In order to
Specifically, we hypothesize that motherese provides the in-       measure prosodic prominence in infant-directed speech each
fant with a subset of high-quality learning tokens that im-        vowel token was judged by a human assessor who indicated
proves distributional category learning. First, we analyze         whether the vowel occurred in a syllable that the mother was
prosodic determinants of vowel expansion within infant-            trying to emphasize (focus vs. no focus). Potential acoustic
directed speech, thereby attempting to predict which vowel         correlates of focus that were considered were: duration (log-
tokens in the infant’s speech input could be particularly bene-    arithm of the absolute duration in ms.), pitch (F0 averaged
ficial for phonetic category learning. Second, we simulate the     over 33% and 50% measurements), and pitch change (the ab-
distributional learning of phonetic categories in order to ex-     solute value of the difference in F0 between measurements at
amine whether prosodic focus helps in discovering category         33% and 50%). The label of “acoustic focus” was assigned
structure in cases of large overlap between categories. Im-        to vowels that exceeded the z-score of 0.5 for at least one of
portantly, analyses and simulations are done on realistic data,    the three dimensions.
using vowel tokens taken from recordings of natural mother-
infant interactions. We thus provide a test of distributional      Results
learning in a setting that acknowledges the variability and
complexities that are found in real everyday speech.               Table 1 shows the number of focused and unfocused tokens
                                                                   for each vowel. The annotated-focus set contained 336 vowel
   Vowel Expansion in Infant-Directed Speech                       tokens (28.8% of the total set). The acoustic-focus set had
Earlier studies on vowel expansion compared speech di-             543 tokens (46.6% of the total set). Figure 1 shows the mean
rected to adult listeners and speech directed to infant listen-    formant frequencies of vowels in focused and unfocused po-
ers (Kuhl et al., 1997). While infant-directed speech is of-       sition. Vowels in focused position were further away from the
ten hyperarticulated compared to adult-directed speech, the        center of the vowel space than vowels in unfocused position.1
mechanisms underlying vowel expansion in infant-directed              Stepwise linear regression analyses revealed that annotated
speech are not yet fully understood. It seems likely that          focus is a significant predictor of the vowel’s distance from
the prosodic exaggeration notable in infant-directed speech        the center of the vowel space, independent of vowel type
has an effect on vowel expansion. Here we explore this             (adjusted R2 = 0.4221; vowel***, focus**, vowel:focus ns).
possibility by asking whether prosodically prominent vow-          Vowels in syllables with annotated focus were thus hyperar-
els in infant-directed speech are hyperarticulated relative to     ticulated relative to vowels in unfocused syllables. This con-
parts that are not prosodically highlighted. In analyses of        firms the intuition that in natural infant-directed speech moth-
recordings of natural mother-infant interactions, we examine       ers exaggerate certain vowels by marking them with sentence
whether prosodic focus predicts vowel expansion (see also          focus. Interestingly, vowel expansion did not manifest itself
Mo, Cole, & Hasegawa-Johnson, 2009). We examine expan-             through stretching of the triangle defined by the “point vow-
sion in tokens that were labeled to have focus by human as-        els” (/i/, /A/, /u/), but rather followed a consistent pattern of
sessors (what we define as “annotated focus”), and also in         expansion throughout the entire set of monophthongs.
tokens that were defined as exaggerated on acoustic grounds           The tokens that had acoustic focus showed very simi-
(higher pitch, greater pitch change, and longer duration; what     lar results. Stepwise regression revealed that acoustic fo-
we define as “acoustic focus”), to determine whether such          cus is a significant predictor of vowel expansion (adjusted
vowels are more differentiable. Evidence of vowel expansion        R2 = 0.4300; vowel***, focus***, vowel:focus*). These re-
at prosodically predictable locations in infant-directed speech    sults indicate that whether infants are able to judge focus (as
would indicate that attention to prosody could aid in vowel        our annotators did), or whether they simply pay attention to
category learning.                                                 tokens that have extreme values on prosodic dimensions (i.e.,
                                                                   “acoustic focus”), the tokens that have focus show expansion,
Methods                                                            and are thus possibly particularly helpful for the learning of
Vowel expansion was examined by analyzing vowel produc-            phonetic categories.
tions by one mother (‘f1’) in the Brent corpus (Brent &               In sum, vowels that are prosodically exaggerated might
Siskind, 2001), available through CHILDES (MacWhinney,             be particularly useful for phonetic learning because they
2000). These recordings consist of natural, unscripted infant-     have distributional properties that enhance the separability of
directed speech and therefore have no restrictions on the          vowel categories. The overlap between categories, however,
words or vowel types that may occur. Formant (F1, F2) mea-         is still substantial. It thus remains to be demonstrated that
surements were obtained and hand-checked for 1,166 vowel           prosodic highlighting makes a meaningfully large difference
tokens. Tokens covered the monophthongs of American En-            in the learnability of vowel categories.
glish (/i/, /I/, /E/, /æ/, /A/, /2/, /O/, /U/, /u/). Measure-
ments taken at 33% and 50% of the vowel’s duration were                1 The exception was /O/ and /U/ in the acoustic-focus set. The
averaged and transformed into z scores to neutralize scale dif-    means of these vowels are unreliable due to their low frequency of
ferences. Vowel expansion was measured by calculating the          occurrence in the data set. (See Table 1.)
                                                                73

                               Table 1: Frequency of occurrence of vowels in focused and unfocused position.
                                                  /i/            /I/        /E/           /æ/             /A/           /2/        /O/       /U/       /u/           Total:
                                                (182)          (320)      (163)         (139)           (112)         (130)       (21)      (22)      (77)         (1,166)
              Focus (annotated)                     41           72          51              67           32              36       12           5          20           336
              No focus (annotated)                 141          248         112              72           80              94        9          17          57           830
              Focus (acoustic)                     105          112             65           95           55              45       16          10          40           543
              No focus (acoustic)                   77          208             98           44           57              85        5          12          37           623
     400                                                                                          400
             /i/                                                                                                /i/
                                                             /u/                                                                                            /u/
                                /ɪ/                                                                                                 /ɪ/
     500                                                           /ʊ/                            500
                                                                                                                                                                    /ʊ/
     600                               /ɛ/                                                        600                                      /ɛ/
F1                                                                                           F1
                                                         /ʌ/                    /ɔ/                                                                               /ʌ/
     700                                                                                          700                                      /æ/                                /ɔ/
                                        /æ/
                                                                                                                                                            /ɑ/
                                                         /ɑ/
                   Focus                                                                                              Focus
                   No focus                                                                                           No focus
     800                                                                                          800
             2400       2200      2000         1800         1600         1400         1200                  2400           2200       2000          1800        1600      1400      1200
                                              F2                                                                                                 F2
                                      (a) Annotated focus                                                                                 (b) Acoustic focus
                   Figure 1: Vowel expansion within infant-directed speech. ‘+’ indicates the center of the mother’s vowel space.
           The Learnability of Vowel Categories                                                   2007), we treat categories as multivariate Gaussian distribu-
                                                                                                  tions. The learning problem is characterized as estimating
In order to see if prosodically highlighted vowels would be
                                                                                                  the parameters (means, covariances and mixing proportions)
beneficial to infant language learners, we simulate the dis-
                                                                                                  for these distributions. In our case, categories are defined
tributional learning of vowel categories from infant-directed
                                                                                                  as 2-dimensional distributions (the z scores of the first and
speech. In particular, we examine whether prosodic fo-
                                                                                                  second formants). Data points are assigned to the category
cus helps in discovering category structure in cases of large
                                                                                                  that has the maximum likelihood for that point. Parameters
overlap between categories. If distributional models of
                                                                                                  of the Gaussian distributions are estimated using the EM al-
vowel learning show improved performance when trained on
                                                                                                  gorithm (Dempster, Laird, & Rubin, 1977) as implemented
prosodically defined subsets of vowel data, then this would
                                                                                                  in the MCLUST for R software package (Fraley & Raftery,
constitute evidence that the prosodic properties of motherese
                                                                                                  2006). All models reported below were trained to discover
support phonetic category learning.
                                                                                                  three ellipse categories. Since vowel ellipses are known to
Methods                                                                                           vary in volume, shape, and orientation (e.g., Hillenbrand,
                                                                                                  Getty, Clark, & Wheeler, 1995), the models were given no
The learnability of vowel categories is simulated for two dif-                                    information or constraints with respect to volume, shape, or
ferent sets of vowels: /i/, /I/, /E/ and /E/, /æ/, /A/. These                                     orientation.
sets were chosen because they each contain three vowels that
are close in the F1-F2 formant space. As a consequence,                                              In order to assess whether focused tokens were helpful for
the overlap between categories is large, and the learning                                         category learning, models were trained on a subset of the data
of these categories poses a substantial problem for distribu-                                     (either the annotated-focus set or the acoustic-focus set). The
tional learning models. In line with earlier work on com-                                         Gaussian distributions that were estimated from these subsets
putational modeling of phonetic category learning (e.g., de                                       were subsequently used to classify all vowel tokens in the
Boer & Kuhl, 2003; McMurray et al., 2009; Vallabha et al.,                                        data set. We predicted that Gaussian mixture models trained
                                                                                         74

on a relatively small set of prosodically prominent vowel to-
                                                                           Table 2: Classification accuracy on two different sets of over-
kens would provide a better classification of the data than
                                                                           lapping vowel categories.
Gaussian mixture models that were trained on the complete
set of vowel tokens. Performance of the unsupervised clus-                               Model                   Accuracy
tering models was assessed by comparing their classification                                                  i-I-E    E-æ-A
accuracy to a supervised learner that learned three Gaussian
categories based on actual vowel category labels. The su-                                All tokens         0.6060    0.6449
pervised learner represented an upper bound on the classi-                               Annotated focus    0.6331       -
fication accuracy that can be obtained given the maximum                                 Acoustic focus     0.7008    0.7343
likelihood classification criterion that is imposed on the over-                         Supervised         0.7278    0.7947
lapping Gaussian distributions.
Results
                                                                                                     Discussion
Table 2 shows the classification accuracy for models trained
                                                                           In learning the phonetic categories of their native language,
using all tokens, annotated-focus tokens, acoustic-focus to-
                                                                           infants face large amounts of variability in the acoustic re-
kens, and all tokens’ category labels (this last being the su-
                                                                           alizations of different vowel tokens. This poses a substan-
pervised “ideal”). The first thing to note is that the classifica-
                                                                           tial problem for the purely bottom-up distributional learning
tion accuracy of the supervised learners was below 80%, con-
                                                                           of vowels. Here we presented one possible source of infor-
firming that overlap between categories was substantial. Con-
                                                                           mation that may guide phonetic category learning. If infants
sidering the unsupervised “All tokens” model, the 12- to 15-
                                                                           are able to detect high-quality learning tokens in the input,
percentage-point decline relative to the supervised model
                                                                           then they could make considerable progress in category learn-
shows that the categories are not trivially detectable in the dis-
                                                                           ing. Motherese may play an important role in this process, by
tributions.2 Using vowel tokens annotated as focused aided
                                                                           bringing such “high-quality” tokens to the infant’s attention
accuracy to a small degree in the i-I-E data set, a result that
                                                                           through prosodic modifications of the speech stream.
nevertheless reveals some utility to focus marking given that
this model was trained on only 164 data points rather than the                In our clustering experiments, focus as annotated by hu-
entire dataset (which consisted of a total of 665 i-I-E tokens).           man listeners was not as effective as “focus” estimated us-
However, for the E-æ-A data set the clustering algorithm was               ing simple, one-dimensional acoustic measures. It is possible
unable to fit a model to the annotated-focus tokens. We be-                that this difference derived from sample-specific gaps in the
lieve that this is due to the small size of the annotated-focus            number or quality of human-annotated focus tokens for some
data set for E-æ-A (n = 150, with only 32 tokens for /A/, see              vowel types; this cannot be ruled out without examining other
Table 1). Thus, focused vowels are, in at least some cases,                samples. Furthermore, it is likely that annotators’ judgments
variable enough that category solutions are difficult to deter-            of focus were, in some cases, based on their interpretation
mine when the quantity of data is very small.                              of the speaker’s intentions: an adult listener might judge a
                                                                           word as being the one the speaker wished to emphasize even
   Training on the bigger set of acoustic-focus tokens helped
                                                                           if the phonetics were not particularly marked. Still, the su-
learning substantially, bringing the model within 3 percent-
                                                                           perior performance of the model that learned from the tokens
age points of the supervised model in the i-I-E data set, and
                                                                           that were simply more extreme on at least one of the acoustic
within 6 percentage points in the E-æ-A data set. Models that
                                                                           dimensions shows that the benefits of “motherese” prosodic
were trained on tokens that were acoustically prominent (long
                                                                           highlighting do not depend on possession of a mature capac-
duration, high pitch, greater pitch movement) thus showed
                                                                           ity for interpreting focus. Sensitivity to simple dimensions
substantial classification improvement as compared to models
                                                                           like duration or pitch goes a long way.
that were prosodically uninformed. To illustrate the perfor-
mance of different learning models, we display the i-I-E data                 Infant-directed speech prosody, with its exaggerated
along with the classifications that are predicted by different             prosodic variation, certainly captures infants’ attention, and
models in Figure 2. Figure 2 shows that only the acoustic-                 this may be important for learning. Earlier studies have
focus training set is able to predict three clearly distinct cate-         shown that pitch contours enhance infants’ discrimination
gories.                                                                    skills, since contours increase the acoustic salience of for-
                                                                           mant frequencies (Trainor & Desjardins, 2002). Such per-
   As it turns out, tokens that have focus or show acoustic ex-
                                                                           ceptual salience is not taken into account by our model. Our
aggeration have a positive effect on the unsupervised learning
                                                                           results show that prosody has additional benefits. We find that
of vowel categories. Importantly, these high-quality tokens
                                                                           acoustically exaggerated tokens show a different distribution
are easily identifiable based on their prosodic properties. It
                                                                           in the F1-F2 space, with greater distances from the center and
is thus likely that these tokens are identifiable for infant lan-
                                                                           enhanced separability of categories. The picture that emerges
guage learners, and contribute to language learning.
                                                                           from earlier studies, combined with the current findings, is
    2 Such a decline is not found in models of the point vowels (i-A-u)
alone, for which we found accuracy > 90% for both the supervised           and unsupervised learner.
                                                                        75

         -2                                                                      -2
                                                                 /i/                                                                       /i/
                                                                 /ɪ/                                                                       /ɪ/
         -1                                                      /ɛ/             -1                                                        /ɛ/
         0                                                                       0
 z(F1)                                                                  z(F1)
         1                                                                       1
         2                                                                       2
         3                                                                       3
               2         1          0         -1           -2    -3                       2        1           0         -1           -2   -3
                                         z(F2)                                                                    z(F2)
                             (a) Actual vowel categories                                               (b) Clustering of all tokens
         -2                                                                      -2
                                                                 /i/                                                                       /i/
                                                                 /ɪ/                                                                       /ɪ/
         -1                                                      /ɛ/             -1                                                        /ɛ/
         0                                                                       0
 z(F1)                                                                  z(F1)
         1                                                                       1
         2                                                                       2
         3                                                                       3
               2         1          0         -1           -2    -3                       2        1           0         -1           -2   -3
                                        z(F2)                                                                     z(F2)
                    (c) Clustering of 'Annotated focus' tokens                                 (d) Clustering of 'Acoustic focus' tokens
Figure 2: The i-I-E data set with (a) actual categories, (b) predicted categories based on all tokens, (c) predicted categories based on focused
tokens, and (d) predicted categories based on acoustically exaggerated tokens. The means are plotted for each (predicted) category.
that the exaggerated prosody of infant-directed speech may                      NIH grant R01-HD049681 to D.S.
capture infants’ attention to speech in a general fashion, and
at the same time provide an enhanced speech signal that sup-                                             References
ports language learning – if infants’ category learning favors                  Bradlow, A. R., Torretta, G. M., & Pisoni, D. B. (1996).
attention to the most salient instances.                                          Intelligibility of normal speech I: Global and fine-grained
                                                                                  acoustic-phonetic talker characteristics. Speech Communi-
                     Acknowledgments                                              cation, 20, 255-272.
This work was funded by the Netherlands Organisation for                        Brent, M. R., & Siskind, J. M. (2001). The role of exposure
Scientific Research (NWO) grant 446.010.027 to F.A. and                           to isolated words in early vocabulary development. Cogni-
                                                                       76

  tion, 81, B33-B44.                                                 tical learning of phonetic categories: insights from a com-
Cristià, A., McGuire, G. L., Seidl, A., & Francis, A. L.            putational approach. Developmental Science, 12, 369-378.
  (2011). Effects of the distribution of acoustic cues on in-      Mo, Y., Cole, J., & Hasegawa-Johnson, M. (2009). Prosodic
  fants’ perception of sibilants. Journal of Phonetics, 39,          effects on vowel production: evidence from formant struc-
  388-402.                                                           ture. In Proceedings of Interspeech 2009 (p. 2535-2538).
de Boer, B., & Kuhl, P. K. (2003). Investigating the role of       Swingley, D. (2009). Contributions of infant word learning to
  infant-directed speech with a computer model. Acoustics            language development. Philosophical Transactions of the
  Research Letters Online, 4, 129-134.                               Royal Society B, 364, 3617-3622.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum like-         Trainor, L. J., & Desjardins, R. N. (2002). Pitch charac-
  lihood from incomplete data via the EM algorithm. Journal          teristics of infant-directed speech affect infants’ ability to
  of the Royal Statistical Society. Series B (Methodological),       discriminate vowels. Psychonomic Bulletin & Review, 9,
  39, 1-38.                                                          335-340.
Feldman, N. H., Griffiths, T. H., & Morgan, J. L. (2009).          Vallabha, G. K., McClelland, J. L., Pons, F., Werker, J. F., &
  Learning phonetic categories by learning a lexicon. In Pro-        Amano, S. (2007). Unsupervised learning of vowel cate-
  ceedings of the 31st Annual Conference of the Cognitive            gories from infant-directed speech. Proceedings of the Na-
  Science Society (p. 2208-2213).                                    tional Academy of Sciences of the United States of America,
Fernald, A., & Kuhl, P. (1987). Acoustic determinants of             104, 13273-13278.
  infant preference for motherese speech. Infant Behavior          Werker, J. F., Pons, F., Dietrich, C., Kajikawa, S., Fais, L.,
  and Development, 10, 279-293.                                      & Amano, S. (2007). Infant-directed speech supports pho-
Fernald, A., Taeschner, T., Dunn, J., Papousek, M., Boysson-         netic category learning in English and Japanese. Cognition,
  Bardies, B. de, & Fukui, I. (1989). A cross-language study         103, 147-162.
  of prosodic modifications in mothers’ and fathers’ speech        Werker, J. F., & Tees, R. C. (1984). Cross-language speech
  to preverbal infants. Journal of Child Language, 16, 477-          perception: Evidence for perceptual reorganization during
  501.                                                               the first year of life. Infant Behavior and Development, 7,
Fraley, C., & Raftery, A. E. (2006). MCLUST Version 3 for            49-63.
  R: Normal mixture modeling and model-based clustering
  (Tech. Rep.). Seattle, WA: University of Washington.
Grieser, D. L., & Kuhl, P. K. (1988). Maternal speech to
  infants in a tonal language: Support for universal prosodic
  features in motherese. Developmental Psychology, 24, 14-
  20.
Hillenbrand, J., Getty, L. A., Clark, M. J., & Wheeler, K.
  (1995). Acoustic characteristics of American English vow-
  els. Journal of the Acoustical Society of America, 97, 3099-
  3111.
Karzon, R. G. (1985). Discrimination of polysyllabic se-
  quences by one- to four-month-old infants. Journal of Ex-
  perimental Child Psychology, 39, 326-342.
Kuhl, P. K., Andruski, J. E., Chistovich, I. A., Chistovich,
  L. A., Kozhevnikova, E. V., Ryskina, V. L., et al. (1997).
  Cross-language analysis of phonetic units in language ad-
  dressed to infants. Science, 277, 684-686.
Liu, H.-M., Kuhl, P. K., & Tsao, F.-M. (2003). An associ-
  ation between mothers’ speech clarity and infants’ speech
  discrimination skills. Developmental Science, 6, F1-F10.
MacWhinney, B. (2000). The CHILDES project: Tools for
  analyzing talk, volume 2: The database (3rd ed.). Mahwah,
  NJ: Lawrence Erlbaum Associates.
Maye, J., Weiss, D. J., & Aslin, R. N. (2008). Statistical
  phonetic learning in infants: facilitation and feature gener-
  alization. Developmental Science, 11, 122-134.
Maye, J., Werker, J. F., & Gerken, L. (2002). Infant sensi-
  tivity to distributional information can affect phonetic dis-
  crimination. Cognition, 82, B101-B111.
McMurray, B., Aslin, R. N., & Toscano, J. C. (2009). Statis-
                                                                77

