UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Causal Structure through Local Prediction-error Learning
Permalink
https://escholarship.org/uc/item/2w52c78z
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Wellen, Sarah
Danks, David
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

               Learning Causal Structure through Local Prediction-error Learning
                                           Sarah Wellen (swellen@andrew.cmu.edu)
                                               Department of Philosophy, Baker Hall 135
                                                       Pittsburgh, PA 15213 USA
                                                  David Danks (ddanks@cmu.edu)
                                               Department of Philosophy, Baker Hall 135
                                                    Pittsburgh, PA 15213 USA; and
                                     Institute for Human & Machine Cognition, 40 S. Alcaniz St.
                                                       Pensacola, FL 32502 USA
                             Abstract                                  and are connected by a pair of assumptions (Markov and
                                                                       Faithfulness) that capture the ways in which causal structure
     Research on human causal learning has largely focused             manifests in observed data. Sloman (2005) and Spirtes,
     on strength learning, or on computational-level theories;         Glymour, & Scheines (1993) provide useful expositions of
     there are few formal algorithmic models of how people             the causal Bayes net framework.
     learn causal structure from covariations. We introduce a
     model that learns causal structure in a local manner via
     prediction-error learning. This local learning is then
     integrated dynamically into a unified representation of
     causal structure. The model uses computationally
     plausible approximations of (locally) rational learning,
     and so represents a hybrid between the associationist and
     rational paradigms in causal learning research. We
     conclude by showing that the model provides a good fit
     to data from a previous experiment.
                                                                             Figure 1: Prototypical 3-variable causal Bayes nets
     Keywords: Causal learning; causal Bayes nets;
     prediction-error learning; algorithmic level
                                                                          There is substantial evidence that the type of structural
                                                                       knowledge captured by a causal Bayes net—or at least, the
                         Introduction                                  directed graphical model part—is necessary to account for
From a young age, we spontaneously, and often effortlessly,            many causal reasoning abilities. One hallmark of causal
come to understand the causal structure of the world, and              reasoning, rather than correlational, is that cases involving
then use that knowledge to both predict what might happen              observations vs. interventions are treated differently
in the future and also design actions that will achieve our            (Sloman & Lagnado, 2005; Waldmann & Hagmayer, 2005).
goals (e.g., Gopnik, et al., 2004; Sloman, 2005). Our focus            For example, one can infer, from an observation of a
here is causal learning from covariational data: how do                professor’s gray hair, that she likely has many publications.
people learn the causal structure of the world from a                  No such inference follows if she instead intervened to dye
sequence of observations or interventions of that world?               her hair gray. Causal Bayes nets can straightforwardly
   Causal learning can usefully be separated into the related-         account for this difference, as interventions are represented
but-distinct problems of representation and dynamics—what              by ‘graph surgery,’ where a variable that is intervened upon
is learned and how is it learned. In this paper, we develop a          is separated from its typical causes (Spirtes, et al., 1993).
novel account of causal learning that, at a high level, uses           This surgery changes the informational relations, and so
quasi-associationist processes to learn directed graph-like            one’s inferences can be different in the two situations.
causal representations. It is thus a hybrid of the standard               Some aspects of causal knowledge are not easily
rationalist vs. associationist approaches to causal learning.          represented by this formalism (e.g. the spatiotemporal
                                                                       relations between causes and effects), but it seems to
Representations of Causal Structure                                    provide a good account of people’s representations of causal
The development of causal Bayesian networks prompted a                 structure. Thus, we aim to develop a theory of causal
major advance in our understanding of causal knowledge. A              learning in which people learn a directed graph (perhaps
causal Bayes net has two components: (i) a directed acyclic            acyclic, though we will allow for cyclic structures).
graph (DAG) whose nodes represent variables and directed
edges represent direct causal relations (see Figure 1); and            Dynamics of Causal Structure Learning
(ii) a probability distribution that encodes how causes                Theories about how people use covariation to learn directed
influence their effects. These two elements represent                  graph representations can be divided roughly into rational
qualitative and quantitative causal structure, respectively,           and heuristic accounts of causal learning. Rational accounts
                                                                   2529

model causal learning as rational inference. These include              Another lacuna in the single-effect learning model is that
constraint-based algorithms (e.g., Glymour, 2003; Gopnik,            it does not explain how the learner uses a causal power
et al., 2004), and those based on Bayesian inference (e.g.,          estimate to determine whether a link actually exists. We
Steyvers, et al., 2003; Griffiths & Tenenbaum, 2005). They           thus provide a decision procedure for causal relation
are usually intended at the computational level of analysis,         acceptance based on both the learner’s point estimate and
as they show how the cognitive system’s performance                  her confidence in that estimate. This addition allows us to
solves the problem faced by that system, but do not attempt          model the dynamics of learning for directed graphs that are
to characterize the underlying cognitive processes. There            more complex than the single-effect structure.
have been some recent attempts to develop algorithmic (i.e.
process) models of causal learning based on approximations                                The LPL Model
of Bayesian inference (e.g., Bonawitz, et al., 2011). These          The Local Prediction-error Learning (LPL) model aims to
models have so far only addressed causal strength learning,          explain how observations and interventions are used to learn
and it is not clear how to extend them (in a computationally         causal structure when one has relatively little prior
tractable manner) to structure learning.                             knowledge. We do not model many other relevant sources
   Heuristic accounts of causal learning propose that people         of information, including verbal communication, reasoning,
use various cues to suggest and modify causal hypotheses in          or spatiotemporal information. The model does assume that
a not-necessarily-rational (though presumably sensible)              the learner knows the functional form of the causal relations
manner. Causal model theory (Waldmann, 1996) proposes                and (when relevant) the expected temporal delay between
that learners use cues such as covariation, temporal order,          causes and effects.
and spatial proximity to select an initial causal structure and         The LPL model begins with an initial causal structure
adjust it in the face of inconsistent data (Lagnado,                 hypothesis: a directed graph representing the individual’s
Waldmann, Hagmayer, & Sloman, 2007). Causal model                    prior beliefs, where an edge indicates an a priori belief that
theory has never been entirely formally specified, though            there is a causal connection, and absence indicates only
some parts have received formal treatment.                           agnosticism.1 For typical experiments in which participants
   The local computations model (Fernbach & Sloman,                  have little prior knowledge, this will be an empty graph. The
2009) attempts to explain how learners use data from                 model alters this causal structure hypothesis by adding or
interventions to learn a causal structure. The key idea is that,     removing single edges, thereby reducing the structure
when a variable is intervened upon and other variables               learning problem to the simpler task of evaluating individual
change, the learner infers that the intervened-upon variable         causal relations. Multiple experimental results suggest that
caused those other variables. Critically, all learning in this       learners focus primarily on single causal relations (e.g.,
model is local, as people evaluate individual causal relations       Gopnik et al., 2004; Waldmann, et al., 2008), presumably
rather than entire graphs. The model we present here adopts          because of the computational complexity of evaluating
this important insight and extends it to all covariation-based       larger structures.
structure learning, including learning from observations.               Figure 2 shows a high-level overview of the LPL
   The single-effect learning model (Waldmann, et al., 2008)         algorithm. The key pieces to be explained are the Causal
also assumes that people focus on evaluating single causal           Strength Estimates, and how the Decision Procedure
relations. It is a model of learning from observations, and          changes the Causal Structure Hypothesis.
proposes that learners estimate the causal power (Cheng,
1997) of each potential cause of an effect. If a variable has
sufficient (estimated) causal power, then the learner accepts
the causal relation and integrates it with her previous causal
knowledge. This model has found some empirical support in
both humans and rats (Waldmann, et al., 2008).
   Our model adopts the single-effect learning model’s focus
on causal power, and the integration of these individually
learned relations into a unified causal structure. However,
the standard causal power theory is a computational theory
that makes no commitment to underlying processes. Danks,
Griffiths, & Tenenbaum (2003) provided a prediction-error-
based model of causal strength learning whose equilibrium
states are causal powers, and so their model can be viewed
as an algorithmic implementation of the causal power
theory. Moreover, its basis in prediction-errors is consistent
with neuroscientific evidence that the right lateral prefrontal           Figure 2: A high-level description of the LPL model
cortex encodes prediction-error signals during causal
learning (Corlett, et al., 2004; Turner, et al., 2004).
                                                                        1
                                                                          The model can also encode a priori belief of definite edge
                                                                     absence, though we omit this complication for reasons of space.
                                                                 2530

(a)                                  (b)
                                                                        0.8
                                             Causal&Strength&Estimate
                                                                        0.6
                                                                                                        V
                                                                                                         B
                                                                        0.4
                                                                                                        V
                                                                        0.2                              C
                                                                          0
                                                                               0   10   20         30    40       50         60       70       80   90       100
                                                                        -0.2
                                                                                                              Trial&Number
Figure 3: (a) Example local learning context (solid / dashed arrows indicate known / potential causal relations); (b) Causal
                         strength estimates of B (blue) and C (red) using five particles per edge
                                                                                             independently after each data point by prediction-error
Causal Strength Estimates                                                                    learning. Such learning can be represented schematically as:
  The LPL model generates causal strength estimates for                                                  VCi,t+1 = VCi,t + α (observed – expected)
each possible cause-effect pair that is not ruled out a priori.                              The learning rate (α) is a free parameter, and observed has
That is, for each pair of variables (A, B), the learner                                      the value 1 if the effect occurs and 0 if it does not. The value
estimates the causal strength of A→B and B→A unless she                                      of expected is typically the expected value of the effect
has prior knowledge about potential edge direction. We                                       variable, calculated using the functional form for the cause-
assume here that the correct functional form for causal                                      effect relation. Many associationist learning models fit this
relations is noisy-OR, and so causal strengths are causal                                    schema, including the classic Rescorla-Wagner model and
powers (Cheng, 1997; Griffiths & Tenenbaum, 2005),                                           the causal power estimator of Danks, et al. (2003).
though this can change based on background information.                                         The expected value is computed separately for each
  Like the single-effect learning model, we assume that the                                  potential cause in a layer. The current structure hypothesis
appropriate scope for learning causal strength includes the                                  has an influence because expected is based on only definite,
potential cause, the effect, and any other definite causes of                                known causes and the particular target potential cause for
that effect. For instance, consider Figure 3(a), where the                                   that update; other variables are ignored. This restriction
learner believes that B causes E and is trying to determine                                  reduces the computational demands on the learner, and fits
whether C also causes E. Unlike the single-effect learning                                   real-world contexts where the learner cannot simultaneously
model, however, causal strength estimates for C are                                          attend to all the potential causes in her environment. If the
generated by a mechanism similar to particle filters in                                      causes combine as causal powers, then the expected value of
approximate Bayesian inference, though our “particles”                                       E (for layer i and potential cause C) is:
move by associationist learning.                                                                                                       #               &
  The LPL model initially draws n particles for each                                               expected = ∏                   (        )
                                                                                                                             1− VKt−1 %%1− ∏ 1− VJt−1 (( (         )
                                                                                                                   K=present
possible causal relation from a prior strength distribution                                                                            $ J=present     '
determined by the learner’s background knowledge. The                                        where J (K) is the set of E’s generative (preventive) causes.
learner’s current beliefs about whether C causes E are                                          Figure 3(b) shows how initial causal strength estimates
represented by these particles { VC1,...,VCn }. There is a                                   can change over time. Data were generated by Figure 3(a)
corresponding set { VB1,...,VBn } of particles for B. The use of                             with a noisy-OR functional form. At first, the particles are
                                                                                             spread widely around zero, representing the learner’s
multiple particles enables the model to capture both strength                                uncertainty in her estimate. As the learner observes more
estimates and confidence in those estimates. The mean                                        data points, prediction-error learning brings the particles
                       1    n
particle value, VC =
                       n
                        ∑   i=1
                                VCi , is the point estimate of C’s                           closer to the true parameter values. The layers of particles
                                                                                             that are further from the true values will generally have
causal strength. The average squared deviation of the                                        greater errors and thus will shift more towards the true
                 1 n               2
                                                                                             values during learning. As a result, the estimates in different
                        (        )
particles, DC = ∑ VCi − VC , is the learner’s (lack of)
                 n    i=1
                                                                                             layers converge,2 representing the learner’s increasing
     €
confidence: low values of DC indicate high confidence.                                       confidence. This process gives no account of structure
  We define a layer i of particles for an effect E as the i-th                               learning, however, so we turn to that now.
particle from each known and potential cause of E. In Figure
3(a), for example, layer i would be { VBi ,VCi }. A layer of                                   2
                 €                                                                               Though they only stabilize around equilibrium values. If the
particles is a specific hypothesis about the strengths of all                                learning rate is based on the learner’s current (lack of) confidence,
known and potential causes of E. Each layer is updated                                       then true convergence is possible.
                                €
                                                                                        2531

Causal Structure Judgments                                                              Evaluating the LPL Model
The LPL model has a single, definite structure hypothesis at
each point in time, which can then be modified by either                 Data
adding or removing an edge. These modifications are based                We evaluate the LPL model using data from Lagnado &
on a decision procedure applied to the causal strength                   Sloman (2006). In this experiment, participants had to
estimates after each update.                                             discover the causal connections between four computers by
   Since an edge with a causal strength of zero is equivalent            sending 100 text messages to computer A and observing
to no edge, the decision procedure uses a t-test on each set             whether those messages were sent on to other computers.
of particles with the null hypothesis that the particles are             The true causal system is shown in Figure 4, where the
drawn from a distribution with mean µ = 0. The outcome of                arrows represent noisy causal relations. Messages always
this test depends on both the particles’ mean and deviation.             reached computer A, and the probability of a message being
A free parameter pcritical guides the decision procedure. If             transmitted from one computer to the next was 0.8.
there is no edge in the graph and the t-test rejects the null            Messages never spontaneously occurred.3 Trial order was
hypothesis (i.e., the p-value p of the test statistic is less than       randomized both for participants and for modeling.
pcritical), then an edge is added. If there is an edge present
and the t-test does not reach significance (i.e., p > pcritical),
then the edge is removed from the graph.
   If a C→E edge is added or removed, future calculations of
expected change for other potential causes of E, as those
involve only the known causes of E. Crucially, this form of
causal structure learning satisfices: the learner accepts the
most plausible structure as a working hypothesis rather than
representing and evaluating all possible structure hypotheses
(as in standard Bayesian models).                                         Figure 4: Causal structure from Lagnado & Sloman (2006)
Other Factors                                                               The original experiment contrasted temporal and
Temporal information and the data source can influence the               covariational information, so there were four conditions that
interpretation of covariational data, and so are also                    varied the temporal order in which messages appeared.
incorporated into the LPL model.                                         Condition 1 involved no timing information, but conditions
                                                                         2-4 did (with different delays4).
Interventions Given an observation about C and E, the LPL
                                                                         LPL Model
model updates the causal strength estimates for both C→E
and E→C whenever the model does not yet know which                       Participants had no prior knowledge of causal structure, so
direction the causal influence flows (if any). If C’s value is           the initial model was the empty graph (i.e., agnosticism).
instead set by intervention, then one knows that C is severed            Connections between the computers were clearly generative,
from its normal causes. Thus, one should not update causal               so the model only considered causal strength estimates
strength estimates for potential causes of C. Operationally,             between 0 and 1. For each possible edge, five particles were
if given data about an intervention on C, the LPL model                  drawn from a truncated Gaussian (µ = 0, σ2 = .2).
updates only the C→E particles, and not the E→C ones.                       The LPL Model has four other free parameters. The
                                                                         expected temporal delay dtyp, and the temporal scaling
Temporal Information Temporal delays between the cause                   parameter s are not used with simultaneous occurrences (as
and effect influence contingency learning, though mediated               in condition 1). We thus first determined the values for the
by the learner’s expectations (Buehner & May, 2003;                      learning rate α and the critical significance level pcritical by
Buehner & McGregor, 2006). The LPL model compares the                    maximizing model fit (via a grid search) for condition 1
observed temporal difference dE-C between a potential cause              only. Model fit was based on R2 values5 for the proportions,
and the effect to the expected temporal difference dtyp. If the          over all possible causal relations CR, of (a) 1000 model runs
learner expects the delay to always be dtyp, then the causal             that yielded CR, and (b) experimental participants that
strength estimates update only when that delay occurs. If the
learner expects the timeframe of the causal mechanism to be                 3
                                                                              The resulting case distribution (N = 100) was: 51 cases with
noisy, then the model reduces the salience of C—captured
                                                                         ABCD; 13 AB¬CD; 13 ABC¬D; 3 AB¬C¬D; and 20 A¬B¬C¬D.
in the learning rate α—as a potential cause of E in                         4
                                                                              The messages always appeared in the same order within
proportion to derr = dE-C – dtyp. We define a learning rate αʹ′          conditions: A-B-D-C in Condition 2, A-D-C-B in Condition 3, and
                                                              −
                                                                derr     A-B-CD (C and D simultaneous) in Condition 4.
that decreases exponentially as derr increases: α ' = α e s ,               5
                                                                              R2 = 1 – (SSerr / SStot), where SSerr and SStot are the sum of
where s is a scaling parameter that determines how                       squared differences between the participant endorsement
sharply αʹ′ drops off as derr increases.                                 frequencies and the model proportion or mean endorsement,
                                                                         respectively.
                                                                     2532

       Figure 5: Proportion of causal relation endorsements by the LPL model, Bayesian model, and experimental participants
  endorsed CR. The optimal model fit (R2 = .47) was with                    delay probabilities followed an exponential decay function:
  α = 0.1 and pcritical = 7 × 10-5.                                                       1 −
                                                                                                derr
     These parameter values were used for all subsequent                     P ( dE−C ) =    e   s
                                                                                          2s         .6
  simulations. Model results for conditions 2-4 thus provide
  cross-validation for those parameter values. We set dtyp = 1,                This adjustment introduces a new free parameter, s, that
€ as the natural temporal delay between a computer sending a                was estimated by maximizing model fit across conditions 2-
  text message and one receiving it would be one time-step.                 4 (s = 2, R2 = .23). To determine Bayesian model
  We then searched and found that s = 7 optimized model fit                 predictions, we assumed that people probability match: the
  across conditions 2-4 (R2 = .47).                                         proportion of “Bayesian endorsements” for each causal
                                                                            relation CR was simply the posterior probability of CR.
  Bayesian Model
  We compare the LPL model to a standard Bayesian model                     Results and Discussion
  of causal structure learning. The model used a uniform prior              Figure 5 shows the LPL and Bayesian model predictions, as
  over all possible graphs (cyclic and acyclic) over the four               well as the actual participant data. R2 values for the models
  variables. The posterior probability of a graph H given the j-            for each condition are shown in Table 1.
  th datapoint is:
                                                                                             Table 1: R2 values for the models
                    (      )
                   P Hi d j =
                                 (                   )
                                P d j H i , do(A) P( H i )
                                          P dj( )                                                       LPL Model    Bayesian Model
  If tV denotes the time of V, then the likelihood is given by:                       Condition 1          .47              -.037
                                                                                      Condition 2          .40               .81
     (               )
   P d j H i , do(A) = P(b,c, d, t B , tC , t D H i , do(A))
                                                                                      Condition 3          .46              -1.01
      €         = P(b,c,d H i ,do(A)) P( t B ,tC ,t D b,c,d,H i ,do(A))               Condition 4          .59               .36
  Participants were told the true parameterization, so we use                         Overall              .47               .23
€ that distribution to calculate P(b,c,d H i ,do(A)) . For
                                                                            The LPL model explains roughly half the variance in
  temporal
  €            sequences, the Bayesian model also assumed that              participant responses across all conditions, whereas the
                                                                            Bayesian model fit varies widely. Moreover, the Bayesian
                               €                                            model does much worse than the LPL model in Condition 1
                                                                               6
                                                                                  The probability of a temporal sequence is complicated for
                                                                            cyclic graphs, as one must consider multiple ways to generate a
                                                                            temporal sequence. Technical details are available upon request.
                                                                               7
                                                                                 If R2 < 0 then the mean predicts more variance than the model.
                                                                        2533

(i.e., with no temporal information), suggesting that the              associations in humans: fMRI evidence in favor of an
modification of the Bayesian model to allow for temporal               associative model of learning. Neuron, 44(5), 877-888.
delays does not explain the poor fit.                                Danks, D., Griffiths, T. L., & Tenenbaum, J. B. (2003).
   At the same time, both models provide good qualitative              Dynamical causal learning. In S. Becker, S. Thrun, & K.
fits to the data: the model-participant correlations are r = .74       Obermayer (Eds.), Advances in neural information
for the LPL model and r = .97 for the Bayesian model.                  processing systems 15 (pp. 67-74). Cambridge, MA: MIT
However, only the LPL model predicts the appropriate                   Press.
variability in the participants’ responses. For instance, the        Fernbach, P. M., & Sloman, S. A. (2009). Causal learning
data are sufficient in Condition 1 for a Bayesian learner to           with local computations. Journal of Experimental
determine the true causal structure (except for D→B and                Psychology: Learning, Memory, and Cognition, 35(3),
C→B, about which it is indifferent), and so even probability           678.
matchers should exhibit relatively little variation. However,        Glymour, C. (2003). Learning, prediction and causal Bayes
many experimental participants select causal relations that            nets. Trends in Cognitive Sciences, 7(1), 43-48.
are not part of the true structure, and some omit relations          Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E.,
that are. Participants do not seem to be fully rational                Kushnir, T., & Danks, D. (2004). A theory of causal
learners, and the LPL model is able to explain the types of            learning in children: Causal maps and Bayes nets.
errors that occur.                                                     Psychological Review, 111(1), 1-31.
                                                                     Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure and
                         Conclusion                                    strength in causal induction. Cognitive Psychology, 51(4),
                                                                       334-384.
The LPL model aims to provide a formal algorithmic model
                                                                     Lagnado, D. A., & Sloman, S. A. (2006). Time as a guide to
of the mechanisms underlying covariation-based causal
                                                                       cause. Journal of Experimental Psychology: Learning,
structure learning. It provides a computationally well-
                                                                       Memory, and Cognition, 32(3), 451-460.
specified dynamical model that learns directed graphs, and
                                                                     Lagnado, D. A., Waldmann, M. R., Hagmayer, Y., &
so potentially captures the cognitive mechanisms underlying
                                                                       Sloman, S. A. (2007). Beyond covariation. In A. Gopnik,
causal learning. Moreover, this model predicts some of the
                                                                       & L. Schultz (Eds.), Causal learning: Psychology,
sub-optimal learning behaviour exhibited by participants.
                                                                       philosophy, and computation, 154-172.
Open questions remain about, for example, the suitability of
                                                                     Sloman, S. A. (2005). Causal models: How people think
the t-test-based decision procedure. But the LPL model
                                                                       about the world and its alternatives. New York: Oxford
provides a model that bridges the gap between associationist
                                                                       University Press.
and rational models of causal learning.
                                                                     Sloman, S., & Lagnado, D. A. (2005). Do we ‘do’.
                                                                       Cognitive Science, 29, 5-39.
                     Acknowledgments                                 Spirtes, P., Glymour, C. N., & Scheines, R. (1993).
This research was partially supported by a Scholar Award               Causation, prediction, and search. Cambridge, MA: The
from the James S. McDonnell Foundation.                                MIT Press.
                                                                     Steyvers, M., Tenenbaum, J. B., Wagenmakers, E. J., &
                         References                                    Blum, B. (2003). Inferring causal networks from
Bonawitz, E., Denison, S., Chen, A., Gopnik, G., &                     observations and interventions. Cognitive Science, 27(3),
   Griffiths, T. L. (2011). A simple sequential algorithm for          453-489.
   approximating Bayesian inference. Proceedings of the              Turner, D. C., Aitken, M. R. F., Shanks, D. R., Sahakian, B.
   Thirty-third Cognitive Science Society.                             J., Robbins, T. W., & Schwarzbauer, C. (2004). The role
Buehner, M. J., & May, J. (2003). Rethinking temporal                  of the lateral frontal cortex in causal associative learning:
   contiguity and the judgement of causality: Effects of prior         Exploring preventative and super-learning. Cerebral
   knowledge, experience, and reinforcement procedure. The             Cortex, 14(8), 872-880.
   Quarterly Journal of Experimental Psychology: Section             Waldmann, M. R. (1996). Knowledge-based causal
   A, 56(5), 865-890.                                                  induction. Psychology of Learning and Motivation, 34,
Buehner, M. J., & McGregor, S. (2006). Temporal delays                 47-88.
   can facilitate causal attribution: Towards a general              Waldmann, M. R., Cheng, P. W., Hagmayer, Y., &
   timeframe bias in causal induction. Thinking &                      Blaisdell, A. P. (2008). Causal learning in rats and
   Reasoning, 12(4), 353-378.                                          humans: A minimal rational model. In N. Chater, & M.
Cheng, P. W. (1997). From covariation to causation: A                  Oaksford, The Probabilistic Mind: Prospects for
   causal power theory. Psychological review, 104(2), 367-             Bayesian Cognitive Science. Oxford: Oxford University
   405.                                                                Press.
Corlett, P. R., Aitken, M. R. F., Dickinson, A., Shanks, D.          Waldmann, M. R., & Hagmayer, Y. (2005). Seeing versus
   R., Honey, G. D., Honey, R. A. E. (2004). Prediction                doing: Two modes of accessing causal knowledge.
   error during retrospective revaluation of causal                    Journal of Experimental Psychology: Learning, Memory,
                                                                       and Cognition, 31(2), 216-227.
                                                                 2534

