UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automatic Detection of Metonymies using Associative Relations between Words
Permalink
https://escholarship.org/uc/item/6jn3z5qz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Teraoka, Takehiro
Higashinaka, Ryuichiro
Okamoto, Jun
et al.
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

   Automatic Detection of Metonymies using Associative Relations between Words
                                             Takehiro Teraoka (teraoka@sfc.keio.ac.jp)
                                       Graduate School of Media and Governance, Keio University,
                                                5322 Endoh, Fujisawa, Kanagawa, Japan
                                 Ryuichiro Higashinaka (higashinaka.ryuichiro@lab.ntt.co.jp)
                                            NTT Cyber Space Laboratories, NTT Corporation,
                                          1-1 Hikarinooka Yokosuka, Kanagawa 239-0847 Japan
                                                 Jun Okamoto (juno@kaetsu.ac.jp)
                                          Department of Business Innovation, Kaetsu University,
                                     2-8-4 Hanakoganeiminamicho, Kodaira, Tokyo 187-0003, Japan
                                               Shun Ishizaki (ishizaki@sfc.keio.ac.jp)
                                       Graduate School of Media and Governance, Keio University,
                                                5322 Endoh, Fujisawa, Kanagawa, Japan
                               Abstract
                                                                       Table 1: Metonymic expressions with spatial contiguity and
   It is crucial for computers to detect metonymic expressions be-     temporal contiguity.
   cause sentences including them may have different meanings
   from literal ones. In previous studies, detecting metonymies          Metonymic patterns         Examples of sentences
   has been done mainly by rule-based and statistical approaches.        -spatial contiguity-       (metonymic reading)
   The problem of current metonymy detection is that using syn-          Container for Content      kare-ha glass-wo nonda
   tactic and semantic information may be not enough to de-                                         ‘He drank the glass (liquid).’
   tect metonymic expressions. In this study, we propose an              Producer for Product       kare-ha Mahler-wo kiita
   approach for detecting them with associative information be-                                     ‘He listened to Mahler (symphony).’
   tween words. We evaluated our method by comparing it with             Controller for Controlled  Nixon-ga Hanoi-wo bakugekishita
   a baseline that uses syntactic and semantic information. As a                                    ‘Nixon (government) bombed Hanoi.’
   result, our method showed significantly better accuracy (0.84)        Object Used for User       gakuseifuku-ga aruiteiru
   of judging words as metonymic or literal expressions than that                                   ‘The school uniform (student)
   of the baseline.                                                                                 is walking.’
   Keywords: Metonymy; Association Experiment; Associative               Material for Product       kare-ha caffeine-wo nonda
   Concept Dictionaries; Verbs; Nouns                                                               ‘He drank caffeine (soft drink).’
                                                                         Others                     riron-ga sore-wo jisshoushita
                          Introduction                                                              ‘The theory (proposer) claimed that.’
                                                                         Metonymic patterns         Examples of sentences
Metonymy is a figure of speech, where one item’s name                    -temporal contiguity-      (metonymic reading)
represents another which usually has a close relation with               Result for Cause           kanojo-ga sekimensuru
the first one. The metonymic relation, as shown in Table                                            ‘She is blushing.’(She is ashamed)
                                                                         Cause for Result           kare-ga sakazuki-wo katamukeru
1 (Lakoff & Johnson, 1980; Taniguchi, 2003; Yamanashi,                                              ‘He is tipping the sake cup.’
1988), has different patterns which are classified predomi-                                         (He is drinking the Japanese sake)
nately into two types: spatial contiguity and temporal con-
tiguity (Taniguchi, 2003). Below is a Japanese example for
‘Container for Content’:                                                  In English metonymy detection, most previous studies
   kare-ga isshoubin-wo nomihoshita                                    have taken mainly rule-based and statistical approaches.
   (He drank up a 1.8-liter bottle.)                                   The rule-based approach uses semantic networks and hand-
                                                                       crafted rules to detect metonymies (Bouaud, Bachimont,
   The Japanese sentence above means literally that he drank           & Zweigenbaum, 1996; Fass, 1991; Iverson & Helmre-
up the bottle. Of course, it does not mean that he drank or            ich, 1992). The representative work of statistical approach
ate the bottle itself, but its content, usually Japanese sake.         used corpus-based metonymy resolution on location names
Japanese sake is generally in a large bottle made from glass,          (Markert & Nissim, 2003). Moreover, by using syntactic,
and called bin in Japanese. It has a capacity of 1.8 liters,           semantic, encyclopedic, or collocation information as ma-
isshou. Therefore, the above example sentence where is-                chine learning features, some conventional studies for detect-
shoubin is a metonymic expression means that he drank up               ing metonymic expressions were suggested (Markert & Nis-
Japanese sake in a 1.8-liter bottle. Since a sentence includ-          sim, 2007; Nastase & Stube, 2009). Their methods are effec-
ing metonymy is grammatically correct on a literal level, it is        tive, but they only dealt with metonymies on country names
difficult for computers to grasp its true meaning as humans            and companies. When considering the variety of metonymic
do.                                                                    patterns in Table 1, it is desirable to be able to detect various
                                                                   2417

                                                                      (Morita, 1989). We prepared ten semantic relations shown
       Table 2: Semantic relations used in experiments.
                                                                      in Table 2: Agent, Object, Source, Goal, Duration, Location,
  Semantic relation   Content                                         Tool, Aspect, Reason, and Purpose. The experiment partici-
  Agent               Subject of an action                            pants were requested to give associated words of the stimulus
  Object              Object of an action                             words with these semantic relations.
  Source              Source of an action
  Goal                Goal or end of an action                        Quantification of Word Distances We used the linear pro-
  Duration            Time or term of an action
  Location            Location or space during an action              gramming method to calculate distances between stimulus
  Tool                Tool or material of an action                   words and associated ones. As shown in Eq. (1), the dis-
  Aspect              Aspect, degree or frequency of an action        tance D(x, y) between the stimulus word x and the associated
  Reason              Reason or cause of an action
  Purpose             Purpose of an action                            word y is expressed with the following formulae:
metonymies. In Japanese, although with small data sets, the                                            7             1
                                                                                        D(x, y) =        IF(x, y) + S(x, y)       (1)
manually constructed case frame dictionary and Goi-Taikei—                                            10             3
A Japanese Lexicon (Ikehara et al., 1999), which consist of                                                N
                                                                               where IF(x, y) =                   ,               (2)
syntactic and semantic information, have been used for de-                                            n(x, y) + δ
tecting various metonymies (Murata, Yamamoto, Kurohashi,                                              N
                                                                                              δ =         − 1(N ≥ 10),            (3)
Isahara, & Nagao, 2000; Suga & Ishizaki, 2006).                                                       10
   The problem of current metonymy detection is that using                                               1
                                                                                                      n(x, y) ∑i=1
                                                                                                                n(x,y)
                                                                                        S(x, y) =                      si (x, y). (4)
syntactic and semantic information may not be enough to
detect metonymic expressions because in our daily conver-
sations and readings we understand metonymic expressions                 The distance consists of the inverse of frequency of an as-
in sentences by using associative relations between words             sociated word IF(x, y) in Eq. (2) and the average of the as-
unconsciously. As Yamanashi described (Yamanashi, 1987,               sociated word order S(x, y) in Eq. (4). Each coefficient was
1988), metonymic relations relate to psychological associa-           obtained by using the Simplex Method. Let N denote the
tion; we consider that computers also need associative infor-         number of participants in the experiments, and n(x, y) denote
mation to improve the accuracy of metonymy detection.                 the number of participants who responded with the associated
   By using our associative concept dictionaries for verbs            word y to the stimulus word x. Let δ in Eq. (3) denote a fac-
and nouns (hereinafter referred to as Verb-ACD and Noun-              tor which limits IF(x, y) to a certain numerical level when N
ACD, respectively) (Okamoto & Ishizaki, 2001; Teraoka,                increases. Let s(x, y) denote the associated word’s order of
Okamoto, & Ishizaki, 2010), our previous study proposed an            each participant.
approach to metonymy detection with associative information              Each semantic relation of two words is expressed by each
and showed its effectiveness (Teraoka, Okamoto, & Ishizaki,           distance where the smaller the distance is, the closer two
2011). In this study, we focus on detecting only metonymic            words are. For example, when a stimulus verb is the Japanese
expressions of the spatial contiguity type as our first step, and     word, aruku ‘walk’ and the semantic relation is Source, one
enhance our approach by using decision tree learning.                 of the associated words is ie ‘home’ of which the distance is
                                                                      1.38. Meanwhile, the distance between walk and kaisha ‘of-
                    ACD Construction                                  fice’ is 9.92. The relation of these distances thus expresses
In this section, we describe the Verb-ACD and the Noun-ACD            a degree of association from the verb with the semantic rela-
that we use to extract associative information for detecting          tion.
metonymic expressions.                                                   Currently, there are 345 stimulus verbs in the Verb-ACD
                                                                      and the number of all participants is approximately 1,300.
Verb-ACD
                                                                      The participants were undergraduates and graduate students
The Verb-ACD (Teraoka et al., 2010) consists of the follow-           of Keio University. Each stimulus verb was presented to 40
ing three elements: stimulus words, associated words from             participants. There were approximately 135,000 associated
the stimulus words with semantic relations, and word dis-             words. When all overlapping words were eliminated, there
tances among them. The stimulus words are basic verbs with            were 30,000 associated words.
semantic relations that corresponded to deep cases. We quan-
tify word distance between the stimulus word and the associ-          Noun-ACD
ated one.
                                                                      The Noun-ACD consists also of stimulus words, i.e., nouns,
Association Experiments To collect associative informa-               associated words with semantic relations, and word distances
tion on verbs, we conducted large-scale association exper-            among these words (Okamoto & Ishizaki, 2001). Table 3
iments on the web. The stimulus words were verbs from                 shows the semantic relations and examples when the stimu-
Japanese elementary school textbooks, and we prioritized 200          lus word is a Japanese word jisho ‘dictionary’. Currently, the
of them that were entry words in a basic Japanese dictionary          number of the stimulus words in the Noun-ACD is 1,100 and
                                                                  2418

                                                                         and a particle corresponding to the semantic relation in Ta-
Table 3: Examples of associated words in the Noun-ACD
                                                                         ble 2 are extracted from the Verb-ACD. If the sentence
 when the stimulus word is ‘dictionary’.
                                                                         has more than one particle, the system extracts associated
   Semantic relation   Examples of associated words                      words from each noun with the particle. If the predicate
   Hypernym            shuppanbutsu ‘Publication’, hon ‘Book’            is anything except a verb, two stimulus words of the noun
   Hyponym              
                       waeijisho ‘Japanese-English dictionary’           as an associated word with the semantic relation Attribute
   Part / Material     midashigo ‘Entry word’
   Attribute           muzukashii ‘Difficult’, yasashii ‘Easy’           in Table 3 are extracted from the Noun-ACD. In the same
   Synonym             jiten ‘Encyclopedia’                              manner as the case with the predicate verb, these word dis-
   Action              yomu ‘Read’, shiraberu ‘Investigate’              tances are the shortest and the second-shortest ones be-
   Situation           toshokan ‘Library’, honya ‘Book store’
                                                                         tween the predicate, i.e., the associated and the stimulus
                                                                         word.
the number of participants is 50. The total number of asso-
                                                                     3. Extraction of Noun Information. The system extracts
 ciated words is approximately 280,000. When all of overlap-
                                                                         synsets and hypernym synsets of all nouns in the sentence
ping words are eliminated, the number of associated words is
                                                                         from the Japanese WordNet. These hypernym synsets are
 about 64,000.
                                                                         all synsets which the system obtains from nouns in the sen-
    Proposed Method for Detecting Metonymies                             tence to each third upper level for the synset hierarchy.
                                                                         If there are proper nouns in the sentence, it extracts each
To detect metonymic expressions in sentences, we use asso-               synset of properties which are from the result of the mor-
 ciative information between words in the Verb-ACD and the               phological analysis because the Japanese WordNet does
Noun-ACD. Our proposed method extracts attribute values of               not have enough synsets of proper nouns. For example,
 input sentences and detects metonymic expressions with deci-            if one of the proper nouns in the sentence in Table 1 is
sion tree learning. We first describe our basic idea, and then,          hanoi ‘Hanoi’, the system extracts sysnsets and hypernym
 the attributes of decision tree learning.                               synsets of chiiki ‘LOCATION’ which is a property from
Basic Idea for Metonymy Detection                                        the result of morphological analysis.
 Semantic relations between metonymic expressions and their          4. Confirmation of Shared Synset. By comparing synsets
predicates seem to be more unnatural than that of literal ex-            and hypernym synsets of the associated words with those
 pressions and their predicates. Hence, it is natural for humans         of nouns or the properties of proper nouns in the sentence,
to associate more literal expressions from predicates than               the system confirms whether a shared synset node is be-
 metonymic ones. Our basic idea therefore is that the degree             tween both paths of synset nodes. If there are one or more
of word distances in the Verb-ACD and the Noun-ACD can                   shared synsets, the system judges the noun as ‘Literal’.
 express the measures of judging expressions as ‘Metonymic’              On the other hand, if there is no shared synset, the system
or ‘Literal’.                                                            judges it as ‘Metonymic’.
    A method based on the basic idea is detecting metonymic
expressions with associative information by using relations of        The system thus decides on the correct category,
 two paths of synset nodes in the Japanese WordNet (Isahara,          ‘Metonymic’ or ‘Literal’, of every noun in input sentences
Bond, Uchimoto, Utiyama, & Kanzaki, 2008). One is the                 and can detect metonymies with associative information.
 path from synsets of associated words to their hypernym              Metonymy Detection using Decision Tree Learning
synsets. The other is from synsets of each word in a sentence
                                                                      We prepared attributes shown in Table 4 for the decision tree
 to their hypernym synsets. If there is a shared synset node
                                                                      learning. These attributes are all factors obtained in the basic
between these two paths, the word in the sentence is regarded
                                                                      idea.
 as a literal expression. On the other hand, it is possible to
                                                                         Semantic relation represents semantic relations corre-
be a metonymic expression if there is no shared synset. Our
                                                                      sponding to particles with nouns in sentences. In addition,
 system outline consists of four steps:
                                                                      one of its values ‘Noun’ was used when the predicate was not
1. Morphological and Syntactic Analyses. The system ana-              a verb. Distance 1st candidate and Distance 2nd candidate
    lyzes an input sentence morphologically and syntactically         were the shortest word distance and the second one be-
    by using MeCab and CaboCha, respectively.                         tween the predicate and the associated word, respectively.
                                                                      Number A synset and Num A hypernym were the number
2. Extraction of Associative Information. From the results            of synsets of the associated words and the sum of hyper-
    of morphological and syntactic analyses, the system ex-           nym synsets from the synsets for three upper levels, respec-
    tracts a predicate in the sentence and its modification rela-     tively. Num N synset and Num N hypernym were also the
    tions. When the predicate is a verb or a verbal noun fol-         number of synsets of nouns in the sentence and the sum of
    lowed by suru, e.g., taiho-suru ‘arrest (verb)’ where suru        hypernym synsets for three upper levels. Num HN synset
    added to taiho ‘arrest (noun)’, the shortest and the second-      and Num HN hypernym were the number of synsets of the
    shortest associated words from a pair of the predicate verb       noun’s hypernyms and the sum of hypernym synsets of the
                                                                  2419

                                     Table 4: Attributes and values with decision tree learning.
                 Attribute                  Description                                     Value
                 Semantic relation          Semantic relations corresponding to             Agent, Object, Source, Goal,
                                            particles with nouns in a sentence              Location, Tool, Noun
                 Distance 1st candidate     The shortest word distance between              Continuous
                                            the predicate and associated words
                 Distance 2nd candidate     The second shortest word distance between       Continuous
                                            the predicate and associated words
                 Number A synset            The number of synsets of associated words       Continuous
                 Number A hypernym          The sum of hypernym synsets from the            Continuous
                                            associated words for three upper levels
                 Number N synset            The number of synsets of nouns in a sentence    Continuous
                 Number N hypernym          The sum of hypernym synsets from the            Continuous
                                            nouns for three upper levels
                 Number HN synset           The number of synsets of hypernyms of           Continuous
                                            nouns in a sentence
                 Number HN hypernym         The sum of hypernym synsets of hypernyms        Continuous
                                            of the nouns in a sentence
                 Match node                 The degree of linked nodes from each            None, Near, Middle-Near,
                                            synset of the associated words and the          Middle, Middle-Far, Far
                                            nouns in a sentence to a shared synset
hypernyms for two upper levels to equalize hypernym lev-                indicates an order of preference in the Goi-taikei. The pref-
els from initial synsets as above, i.e., three upper levels. Let        erence order was defined in order to translate from Japanese
Match node denote the degree of linked synset nodes from                to English or from English to Japanese (Shirai, Ooyama, Ike-
each synset of the associated words and the nouns in the sen-           hara, Miyazaki, & Yokoo, 1998). The syntactic information
tence to the shared synset. By using the sum number of linked           on each verb is a set of syntactic type and noun properties,
nodes, this degree was separated to the following six levels:           and expresses that each verb has nouns with a part of speech.
‘None’, ‘Near’, ‘Middle-Near’, ‘Middle’, ‘Middle-Far’, and              The baseline system then obtains nouns in the syntactic in-
‘Far’. ‘None’ means that there was no shared synset, i.e., the          formation and their properties. These noun properties consist
noun was judged as ‘Metonymic’. ‘Near’ means that either                of some nouns and are expressed by the hypernyms and hy-
of the synset of the associated word or that of the noun in the         ponyms in the noun semantic hierarchy. Finally, the system
sentence was just the shared synset at least, i.e., the sum of          judges the word as ‘Metonymic’ if each word in the sentence
linked nodes was 0 or 1. ‘Middle-Near’ means that the aver-             does not belong to the noun’s hyponyms in the hierarchy.
age of each node was 1, i.e., the sum of linked nodes was 2.
‘Middle’ means that the sum of linked nodes was 3. ‘Middle-             Test Sentences
Far’ means that the average of each node was between 2 and              We prepared 90 test sentences which consisted of 45 ones
3. ‘Far’ means that the average of each node was more than              with metonymic expressions and 45 ones with literal expres-
3, i.e., the sum of linked node was more than 6.                        sions. As shown in Table 5, most of the former sentences
                                                                        were extracted from the previous studies (Murata et al., 2000;
                         Experiment                                     Yamanashi, 1988). The latter were extracted from newspaper
To evaluate our method, we prepared a baseline system where             corpora of the Mainichi Newspaper (’93–’95 and ’03–’04)
the Goi-Taikei—A Japanese Lexicon (Ikehara et al., 1999)                and included words used in the metonymic sentences. In 90
was used to automatically detect metonymies. We prepared                test sentences, there were 113 nouns which both our method
test sentences with literal and metonymic expressions and               and the baseline judged as ‘Metonymic’ or ‘Literal’.
evaluated our method by comparing its recall, precision, and
F-measure rates with those of the baseline. In this section,            Results and Discussion
we describe the baseline, test sentences, and the evaluation            To judge each noun as ‘Metonymic’ or ‘Literal’, we extracted
results.                                                                attributes from 90 test sentences and constructed 113 cases.
                                                                        We trained 112 cases, tested the other case with the training
Baseline System                                                         data, and repeated this procedure in a round-robin fashion. By
The baseline system consisted of syntactic structures and               running 113 folds, each case was judged as ‘Metonymic’ and
noun properties in the Goi-Taikei, which was used for detect-           ‘Literal’. From Table 6, we can see that our method judged
ing metonymies (Murata et al., 2000). It first selects a syntac-        correctly 95 cases and the baseline system did 81 cases cor-
tic type of the predicate using its syntactic information in the        rectly. Our method showed higher accuracy (0.84) than that
Goi-Taikei after morphological and syntactic analyses of an             of the baseline. There was significant difference (p < 0.05)
input sentence. It employs the highest priority order of syn-           between them. Here, the statistical difference was deter-
tactic information in each predicate verb because this order            mined by McNemar’s test. The evaluation measurements
                                                                   2420

                                          Table 5: Examples of test sentences (in Japanese).
                       Metonymic sentence (English translation)         Literal sentence (English translation)
                       isshoubin-wo nonda                               isshoubin-wo saidan-ni oita
                       (Someone drank the issho-bottle.)                (He places the issho-bottle on the altar.)
                       kasetsu-ga genri-wo setsumei-suru                kankeisha-ga setsumei-shita
                       (The hypothesis explains the elements.)          (People involved explained that.)
                       shirobai-ga ihansha-wo taiho-shita               keisatsukan-ga hanzaisha-wo taiho-shita
                       (The police motorcycle arrested the criminals.)  (The police man arrested the criminals.)
                       shikisha-ha sono-clarinet-wo waratta             jibun-wo waratta
                       (The conductor laughed at the clarinet.)         (Someone laughed about oneself.)
                       kao-wo soru                                      hige-wo soru
                       (Someone shaves own face.)                       (Someone shaves a beard.)
                       atama-wo karu                                    tanbo-de ine-wo karu
                       (Someone clips own head.)                        (Someone mows rice plants in the paddies.)
                                                                                                                                        
Table 6: Accuracy in judging whether metonymic expres-                     Match_node in {None,Far}: Metonymic (32/5)
sions or literal meanings. Asterisk indicates statistical sig-             Match_node in {Near,Middle}: Literal (43/6)
nificance over baseline. (* p < 0.05)                                      Match_node = Middle-Near:
                                                                           :...Distance_2nd_candidate <= 2.74: Metonymic (3)
                       Baseline        Proposed method                     :    Distance_2nd_candidate > 2.74: Literal (8)
           Accuracy    0.72 (81/113)   0.84 (95/113)*                      Match_node = Middle-Far:
                                                                           :...Number_S_hypernym <= 19: Literal (22/4)
                                                                                Number_S_hypernym > 19: Metonymic (5)
                                                                                                                                        
Table 7: Precision, recall, and F-measure rates in detecting
metonymic expressions.                                                      Figure 1: Result of decision tree learning in 113 cases.
                        Baseline       Proposed method
           Precision    0.63 (31/49)   0.85 (33/39)
           Recall       0.69 (31/45)   0.73 (33/45)                    are more synsets of abstract nouns in higher levels hence it
           F-measure    0.66           0.79
                                                                       is natural to be judged as ‘Metonymic’ in ‘Far’ where the
                                                                       matching synset is at higher levels in the mean. On the other
                                                                       hand, it is also natural to be judged as ‘Literal’ in ‘Near’ or
were recall, precision, and F-measure calculated by using the          ‘Middle’. From these, the sum of both the synset node from
numbers of correct detections above. Our method expressed              associated words and that from nouns indicates the measures
higher recall (0.73), precision (0.85), and F-measure (0.79)           of detecting metonymies.
than those of the baseline system as shown in Table 7.                     Given an example of the results, when an input Japanese
   The two main reasons for our method’s superiority are as            sentence was shikisha-ha sono-clarinet-wo waratta ‘The con-
follows. First, there were differences between our method              ductor laughed at the clarinet.’ in Table 5, our method judged
and the baseline in the way that knowledge was used. As de-            ‘clarinet’ as ‘Metonymic’ while the baseline could not. In the
scribed previously, the baseline used the highest priority order       Verb-ACD, the associated words whose distances were espe-
of syntactic information in each predicate. The priority order         cially short were hito ‘human’ and telebi-bangumi ‘TV pro-
in the Goi-Taikei was defined as preference to translate, so it        gram’. Therefore, it extracted these associated words, their
seemed to express the order of frequency of its usage (Shirai          synsets, and hypernym synsets from Japanese WordNet. It
et al., 1998). From these, the baseline system used the highest        then compared them with ‘clarinet’ and its synset expressed
frequency of syntactical information of the predicates. On the         by music instruments. Since the extracted words and their
other hand, information on the predicates which our method             synsets did not match ‘clarinet’ and or its synset, the ex-
used was short word distances between them and their asso-             pression was judged as ‘Metonymic’. Meanwhile, the base-
ciated words in the Verb-ACD and the Noun-ACD. From the                line extracted syntactic information of the following predicate
results, it seemed to be more suitable to use the associative in-      verb ‘laugh’ from the Goi-Taikei: “N1 laughs at N2” where
formation of predicates. The second reason is that separating          noun properties of “N1” and “N2” were hito ‘human’ and as-
stages of Match node was a good way to detect metonymies.              terisk ‘all properties’, respectively. The property of ‘clarinet’
Here, to investigate the detail of our method, we show the             was gakki ‘instrument’ and belonged to “N2” whose prop-
result of the decision tree learning in training 113 cases in          erty was asterisk ‘all properties’. As a result, the baseline
Figure 1. As shown in the figure, Match node in ‘None’ or              system judged ‘clarinet’ as ‘Literal’. In general, we usually
‘Far’ was judged as ‘Metonymic’ and that in ‘Near’ or ‘Mid-            understand the meaning ‘The conductor laughed at the clar-
dle’ was done as ‘Literal’. As mentioned previously, ‘Far’             inet player’ when we read the sentence. Of course, it is not
means that the average of each node is more than 3. There              wrong syntactically that the conductor laughed at the instru-
                                                                   2421

ment of clarinet, but it is unnatural in daily conversations. Our     Lakoff, G., & Johnson, M. (1980). Metaphors We Live By.
method was closer to our associations in daily conversations            University of Chicago Press.
and more appropriate to detect metonymies than the baseline.          Markert, K., & Nissim, M. (2003). Corpus-Based Metonymy
We therefore conclude that using associative information can            Analysis. Metaphor and Symbol, 18(3), 175–188.
improve computer’s ability to detect metonymies as humans             Markert, K., & Nissim, M. (2007). Semeval-2007 task 08:
do.                                                                     Metonymy resolution at semeval-2007. In Proceedings
   However, our method incorrectly judged some literal ex-              of the 4th international workshop on semantic evaluations
pressions as ‘Metonymic’. The reason was that some associ-              (SemEval-2007) (pp. 36–41).
ated words in the Verb-ACD and those in their synsets in the          Morita, Y. (1989). A Dictionary of Basic Japanese.
Japanese WordNet were metonymies. Our method incorrectly                Kadokawa Gakugei Shuppan Publishing.
judged some metonymic expressions as ‘Literal because the             Murata, M., Yamamoto, A., Kurohashi, S., Isahara, H., & Na-
variety of associated words with the short word distances was           gao, M. (2000). Metonymy Interpretation Using the Exam-
sometimes too restricted. This small variety within the group           ples, “Noun X of Noun Y” and “Noun X Noun Y”. Journal
of associated words could have led to a smaller range in the            of Japanese Society for Artificial Intelligence, 15(3), 503–
search space of the Japanese WordNet, leading to the ten-               510. (in Japanese)
dency to detect too many metonymies.                                  Nastase, V., & Stube, M. (2009). Combining Collocations,
                                                                        Lexical and Encyclopedic Knowledge for Metonymy Res-
             Summary and Future Work                                    olution. In Proceedings of the 2009 Conference on Em-
We used the Verb-ACD and the Japanese WordNet to detect                 pirical Methods in Natural Language Processing (pp. 910–
metonymic expressions in sentences with associative infor-              918).
mation. We found that our method has a higher accuracy                Okamoto, J., & Ishizaki, S. (2001). Construction of As-
of judging ‘Metonymic’ or ‘Literal’, recall, precision, and F-          sociative Concept Dictionary with Distance Information,
measure of detecting metonymies than those of the baseline              and Comparison with Electronic Concept Dictionary. Jour-
that only uses syntactic and semantic information.                      nal of Natural Language Processing, 8(4), 37–54. (in
   Future work includes detecting metonymies for the tem-               Japanese)
poral contiguity and constructing a system for interpreting           Shirai, S., Ooyama, Y., Ikehara, S., Miyazaki, M., & Yokoo,
metonymic expressions. We would like to integrate them                  A. (1998). Introduction to Goi-Taikei: A Japanese Lexi-
into our current detection method to improve our analysis of            con. In Ipsj sig notes (pp. 47–52). (in Japanese)
metonymy.                                                             Suga, T., & Ishizaki, S. (2006). Construction of Metonymy
                                                                        Understanding System Using Associative Concept Dictio-
                    Acknowledgments                                     nary. In Proceeding of Annual Meeting of the Natural
This work has been partially supported by the Graduate                  Language Processing Society of Japan (nlp2006) (pp. 817–
School Doctorate Student Grant Aid Program 2011, Keio                   820). (in Japanese)
University. We would like to thank the students at Shonan             Taniguchi, K. (2003). New Developments of Cognitive
Fujisawa Campus of Keio University for their participation in           Semantics -Metaphor and Metonymy-. Kenkyusha. (in
the association experiments.                                            Japanese)
                                                                      Teraoka, T., Okamoto, J., & Ishizaki, S. (2010). An asso-
                           References                                   ciative concept dictionary for verbs and its application to
Bouaud, J., Bachimont, B., & Zweigenbaum, P. (1996).                    elliptical word estimation. In Proceedings of the 7th Inter-
  Processing metonymy: a Domain-Model Heuristic Graph                   national Conference on Language Resources and Evalua-
  Traversal Approach. In Proceedings of the 16th Interna-               tion (pp. 3851–3856).
  tional Conference on Computational Linguistics (Vol. 1,             Teraoka, T., Okamoto, J., & Ishizaki, S. (2011). Detecting
  pp. 137–142).                                                         metonymic expressions with associative information from
Fass, D. (1991). met*: A Method for Discriminating                      words. In Proceedings of the 12th Pacific Association for
  Metonymy and Metaphor by Computer. Computer Linguis-                  Computational Linguistics Conference, #13.
  tics, 17(1), 49–90.                                                 Yamanashi, M. (1987). Metonymic interpretation and asso-
Ikehara, S., Miyazaki, M., Shirai, S., Yokoo, A., Nakaiwa, H.,          ciative processes in natural language. In M. Nagao (Ed.),
  Ogura, K., et al. (1999). Goi-Taikei: A Japanese Lexicon              Language and artificial intelligence (pp. 77–86). Elsevier
  CD-ROM. Iwanami Shoten.                                               Science Publishers B.V. (North-Holland).
Isahara, H., Bond, F., Uchimoto, K., Utiyama, M., & Kan-              Yamanashi, M. (1988). Metonymy and Understanding. Uni-
  zaki, K. (2008). Development of Japanese WordNet. In                  versity of Tokyo Press. (in Japanese)
  Proceedings of the 6th International Conference on Lan-
  guage Resources and Evaluation (pp. 2420–2422).
Iverson, E., & Helmreich, S. (1992). Metallel: An Integrated
  Approach to Non-Literal Phrase Interpretation. Computa-
  tional Intelligence, 8(3), 477–493.
                                                                  2422

