UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automatic Detection of Metonymies using Associative Relations between Words

Permalink
https://escholarship.org/uc/item/6jn3z5qz

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Teraoka, Takehiro
Higashinaka, Ryuichiro
Okamoto, Jun
et al.

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Automatic Detection of Metonymies using Associative Relations between Words
Takehiro Teraoka (teraoka@sfc.keio.ac.jp)
Graduate School of Media and Governance, Keio University,
5322 Endoh, Fujisawa, Kanagawa, Japan

Ryuichiro Higashinaka (higashinaka.ryuichiro@lab.ntt.co.jp)
NTT Cyber Space Laboratories, NTT Corporation,
1-1 Hikarinooka Yokosuka, Kanagawa 239-0847 Japan

Jun Okamoto (juno@kaetsu.ac.jp)
Department of Business Innovation, Kaetsu University,
2-8-4 Hanakoganeiminamicho, Kodaira, Tokyo 187-0003, Japan

Shun Ishizaki (ishizaki@sfc.keio.ac.jp)
Graduate School of Media and Governance, Keio University,
5322 Endoh, Fujisawa, Kanagawa, Japan
Abstract

Table 1: Metonymic expressions with spatial contiguity and
temporal contiguity.

It is crucial for computers to detect metonymic expressions because sentences including them may have different meanings
from literal ones. In previous studies, detecting metonymies
has been done mainly by rule-based and statistical approaches.
The problem of current metonymy detection is that using syntactic and semantic information may be not enough to detect metonymic expressions. In this study, we propose an
approach for detecting them with associative information between words. We evaluated our method by comparing it with
a baseline that uses syntactic and semantic information. As a
result, our method showed significantly better accuracy (0.84)
of judging words as metonymic or literal expressions than that
of the baseline.
Keywords: Metonymy; Association Experiment; Associative
Concept Dictionaries; Verbs; Nouns

Metonymic patterns
-spatial contiguityContainer for Content
Producer for Product
Controller for Controlled
Object Used for User
Material for Product
Others

Introduction
Metonymy is a figure of speech, where one item’s name
represents another which usually has a close relation with
the first one. The metonymic relation, as shown in Table
1 (Lakoff & Johnson, 1980; Taniguchi, 2003; Yamanashi,
1988), has different patterns which are classified predominately into two types: spatial contiguity and temporal contiguity (Taniguchi, 2003). Below is a Japanese example for
‘Container for Content’:
kare-ga isshoubin-wo nomihoshita
(He drank up a 1.8-liter bottle.)
The Japanese sentence above means literally that he drank
up the bottle. Of course, it does not mean that he drank or
ate the bottle itself, but its content, usually Japanese sake.
Japanese sake is generally in a large bottle made from glass,
and called bin in Japanese. It has a capacity of 1.8 liters,
isshou. Therefore, the above example sentence where isshoubin is a metonymic expression means that he drank up
Japanese sake in a 1.8-liter bottle. Since a sentence including metonymy is grammatically correct on a literal level, it is
difficult for computers to grasp its true meaning as humans
do.

Metonymic patterns
-temporal contiguityResult for Cause
Cause for Result

Examples of sentences
(metonymic reading)
kare-ha glass-wo nonda
‘He drank the glass (liquid).’
kare-ha Mahler-wo kiita
‘He listened to Mahler (symphony).’
Nixon-ga Hanoi-wo bakugekishita
‘Nixon (government) bombed Hanoi.’
gakuseifuku-ga aruiteiru
‘The school uniform (student)
is walking.’
kare-ha caffeine-wo nonda
‘He drank caffeine (soft drink).’
riron-ga sore-wo jisshoushita
‘The theory (proposer) claimed that.’
Examples of sentences
(metonymic reading)
kanojo-ga sekimensuru
‘She is blushing.’(She is ashamed)
kare-ga sakazuki-wo katamukeru
‘He is tipping the sake cup.’
(He is drinking the Japanese sake)

In English metonymy detection, most previous studies
have taken mainly rule-based and statistical approaches.
The rule-based approach uses semantic networks and handcrafted rules to detect metonymies (Bouaud, Bachimont,
& Zweigenbaum, 1996; Fass, 1991; Iverson & Helmreich, 1992). The representative work of statistical approach
used corpus-based metonymy resolution on location names
(Markert & Nissim, 2003). Moreover, by using syntactic,
semantic, encyclopedic, or collocation information as machine learning features, some conventional studies for detecting metonymic expressions were suggested (Markert & Nissim, 2007; Nastase & Stube, 2009). Their methods are effective, but they only dealt with metonymies on country names
and companies. When considering the variety of metonymic
patterns in Table 1, it is desirable to be able to detect various

2417

(Morita, 1989). We prepared ten semantic relations shown
in Table 2: Agent, Object, Source, Goal, Duration, Location,
Tool, Aspect, Reason, and Purpose. The experiment participants were requested to give associated words of the stimulus
words with these semantic relations.

Table 2: Semantic relations used in experiments.
Semantic relation
Agent
Object
Source
Goal
Duration
Location
Tool
Aspect
Reason
Purpose

Content
Subject of an action
Object of an action
Source of an action
Goal or end of an action
Time or term of an action
Location or space during an action
Tool or material of an action
Aspect, degree or frequency of an action
Reason or cause of an action
Purpose of an action

Quantification of Word Distances We used the linear programming method to calculate distances between stimulus
words and associated ones. As shown in Eq. (1), the distance D(x, y) between the stimulus word x and the associated
word y is expressed with the following formulae:

metonymies. In Japanese, although with small data sets, the
manually constructed case frame dictionary and Goi-Taikei—
A Japanese Lexicon (Ikehara et al., 1999), which consist of
syntactic and semantic information, have been used for detecting various metonymies (Murata, Yamamoto, Kurohashi,
Isahara, & Nagao, 2000; Suga & Ishizaki, 2006).
The problem of current metonymy detection is that using
syntactic and semantic information may not be enough to
detect metonymic expressions because in our daily conversations and readings we understand metonymic expressions
in sentences by using associative relations between words
unconsciously. As Yamanashi described (Yamanashi, 1987,
1988), metonymic relations relate to psychological association; we consider that computers also need associative information to improve the accuracy of metonymy detection.
By using our associative concept dictionaries for verbs
and nouns (hereinafter referred to as Verb-ACD and NounACD, respectively) (Okamoto & Ishizaki, 2001; Teraoka,
Okamoto, & Ishizaki, 2010), our previous study proposed an
approach to metonymy detection with associative information
and showed its effectiveness (Teraoka, Okamoto, & Ishizaki,
2011). In this study, we focus on detecting only metonymic
expressions of the spatial contiguity type as our first step, and
enhance our approach by using decision tree learning.

ACD Construction
In this section, we describe the Verb-ACD and the Noun-ACD
that we use to extract associative information for detecting
metonymic expressions.

Verb-ACD
The Verb-ACD (Teraoka et al., 2010) consists of the following three elements: stimulus words, associated words from
the stimulus words with semantic relations, and word distances among them. The stimulus words are basic verbs with
semantic relations that corresponded to deep cases. We quantify word distance between the stimulus word and the associated one.
Association Experiments To collect associative information on verbs, we conducted large-scale association experiments on the web. The stimulus words were verbs from
Japanese elementary school textbooks, and we prioritized 200
of them that were entry words in a basic Japanese dictionary

D(x, y) =
where IF(x, y) =
δ =
S(x, y) =

1
7
IF(x, y) + S(x, y)
10
3
N
,
n(x, y) + δ
N
− 1(N ≥ 10),
10
1
n(x,y)
si (x, y).
n(x, y) ∑i=1

(1)
(2)
(3)
(4)

The distance consists of the inverse of frequency of an associated word IF(x, y) in Eq. (2) and the average of the associated word order S(x, y) in Eq. (4). Each coefficient was
obtained by using the Simplex Method. Let N denote the
number of participants in the experiments, and n(x, y) denote
the number of participants who responded with the associated
word y to the stimulus word x. Let δ in Eq. (3) denote a factor which limits IF(x, y) to a certain numerical level when N
increases. Let s(x, y) denote the associated word’s order of
each participant.
Each semantic relation of two words is expressed by each
distance where the smaller the distance is, the closer two
words are. For example, when a stimulus verb is the Japanese
word, aruku ‘walk’ and the semantic relation is Source, one
of the associated words is ie ‘home’ of which the distance is
1.38. Meanwhile, the distance between walk and kaisha ‘office’ is 9.92. The relation of these distances thus expresses
a degree of association from the verb with the semantic relation.
Currently, there are 345 stimulus verbs in the Verb-ACD
and the number of all participants is approximately 1,300.
The participants were undergraduates and graduate students
of Keio University. Each stimulus verb was presented to 40
participants. There were approximately 135,000 associated
words. When all overlapping words were eliminated, there
were 30,000 associated words.

Noun-ACD
The Noun-ACD consists also of stimulus words, i.e., nouns,
associated words with semantic relations, and word distances
among these words (Okamoto & Ishizaki, 2001). Table 3
shows the semantic relations and examples when the stimulus word is a Japanese word jisho ‘dictionary’. Currently, the
number of the stimulus words in the Noun-ACD is 1,100 and

2418

and a particle corresponding to the semantic relation in Table 2 are extracted from the Verb-ACD. If the sentence
has more than one particle, the system extracts associated
words from each noun with the particle. If the predicate
is anything except a verb, two stimulus words of the noun
as an associated word with the semantic relation Attribute
in Table 3 are extracted from the Noun-ACD. In the same
manner as the case with the predicate verb, these word distances are the shortest and the second-shortest ones between the predicate, i.e., the associated and the stimulus
word.

Table 3: Examples of associated words in the Noun-ACD
when the stimulus word is ‘dictionary’.
Semantic relation
Hypernym
Hyponym
Part / Material
Attribute
Synonym
Action
Situation

Examples of associated words
shuppanbutsu ‘Publication’, hon ‘Book’

waeijisho
‘Japanese-English dictionary’
midashigo ‘Entry word’
muzukashii ‘Difficult’, yasashii ‘Easy’
jiten ‘Encyclopedia’
yomu ‘Read’, shiraberu ‘Investigate’
toshokan ‘Library’, honya ‘Book store’

the number of participants is 50. The total number of associated words is approximately 280,000. When all of overlapping words are eliminated, the number of associated words is
about 64,000.

Proposed Method for Detecting Metonymies
To detect metonymic expressions in sentences, we use associative information between words in the Verb-ACD and the
Noun-ACD. Our proposed method extracts attribute values of
input sentences and detects metonymic expressions with decision tree learning. We first describe our basic idea, and then,
the attributes of decision tree learning.

Basic Idea for Metonymy Detection
Semantic relations between metonymic expressions and their
predicates seem to be more unnatural than that of literal expressions and their predicates. Hence, it is natural for humans
to associate more literal expressions from predicates than
metonymic ones. Our basic idea therefore is that the degree
of word distances in the Verb-ACD and the Noun-ACD can
express the measures of judging expressions as ‘Metonymic’
or ‘Literal’.
A method based on the basic idea is detecting metonymic
expressions with associative information by using relations of
two paths of synset nodes in the Japanese WordNet (Isahara,
Bond, Uchimoto, Utiyama, & Kanzaki, 2008). One is the
path from synsets of associated words to their hypernym
synsets. The other is from synsets of each word in a sentence
to their hypernym synsets. If there is a shared synset node
between these two paths, the word in the sentence is regarded
as a literal expression. On the other hand, it is possible to
be a metonymic expression if there is no shared synset. Our
system outline consists of four steps:
1. Morphological and Syntactic Analyses. The system analyzes an input sentence morphologically and syntactically
by using MeCab and CaboCha, respectively.
2. Extraction of Associative Information. From the results
of morphological and syntactic analyses, the system extracts a predicate in the sentence and its modification relations. When the predicate is a verb or a verbal noun followed by suru, e.g., taiho-suru ‘arrest (verb)’ where suru
added to taiho ‘arrest (noun)’, the shortest and the secondshortest associated words from a pair of the predicate verb

3. Extraction of Noun Information. The system extracts
synsets and hypernym synsets of all nouns in the sentence
from the Japanese WordNet. These hypernym synsets are
all synsets which the system obtains from nouns in the sentence to each third upper level for the synset hierarchy.
If there are proper nouns in the sentence, it extracts each
synset of properties which are from the result of the morphological analysis because the Japanese WordNet does
not have enough synsets of proper nouns. For example,
if one of the proper nouns in the sentence in Table 1 is
hanoi ‘Hanoi’, the system extracts sysnsets and hypernym
synsets of chiiki ‘LOCATION’ which is a property from
the result of morphological analysis.
4. Confirmation of Shared Synset. By comparing synsets
and hypernym synsets of the associated words with those
of nouns or the properties of proper nouns in the sentence,
the system confirms whether a shared synset node is between both paths of synset nodes. If there are one or more
shared synsets, the system judges the noun as ‘Literal’.
On the other hand, if there is no shared synset, the system
judges it as ‘Metonymic’.
The system thus decides on the correct category,
‘Metonymic’ or ‘Literal’, of every noun in input sentences
and can detect metonymies with associative information.

Metonymy Detection using Decision Tree Learning
We prepared attributes shown in Table 4 for the decision tree
learning. These attributes are all factors obtained in the basic
idea.
Semantic relation represents semantic relations corresponding to particles with nouns in sentences. In addition,
one of its values ‘Noun’ was used when the predicate was not
a verb. Distance 1st candidate and Distance 2nd candidate
were the shortest word distance and the second one between the predicate and the associated word, respectively.
Number A synset and Num A hypernym were the number
of synsets of the associated words and the sum of hypernym synsets from the synsets for three upper levels, respectively. Num N synset and Num N hypernym were also the
number of synsets of nouns in the sentence and the sum of
hypernym synsets for three upper levels. Num HN synset
and Num HN hypernym were the number of synsets of the
noun’s hypernyms and the sum of hypernym synsets of the

2419

Table 4: Attributes and values with decision tree learning.
Attribute
Semantic relation
Distance 1st candidate
Distance 2nd candidate
Number A synset
Number A hypernym
Number N synset
Number N hypernym
Number HN synset
Number HN hypernym
Match node

Description
Semantic relations corresponding to
particles with nouns in a sentence
The shortest word distance between
the predicate and associated words
The second shortest word distance between
the predicate and associated words
The number of synsets of associated words
The sum of hypernym synsets from the
associated words for three upper levels
The number of synsets of nouns in a sentence
The sum of hypernym synsets from the
nouns for three upper levels
The number of synsets of hypernyms of
nouns in a sentence
The sum of hypernym synsets of hypernyms
of the nouns in a sentence
The degree of linked nodes from each
synset of the associated words and the
nouns in a sentence to a shared synset

hypernyms for two upper levels to equalize hypernym levels from initial synsets as above, i.e., three upper levels. Let
Match node denote the degree of linked synset nodes from
each synset of the associated words and the nouns in the sentence to the shared synset. By using the sum number of linked
nodes, this degree was separated to the following six levels:
‘None’, ‘Near’, ‘Middle-Near’, ‘Middle’, ‘Middle-Far’, and
‘Far’. ‘None’ means that there was no shared synset, i.e., the
noun was judged as ‘Metonymic’. ‘Near’ means that either
of the synset of the associated word or that of the noun in the
sentence was just the shared synset at least, i.e., the sum of
linked nodes was 0 or 1. ‘Middle-Near’ means that the average of each node was 1, i.e., the sum of linked nodes was 2.
‘Middle’ means that the sum of linked nodes was 3. ‘MiddleFar’ means that the average of each node was between 2 and
3. ‘Far’ means that the average of each node was more than
3, i.e., the sum of linked node was more than 6.

Experiment
To evaluate our method, we prepared a baseline system where
the Goi-Taikei—A Japanese Lexicon (Ikehara et al., 1999)
was used to automatically detect metonymies. We prepared
test sentences with literal and metonymic expressions and
evaluated our method by comparing its recall, precision, and
F-measure rates with those of the baseline. In this section,
we describe the baseline, test sentences, and the evaluation
results.

Baseline System
The baseline system consisted of syntactic structures and
noun properties in the Goi-Taikei, which was used for detecting metonymies (Murata et al., 2000). It first selects a syntactic type of the predicate using its syntactic information in the
Goi-Taikei after morphological and syntactic analyses of an
input sentence. It employs the highest priority order of syntactic information in each predicate verb because this order

Value
Agent, Object, Source, Goal,
Location, Tool, Noun
Continuous
Continuous
Continuous
Continuous
Continuous
Continuous
Continuous
Continuous
None, Near, Middle-Near,
Middle, Middle-Far, Far

indicates an order of preference in the Goi-taikei. The preference order was defined in order to translate from Japanese
to English or from English to Japanese (Shirai, Ooyama, Ikehara, Miyazaki, & Yokoo, 1998). The syntactic information
on each verb is a set of syntactic type and noun properties,
and expresses that each verb has nouns with a part of speech.
The baseline system then obtains nouns in the syntactic information and their properties. These noun properties consist
of some nouns and are expressed by the hypernyms and hyponyms in the noun semantic hierarchy. Finally, the system
judges the word as ‘Metonymic’ if each word in the sentence
does not belong to the noun’s hyponyms in the hierarchy.

Test Sentences
We prepared 90 test sentences which consisted of 45 ones
with metonymic expressions and 45 ones with literal expressions. As shown in Table 5, most of the former sentences
were extracted from the previous studies (Murata et al., 2000;
Yamanashi, 1988). The latter were extracted from newspaper
corpora of the Mainichi Newspaper (’93–’95 and ’03–’04)
and included words used in the metonymic sentences. In 90
test sentences, there were 113 nouns which both our method
and the baseline judged as ‘Metonymic’ or ‘Literal’.

Results and Discussion
To judge each noun as ‘Metonymic’ or ‘Literal’, we extracted
attributes from 90 test sentences and constructed 113 cases.
We trained 112 cases, tested the other case with the training
data, and repeated this procedure in a round-robin fashion. By
running 113 folds, each case was judged as ‘Metonymic’ and
‘Literal’. From Table 6, we can see that our method judged
correctly 95 cases and the baseline system did 81 cases correctly. Our method showed higher accuracy (0.84) than that
of the baseline. There was significant difference (p < 0.05)
between them. Here, the statistical difference was determined by McNemar’s test. The evaluation measurements

2420

Table 5: Examples of test sentences (in Japanese).
Metonymic sentence (English translation)
isshoubin-wo nonda
(Someone drank the issho-bottle.)
kasetsu-ga genri-wo setsumei-suru
(The hypothesis explains the elements.)
shirobai-ga ihansha-wo taiho-shita
(The police motorcycle arrested the criminals.)
shikisha-ha sono-clarinet-wo waratta
(The conductor laughed at the clarinet.)
kao-wo soru
(Someone shaves own face.)
atama-wo karu
(Someone clips own head.)

Literal sentence (English translation)
isshoubin-wo saidan-ni oita
(He places the issho-bottle on the altar.)
kankeisha-ga setsumei-shita
(People involved explained that.)
keisatsukan-ga hanzaisha-wo taiho-shita
(The police man arrested the criminals.)
jibun-wo waratta
(Someone laughed about oneself.)
hige-wo soru
(Someone shaves a beard.)
tanbo-de ine-wo karu
(Someone mows rice plants in the paddies.)


Table 6: Accuracy in judging whether metonymic expressions or literal meanings. Asterisk indicates statistical significance over baseline. (* p < 0.05)
Accuracy

Baseline
0.72 (81/113)

Match_node in {None,Far}: Metonymic (32/5)
Match_node in {Near,Middle}: Literal (43/6)
Match_node = Middle-Near:
:...Distance_2nd_candidate <= 2.74: Metonymic (3)
:
Distance_2nd_candidate > 2.74: Literal (8)
Match_node = Middle-Far:
:...Number_S_hypernym <= 19: Literal (22/4)
Number_S_hypernym > 19: Metonymic (5)

Proposed method
0.84 (95/113)*


Table 7: Precision, recall, and F-measure rates in detecting
metonymic expressions.
Precision
Recall
F-measure

Baseline
0.63 (31/49)
0.69 (31/45)
0.66





Figure 1: Result of decision tree learning in 113 cases.

Proposed method
0.85 (33/39)
0.73 (33/45)
0.79

were recall, precision, and F-measure calculated by using the
numbers of correct detections above. Our method expressed
higher recall (0.73), precision (0.85), and F-measure (0.79)
than those of the baseline system as shown in Table 7.
The two main reasons for our method’s superiority are as
follows. First, there were differences between our method
and the baseline in the way that knowledge was used. As described previously, the baseline used the highest priority order
of syntactic information in each predicate. The priority order
in the Goi-Taikei was defined as preference to translate, so it
seemed to express the order of frequency of its usage (Shirai
et al., 1998). From these, the baseline system used the highest
frequency of syntactical information of the predicates. On the
other hand, information on the predicates which our method
used was short word distances between them and their associated words in the Verb-ACD and the Noun-ACD. From the
results, it seemed to be more suitable to use the associative information of predicates. The second reason is that separating
stages of Match node was a good way to detect metonymies.
Here, to investigate the detail of our method, we show the
result of the decision tree learning in training 113 cases in
Figure 1. As shown in the figure, Match node in ‘None’ or
‘Far’ was judged as ‘Metonymic’ and that in ‘Near’ or ‘Middle’ was done as ‘Literal’. As mentioned previously, ‘Far’
means that the average of each node is more than 3. There

are more synsets of abstract nouns in higher levels hence it
is natural to be judged as ‘Metonymic’ in ‘Far’ where the
matching synset is at higher levels in the mean. On the other
hand, it is also natural to be judged as ‘Literal’ in ‘Near’ or
‘Middle’. From these, the sum of both the synset node from
associated words and that from nouns indicates the measures
of detecting metonymies.
Given an example of the results, when an input Japanese
sentence was shikisha-ha sono-clarinet-wo waratta ‘The conductor laughed at the clarinet.’ in Table 5, our method judged
‘clarinet’ as ‘Metonymic’ while the baseline could not. In the
Verb-ACD, the associated words whose distances were especially short were hito ‘human’ and telebi-bangumi ‘TV program’. Therefore, it extracted these associated words, their
synsets, and hypernym synsets from Japanese WordNet. It
then compared them with ‘clarinet’ and its synset expressed
by music instruments. Since the extracted words and their
synsets did not match ‘clarinet’ and or its synset, the expression was judged as ‘Metonymic’. Meanwhile, the baseline extracted syntactic information of the following predicate
verb ‘laugh’ from the Goi-Taikei: “N1 laughs at N2” where
noun properties of “N1” and “N2” were hito ‘human’ and asterisk ‘all properties’, respectively. The property of ‘clarinet’
was gakki ‘instrument’ and belonged to “N2” whose property was asterisk ‘all properties’. As a result, the baseline
system judged ‘clarinet’ as ‘Literal’. In general, we usually
understand the meaning ‘The conductor laughed at the clarinet player’ when we read the sentence. Of course, it is not
wrong syntactically that the conductor laughed at the instru-

2421

ment of clarinet, but it is unnatural in daily conversations. Our
method was closer to our associations in daily conversations
and more appropriate to detect metonymies than the baseline.
We therefore conclude that using associative information can
improve computer’s ability to detect metonymies as humans
do.
However, our method incorrectly judged some literal expressions as ‘Metonymic’. The reason was that some associated words in the Verb-ACD and those in their synsets in the
Japanese WordNet were metonymies. Our method incorrectly
judged some metonymic expressions as ‘Literal because the
variety of associated words with the short word distances was
sometimes too restricted. This small variety within the group
of associated words could have led to a smaller range in the
search space of the Japanese WordNet, leading to the tendency to detect too many metonymies.

Summary and Future Work
We used the Verb-ACD and the Japanese WordNet to detect
metonymic expressions in sentences with associative information. We found that our method has a higher accuracy
of judging ‘Metonymic’ or ‘Literal’, recall, precision, and Fmeasure of detecting metonymies than those of the baseline
that only uses syntactic and semantic information.
Future work includes detecting metonymies for the temporal contiguity and constructing a system for interpreting
metonymic expressions. We would like to integrate them
into our current detection method to improve our analysis of
metonymy.

Acknowledgments
This work has been partially supported by the Graduate
School Doctorate Student Grant Aid Program 2011, Keio
University. We would like to thank the students at Shonan
Fujisawa Campus of Keio University for their participation in
the association experiments.

References
Bouaud, J., Bachimont, B., & Zweigenbaum, P. (1996).
Processing metonymy: a Domain-Model Heuristic Graph
Traversal Approach. In Proceedings of the 16th International Conference on Computational Linguistics (Vol. 1,
pp. 137–142).
Fass, D. (1991). met*: A Method for Discriminating
Metonymy and Metaphor by Computer. Computer Linguistics, 17(1), 49–90.
Ikehara, S., Miyazaki, M., Shirai, S., Yokoo, A., Nakaiwa, H.,
Ogura, K., et al. (1999). Goi-Taikei: A Japanese Lexicon
CD-ROM. Iwanami Shoten.
Isahara, H., Bond, F., Uchimoto, K., Utiyama, M., & Kanzaki, K. (2008). Development of Japanese WordNet. In
Proceedings of the 6th International Conference on Language Resources and Evaluation (pp. 2420–2422).
Iverson, E., & Helmreich, S. (1992). Metallel: An Integrated
Approach to Non-Literal Phrase Interpretation. Computational Intelligence, 8(3), 477–493.

Lakoff, G., & Johnson, M. (1980). Metaphors We Live By.
University of Chicago Press.
Markert, K., & Nissim, M. (2003). Corpus-Based Metonymy
Analysis. Metaphor and Symbol, 18(3), 175–188.
Markert, K., & Nissim, M. (2007). Semeval-2007 task 08:
Metonymy resolution at semeval-2007. In Proceedings
of the 4th international workshop on semantic evaluations
(SemEval-2007) (pp. 36–41).
Morita, Y. (1989). A Dictionary of Basic Japanese.
Kadokawa Gakugei Shuppan Publishing.
Murata, M., Yamamoto, A., Kurohashi, S., Isahara, H., & Nagao, M. (2000). Metonymy Interpretation Using the Examples, “Noun X of Noun Y” and “Noun X Noun Y”. Journal
of Japanese Society for Artificial Intelligence, 15(3), 503–
510. (in Japanese)
Nastase, V., & Stube, M. (2009). Combining Collocations,
Lexical and Encyclopedic Knowledge for Metonymy Resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (pp. 910–
918).
Okamoto, J., & Ishizaki, S. (2001). Construction of Associative Concept Dictionary with Distance Information,
and Comparison with Electronic Concept Dictionary. Journal of Natural Language Processing, 8(4), 37–54. (in
Japanese)
Shirai, S., Ooyama, Y., Ikehara, S., Miyazaki, M., & Yokoo,
A. (1998). Introduction to Goi-Taikei: A Japanese Lexicon. In Ipsj sig notes (pp. 47–52). (in Japanese)
Suga, T., & Ishizaki, S. (2006). Construction of Metonymy
Understanding System Using Associative Concept Dictionary. In Proceeding of Annual Meeting of the Natural
Language Processing Society of Japan (nlp2006) (pp. 817–
820). (in Japanese)
Taniguchi, K. (2003). New Developments of Cognitive
Semantics -Metaphor and Metonymy-. Kenkyusha. (in
Japanese)
Teraoka, T., Okamoto, J., & Ishizaki, S. (2010). An associative concept dictionary for verbs and its application to
elliptical word estimation. In Proceedings of the 7th International Conference on Language Resources and Evaluation (pp. 3851–3856).
Teraoka, T., Okamoto, J., & Ishizaki, S. (2011). Detecting
metonymic expressions with associative information from
words. In Proceedings of the 12th Pacific Association for
Computational Linguistics Conference, #13.
Yamanashi, M. (1987). Metonymic interpretation and associative processes in natural language. In M. Nagao (Ed.),
Language and artificial intelligence (pp. 77–86). Elsevier
Science Publishers B.V. (North-Holland).
Yamanashi, M. (1988). Metonymy and Understanding. University of Tokyo Press. (in Japanese)

2422

