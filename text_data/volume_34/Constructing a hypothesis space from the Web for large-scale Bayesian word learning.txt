UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Constructing a hypothesis space from the Web for large-scale Bayesian word learning
Permalink
https://escholarship.org/uc/item/77v8r6h3
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Abbott, Joshua
Austerweil, Joseph
Griffiths, Tom
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                Constructing a hypothesis space from the Web
                                       for large-scale Bayesian word learning
                                         Joshua T. Abbott (joshua.abbott@berkeley.edu)
                                      Joseph L. Austerweil (joseph.austerweil@gmail.com)
                                        Thomas L. Griffiths (tom griffiths@berkeley.edu)
                             Department of Psychology, University of California, Berkeley, CA 94720 USA
                               Abstract                              Bayesian generalization model. In this paper, we use this
                                                                     approach to show how a hypothesis space and prior can be
   The Bayesian generalization framework has been successful
   in explaining how people generalize a property from a few         constructed automatically from a large online database, mak-
   observed stimuli to novel stimuli, across several different       ing it possible to apply the Bayesian generalization frame-
   domains. To create a successful Bayesian generalization           work to a wide range of naturalistic stimuli. We focus on one
   model, modelers typically specify a hypothesis space and
   prior probability distribution for each specific domain. How-     specific generalization problem, word learning, where peo-
   ever, this raises two problems: the models do not scale beyond    ple learn new words from observing a few objects that can be
   the (typically small-scale) domain that they were designed        labeled with that word. Given that the number of possible ex-
   for, and the explanatory power of the models is reduced by
   their reliance on a hand-coded hypothesis space and prior. To     tensions of a word is essentially infinite, learning the objects
   solve these two problems, we propose a method for deriving        referred to by a word is a very difficult inductive problem
   hypothesis spaces and priors from large online databases. We      (Quine, 1975). Xu and Tenenbaum (2007) showed how the
   evaluate our method by constructing a hypothesis space and
   prior for a Bayesian word learning model from WordNet, a          Bayesian generalization framework could be used to explain
   large online database that encodes the semantic relationships     how people learn new words. However, to construct the hy-
   between words as a network. After validating our approach         pothesis space of their Bayesian model, Xu and Tenenbaum
   by replicating a previous word learning study, we apply the
   same model to a new experiment featuring three additional         (2007) elicited approximately 400 similarity judgments from
   taxonomic domains (clothing, containers, and seats). In           their participants. Clearly this is not practical to extend into
   both experiments, we found that the same automatically            every domain where people learn words. Thus, word learn-
   constructed hypothesis space explains the complex pattern of
   generalization behavior, producing accurate predictions across    ing is an appropriate setting for exploring novel methods of
   a total of six different domains.                                 constructing hypothesis spaces and prior distributions.
   Keywords: generalization; concept learning; word learning;           We propose a method for automatically constructing the
   Bayesian modeling; online databases                               hypothesis space and prior distribution of a Bayesian word
                                                                     learning model using freely available online resources. In
                            Introduction                             particular, we use WordNet (Fellbaum, 2010; Miller, 1995)
Many problems solved by the mind conform to the same ab-             as an initial source for automatically creating the hypothesis
stract computational formulation: How should a property be           space, and ImageNet (Deng et al., 2009) as a source of natu-
generalized to novel stimuli from a set of stimuli observed to       ralistic images that can be used as stimuli to test the resulting
have the property? As there are many ways to extend the              model in behavioral experiments. WordNet is a popular lexi-
property that are consistent with some observed evidence,            cal database of English comprised of over 100,000 relational
these are problems of induction, where the evidence con-             sets of synonyms. ImageNet is a large ontology of images
strains, but does not determine, the solution to a problem. The      conforming to the hierarchical structure of WordNet, with the
Bayesian generalization framework (Shepard, 1987; Tenen-             aim of providing over 500 high-quality images per noun in
baum & Griffiths, 2001) has been remarkably successful at            WordNet. These resources allow us to construct hypothesis
explaining human generalization behavior in a wide range of          spaces and prior distributions for word learning without elic-
domains. However, its success is largely dependent on the            iting a single judgment from participants and test the result-
choice of a hypothesis space and a prior probability distribu-       ing model on a much larger scale than was previously pos-
tion on hypotheses, which are usually hand constructed by            sible. We demonstrate that the Bayesian model formulated
the researcher for each specific problem. This is unsatisfy-         from WordNet captures participant judgments in two behav-
ing practically, because the models do not scale beyond the          ioral experiments, addressing the practical and theoretical is-
originally modeled problem, and theoretically, as it is unclear      sues with Bayesian models discussed earlier.
whether their success is due to the cleverness of the modeler           The plan of the rest of the paper is as follows. In the next
and not because of a deep mathematical property of the com-          sections we review the Bayesian generalization model and
putational problem that people solve.                                then examine how Xu and Tenenbaum (2007) constructed the
   One possible solution is to use existing sources of infor-        hypothesis space for their Bayesian word learning model. We
mation about the organization of a domain as the basis for           then show how to build a hypothesis space from WordNet that
specifying a hypothesis space and prior. This helps address          can be used to evaluate word learning models on a large scale.
both the practical and the theoretical concerns raised by the        Afterwards, we present two experiments utilizing this hypoth-
                                                                  54

esis space: one that replicates a previous study of adult word    Word Learning as Bayesian Inference
learning, and one that investigates word learning for a set of    Xu and Tenenbaum (2007) derived the hypothesis space for
complex concepts in novel domains. Finally, we discuss the        their Bayesian word learning model by applying hierarchical
implications of our work and future directions for research.      clustering (see Duda & Hart, 1973) to the perceived similar-
                                                                  ity of every pair of objects. The hypothesis space, prior and
     The Bayesian Generalization Framework                        likelihood are defined by the tree resulting from hierarchical
The Bayesian word learning model is a special case of the         clustering. Using a tree is well justified from a psycholog-
Bayesian generalization framework. This framework has             ical perspective as children assume the possible referents of
been used to model generalization in a number of domains in-      novel nouns are tree-structured (Markman, 1991). Nodes in
cluding dimensional concepts (Austerweil & Griffiths, 2010;       the tree represent potential words (hypotheses) which extend
Shepard, 1987; Tenenbaum, 1999), word learning (Xu &              to all the leaves they cover, where the leaves of the tree corre-
Tenenbaum, 2007), numerical concepts (Tenenbaum, 2000),           spond to the domain of possible objects. The height of a node
sequential rules (Austerweil & Griffiths, 2011) and rule-         h (minimal distance from the node to a leaf) is a measure of
based categorical concepts (Goodman, Tenenbaum, Feldman,          the average pairwise dissimilarity of objects covered by node
& Griffiths, 2008). Typically, problems are formulated in this    h and approximates the heterogeneity of the objects that can
framework as follows: Assume we observe n positive ex-            be called that word. The intuition that more distinctive clus-
amples x = {x1 , . . . , xn } of concept C and want to compute    ters are more likely to have distinguishing names, was incor-
P(y ∈ C|x), the probability that some new object y belongs        porated by defining the prior P(h) to be proportional to the
to C given the observations x. We compute this probability        branch length separating node h from its parent:
by using a hypothesis space H , which is a set of hypothetical
concepts, where each hypothesis is defined by the objects that                 P(h) ∝ height(parent(h)) − height(h),            (3)
would be members of the concept if the hypothesis were true,
P(x|h).                                                           where parent(h) returns the parent of node h. To incorporate a
   Defining a Bayesian generalization model amounts to            basic-level bias (Markman, 1991; Rosch, Mervis, Gray, John-
defining a hypothesis space H , a prior probability distribu-     son, & Boyes-Braem, 1976) in which new words tend to refer
tion over hypotheses, P(h), and for each hypothesis, a likeli-    more often to a word at an intermediate level in a taxonomy,
hood function, P(x|h), indicating the probability of observing    the prior probability of hypotheses at the basic level were 10
a set of objects x given that the hypothesis is true. A typi-     times the value given by Equation 3 (see below for examples).
cal definition of the likelihood follows from assuming strong     As the height of node h also approximates the number of ob-
sampling, where objects are generated uniformly at random         jects in the extension of the possible word h, the likelihood of
from the true hypothesis (Tenenbaum & Griffiths, 2001)            observing n objects called word h is defined as
                                                                                                             n
                                                                                                      1
                             (
                               1/|h|n if x ⊂ h                                       P(x|h) ∝                    ,              (4)
                P(x|h) =                         .         (1)                                  height(h) + ε
                               0       otherwise
                                                                  where ε is a small constant so that the leaf hypotheses (those
This likelihood function instantiates the size principle for      that refer to only a single object) do not have infinite likeli-
scoring hypotheses: hypotheses containing a smaller num-          hood (as their height is zero).
ber of objects assign greater likelihood than hypotheses with        Using this framework, Xu and Tenenbaum (2007) accu-
more objects to the same set of objects (Tenenbaum, 1999;         rately predicted how people extend words to new objects de-
Tenenbaum & Griffiths, 2001). The prior distribution over         pending on the diversity and number of objects labeled with
hypotheses, P(h) depends on the domain and in previous lit-       that word. In a set of experiments on both adults and chil-
erature has ranged from a simple uniform distribution over        dren, they showed participants one or more positive exam-
the hypothesis space (Shepard, 1987) to a stochastic process      ples of a novel word while manipulating the taxonomic re-
over tree structures (Kemp & Tenenbaum, 2009). Given the          lationship of the objects the word referred to. For example,
prior and likelihood, the posterior probability that a hypoth-    participants might observe one Dalmatian, three Dalmatians
esis is true given a set of objects belonging to a novel con-     (exemplars at the subordinate-level), a Dalmatian, terrier, and
cept, P(h|x), follows from Bayes’ rule: P(h|x) ∝ P(x|h)P(h).      mutt (exemplars at the basic-level), or a Dalmatian, pig, and
From this, we can compute the probability that a new object       toucan (exemplars at the superordinate-level) being labeled
y is also a member of the concept C by averaging the predic-      with a novel word (e.g. “fep”). After observing a word re-
tions of all hypotheses weighted by their posterior probabili-    fer to one or three example objects at the subordinate, basic,
ties:                                                             or superordinate-level, they were asked whether the word re-
              P(y ∈ C|x) = ∑ P(y ∈ C|h)P(h|x),             (2)    ferred to novel subordinate, basic, superordinate, and out-of-
                               h∈H
                                                                  domain objects.
where P(y ∈ C|h) = 1 if the new object y is in hypothesis h,         When participants were given one example of an ob-
and 0 otherwise.                                                  ject that refers to a word (e.g. one Dalmatian), they tended
                                                               55

to select the subordinate-level matches (e.g. the two other         objects at the subordinate-level. To construct a hypothesis
Dalmatians) and the basic-level matches (e.g. the two non-          space from WordNet, we first extracted a tree from the 82,115
Dalmatian dogs). However, when they were shown three                noun nodes of WordNet.1 The nodes are hypotheses, which
subordinate-level examples of a concept (e.g. three Dalma-          represent possible words, and form the hypothesis space for
tians), the participants tended to choose only the subordinate-     the model. From this graph we create a hypothesis space that
level matches (e.g. they only believed the word referred to         is a binary matrix, H , whose rows are the objects (64,958
the two other Dalmatians). The Bayesian word learning               leaf nodes from the graph) and columns are the hypotheses
model captured this phenomenon because the prior favors             (82,115 nodes, 17,157 of which are inner nodes and 64,958
words at the basic-level, but the likelihood favors words at        are leaf nodes). Each entry (i, j) of the matrix H denotes
the subordinate-level, and the likelihood’s weight increases        whether or not hypothesis node j is an ancestor of leaf node
exponentially in the number of objects.                             i in the WordNet graph (with a 1 indicating it is). The leaf
   Unfortunately, the manner in which the hypothesis space          nodes are included as hypotheses so that the model distin-
was constructed (through hierarchical clustering on pairs of        guishes between subordinate objects.
similarity judgments) poses a serious constraint to assessing
the model’s validity. To construct the hypothesis space in the      Generalization Models
three domains tested by Xu and Tenenbaum (2007), where              With a hypothesis space derived from WordNet, we now have
there are 15 images per concept, each participant had to pro-       the ability to test the Bayesian model of word learning on
vide roughly 400 similarity judgments. To test how well this        a much larger scale. In addition, we can use the hypothesis
framework extends to new concepts and domains using their           matrix as a feature space for testing alternative models. We
method for constructing the hypothesis space, an impracti-          compare the Bayesian model against two similarity models:
cally large quantity of human judgments would need to be            a prototype model and an exemplar model. Given a set
elicited. In the following section, we introduce an alternative     of examples x = {x1 , . . . , xn } representing some concept
method of constructing a hypothesis space for the Bayesian          C (where the elements of x correspond to rows in the
word learning model, which allows for testing the framework         hypothesis matrix H ), we can compute a score for each row
without eliciting any judgments from participants.                  y ∈ H denoting the probability that y is also a member of
                                                                    C. We present the different ways to compute this score below.
              Large-Scale Word Learning
Using an online word ontology, we can automatically con-            Bayesian model. This is the Bayesian generalization frame-
struct the hypothesis space of a Bayesian word learning             work that we discussed earlier. We used strong sampling for
model. WordNet is a large lexical database of English rep-          the likelihood, P(x|h), which is computed via Equation 1,
resented as a network of words linked by directed edges de-         where the size of h is the number of nodes that can be reached
noting semantic relatedness (Fellbaum, 2010; Miller, 1995).         by a directed path from h. This simply corresponds to the sum
Its structure was manually designed to group lexical concepts       of the elements in the column corresponding to h.
in an “is-a” hierarchy based on the many-to-one mapping of             The prior P(h) was defined to be Erlang distributed in the
synonyms. For example, a Poodle “is-a” type of dog, thus            size of the hypothesis (a standard prior over sizes in Bayesian
WordNet has a directed edge from the node for dog to the            models; Shepard, 1987; Tenenbaum, 2000)
node for Poodle. As WordNet is hierarchically structured like
                                                                                      P(h) ∝ (|h|/σ2 )exp{−|h|/σ},                   (5)
the hypothesis space used by Xu and Tenenbaum (2007), it is
an ideal candidate for constructing our hypothesis space.           where the σ parameter was set to 200 by hand fitting the
   Using a hypothesis space derived from WordNet, we can            model predictions to all human responses (the same value
better test the predictions of different generalization theories    was used in both experiments). This value favors medium
for word learning by examining their predictions for a large        sized hypotheses, which is roughly equivalent to a basic-level
range of concepts. In the rest of this section, we present the      bias. The probability that word C extends to object y after
method used to construct a hypothesis space from WordNet            observing a set of objects called C is
and outline the implementations of three generalization mod-
els using this hypothesis space for large-scale word learning.            Bscore(y) = P(y ∈ C|x) =       ∑ P(y ∈ C|h)P(h|x),         (6)
                                                                                                        h∈H
Constructing a Hypothesis Space
In the context of the Bayesian generalization framework, the        where P(y ∈ C) = 1 if y ∈ h and 0 otherwise, and P(h|x), is
hypotheses correspond to subsets of the universe of objects         the posterior distribution over hypotheses.
that are psychologically plausible candidates as extensions of
concepts (Tenenbaum & Griffiths, 2001). Using WordNet as            Prototype model. In this model, we define the prototype of
the basis of our hypothesis space, the set of objects is the set    a set of objects, xproto , to have those features owned by a ma-
of leaf nodes from the noun-space of the directed graph and         jority of the objects in the set. The generalization measure for
the hypotheses correspond to both the inner nodes of the di-            1 Technically WordNet is a directed acyclic graph because some
rected graph and the leaf nodes, which distinguish between          nodes have multiple parents (the method still works in these cases).
                                                                 56

an object y is                                                       two basic-level objects (e.g. a Dalmatian, a Shih Tzu, and a
                                                                     Beagle); and the subordinate object and two superordinate-
              Pscore(y) = exp{−λ p dist(y, xproto )},         (7)    level objects (e.g. a Dalmatian, a hippopotamus, and a tou-
                                                                     can). This corresponds to twelve trials total (four conditions
where dist(·, ·) is the Hamming distance between the two
                                                                     for each of the three object taxonomies).
vectors and λ p is a free parameter (for all of the results pre-
                                                                        The test sets were the same regardless of the training set
sented here, λ p = 0.15, optimized by hand using half-interval
                                                                     and consisted of eight objects matching the currently tested
search). Pscore was then normalized over all objects y in the
                                                                     taxonomy: two subordinate examples (e.g. two other Dalma-
hypothesis space (all leaf nodes).
                                                                     tians); two basic-level examples (e.g. a Cocker Spaniel and a
                                                                     Corgi); and four superordinate examples (e.g. a cat, a bear, a
Exemplar model. We define the exemplar model using a
                                                                     sea lion, and a horse). There were also sixteen non-matching
similar scoring metric as the prototype model, except rather
                                                                     objects in the test set corresponding to the objects that match
than computing the distance of object y to a single prototype
                                                                     the two other taxonomies.
vector, we compute a distance for each item x j in the set of
                                                                        For each trial, participants were instructed that they needed
observations x. The exemplar generalization measure is thus
                                                                     to help a cartoon frog who speaks a different language from
computed as
                                                                     us, pick out objects that he wants. The frog shows one
             Escore(y) =                                             or more examples of a novel word (e.g. “dak”) and the
                           ∑ exp{−λe dist(y, xj )},           (8)
                                                                     participant is instructed to select other items that are a “dak”
                          x j∈x
                                                                     from the objects comprising the test set. A unique novel
where dist(·, ·) is the Hamming distance between two vectors         word was associated with each of the twelve trials.
and λe is a free parameter (for all of the results presented
here, λe = 0.20, optimized by hand using half-interval               Results. Figure 1 shows the results of this experiment, along
search). Escore was then normalized over all objects y in the        with the predictions of the different generalization models.
hypothesis space (all leaf nodes).                                   For each training set condition, the data for each test item has
                                                                     been averaged over participants and domains. The general-
                                                                     ization judgments of participants (left-most panel of Figure
                 Behavioral Experiments                              1) follows the same qualitative trend as those reported in Xu
To evaluate the performance of our models using the                  and Tenenbaum (2007). There is a sharp drop in generaliza-
WordNet-based hypothesis space, we conducted two experi-             tion to basic-level objects when seeing only a single subor-
ments using the paradigm of Xu and Tenenbaum (2007). The             dinate example compared to the condition when seeing three
first experiment replicates Xu and Tenenbaum (2007) on their         subordinate examples.
three object taxonomies (animals, vehicles, and vegetables),            The Bayesian model predictions (second panel from the
which validates our approach for constructing a hypothesis           left) exhibits this same generalization pattern (r2 = 0.98),
space from WordNet and using images from ImageNet as                 while the prototype and exemplar models do not (r2 = 0.66
stimuli. The second experiment extends the paradigm into             and r2 = 0.84, respectively). This validates our method of
three previously unexplored domains (clothing, containers,           automatically creating hypothesis spaces with WordNet.
and seats), which have hierarchical structure, but it is not as
clear how well they conform to a natural basic-level taxon-          Experiment 2: Novel Domains
omy (Rosch et al., 1976).                                            Participants. Thirty six participants were recruited via
Experiment 1: Validating Our Approach                                Amazon Mechanical Turk and compensated $0.05 for each
                                                                     trial completed out of twelve possible. As in Experiment
Participants. Thirty four participants were recruited via
                                                                     1, each participant completed as many trials as he or she
Amazon Mechanical Turk and compensated $0.05 for each
                                                                     wished, and twenty unique participants completed each trial.
trial (training set) completed out of twelve possible. Each
                                                                     All participant responses were used.
participant completed as many trials as he or she wished,
and twenty unique participants completed each trial. All
                                                                     Stimuli and Procedure. Table 1 contains the objects we used
participant responses were used.
                                                                     for training in the three hierarchical domains (clothing, con-
                                                                     tainers, and seats).2 As in Experiment 1, the same test objects
Stimuli and Procedure. Within each taxonomy, the stimuli
                                                                     were used for every training set, and the “non-match” test ob-
consisted of the images of objects distributed across the su-
                                                                     jects were the objects in the test set which match the two other
perordinate, basic and subordinate-levels, and subsequently
                                                                     taxonomies that are not contained in the training set. As be-
split into training and test sets. The training sets were the la-
                                                                     fore, this corresponds to twelve trials total. The procedure
beled objects given to participants of which there were four
                                                                     was identical to Experiment 1.
conditions: a single subordinate-level example (e.g. a Dal-
matian); three examples of the same subordinate-level ob-                2 The additional subordinate-level training image and the test im-
ject (e.g. three Dalmatians); the subordinate-level object and       ages were omitted from Table 1 for brevity.
                                                                  57

                      Subject Responses               Bayesian Model                   Prototype Model                Exemplar Model
                 1                              1                                 1                             1
Generalization                                                                                                                                 sub
                 .5                             .5                            .5                                .5                             basic
 Probability
                                                                                                                                               super
                 0     1     3     3      3
                                                0     1     3   3      3
                                                                                  0    1     3     3      3
                                                                                                                0     1     3     3      3
                      Sub   Sub   Basic Super        Sub   Sub Basic Super            Sub   Sub   Basic Super        Sub   Sub   Basic Super
Figure 1: Participant generalization judgments and predictions of the Bayesian, prototype, and exemplar models averaged
across the three domains in Experiment 1. The generalizations for non-matching items are omitted for brevity (neither the
participants chose nor the Bayesian model predicted non-matching objects, while the prototype and exemplar models predicted
non-matches less than 4% of the time for each condition).
Results. Figure 2 presents the averaged results of how partici-                   source as a potential solution to the methodological chal-
pants 3 and the Bayesian model generalized the learned words                      lenges posed by this problem. In the first behavioral ex-
to the test objects based on the observed training set across                     periment, we validated that the Bayesian model using this
the different domains in Experiment 2.4 Across the three do-                      hypothesis space can capture previously found word learn-
mains, the generalization probabilities of the participants and                   ing phenomena. In the second behavioral experiment, we
Bayesian model with the same parameters are extremely simi-                       showed that the same Bayesian model explains how partic-
lar. This is exemplified in the very good quantitative model fit                  ipants learned words in three novel domains. Using the auto-
on the averaged data (r2 = 0.95). Furthermore, the hypothesis                     matically constructed hypothesis space, the model predicted
space constructed automatically from WordNet explains the                         the subtle changes in participants’ word learning behavior
idiosyncrasies of participant generalization behavior in each                     across three domains, thus demonstrating the practical and
domain (r2 = 0.97, 0.88, and 0.91, for clothing, containers,                      theoretical benefits of our approach.
and seats respectively). For example, the model accurately                           In the future, we hope to perform a large scale empirical
predicts that participants would generalize most broadly in                       test of the Bayesian word learning model using more het-
the seats domain for the single exemplar and three basic-level                    erogeneous training sets (e.g. one subordinate-level and one
exemplar training sets. Additionally, the model captures that                     basic-level object) and more domains with varied conceptual
people generalized the least in the containers domain for the                     structure. The larger set of empirical results would enable us
three subordinate-level exemplar training sets. This would                        to perform a more detailed investigation of the prior knowl-
not have been possible if the hypothesis space for each do-                       edge over the types of conceptual structures that people use
main had the same structure.                                                      when they learn words (e.g. do people prefer shallow or deep
    Note that there is a larger amount of variance between                        taxonomies?). Additionally, we hope to incorporate how par-
model predictions and human performance in Experiment 2                           ticipant behavior is affected by the visual similarity of the
than Experiment 1. We believe that this is due to the domains                     images in the training and tests sets (and its interaction with
not conforming to a natural taxonomy. For example, it is un-                      conceptual structure), which at the moment would not be pos-
clear if box should be the basic-level category for a mail box                    sible to explore with the Bayesian word learning model.
and a cigar box; however, this is the basic level of these ob-                       As word learning is a special case of the more general prob-
jects provided by WordNet. Regardless, the good quantitative                      lem of generalization, our approach potentially could be ap-
fit of the Bayesian model’s predictions provides evidence that                    plied to automatically construct hypothesis spaces for gener-
using WordNet as a hypothesis space for word learning can                         alization problems in other domains. For example, a Bayesian
capture people’s generalizations even for hierarchies without                     model of commonsense reasoning could be formulated by au-
clearly defined basic-level concepts.                                             tomatically deriving hypothesis spaces from ConceptNet (Liu
                                                                                  & Singh, 2004) or OpenCyc (Matuszek, Cabral, Witbrock, &
                                    Discussion
                                                                                  DeOliveira, 2006). This follows a development in modern
Although the Bayesian generalization framework has been                           machine learning, which has leveraged online resources to
extremely successful in explaining human generalization be-                       make more successful learning algorithms (Medelyan, Legg,
havior, the hypothesis spaces are typically hand-constructed,                     Milne, & Witten, 2009; Ponzetto & Strube, 2006). We hope
which is unsatisfying. In this paper, we explored automat-                        that this draws a closer connection between computer science
ically constructing the hypothesis space using an online re-                      and cognitive science, which can lead to more psychologi-
    3 Non-matching objects were only chosen twice (both in the con-               cally valid, yet still scalable, artificial intelligence systems.
tainers domain) and so, they were omitted from Figure 2.
    4 The prototype and exemplar models were omitted from Figure                  Acknowledgments. This work was supported by the DARPA BOLT
2 for brevity (r2 = 0.80 and r2 = 0.90 averaged over domains, re-                 contract HR0011-11-2-0009 and grant number IIS-0845410 from
spectively).                                                                      the National Science Foundation.
                                                                             58

                                                               Clothing                              Containers                           Seats
                               Object level               1                 2                    1                 2                1               2
                               Subordinate
                                  Basic
                           Superordinate
                                                                    Table 1: Training images for Experiment 2.
                                  Clothing                            Containers                           Seats                            Average
Subject Responses   1                                1                                      1                                  1
  Generalization    .5                               .5                                    .5                                  .5
   Probability      0     1       3     3      3
                                                     0         1       3   3         3
                                                                                            0
                                                                                                   1      3     3       3
                                                                                                                               0     1      3      3      3
                         Sub     Sub   Basic Super            Sub     Sub Basic    Super          Sub    Sub   Basic   Super        Sub    Sub    Basic Super   sub
                                                                                                                                                                basic
Bayesian Model                                                                                                                                                  super
                    1                                1                                      1                                  1
 Generalization     .5                               .5                                     .5                                 .5
  Probability       0                                0                                      0                                  0
                          1       3     3      3               1       3     3      3              1      3     3        3           1      3      3      3
                         Sub     Sub   Basic Super            Sub     Sub   Basic Super           Sub    Sub   Basic   Super        Sub    Sub    Basic Super
Figure 2: Participant generalization judgments and the predictions of the Bayesian model for Experiment 2. From left to right,
the columns present the results for the three taxonomies (clothing, containers, and seats) and average results.
                                          References                                               (Ed.), Proceedings of the AAAI 2006 Spring Symposium (p. 44-
                                                                                                   49). Menlo Park, CA: AAAI Press.
Austerweil, J. L., & Griffiths, T. L. (2010). Learning hypothesis                                Medelyan, O., Legg, C., Milne, D., & Witten, I. H. (2009). Min-
  spaces and dimensions through concept learning. In S. Ohlsson                                    ing meaning from Wikipedia. International Journal of Human-
  & R. Catrambone (Eds.), Proceedings of the 32nd Annual Con-                                      Computer Studies, 67(9), 1-76.
  ference of the Cognitive Science Society (pp. 73–78). Austin, TX:                              Miller, G. (1995). WordNet: a lexical database for english. Com-
  Cognitive Science Society.                                                                       munications of the ACM, 38(11), 39–41.
Austerweil, J. L., & Griffiths, T. L. (2011). Seeking confirmation                               Ponzetto, S. P., & Strube, M. (2006). Exploiting semantic role la-
  is rational for deterministic hypotheses. Cognitive Science, 35,                                 beling, WordNet and Wikipedia for coreference resolution. In
  499–526.                                                                                         Proceedings of the HLT Conference of the NAACL (p. 192-199).
Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., & Fei-Fei, L. (2009).                         Quine, W. V. O. (1975). Word and object. MIT Press.
  Imagenet: A large-scale hierarchical image database. In Pro-                                   Rosch, E., Mervis, C. B., Gray, W. D., Johnson, D. M., & Boyes-
  ceedings of the IEEE Conference on Computer Vision and Pattern                                   Braem, P. (1976). Basic objects in natural categories. Cognitive
  Recognition (pp. 248–255).                                                                       Psychology, 8(3), 382–439.
Duda, R. O., & Hart, P. E. (1973). Pattern classification and scene                              Shepard, R. N. (1987). Towards a universal law of generalization
  analysis. New York: Wiley.                                                                       for psychological science. Science, 237, 1317-1323.
Fellbaum, C. (2010). WordNet. Theory and Applications of Ontol-                                  Tenenbaum, J. B. (1999). Bayesian modeling of human concept
  ogy: Computer Applications, 231–243.                                                             learning. In M. S. Kearns, S. A. Solla, & D. A. Cohn (Eds.),
Goodman, N. D., Tenenbaum, J. B., Feldman, J., & Griffiths, T. L.                                  Advances in Neural Information Processing Systems 11 (Vol. 11,
  (2008). A rational analysis of rule-based concept learning. Cog-                                 p. 59-65). Cambridge, MA: MIT Press.
  nitive Science, 32(1), 108–154.                                                                Tenenbaum, J. B. (2000). Rules and similarity in concept learning.
Kemp, C., & Tenenbaum, J. B. (2009). Structured statistical models                                 In S. A. Solla, T. K. Leen, & K.-R. Muller (Eds.), Advances in
  of inductive reasoning. Psychological Review, 116(1), 20–58.                                     Neural Information Processing Systems 12 (Vol. 12, pp. 59–65).
Liu, H., & Singh, P. (2004). ConceptNet - A practical commonsense                                Tenenbaum, J. B., & Griffiths, T. L. (2001). Generalization, sim-
  reasoning tool-kit. BT Technology Journal, 22(4), 211-226.                                       ilarity, and Bayesian inference. Behavioral and Brain Sciences,
Markman, E. M. (1991). Categorization and naming in children:                                      24(4), 629–640.
  Problems of induction. MIT Press.                                                              Xu, F., & Tenenbaum, J. (2007). Word learning as Bayesian infer-
Matuszek, C., Cabral, J., Witbrock, M., & DeOliveira, J. (2006).                                   ence. Psychological Review, 114(2), 245–272.
  An introduction to the syntax and content of cyc. In C. Baral
                                                                                           59

