UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning What is Where from Social Observations
Permalink
https://escholarship.org/uc/item/4vd0v65h
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Jara-Ettinger, Julian
Baker, Chris
Tenenbaum, Joshua
Publication Date
2012-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                             Learning What is Where from Social Observations
                                                 Julian Jara-Ettinger (jjara@mit.edu)
                                                   Chris L. Baker (clbaker@mit.edu)
                                                  Joshua B. Tenenbaum (jbt@mit.edu)
                                             Department of Brain and Cognitive Sciences, MIT
                                                               Cambridge, MA 02139
                               Abstract                                    Gopnik & Meltzoff, 1997). Implicitly you assume basic as-
                                                                           pects of rationality in the person you see crossing the street:
   Observing the actions of other people allows us to learn not
   only about their mental states, but also about hidden aspects           that they want to cross safely, that they update their beliefs
   of a shared environmental situation – things we cannot see,             about the presence of oncoming cars based on what they can
   but they can, and that influence their behavior in predictable          see, and that they plan their actions appropriately to achieve
   ways. This paper presents a computational model of how peo-
   ple can learn about the world through these social inferences,          their goals given their beliefs. If they are clearly paying at-
   supported by the same Theory of Mind (ToM) that enables rep-            tention to the side of the street you cannot see, and they are
   resenting and reasoning about an agent’s mental states such as          walking across unhurriedly and unworriedly, it is then a good
   beliefs, desires, and intentions. The model is an extension of
   the Bayesian Theory of Mind (BToM) model of Baker et al.                bet that no traffic is headed imminently toward them; if they
   (2011), which treats observed intentional actions as the output         are jumping or dashing out of the way, that is another story.
   of an approximately rational planning process and then rea-                Accounts of distinctively human cognition often empha-
   sons backwards to infer the most likely inputs to the agent’s
   planner – in this case, the locations and states of utility sources     size the sophisticated representational power of people’s
   (potential goal objects) in the environment. We conducted a             ToM, as in the capacity to represent arbitrary belief states,
   large-scale experiment comparing the world-state inferences of          false beliefs as well as true ones, and predict how people will
   the BToM model and those of human subjects, given observa-
   tions of agents moving along various trajectories in simple spa-        act accordingly. But just as or more important is the sophis-
   tial environments. The model quantitatively predicts subjects’          ticated inferential power of ToM: how we can learn about the
   graded beliefs about possible world states with high accuracy           contents of other agents’ mental states, or even the structure
   – and substantially better than a non-mentalistic feature-based
   model with many more free parameters. These results show the            of the world, by reasoning backwards to the best explanations
   power of social learning for acquiring surprisingly fine-grained        of agents’ observed behaviors. This kind of inverse reasoning
   knowledge about the world.                                              underlies not only the traffic example above, but many other
   Keywords: Social Cognition; Theory of Mind; Social Learn-               situations of practical importance for everyday cognition. For
   ing; Reinforcement Learning                                             example, if you see people filing out of a new restaurant with
                                                                           contented looks, it is a good bet the food inside is satisfying.
                           Introduction                                    If you see someone enter the restaurant with an expression of
The most obvious way to learn about the world is by direct                 eager anticipation, then exit a moment later and start looking
observation. You may believe there is a Starbucks across                   for a different place to eat, you might guess that the restau-
the street from your office because you have passed it many                rant is unexpectedly closed – or perhaps he mistook it for a
times, and believe it is open at this moment because you just              different place. If your friend the foodie goes far out of his
passed by a few minutes ago and saw a number of people go-                 way while visiting a new city to visit a particular restaurant,
ing in and out. But many aspects of the world are unobserv-                you can bet that place is one of the city’s best.
able and must be inferred indirectly, often based on observing                In this paper, we present a computational model of this
the actions of other people who know or perceive what you                  social-learning capacity – inferring the world’s state from ob-
do not. Consider the situation of driving or biking and need-              serving other agents’ behavior, guided by ToM. Similar in-
ing to turn left at an intersection onto a busy street, across             ferential abilities have been studied in infants (Csibra, Biró,
oncoming traffic. Of course before turning you will check to               Koós, & Gergely, 2003) and adults (Goodman, Baker, &
see whether there are any cars coming down the busy street                 Tenenbaum, 2009), and the latter paper presented a compu-
from the left, but suppose there is a large truck parked on                tational model similar to ours in key respects (but focused
the street, blocking your view so that you cannot see whether              on causal learning). Our work is the first to test people’s
there is any oncoming traffic. You may inch out slowly until               social learning against rational model predictions in a large-
you can see, but you may also observe what other drivers or                scale quantitative experiment, showing that people can form
pedestrians are doing. If they are in a position to see the on-            surprisingly accurate fine-grained beliefs about the relative
coming cars that you cannot, and if they are crossing the busy             probabilities of different possible worlds from sparse social
street at the same point you wish to turn, then it is a good bet           observations – just a single agent moving along a single goal-
that your turn would also be safe.                                         directed path of intentional action. We contrast our model
   Making such a judgment is literally betting your life on                with a non-intentional, non-ToM account based on low-level
a mental model of another person’s cognitive processes – a                 features of the agent’s motion. Even when we introduce
Theory of Mind (ToM) (e.g. Dennett, 1987; Wellman, 1990;                   many free parameters in the form of variable feature weights,
                                                                       515

and optimize their values to best fit people’s world-state in-          (a)         Situation                  (b)     Situation
ferences, the feature-based alternative performs substantially                 World          Agent                World         Agent
worse than a ToM-based model with many fewer parameters.                        State         State                State         State
                                                                                  Observation                        Observation
               Computational framework
                                                                                   Principle of          Agent        Principle of         Agent
                                                                                  rational belief                    rational belief
A rapidly growing body of research suggests that human
judgments about intentional agents’ mental states (goals,                             Belief          Desire             Belief          Desire
preferences, beliefs) can be modeled as probabilistic in-                                   Principle of                       Principle of
                                                                                          rational action                    rational action
verse planning, inverse optimal control, or inverse decision-
making: Bayesian inferences over predictive models of                                         Action                             Action
agents’ rational behavior (Baker, Saxe, & Tenenbaum, 2009;
Lucas, Griffiths, Xu, & Fawcett, 2009; Bergen, Evans, &                Figure 1: Causal structure of Theory of Mind. Traditional accounts
Tenenbaum, 2010; Jern, Lucas, & Kemp, 2012; Baker, Good-               of ToM (e.g., Dennett, 1987; Wellman, 1990; Gopnik & Meltzoff,
                                                                       1997) have proposed informal versions of these schemata, charac-
man, & Tenenbaum, 2008; Ullman et al., 2010; Tauber &                  terizing the content and causal relations of ToM in commonsense
Steyvers, 2011). Here we adopt the Bayesian ToM (BToM)                 terms, e.g., “seeing is believing” for the principle of rational be-
formulation of Baker, Saxe, and Tenenbaum (2011), express-             lief. (a) Schematic of the Bayesian theory of mind (BToM) model
                                                                       proposed by Baker et al. (2011). Grey shaded nodes – World State
ing relations between the world’s state, an agent’s state, and         and Agent State – are assumed to be observed (for the observer; not
the agent’s observations, beliefs, desires, and actions in terms       necessarily for the agent, as described in the main text). (b) Our ex-
of a rational-agent model known as a partially observable              tension of BToM to allow inference of hidden aspects of the World
                                                                       State by observing an agent’s behavior. Here, the Agent State and
Markov decision process (POMDP) (Kaelbling, Littman, &                 Desire are observed, but the World State is only partially observable
Cassandra, 1998). This captures a probabilistic version of the         for both agent and observer.
classical rational agent who updates their beliefs to conform
with their observations and chooses sequences of actions ex-
pected to achieve their desires given their beliefs. The causal        closed.
schema for BToM is shown in Fig. 1(a).                                    Fig. 2(a) shows a hypothetical path that Harold could take,
   Baker et al. (2011) used the BToM model to explain hu-              ending in the North room. What, if anything, does this tell
man observers’ joint inferences about agents’ beliefs and de-          us about the cart locations? From where Harold enters the
sires, based on how these mental states guided agents’ ac-             food hall, he can observe the cart in the North room. Next,
tions exploring a small, spatially structured world with dif-          he checks the East room, indicating that either cart A is not
ferent sources of utility (candidate goals) in different loca-         in the North room, or that cart A is in the North room, but
tions. Observers had full knowledge of the agent’s situation           is closed. When Harold returns to the North room, only one
and world state, but the agent only learned about the world            possibility remains: that he saw cart A in the East room, but it
piecemeal (based on line-of-sight perceptual access) as it ex-         was closed, so he returned to the North room to eat at cart B,
plored. In contrast, in this paper we consider scenarios where         which was open (this cart configuration is shown in Fig. 2(d),
neither the agent nor the observer have full access to the state       row 1, column 3). Crucially, this inference also depends on
of the world. The agent again has line-of-sight perceptual             Harold’s not checking the West room, which is consistent
access, but the observer sees none of the utility sources (can-        with several other configurations in Fig. 2(d). In our exper-
didate goals) in the environment; these must be inferred from          iment, 66% of participants rated the correct configuration to
observing the agent’s movements. At first blush, this infer-           be the most likely in this condition (chance = 17%).
ence problem might seem hopelessly underconstrained; how-
ever, we will show that when the observer knows the agent’s            Informal Model Sketch
preferences, and if those preferences are strong enough, then          Fig. 1 sketches the causal schema for BToM. For concrete-
joint inferences about the agent’s beliefs and the unobserv-           ness, we will describe the content of the model in terms of
able world state are possible.                                         our food carts scenario, but in principle the BToM framework
   To illustrate how this works, consider the scenario shown           can be defined over arbitrary state and action spaces. In our
in Fig. 2. At a certain university food hall, every day at             food cart examples, there are 24 possible World States: 6 pos-
lunchtime three different food carts arrive: an Afghani (A)            sible cart configurations (shown in Fig. 2(d)) times 4 possible
cart, a Burmese (B) cart, and a Colombian (C) cart. The food           joint combinations of open/closed for carts A and B. There
hall contains three rooms, West (W), North (N) and East (E),           are 12 possible Agent States, one for each grid square in the
and on any given day, any cart can be in any room. Harold,             food hall scenario. Agents’ Observations provide information
the student shown in the figure, always prefers to eat at cart         about the World State, conditioned on the Agent State, and
A over carts B and C, and prefers to eat at cart B over cart           are based on line-of-sight visibility – Fig. 2(b,c) give exam-
C. Furthermore, carts A and B can be open or closed when               ples of what can be seen from different vantage points. The
Harold arrives; he only goes to a cart if he sees that it is open.     observer represents an agent’s Belief as a probability distri-
Cart C is always open and is the last resort when all others are       bution over possible World States. The observer maintains a
                                                                   516

  (a)                  N                    (b)             B                    p(A|D,W, S) =        ∑ p(A|B, D) ∑ p(B|O)p(O|W, S).       (1)
                                                                                                      B             O
                                                                                 In Fig. 1(b), the World State is unknown, and the prob-
                                                                              lem of “learning what is where” involves inferring the World
                                            (c)                               State, given an agent’s Desire and Action using Bayes’ rule:
                                                            B
                     Entrance                                                                p(W |A, D, S) ∝ p(A|D,W, S)p(W ).             (2)
   W                                E
                                                                              Intuitively, this involves evaluating the likelihood of every
                                                                    A         possible World State, given the agent’s Action, Desire and
  (d)       A                       A                        B                Agent State, and integrating these likelihoods with the prior
                                                                              over possible World States. Evaluation of each likelihood also
                                                                              requires simultaneously inferring and updating the agent’s
                                                                              Beliefs over time.
 C                 B       B               C      C                 A
            B                        C                       C                An alternative cue-based model
                                                                              To assess the intrinsic difficulty or logical complexity of our
                                                                              task, we formulated a cue-based alternative to our BToM ac-
                                                                              count of social inference of food cart locations. We name the
  A                C       B               A      A                  B        alternative model F-40; the model considered 7 key features
                                                                              and fit 40 free parameters (one for each feature, plus an addi-
Figure 2: Example experimental stimulus. (a) Example of an ob-
served path. The task is to figure out where each of three food carts         tive constant, multiplied by 5 independent response variables)
is, given the trajectory the agent took. (b) In the agent’s initial posi-     using multinomial logistic regression to minimize the error
tion he can observe the North spot with food truck B in it. However,          in prediction of human judgments. The features were cho-
he doesn’t know where his favorite cart A is. (c) Agent’s state when
he travels to the entrance of the East hallway. He can now observe            sen to capture key moments in the paths that were strongly
cart A being closed and remembers having seen cart B in the North             indicative of a preferred cart being in a particular location.
spot. With this information he can deduce that cart C is in the West          Specifically, for each room, we assigned a unique vantage
room and so his best option is to choose the North spot, produc-
ing the path shown in (a). (d) Possible configurations the carts can          point at which the agent could see what was in that room,
take independent of them being closed or open. In the experiment,             and could choose to either commit to eating at that room by
subjects ranked these six configurations for each path.                       moving North/South, or commit to moving to another van-
                                                                              tage point by moving East/West. The set of vantage points is
                                                                              indicated by the marked cells in Fig. 5. Features Toward and
finite set of possible Beliefs the agent could hold, drawn from               Away were computed for each room by counting the number
a prior over initial Beliefs, and simulates the agent’s Belief                of times the agent moved to or away from that room, starting
update for each possible Observation, given the Agent State                   from that room’s vantage point. In addition to the 6 Toward
and World State. An agent’s Desire is captured by utilities for               and Away features, the 7th feature recorded whether or not the
each cart which capture the preference relation A  B  C.                    condition was part of the introduction (in which carts could
    Given the representational content of the nodes, BToM ex-                 not be closed) or the main experiment. Because of its large
presses the functional form of the causal relations in Fig. 1 in              number of free parameters, we hypothesized that F-40 would
terms of POMDPs, which capture the dual principles of ratio-                  capture those regularities in people’s judgments that could be
nal Belief and Action in Fig. 1. To generate a POMDP policy                   explained by low-level movement properties.
for each initial Belief point, we employ an implementation of
the SARSOP algorithm (Kurniawati, Hsu, & Lee, 2008), pro-                                              Experiment
vided by the APPL POMDP solver. These policies represent                      Design
a predictive, Belief- and Desire-dependent distribution over
                                                                              Fig. 2 illustrates our experimental design. On each trial, sub-
the agent’s actions.
                                                                              jects were shown either a complete or an incomplete path that
    The schema in Fig. 1 illustrates the conditional dependen-                the agent took. They were then asked to rate on a scale from 0
cies involved in the model of the agent. For clarity, in this in-             to 10 (with 0 meaning “Definitely Not”; 10 “Definitely”; and
formal sketch we suppress the temporal nature of the model;                   5 “Maybe”) how much they believed each possible configura-
technical details of dynamic inference are provided in Baker                  tion of carts was the real one. Fig. 2(d) shows the six possible
et al. (2011). The predictive distribution over the agent’s Ac-               configurations of carts that subjects rated on each trial. Food
tion, given its Desire, Beliefs, the World State and the Agent                cart names as well as stimulus order were randomized across
State (abbreviating variable names as A, D, B, W, S respec-                   subjects. For simplicity we will refer to the carts as Afghani
tively) is:                                                                   (A), Burmese (B), and Colombian (C), always with the pref-
                                                                              erence order: A  B  C.
                                                                          517

   In this scenario there are 24 possible worlds (6 possible             In contrast, the F-40 model has forty free parameters fit
permutations of the cart’s locations multiplied by 4 permuta-         to the average subject ratings, and so, by construction, the
tions of carts A and B being open or closed). Stimuli were            fit is very close to human judgment. Looking deeper into
generated as follows. We assume that the agent always starts          the model, there were no outstanding predictive features of
at the entrance of the North hallway, being able to chose be-         the path that would determine the food cart ordering. That
tween entering that hall, going to the West hall, or going to         is, F-40 shows a great capacity to mimic human reasoning,
the East hall. An exhaustive list of possible paths was con-          but it fails to capture the essence of the task. This clear in
structed by listing all possible combinations of the short-term       Fig. 4, where we can see that mean human judgments have a
goals of the agent (go to entrance of W hall, go to entrance of       r = 0.91 correlation with the BToM model, but a correlation
N hall, and go to entrance of W hall), assuming that the first        of r = 0.64 with the F-40 model. As we can see in the scat-
time a hall is selected it is for the purpose of exploration, and     terplot, BToM comes much closer to explaining the variance
any selection of a hall that had been selected before is for ex-      in the human data, while F-40 is much less accurate over-
ploitation, meaning the agent has chosen where to eat. From           all. Fig. 4(c) shows that for a strong majority of individual
the eleven exhaustively enumerated paths, two paths that only         subjects, the BToM model provides a superior fit. To further
produced permutations of beliefs were removed, leaving a to-          assess the statistical significance of the models we performed
tal of 9 complete paths. In addition, 7 incomplete paths (sub-        a Bootstrap Cross-Validated Correlational Analysis (Cohen,
sequences of the 9 complete paths) which produce different            1995). For 10,000 iterations, we trained F-40 on randomly
judgments were selected. Lastly, three of these paths were            selected subsets of paths and compared its performance on
duplicated in initial displays in which all carts are assumed         the remaining untrained paths. This produced average cor-
to be open, shown to subjects to familiarize them with the            relations of r = −0.0733, −0.0832 and 0.0830, for training
task. This produced a total of 19 different paths (see Fig. 3)        sets of size 16, 17 and 18 (and testing sets of size 3, 2, and 1),
for which each subject rated the six possible configurations          respectively. A similar analysis with BToM (for which no pa-
of carts, for a total of 114 judgments per subject.                   rameters were fit to data) yielded correlations of r = 0.9015,
                                                                      0.8922 and 0.8714 for testing sets of size 3, 2 and 1, respec-
Participants                                                          tively. These analyses suggest that the feature-based model is
200 U.S. residents were recruited using the Amazon Mechan-            not tapping into the cognitive mechanisms underlying human
ical Turk. 176 subjects were included in the analysis, with 24        performance, but rather just fitting the data without strong
excluded due to server error.                                         predictive power.
                                                                         This is clear in Fig. 5, where two paths that contrast the
Procedure
                                                                      models’ performance are shown. For path 1, BToM is capa-
Subjects first completed a familiarization stage, which began         ble of realizing that if the carts were set as C, B, A/closed in
with an explanation of the basic food cart setting, and allowed       positions West, North, and East respectively, then the agent
subjects to provide judgments for three paths where the food          would have no reason to visit the West position, since by the
carts were assumed to always be open. Next, the possibility           time it has observed B and A/closed it already has all the in-
that carts could be closed was introduced with a step by step         formation it needs to make its final choice. It is this type of
example. The experimental stage immediately followed.                 fine grained reasoning that allows BToM to make subtle infer-
                                                                      ences when F-40 fails as a result of mimicking the data rather
Results
                                                                      than predicting it.
We begin by analyzing the fit between people’s judgments
and our two models. Fig. 3 shows the average human rat-                                         Discussion
ing of the likelihood of each cart configuration, the BToM
model, and the F-40 model. In Fig. 3 it is clear that both            In this work we have proposed a Bayesian Theory of Mind
models perform well in capturing the general contours of the          model to explain how we make sense of the world by observ-
mean subject belief, but with a quantitative difference in their      ing how others interact with it. Our experiment shows that
explanatory power.                                                    subjects produce very similar predictions to that of the ideal
   The BToM model has four parameters that were not fit to            Bayesian observer. We have compared the BToM model to
the data: three parameters indicating how strong the prefer-          a feature-based regression model (F-40) that was fit to sub-
ence for each food cart is, and a discount parameter indicating       jects’ mean judgments. Although the F-40 model appears to
the tradeoff between immediate and delayed rewards. Intu-             be a good competitor, we show that at both the individual and
itively, these four parameters together determine whether an          average level, the correlation with the BToM model is sub-
agent is willing to spend time and energy finding food carts          stantially higher compared to the correlation with F-40. Fur-
he likes better or whether he should settle for a closer cart.        ther analysis showed how BToM is capable of more subtle,
These parameters were set only qualitatively, to ensure that          fine-grained reasoning, making sensible inferences in several
the agent would have a strong preference order that would             situations where F-40 gives counter-intuitive predictions.
motivate him to explore the environment until he finds the               One interesting point is that the BToM model is more sensi-
best option.                                                          tive to the precise geometry of the environment than humans
                                                                  518

   1                                     1                                   1                                  1
 0.5                                   0.5                                0.5                                 0.5
   0                                     0                                   0                                  0
        A A B B C C                          A A B B C C                         A A B B C C                       A A B B C C
        C B B C CA AC B A A B               C B B C CA AC B A A B               C B B C CA AC B A A B              C B B C CA AC B A A B
   1                                     1                                   1                                  1
 0.5                                   0.5                                0.5                                 0.5
   0                                     0                                   0                                  0
         A A B B C C                         A A B B C C                         A A B B C C                       A A B B C C
        C B B C CA AC B A A B               C B B C CA AC B A A B               C B B C CA AC B A A B              C B B C CA AC B A A B
   1                                     1                                   1                                  1
 0.5                                   0.5                                0.5                                 0.5
   0                                     0                                   0                                  0
         A A B B C C                         A A B B C C                         A A B B C C                       A A B B C C
        C B B C CA AC B A A B               C B B C CA AC B A A B               C B B C CA AC B A A B              C B B C CA AC B A A B
   1                                     1                                   1                                  1
 0.5                                   0.5                                0.5                                 0.5
   0                                     0                                   0                                  0
         A A B B C C                         A A B B C C                         A A B B C C                       A A B B C C
        C B B C CA AC B A A B               C B B C CA AC B A A B               C B B C CA AC B A A B              C B B C CA AC B A A B
   1                                     1                                   1
                                                                                                                          Human Judgments
 0.5                                   0.5                                0.5                                             BToM Model
                                                                                                                          F-40 Model
   0                                     0                                   0
         A A B B C C                         A A B B C C                         A A B B C C
        C B B C CA AC B A A B               C B B C CA AC B A A B               C B B C CA AC B A A B
Figure 3: Mean subjects’ judgments (normalized degrees of belief in each of six possible configurations of the food carts), along with BToM
and F-40 predictions for the 19 displayed paths. The agent’s preference order for these carts is always known to be A  B  C, and carts A
and B may be open or closed. The first three conditions were those used in the familiarization phase. The second block used “completed”
paths, in which the agent committed to a particular cart in the last frame. The last block of conditions used “incomplete” paths, in which the
agent’s final destination had not yet resolved.
seem to be. Specifically, because of the asymmetry of the                  the (B) food truck was in the East room but that the agent had
hallway in our experiment, the model assigned a significantly              a prior belief that it was closed and therefore did not bother
higher cost to checking the West hallway versus checking the               checking it. Analogous disparities were found by Baker et
East hallway. Thus, when the model observed the agent go-                  al. (2011), and in ongoing work we are investigating more
ing West, it reasoned that the agent must have had some prior              qualitative representations of the spatial structure of the en-
belief in the presence of a high value cart in the West hall-              vironment that might support a closer match between BToM
way or a low value cart in the East hallway that made him                  model reasoning and human judgments.
go through the more lengthy path versus the shorter path to                   In sum, these results show the power of social inference
check the East hallway. In contrast, subjects did not appear to            for acquiring surprisingly fine-grained knowledge about the
be sensitive to the distance mismatch and produced relatively              world. ToM is typically thought of as a system of knowl-
symmetric judgments on paths that had the same structure                   edge for reasoning about the mental states and actions of in-
but traveled in opposite directions. This is particularly evi-             tentional agents, but it is not only that. In the context of a
dent in the plot (3,1) of Fig. 3. In this path, subjects believed          Bayesian framework, actions of other agents become clues to
that the agent had already found carts (A) and (B) and there-              any aspects of the environment that causally influence their
fore had no need to visit the East room. The model however,                behavior – sometimes the only clues available. ToM thus also
when observing the agent choose the longer path, reasoned                  provides an essential tool for learning about the world.
that there was some prior belief the agent had that could have
been wrong. This leads the model to consider it possible that
                                                                       519

(a)                                    (b)                             (c)
         0.6
         0.5
                                             0.6
                                             0.5
                                                                           1
                                                                         0.8                                             B                                 B
People
         0.4
         0.3                           People
                                             0.4
                                             0.3                   r F−40
                                                                         0.6
                                                                         0.4
                                                                         0.2
                                                                                                              BToM                               F-40
         0.2                                 0.2
                          r=0.91                          r=0.64           0
         0.1                                 0.1
           0                                   0                        −0.2
               0    0.5            1            0   0.5            1        −.2 0 .2 .4 .6 .8 1                         Entrance                          Entrance
                   BToM                             F−40                         r BToM
Figure 4: Comparison of models and normalized human judgments.
                                                                                                         A                          C C                               A
(a) BToM vs. mean normalized human judgments. Each point repre-
sents a mean human rating plotted against the corresponding model
prediction; there are 114 points in all (19 conditions times ratings                                                     B                                 B
                                                                                                                                                 F-40
for 6 possible cart configurations), with an overall correlation of
r = 0.91. (b) F-40 vs. mean normalized human judgments; analo-                                                BToM
gous to analysis (a), with an overall correlation of r = 0.64. (c) Scat-
ter plot of individual subjects’ correlations with BToM vs. individ-
ual subjects’ correlations with F-40; 176 points in all (one point for                                                  Entrance                          Entrance
each subject). For 80% of subjects, the correlation between BToM
                                                                                                         C                          A A                               C
and that subject’s ratings is higher than the correlation of F-40 with
that subject’s ratings. The bold “X” plots the correlation of BToM
with the mean human judgments vs. that of F-40.
                                                                                                        Figure 5: Comparing MAP predictions (the configuration shown for
                                                                                                        each path) of BToM and F-40 models for two different paths. F-40’s
Acknowledgements This work was supported by                                                             errors reveal how a non-mentalistic approach fails to use context
ARO MURI contract W911NF-08-1-0242 and ONR                                                              specific reasoning to make accurate predictions. For the F-40 model,
                                                                                                        marked grid squares indicate “vantage points” used to compute the
MURI contract 1015GNA126.         We thank the Mo-                                                      features.
tion Modeling, Analysis and Planning group at
the National University of Singapore for providing
the APPL POMDP solver.         APPL is available at:                                                    Gopnik, A., & Meltzoff, A. N. (1997). Words, thoughts, and
http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl.                                                          theories. Cambridge, MA: MIT Press.
                                                                                                        Jern, A., Lucas, C. G., & Kemp, C. (2012). Evaluating the
                                             References                                                   inverse decision-making approach to preference learning.
                                                                                                          In Advances in Neural Information Processing Systems.
Baker, C. L., Goodman, N. D., & Tenenbaum, J. B. (2008).                                                Kaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998).
  Theory-based social goal inference. In Proceedings of the                                               Planning and acting in partially observable stochastic do-
  Thirtieth Annual Conference of the Cognitive Science So-                                                mains. Artificial Intelligence, 101, 99–134.
  ciety (pp. 1447–1455).                                                                                Kurniawati, H., Hsu, D., & Lee, W. (2008). SARSOP: Effi-
Baker, C. L., Saxe, R., & Tenenbaum, J. B. (2009). Action                                                 cient point-based POMDP planning by approximating op-
  understanding as inverse planning. Cognition, 113, 329–                                                 timally reachable belief spaces. In Proc. Robotics: Science
  349.                                                                                                    and Systems.
Baker, C. L., Saxe, R., & Tenenbaum, J. B. (2011). Bayesian                                             Lucas, C. G., Griffiths, T. L., Xu, F., & Fawcett, C. (2009). A
  theory of mind: Modeling joint belief-desire attribution. In                                            rational model of preference learning and choice prediction
  Proceedings of the Thirtieth Third Annual Conference of                                                 by children. In Advances in Neural Information Processing
  the Cognitive Science Society (p. 2469-2474).                                                           Systems 21 (pp. 985–992).
Bergen, L., Evans, O. R., & Tenenbaum, J. B. (2010). Learn-                                             Tauber, S., & Steyvers, M. (2011). Using inverse planning
  ing structured preferences. In Proceedings of the Thirty-                                               and theory of mind for social goal inference. In Proceed-
  Second Annual Conference of the Cognitive Science Soci-                                                 ings of the Thirtieth Third Annual Conference of the Cog-
  ety (pp. 853–858).                                                                                      nitive Science Society.
Cohen, P. R. (1995). Empirical methods in artificial intelli-                                           Ullman, T. D., Baker, C. L., Macindoe, O., Evans, O., Good-
  gence. Cambridge, MA: MIT Press.                                                                        man, N. D., & Tenenbaum, J. B. (2010). Help or hinder:
Csibra, G., Biró, S., Koós, O., & Gergely, G. (2003). One-                                              Bayesian models of social goal inference. In Advances
  year-old infants use teleological representations of actions                                            in Neural Information Processing Systems 22 (pp. 1874–
  productively. Cognitive Science, 27, 111-133.                                                           1882).
Dennett, D. C. (1987). The intentional stance. Cambridge,                                               Wellman, H. M. (1990). The child’s theory of mind. Cam-
  MA: MIT Press.                                                                                          bridge, MA: MIT Press.
Goodman, N. D., Baker, C. L., & Tenenbaum, J. B. (2009).
  Cause and intent: Social reasoning in causal learning. In
  Proceedings of the Thirty-First Annual Conference of the
  Cognitive Science Society (pp. 2759–2764).
                                                                                                  520

