UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Do you see what I'm singing? Visuospatial movement biases pitch perception

Permalink
https://escholarship.org/uc/item/5d138552

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Connell, Louise
Cai, Zhenguang
Holler, Judith

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Do You See What I'm Singing? Visuospatial Movement Biases Pitch Perception
Louise Connell (louise.connell@manchester.ac.uk)
Zhenguang G. Cai (zhenguang.cai@manchester.ac.uk)
School of Psychological Sciences, University of Manchester, Oxford Road, Manchester M13 9PL, UK

Judith Holler (judith.holler@mpi.nl)
Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD, Nijmegen, Netherlands
School of Psychological Sciences, University of Manchester, Oxford Road, Manchester M13 9PL, UK
Abstract

order to create a common spatial code (Bryant, 1992;
Giudice, Betty, & Loomis, 2011; Lacey, Campbell, &
Sathian, 2007). Numerous studies have shown that
activating pitch also activates space along the vertical axis.
A high-pitch prime leads people to explicitly relate it to a
high spatial location (Pratt, 1930), and to implicitly attend to
a visual target (Walker et al., 2010) or make a manual
response (Rusconi et al., 2006) in a high spatial location.
However, the above findings cannot distinguish between an
associative mapping explanation, where representations of
pitch and space are separate but linked, and a shared
representation explanation, where pitch and space share
common representational and processing resources.
According to an associative mapping explanation, the
representation of musical pitch is purely auditory in nature.
An individual's perception of a note’s pitch would
essentially comprise a modality-specific auditory
representation of its sound frequency, and one would recall
its pitch as a simulation (i.e., a partial replay of the neural
activation that arose during experience: Barsalou, 1999) of
that frequency. Perceiving a high pitch note rapidly
activates a high spatial location because the two
representational dimensions are directly associated, as are
the dimensions of pitch and loudness (McDermott et al.,
2008) or pitch and happiness (Eitan & Timmers, 2010).
Notwithstanding these associations, pitch perception and
discrimination itself remains an exclusively auditory matter.
Conversely, a shared representation explanation for
pitch/space effects would hold that the representation of
musical pitch is audiospatial in nature. Here, an individual's
perception of a note’s pitch would comprise an audiospatial
representation of both its sound frequency and its height on
the vertical axis. One would then recall its pitch as an
auditory and spatial simulation of that frequency and height.
People may therefore be willing to map musical pitch to
other dimensions because they all share a common spatial
grounding (i.e., are mediated by space): for example, both
loudness (Eitan, Schupak, & Marks, 2010) and emotional
valence (Meier & Robinson, 2004) show similar effects to
pitch in vertical space. Pitch perception and discrimination,
therefore, is obligatorily audiospatial.
In the present studies, we aimed to distinguish between
these two explanations by using a basic psychophysical task
of pitch discrimination, where participants must judge
whether a target vocal note is the same as (or different from)
a preceding cue note. Importantly, target trials were
presented as video clips where a singer sometimes gestured
upward or downward while singing that target note, thus

The nature of the connection between musical and spatial
processing is controversial. While pitch may be described in
spatial terms such as “high” or “low”, it is unclear whether
pitch and space are associated but separate dimensions or
whether they share representational and processing resources.
In the present study, we asked participants to judge whether a
target vocal note was the same as (or different from) a
preceding cue note. Importantly, target trials were presented
as video clips where a singer sometimes gestured upward or
downward while singing that target note, thus providing an
alternative, concurrent source of spatial information. Our
results show that pitch discrimination was significantly biased
by the spatial movement in gesture. These effects were
eliminated by spatial memory load but preserved under verbal
memory load conditions. Together, our findings suggest that
pitch and space have a shared representation such that the
mental representation of pitch is audiospatial in nature.
Keywords: mental representation; pitch perception; music;
gesture; spatial representation; metaphor

Introduction
Musical and spatial processing are interlinked, but the exact
nature and extent of the connection is controversial. People
with amusia (i.e., an impaired ability to discriminate pitch)
have corresponding spatial deficits in some reports (Douglas
& Bilkey, 2007), but others have failed to replicate the
association (Tillman et al., 2010; Williamson, Cocchini, &
Stewart, 2011). People have been found to map musical
pitch to vertical spatial locations (Pratt, 1930; Rusconi,
Kwan, Giordano, Umiltà, & Butterworth, 2006), but they
are also willing to map it to psychophysical luminosity and
loudness (Hubbard, 1996; McDermott, Lehr, & Oxenham,
2008), and to words denoting emotion, size, sweetness,
texture and temperature (Eitan & Timmers, 2010; Walker &
Smith, 1984). Thus, while pitch may be described in spatial
terms such as “high” or “low”, it remains unclear whether
pitch and space are merely two amongst many associated
dimensions or whether the representation of pitch is
fundamentally spatial.
Pitch is a psychoacoustic property that corresponds to
waveform frequency; its representation involves the primary
auditory cortex but the full neural specification of pitch
processing is still not well understood (e.g., Bendor, 2011).
Space is a physical property of the three-dimensional body
we occupy and the world through which we move, and is
represented in a multimodal or supramodal system that takes
input from vision, touch, and other perceptual modalities in

252

providing an alternative, concurrent source of spatial
information. Signal detection analysis then allowed us to
isolate the response criterion of pitch discrimination (i.e.,
underlying bias towards the belief that pitch has or has not
changed), for which the two accounts produced differing
predictions. An associative mapping explanation of the
pitch/space relationship would predict that a concurrent
spatial stimulus should have no effect on response criterion.
Because pitch representations are purely auditory, people
can discriminate pitch on the basis of auditory frequency,
regardless of what other processing might be taking place in
the spatial system. Only in the shared representation
account, where the audiospatial representation of musical
pitch cannot be disentangled from the visuospatial
representation of vertical gesture, would a criterion shift
emerge. Because pitch representation is audiospatial,
people cannot discriminate pitch without being biased by
concurrent spatial movement.

Figure 1: Stills from video stimuli, showing a singer
gesturing downward, at rest with no gesture, and gesturing
upward. Arrows indicate extent and direction of movement.
Hz) to A4 (440 Hz) for the female actor. The fundamental
frequency of these vocal notes was a maximum of 17 cents
(17% of a whole tone) away from the intended pitch. Each
actor was filmed moving the right hand downward or
upward for the duration of the note, (i.e., downward or
upward gesture), or resting their hands naturally on the lap
(i.e., no gesture) (see Figure 1). In order to ensure stimulus
consistency in gestural and vocal behaviour, we overdubbed
the best gesture videos with the best target notes, and
ensured each final stimulus was a seamless synchronization
of mouth movement, gesture movement, and sung vocal.
All 48 target videos lasted 1.4 seconds.
Cue notes consisted of synthesized notes at the same
fundamental frequencies as the target notes, created with
Garageband software with the Classical Ensemble voice
(which sounded like a mixed choir of male and female
vocalists). We chose to use synthesized human voices in
order to avoid the spatial pitch characteristics associated
with musical instruments (e.g., horizontal for a piano,
vertical for a clarinet), and to give cue notes a similar timbre
to target notes while still allowing us to use the same type of
cue for male and female actors' notes. We then edited the
synthesized cue notes in Audacity to replicate the target
sung notes' frequency exactly (same pitch), or to shift it one
semitone up (higher pitch) or down (lower pitch).
Cue and target stimuli were paired so that each target note
(accompanied by a downward gesture, no gesture, or
upward gesture) was preceded by a cue note of the same
pitch, higher pitch, or lower pitch. We divided these 144
pairs into two materials lists, where both lists included all 48
same-pitch pairs, and the remaining stimuli were distributed
so each list had 24 higher-pitch and 24 lower-pitch pairs
(i.e., an equal number of same and different pitch).

Experiment 1: Biasing Pitch
In this and the following experiments, participants watched
target trials of an actor gesturing while singing a particular
musical note.
Gestures frequently and effectively
communicate spatial information to recipients that goes
beyond what is conveyed in speech (Graham & Argyle,
1975; Holler, Shovelton, & Beattie, 2009).
Our
nonlinguistic combination of gesture and pitch stimuli
therefore allowed us to embed spatial information in a
naturalistic context to which people are sensitive, but in a
less obtrusive manner than pairing pitch with (for example)
geometric shapes.
Our hypotheses were simple. If the shared representation
explanation is correct and pitch representations are
audiospatial, then spatial information in concurrent gesture
should influence pitch discrimination in two specific ways.
First, the spatial movement of gesture should bias
participants towards the belief they had perceived a pitch
movement (i.e., that the target note was different to the cue).
Furthermore, participants should be sensitive to the
direction of spatial movement, where downward gestures
would make pitch appear lower in frequency, and upward
gestures would make pitch appear higher in frequency. On
the other hand, if the associative mapping explanation is
correct, then none of these effects would appear.

Method
Participants Thirty-two native speakers of English from
the University of Manchester took part in the experiment.
Five were replaced when funnel debriefing indicated they
were aware of the potential effect the gestures could have
had on their pitch discrimination judgements. All were
right-handed, had no hearing impairment, and were nonmusicians (i.e., not musically trained). They received course
credits or £4 for participation.

Procedure Participants were instructed that they should
watch videos of professional actors singing musical notes,
and, in each case, judge as quickly and accurately as
possible whether the actor's sound was the same pitch as an
earlier musical note. The experiment was run with Superlab
4.0 on a MacBook laptop, with videos displayed onscreen at
approximately 14 x 10.5 cm. Participants were randomly
assigned to one of the two material lists and were tested
individually in a lab cubicle. In each trial, they first saw a
fixation cross for 500 ms, then heard the synthesized note,
and immediately afterwards saw the target note video. After

Materials Target notes consisted of 16 vocal notes, sung by
professional actors/singers on a major scale from A2 (110
Hz) to A3 (220 Hz) for the male actor, and from A3 (220

253

the video, a screen appeared with the prompt “SAME
DIFFERENT”, and participants were asked to press the lefthand key on a response box if they thought the actor's sound
was the same pitch as the earlier musical note, or the righthand key if they thought it was a different pitch to the earlier
musical note (left/right mapping to same/different responses
counterbalanced). If participants pressed the “different” key,
another screen appeared with the prompt “HIGHER
LOWER”, and participants were asked to press the left-hand
key if they thought the actor's sound was a higher pitch than
the earlier musical note, or the right-hand key if they
thought it was a lower pitch (left/right mapping to
higher/lower responses counterbalanced). There was a
blank of 500 ms between trials.
Within each lost of materials, stimuli were arranged into
six blocks so that each of the 16 target notes appeared once
per block (gestures counterbalanced). The order of blocks
was fixed but presentation of trials within a block was
randomized per participant. Participants performed 4
practice trials before the main experiment, and the whole
procedure lasted for about 15 minutes.

= .006, ηp2 = .187) and upward (p = .011, ηp2 = .156)
gestures compared to when notes were unaccompanied by
gesture. Upwards and downward gestures had the same
response bias (p = .999). Participants' increased propensity
to make “different” responses in the presence of gesture did
not affect their overall sensitivity in pitch discrimination,
F(2, 62) = 2.04, p = .139, ηp2 = .062, with equivalent
performance in no-gesture (d' = 1.79), downward (d' = 1.99)
and upward (d' = 1.83) gesture conditions.
Analysis of error trajectory also followed predictions (see
Figure 3, left panel). The nature of errors that people made
was influenced by gesture, F(2, 54) = 9.23, p < .001, ηp2 = .
255. Specifically, planned comparisons showed that,
relative to the no-gesture condition, downward gestures
increased the number of downward trajectory errors (p = .
007, ηp2 = .205) while upward gestures reduced them (p = .
043, ηp2 = .105).1

Experiment 2: Spatial Memory Load
If the shared representation explanation of pitch/space
effects is correct, then the criterion shift and error trajectory
in Experiment 1 emerge from an overlapping spatial
representation of gestural movement and pitch. A spatial
memory load should therefore attenuate these effects by
occupying resources required for audiospatial pitch
discrimination. Holding a spatial load in memory should
remove the biasing effect of spatial movement on pitch
discrimination, meaning that people will remain quite liberal
in their tendency to assume that notes are the same.
Consequently, the direction of spatial movement should no
longer drive the trajectory of error to the same extent.

Design & Analysis We ran two stages of analysis of
variance, each with a single within-participants factor of
gesture (downward, no-gesture, upward) and effect sizes
reported as partial eta-squared (ηp2). First, signal detection
analysis examined performance on the same/different
judgments to determine if gesture affected people's response
bias and sensitivity in pitch discrimination. “Different”
responses to different-pitch targets constituted hits, and
those to same-pitch targets constituted false alarms. For
each participant, we then calculated criterion c (criterion or
bias) and d' (sensitivity) statistics for each gesture condition
(e.g., Stanislaw & Todorow, 1999).
Second, we examined the trajectory of error to determine
whether downward gestures made notes seem lower than
they really were (and upward gestures higher). Each error
in the same/different and higher/lower judgments
represented an upward or downward response trajectory: for
example, a downward trajectory was one where (1) a samepitch target was judged to be lower in pitch, (2) a higherpitch target was judged to be the same pitch, or (3) a higherpitch target was judged to be lower in pitch. For each
participant, we calculated the proportion of downward
errors out of all errors in each gesture condition. Four
participants with empty cells (i.e., perfect accuracy in one or
more conditions) were excluded from trajectory analysis.

Method
Participants Thirty-two new participants took part under
the same criteria as Experiment 1. Five participants were
replaced for awareness of the gesture effect. All had
adequate recall of the spatial memory load (i.e., correctly
recalled four or more out of six grids, see Materials).
Materials Stimuli were as per Experiment 1. In addition,
items in the spatial memory task consisted of six different 3by-3 grids (plus one for practice) in which five random cells
had been filled with an X.
Procedure Instructions were identical to Experiment 1
except that participants were asked to hold in memory a
visually-presented spatial grid during each block of the task.
Before each of the six blocks, participants saw a spatial grid
onscreen and could study it until they were satisfied they
had memorised it. At the end of the block, participants were

Results & Discussion
People found the pitch discrimination task moderately
difficult, with overall accuracy of 71.1%. Signal detection
analysis supported the shared representation prediction that
the spatial movement in gesture would affect pitch
discrimination. There was a criterion difference between
gesture types, F(2, 62) = 4.57, p = .014, ηp2 = .129, as
shown in Figure 2 (left panel). Most trials showed a bias
towards “same” responses (i.e., c > 0), but planned
comparisons showed this bias was weaker for downward (p

1
Although our participants were not musically trained, this fact
did not preclude some level of knowledge about music; at the end
of the experiment, we therefore gave participants a questionnaire to
probe their exposure to music instruction (e.g., experience of
playing a musical instrument, ability to distinguish pitch
differences in staff notation). Musical knowledge was unrelated to
either global response criterion r(30) = -.055, p = .765, or
downward error trajectory r(26) = -.182, p = .354, though it did
correlate positively with overall sensitivity r(30) = .597, p < .001.

254

Figure 2: Response criterion in pitch discrimination (i.e., bias towards belief that target note was same as / different to cue)
per gesture condition in Experiment 1-3. Error bars show within-participants 95% CI.

Figure 3: Proportion of pitch discrimination errors that expressed a downward trajectory (i.e., where participants thought the
note was lower in pitch than reality) per gesture condition in Experiments 1-3. Error bars show within-participants 95% CI.
asked to recall the grid by drawing the positions of the Xs
on a blank grid; these were later coded for accuracy (a grid
must be perfectly recalled to qualify as an accurate
response). The experiment lasted approximately 20 minutes.

= 2.01, downward gesture d' = 1.92, upward gesture d' =
1.88.
Analysis of error trajectory showed attenuated effects
compared to Experiment 1 (see Figure 3, centre panel).
Spatial movement in gesture had an influence on the
direction of error, F(2, 50) = 3.61, p = .034, ηp2 = .191.
Downward gestures led to more downward trajectory errors
than no gesture (p = .034, ηp2 = .127), but upward gestures
did not reduce their occurrence relative to no gesture (p = .
406, ηp2 = .002). 2

Design & Analysis As in Experiment 1. Six participants
with perfect accuracy in one or more conditions were
excluded from trajectory analysis.

Results & Discussion
Overall accuracy was similar to Experiment 1 at 73.8%.
Signal detection analysis confirmed the predictions of the
shared representation account that a spatial memory load
would eliminate the biasing effect of spatial movement on
pitch discrimination. There was no longer any criterion
difference between gesture types, F(2, 62) = 0.15, p = .856,
ηp2 = .005 (see Figure 2, centre panel): a similar bias
towards “same” responses appeared for downward, upward
and no-gesture conditions (all ps > .3, ηp2s < .009).
Sensitivity of pitch discrimination was unaffected by
gesture, F(2, 62) = 1.11, p = .176, ηp2 = .054: no-gesture d'

Experiment 3: Verbal Memory Load
While the results of Experiment 1 support the shared
representation account of pitch/space effects, it is possible
that participants were silently labelling the pitch of the target
notes as “higher” or “lower” in preparation for the
discrimination task. The spatial movement in gesture could
then have interacted with the representation of this verbal
2
Musical knowledge was again unrelated to response criterion
r(30) = -.196, p = .282, and error trajectory r(24) = .084, p = .984,
and correlated with overall sensitivity, r(30) = .546, p = .001.

255

label rather than inducing a bias in pitch discrimination
itself. We therefore examined the origin of the criterion
shift by replicating the task while participants held a verbal
load in memory to block a linguistic labelling strategy. If the
shared representation explanation is correct, then the
criterion shift of Experiment 1 should emerge unscathed.
Furthermore, if the criterion shift re-emerges under a verbal
memory load, it will verify that the cancelled effects in
Experiment 2 were not due to generic processing difficulties
under memory load conditions but rather were specific to
spatial content.

sensitivity of pitch discrimination did not change with
gestural movement, F(2, 62) = 1.78, p = .176, ηp2 = .054,
with equivalent performance in no-gesture (d' = 1.68),
downward (d' = 1.89) and upward (d' = 1.84) gesture
conditions.3
Analysis of error trajectory again replicated Experiment 1
(see Figure 3, right panel). The nature of errors in pitch
discrimination was influenced by the spatial movement in
gesture, F(2, 56) = 6.62, p = .003, ηp2 = .191. Downward
gestures marginally increased the frequency of downward
trajectory errors compared to no gesture (p = .052, ηp2 = .
092) while upward gestures reduced their occurrence (p = .
034, ηp2 = .115).

Method
Participants Thirty-two new participants took part under
the same criteria as Experiment 1. Three participants were
replaced for inadequate recall of the verbal memory load
(i.e., anyone who recalled fewer than four out of six diphone
sequences, see Materials).

General Discussion
In the present paper, we show that concurrent visuospatial
movement biases pitch discrimination. Viewing upward and
downward gestures biased people towards believing they
had perceived a change in pitch, despite an underlying
tendency to assume that all notes were the same. Indeed,
when we examined the pattern of errors that people made,
we found that the direction of gesture was also driving the
direction of error: downward gestures made notes seem
lower in pitch than they really were, and upward gestures
made notes seem higher in pitch than they really were.
These effects were not due to a verbal labelling strategy as
they were preserved under verbal memory load. However,
their disappearance under spatial memory load conditions
indicates that the biasing effect is spatial in origin. Together,
these findings support the shared representation explanation
for the relationship between pitch and space.
When people hear a musical note, its pitch is not just
represented in the auditory modality.
Rather, its
representation is audiospatial, in that it comprises both an
auditory and spatial representation of the note's frequency.
However, things become more complicated when people
watch someone singing a note. On the one hand, if the
singer remains still, then the same story applies: the
audiospatial representation still reflects the note's pitch.
But, on the other hand, if the singer gestures with an upward
or downward movement, then both the visual gesture and
auditory note require representational resources in the
vertical spatial axis. Hence, the spatial information in the
gesture is co-perceived with that in the note, and results in
an audiospatial representation of the note's pitch that has
been modulated by the direction of spatial movement in the
gesture.
While many previous studies have examined the
relationship between pitch and vertical space, they could not
determine the nature of pitch representation because both
associative mappings and shared representations would lead
a pitch stimulus to prime its associated spatial location and
facilitate motor responses to that location (e.g., Rusconi et
al., 2006). However, a mapping from high pitch to high
spatial location would be static, and could not explain why

Materials Stimuli were as per Experiment 1. In addition,
items in the verbal memory task consisted of six different
sequences of three nonsense diphones (e.g., [tɛ kæ vo]); one
further sequence was used for practice. Each sequence was
recorded by a male native speaker with clear enunciation.
Procedure Instructions were identical to Experiment 1
except that participants were asked to hold in memory an
auditorily-presented diphone sequence during each block of
the task. Before each of the six blocks, participants listened
to a diphone sequence three times and repeated it back to the
experimenter (second author); if there were any errors in
repetition, the experimenter enunciated the sequence again
until participants got it right. At the end of each block,
participants recalled aloud the memorised diphone sequence
to the experimenter who transcribed it and later coded it for
accuracy (a sequence must be perfectly recalled to qualify as
an accurate response). Participants were familiarised with
diphone recall during the practice session. The experiment
took approximately 20 minutes to complete.
Design & Analysis As in Experiment 1. Three participants
with perfect accuracy in one or more conditions were
excluded from trajectory analysis.

Results & Discussion
Overall accuracy was similar to Experiment 1 at 69.3%.
Signal detection analysis replicated the findings of
Experiment 1, and confirmed that the biasing effect of
spatial movement on pitch discrimination was not due to a
verbal labelling strategy. Figure 2 (right panel) shows the
criterion difference emerged between gesture types, F(2, 62)
= 3.39, p = .040, ηp2 = .098. As before, the bias towards
“same” responses was weaker for downward (p = .040, ηp2
= .095) and upward (p = .009, ηp2 = .168) gestures
compared to when notes were unaccompanied by gesture.
Upwards and downward gestures had the same response
bias (p = .549). Since these “different” responses were
distributed across both correct and incorrect trials,

3
Musical knowledge was again unrelated to response criterion
r(30) = -.040, p = .828, or error trajectory r(27) = .044, p = .820,
and correlated with overall sensitivity, r(30) = .394, p = .026.

256

the spatial movement in gesture biased participants towards
believing they had perceived a movement in pitch. A
dynamic, shared representation of pitch and space, where
pitch is represented not only in terms of spatial position but
also movement and direction, is consistent with our results.
There are several possibilities as to how and why musical
pitch is represented in vertical space, and not in some other
spatial dimension. When speaking, producing a pitch higher
than normal voice frequency moves the larynx upward in
the throat, and producing a lower pitch moves it downward.
Furthermore, breathing from the top of the lungs by raising
and lowering the shoulders tends to produce higher-pitch
vocal notes, while breathing from the bottom of the lungs by
tensing and relaxing the thoracic diaphragm tends to
produce lower-pitch, resonant notes. Thus, cumulative
experience of our own voices provides a possible vertical
grounding for vocal pitch, which could then generalize to
pitch of other people's voices or musical instruments, and so
on. While some have claimed the appearance of pitch/space
effects in young infants means the connection between
domains is innate (Walker et al., 2010), even 3-4 month old
babies have considerable experience of vocalisation. A
conservative estimate of one hour per day crying, fussing
etc. (e.g., Michelsson, Rinne, & Paajanen, 1990) provides a
4-month old infant with over 100 hours experience of vocal
pitch under various body configurations. Since infants of
that age can learn statistical regularities in the environment
with only a few minutes' exposure (Kirkham, Slemmer &
Johnson, 2002), it seems premature to assume they could
not have learned to represent pitch spatially.
Future research will need to determine whether
pitch/space effects emerge from a learned or innate
mechanism, but, whatever its origin, the present paper
demonstrates that pitch is fundamentally audiospatial. The
nature of the link between musical and spatial processing is
one of shared representation.

sonata and those who follow crocodiles: Cross-domain
mappings of auditory pitch in a musical context.
Cognition, 114, 405–422.
Giudice, N. A., Betty, M. R., & Loomis, J. M. (2011).
Functional equivalence of spatial images from touch and
vision: Evidence from spatial updating in blind and
sighted individuals. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 37, 621-634.
Graham, J. A., & Argyle, M. (1975). A cross-cultural study
of the communication of extra-verbal meaning by
gestures. International Journal of Psychology, 10, 57–67.
Holler, J., Shovelton, H., & Beattie, G. (2009). Do iconic
hand gestures really contribute to the communication of
semantic information in a face-to-face context? Journal of
Nonverbal Behavior, 33, 73–88.
Hubbard, T. L. (1996). Synesthesia-like mappings of
lightness, pitch, and melodic interval. American Journal
of Psychology, 109, 219–238.
Kirkham, N.Z., Slemmer, J.A., & Johnson, S.P. (2002).
Visual statistical learning in infancy: Evidence of a
domain general learning mechanism. Cognition, 83, B35–
B42.
Lacey, S., Campbell, C., & Sathian, K. (2007). Vision and
touch: Multiple or multisensory representations of
objects? Perception, 36, 1513–1521.
McDermott, J. H., Lehr, A. J., & Oxenham, A. J. (2008). Is
relative pitch specific to pitch? Psychological Science, 19,
1263-1271.
Meier, B. P., & Robinson, M. D. (2004). Why the sunny side
is up: Associations between affect and vertical position.
Psychological Science, 15, 243–247.
Michelsson, K., Rinne, A., & Paajanen, S. (1990). Crying,
feeding and sleeping patterns in 1 to 12-month-old
infants. Child: Care, Health and Development, 16, 99111.
Nygaard, L. N., Herold, D. S., & Namya, L. L. (2009). The
semantics of prosody: Acoustic and perceptual evidence
of prosodic correlates to word meaning. Cognitive
Science, 33, 127–146.
Pratt, C. C. (1930). The spatial character of high and low
tones. Journal of Experimental Psychology, 13, 278–285.
Rusconi, E., Kwan, B., Giordano, B. L., Umilta, C., &
Butterworth, B. (2005). Spatial representation of pitch
height: The SMARC effect. Cognition, 20, 1–17.
Stanislaw, H., & Todorov, N. (1999). Calculation of signal
detection theory measures. Behavior Research Methods,
Instruments & Computers, 31, 137–149.
Tillmann, B., Jolicœur, P., Ishihara, M., Gosselin, N.,
Bertrand, O., et al. (2010). The amusic brain: Lost in
music, but not in space. PLoS ONE, 5(4), e10173.
Walker, P., Brenner, G., Spring, J., Masttock, K., Slater, A.,
& Johnson, S. (2010). Preverbal infants’ sensitivity to
synaesthetic
cross
modality
correspondences.
Psychological Science, 21, 21-25.
Walker, P., & Smith, S. (1984). Stroop interference based on
the synaesthetic qualities of auditory pitch. Perception,
13, 75–81.
Williamson, V., Cocchini, G. & Stewart, L. (2011). The
relationship between pitch and space in congenital
amusia. Brain and Cognition, 76, 70-76.

Acknowledgments
This work was supported by a research project grant from
the Leverhulme Trust (F/00 120/CA).

References
Barsalou, L. W. (1999). Perceptual symbol systems.
Behavior and Brain Sciences, 22, 577–660.
Bendor, D. (2011). Does a pitch center exist in auditory
cortex? Journal of Neurophysiology, 107, 743–746.
Bryant, D. J. (1992). A spatial representation system in
humans. Psycoloquy, 3(16), space 1.
Douglas, K. M., & Bilkey, D. K. (2007). Amusia is
associated with deficits in spatial processing. Nature
Neuroscience, 10, 915–921.
Eitan, Z., Schupak, A., & Marks, L. E. (2008). Louder is
higher: Cross-modal interaction of loudness change and
vertical motion in speeded classification. Proceedings of
the 10th International Conference on Music Perception
and Cognition (pp. 1-10). Adelaide, Australia: Causal
Productions.
Eitan, Z., & Timmers, R. (2010). Beethoven’s last piano

257

