UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Misconceptions Regarding Emergent Phenomena Vary By Domain

Permalink
https://escholarship.org/uc/item/2x42b69c

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Brem, Sarah
Stump, Glenda
Sinatra, Gale
et al.

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Misconceptions Regarding Emergent Phenomenon Vary By Domain
Sarah K. Brem (sarah.brem@asu.edu)
School of Social and Family Dynamics, Mail Code 3701
Arizona State Univerity
Tempe, AZ 85287-3701

Glenda S. Stump (glenda.stump@asu.edu)
School of Social and Family Dynamics, Mail Code 3701
Arizona State University
Tempe, AZ 85287-3701

Gale M. Sinatra (gsinatra@usc.edu)
Rossier School of Education, 3470 Trousdale Parkway
University of Southern California
Los Angeles, CA 90089
Raymond Reichenberg (raymond.reichenberg@asu.edu)
Mary Lou Fulton Teacher's College, Mail Code 3151
Arizona State University
Tempe, AZ 85287-3151

Benjamin Heddy (heddy@usc.edu)
Rossier School of Education, 3470 Trousdale Parkway
University of Southern California
Los Angeles, CA 90089
Abstract

central role in every scientific discipline. Color and
convection are emergent phenomena, as are weather
patterns, earthquakes, and the evolution of galaxies. The
activities carried out by ant colonies, bee hives, and
American voters exhibit emergence, as does the coevolution of flowers and bees. There is, therefore, potential
for great benefit in developing an understanding of how
emergent systems arise and behave, but this is a difficult
task for learners.
In non-complex, or “direct,” systems, the overall behavior
of the system and its outcomes tends to be deterministic,
linear, and predictable, often organized by a centralized
process or individual leader. The circulatory system (Chi,
2005, in press) follows a clear path, each step having a clear
purpose in a system that is regulated by nerves keeping the
heart beating at a regular pace. A problem in Newtonian
mechanics, say, the building of a bridge, involves
identifying forces that sum to indicate the stresses on a
particular element of the bridge, stressors which can be
offset directly by adding new elements in a cumulative way,
or inventing new structures that alter how the forces sum.
In contrast, complex systems are unpredictable, nonlinear,
and give rise to novel, or emergent, behavior (Holland,
1999). Even when the exact rules governing each agent are
fully specified, the resulting phenomenon will be
unpredictable and irreducible, and adding new elements
multiplies the possible interactions between agents, leading
to unexpected, non-replicable outcomes. There are no set

Although the study of how learners approach emergent
phenomena is relatively new, a consistent set of
misconceptions associated with emergence have been
documented. However, little consideration has been given as
to whether some misconceptions manifest more frequently in
one domain than another, or take on a different character
depending on the agents or phenomenon involved. We
examined participants' explanations of emergent phenomena
from three domains. We found significant differences
between domains, showing greater or lesser evidence of
misconceptions. We propose that that novices bring prior
knowledge, folk psychology, and folk biology to bear in
determining the capabilities of the agents involved in a
phenomenon, and that these beliefs guide their explanations.
We believe that the study of how people perceive emergence
would benefit from drawing upon research on folk theories,
anthropomorphism, developmental constraints, and other
areas that will help us understand how learners characterize
agents, environments, and their interactions.
Keywords:
emergence;
complexity
theory;
misconceptions; science education; folk biology; folk
psychology

Introduction
We live in a complex world. Not just in the everyday sense,
but in a mathematical, or scientific, sense. Many of the
phenomena we encounter in everyday life are of the
emergent, or complex, sort. Emergent phenomena play a

150

leaders or controllers; an agent may appear to have such
powers, such as the lead goose in a flock, but they are in the
lead simply because the other geese fell in line with them.
It is not surprising that the naïve learner struggles when
faced with explaining and understanding emergent
phenomena. Previous studies have well-documented the
challenges that emergent systems present for learners
(Jacobson, 2001; Hmelo-Silver & Azevedo, 2006). Learners
new to emergent systems are likely to expect clear patterns
of cause-and-effect, purposeful encounters between agents,
and a central control system that oversees their movements
and actions (Chi, 2005; Resnick, 1996). Complex systems
introduce the notion that order can emerge out of random
interactions; stochastic movements and actions are central to
how emergent phenomena arise and evolve. This challenges
the commonsense belief that ascribes purposefulness to
events in the universe (Jacobson, 2001). In a deterministic,
linear system, small changes to the starting conditions
generally lead to small changes in outcomes. In a complex
system, the smallest change can have a drastic effect on the
outcome, as interactions amplify and reshape the actions of
individual agents and their encounters with their
environment. The learner tries to make sense of these
patterns by invoking centralized control, in the form of a
“queen” bee or other sort of leader, who has knowledge of
the entire goings-on and can shift the pattern according to
their needs or the needs of the group. But there is no leader
to be found.
The study of how people perceive, explain, and
understand emergent systems is a relatively new area, and
both logistical considerations and underlying assumptions
have led us, as researchers, to pursue our investigations
through a close examination of single phenomenon (Chi, in
press), a single self-contained ecosystem (Hmelo-Silver &
Pfeffer, 2004), or a small set of phenomena within a single
domain, such as chemistry (e.g., Talanquer, 2008;
Rappoport & Ashkenazi, 2008) or evolution (e.g., Evans,
2001; Poling & Evans, 2004).
Logistically, this approach has been fostered by the fact
there are only a few tools for modeling emergent systems
(e.g., Colella, Klopfer & Resnick, 2001; Tisue & Wilensky,
2004), and creating such models is highly time-consuming.
Data collection is similarly time-consuming, and research
has focused heavily on case studies and close observation of
small groups in complex settings (e.g., Charles &
d'Apollonia, 2004; Wilensky & Resnick, 1999), or larger
groups interacting with a single aspect of a phenomena. We
have spent little time looking at whether and how learners'
actions and ideas change from one domain to the next.
Theoretically, too, there is a basic reason why we might
believe that, with time, these individual studies would come
together to create a fuller account of how learners perceive,
represent, and think about emergent systems. To be
considered an emergent system, a phenomenon must meet
specific mathematically-defined criteria. At the
mathematical level, diffusion, chemical bonds, and traffic
jams have a great deal in common; emergent phenomenon

belong to a class that is unaffected by features specific to a
particular domain.
It remains to be seen, then, to what degree the abstract
features and behaviors of an emergent system actually do
cross domain boundaries for learners. If I become proficient
in understanding diffusion, for example, will this make
learning about traffic jams or chemical bonds any easier for
me? We not only do not have such comparisons, we lack
assessments that allow us to directly compare a learner's
understanding of the principles of emergence in one domain
to their understanding in another.
Our goal for the project we describe here was to create an
assessment of key aspects of emergent systems that could be
applied across topics. Learners' understanding of each
phenomenon was assessed using an instrument that had
identical stems representing each component of emergence,
into which the particular phenomenon could be inserted. If
learners respond to the basic patterns that underlie the
phenomenon, they should show similar levels of
understanding (or misunderstanding) across domains. If a
person showed a low understanding of diffusion, they
should show a similarly low understanding of geese
flocking, as the same basic principles are needed to make
sense of these two phenomena. Thus, we can determine
whether their knowledge is tied to a particular system, or is
available at a more abstract level.
If domain knowledge plays a role, however, then
responses may be influenced by folk theories that ascribe
greater capacity for volition, control, and decision making to
certain sorts of entities, and less to others. A bacterium may
be seen as relatively incapable of engaging in goal-oriented
behavior, of communicating with other bacteria, or of
choosing a course of action. A goose, given that it has a
brain and nervous system, may be seen as more capable.
The social behavior of ants, likewise, may cause us to
assume they are more intentional and communicative, and
less driven by instinct and environment. Given people's bias
to find centralized, intentional causes for emergent patterns,
it may be harder to believe that animals with greater
neurological development are subject to random processes,
do not engage in communication and group planning, and
do not make choices when they act.
We therefore decided to test our domain-general stems in
the context of three different domains: unicellular slime
molds aggregating before sporing, ants, a social animal,
foraging for food, and geese, the most “advanced”
neurologically, flocking. These three entities not only come
from different locations on the phylogenetic tree, they differ
in the ways that we describe above.
We designed a study in which participants watched
simulations of three phenomena. Participants responded to
an open-ended written protocol that used the same questions
for each domain, altered only to refer to the domain at hand.
We then coded participants' responses and compared their
conceptualizations of each phenomena.
If misconceptions arise due to the features that all
emergent phenomenon have in common, we would expect

151

responses to our probes to be roughly the same across the
simulations. If, however, domain-specific considerations
come into play, we expect to see misconceptions arising
more often in some domains than in others. In particular, we
predicted that misconceptions would be invoked less often
with regard to slime molds than ants or geese. In addition,
we predicted ants would give rise to the greatest number of
misconceptions due to the familiarity of their social nature.

3. Do you think that there are special leader
ants/geese/slime molds that signal the others to
follow them/ follow them/ come to them and form
clusters?
4. If we make a new video with the same ants and
food/geese/slime molds in the same starting
positions, how similar do you think the patterns
they form will be?
We instructed participants to write as much as they could,
giving as much detail as they could provide. They were told
to answer the questions in the order they were given, and
not to go back and change any of their answers.

Methods
Participants
Forty participants, undergraduates from a large
Southwestern University, completed the written protocol,
receiving $20 in compensation. None had formal training in
emergence or complexity theory. The protocol took
approximately 60 minutes to complete.

Results
To create the coding system used to categorize
participants' answers, two of the authors (SKB and GSS),
conducted an open coding of the data, allowing codes to
emerge, rather than searching for codes based on existing
expectations and hypotheses. We iteratively coded sections
of the data and discussed our codes, coming to agreement
on 13 themes that were present across all domains. No
theme arose that was not present at least once in each
domain. Two of the other authors (RR and BH) who did not
have contact with GSS and SKB during the development of
the codes, applied the codes to the data. Both were blind to
the hypotheses regarding the relationship between a given
domain and possible patterns for that domain. They applied
the codes with 94.5% agreement, resolving disagreements
through discussion. Less than 5% of the answers were
deemed uncodable. Multiple codes could be applied to a
single answer, if all of the criteria for each code was met.
Although we arrived at 13 themes, not all of these codes
spoke to the issue of misconceptions about emergence.
Some were not directly relevant (e.g. “descriptive,” used
when for a play-by-play description of the simulation,
without interpretation, or “external factors,” when
characteristics of the simulation itself were the focus,
instead of the content.) Other codes proved complex and
potentially misleading because they captured different
concepts for different individuals (this is further discussed
below).
We chose to focus on the codes that, based on prior
research, are most central to identifying whether participants
hold a misconception or correct representation. We chose
four that directly invoke misconceptions well-documented
in the literature, and two providing evidence that the
participant held a correct representation of the phenomenon
(see Table 1 for a description of the codes, and a sample
response). Regarding the misconceptions, people tend to
assume that there is a controlling force directing the agents,
that the agents are communicating and cooperating, that
certain agents have special powers that allow them to direct
the pattern, and that all of the agents are acting out of a
sense of purpose. In contrast, the last two suggest
understanding of two basic principles of emergence: the

Materials and Procedure
The participants completed a written protocol posing
questions about three emergent phenomena: geese flocking,
ants foraging for food, and slime molds aggregating to
spore. The order in which the phenomena were presented
was counterbalanced across participants.
Each phenomenon was illustrated with a NetLogo
simulation that had been video-captured, so that the same
run could be shown to all participants. Agents were
represented by icons that captured the basic appearance of
the real entity (i.e., ant, slime mold, goose), and participants
were told before the simulation began what symbols would
be used, and what they would mean.
Each simulation lasted approximately 90 seconds, and
were roughly divided into three phases. First, there was a
brief section that allowed participants to orient themselves
to the simulation, the symbols used for the agents and
environmental objects, and the agents' behavior. Next, the
behavior began to develop emergent properties, i.e., patterns
began to form at the group level. Finally, the simulation
reached equilibrium (in the case of the flocking and slime
mold simulations) or the agents achieved their goal (of
finding food, in the ant simulation). Pilot runs of the
simulations and the responses of the participants suggested
that few had any difficulties mapping the real phenomenon
onto the simulation.
There were a total of 7 questions. We began each of the
three protocol sections with broad questions (e.g., #1 and #2
below), moving to more specific questions that capture key
aspects of emergent phenomena (e.g., #3 and #4 below).
The questions were designed to be as similar as possible
across entities, substituting in the appropriate phrases:
1. Describe the patterns that the ants/geese/slime mold
organisms make in as much detail as possible.
2. What do you think causes the ants/geese/slime
molds to make the patterns you see?

152

lack of centralized control, and the role of stochastic
processes.

Our first step in analyzing the data was to calculate the
means and standard errors for each domain on each of these
6 codes (see Table 2 for descriptive and inferential
statistics). We took a “token-counting” approach, adding up
the number of times a particular code was used a participant
in a domain. This gives a sense of how strongly the
participants relied on a particular conception in providing
their explanations for the phenomena. Since a participant
could have invoked a particular concept or principle in
answering each question, the maximum token score for each
code is seven.

Table 1: Codes Used in The Analysis
Code
Centralized
Control

Cooperation

Description
Reference to a group
member determining,
directing, or guiding
the actions of the rest
of the members.

Agents
cooperatively
determine their
behavior, or work
together as a group.

Differentiation Members have
different abilities,
roles, or attributes
from one another.

Goal-oriented

Example
The slime mold
that produces
more pheromones
will signal the
others to come
and cluster
around them.
Each geese are
telling each other
where to move

Maybe the ones
clustered have a
similar
pheromone (sic).
Also the levels of
what they give off
could be different.

Specifies a behavior
being performed to
fulfill a specific,
stated purpose.

He takes the path
he does because
he’s searching for
food.

Lack of
Refers to lack of a
Central Control group member
determining,
directing, or guiding
the actions of other
members.

I think the ants
are generally just
concerned with
getting some food,
so following a
leader was not the
goal. They all
followed very
similar paths
because they
shared a common
goal.

Random
Processes

I think this is a
random pattern
while they search
for food. The first
makes random
search while the
followers more
directly follow.

Describes movement
or other activity
explicitly as
“random.” Does not
include descriptors
such as “haphazard”
or “scattered,” but
only those which or
seem to be referring
to a reasonably
accurate version of
statistical
randomness.

Table 2. Descriptives For Each Domain, By Code
(alpha corrected to account for experiment-wide error)
Code
Slime Ants Geese F(2, 78)
Centralized Control

0.23
(.07)

3.35
(.27)

1.18
(.21)

64.22***

Cooperating Agents

1.08
(.17)

0.55
(.13)

1.50
(.27)

8.10**

Differentiated

1.05
(.22)

3.95
(.26)

1.85
(.28)

35.86**

Goal-Oriented

2.70
(.29)

3.77
(.25)

3.03
(.29)

5.34*

Lack Central Control

0.78
(.09)

0.32
(.17)

0.38
(.13)

3.40m

Random Processes

0.70
(.22)

0.48
(.14)

0.38
(.13)

1.51ns

We also calculated participants' use of these codes using a
binary process; a score of “1” meant that the participant
used the code at least once within that domain; “0” indicated
they did not use the code at all in that domain. The results
were quite similar; the same pattern of significant findings
was found for all but two of the codes. In the case of “goaloriented,” the differences decreased, and the F-value fell to
2.69 (non-significant). In the case of “lack of centralized
control,” differences increased, and the F-value rose to
16.98 (p < 0.01). We believe these differences are due to the
following: in the case of goal-orientation, almost every
participant invoked it at least once in every domain,
restricting the range when using binary scoring. The
opposite is true in the case of a lack of centralized control;
so few participants invoked this, a binary analysis was able
to detect differences that were swamped by non-responses
in the token analysis.
Other Points of Interest
As noted above, there were themes in the data that were not
as central, but might shed some light on how participants
conceptualized emergence. For example, in reviewing the
protocols, we found that participants were expressing quite
different ideas, even when using similar language. In one

153

case, we inquired as to whether the participants believed
that the agents followed rules in carrying out their actions.
The consensus seemed to favor that they did not follow
rules (approximately 2/3 of the replies).
However, we also discovered that participants had
different ideas about what constituted a “rule.” For some,
following a rule meant making a conscious decision based
on a learned rule—we learn to stop at red lights, for
example, and we (usually) follow that rule. For others, rules
could also be innate or instinctual. Some even went so far as
to explicitly state “if you mean conscious rules, no, but if
you mean instincts, then yes, they follow instincts.”
Because we could not go back and further probe to see
what meaning of “rule” each participant used, we excluded
it from further analysis, but we think this disagreement
about what constitutes a rule is interesting, for reasons we
will address in the discussion.

misconception is not just due to the phenomenon’s abstract
characteristics, but also what the novice brings to the
phenomenon, perhaps in the form of specific knowledge of
the entities, or perhaps in the form of folk theories.
The problem of interpreting participants' use of the word
“rules” illustrates our account well. Differences in one's
beliefs about what constitutes a rule, and whether an entity
is capable of acting on rules created differences in the way
participants responded. Most participants seem to think of
rules as learned guides to appropriate behavior to which one
consciously refers. They were reluctant to ascribe that
ability to the entities we used in this study. Those who
believed that instincts could be thought of as rules were
much more willing to think of agents as following rules.
Similarly, we believe that the differences between the
three domains on the codes we examined are driven less by
specific knowledge of emergence, and more by one's beliefs
about the entities' capacity for thinking, consciousness, and
deliberate decision making. They invoked misconceptions
less for slime molds, unicellular microorganisms, than for
geese and ants, and there is some evidence that they were
more likely to invoke a correct explanation for the slime
molds, based on a lack of centralized control and random
processes.
Their accounts of ants consistently showed the greatest
number of misconceptions; only for cooperation did geese
outperform ants. Anecdotally, a fair number of participants
spontaneously stated that they knew how ants worked
because (a) they have had extensive experience with ants,
usually trying to get them out of their houses, and (b)
because they had seen the movie 'Antz.' They were also
inclined to mention that ants were social creatures, and that
ability suggested organization, and the mental capacities
needed to create organization.
At very least, this should serve as a warning to those of us
engaging in research about complexity and emergence. By
relying on one or a few phenomena to characterize how
people perceive, explain, and understand emergence more
generally, we may be greatly over or underestimating the
abilities depending on the domains and agents we choose.
Testing a model on a variety of phenomena, with agents at
different levels of familiarity and perceived cognitive
capacity would be a good step to take before deciding that a
particular pattern of results arises because of the character of
emergent systems generally, and because of to the specific
properties of the agents and the activities they undertake.
We believe, however, that there is something more
interesting going on here, and that a better understanding of
how people experience emergence will require us to draw
upon research into folk theories (Arico, Fiala, Goldberg &
Nichols, 2011) developmental constraints (e.g.,
intentionality, teleology; Sinatra, Brem & Evans, 2008),
anthropomorphism (Tamir & Zohar, 2006), and
sociocultural accounts of the differences in ways that
different groups of people characterize animals, people, and
objects. We need a better sense of how people characterize
agents and their abilities to exhibit volition, teleological

Discussion
As predicted, slime molds elicited fewer misconceptions
overall than the other two entities, and produced the lowest
level of misconception use in three of the four categories
associated with misconceptions. Ants also elicited the
predicted performance, with the highest use of
misconceptions in three of the four categories. Trends in the
two categories related to correct conceptions were unclear;
reference to an explicit lack of centralized control was only
significant in the binary coding of the data; this trend did
favor our prediction, in that slime molds had the highest
invocation of this correct concept. However, random
processes produced no significant differences in either
analysis.
The mathematical and scientific power of complexity
theory and emergence comes from the ability of these
theories to draw bridges between seemingly disparate
disciplines. These isomorphisms, along with the tremendous
overhead involved in modeling any phenomenon, have led
educational researchers and cognitive scientists to focus on
a small sub-set of emergent phenomena, reasonably
inferring that the errors that crept up in one domain would
appear in another, given the underlying similarities. Even if
novices did not know the phenomena were isomorphs, the
phenomena were governed by the same principles, manifest
in similar ways, and created similar puzzles.
There was indeed some similarity in how the participants
responded to phenomena; of the 13 themes we identified,
every one was present at least once in each domain. That
suggests a relatively high degree of consistency across
domains in terms of how participants describe and explain
phenomena.
However, we also believe that researchers have not been
paying enough attention to the fact that each phenomenon is
carried out by a different cast of characters—be it
molecules, ants, geese, or air streams—and novices might
rely on prior knowledge and beliefs in perceiving a
phenomenon and devising an explanation for it. As a result,
the likelihood of invoking a particular concept or

154

thinking, to communicate, and to control themselves, others,
and their environment.
We hypothesize that the greater the perceived capabilities
of an agent or group of agents, the more likely it is that
people will reject explanations that invoke emergence in
favor of accounts that that give agents greater control over
the events that occur. Alternatively, the differences between
simulations were due to differences in the phenomena we
chose. It may be, for example, that flocking seems to require
greater mental skill than following a pheromone trail.
As a first step in addressing these hypotheses, we are
currently running a study in which we present isomorphic
phenomena across different levels of agents (physical,
“lower animal,” “higher animal,” and human), and are also
gathering data about the perceived capacities of each of
these agent types. We believe that simulations depicting
agents deemed more mentally capable will correlate with
greater misconceptions, even when the underlying
mechanisms are actually identical. However, if it is the type
of phenomenon that drives the differences in our first study,
this should surface in this study; responses should be more
similar by phenomenon than by level of agent.
In either case, having a better understanding of how
perceptions of phenomena and agents vary, this should
improve our ability to understand how people look at
emergent phenomena, and suggest ways to dispel
misconceptions.

Evans, E.M.(2001).Cognitive and Contextual Factors in
the Emergence of Diverse Belief Systems: Creation
versus Evolution, Cognitive Psychology, 42, 217-266.
Hmelo-Silver, C.E. & Azevedo, R. (2006). Understanding
Complex Systems: Some Core Challenges. Journal of
the Learning Sciences, 15, 53-61.
Hmelo-Silver, C.E. & Pfeffer, M.G.(2004). Comparing
expert and novice understanding of a complex system
from the perspective of structures, behaviors, and
functions, Cognitive Science, 28, 127-138.
Holland, J. H. (1999). Emergence: From Chaos to Order.
New York: Basic Books.
Jacobson, M.J. (2001). Problem solving, cognition, and
complex systems: Differences between experts and
novices. Complexity, 6, 41-49.
Poling, D. A., & Evans, E. M. (2002). Why do birds of a
feather flock together? Developmental change in the
use of multiple explanations: Intention, teleology,
essentialism. British Journal of Developmental
Psychology, 20, 89-112.
Rappoport, L.T. & Ashkenazi, G. (2008). Connecting
Levels of Representation: Emergent versus submergent
perspective. International Journal of Science
Education, 30, 1585-1603.
Resnick, M. (1996). Beyond the centralized mindset.
Journal of the Learning Sciences, 5, 1-22.
Sinatra, G.M., Brem, S.K., & Evans, E.M. (2008). Changing
minds? Implications of Conceptual Change for Teaching
and Learning about Biological Evolution. Evolution
Education and Outreach, 2. 189-195.
Talanquer, V. (2008) Students' predictions about the sensory
properties of chemical compounds: Additive versus
emergent frameworks. Science Education, 92, 96–114.
Tamir, P. & Zohar, A. (2006).Anthropomorphism and
teleology in reasoning about biological phenomena.
Science Education, 75, 57-67.
Tisue, S. & Wilensky, U. (2004). NetLogo: A simple
environment for modeling complexity. International
Conference on Complex Systems. Boston.
Wilensky, U. & Resnick, M. (1999). Thinking in Levels: A
Dynamic Systems Approach to Making Sense of the
World. Journal of Science Education and Technology, 8,
3-19.

Acknowledgments
This work was made possible by a grant from the National
Science Foundation to the first and third authors (0910115).
We also thank Katherine G. Nelson and Susan Shapcott for
their assistance in preparing this manuscript.

References
Arico, A., Fiala, B., Goldberg, R.F., Nichols, S.
(2011).The folk psychology of consciousness. Mind
and Language, 26, 327-352.
Charles, E.S. & d'Apollonia, S.T. (2004).Developing a
conceptual framework to explain emergent causality:
Overcoming ontological beliefs to achieve conceptual
change. Proceedings of the 26th Annual Meeting of the
Cognitive Science Society. Mahwah, NJ: Erlbaum
Associates.
Chi, M.T.H. (2005). Common sense conceptions of
emergent processes: Why some misconceptions are
robust. Journal of the Learning Sciences, 14, 161-199.
Chi, M.T.H., Roscoe, R., Slotta, J., Roy, M., & Chase, M.
(in press). Misconceived causal explanations for
"emergent" processes. Cognitive Science.
Colella, V.S., Klopfer, D., Resnick, M. (2001).
Adventures in Modeling: Exploring Complex, Dynamic
Systems with StarLog. Willston, VT: Teachers College
Press.

155

