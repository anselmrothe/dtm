UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Acoustic analysis supports the existence of a single distributional learning mechanism in
structural rule learning from an artificial language
Permalink
https://escholarship.org/uc/item/47g0j3b0
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Rasanen, Okko
Rasilo, Heikki
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                       University of California

          Acoustic analysis supports the existence of a single distributional learning
                 mechanism in structural rule learning from an artificial language
                                               Okko Räsänen (okko.rasanen@aalto.fi)
                                   Department of Signal Processing and Acoustics, Aalto University,
                                                  Otakaari 5 A, FI-00076 Aalto FINLAND
                                                 Heikki Rasilo (heikki.rasilo@aalto.fi)
                                   Department of Signal Processing and Acoustics, Aalto University,
                                                  Otakaari 5 A, FI-00076 Aalto FINLAND
                              Abstract                                   artificial nonsense language consisting of three-syllabic
   Research on artificial language acquisition has shown that            CVCVCV words with the middle syllable being always
   insertion of short subliminal gaps to a continuous stream of          randomly selected from a pool of “fillers”, but the first and
   speech has a notable effect on how human listeners interpret          last syllable occurring always together (hence a “high-
   speech tokens constructed from syllabic constituents of the           probability word”). It has been found out that when human
   language. It has been argued that the observed results cannot         listeners are familiarized with a continuous stream of such
   be explained by a single statistical learning mechanism. On           language without gaps between the high-probability words,
   the other hand, computational simulations have shown that as          and then later tested for preference between three-syllabic
   long as the gaps are treated as structurally significant units of     words that have different TPs between the syllables in terms
   the language, a single distributional learning model can
                                                                         of the familiarization stream, the listeners seem to prefer
   explain the behavioral results. However, the reason why the
   subliminal gaps interfere with processing of language at a            words that have occurred with higher internal TPs in the
   linguistic level is currently unknown. In the current work, we        familiarization stream (Endress & Bonatti, 2007; Peña et al.
   concentrate on analyzing distributional properties of purely          2002). However, introduction of 25 ms subliminal segments
   acoustic representations of speech, showing that a system             of silence between the high-probability words in the
   performing unsupervised learning of transition probabilities          familiarization stream leads to a notable change in the
   between short-term acoustic events can replicate the main             learning outcome: the listeners start to prefer word forms
   behavioral findings without a priori linguistic knowledge.            that do not necessarily have the highest TPs across all
                                                                         syllables in the word. Instead, the preferred words may
   Keywords: language acquisition; pattern discovery;                    contain partially novel surface form but have dependencies
   distributional learning; acoustic analysis; lexical learning
                                                                         between syllables that can be explained by abstract rules
                                                                         that are also valid for the words in the familiarization stream
                           Introduction                                  (Endress & Bonatti, 2007; Peña et al. 2002).
There is an ongoing debate regarding the degree that                        The above finding is somewhat unexpected from the
distributional learning mechanisms can explain aspects of                perspective of distributional learning at a linguistic level.
language acquisition from speech, and the degree that rule-              The learning results between continuous and gapped
based mental processes are required in the task (e.g.,                   familiarization streams should not differ as long as the
Endress & Bonatti, 2007; Laakso & Calvo, 2011; Peña et al.               perceived linguistic units and their ordering in the two
2002). Experimental studies with human test subjects have                conditions do not differ either. The result is also
shown that both infants and adults are able to learn                     counterintuitive due to the fact that the gaps are tiny in
statistical regularities in continuously spoken artificial               duration in comparison to the other relevant signal segments
languages and use these regularities to segment speech into              such as syllables, and since CV-syllable based languages
word-like units (e.g., Peña et al. 2002; Saffran, Aslin &                already contain natural silences associated with closures of
Newport, 1996). Based on these findings, it has been                     plosives (e.g., word “#pura#ki”, where # denotes a closure).
suggested that the listeners may be using transitional                      Peña et al. (2002) and Endress and Bonatti (2007) suggest
probabilities (TPs) between speech units such as phones or               that the additional silent gaps provide direct (but
syllables in order to discover statistically regular segments            unconscious) cues to the segmentation of words from
of speech (e.g., Saffran et al., 1996). Computational                    speech, freeing computational resources to structural
simulations have also verified that the TPs between signal               learning of rule-like relations between constituents of the
events can be used to discover word-like units from                      words. On the contrary, the absence of the gaps necessitates
continuous speech, and that these units do not necessarily               that the segmentation has to be first learned from the data
need to be linguistic or phonetic in nature (Räsänen, 2011).             (Endress & Bonatti, 2007; but see also discussion in Laakso
   Of especial interest is the degree that distributional                & Calvo, 2011). It is therefore argued that the change in
learning can explain the learning of non-adjacent                        learning outcomes after introduction of the gaps provides
dependencies in a language. In earlier work, the learning of             evidence for non-distributional learning of structural
non-adjacent dependencies has been studied using an                      relations between syllabic units (Bonatti & Endress, 2007).
                                                                     887

However, a possible auditory processing mechanism for               serving any explicit linguistic function but still affect the
differentiating gaps associated with segmental cues and,            learning results, it can be taken as evidence that the acoustic
e.g., the intra-word gaps related to closures of plosives has       level perception, including temporal relationships of
not been described in the existing work.                            acoustic patterns, may play an important role in the process.
   Lately, Laakso and Calvo (2011) have shown that the                 Why distributional analysis at the acoustic level would
experimental results of Peña et al. (2002) and Endress and          then lead to different results than analysis on the segmental
Bonatti (2007) can actually be modeled with a single                or syllabic level? The major difference comes from temporal
distributional connectionist model when the silent gaps are         relationships between sound events. At the syllabic level,
represented as equally significant units as the consciously         the relevant units and their distances from each other are
perceived syllables. As long as Occam’s razor is concerned,         well defined. Therefore the TP statistics also become well
the distributional model of Laakso and Calvo (2011)                 defined after a small number of word occurrences in
provides a more coherent and simple explanation for the             different contexts. At the acoustic level, a syllable is not
observed data instead of resorting to the more than one             perceived as a categorical unit with a well-defined duration,
mechanisms (MOM) hypothesis of Peña et al. (2002) and               but as a constantly evolving spectrotemporal trajectory that
Endress and Bonatti (2007). However, the model of Laakso            has very low predictability over larger temporal distances.
and Calvo also has a shortcoming: it does not explain how           This means that the typical acoustic level dependencies are
the short subliminal gaps end up with an equally large role         limited to a time scale much shorter than the tri-syllabic
as the syllabic units in the distributional learning process.       words in the artificial language of Peña et al. (2002).
   The goal of the current work is to study the distributional      Therefore the acoustic TP analysis must also pay attention
learning hypothesis in the context of the artificial language       to dependencies at a very fine temporal resolution,
of Peña et al. (2002) by focusing on the analysis of recurring      potentially increasing the relative role of temporal
acoustic patterns in a speech stream. Unlike earlier work, we       asynchronies caused by the introduction of silent gaps to the
study TPs of short-term acoustic events instead of                  familiarization stream.
linguistically or phonetically motivated units such as
syllables or segments. This provides a novel perspective to                                    Material
the learning problem by assuming that the listeners may not         The speech material for the experiments was reproduced
be directly analyzing the speech stream as a sequence of            from the work of Peña et al. (2002). In this material, the
linguistic units, but may treat the language-learning task as a     familiarization stream of the artificial language consists of
generic auditory patterning problem. Still, the current             three CV-syllable words of form AiXCi so that each word
approach does not exclude the possibility that the listeners        starts with one of three possible syllables Ai (i ∈ {1,2,3}).
can extract basic recurring units such as syllables or              Importantly, the first syllable always uniquely determines
segments from the acoustic speech stream and perceive               the last syllable Ci of the word (i.e., P(Ci|Ai) = 1, ∀i) so that
these as linguistically significant units. We simply show that
                                                                    there are also three different possibilities for end syllables.
the behavioral results of Peña et al. (2002) and Endress and
                                                                    Finally, the medial syllable, or filler, is chosen randomly
Bonatti (2007) can be explained with a single distributional
                                                                    from a set of three CV syllables. In total this produces three
learning mechanism that performs pattern discovery at the
                                                                    word templates “pu … ki”, “be … ga”, and “ta … du” where
level of acoustic signal instead of assuming TP analysis of
                                                                    one of the following three fillers are used in the medial
segments or syllables.
                                                                    position: “li”, “ra” or “fo”.
                                                                       Based on Endress and Bonatti (2007), four types of
Motivation for Acoustic Learning
                                                                    probes were used during testing: 1) words, i.e., tri-syllable
There are multiple reasons to assume that the listeners may         constructs that correspond directly to the ones used in the
utilize generic acoustic patterning instead of purely               familiarization (e.g., AiXCi), 2) part-words, where the
linguistic coding of input during perception of an artificial       sequential order of syllables was from the familiarization
language. First of all, test subject preferences towards            data but the word straddles a word boundary (e.g., XCiAj),
specific test probe types are typically only slightly above         therefore having a smaller overall TPs across the word, 3)
chance level even for extended familiarization periods (Peña        rule words of form AiX’Ci, where the X’ is familiar from
et al., 2002; Endress & Bonatti, 2007). If the learning would       the training but has never occurred in the word-medial
be based on categorically perceived segments or syllables,          position, and 4) class words of form AiXCj (i ≠ j) so that all
one could expect more robust preference for one probe type          Ai, X, and Cj are familiar from the familiarization data but
over another due to the systematically different overall TPs        the Ai and Cj have never occurred in the same word (see
or learned rules for the tokens. Also, the initial preference       Endress & Bonatti, 2007, for detailed word lists).
for specific probe types degrades over longer familiarization          The familiarization data and test probes were synthesized
periods, suggesting that the low-level distributional               into speech signals using a Kelly-Lochbaum model based
properties of the speech stream interfere with the processing       articulatory synthesizer of Rasilo, Räsänen and Laine (in
of the abstract generalizations. Finally, the introduction of       preparation) using articulatory positions of Finnish vowels
subliminal gaps introduces notable qualitative changes to           as targets for the vowel sounds. Sampling rate of the signals
the learning outcomes. Since these gaps are clearly not             was set to 16000 Hz and fundamental frequency of the
                                                                888

                                                                                                The basic principle of the UDLA is to study the TPs
     mutual information (bits)
                                 3
                                                                                             between the atomic acoustic events (VQ indices) in order to
                                        Baseline
                                                                                             discover multiple segments of speech that share similar local
                                 2                                Extended
                                      configuration                                          TP distributions. Unlike typical distributional analysis of
                                                                 configuration
                                          (BC)                                               syllabic, phonemic, or ortographic units (e.g., Saffran,
                                 1                                   (EC)
                                                                                             1996), UDLA analyzes TPs between short-term acoustic
                                                                                             events at several temporal distances (lags) in parallel so that
                                 0                                                           dependencies between non-adjacent acoustic events also
                                  0       100       200       300      400       500
                                                temporal distance (ms)                       become modeled. When recognizing novel patterns,
                                                                                             statistical support from all lags is combined in order to
Figure 1: Temporal dependencies of acoustic events                                           provide a uniform and noise robust estimate of familiarity of
measured from continuous English speech. The two learning                                    the pattern. Instead of modeling global TPs, UDLA creates a
parameter configurations BC and EC are also shown.                                           separate TP model for each novel pattern discovered from
                                                                                             the data, where a novel pattern is defined as a sequence of
speaker was set to 120 Hz. In order to create familiarization                                acoustic events whose TPs do not match any of the
data, all words in a training epoch (one occurrence of each                                  previously learned patterns.
word) were concatenated into one long string before                                             From the perspective of pattern discovery, it is beneficial
synthesis so that the coarticulatory effects were consistent                                 to study temporal dependencies up to approximately 200 ms
for both intra-word and across-word transitions. In addition                                 in case of continuous speech. This is because the statistical
to the continuous stream, the gapped familiarization stream                                  dependencies between acoustic events diminish to a non-
of Peña et al. was also created by inserting silent segments                                 existent level at larger temporal distances and provide no
of 25 ms between the words. It was also confirmed                                            further support for pattern discovery (Räsänen & Laine,
perceptually that the perception of the gaps was subliminal                                  2012). This temporal scale also corresponds to the typical
and no other audible artifacts were introduced to the signals.                               signal integration times measured in human auditory
                                                                                             perception in the context of loudness perception or forward
                                                  Methods                                    masking of speech sounds, suggesting that the integration
Preprocessing                                                                                times in human hearing are matched to the typical temporal
                                                                                             structure of acoustic speech signals. As an example, Figure
The goal of the preprocessing was to convert synthesized                                     1 shows the statistical dependencies of short-term acoustic
speech signals into sequences of automatically discovered                                    events as a function of temporal distance for continuous
discrete acoustic events for further statistical modeling. This                              English speech measured in terms of mutual information
was achieved by extracting Mel-frequency cepstral features                                   function (MIF; Li, 1990). As can be observed from the
(MFCCs) from the signals using a window length of 25 ms                                      figure, majority of the dependencies at the acoustic level are
and a step size of 10 ms (see, Appendix B in Räsänen 2011                                    limited to temporal distances shorter than 100 ms.
a for detailed description). A total of 12 coefficients +                                       Since the amount of statistical information diminishes at
energy were used. A random subset of 10000 MFCC vectors                                      longer distances, one can hypothesize that the human
from the familiarization data set was then clustered into 64                                 hearing system would be adapted to process temporal
clusters using the standard k-means algorithm. The obtained                                  dependencies at such timescale where, on average,
cluster centroids were treated as prototypes for the                                         dependencies do exist. Therefore, in baseline configuration
corresponding clusters (“atomic acoustic events”) and each                                   (BC), we use UDLA in a mode in which dependencies are
cluster was assigned with a unique integer label i ∈ [1, 2,                                  modeled up to 80 ms, capturing approximately 90 % of the
…, 64]. Finally, all MFCCs vectors were vector quantized                                     statistical dependencies in terms of MIF (Fig. 1). However,
(VQ) by representing the original feature frames with labels                                 we also measure UDLA behavior in the artificial language
corresponding to the nearest cluster centroids for the given                                 learning task using TP modeling up to 390 ms. This
frame. This led to a signal representation where the                                         configuration will be referred to as extended configuration
synthesized speech was represented as a sequence of                                          (EC). In terms of the current experiments, this means that
discrete elements, each element being one of the 64 possible                                 the TPs were studied at lags k = {1, 2, …, 8} for BC and at
choices and one element occurring every 10 ms.                                               lags k = {1, 3, 5, …, 39} for EC, corresponding to the
                                                                                             modeling of acoustic dependencies at temporal distances of
Discovery of Acoustic Patterns                                                               10 ms – 80 ms and 10 ms – 390 ms, respectively.
In order to learn distributional patterns from the artificial                                   The hypothesis was that, if acoustic and non-linguistic
speech data, a statistical learning mechanism is needed. In                                  patterning can explain the results of the experiment of Peña
the current work, we utilized the unsupervised word                                          et al. (2002), and if human hearing is actually specialized for
learning model of Räsänen (2011) that has been shown to be                                   learning dependencies according the curve shown in Fig. 1,
able to discover recurring word patterns from real                                           the learning outcomes in the baseline configuration should
continuous speech. This algorithm will be referred to as the                                 have better correspondence to the behavioral results than the
unsupervised distributional learning algorithm (UDLA).                                       extended condition. On the other hand, the extended
                                                                                       889

    configuration should show higher preference for part words
    than class or rule words due to the diminishing role of the                        Recognition Phase During the testing phase, the test probes
    gaps in terms of dependencies across all temporal distances.                       were pre-processed into discrete VQ sequences similarly to
                                                                                       the familiarization data. Then the instantaneous activation of
    Training Phase The learning process in UDLA proceeds as                            each model c at time t given input probe X was measured
    follows (see also Räsänen, 2011): the sequential discrete                          according to
    familiarization stream X is analyzed in windows of length Lr                                               1
                                                                                                                  K
    elements and window step size Ls. For each window                                               Ac (t) =     ∑ Pc ( X [t] | X [t − k], k )       (5)
                                                                                                              K
    position, the TPs between all elements ai and aj in the                                                      k =1
    window are modeled in parallel for lags k = {k1,k2,…kK}.                           The total activation induced by the probe was then
    For the TPs in the first window position, the first statistical                    computed as
    model c1 is created by storing all transitions at all lags to a                       €       Atot = arg t,c max( Ac (t) | ∀t,c)                 (6)
    transition probability matrix. In the model, the probability of                    In other words, the total activation caused by the probe X
    a transition from element ai to aj at lag k is defined as                          was obtained as the maximum instantaneous activation1 in
                                               NA                                      the pool of all pattern models c.
                                                                                       €
     PcS (a j | ai , k ) = Fc (ai ,a j | k ) / ∑ Fc (ai ,a j | k )             (1)
                                               j=1                                                                Experiments
    where Fc(ai,aj|k) is the frequency of ordered pairs [ai aj] at                     In the experiments, UDLA was first used to discover
    distance k in the context of model c.                                              recurring acoustic patterns from the familiarization stream,
€      When the window is moved incrementally across the                               and then to recognize novel test probes using the learned
    input sequence, all previously learned models are used to                          models. During each test round, the system was shown one
    recognize the contents of the current window position. First,                      token from each of the four possible probe classes and the
    activation Ac(t) of each model c at each moment of time t is                       overall activation caused by each token was measured. A
    computed by calculating the mean of the TPs over all k:                            total of 600 probe quartets were generated by randomly
                                      K
                                  1                                                    sampling one token from each probe class for each quartet.
                        Ac (t) =
                                 K
                                     ∑ PcS ( X [t] | X [t − k], k )            (2)
                                                                                          In all experiments, the UDLA model was run with a
                                    k =1
                                                                                       familiarity threshold of tr = 0.16 and window step size Ls =
    The cumulative activation of each model is then calculated
                                                                                       50 ms (5 frames). The analysis window length was set to Lr
    over the window and normalized by the window length:
                                                                                       = 200 ms and Lr = 600 ms for baseline and extended
                                           T +Lr −1
       €                                1                                              conditions, respectively, so that multiple transitions at
                        Accum (T ) =           ∑ Ac (t[x])                     (3)
                                      Lr                                               maximal lags would fit to the analysis window. These
                                              x=T
                                                                                       parameters led to the learning of NC = 26-33 acoustic
    where T denotes the window position. Now if activation
                                                                                       patterns depending on the familiarization type (continuous
     Accum of the most activated model cM exceeds a pre-defined                        vs. segmented), modeling conditions (baseline vs.
    familiarity
       €                threshold tr, the transition frequencies in the                extended), and on the duration of the familiarization. Since
    current window of analysis XT are used to update the                               the number of learned patterns exceeded the number of
€   statistics of the model cM according to Eq. (1). Otherwise, a                      unique syllables (nine), the system had learned multiple
    new model cN is created from the window contents using the                         context-sensitive variants of syllable-like units.
    Eq. (1). This process is repeated for the entire training data                        Figure 1 shows the mean activation levels of the four
    set, producing a set of models that incrementally increase                         different probe types (words, part words, rule words and
    their selectivity towards specific structures in the speech                        class words) as a function of familiarization duration for
    signal.                                                                            segmented (top) and continuous (bottom) familiarization
       After the familiarization is complete, the learned models                       stream in the baseline condition with temporal dependency
    are normalized according to                                                        modeling up to 80 ms. As can be observed, the insertion of
                                                   NC                                  25 ms gaps between tri-syllable words in the familiarization
                                                                            1
        Pc (a j | ai , k ) = PcS (a j | ai , k ) / ∑ PmS (a j | ai , k ) − N   (4)     stream is sufficient to induce a change of preference from
                                                   m=1                       C         part words to rule words and class words. This is in line
    where NC is the total number of models learned. This                               with the behavioral results of Peña et al. (2002) and Endress
    changes the nature of the statistics so that now Pc describes                      and Bonatti (2007) who found out that the use of subliminal
  € how likely the given transition from aj to ai occurs in case of
    pattern c instead of any other pattern (i.e., classification
                                                                                       1
    task). The 1/Nc term forces the total activation across all                           The decoding criterion of probabilities was compared across
    models to zero at all times, ensuring that the total activation                    numerous different possibilities, including, e.g., total activation of
    level of the system does not increase with increasing                              all models across the entire probe, temporally integrated maximum
    number of learned models. Note that the learning process is                        activation, and number of models exceeding a pre-defined
    purely incremental and requires the storage of the previous                        threshold in activation. However, unlike the used approach in Eq.
    inputs only up to maximum lag K (i.e., 80 or 390 ms).                              (6), none of the other criteria were able to replicate the main
                                                                                       findings of Peña et al. (2002) and Endress & Bonatti (2007).
                                                                                   890

gaps in the familiarization stream causes a change of                                       More specifically, the relative probabilities of the tokens in
preference from part words to rule words and class words at                                 each pair were compared separately across all 600 test cases
short familiarization periods.                                                              in the baseline configuration. For each pair, a binary flag
  However, when the TPs between acoustic events are                                         was used to denote a response for the probe that had the
measured beyond the typical dependencies in speech                                          higher activation. Then the distribution of responses was
signals, the situation changes notably. Figure 3 shows the                                  tested against the null hypothesis that the model shows no
mean activation levels of the probes in the extended                                        preference for either probe type (t-test). Table 1 illustrates
condition where temporal dependencies are modeled up to                                     the results from the statistical analysis.
390 ms. Despite the fact that the only difference to the                                       It is evident that the segmented familiarization stream
earlier simulation is the distance up to which TPs are                                      leads to a preference order of words > rule words > class
measured, there is no sign of difference between the                                        words > part words at short familiarization durations. On
continuous and segmented familiarization streams.                                           the other hand, continuous stream leads to order of words >
  Based on the mean probe activities, it seems that the                                     part words > rule words and class words. This is largely in
distributional learning of acoustic patterns without any a                                  line with the results of Laakso and Calvo (2011), confirming
priori or intervening linguistic component can explain the                                  that a single distributional learning mechanism can explain
experimental results of Peña et al. (2002) and Endress and                                  the change of preference between the two conditions.
Bonatti (2007), but only if it is assumed that the system is                                However, the previous studies do not always report
able to learn acoustic dependencies up to a limited temporal                                statistically significant order of preference between all probe
distance defined by typical structure in continuous speech. If                              types (Laakso & Calvo, 2011), whereas the current
the dependency modeling is extended up to much longer                                       simulations show statistically significant order of preference
delays, the UDLA model is no longer able to replicate the                                   for all learning conditions except for the continuous
behavioral findings.                                                                        familiarization stream of 3 minutes. This can be largely
  In addition to computing overall activations, pair-wise                                   explained by the fact that the deterministic nature of UDLA
comparisons of probe activities were carried out for all                                    leads to a consistent response pattern across multiple trials
possible probe pairs in the test set in order to simulate                                   even for minor statistical biases between the probe types. In
behavior in a forced-choice task similar to the one used with                               contrast, responses of human test subjects contain additional
human experiments.                                                                          sources of variation (e.g., fatigue) and are based on a limited
                                                                                            number of test trials, possibly rendering minor differences in
                       0.1
                                           segmented
                                                                                            probe familiarity invisible to statistical analysis.
    mean activation
                        0                                                                                           Discussion
                      ï0.1                                                                  In Peña et al. (2002) and Endress and Bonatti (2007) it was
                          0   5   10            15            20    25     30
                                            continuous                   part word          found that adult test subjects, when familiarized with 10
                                                                         word
                                                                                            minutes of continuous stream of speech from an artificial
    mean activation
                       0.1                                               rule word
                                                                         class word
                                                                                            language, prefer words over part words and show no
                        0
                                                                                            preference between class words, part words and rule words.
                      ï0.1
                          0   5   10             15            20   25    30                However, when subliminal gaps were introduced between
                                   familiarization duration (min)
                                                                                            words in the familiarization stream, the participants started
                                                                                            to prefer class words and rule words over part words. Based
Figure 2: The mean activation levels of the four different
                                                                                            on these findings, Peña et al. (2002) put forward the MOM
probe types in baseline condition for segmented stream (top)
                                                                                            hypothesis that the learning of a language might consist of
and for continuous stream (bottom). Only relative mean
                                                                                            several different processes: a distributional process
activations of the probes are shown (zero mean).
                                                                                            responsible for discovery of statistically significant patterns
                                           segmented
                                                                                            and a separate mechanism responsible for modeling of
                       0.2
                                                                                            structural relation between the discovered patterns. Endress
    mean activation
                        0
                                                                                            and Bonatti (2007) provided further support to the MOM
                                                                                            hypothesis by failing to replicate the behavioral findings of
                      ï0.2
                          0   5   10           15             20    25    30
                                                                                            Peña et al. when modeling the learning task with a
                       0.2
                                           continuous                    part word          distributional system (a recurrent neural network or RNN).
                                                                         word
                                                                                               Lately, Laakso and Calvo (2011) showed that RNNs can
    mean activation
                                                                         rule word
                        0
                                                                         class word
                                                                                            replicate the main behavioral findings of Peña et al. when
                                                                                            the modeling parameters are properly set up, and when the
                      ï0.2
                          0   5   10             15            20
                                   familiarization duration (min)
                                                                    25    30                silent gaps between syllables are modeled as separate units
                                                                                            with equal importance to syllabic units. Their results
Figure 3: The mean activation levels of the four different                                  undermine the argument for the necessity of multiple
probe types in extended condition for segmented stream                                      mechanisms of learning in this specific context. However,
(top) and for continuous stream (bottom).                                                   Laakso and Calvo limited their analysis to purely linguistic
                                                                                      891

Table 1: Pair-wise preference for the four different types of              syllabic dependencies could be also explained by the finite
test probes with segmented (left) and continuous (right)                   length temporal integration in the auditory processing.
familiarization streams. W stands for word, PW for part                    Segmental dependencies with an interleaved random
word, C for class word and R for rule word.                                segment in between could be readily captured by a system
                                                                           modeling statistical dependencies up to, e.g., 150 ms, but
                segmented                     continuous                   dependencies across multiple syllables may simply be too
          preference    %        p     preference     %        p           distant to be captured by such short-term analysis.
          W over PW    82.1   0.0000   W over PW     77.8   0.0000            Note that the inability to capture acoustic dependencies at
          R over PW    74.0   0.0000   PW over R     57.1   0.0005         longer temporal distances does not imply that long-range
 3 min
          C over PW    70.5   0.0000   PW over C     64.0   0.0000
                                                                           linguistic dependencies would not exist or could not be
           W over R    58.8   0.0000    W over R     89.5   0.0000
           W over C    68.3   0.0000    W over C     90.0   0.0000
                                                                           captured by a distributional learning mechanism. It is well
                                        No pref. R                         known that such dependencies do exist. However, the huge
           R over C    56.9   0.0032     and C       51.4   0.5156         variability and dimensionality of the acoustic space strongly
          W over PW    78.4   0.0000   W over PW     71.2   0.0000         points towards the necessity of an intermediate represen-
          R over PW    70.0   0.0000   PW over R     60.1   0.0000         tation upon which further analysis and learning can take
 10 min
          C over PW    69.1   0.0000   PW over C     57.0   0.0006
                                                                           place. Given the current knowledge of human speech
          W over R     68.4   0.0000    W over R     83.4   0.0000
          W over C     74.9   0.0000    W over C     79.0   0.0000
                                                                           perception, it is early to say whether these units are phones,
          No pref. R                                                       syllables, morphemes or something else (see Räsänen,
            and C      55.9   0.0113    C over R     59.7   0.0000         2011), and whether the computations are distributional or
                                                                           structural in nature. The current study does not exclude the
level, assuming that the learner perceives artificial language             possibility that the human listeners are directly utilizing
as a sequence of syllabic units and silences even though the               syllable level TPs in the artificial language learning task, but
silences were not consciously perceived by the participants.               simply shows that the TP analysis at the acoustic level can
   Current work studied the hypothesis that the findings of                also explain behavioral observations to a large degree.
Pena et al. could be based on generic distributional learning
at the acoustic level instead of using linguistic level rep-                                 Acknowledgements
resentations. More specifically, we analyzed TPs of short-                 This research was financially supported by Nokia NRC.
term acoustic events that were extracted from speech in
purely unsupervised manner. Notably, we were able to
                                                                                                   References
replicate the behavioral findings related to the change of
preference across familiarization conditions by using the                  Endress, A. D., & Bonatti, L. L. (2007). Rapid learning of
UDLA model of word learning from continuous speech, but                      syllable classes from a perceptually continuous speech
only when the TP analysis of acoustic events was limited to                  stream. Cognition, 105(2), 247-299.
a temporal window matching to the temporal dependencies                    Laakso, A., & Calvo, P. (2011). How Many Mechanisms
of normal continuous speech (Räsänen & Laine, 2012).                         Are Needed to Analyze Speech? A Connectionist
   If this constraint is violated by exceeding the temporal                  Simulation of Structural Rule Learning in Artificial
scale of modeling to several hundreds of milliseconds, the                   Language Acquisition. Cognitive Science, 35, 1243-1281.
model systematically prefers words over part words, and                    Li, W. (1990). Mutual Information Functions versus
part words over class words or rule words also in case of                    Correlation Functions. J. Statistical Physics, 60, 823-837.
segmented familiarization stream. The change of model                      Newport, E. L., & Aslin, R. N. (2004). Learning at a
behavior is driven by the fact that the synthesized speech                   distance I. Statistical learning of non-adjacent
lacks the acoustic variability and lexical complexity of                     dependencies. Cognitive Psychology, 48, 127-162.
normal speech, and therefore unnaturally strong long-                      Peña, M., Bonatti, L. L., Nespor, M., & Mehler, J. (2002).
distance dependencies exist in the speech tokens. By                         Signal-driven computations in speech processing. Science,
modeling the TPs at increasingly long distances, the relative                298(5593), 604-607.
statistical contribution of the short-term gaps between the                Rasilo, H., Räsänen, O., & Laine, U. (In preparation). An
words in the segmented condition become too small to                         approach to language acquisition of a virtual child:
affect the preference of word tokens in the testing phase.                   learning based on feedback and imitation by caregiver.
   This suggests that if human responses in the task are                   Räsänen, O. (2011). A computational model of word
based on acoustic level patterning, it may be the case that                  segmentation from continuous speech using transitional
the human auditory system is not able to capture                             probabilities of atomic acoustic events. Cognition, 120,
dependencies at extended temporal distances. This is closely                 149–176.
related to the study of Newport and Aslin (2004) who found                 Räsänen, O., & Laine, U. (2012). A method for noise-robust
that adult listeners are unable to learn dependencies between                context-aware pattern discovery and recognition from
non-adjacent syllables whereas dependencies between non-                     categorical sequences. Pattern Recognition, 45, 606-616.
adjacent segments (either vowels or consonants) were                       Saffran, J., Aslin, R., & Newport, E. (1996). Statistical
readily learned when familiarized with continuous stream of                  Learning by 8-Month-Old Infants. Science, 274, 1926-
artificial language. The inability to learn non-adjacent                     1928.
                                                                     892

