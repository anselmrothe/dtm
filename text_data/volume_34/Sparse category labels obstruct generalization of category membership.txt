UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Sparse category labels obstruct generalization of category membership
Permalink
https://escholarship.org/uc/item/5wj0m4g2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
McDonnell, John V.
Jew, Carol A.
Gureckis, Todd M.
Publication Date
2012-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

             Sparse category labels obstruct generalization of category membership
                                             John V. McDonnell (john.mcdonnell@nyu.edu)
                                                      Carol A. Jew (carol.jew@nyu.edu)
                                               Todd M. Gureckis (todd.gureckis@nyu.edu)
                                               New York University, Department of Psychology
                                                6 Washington Place, New York, NY 10003 USA
                               Abstract                                    child’s pre-linguistic grouping of objects in their environment
   Studies of human category learning typically focus on situa-            into classes.
   tions where explicit category labels accompany each example                 A similar position is advocated by a number of in uen-
   (supervised learning) or on situations were people must infer           tial theories of category learning which hold that supervised
   category structure entirely from the distribution of unlabeled
   examples (unsupervised learning). However, real-world cate-
                                                                           and unsupervised learning are subserved by a single under-
   gory learning likely involves a mixture of both types of learning       lying learning process (e.g., the rational model of categoriza-
   (semi-supervised learning). Surprisingly, a number of recent            tion, Anderson, 1991; or the Supervised and Unsupervised
     ndings suggest that people have diﬃculty learning in semi-            STrati ed Adaptive Incremental Network, abbreviated -
   supervised tasks. To further explore this issue, we devised a
   category learning task in which the distribution of labeled and
                                                                           , Love, Medin, & Gureckis, 2004). Such models naturally
   unlabeled items suggested alternative organizations of a cate-          predict that semi-supervised learning should not only be pos-
   gory. is design allowed us to determine whether learners               sible, but may be the primary way in which people learn cate-
   combined information from both types of episodes via their              gories and their respective names.
   patterns of generalization at test. In contrast with the prediction
   of many models, we nd little evidence that unlabeled items in-
     uenced categorization behavior when labeled items were also           Can people acquire categories via semi-supervised
   present. Keywords: Semi-supervised category learning; rule              learning?
   induction; unsupervised learning
                                                                           Despite these arguments, recent empirical attempts to demon-
                           Introduction                                    strate semi-supervised category learning in the lab have met
Category learning is a critical cognitive ability which is cen-            with mixed success. For example, Vandist, De Schryver, and
tral to many aspects of cognition. As a result, considerable re-           Rosseel (2009) found that adding unlabeled training exam-
search over the last – years has explored the psychology of            ples to a mostly supervised task oﬀered no additional bene-
category learning using laboratory tasks. e majority of this                t beyond learning from only the supervised trials. However,
work can be divided into two groups. Most research has fo-                 the category structures they tested (known as Information-
cused on supervised learning tasks where corrective feedback               Integration categories) are typically diﬃcult for people to
or category labels are presented following or alongside each               learn even in fully unsupervised settings (Ashby, Queller, &
observation of a stimulus (e.g., Medin & Schaﬀer, 1978; Nosof-             Berretty, 1999), which may explain the limited impact that the
sky, 1986). More recently, there has been an interest in unsu-             unlabeled examples had.
pervised learning, wherein participants must organize exam-                    On the other hand, Kalish, Rogers, Lang, and Zhu (2011)
ples in the absence of explicit instruction using the distribu-            showed that aer learning a simple category distinction on a
tional properties of the stimuli (e.g., Clapper & Bower, 1994;             single dimension from a small set of labeled examples, par-
Love, 2002; Pothos et al., 2011). However, neither of these sit-           ticipants’ estimate of the category boundary could be shied
uations adequately re ect the problem of real world category               by the presentation of a large number of unlabeled examples
learning, in which feedback is not altogether absent nor always            whose distribution was shied compared to the labeled set
present, but is typically sparse and intermittent. Such tasks re-          (see also Lake & McClelland, 2011). While this study provides
quire learners to combine information from both labeled and                some evidence of semi-supervised learning, there remain al-
unlabeled episodes. In machine learning, this problem is fre-              ternative explanations of the eﬀect. For example, since the
quently studied under the name semi-supervised learning (for               central tendency of both categories are shied in these studies
review, see Zhu, 2005).                                                    it is unclear whether people are separately updating each cat-
   Aside from oﬀering a more ecologically relevant approach                egory representation or responding to the global shi in the
to the study of category learning, the study of semi-supervised            stimulus space.
learning has important implications for theories of human                      Finally, Rogers, Kalish, Gibson, Harrison, and Zhu (2010)
concept learning. Consider the problem of learning a con-                  compared learning in a semi-supervised learning condition
crete noun such as horse. One proposal is that word learn-                 with a fully supervised condition. In this study, adding un-
ing essentially links sound tokens (words) to already-acquired             labeled items to a supervised category learning task caused
hypotheses or representations (Bloom, 2000; Gentner, 1982).                faster learning only when trials were speeded. However, the
Under this view, the label information from a teacher or par-              question of whether people can integrate labeled and unla-
ent about a single example horse must be integrated with the               beled training examples is logically separate from claims about
                                                                       749

                                                                                                                A                      A
                                                                                      A B                                                  B
                                                                                                                B
      Unimodal Dimension
                                                                                    Bimodal                 Unimodal            Two-Dimensional
                                                                              Figure 2: A range of possible category strategies consistent with the
                                                                              category in Figure 1. In the Bimodal strategy, the learner classi es
                                                                              all the items that fall in each clustered column with the label given
                                                                              to the labeled items within the column. In the Unimodal strategy,
                                                                              the learner divides the example along the unimodal dimension. is
                                                                              strategy is acceptable if the unlabeled examples are ignored. e 2D
                                                                              strategy is more complex (in the sense that it depends on attention to
                             Bimodal Dimension                                both stimulus features) but is also consistent with the labeled exam-
                                                                              ples and inconsistent with the unlabeled distribution.
                   Unlabeled Examples   A Examples   B Examples
Figure 1: A schematic depiction of the design used in the experiment.         prediction was that if people combine information from both
Category stimuli varied along two continuous dimensions. e plot              the labeled and unlabeled examples, they will generalize the
edges represent the marginal distribution of examples. Unlabeled ex-
amples fall in two columnar clusters, while two clusters of examples          label information according to the distribution implied by the
with labels A and B appear in the corners of the space. Taken alone,          unlabeled examples. is should be clearly captured in their
the distribution of labeled examples is ambiguous concerning how to           patterns of generalization in a test phase (see Figure 2).
generalize, since a rule on either dimension alone could explain the             In addition to comparing semi-supervised learning to fully
labels.
                                                                              supervised learning we also include a second control condi-
                                                                              tion assessing fully unsupervised learning. In fact, this condi-
                                                                              tion of our study represents a conceptual replication of a pre-
                                                                              vious study on unsupervised category learning by Zeithamova
learning rates between tasks. For example, a participant’s                    and Maddox (2009, henceforth referred to as Z&M). is
learning rate might vary based on features of the overall task                served two purposes. First, it allows us to establish a baseline
context rather than the information conveyed by any subset of                 measure of behavior for both extremes of supervision. Sec-
examples.                                                                     ond, this ensures that participants can learn the category from
   Collectively, these results tell a surprisingly unclear story.             the distribution of unlabeled examples alone.
Despite decades of research on supervised and unsupervised                       Finally, rather than test a single semi-supervised learning
learning with arti cial stimuli, studies which have attempted                 condition, we systematically explore the eﬀect of the number
to combine these two forms of learning fail to show robust                    of labeled examples on semi-supervised learning. Our design
and consistent eﬀects. Some nd limited evidence of semi-                      thus interpolates between fully unsupervised learning to fully
supervised learning while others fail to nd any evidence at                   supervised learning by changing the relative amount of labeled
all. e goal of the present study is to attempt to revisit this               versus unlabeled information.
issue with a novel design which may be more diagnostic of
semi-supervised learning. As will be revealed shortly, our re-                                       e Experiment
sults add modest light to an already murky picture.                           In our experiment, we developed a cover story which provided
                                                                              a plausible explanation for why some category examples were
Evaluating semi-supervised learning through patterns                          unlabeled (but still came from the same category). e cover
of generalization at test.                                                    story asked participants to imagine that they were working in
Our study (summarized abstractly in Figure 1) departs from                    a  repair shop in a town where people tuned special loop
the studies described above in a number of ways. In some pre-                 antennas to pick up one of only two possible channels (sim-
vious work, the distributional properties of both labeled and                 ilar to Markant & Gureckis, 2010). Similar antennas tended
unlabeled examples were identical (e.g., Vandist et al., 2009).               to pick up similar channels. Although all the s were tuned
In contrast, we manipulated the distribution of examples so                   to one of the two channels, many had broken tubes making
that the distribution of unlabeled examples and the distribu-                 it impossible to turn on and verify the channel. e partici-
tion of labeled examples suggested alternative organizations                  pants’ job over the course of the experiment was to determine
of the category. In particular, the labeled items alone were                  how diﬀerent settings of the antennas determine which chan-
ambiguous about the basis for the category diﬀerence. How-                    nel the  is tuned to pick up. ey were reminded that learn-
ever, the distribution of unlabeled examples suggested a clear                ing about the antennas was possible even if the  tube was
organization of the categories along a single dimension. Our                  broken.
                                                                        750

   e experiment was organized into two phases. e rst
was a training phase in which participants were shown var-
ious category members with and without labels (depending                                             Labeled      Unlabeled       Sham       Total
on condition). e second was a test phase in which partici-                           Unlabeled          0            280           0         280
pants were asked to classify novel examples. Decision bound                          10-Labeled         10            270           0         280
models (Ashby, 1992) were t to subjects’ responses during                            40-Labeled         40            240           0         280
                                                                                40-All-Labeled          40             0           240        280
the test phase in an attempt to infer the strategy they applied.
We then analyzed the frequency by which diﬀerent strategies                   Table 1: Summary of the four training conditions. All participants
were adopted as a function of condition.                                      viewed 280 items in the training condition. Labeled and Unlabeled
                                                                              here denotes a  with an antenna, which were either working (la-
Methods                                                                       beled) or broken (unlabeled). A sham  consisted of a broken 
                                                                              set without an antenna (examples are provided along the top).
Participants  New York University undergraduates partic-
ipated for course credit. Participants were randomly assigned
to one of four possible conditions: Unlabeled (N = 33),
10-Labeled (N = 31), 40-Labeled (N = 30), or 40-All-
Labeled (N = 30). Four participants, three in the Unlabeled Con-                 Regardless of condition, labeled items in the training phase always
dition and one in the 10-Labeled Condition, were classi ed as re-             came from the corners of the space as depicted in Figure 3, which
sponding randomly (see the results section) and were dropped from             meant they were always non-diagnostic with respect to the best cat-
the analysis, leaving  participants in each condition.                      egory rule.
                                                                                 e test phase was identical for all four groups and, following
Materials e objects to be categorized were line stimuli varying              Z&M (2009), involved the presentation of 50 broken s sampled
in their length and orientation. e stimulus properties (lengths and          from the same distribution as used during training. Participants were
angles) of the antennas were chosen to be similar to those used by            asked to predict the channel based on the antenna setting.
Z&M (2009). e range of possible angles was diﬀerent for each sub-
                                                                                 All remaining arbitrary aspects of the design (e.g., which dimen-
ject, but it covered ○ and was constrained not to cross the verti-
                                                                              sion served as the bimodal dimension) were counterbalanced across
cal or horizontal axes. e range of lengths was always between 
                                                                              conditions.
and  pixels. e line stimuli were attached to pictures of  via
a stem. Category label information was given by changing what was             Procedure e experiment was administered on standard Macin-
showing on the  screen. For unlabeled examples, the screen took             tosh computers using an in-house data collection system written in
on the appearance of broken glass. Participants were told that these          Python1 . Participants were tested over a single one-hour session.
s were broken, but still tuned correctly to one of the two chan-               e instructions emphasized that all of the antennas were in good
nels. When category label information was given, the letters  or           working order and purposefully tuned either to  or . Partici-
 appeared on the screen, indicating that the  was set to pick up         pants were also told that, as a result, the antennas as a whole consti-
one of the channels (see the top row of Table 1 for examples).                tuted two categories of items. Although many of the s were bro-
Design During the training phase, the s were drawn from two                 ken, being broken had nothing to do with the setting of the antenna
elongated distributions which were naturally separable along one of           or the potential to pick up one of the two channels. Broken s were
the stimulus dimensions (the bimodal dimension). For reasons of               missing some information, but were otherwise not diﬀerent from the
control, stimuli were sampled using a discrete binning method de-             others. To con rm that they had understood the instructions, par-
scribed in Figure 3. is diﬀers slightly from Z&M (2009) who used             ticipants were given a brief quiz and misconceptions were addressed.
bivariate normal distributions but was necessary to ensure tight con-            Next, participants observed  randomly generated antennas in
trol over the distributional properties of the stimuli, and in particular     quick succession (ms each), giving information about the range
to ensure that the distributions of labeled items were unbiased with          of values for each of the two stimulus dimensions (angle and length).
respect to the particular categorization strategies.                             On each trial of the training phase, participants viewed a new
   Our primary experimental manipulation was to alter the training             (which was broken, working, or a sham), and aer ms were
that participants received in the task. Four training conditions rang-        prompted to press the space bar to continue. Aer the button press,
ing from completely unsupervised to completely supervised (with no            the stimulus remained on the screen for ms. Between trials the
unlabeled training items) were included (see Table 1 for a summary).          screen was blank for an inter-stimulus interval of ms.
   Unlabeled Condition. In this condition, all s were broken (i.e.,            e test phase consisted of  trials in which participants saw a
unlabeled). is condition is a traditional unsupervised category              broken  drawn from the same distribution as the training trials.
learning task and a conceptual replication of the intermixed condi-           On each test trial, participants viewed a new broken  and were
tion from Z&M (2009), Exp. 1A.                                                asked to press a button on their keyboard to indicate whether they
   10-Labeled Condition. is condition was identical to the                   believed the antenna was tuned to  or . Aer each trial, a
Unlabeled Condition except that ten of the items in the corners were          thank you message (along with the original stimulus) remained on
presented along with category labels (i.e., the appropriate channel).         the screen for ms. No feedback was given. e next trial fol-
   40-Labeled Condition.        is condition was similar to the              lowed aer ms.
Unlabeled Condition and the 10-Labeled Condition except that all
of the items in the corners ( in total) were presented along with           Results
category labels.
   40-All-Labeled Condition. In this condition, all antennas were la-         Accuracy Analysis In our rst analysis, we considered
beled in the training phase, meaning that this condition was fully su-        whether participants correctly applied the category labels in
pervised. However, to hold other aspects of the task consistent with          the unambiguous regions of the space (i.e., the corners) in the
the other conditions,  broken s without antennas (sham tri-
als) took the place of the unlabeled examples, giving participants in
                                                                              10-Labeled, 40-Labeled, and 40-All-Labeled conditions. Re-
this condition the same number of training trials as those in other           sponding was signi cantly above chance in all conditions: 10-
conditions, and similar temporal spacing between labeled items to
                                                                                  1
participants in the 40-Labeled Condition.                                           Available at http://www.pypsyexp.org
                                                                          751

            Item
                                     20                   120
           Density                  120                    20
                                    CH1                             40
         Unimodal Dimension
                                                                    60
                                                                    80
                                                                    60
                              20%
                                                              CH2   40
                                      10%                            Item
                                        20%                         Density
                                          Bimodal Dimension
Figure 3: A graphical depiction of the distribution of items in the
task. e two dimensions correspond to the size or angle of the stim-
uli (counterbalanced across participants). Each columnar distribu-
tion held half of all items. Items were placed into the bins to achieve
the sampling distribution in the right-hand histogram, assuring that
items in the center were more common than items at the ends of the
distribution. Most of the bins took up  of the variability on the
bimodal dimension and  on a unimodal dimension. e excep-
tions were the bins in the corners, which were given  of the space
on both dimensions to assure that they were symmetrical with re-                            Bimodal                Unimodal            Two-Dimensional
spect to one another. Labeled items were only placed into two corner
bins opposite one another, marked and .
                                                                                    Figure 4: Performance of randomly selected subjects in the test phase.
                                                                                    Four subjects best t by each model were chosen at random. Each
                                                                                    point represents an item that was presented to that participant dur-
                                                                                    ing the test phase. e color and shape (red circles or blue crosses)
Labeled (X̄ = .95, SD = .18, t(29) = 13.43, p < .001),                              indicate the response given by the participant to that item (i.e.,  or
40-Labeled (X̄ = .92, SD = .16, t(29) = 13.63, p < .001),                           ). e dashed black line indicates the discriminant boundary that
                                                                                    best t the pattern of responding.
and 40-All-Labeled (X̄ = .98, SD = .049, t(29) = 54.50,
p < .001). Two participants reversed the rule (that is, consis-
tently answered  when  was correct, and vice versa).                          examples), and showed high agreement with the model clas-
Overall, subjects were familiar enough with the labeled train-                      si cation (90% and 91%)2 .
ing examples to generalize consistently to highly similar test                          Four participants were best t by the Flat model. Because
items.                                                                              there were few of them and their strategies were diﬃcult to
Strategy Analysis Following Z&M (2009), participants’                               interpret, they were excluded from the analysis and replaced.
classi cation strategies were characterized using the General                       A summary of the ts of the remaining participants can be
Linear Classi er (or , Ashby, 1992). Four potential mod-                         found in Figure 5.
els were t to each subject. e rst two assumed that par-                                Replicating the ndings of Z&M (2009), participants in the
ticipants formed a rule that could be characterized as a cri-                       Unlabeled Condition showed a strong preference for classify-
terion on a single perceptual dimension: a Bimodal strategy                         ing stimuli along the bimodal dimension (20⁄30, binomial test
was characterized by a criterion on the bimodal perceptual                          with H0 ∶ k/n = 1/3, p < .001). No analogous preference
dimension, and a Unimodal strategy was characterized by a                           was found in the fully supervised (40-All-Labeled) condition
criterion on the unimodal dimension. e Two-Dimensional                             (13⁄30, H0 ∶ k/n = 1/3, p = .25). A direct comparison of
(2D) strategy was characterized by the use of a classi er in-                       the fully unsupervised (Unlabeled) and fully supervised (40-
tegrating information from both stimulus dimensions (i.e., a                        All-Labeled) conditions showed a reliable diﬀerence (Fisher’s
diagonal boundary through the space). ese three strategies                         exact test, p < .05). ere was a slight preference for the
formalize the strategies described in Figure 2. Finally, a Flat                     Bimodal strategy over the Unimodal strategy in the 40-All-
model was t, which assumed that all responses were random                           Labeled Condition (presumably from learning about the dis-
and did not depend on the observed stimulus. e best- tting                         tribution at test). However, since this is a control condition
model was chosen for each participant by comparing the                              2
                                                                                         Raters mostly disagreed in cases where subjects were best t by
values for each of these models (which penalizes more ex-                           the 2D model, but deviated from a 1D rule on only a few trials. Lack-
ible models such as our 2D model). Two research assistants                          ing a more principled method of choosing an objective criterion for
visually rated the response patterns as well (see Figure 4 for                      classi cation, we deferred the outcome of model comparison via .
                                                                              752

                         20                                                                          learning (Anderson, 1991; Love et al., 2004), but has proven
                                                                                                     surprisingly diﬃcult to observe. Our study represents yet an-
                                                                                                     other attempt to nd laboratory support for this form of cat-
Number of Participants
                         15                                                                          egory learning. However, the patterns of generalization be-
                                                                          Strategy                   havior exhibited at test during the two semi-supervised con-
                                                                             Bimodal
                                                                                                     ditions most closely resembled the strategies of participants
                         10                                                                          who learned in the fully supervised condition.
                                                                             Unimodal
                                                                                                        is result is striking for two reasons. First, unlike some
                                                                             Two-Dimensional         of the previous work on semi-supervised learning, our ex-
                          5                                                                          periment closely following existing protocols for studying un-
                                                                                                     supervised category learning in the literature in successfully
                                                                                                     replicating the results of Z&M (2009). In addition, given no
                          0                                                                          other information participants in our study were willing to
                              Unlabeled     10-        40-      40-All-
                                          Labeled    Labeled   Labeled                               generalize according to the distribution of unlabeled exam-
                                                                                                     ples. In the Unlabeled Condition, the most common strategy
    Figure 5: Histogram showing the trend in the number of subjects                                  was to use a rule on the bimodal dimension. However, when
    adopting each strategy across conditions. ere is a general trend of                             labeled examples were included, participants responded sim-
    an increase in the use of 2D rules in the presence of labeled items, as                          ilarly to the 40-All-Labeled Condition. is is the response
    well as a drop in the use of a  rule on the bimodal dimension, but                             pattern we would expect to see if subjects mostly failed to in-
    trends among the labeled conditions were weak.
                                                                                                     corporate the unlabeled items into their representation of the
                                                                                                     category in the semi-supervised learning conditions. In this
                                                                                                     sense, our results join a growing chorus of studies which have
    the same bias can be evaluated in other conditions. Overall,                                     failed to nd semi-supervised learning except under very spe-
    the diﬀerence between the Unlabeled and 40-All-Labeled con-                                      ci c and limited circumstances (Gibson, Zhu, Rogers, Kalish,
    ditions was driven largely by the increase in the use of 2D rules                                & Harrison, 2010; Rogers et al., 2010; Vandist et al., 2009).
    in the 40-All-Labeled Condition. Note that while the distri-                                        In the following sections, we outline a number of possibil-
    bution of labeled examples in the 40-All-Labeled Condition                                       ities about why semi-supervised learning has been so elusive
    is logically consistent with all three strategies (Unimodal, Bi-                                 in the lab.
    modal, 2D), a bias toward 2D rules is in line with the predic-                                   Noticing “gaps” in the input? In our design, the distribu-
    tions of the optimal linear discriminant for the labeled exam-                                   tion of labeled examples was systematically biased. One pos-
    ples.                                                                                            sibility is that learners eventually noticed the “gaps” in their
       Turning to the semi-supervised conditions, the distribution                                   input (i.e., that the labels only appeared with particular items)
    of strategies did not diﬀer signi cantly between these two con-                                  and thus inferred that these examples were somehow special
    ditions (Fisher’s exact test, p = .79). In addition, the propor-                                 or diﬀerent. Such a hypothesis may be consistent with a ratio-
    tion of participants using 2D rules did not vary between the                                     nal learner who tries to determine which items should be clus-
    conditions (Fisher’s exact test, p = .78).                                                       tered together (Griﬃths, Sanborn, Canini, & Navarro, 2008).
       Combining the two semi-supervised conditions, we nd                                           Under this view, an even smaller number of labeled exam-
    an overall interaction between condition and the use of 2D                                       ples (perhaps even one) may actually facilitate generalization
    rules (3 conditions × 2 strategies, Fisher’s exact test, p < .05).                               (since the amount of data is enough to learn, but not enough
    However, the primary source of this eﬀect seems to be the                                        to infer some systematic bias). We attempted to get at this is-
    diﬀerence between the Unlabeled Condition and the other                                          sue by modulating the number of labeled training examples,
    conditions. When we aggregate all the labeled conditions to-                                     and found no evidence of a trend. However, recent studies
    gether, we see a greater use of 2D rules by the labeled condi-                                   of one-shot learning suggest that oen even a single labeled
    tions than the unlabeled condition (2 conditions × 2 strategies,                                 example can support robust generalization (Lake, Salakhutdi-
    Fisher’s exact test, p < .05), while evidence for a parallel ef-                                 nov, Gross, & Tenenbaum, 2011).
    fect when aggregating the conditions had access to unlabeled
    training items together fell short of signi cance (2 conditions                                  Overweighting of labeled examples Another interpreta-
    × 2 strategies, Fisher’s exact test, p = .07). In summary, we                                    tion, suggested by Zhu et al. (2010) and Lake and McClel-
    found minimal evidence that the semi-supervised conditions                                       land (2011), is that labeled items may simply be given more
    were diﬀerent from the all-labeled condition.                                                    weight. Although this seems plausible, it would appear that
                                                                                                     the 10 labeled items in the 10-Labeled Condition outweighed
                                                    Discussion                                       the other 270 trials in the training phase, suggesting a weight
                                                                                                     for unlabeled items much lower than the previously reported
    Semi-supervised learning is a bit like the Higgs boson in par-                                   estimate of around 40% (Lake & McClelland, 2011). Interest-
    ticle physics. It is believed to occur (e.g., to allow word learn-                               ingly, subjects in our 10-Labeled Condition spent consider-
    ing) and is strongly suggested by theories of human category
                                                                                               753

ably more time studying the labeled items, presumably raising             Ashby, F. G., Queller, S., & Berretty, P. M. (1999). On the dominance
their relative in uence. One possibility is that the weight given                of unidimensional rules in unsupervised categorization. Per-
                                                                                 ception and Psychophysics.
to labeled items is actively adjusted by learners based on the            Bloom, P. (2000). How children learn the meaning of words. Cam-
task context.                                                                    bridge, MA: MIT Press.
                                                                          Clapper, J. P., & Bower, G. H. (1994). Category Invention in Unsuper-
Pedagological sampling While assuming that labeled ex-                           vised Learning. Journal of Experimental Psychology: Learning,
amples are given more weight might describe the lack of semi-                    Memory, and Cognition, 20, 443–460.
supervised learning, it oﬀers no speci c proposal for why this            Gentner, D. (1982). Why nouns are learned before verbs: linguistic
should be the case. One possibility is that participants be-                     relativity versus natural partitioning. In S. Kuczaj (Ed.), Lan-
                                                                                 guage development: lanugage, cognition, and culture (pp. 301–
lieved that the experimenter was providing information to                        334). Hillsdale, NJ: Erlbaum.
teach them the category via the labeled examples (i.e., the la-           Gibson, B., Zhu, X., Rogers, T., Kalish, C., & Harrison, J. (2010). Hu-
beled examples were pedagogically sampled). In this case, it                     mans learn using manifolds, reluctantly. In Advances in neural
                                                                                 information processing systems (Vol. 24).
may be reasonable to trust that the labeled items are particu-            Griﬃths, T. L., Sanborn, A. N., Canini, K. R., & Navarro, D. J. (2008).
larly informative about the category distinction. For example,                   Categorization as Nonparametric Bayesian Density Estima-
Shao, Goodman, Gerstle, and Ladusaw (2010) have shown                           tion.
that adults adjust their inferences based on the intention of a           Kalish, C. W., Rogers, T. T., Lang, J., & Zhu, X. (2011). Can semi-
                                                                                 supervised learning explain incorrect beliefs about categories?
speaker (either pedagogical or overheard). It is possible that                   Cognition, 1–13.
participants in a lab-like setting oen assume that training ex-          Lake, B., & McClelland, J. (2011). Estimating the strength of un-
amples are presented pedagogically, causing them to down-                        labeled information during semi-supervised learning. In L.
play the relevance of unlabeled trials.                                          Carlson, C. Hölscher & T. Shipley (Eds.), Proceedings of
                                                                                 the 33rd Annual Conference of the Cognitive Science Society.
Is an explicit prediction required? A nal hypothesis, there                      Austin, TX: Cognitive Science Society.
were minor diﬀerences between our task and previous work                  Lake, B. M., Salakhutdinov, R., Gross, J., & Tenenbaum, J. B. (2011).
                                                                                 One shot learning of simple visual concepts. In L. Carlson, C.
that may have in uenced performance. For example, partici-                       Hölscher & T. Shipley (Eds.), Proceedings of the 33rd annual
pants made observations and then simply pressed the space                        conference of the cognitive science society. Cognitive Science
bar to acknowledge each item. By contrast, both Kalish et                        Society. Austin, TX.
                                                                          Love, B. C. (2002). Comparing supervised and unsupervised category
al. (2011) and Lake and McClelland (2011) asked participants                     learning. Psychonomic Bulletin & Review, 9, 829–835.
to make a response on each trial. It is possible that mak-                Love, B. C., Medin, D. L., & Gureckis, T. M. (2004). SUSTAIN: A Net-
ing a response or prediction on each trial facilitates the inte-                 work Model of Category Learning. Psychological Review, 111,
gration of information across learning episodes. Consistent                      309–332.
                                                                          Markant, D., & Gureckis, T. M. (2010). Category Learning rough
with this view is the fact that subjects 40-All-Labeled Con-                     Active Sampling. Proceedings of the 32nd Annual Conference
dition showed evidence of learning from the items presented                      of the Cognitive Science Society.
at test (where predictions were required)—recall that partici-            Medin, D. L., & Schaﬀer, M. M. (1978). Context eory of Classi -
pants were slightly biased to respond according to the bimodal                   cation Learning. Psychological Review, 85, 207–238.
                                                                          Nosofsky, R. M. (1986). Attention, similarity, and the identi cation-
dimension, even though the only information about its bi-                        categorization relationship. Journal of Experimental Psychol-
modality was provided by the distribution of test examples.                      ogy: General, 115, 39–57.
A similar eﬀect may have carried over to the semi-supervised              Pothos, E. M., Perlman, A., Bailey, T. M., Kurtz, K., Hines, P., & Mc-
conditions as well.                                                              Donnell, J. V. (2011). Measuring category intuitiveness in un-
                                                                                 constrained categorization tasks. Cognition, 121, 83–100.
   Current work is exploring each of these possibilities. e              Rogers, T. T., Kalish, C., Gibson, B. R., Harrison, J., & Zhu, X. (2010,
hunt for semi-supervised learning continues.                                     May). Semi-supervised learning is observed in a speeded but
                                                                                 not an unspeeded 2D categorization task. Proceedings of the
                       Acknowledgments                                           32nd Annual Conference of the Cognitive Science Society.
We thank Seth Madlon-Kay and Dylan Simon for helpful com-                 Shao, P., Goodman, N. D., Gerstle, B., & Ladusaw, F. (2010). Prior
ments and discussion in the development of this project. TMG                     expectations in pedagological situations. Proceedings of the
was supported by the Intelligence Advanced Research Projects                     32nd Annual Conference of the Cognitive Science Society.
Activity (IARPA) via Department of the Interior (DOI) contract            Vandist, K., De Schryver, M., & Rosseel, Y. (2009). Semisupervised
D10PC20023. e U.S. Government is authorized to reproduce and                    category learning: e impact of feedback in learning the
distribute reprints for Governmental purposes notwithstanding any                information-integration task. Attention, 71, 328–341.
copyright annotation thereon. e views and conclusions contained          Zeithamova, D., & Maddox, W. (2009). Learning mode and exemplar
herein are those of the authors and should not be interpreted as nec-            sequencing in unsupervised category learning. Journal of Ex-
essarily representing the oﬃcial policies or endorsements, either ex-            perimental Psychology: Learning, Memory, and Cognition, 35,
pressed or implied, of IARPA, DOI, or the U.S. Government.                       731.
                                                                          Zhu, X. (2005). Semi-Supervised Learning Literature Survey. Techni-
                                                                                 cal Report 1530, 1–60.
                            References                                    Zhu, X., Gibson, B. R., Jun, K.-S., Rogers, T. T., Harrison, J., & Kalish,
Anderson, J. R. (1991). e adaptive nature of human categorization.              C. (2010). Cognitive Models of Test-Item Eﬀects in Human
        Psychological Review, 98, 409–429.                                       Category Learning. In e 27th international conference on
Ashby, F. G. (1992). Multidimensional Models of Categorization. In               machine learning (ICML) (p. 158).
        F. G. Ashby (Ed.), Multidimensional models of perception and
        cognition (pp. 449–483). Hillsdale, NJ: Lawrence Erlbaum As-
        sociates.
                                                                      754

