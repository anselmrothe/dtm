UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Efficient Serial Visual Search
Permalink
https://escholarship.org/uc/item/2q06449v
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Veksler, Bella
Gray, Wayne
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                       Modeling Efficient Serial Visual Search
                                              Bella Z. Veksler (bellav717@gmail.com)
                                    Air Force Research Laboratory, Wright-Patterson Air Force Base
                                                           Dayton, OH 45431 USA
                                                   Wayne D. Gray (grayw@rpi.edu)
                                     Cognitive Science Department, Rensselaer Polytechnic Institute
                                                             Troy, NY 12180 USA
                              Abstract                                   Canosa, 2001, p. 3588). For this reason, the task our partic-
   Humans perform visual search fairly efficiently, finding targets
                                                                         ipants performed was not visual search, but a decision mak-
   within only a few fixations. Data from eye-tracked participants       ing task that, like grocery shopping or finding the car in the
   was subjected to a fixation by fixation analysis to pinpoint why      parking garage, just happened to require visual search. The
   participants tended to make fewer fixations than would be ex-         vast majority of visual search studies have largely ignored
   pected by chance. The goal of this paper is to present a com-
   putational model that performs visual search as efficiently as        the process of visual search, with a few notable exceptions
   humans. The model varied several components that may have             (Zelinsky, Rao, Hayhoe, & Ballard, 1997; Araujo, Kowler, &
   aided visual search: memory, search strategy, and degree of           Pavel, 2001; Unema, Pannasch, Joos, & Velichkovsky, 2005;
   parafoveal vision. Two dependent measures were used to eval-
   uate the model: number of fixations to find the target and the        Zelinsky, 2008). This is problematic because “visual search
   distribution of saccade amplitudes. The best fitting model sug-       is more than the time taken by an observer to detect a target
   gested that the biggest contribution to efficient search came         and press a button. It is instead a richly complex behavior
   from larger parafoveal vision. Search strategy, however, ac-
   counted for the distribution of saccade amplitudes.                   having both a spatial and temporal dynamic” (Zelinsky et al.,
   Keywords: visual search; model; memory; parafovea                     1997, p. 448). By relying on only response time data, visual
                                                                         search paradigms have essentially thrown out the spatiotem-
                          Introduction                                   poral contingencies that propel the search process. In recent
Visual search is ubiquitous. Whether we are locating an item             years, however, a considerable effort has been put forth to
in the grocery store, trying to find our car in a busy park-             connect eye movements with the underlying cognitive pro-
ing garage, or looking for an important piece of information             cess (Liversedge & Findlay, 2000).
on a web page, visual search is involved in most every task                 Zelinsky (2008) analyzed eye movements from partici-
we perform. In this paper we discuss two critical compo-                 pants who searched for common household items on a table-
nents of efficient serial visual search, the number of fixations         top. The display was limited to six stationary locations where
taken to find a target and the strategy used to move the eyes            objects could appear and on each trial there was either one,
around the screen. Our emphasis is on active vision (Findlay             three or five items to search through. Results demonstrated
& Gilchrist, 2003) to examine the search strategies used by              that eye movements were directed towards geometric centers
people as they search for items in their environment. The goal           of progressively smaller groups of objects. It should be noted
of the current work was to devise a computational cognitive              that due to the limited search display (only six possible loca-
model that was capable of reproducing human visual search                tions and up to five items visible on any given trial) the eye
efficiency. A set of process models varied different cognitive           movement sequences were relatively short and, in practice,
capacities theorized to affect search efficiency (i.e., deliber-         limited to the first three fixations. Thus, a study which has
ate strategy, memory size and parafovea size) to explore the             a more complex object structure and which examines longer
parameter space associated with serial search efficiency.                sequences of fixations may better elucidate the visual search
   Visual search as a paradigm has been studied meticulously             process. One study that looked at longer fixation traces found
for the better part of the last 50 years. In that time several no-       that fixations and saccades progress in a coarse-to-fine strat-
table models of visual search have been proposed (Duncan &               egy whereby fixation durations increase while saccade ampli-
Humphreys, 1989; Treisman & Gelade, 1980; Wolfe, 1994).                  tudes decrease as search continues (Over, Hooge, Vlaskamp,
The paradigm itself consists of the detection of a target among          & Erkelens, 2007). Over et al. (2007) found that participants
a varying number of distractors. Search time has been found              initially attended to general properties of the search environ-
to be influenced by number of distractors (set size), similarity         ment (i.e., the lay of the land) but, as the trial progressed,
of distractors and targets, and number of features used to de-           gradually paid attention to specific, detailed information.
fine a target (Davis & Palmer, 2004; Wolfe, 2003). The ease                 One question we can ask is whether the layout of the
with which a target can be detected is often varied and re-              display facilitates and/or guides the visual search process.
sponse time data is typically used as the dependent measure.             Others have found that external landmarks aid visual search
   While knowing how quickly visual information is found                 by reducing the number of refixations on previously viewed
is important, understanding how that information is found is             items (Peterson, Boot, Kramer, & McCarley, 2004; Myers &
just as important—“vision is a tool, not the task” (Pelz &               Gray, 2010). In previous work, we found that segmenting
                                                                     2481

 the visual search display into perceptual clusters provides a      5. Participants held the number and threat value of the target
 starting point for understanding where the eyes may go (Vek-           with the “highest threat value so far” in memory as they
 sler & Gray, 2011). The modeling work presented here uti-              continued to locate other targets in the list of six.
 lizes the perceptual segmentation found in our previous work
 to explore the efficiency of serial visual search within this      6. When they decided that they had found the target with the
 paradigm. Furthermore, two metrics are used to compare hu-             highest threat value (usually, but not always, after an ex-
 man and model data: number of fixations to locate the tar-             haustive search), they selected that target (with the mouse)
 get and the distribution of saccades around the screen during          in the list on the right hand side, and clicked on the Choose
 search.                                                                button (at the bottom right of Figure 1).
    The role of memory within visual search has also been
                                                                        Although participants searched through the display for
 greatly debated. In some instances, researchers have inferred
                                                                     multiple targets on any given trial, for purposes of this pa-
 from response time data that memory is not utilized during
                                                                     per, only the first search through the display (until the first
 search (Horowitz & Wolfe, 2003; Melcher & Kowler, 2001).
                                                                     search target is found) will be reported and modeled.
 In other instances, it has been shown that visual search is
 guided by memory for previously viewed items (Korner &              Method
 Gilchrist, 2007; Peterson, Beck, & Wong, 2008, 2001), that
 there is some memory for the search path (Dickinson & Zelin-        Participants were divided into four conditions which varied
 sky, 2007), and that more new locations are searched as op-         the duration of how long they had to wait before information
 posed to old (Beck, Peterson, Boot, Vomela, & Kramer, 2006;         (threat value of target) appeared (1, 2, 4, or 8 s). All other
 McCarley, Wang, Kramer, Irwin, & Peterson, 2003). The cur-          aspects of the task remained the same across all participants.
 rent work also explores the role of memory within visual
 search, by varying the number of previously seen items that
 the model avoids re-fixating during search.
    In summary, we use human data and computational model-
 ing to explore the combination of components that contribute
 to efficient serial visual search. The components explored in-
 clude search strategy, amount of memory for previously seen
 items, and the effective field of view. Previewing our conclu-
 sions, the major contribution to search efficiency comes from
 a larger parafovea. Memory plays an important role in this
 task, though not as an important role as we might have ex-
 pected. Search strategy was explored as human data indicated
 that participants did not move their eyes around the screen in
 a random fashion, but rather transitioned across clusters of
 items on the screen.
                                                                                        Figure 1: Task environment.
                          Experiment
 We explore the allocation of attention during visual search         Participants A total of 88 participants from Rensselaer
 when search is a subtask of a larger decision making task.          Polytechnic Institute were run during the study. Of those, 12
 The larger task was composed of the following on each trial,        were excluded because their valid eye data fell below 90%,
                                                                     and two were excluded because their accuracy scores fell be-
1. 20 targets (represented as two-digit numbers) appeared on         low 3 standard deviations of the group mean resulting in 74
    a radar screen at random locations (left-side of Figure 1).      participants included in the analyses (57 males). There were
    Each two-digit target subtended a 0.62◦ of visual angle.         19 participants in two of the conditions and 18 in the other
                                                                     two. The mean age of all participants was 18.8, SD=0.85.
2. Participants were provided with a list of six targets (right-     Apparatus The experiment was presented using a com-
    side of Figure 1) and told to determine which target had the     puter running Mac OS X on a 17 inch flat-panel LCD monitor
    highest threat value.                                            set to 1024x768 resolution, 39◦ x 25◦ of visual angle at the
                                                                     distance at which participants sat from the screen.The soft-
3. Participants had to locate each one of the targets on the         ware used for the experiment was written in LispWorks 5.0.
    radar screen (visual search) and click on it with the mouse.     An LC Technologies eye tracker was used to collect eye data
                                                                     during the study at a rate of 120Hz. A chin rest was used to
4. The target’s threat value appeared next to the target. The        help ensure the accuracy of recorded eye data. Eye data qual-
    delay between clicking and appearance varied between             ity was checked after every block of 10 trials to ensure the eye
    groups – 1, 2, 4, or 8 seconds.                                  tracker was functioning and participants remained calibrated.
                                                                 2482

Procedure Participants were run separately. After signing             ison with the models.
informed consent forms, participants were given task instruc-
tions, calibrated to the eye-tracker and asked to keep their
chin in the chinrest throughout the duration of the experiment.                                       Cumulative Probability of Finding Target
They also had to fixate a fixation cross prior to each trial to                         1.0
ensure the eye-tracker’s accuracy.
   Participants completed six blocks of 10 trials (60 trials to-
tal). A mandatory 60s break was included halfway through                                0.8
the study. A practice block of 5 trials was included prior to
the 60 experimental trials during which time the experimenter
remained in the room to ensure that participants understood                             0.6
                                                                          Probability
how to do the task and that eye data remained valid. The
experiment took ≈ 40 minutes to complete. Each trial pro-
                                                                                        0.4
ceeded as described in the beginning of the Experiment sec-
                                                                                                                         Human
tion.                                                                                                                    Best Fit Cluster
                                                                                                                         Best Fit Cluster w/ Mem
                                                                                        0.2                              Best Fit Random
Results
                                                                                                                         Random no Memory
The majority of participants tended to search for targets in                                                             Random w/ Perfect Memory
the order presented on the right hand side of the display (top                          0.0
to bottom). Participants tended to locate the first target they                               1   5      10    15       20      25        30   35   40   45
were searching for after ≈ 8 fixations on radar items. Since                                                        Number of Fixations
the first search in a trial was not biased by any memory effects
of having found a target on a previous search, it will be used
for comparison to simulation model results.                           Figure 2: Cumulative Probability of Finding the Target
                                                                      Within Number of Fixations.
Number of Fixations to Find Target Table 1 summarizes
the average number of fixations to locate the target, by con-
dition in the study. A one-way ANOVA was conducted and                   Figure 2 shows the cumulative probability of finding the
indicated that there was not a significant effect of condition        initial target within N fixations, aggregated across all 74 par-
on either the total number of fixations to find the target, F(3,      ticipants. This figure also suggests that about 50% of the time
69) = 1.27, p = .29, or the number of unique fixations to find        participants located the target within 8 fixations. For compar-
the target, F(3,69) = 0.63, p = .60. Importantly, of the fix-         ison purposes, Figure 2 also shows what would be expected
ations shown in Table 1, roughly one target is fixated twice.         by chance in a model that randomly searched the radar with
This pattern suggests that participants were not necessarily          either no memory (dashed line) for previously seen items or
maintaining all of the searched items in memory.                      perfect memory (dotted line). As can be seen, participants
                                                                      find the target in fewer fixations (8 on average) than would
                                                                      be expected by chance (10 or half of the items on the screen).
Table 1: Average number of total and unique fixations on              This suggests that accounting only for the amount of items
radar items prior to finding first target in a trial.                 held in memory (so as not to refixate them) during search is
                                                                      insufficient to model this efficiency.
 Condition     N     Mean Total (SD)      Mean Unique (SD)
                                                                      Eye Movements and Clusters In prior work, we derived a
    1          18      8.38 (1.6)            7.66 (0.86)
                                                                      perceptual clustering algorithm which utilized human judg-
    2          19      7.57 (1.06)           7.24 (0.75)
                                                                      ments of clusters to segment the display (Veksler & Gray,
    4          19      8.2 (1.48)            7.47 (0.93)
                                                                      2011). Participants in that study judged items to be part of
    8          18      8.0 (1.19)            7.48 (0.87)
                                                                      the same cluster if they were within 3.28◦ of visual angle of
                                                                      each other. The algorithm adds items to a single cluster if
   Collapsing over conditions, Figure 2 plots the cumulative          they are less than 3.28◦ of visual angle apart, further adding
probability of finding the first target selected. A two-way           more items that fall within 3.28◦ of all the items in the cluster
ANOVA (number of fixations as a repeated factor) was run              already until no more can be added. The segmented displays
to determine whether the lockout condition influenced search          generated using this algorithm were then used to determine
efficiency. There was a significant main effect of number of          whether search is based on clusters of targets.
fixations, F(43, 2967) = 2847.23, p < .001, no interaction,              Figure 3 illustrates the probability within the human eye
F(129, 2967) = 0.95, p = .63, and no main effect of condi-            data of a participant remaining in any given cluster given the
tion, F(3, 69) = 0.54, p = .66 on the probability of finding the      size of that cluster. Given the eye fixation transitions, three
target within that number of fixations. Therefore all data from       equations were derived to fit the transition probabilities in the
the different conditions was collapsed to be used for compar-         human data and to be later used in the model that moves its
                                                                   2483

eyes around the screen.                                                           participants occasionally swept their eyes across larger areas
                                                                                  of the screen. It is beyond the scope of this paper to address
• Likelihood of staying in a cluster given the size of the clus-                  these larger sweeps or when they tended to occur.
  ter is:
                                                                                                               Model
               P(Stay In Cluster) = .3292 ∗ ln(clustersize) − .0266 (1)
                                                                                  Several visual search models were explored and simulated in
• If participants stay within a cluster, the likelihood of them                   order to model the efficiency of human serial visual search.
  looking at the closest item to the current fixation within the                  There were three parameters that were manipulated in the
  cluster is:                                                                     modeling of the visual search process in this task. The first
                                                                                  was the degree to which memory for previously seen items
              P(Go To Closest In Cluster) = 1.4324 ∗ (clustersize)−.776           was used in the search process. The memory component es-
                                                                     (2)          sentially avoids shifting gaze to a target if it has been pre-
                                                                                  viously fixated within the last N fixations. The number of
• If participants move their gaze outside of the cluster, the
                                                                                  items held in memory was varied between 1(no memory)-
  likelihood of them looking at the closest item outside of
                                                                                  19(perfect memory). It should be noted that even though we
  the cluster is:
                                                                                  only looked at the first search within the trial, there may still
          P(Go To Closest Outside Cluster) = .1888∗e(.0577∗clustersize)           be memory operating during search, particularly for previ-
                                                                 (3)              ously searched locations.
                                                                                     The second parameter that was explored was the effective
                                                                                  Field of View (FOV) that the model has. The model is able
                                                                                  to shift its gaze to the target it is searching for if it notices it
                              Probability of Staying In Cluster
                                                                                  within its parafovea, typically about 2 to 6 degrees of visual
               1.0                                                                angle around the current fixation (Reis & Judd, 2000). While
                                                                                  the fovea is the high acuity region of the retina, up to about 2◦
                                                     Distance First               of visual angle, the parafovea is a region in which acuity is not
               0.8                                   Human                        as high, with decreasing acuity as the eccentricity from the
                                                     Random                       fovea increases. We explored values of 1,2,2.5, and 3 degrees
                                                                                  of visual angle around the current fixation point providing
               0.6
Probability
                                                                                  an effective fovea+parafovea region (FOV) of 2, 4, 5, and 6
                                                                                  degrees, respectively.
               0.4                                                                   The final manipulation had to do with the actual search
                                                                                  strategy used. Three search strategies were explored: cluster-
                                                                                  based, cluster-based with memory for clusters and random.
               0.2                                                                   The cluster-based search model first segments the screen
                                                                                  into several clusters based on prior empirical work (Veksler &
                                                                                  Gray, 2011). These clusters are then used to guide the model’s
               0.0
                                                                                  eye movements based on the cluster transition probabilities
                     1   2    3     4     5      6       7     8      9   10      as per Equations 1-3. The model decides on each fixation
                                        Cluster Size                              whether or not it wants to shift attention away from the cur-
                                                                                  rent cluster. It then decides with a certain probability to shift
                                                                                  its gaze to either the closest item within the cluster or the
Figure 3: Probability of staying in the cluster on subsequent
                                                                                  closest item outside of the current cluster. The cluster-based
fixation. Distance First: prediction if participants always sac-
                                                                                  model with memory for clusters also maintained memory for
caded to closest item to current. Random: prediction if par-
                                                                                  clusters it has already searched. Thus, when transitioning out
ticipant randomly saccaded around the screen.
                                                                                  of a cluster, it avoided looking to targets within previously
                                                                                  searched clusters.
Distribution of Saccade Amplitudes In addition to look-                              The random model search strategy is used as a baseline
ing at the number of fixations that participants made to find                     model. This model disregards the placement of the items on
the target, we also looked at the distribution of saccades (dis-                  the screen and randomly chooses a target from the set of tar-
tances traveled by the eye between fixations). Figure 4 il-                       gets in the radar. The memory component was varied from
lustrates the distribution of saccade amplitudes in the human                     a random model with no memory to one with perfect mem-
data (solid black line). As can be seen, the majority of sac-                     ory for targets already seen. One limitation of this model is
cades span about 2.26◦ of visual angle indicating participants                    that because the model disregards placement of items on the
moved their eyes to locations fairly close to each other. There                   screen, its shifts of gaze can span long distances resulting in
is however, a smaller second mode around 17◦ indicating that                      inefficient eye movements.
                                                                               2484

   There were 19(memory store) × 4(FOV angle) × 3(strate-
                                                                    Table 2: Best fitting simulation model in each search strategy,
gies) models run on the radar targets used by participants in
                                                                    comparing cumulative number of fixations. FOV: effective
the study. Each model was run on each of the trials of hu-
                                                                    field of view in degrees of visual angle.
man data and the number of fixations along with saccade am-
plitudes that were made prior to finding the first target were          Search Strategy   Memory      FOV (◦ )    RMSE       R2
recorded to be compared with human data from the same set.                 Random            1          2          0.19     0.83
In all, each model was run on 4559 trials.                                 Random           19          2          0.04     0.90
                                                                           Random           14          5         0.017     0.99
Results                                                                     Cluster         15          6         0.025     0.99
The simulations were run to determine which models could                Cluster w/ Mem       4          5         0.018     0.99
find the targets in the radar using the same number of fix-
ations that participants used. The cumulative likelihood of
finding the first target in a trial within N fixations was de-
rived for each model and the human data and then compared.
                                                                    Table 3: Simulation models’ results comparing saccade am-
As an additional dependent measure, fixation transitions were
                                                                    plitude distributions. FOV: effective field of view in degrees
recorded for each model and the distribution of saccade am-
                                                                    of visual angle.
plitudes was compared with human data.
                                                                        Search Strategy    Memory      FOV (◦ )    RMSE      R2
                                                                           Random            13          6         0.0009    .44
                            Saccade Amplitude
                                                                         Distance First      16          6         0.0015    .75
                                                                            Cluster           4          6         0.0004    .90
                                                                        Cluster w/ Mem        8          6         0.0004    .86
            0.4
                                                                           Random            14          5         0.0010    .36
                                                                            Cluster          15          6         0.0004    .88
                                         Human                          Cluster w/ Mem        4          5         0.0005    .82
            0.3                          Random
                                         Distance First
Frequency
                                         Cluster
                                         Cluster w/ Mem
            0.2
                                                                    cluster-based search model that did not utilize cluster mem-
                                                                    ory needed to remember 15 items and required a FOV of 6
            0.1                                                     degrees to attain good fit, RMSE=0.0252 and an R2 =.99. The
                                                                    top random search model needed a memory for 14 items and
                                                                    a FOV of 5 degrees, RMSE=0.017, R2 =.99. Table 2 summa-
            0.0                                                     rizes the results of the model comparisons along with baseline
                                                                    comparison to the two models depicted in Figure 2. For con-
                  0   5             10              15    20
                                                                    ciseness only the best fitting models are reported.
                          Degrees of Visual Angle
                                                                      These results suggest that for a model to be able to search
                                                                    as efficiently as human participants, it needs to have some
Figure 4: Distribution of saccade amplitudes across all eye
                                                                    amount of a parafovea and either a large memory for individ-
data for humans and models. Models depicted are best fitting.
                                                                    ual items or a small memory for individual items along with
                                                                    some memory for clusters searched.
    Search efficiency was greatly improved by the inclusion of
a parafovea in all of the models (a FOV of 4, 5 or 6 degrees            Next we compared the distribution of saccade amplitudes
of visual angle). Without a parafovea (57 models), the best         over the course of the search in each of the models. As an
fit that can be achieved between human and model data has           added baseline, a distance-first model was run to show what
an RMSE=0.11 and an R2 =.92. The model that achieves this           would happen if the model always saccaded to the closest
is the cluster search model with cluster memory and memory          item to its current point of gaze. Figure 4 depicts the hu-
for 16 individual targets. If we include a parafovea, 74% of        man data along with the best fitting models using each of the
the parafovea-included models surpass this fit. Therefore, the      search strategies. Table 3 provides statistics for both the best
models that were next compared all had varying degrees of a         fitting models (top panel) as well as the best fitting models
parafovea.                                                          from the cumulative number of fixations comparison (bottom
    Based on RMSE, the top 15 models all had an effec-              panel). In terms of modeling the distribution of saccade am-
tive FOV of 5 degrees. The top cluster-based search model           plitudes, both of the cluster-based search models fit the hu-
that utilized cluster memory had a memory of 4 items,               man data well. The random search and distance first model,
RMSE=0.018 and an R2 =.99. For comparison, the top                  however, have much poorer fits.
                                                                 2485

                          Discussion                                Liversedge, S. P., & Findlay, J. M. (2000). Saccadic eye
This work was intended to provide a computational model of            movements and cognition. Trends in Cognitive Sciences,
the efficiency of serial visual search found in humans. Two           4 (1), 6–14.
dependent measures were used to evaluate the models gen-            McCarley, J. S., Wang, R. X. F., Kramer, A. F., Irwin, D. E.,
erated: efficiency of search (number of fixations to locate a         & Peterson, M. S. (2003). How much memory does ocu-
target) and the distribution of saccade amplitudes (how far           lomotor search have? Psychological Science, 14 (5), 422–
the eye moved between fixations). It was found that incor-            426.
porating a larger parafovea contributed a great deal to the         Melcher, D., & Kowler, E. (2001). Visual scene memory and
efficiency with which the model was capable of finding the            the guidance of saccadic eye movements. Vision Research,
target. The inclusion of a memory for clusters allowed the            41 (25-26), 3597–3611.
model to have less of a need for a larger memory store for in-      Myers, C. W., & Gray, W. D. (2010). Visual scan adaptation
dividual items searched. The cluster-based search model was           during repeated visual search. Journal of Vision, 10 (8.).
also much better able to reproduce the distribution of saccade      Over, E. A. B., Hooge, I. T. C., Vlaskamp, B. N. S., & Erke-
amplitudes found during human visual search, suggesting the           lens, C. J. (2007). Coarse-to-fine eye movement strategy in
efficacy of a search strategy based on segmentation of a dis-         visual search. Vision Research, 47 (17), 2272–2280.
play into clusters.                                                 Pelz, J. B., & Canosa, R. (2001). Oculomotor behavior and
   One limitation of the current cluster-based model and di-          perceptual strategies in complex tasks. Vision Research,
rection for future work is accounting for the longer spanning         41 (25-26), 3587–3596.
saccades as when human participants transition out of a clus-       Peterson, M. S., Kramer, A. F., Wang, R. X. F., Irwin, D. E.,
ter (i.e. moving to the opposite side of the screen). Another         & McCarley, J. S. (2001). Visual search has memory. Psy-
is addressing the discrepancy between the best fitting models         chological Science, 12 (4), 287–292.
according to the two dependent measures.                            Peterson, M. S., Boot, W. R., Kramer, A. F., & McCarley,
                                                                      J. S. (2004). Landmarks help guide attention during visual
                     Acknowledgments                                  search. Spatial Vision, 17 (4-5), 497–510.
The work was supported, in part, by grant N000141010019             Peterson, M. S., Beck, M. R., & Wong, J. H. (2008). Were you
to Wayne Gray from the Office of Naval Research, Dr. Ray              paying attention to where you looked? the role of executive
Perez, Project Officer. Preparation of this document was per-         working memory in visual search. Psychonomic Bulletin &
formed while the main author held a National Research Coun-           Review, 15 (2), 372–377.
cil Research Associateship Award at Air Force Research Lab.         Reis, H., & Judd, C. (2000). Handbook of research meth-
                                                                      ods in social and personality psychology. Cambridge Univ
                          References                                  Press.
Araujo, C., Kowler, E., & Pavel, M. (2001). Eye movements           Treisman, A. M., & Gelade, G. (1980). Feature-integration
   during visual search: the costs of choosing the optimal            theory of attention. Cognitive Psychology, 12 (1), 97–136.
   path. Vision Research, 41 (25-26), 3613–3625.                    Unema, P. J. A., Pannasch, S., Joos, M., & Velichkovsky, B.
Beck, M. R., Peterson, M. S., Boot, W. R., Vomela, M., &              M. (2005). Time course of information processing during
   Kramer, A. F. (2006). Explicit memory for rejected distrac-        scene perception: the relationship between saccade ampli-
   tors during visual search. Visual Cognition, 14 (2), 150–          tude and fixation duration. Visual Cognition, 12 (3), 473–
   174.                                                               494.
Davis, E. T., & Palmer, J. (2004). Visual search and attention:     Veksler, B. Z., & Gray, W. D. (2011). A tale of two prob-
   an overview. Spatial Vision, 17 (4-5), 249–255.                    lems: human judgments of visual clusters and data collec-
Dickinson, C. A., & Zelinsky, G. J. (2007). Memory for the            tion via the web vs. paper. In Proceedings of the Human
   search path: evidence for a high-capacity representation of        Factors and Ergonomics Society 55th Annual Meeting. Hu-
   search history. Vision Research, 47 (13), 1745–1755.               man Factors and Ergonomics Society. Las Vegas, NV.
Duncan, J., & Humphreys, G. W. (1989). Visual-search and            Wolfe, J. M. (1994). Guided search 2.0 - a revised model of
   stimulus similarity. Psychological Review, 96 (3), 433–            visual-search. Psychonomic Bulletin & Review, 1 (2), 202–
   458.                                                               238.
Findlay, J. M., & Gilchrist, I. D. (2003). Active vision. Oxford    Wolfe, J. M. (2003). Moving towards solutions to some en-
   Univ. Press.                                                       during controversies in visual search. Trends in Cognitive
Horowitz, T. S., & Wolfe, J. M. (2003). Memory for rejected           Sciences, 7 (2), 70–76.
   distractors in visual search? Visual Cognition, 10 (3), 257–     Zelinsky, G. J. (2008). A theory of eye movements during tar-
   298.                                                               get acquisition. Psychological Review, 115 (4), 787–835.
Korner, C., & Gilchrist, I. D. (2007). Finding a new target         Zelinsky, G. J., Rao, R. P. N., Hayhoe, M. M., & Ballard, D.
   in an old display: evidence for a memory recency effect            H. (1997). Eye movements reveal the spatiotemporal dy-
   in visual search. Psychonomic Bulletin & Review, 14 (5),           namics of visual search. Psychological Science, 8 (6), 448–
   846–851.                                                           453.
                                                                2486

