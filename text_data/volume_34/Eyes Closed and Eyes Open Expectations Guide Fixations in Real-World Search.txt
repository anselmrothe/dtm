UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
“Eyes Closed” and “Eyes Open” Expectations Guide Fixations in Real-World Search
Permalink
https://escholarship.org/uc/item/81z9n61t
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Author
Foulsham, Tom
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                  “Eyes Closed” and “Eyes Open” Expectations
                                         Guide Fixations in Real-World Search
                                              Tom Foulsham (foulsham@essex.ac.uk)
                                              Department of Psychology, University of Essex
                                                Wivenhoe Park, Colchester, CO4 3SQ, UK
                             Abstract                                   to regions of high salience until they find what they are
                                                                        looking for. However, it is clear from several experiments
   Investigations of search within realistic scenes have identified     that, when searchers know what they are looking for, this
   both bottom-up and top-down influences on performance.               knowledge, and not simple visual salience, dominates the
   Here, I describe two types of top-down expectations that
   might guide observers looking for objects. Initially, likely         locations inspected during search (Chen & Zelinsky, 2006;
   locations can be predicted based only on the target identity         Foulsham & Underwood, 2007).
   but without any visual information from the scene (“Eyes                This has led to more realistic models that combine top-
   closed”). When a visual preview becomes available, a more            down knowledge of the searcher to prioritize those locations
   refined prediction can be made based on scene layout (“Eyes          in a scene in which an object is likely to appear. One way to
   open”). In two experiments participants guessed the location         do this is to compare scene locations with a representation
   of a target with or without a brief preview of the scene.
                                                                        of target appearance. If one knows that the target is red,
   Responses were consistent between observers and were used
   to predict the eye movements of new observers in a third             locations with this colour should be more likely to be
   experiment. The results confirm that participants use both           fixated. This principle underlies several models of search
   types of top-down cues during search, and provide a simple           guidance (Wolfe, 1994; Navalpakkam & Itti, 2005), and can
   method for estimating these expectations in predictive               be successful at predicting fixations in real scenes
   models.                                                              (Zelinsky, 2008; Kanan et al., 2009).
                                                                           However, it is clear from the scenario at the beginning of
   Keywords: scene perception; visual search; attention; eye
                                                                        this paper that searchers also have access to detailed
   movements
                                                                        expectations about target location. There is evidence from
                                                                        several different experiments that these expectations are
                          Introduction
                                                                        used to direct attention during search. For example,
Imagine walking into a friend’s kitchen to look for a coffee            scrambling an image—so that local visual features remain
mug when you have never been there before. Even before                  the same but their configuration is altered—impedes search
you open the door you would already have a significant                  and alters eye movements (Biederman et al., 1973;
amount of knowledge about where this object might be. For               Foulsham, Alan & Kingstone, 2011). Objects that are
example, you would not expect it to be on the floor or near             incongruent with their context or out of place may be found
the ceiling, so you would be unlikely to look in these                  more slowly (Henderson, Weeks & Hollingworth, 1999).
locations. When entering the room, the first glance tells you           The contextual guidance model proposed by Torralba et al.
that, in this particular kitchen, there is a large window on            (2006) accounts for these effects by combining bottom-up
one side of the room and shelving with cupboards on the                 salience with a Bayesian prior for where an object is likely
opposite side. You refine your expectations about where the             to be, conditioned on the global features of an image. In
object will be and subsequently recognize the mug on a                  essence, the model recognizes the gist and layout of a scene
shelf.                                                                  (e.g., finding street level in an urban environment), learns
   As this scenario reveals, searching for something in the             the target’s likely location within this representation, and
real world involves not just the matching of visual                     searches accordingly (e.g., by looking for people at street
information to a stored template but also the use of detailed           level).
semantic knowledge about scenes and objects. Although                      The top-down guidance by context discussed so far
visual search has been very well studied in cognitive                   emerges early, with the first glance of a scene, but requires
psychology, this has mostly been in the context of simple               visual input in the form of low spatial-frequency features
search displays and models that predict performance based               and “gist”. On the other hand, it is likely that the semantic
on target features (e.g., Wolfe, 1998). More recently, there            information associated with different objects might include
has been significant interest in exploring the mechanisms               general expectations about position within a scene-centered
involved in directing attention during search within natural            or person-centered frame-of-reference which could be
scenes, and in testing these mechanisms by measuring eye                activated before exposure to the to-be-searched scene. The
fixations.                                                              present paper investigates whether these expectations are
   In one approach, computational models of bottom-up                   reliable and whether they effect the distribution of attention
visual salience have been proposed that select targets based            in real-world search. If so, they could be incorporated into
on the degree to which they stand out from their background             probabilistic models (e.g., Kanan et al., 2009; Torralba et
(Itti & Koch, 2000). By this account, participants will attend          al., 2006).
                                                                    330

   I will distinguish between “Eyes closed” expectations,                                     KETTLE
which can be made prior to any perception of the scene, and
                                                                                                                    !
“Eyes open” expectations, which are affected by a rapid                  Experiment 1
perception of scene gist, as might be available during the               “Eyes closed”
first fixation on a scene. I describe two simple experiments
to quantify “Eyes closed” and “Eyes open” predictions, and                                 Guess prompt      Response
these predictions are then compared to the eye fixations
                                                                                                                 "#$$%#!
made by independent searchers. If contextual guidance of
attention occurs only in response to scene features then
”Eyes closed” expectations will not be a good description of             Experiment 2
                                                                          “Eyes open”
where people look during search.
                  Experiments 1 and 2                                                   Scene preview (67ms)  Guess prompt      Response
In Experiments 1 and 2, participants guessed where a target          Figure 1: The procedure for one trial in Experiment 1 (top)
object would be located based on very little information.            and Experiment 2 (bottom). The target is highlighted in the
                                                                                scene preview, for display purposes only.
Method
                                                                    Scores were calculated from the average Euclidian distance
Participants Eighteen student volunteers (12 females) took          between the chosen location and the centre of the target
part in return for course credit. All participants took part in     object, in target present trials only, and normalized by the
Experiment 1 first, followed by Experiment 2. The mean              scene diagonal. All 72 target labels were presented in a
age was 19.4 years.                                                 random order, but the actual scenes were not shown to
                                                                    participants.
Stimuli and Apparatus The stimuli for all experiments                  In Experiment 2, participants were given a brief preview
were derived from 72 colour photographs of indoor and               of the scene in which the target was located before they
outdoor scenes collected from the Internet. Scenes were             made their response. In each trial, a text prompt told
chosen which contained a single example of an easily                participants to get ready, and a fixation cross was then
nameable target object that was not located directly in the         presented in the centre of the screen for 1s. The scene was
centre of the image. The name of this object was the                then presented briefly for 67ms, followed by a target label
matching target label for the scene.                                presented alongside a grey rectangle representing the image
   Each target label was also matched to another scene from         frame. The brief preview was chosen because it is known
the set in which it could plausibly be found. This led to 144       that scene gist can be perceived very quickly (Biederman et
label-scene pairs, half of which were “target-present” trials,      al., 1973), and also to limit the possibility that targets would
where the scene contained the target, and half of which were        be attended during the preview. A pattern mask was not
“target-absent”. The same target labels were used in both           included, and so after-images may have persisted, although
experiments.                                                        the guess prompt had the effect of partly masking the
   Target labels were presented in large black font centred         display and drawing attention away from the scene. As in
above a grey rectangle representing the scene. In                   Experiment 1, participants were instructed to guess the
Experiment 2, scene images were presented at a resolution           location of the target with a mouse click, and feedback was
of 1024 x 768 pixels. Stimuli were presented on a 19-inch           given regarding average performance over the previous 12
CRT monitor with a refresh rate of 60Hz. Presentation was           trials. In Experiment 2, all 144 label-scene pairs were
controlled by PsychoPy (Pierce, 2007), and responses were           presented in a random order.
entered with the mouse.
                                                                    Analysis and Results
Procedure Figure 1 depicts the procedure. In Experiment 1,          The results were analysed in order to estimate the inter-
participants were instructed to “make their best guess”             observer agreement, i.e., the degree to which different
where a target was located in an image. The experiment              participants “guessed” in similar locations for each target
began with a practice example of a target and scene. In the         label. The approach used closely followed that in previous
experimental trials, a target label was presented alongside a       studies of fixations in real-world search (Torralba et al.,
grey rectangle representing the image frame, and                    2006; Ehinger et al., 2009). Participant-selected locations
participants were instructed to click with a mouse cursor           were first combined to produce a spatial model of target
where in the frame they thought the target was located. In          predictions—an “expectation map”—which was then used
order to motivate participants, feedback was given after            to predict search behaviour in Experiment 3.
every 12 trials in the form of a percentage score                      Expectation maps were formed by representing each
representing how close their mouse clicks had been to the           participant’s guessed location as a 2-dimensional Gaussian
actual target locations.                                            and summing across all participants. The highest points on
                                                                    this map indicate locations that, according to the
                                                                331

participants, are most likely to contain the target. The                 The targets used were distributed throughout the scene,
dispersion of the map will reflect between-participant                 and could appear anywhere. However, some of the
agreement: maps that cluster into a few small areas signify            agreement may have originated because, across all trials,
that participants agreed on where a target was likely to               objects and mouse clicks were more likely to be in some
appear. Maps were computed separately for each target label            locations (such as the centre of the image) than others. To
in Experiment 1, and for target-present and target-absent              control for this, an additional “between-target” analysis was
trials in Experiment 2.                                                performed using the method described above but with the
   The receiver operating characteristic (ROC) curve was               responses associated with each object used to predict those
used to evaluate expectation maps. The ROC curve is a non-             from a different target (e.g., how well do guesses for the
parametric measure of sensitivity originating from signal              location of a flower pot predict those for a ceiling fan or a
detection theory. This measure has become common in                    TV?). This control analysis will therefore quantify
machine learning, and also in studies of spatial attention and         convergence that is independent of the particular target. This
eye movements, as it allows spatial distributions (e.g.,               between-target control was higher than 0.5, probably
salience maps) to be compared to specific locations (e.g.,             because some objects were in a similar position.
eye fixations). Full coverage of this method can be found              Importantly, inter-observer agreement was significantly
elsewhere (e.g., Ehinger et al., 2009). The area under the             higher than the between-target control AUC, in both
curve (AUC) was computed as a summary statistic. AUC                   Experiments (all ts(71)>3.8, ps<.001).
values indicate the probability that the map will rank a
selected location more highly than a non-selected location                Table 1: Inter-observer agreement in target guesses in
and range from 0 to 1, with a score of 0.5 indicating chance              Experiments 1 and 2. AUC values give the mean and
performance.                                                                       standard deviation across all targets.
Inter-Observer Agreement An all-except-one method was                                                                 AUC
                                                                                      Trial type
used to compute the between-participant agreement for each                                                         Mean   SD
expectation map. In this analysis, a map was computed                       Experiment 1: “Eyes closed”
based on the responses of all participants except one, and
the ROC curve was used to evaluate how well this model                                All trials                    0.79       0.07
predicted the location chosen by the remaining participant.                  Experiment 2: “Eyes open”
This process was repeated for all participants, and the mean
                                                                                   Target-present                   0.88       0.08
AUC value obtained is an indicator of the inter-observer
agreement in guessed locations.                                                     Target-absent                   0.83       0.08
   Figure 2 shows a target expectation map for two example                     Between-target control               0.71       0.1
target labels from Experiment 1. The first is from a target on
which participants showed considerable agreement, while
the mouse clicks in the second are more distributed. Table 1             Inter-observer agreement was significantly higher in the
summarizes the between-participant AUC scores across all               preview Experiment 2 than in Experiment 1. Moreover, this
targets in Experiments 1 and 2. Critically, all the scores are         was the case in both target-present scenes (where
much greater than 0.5, confirming that participants were               participants could have, in theory, perceived the target
indeed consistent in the points that they chose. This was true         object during the preview; t(71)=5.6, p<.0001) and in target-
for Experiment 2, where participants saw a brief preview of            absent scenes (where there was no target to find; t(71)=3.5,
the search scene, and also for Experiment 1, when                      p<.001). In other words, exposure to a brief glimpse of a
participants guessed (“eyes closed”) with only the target              scene made participants more likely to predict the same
identity to go on.                                                     location for an object, even when that object was not
                                                                       present. Figure 3 shows the expectation map for the target
                      Ceiling fan       Flower pot                     label “TV”, from responses in Experiment 1 (where
                                                                       participants made a blind guess) and for a target absent trial
 Response frequency
                                                                       in Experiment 2 (where participants saw the depicted
                                                                       preview scene which did not contain a TV). Participants
                                                                       responding in Experiment 2 changed their guesses
                                                                       considerably and focused on a spot where a TV might
                                                                       appear.
                      AUC = 0.89       AUC = 0.59
Figure 2: Expectation maps for two targets in Experiment 1.
 AUC scores represent the inter-observer agreement, which
  is high for one target (left) and much lower for the other
                             (right).
                                                                 332

                                                                       for 1s. This was replaced by a fixation point presented in the
                      TV - Eyes closed   TV - Eyes open
                                                                       centre of the screen and participants pressed a button to
                                                                       proceed with the search. At this time the eyetracker checked
 Response frequency
                                                                       that fixation was on the centre. The search scene then
                                                                       appeared, and participants were told to press one of two
                                                                       buttons as quickly and accurately as possible to identify
                                                                       whether or not the target was present in the scene. The
                                                                       search response terminated the trial, which ended with a
                                                                       blank screen for 500ms. All 72 trials were presented in the
Figure 3: Expectation maps for the target label “TV” when              same way, in a random order, and the eye-tracker was
guessing in Experiment 1 (left) and in Experiment 2 (right,            recalibrated at the halfway point.
  superimposed over the preview scene that was shown).
                                                                       Results
                              Experiment 3                             Search Performance Participants responded accurately on
                                                                       a mean of 89% of all trials. In correct, target-present trials,
Experiments 1 and 2 confirmed that people were consistent
                                                                       the mean reaction time was 1350ms (standard error of the
in their expectations about where a named target would be
                                                                       mean, SEM = 134) and participants made 5.5 fixations on
likely to appear in a real world scene. The target maps
                                                                       average, per trial (SEM = 0.4). As with most visual search
provide a simple way of representing these expectations.
                                                                       tasks, target absent trials were responded to more slowly (M
Experiment 3 tested whether the eye movements of a new
                                                                       = 2063ms, SEM = 237) and with more fixations per trial (M
group of observers could be predicted from the target
                                                                       = 7.9, SEM = 0.7). Figure 4 gives an example of the
guesses.
                                                                       locations fixated during a trial.
Method
Participants Eighteen new participants (12 females), who
                                                                                           TV - Search
had not taken part in Experiments 1 and 2, were recruited
for payment. All participants had normal or corrected-to-
normal vision, and their mean age was 22.5 years.
Stimuli and Apparatus The same set of target labels and
scenes was used as in the previous experiments. To avoid
trial-to-trial learning, each scene was presented once only,
with half of the scenes containing the target and half without
(i.e. matched with a different target label not present in the
scene as in Experiment 2). Across participants, each scene
appeared in both target-present and target-absent conditions.
   Stimuli were presented on a 19-inch monitor positioned
                                                                       Figure 4: The locations of fixations made by all participants
60cm from the observers. Participants rested on a chin-rest,
                                                                       searching for the target “TV” in a target-absent trial. White
which ensured a constant viewing distance and restricted
                                                                              markers indicate the first fixation in the trial.
head movements. Scene images filled the screen, subtending
33 x 26 degrees of visual angle at this viewing distance.
                                                                       Predicting Fixation Locations From Expectation Maps
   Eye movements were recorded during search using the
                                                                       The remaining analyses aimed to assess whether fixation
EyeLink 1000 system (SR Research), which used a desk-
                                                                       locations in the visual search task could be predicted based
mounted camera to record monocular eye position from a
                                                                       on the expectation maps derived from each target in
video image of the pupil and the corneal reflection. This
                                                                       Experiments 1 and 2. As previously, an ROC approach was
eye-tracker has a high spatial resolution (error of less than
                                                                       followed. For each target-scene pair, the analysis asked how
0.5 degrees on average) and captured eye position at
                                                                       well the expectation maps formed from guesses could
1000Hz. Samples were parsed into oculomotor events using
                                                                       discriminate between fixated and non-fixated locations.
the EyeLink system’s default algorithm, which identifies
                                                                       Because it was anticipated from theory and previous
saccades and fixations based on velocity and acceleration
                                                                       experiments that attentional priorities might change over
thresholds. Search responses were entered via a button box.
                                                                       time, separate ROC curves were computed from each
                                                                       participant’s first saccade target (i.e., the location of the first
Procedure The experiment began with an eye-tracker
                                                                       fixation away from the central starting point) and from all
calibration (using a nine-dot grid), followed by instructions
                                                                       fixations in the trial. It is also essential to take into account
and 8 practice trials. The experimental trials followed a
                                                                       the general tendencies for fixations (and probably mouse
standard visual search procedure. First, a target label was
                                                                       clicks) to be located near to the centre of the image and
presented, written in black font in the centre of the screen
                                                                       away from the scene edges.
                                                                 333

                   Table 2: Predicting fixation locations from the guessed locations in Experiments 1 and 2.
                                                              AUC (all saccades)                                               AUC (first saccade)
    Prediction                 Trial type
                                                             M                                       SD                     M                        SD
                            Target-present                  0.67                                    0.12                  0.71                      0.16
  Experiment 1:
                             Target-absent                  0.68                                    0.13                  0.73                      0.17
  “Eyes closed”
                         Between-trial control              0.62                                    0.05                  0.67                      0.05
                            Target-present                  0.82                                    0.12                  0.83                      0.13
  Experiment 2:
                             Target-absent                  0.76                                    0.11                  0.79                      0.10
   “Eyes open”
                         Between-trial control              0.64                                    0.07                  0.72                      0.11
Therefore, following Ehinger et al. (2009), I computed a                 considerable amount of inter-observer agreement in the
between-trial control comparison where the expectation map               expectation maps (e.g., compare the two maps in Figure 2).
for one target/scene was used to predict the fixations made              If these expectations are an important factor in real world
while searching for a different object.                                  search, then the inter-observer agreement should correlate
   Table 2 displays AUC summary statistics for the                       with reaction time in Experiment 3.
comparison between expectation maps and fixated                             The mean reaction time was calculated across all
locations. There were several noteworthy results. First, all             participants for each correct, target-present trial, and then
the AUC values are greater than 0.5, showing that fixation               correlated with the AUC values representing inter-observer
locations could be predicted on the basis of the mouse                   agreement from Experiments 1 and 2. In both cases there
responses made in Experiments 1 and 2. Moreover, in all                  was a negative correlation (see Figure 5). When participants
trial types, the observed AUC values are greater than the                were more consistent in their guesses about where an object
between-trial control estimate. This was statistically reliable          would appear, this object was found more quickly. The
across the different target/scene pairs (all t(71)>2.6, ps<.01)          correlation with “Eyes closed” guesses approached
and confirms that the results cannot be attributed to general            significance (r=-.21, p=.08), while the correlation with
spatial biases.                                                          “Eyes open” guesses was larger and statistically reliable
   In addition, both expectation models were better                      (r=.50, p<.001).
predictors of the first saccade in a trial than they were of all
saccades. This may be because the initial saccade was most
likely to move toward the expected location, whereas later
saccades might be exploring different areas of the picture.
                                                                                                                 Eyes closed      Eyes open
However, the between-trial control also led to higher AUC
                                                                                            4000
values when only the first saccade was evaluated, so it
seems the first saccade is more predictable in general. This                                3500
might be because of a strong central bias in scene viewing
which tends to decrease over time, particularly when                                        3000
viewing starts in the centre (as it did here).                                              2500
                                                                             Mean RT (ms)
   Most importantly, the guesses made by participants who
saw a brief preview of the scene (“Eyes open”) were a                                       2000
significantly better predictor of fixation locations than those
                                                                                            1500
who guessed blindly without seeing the scene. The best
performance came in target-present trials, which indicates                                  1000
that participants in Experiment 2 had seen the target at least
                                                                                             500
some of the time when guessing. Searchers in Experiment 3
were obviously highly likely to look at this correct target                                    0
location, whereas there was more variability in target-absent                                      0.5     0.6             0.7          0.8         0.9    1
                                                                                                                   Inter-observer agreement (AUC)
images. However, it is important to note that, even when
there was no target, the “Eyes closed” guesses of an
independent group of participants were a significant                     Figure 5: The correlation between inter-observer agreement
predictor of fixation.                                                    and search RT. Each data point represents a target/scene
                                                                         pair from Experiments 1 or 2, with least-squares regression
Predicting Between-target Variation An additional                                                   lines.
question concerns the relationship between expectations and
search performance. If target objects are strongly associated
with a particular location then we would expect a
                                                                   334

                          Discussion                               such as those in the contextual guidance model of Torralba
                                                                   et al., (2006).
In this paper I have proposed a distinction between the
different types of top-down information available in guiding
search in real-world scenes. Unlike previous descriptions of                                References
contextual effects (Biederman et al., 1973; Torralba et al.,
2006), I specifically emphasized the fact that some                Biederman, I., Glass, A. L., & Stacy, E. W. (1973).
predictions based on semantic knowledge can be made prior             Searching for objects in real-world scenes. Journal of
to the onset of the search scene. There were several                  Experimental Psychology, 97, 22–27.
interesting findings, which point to promising future              Chen, X., & Zelinsky, G. J. (2006). Real-world visual
directions for this approach.                                         search is dominated by top-down guidance. Vision
   First, participants showed a reliable amount of agreement          Research, 46(24), 4118-4133.
when asked to blindly guess the target location. Although          Ehinger, K. A., Hidalgo-Sotelo, B., Torralba, A., & Oliva,
participants initially found this task unusual they were able         A. (2009). Modeling search for people in 900 scenes: A
to do so quickly and often chose the same locations for an            combined source model of eye guidance. Visual
object. There was some variation between different objects,           Cognition, 17, 945-978.
with objects showing the largest amount of agreement those         Foulsham, T., & Underwood, G. (2007). How does the
which are strongly constrained to spatial locations (such as          purpose of inspection influence the potency of visual
light fittings). The method described here could be used in           saliency in scene perception? Perception, 36, 1123-1138.
further research to characterise different search objects and      Foulsham, T., Alan, R. & Kingstone, A. (2011). Scrambled
their effects on performance. It should be noted that,                eyes? Disrupting scene structure impedes focal processing
because the present studies were limited to a fixed image             and increases bottom-up guidance. Attention, Perception
frame on a monitor it mainly measured knowledge about                 and Psychophysics, 73 (7), 2008-2025.
picture composition (e.g., where the horizon is likely to be       Foulsham, T., Walker, E. & Kingstone, A. (2011). The
in a scene). How participants use such information in real            where, what and when of gaze allocation in the lab and
life, where frames of reference change with head and body             the natural environment. Vision Research, 51 (17), 1920-
position, remains an open question and could be explored by           1931.
looking at attention in active, real-world environments (see       Henderson, J. M., Weeks, P. A., & Hollingworth, A. (1999).
Foulsham, Walker & Kingstone, 2011).                                  The effects of semantic consistency on eye movements
   Second, “Eyes closed” predictions were at least partly             during complex scene viewing. Journal Of Experimental
separable from those made in response to a preview of the             Psychology: Human Perception & Performance, 25, 210–
scene. A brief preview of the scene gist, prior to seeing the         228.
target label, was enough to increase agreement between             Itti, L., & Koch, C. (2000). A saliency-based search
observers, even when there was no target to find. In other            mechanism for overt and covert shifts of visual attention.
words, additional information about the scene was used by             Vision Research, 40(10-12), 1489-1506.
participants in a consistent way. It would be interesting to       Kanan, C., Tong, M. H., Zhang, L., & Cottrell, G. W.
determine some of the cues that participants are responding           (2009). SUN: Top-down saliency using natural statistics.
to in this situation, as they could potentially be both               Visual Cognition, 17, 979-1003.
appearance-based (selecting something which looked like            Navalpakkam, V., & Itti, L. (2005). Modeling the influence
the target) and location-based (selecting a region where the          of task on attention. Vision Research, 45(2), 205-231.
target might reasonably occur).                                    Peirce, JW (2007) PsychoPy - Psychophysics software in
   Third, the guesses of the participants in Experiments 1            Python. Journal of Neuroscience Methods, 162(1-2), 8-
and 2 were reliable predictors of fixation locations in               13.
independent searchers in Experiment 3. This was true when          Torralba, A., Oliva, A., Castelhano, M. S., & Henderson, J.
participants guessed based on a brief preview of the scene,           M. (2006). Contextual guidance of eye movements and
which confirms that searchers look towards the parts of the           attention in real-world scenes: The role of global features
scene which are contextually relevant given the gist. This            in object search. Psychological Review, 113(4), 766-786.
finding, in both target-present and target-absent scenes, is       Wolfe, J. M. (1994). Guided Search 2.0: A revised model of
similar to that reported by Ehinger et al. (2009), who used a         visual search. Psychonomic Bulletin and Review, 1, 202-
“context oracle” defined by the responses of independent              228.
observers predicting the y-coordinate where pedestrians            Wolfe, J. M. (1998). What can 1 million trials tell us about
should occur in street scenes. However, what is surprising in         visual search? Psychological Science, 9(1), 33-39.
the current experiments is that, even without the scene,           Zelinsky, G. J. (2008). A Theory of Eye Movements During
participants are able to predict target locations, and these          Target Acquisition. Psychological Review, 115(4), 787-
predictions are reflected in fixation behavior. In future work        835.
this could be modeled by positing a “blind” statistical prior
which could then be refined according to global features
                                                               335

