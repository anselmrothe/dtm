UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Children's Inferences in Generalizing Novel Nouns and Adjectives
Permalink
https://escholarship.org/uc/item/1rz1x81b
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Gagliardi, Annie
Bennett, Erin
Lidz, Jeffrey
et al.
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

               Children’s Inferences in Generalizing Novel Nouns and Adjectives
                                                 Annie Gagliardi (acg39@umd.edu)
                                                 Erin Bennett (ebennet2@umd.edu)
                                                     Jeffrey Lidz (jlidz@umd.edu)
                                                 Naomi H. Feldman (nhf@umd.edu)
                          Department of Linguistics, University of Maryland, College Park, MD 20742 USA
                               Abstract                                 (2) it largely limits the model to the discussion of object la-
                                                                        bel learning, as this is the domain that primarily uses the kind
   By the time children begin to rapidly acquire new word mean-
   ings they are already able to determine the grammatical cat-         hierarchy.
   egory of novel words based on syntactic and morphological               In this paper we probe the predictions of the Bayesian
   cues. Here we test whether children can leverage this knowl-         model on different grammatical categories, nouns and adjec-
   edge when inferring the meaning of a novel word. Through
   a novel word learning experiment we determine that children          tives, which tend to draw from different concept hierarchies.
   can use this information, drawing different conclusions for the      This allows us to better test the role of the prior probabil-
   most likely meanings of novel words in distinct grammatical          ity of a concept given a grammatical category by letting us
   categories. We use a Bayesian model to formalize the higher
   level knowledge that children might have about noun and ad-          examine the link between grammatical category and concept
   jective meanings. Simulations show that children’s behavior          hierarchy. Toward these goals we conducted a word learn-
   reflects the type of shift we would predict on the basis of noun     ing experiment that replicates Xu and Tenenbaum’s finding
   and adjective meanings in the English lexicon.
                                                                        with learning novel nouns, and extends the paradigm to novel
   Keywords: language acquisition; word learning; Bayesian in-          adjective learning. We find that children use the grammatical
   ference
                                                                        category of the novel word to constrain their hypotheses about
   One of the most striking phenomena in language acquisi-              the meaning of the novel word. This is demonstrated through
tion is children’s ability to rapidly learn the meanings of novel       their sensitivity to the suspicious coincidence in the distribu-
words with only limited exposure. How exactly children do               tion of exemplars on the kind hierarchy when learning nouns
this has been researched extensively, with three lines of in-           but not adjectives. A Bayesian model that takes into account
quiry dominating the attempts to formalize this process: hy-            not only conceptual similarity but also the link between gram-
pothesis elimination (Berwick, 1963; Pinker, 1989; Siskind,             matical category and concept matches the qualitative shift be-
1996), associative learning (Colunga & Smith, 2005; Regier,             tween nouns and adjectives seen in the children’s data. The
2005) and Bayesian inference (Xu & Tenenbaum, 2007). Xu                 model’s ability to capture this shift highlights the crucial role
and Tenenbaum argue that Bayesian inference is superior to              that children’s prior beliefs contribute to their generalizations
hypothesis elimination and associative learning because it              in word learning. Through this work we extend the Bayesian
uniquely allows the learner to take advantage of ‘suspicious            model of word learning in ways that make it more realistic
coincidences’ when learning words for overlapping concepts.             with respect to both the structure of natural language and the
For example, in a word learning experiment they found that              task faced by a child acquiring novel words.
when children were shown three Dalmatians labeled with a                   Our paper is organized as follows. We first present our
novel object label, there was a strong bias for children to think       word learning experiment. We then use a Bayesian model
that the novel word meant Dalmatian, rather than dog, or ani-           to formalize children’s prior distribution over concepts. The
mal. This bias was not as strong when children only saw one             next section presents simulations comparing the model to
Dalmatian labeled with the novel label. Neither hypothesis              children’s behavior. We conclude by discussing the implica-
elimination nor associative learning predict the effect of the          tions that this work has for language acquisition, in particular
suspicious coincidence that results from the narrow distribu-           the importance of considering how a learner’s prior knowl-
tion of exemplars on the kind hierarchy (which is in turn con-          edge affects the way in which the data from the environment
tingent on the number of exemplars). Xu and Tenenbaum’s                 are used in language acquisition.
model does predict this effect, via the likelihood term, which
takes into account both the number of exemplars and the size                          Word Learning Experiment
of the hypothesis.                                                      In a novel word learning experiment children were presented
   One key assumption that Xu and Tenenbaum relied on was               with an array of animals and vehicles and taught a novel label
that the candidate concepts fell on a hierarchy of kinds. That          (noun or adjective) for a concept. Children were then asked to
is, in their model the learner does not have to determine what          generalize their inferred concept to novel items. The stimuli
domain to generalize across, as this domain was given by                allowed generalization along both kind and property dimen-
the kind hierarchy. This assumption has two implications                sions. If children are able to use syntactic information to con-
for their model: (1) most of the work in hypothesis selec-              strain their inference of words’ meanings, then we should ex-
tion is being done by the likelihood, as the prior probability          pect them to generalize differently when learning nouns ver-
of each hypothesis is comparatively much less variable and              sus adjectives.
                                                                    354

                                                                        Speaker           Utterance              Action
                                                                        Snail             ‘This is a blicky      points to striped
                                                                                          one’                   Dachshund 1
                                                                        Snail             ‘Look, another         points to striped
                                                                                          blicky one’            Dachshund 2
                                                                        Snail             ‘Here’s another        points to striped
                                                                                          blicky one’            Dachshund 3
                                                                        Snail             ‘I’m going to go       retreats to shell
                                                                                          have a rest’
                                                                        Experimenter      ‘Here are some         lays    out new
                                                                                          more      pictures.    array  of pictures
                                                                                          Can you put            and    gives the
                                                                                          circles on all         child   a set of
                                                                                          the blicky ones        rings
                                                                                          to surprise the
Figure 1: The stimuli for our experiment included 36 objects                              snail?’
in subordinate, basic, and superordinate vehicle and animal             Child             —                      puts rings on
categories. Half the items were striped and half spotted.                                                        items that match
                                                                                                                 child’s hypoth-
                                                                                                                 esis     for    the
Methods                                                                                                          meaning of blicky
Our experiment tested two groups of children using a between         Table 1: Sample adjective trial. Noun trials were identical
subjects design. The noun group learned two novel nouns,             with blick substituted for blicky one.
and the adjective group learned two novel adjectives.
Participants Participants were 24 children (mean                     level categories (e.g., a striped dachshund). In the noun con-
age = 4;0, range = 3;6-5;0) recruited from the greater               dition he described it as a blick, and in the adjective condition
College Park area as well as an on campus preschool.                 he described it as a blicky one. This happened 3 times, with
Children either visited the lab with their parents or were           the snail pointing to a different striped dachshund each time.
visited by researchers at their preschool. Four children were        Then the snail would get tired and retire to his shell for a nap.
excluded from the final analysis for the following reasons.
                                                                        While the snail slept, the experimenter initiated the test
One was too shy to interact with the snail and three said
                                                                     phase, during which the child was presented with another ar-
they didn’t know when they were asked to perform the
                                                                     ray of pictures and asked to place circles on the other blicks
generalization task outlined below.
                                                                     (noun condition) or blicky ones (adjective condition). A sin-
Stimuli All children were presented with an array of pic-            gle trial is schematized in Table 1. The entire procedure was
tures (Figure 1) that included 36 items from two superordi-          repeated for a second novel word used to describe another
nate categories on the kind hierarchy (18 vehicles and 18 an-        item from a different subordinate level (e.g., a spotted taxi).
imals). Each category had items from several basic levels            Order of item (dog before vehicle or vice versa), described
(animals: 12 dogs, 2 cats, 2 squirrels, 2 owls; vehicles: 12         subordinate level item (dachshund vs yorkie and taxi vs po-
roofed cars, 2 convertibles, 2 vans, 2 trucks). One basic level      lice car), and described pattern order (striped before spotted
from each superordinate category had items from two subor-           and vice versa) were counterbalanced across subjects.
dinate level categories (dogs: 6 Dachshunds and 6 Yorkshire
terriers, roofed cars: 6 taxis and 6 police cars). There were        Results
both striped and spotted items of each item type.
                                                                     Each item presented during the word learning phase was con-
Procedure A snail puppet was introduced to the child, and            sistent with seven candidate concepts (illustrated in Table 2),
the child was told that the snail spoke a funny snail lan-           picking from the kind hierarchy, property hierarchy or com-
guage that was mostly like English but included some new             bining concepts from both. For data analysis, children’s hy-
words. The experimenter explained that they would try to             potheses were collapsed depending where the generalization
figure out the snail’s words by listening to him talk about          fell on the kind hierarchy. Children’s choices were coded
some of the pictures. Before proceeding further, the exper-          as follows, with one response recorded per trial. Subordi-
imenter checked that both the snail and the child could see          nate responses were recorded if children chose only items
all of the pictures in the array. This ensured that participants     from the same subordinate level as the example (e.g., only
were aware of the range of items in the experimental world.          dachshunds after being presented with dachshunds). Basic
   During the word learning phase the snail looked at the            responses were recorded if children chose from only the ba-
pictures and pointed out an item from one of the subordinate         sic level (e.g. either dog type after being presented with
                                                                 355

        Hypothesis             Dimension              Level            to determine whether children are behaving optimally with
        Dachshund                  Kind           subordinate          respect to a specific hypothesis space (conditioned by gram-
            Dog                    Kind                basic           matical category and the information available to them in the
          Animal                   Kind          superordinate         English lexicon), we used a Bayesian model to predict gen-
          Striped                Property             neutral          eralization behavior from the nouns and adjectives that are
  Striped ∧ Dachshund        Property ∧ Kind      subordinate          likely to be present in the children’s early lexicons.
      Striped ∧ Dog          Property ∧ Kind           basic
    Striped ∧ Animal         Property ∧ Kind     superordinate                                        Model
                                                                       We assume the generative model shown in Figure 3(a). Our
Table 2: Candidate concepts, given three exemplars of striped          model assumes that the snail in our experiment, having cho-
Dachshunds.                                                            sen a grammatical category for the word he will teach the
                                                                       children, chooses a concept to teach (such as dog, striped, or
dachshunds) or from the basic and subordinate levels. A                dachshund), and then independently chooses three objects as
superordinate response was recorded if children chose only             examples of that concept.
from the superordinate level (e.g., any animal after being                The children in our experiment inferred what concept a
presented with dachshunds) or from the superordinate level             new word referred to based on the grammatical category of
with any combination of the lower levels. Finally, neutral re-         the novel word (noun or adjective) and the objects the snail
sponses were recorded if children chose from anywhere on               identified as examples of that word. Our model therefore
the kind hierarchy (e.g., anything from the vehicle hierarchy          computes the probability of each concept C for a given gram-
after being shown a dachshund). All items chosen by chil-              matical category P and set of objects X,
dren with neutral responses were consistent with the property
(either striped or spotted) that they had been taught.                                               P(C|X, P)                        (1)
   Results are shown in Figure 2(a). In the noun condi-
                                                                          We can use Bayes’ rule to compute the posterior probabil-
tion, we replicated Xu & Tenenbaum’s finding, uncovering
                                                                       ity over concepts given a set of examples and a word’s gram-
a bias for the subordinate level meaning when all observa-
                                                                       matical category,
tions fall into the same subordinate level. In the adjective
condition, however, we see a different pattern. The place-                                              P(X|Ci ) · P(Ci |P)
ment of the item on the kind hierarchy had no bearing on                      P(Ci |X, P) =                                           (2)
                                                                                                       ∑        P(X|C j ) · P(C j |P)
children’s choices, with the overwhelming majority choosing
                                                                                             C j ∈{all concepts}
the neutral interpretation, indicating their belief that the novel
adjective’s meaning referred just to the most salient property         We assume that the probability of the data X depends only
(striped versus spotted) rather than the kind. Planned compar-         on the concept C and is independent of the grammatical cat-
isons revealed that the proportion of trials that children chose       egory, given the concept. Since the normalizing constant in
the subordinate and neutral meanings differed significantly            the denominator will be the same for all candidate concepts,
by condition (subordinate: t(33) = 3.49, p < 0.002, neutral:           we only need to find the values of P(X|Ci ) and P(Ci |P) for
t(26) = 3.39, p < 0.003).                                              the concepts we are considering.
Discussion                                                             Concept Prior: P(C|P)
These results demonstrate that children use their knowledge            Following Goodman, Tenenbaum, Feldman and Griffiths
of grammatical categories, and the associated kinds of mean-           (2008) (cf. Austerweil & Griffiths, 2010), we represent
ings that correlate with these categories, when inferring the          concepts according to the concept grammar in Figure 3(b),
meanings of novel words. In particular, they favor concepts            with nonterminal nodes Kind and Property representing the
from a kind hierarchy for novel nouns, and from a property             dimensions a concept is defined along. Words like dog
hierarchy for novel adjectives. In one respect this result is not      and striped are defined along only one of these dimensions
new, as infants as young as 14 months have been shown to               (Kind and Property, respectively). Words like kitten, which
know the mapping between grammatical and conceptual cat-               describes a young cat, are defined along both dimensions
egories (Waxman & Markow, 1998; Booth & Waxman, 2003,                  (Kind ∧ Property). The derivation of each concept involves
2009). Instead, the novelty is in showing that this mapping            first applying a rule determining the dimension of the concept
constrains children’s inferences. A very low prior probability         and then applying the dimension-specific rules until all termi-
for a hypothesis on the kind hierarchy blocks it from being            nal nodes have been identified. For example, in our concept
determined the most likely for a novel adjective meaning, de-          language, the concept dog is formed by first applying the rule
spite it being the narrowest possible hypothesis.                      Concept → Kind and then applying the rule Kind → dog.
   This finding emphasizes the role of the hypothesis space,              If we assign probabilities to each of the rules in this concept
since the most likely hypothesis differs depending on the              grammar and assume that the rules are applied independently
grammatical category of the word being learned. In order               of one another, then the resulting PCFG will determine the
                                                                   356

   (a)
                                                  Experimental Results                                               (b)                                                       Model Results
                         1.0                                                                                                                               1.0
                                                                                                                     Posterior Probability of Hypothesis
                         0.8                                                                                                                               0.8
  Proportion of Trials
                         0.6                                                                                                                               0.6
                                                                                                Condition                                                                                                              Condition
                                                                                                       Noun                                                                                                                   Noun
                         0.4                                                                        Adjective                                              0.4                                                             Adjective
                         0.2                                                                                                                               0.2
                         0.0                                                                                                                               0.0
                                   Subordinate          Basic      Superordinate      Neutral                                                                    Subordinate      Basic     Superordinate    Neutral
                                                          Hypothesis                                                                                                                Hypothesis
                                                        Figure 2: (a) Results of word learning experiment and (b) results of modeling.
  (a)                                            (b)     Concept         →         Kind                                                                                           Kind      Property        Both
                                                                         →         Property                                                                        Noun           335           4            24
                               P                                         →         Kind ∧ Property                                                                Adjective        3           61             2
                                                                Kind     →         animal                         Table 3: Average counts (rounded) from 22 participants’ rat-
                                                                         →         dog                            ings of nouns and adjectives as descriptions of kinds, proper-
                                                                         →         dachshund                      ties, or both.
                           C                                             →         ···
                                                                         →         vehicle                        the counts pdi ,P of the productions seen by the learner of a
                                                                         →         car                            particular dimension di for that grammatical category P is
                                                                         →         taxi
                           X                                                                                                                                                                 pdi ,P + 1
                                                                                                                                                                     P(di |P) =                                            (4)
                                                         Property        →         spotted                                                                                                ∑ pd j ,P + 3
                                                                         →         striped                                                                                         d j ∈{all dims}
Figure 3: (a) Grammatical categories P determine the param-                                                          We approximated these production counts from a Mechan-
eters for our prior over concepts C. Specific objects X are                                                       ical Turk survey where for each word in a vocabulary list of
sampled from the set of items that exemplify a concept. (b) A                                                     429 words (363 nouns and 66 adjectives) that 30-month-old
probabilistic context-free grammar for concepts. Probabili-                                                       children likely know (Dale & Fenson, 1996), we asked adult
ties for each expansion rule are discussed in the Concept Prior                                                   English speaking participants to judge whether the word was
section.                                                                                                          best described as a kind, a property, or both. Different but
                                                                                                                  often overlapping sets of 10 people were asked to respond to
                                                                                                                  each word, and so we had a total of 22 participants in our
probabilities of all the concepts in our experiment. The prob-                                                    study. Two participants’ judgments were excluded due to an
ability of each concept would be the product of the probabil-                                                     extraordinarily high proportion of Both responses (proportion
ities of the rules applied to form it,                                                                            Both > 0.36, over two standard deviations outside the mean
                                                                                                                  proportion of Both responses). While the children in our ex-
                                        P(C) =                    ∏                P(R)              (3)
                                                                                                                  periment (3-5 year-olds) were much older than 30 months,
                                                       R∈{rules   to form C}
                                                                                                                  we believe that this vocabulary list is appropriate for our pur-
   The differences in the types of concepts denoted by nouns                                                      poses, since the children in our experiments are almost cer-
and adjectives are represented in our model through differ-                                                       tainly familiar with these words and differ only in additional
ences in the probability distributions over the set of rules that                                                 words they might know. We assume that the distribution of
expand Concept to particular dimensions. We assume chil-                                                          noun and adjective dimensions in this set of words is repre-
dren are computing this prior distribution separately for each                                                    sentative of that of the larger and more varied set of words that
part of speech, keeping track of the number of nouns or ad-                                                       our participants are familiar with. Table 3 shows the average
jectives whose meanings denote a kind, a property, or both a                                                      counts of each description for each grammatical category.
kind and a property. They can estimate the rule probabilities                                                        For kinds, we assume a structure like Xu and Tenenbaum
from these counts using a Dirichlet-multinomial model. Un-                                                        (2007) where the probability of a concept depends on its dis-
der this model, the prior over dimension expansions based on                                                      tinctiveness. For these measures we use a hierarchical cluster
                                                                                                            357

                                                                                                           pKind,Noun + 1
                                                                             P(Kind|Noun) =
                                                                                                           ∑              pd,Noun + 3
                                                                                                 d∈{Kind, Property, Both}               (7)
                                                      animals
                                                                                                 335 + 1
                                                                                              =           = 0.92
                                                                                                 363 + 3
                            vehicles
                       cars                     dogs
                                                                          Then we find the probability of the concept being
                                                                       Dachshund given that it is defined only along the Kind di-
                                                                       mension, using the height of the branch Dachshund and
                     taxis
                                                                       its immediate parent dog. These heights were 0.1259 and
         police cars                   dachshunds yorkshires
                                                                       0.3115, respectively.
Figure 4: Hierarchical clustering of experimental item simi-                                       height(parent(dog)) − height(dog)
                                                                        P(dachshund|Kind) =
larity.                                                                                             ∑ height(parent(C) − height(C)
                                                                                                   C∈K
                                                                                                   0.1856
tree, shown in Figure 4. To make this tree, we conducted                                        =           = 0.1056
a similarity judgment study, similar to Xu and Tenenbaum’s                                         1.7576
                                                                                                                                        (8)
using the items that the snail had labeled in our experiment.
Our participants, 26 students from the University of Mary-                Finally, to compute the prior probability of the concept
land who received course credit for their participation, rated         Dachshund given that it is a noun, we multiply the proba-
the similarity of all possible pairs of the 36 pictures on a scale     bility of expanding Concept to Kind by the probability of the
from 1 (not similar at all) to 9 (very similar).                       concept being Dachshund.
   To incorporate cluster distinctiveness, Xu and Tenenbaum
measure the branch length (which represents the Euclidean
distance) between the concept node and its parent node. By             P(Dachshund|Noun) = P(Kind|Noun) · P(Dachshund|Kind)
this measure, the further a particular node is from its parent,                                 = 0.92 · 0.1056 = 0.09715
the more distinct it is considered to be. Where K is the set                                                                            (9)
of all Kind concepts, the probability of a concept Ci given
that it is defined over the Kind dimension is the branch length        Concept Likelihood: P(X|C)
normed over all Kind concepts,                                         We assume that, given a set of objects that are examples of a
                                                                       concept C, each object is equally likely to be chosen by the
                                                                       snail.1 Therefore, the probability of the data given a concept
                           height(parent(Ci )) − height(Ci )
   P(Ci |Kind) =                                               (5)     is proportional to the size of the set of things matching that
                        ∑ height(parent(C j )) − height(C j )          concept. For example, for the concept dog, the probability
                      C j ∈K
                                                                       of picking a particular dog, Fido, is inversely proportional to
                                                                       the number of dogs there are in the scene. So if n objects
   For properties, we assume that in our experiment they are
                                                                       are chosen by the snail as examples of a concept C, and these
chosen from a multinomial distribution with each property
                                                                       objects are plausible examples of the concept,
equally likely to be selected. Since there were only two very
                                                                                                            n
salient properties in our experiment, we give each property                                                    1
the probability of 21 ,                                                                        P(X|C) =                                (10)
                                                                                                              |C|
                                              1                                                   Simulations
                            P(C|Property) =                    (6)
                                              2                        For each experimental trial we computed the posterior proba-
Example Derivation of a Concept Prior Under this model                 bility over concepts using both the noun and adjective priors.
of the concept prior, the prior probability that the noun blick        We assumed that on each trial children were sampling a con-
refers to the concept Dachshund will have the following                cept from the posterior distribution over concepts given the
derivation. First, we have production counts for nouns that                1 Xu and Tenenbaum use a different estimate of category sizes for
describe kinds pKind,Noun that were found in our Mechanical            kinds, which is based on the same heirarchy as their concept prior.
Turk study (we found that on average 335 out of 363 nouns              We found little difference when we compared the our own likelihood
were categorized as kinds). From this production count and             distributions with those computed by Xu and Tenenbaum’s methods
                                                                       on our experimental items. A very similar ordering applied over
the total production counts for nouns, we derive the probabil-         concepts, and each item was on the same order of magnitude for
ity of expanding Concept to Kind.                                      both measures of the likelihood.
                                                                   358

grammatical category of the novel word. Thus the posterior          ical categories in the children’s own lexicons, there are obvi-
probability over concepts as generated by the model should          ous extensions of this work to modeling the infant word learn-
give us the frequency with which a child should show any            ing by weakening (or making nonexistent or unavailable) the
given behavior. In order to be able to compare the model to         link between between grammatical category and concept hi-
the experimental data, we sorted the concepts into the same         erarchy. There are several findings that would be interesting
categories that we used for analyzing the experimental data:        to model this way, including (1) that 11-month-olds make the
subordinate, basic, superordinate and neutral. The candidate        same generalizations for words presented as nouns and adjec-
concepts for striped Dachshund, along with the levels they          tives and these generalizations are neutral with respect to kind
mapped on to, are found in Table 2 (in the Results section of       vs. property meanings (Waxman & Booth, 2003), or (2) that
the Word Learning Experiment, above).                               the noun-kind link is established earlier than the adj-property
    The results of our model are shown in Figure 2(b). Overall      link (Booth & Waxman, 2003, 2009). Finally, we can ask
the model captures the qualitative shift seen between noun          to what degree a group of exemplars’ distribution on a given
and adjective generalization in the experimental results, with      concept hierarchy is used in acquiring linguistic phenomena
a much higher posterior probability for the subordinate level       that extend beyond word meanings (e.g., word classes).
given a noun, and a shift of a large part of the probability to     Acknowledgments. This research was supported by NSF IGERT
the neutral level given an adjective.                               0801465, a NSF GRF to Gagliardi, and a Baggett Fellowship to
                                                                    Bennett. We would like to thank the UMD Cognitive Neuroscience
                          Discussion                                of Language Lab, the UMD Project on Childrens Language Learn-
In this paper we have shown that while children tend to map         ing and the UMD Computational Psycholinguistics group for helpful
novel nouns onto a kind hierarchy, they prefer to map novel         discussion and assistance.
adjectives onto a property hierarchy. This behavior is pre-
dicted if children use their knowledge of grammatical cate-                                      References
gories and the distributions of different concept types within      Austerweil, J. L., & Griffiths, T. L. (2010). Learning hypothesis
                                                                       spaces and dimensions through concept learning. In S. Ohlsson
these categories to constrain the space of hypothesized mean-          & R. Catrambone (Eds.), Proceedings of the 32nd Annual Con-
ings when learning novel words. A Bayesian model trained               ference of the Cognitive Science Society (pp. 73–78). Austin, TX:
on the distribution of concepts across grammatical categories          Cognitive Science Society.
                                                                    Berwick, R. C. (1963). Learning from positive-only examples:
in the English lexicon predicts a qualitatively similar gener-         The subset principle and three case studies. In J. G. Carbonell,
alization pattern. Together these results suggest that not only        R. S. Michalski, & T. M. Mitchell (Eds.), Machine learning: An
are children able to use what they know about grammatical              artificial intelligence approach (vol. 2). Los Altos, CA: Morgan
                                                                       Kaufmann.
categories when inferring the meanings of novel words, the          Booth, A. E., & Waxman, S. R. (2003). Mapping words to the world
way they do this is predicted by the distributions of concept          in infancy: Infants’ expectations for count nouns and adjectives.
types across grammatical categories in English. Moreover,              Journal of Cognition & Development, 4, 357–381.
                                                                    Booth, A. E., & Waxman, S. R. (2009). A horse of a different color:
the constraints imposed on inference by grammatical cate-              Specifying with precision infants’ mappings of novel nouns and
gory are powerful enough to overcome much of the effect of             adjectives. Child Development, 80(1), 15–22.
the size principle on the likelihood.                               Colunga, E., & Smith, L. B. (2005). From the lexicon to expecta-
                                                                       tions about kinds: A role for associative learning. Psychological
    These findings have several implications for language ac-          Review, 112, 347–382.
quisition and models of language acquisition. First, while the      Dale, P., & Fenson, L. (1996). Lexical development norms for young
‘size principle’ has received considerable attention as a so-          children. Behavior Research Methods, Instruments, & Comput-
                                                                       ers, 28, 125–127.
lution to the word learning problem, this work demonstrates         Goodman, N. D., Tenenbaum, J. B., Feldman, J., & Griffiths, T. L.
that the beliefs children bring to the word learning task also         (2008). A rational analysis of rule-based concept learning. Cog-
play a key role in word learning. Second, while a model                nitive Science, 32, 108–154.
                                                                    Hudson-Kam, C. L., & Newport, E. L. (2009). Getting it right
based on priors derived from the lexicon captured the shift we         by getting it wrong: When learners change languages. Cognitive
see between noun adjective generalizations, it does not per-           Psychology, 59, 30–66.
fectly predict children’s behavior. Future research will probe      Pinker, S. (1989). Learnability and cognition: The acquisition of
                                                                       argument structure. Cambridge, MA: MIT Press.
whether this can be explained by making a closer approxima-         Regier, T. (2005). The emergence of words: Attentional learning in
tion of the child’s lexicon (as our Mechanical Turk task may           form and meaning. Cognitive Science, 29, 819–865.
have overestimated the number of both concepts), or whether         Siskind, J. M. (1996). A computational study of cross-situational
                                                                       techniques for learning word-to-meaning mappings. Cognition,
it stems from the learner’s tendency to amplify biases that ex-        61, 39–91.
ist in the input (e.g. Hudson-Kam & Newport, 2009). Third,          Waxman, S. R., & Booth, A. E. (2003). The origins and evolution
we can ask how children behave with respect to concept hi-             of links between word learning and conceptual organization: New
                                                                       evidence from 11-month-olds. Developmental Science, 6(2), 130–
erarchies in languages that collapse the distinction between           137.
nouns and adjectives (e.g., Georgian). Does the size prin-          Waxman, S. R., & Markow, D. B. (1998). Object properties and ob-
ciple play a role only to the extent that nouns are likely to          ject kind: Twenty-one-month-old infants extension of novel ad-
                                                                       jectives. Child Development, 69, 1313–1329.
draw from the kind hierarchy? Next, as these beliefs are at-        Xu, F., & Tenenbaum, J. B. (2007). Word learning as Bayesian
tributable to the distribution of concept types across grammat-        inference. Psychological Review, 114(2), 245–272.
                                                                359

