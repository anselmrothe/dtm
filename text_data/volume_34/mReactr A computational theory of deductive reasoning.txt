UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
mReactr: A computational theory of deductive reasoning
Permalink
https://escholarship.org/uc/item/06r974dg
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Khemlani, Sangeet
Trafton, Greg
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                       mReactr: A computational theory of deductive reasoning
                                                Sangeet Khemlani and J. Gregory Trafton
                                         khemlani@aic.nrl.navy.mil, trafton@itd.nrl.navy.mil
                                     Navy Center for Applied Research in Artificial Intelligence
                                      Naval Research Laboratory, Washington, DC 20375 USA
                             Abstract                                 simulations, or mental models, is the fundamental intuition
   The mReactr system is a computational implementation of the
                                                                      behind the mental model theory of reasoning (Johnson-
   mental model theory of reasoning (Johnson-Laird, 1983) that        Laird, 1983). In the present paper, we outline the theory and
   is embedded within the ACT-R cognitive architecture                address one of its major limitations, namely its inability to
   (Anderson, 1990). We show how the memory-handling                  explain how models are stored and manipulated in memory.
   mechanisms of the architecture can be leveraged to store and       We describe a computational implementation of the theory
   handle discrete representations of possibilities, i.e., mental     that is embedded within the ACT-R cognitive architecture
   models, efficiently. Namely, the iconic representation of a        (Anderson, Bothell, Byrne, Douglass, Lebiere, & Qin,
   mental model can be distributed, in which each component of
   a model is represented by a “chunk” in ACT-R’s declarative         2004), and we show how the memory-handling mechanisms
   memory. Those chunks can be merged to create minimal               of the architecture can be leveraged to store and handle
   mental models, i.e., reduced representations that do not           mental models efficiently.
   contain redundant information. Minimal models can then be
   modified and inspected rapidly.                                                 Reasoning and mental models
      We describe three separate versions of the mReactr
   software that minimize models at different stages of the              The “model” theory of reasoning proposes that when
   system’s inferential processes. Only one of the versions           individuals comprehend discourse, they construct mental
   provides an acceptable model of data from an immediate             models of the possibilities consistent with the meaning of
   inference task. The resulting system suggests that reasoners       the discourse (Johnson-Laird, 2006). The theory depends on
   minimize mental models only when they initiate deliberative        three main principles: 1) Individuals use a representation of
   mental processes such as a search for alternative models.
                                                                      the meaning of a premise and their knowledge to construct
   Keywords: reasoning, mental models, immediate inferences,          mental models of the various possibilities to which the
   mReactr, ACT-R                                                     premises refer. 2) The structure of a model corresponds to
                                                                      the structure of what it represents (see Peirce, 1931-1958,
                         Introduction                                 Vol. 4), and so mental models are iconic insofar as possible.
   People regularly make complex deductive inferences. For            3) The more models a reasoner has to keep in mind, the
instance, if you know that none of the lawyers in the room            harder an inference is. On a model-based account, a
are men, you might refrain from asking any of the men in              conclusion is necessary if it holds in all the models of the
the room for legal advice. If so, you have made an                    premises and possible if it holds in at least one model of the
“immediate” inference from a single premise:                          premises.
                                                                         mReasoner (Khemlani, Lotstein, & Johnson-Laird, under
   1. None of the lawyers are men.                                    review) is a unified computational implementation of the
      Therefore, none of the men are lawyers.                         mental model theory of reasoning. It implements two
                                                                      interoperating systems for reasoning:
The inference is valid because its conclusion must be true
given that its premise is true (Jeffrey, 1981, p. 1). You likely      a)   An intuitive system (system 1) for building an initial
followed up the deductive inference above with an inductive                mental model and drawing rapid inferences from that
inference:                                                                 model
   2. None of the men are lawyers.                                    b) A deliberative system (system 2) for more powerful
      Therefore, they do not possess legal knowledge.                      recursive processes that search for alternative models.
                                                                           This system can manipulate and update the initial
The second inference is inductive – the conclusion is not                  model created in system 1, and it can modify
necessary given the truth of the premise.                                  conclusions
   How do reasoners make deductive and inductive
inferences like the ones above? One prominent answer is               The system is akin to dual-process models of reasoning (see,
that they construct mental simulations of the things they             e.g., Evans, 2003, 2007, 2008; Johnson-Laird, 1983, Ch. 6;
already know or believe. They then manipulate those                   Kahneman, 2011; Sloman, 1996; Stanovich, 1999;
simulations to obtain information they did not have at the            Verschueren, Schaeken, & d’Ydewalle, 2005). Below, we
outset. The idea that reasoning depends on building                   describe the various processes that each system implements.
                                                                  581

The intuitive system                                                separate operations: adding properties to individuals,
                                                                    breaking one individual into two separate individuals, and
Model building. The system builds an initial model from the
                                                                    moving properties from individual to another (see Khemlani,
meaning of a premise, and it updates that initial model if
                                                                    Lotstein, & Johnson-Laird, under review). The operations
additional premises occur. The system begins by building a
                                                                    correspond to those that naïve participants spontaneously
model with a small, arbitrary set of individuals. For
                                                                    adopt when they reason about syllogisms (as evidenced by
example, the model of some of the artists are bohemians is
                                                                    their manipulations of external models, see Bucciarelli &
built by first constructing a set of artists:
                                                                    Johnson-Laird, 1999). Consider our example above. After
                                                                    an individual represents the initial model and provides an
             artist
                                                                    initial conclusion that is false, it can modify that conclusion
             artist
                                                                    by adding properties to the initial model. If the system can
             artist
                                                                    successfully create a model in which some of the artists are
             artist
                                                                    bohemians and all of the artists are bohemians are both
                                                                    true, then it can conclude that it is possible, but not
In the diagram above, each row represents an individual
                                                                    necessary that all of the artists are bohemians. By adding
with the property of being an artist, and so the model as a
                                                                    properties, the system finds such a model:
whole represents a finite number of individuals. Mental
models are representations of real individuals, not letters or
                                                                                artist     bohemian
words, which we use here for convenience. The meaning of
                                                                                artist     bohemian
the assertion some of the artists are bohemians provides
                                                                                artist     bohemian
instructions for the system to add additional properties,
                                                                                artist     bohemian
namely the property of being bohemian. The model is
                                                                                artist     bohemian
updated accordingly:
                                                                    The new model, which contains individuals who are all
             artist    bohemian
                                                                    artists and bohemians at the same time, refutes the
             artist    bohemian
                                                                    conclusion that it is impossible that all the bohemians are
             artist
                                                                    artists. However, the search for alternative models places a
             artist
                                                                    considerable tax on working memory. Until now, the
                       bohemian
                                                                    limitations of the model theory have prevented it from
                                                                    characterizing the cost of holding models in memory.
The model therefore represents a set of individuals, some of
whom are both artists and bohemians, some of whom are
just artists, and one who is just a bohemian. Once a premise
                                                                    Limitations of the model theory
has been represented, the system can assess whether the                The model theory and its unified implementation explain
given conclusion is true in the initial model.                      many aspects of how people make inferences. The theory
                                                                    provides an explanation of how discourse is mapped to
Assessing initial conclusions. When reasoners have to assess        high-level representations. It accounts for why some
a given conclusion, the system inspects the initial model to        reasoning problems are hard and others are easy (Khemlani
verify that the given conclusion holds or does not hold. For        & Johnson-Laird, 2012). It provides working algorithms for
instance, suppose that reasoners are asked to decide whether        how individuals assess whether a given conclusion is
it is possible that all bohemians are artists given the             possible, necessary, or consistent with a given set of
previous premise. From the model above, the system                  premises. And the model theory as a whole can explain
initially responds in the negative, i.e., the putative              deductive, inductive, and abductive inferences (Johnson-
conclusion is impossible. The process is simple, and the            Laird, 2006). As such, it represents a unified theory of
response is rapid. However, it is incorrect: the system’s           reasoning.
ability to assess and generate initial conclusions is fallible.        The theory is limited by design, however, in that most of
For instance, one can indeed show that all of the bohemians         its predictions are qualitative. For instance, it can explain
are artists is possible. To revise its initial conclusion, the      that an inference that requires a reasoner to hold one model
system needs to find an alternative model in which both the         in working memory should be easier than an inference that
premise and conclusion hold. We turn to the second system           requires three models in memory, but it cannot explain or
to explain how such a model is found.                               predict the degree of the difficulty. Is the former inference
                                                                    twice as easy or thrice as easy as the latter? And how long
The deliberative system                                             should each inference take? The computational model is
                                                                    silent on these matters, because it specifies only those
Searching for alternative models. In the preceding section,
                                                                    algorithms that are pertinent to how individuals make
we focused on how the system assesses conclusions based
                                                                    inferences. It ignores other aspects of cognition, such as
on an initial model. However, the conclusions it draws can
                                                                    how models are stored in working memory and how they
be invalid. System 2 attempts to revise initial conclusions by
                                                                    are retrieved. To overcome these limitations, we
searching for alternative models. To do so, it uses three
                                                                582

implemented the theory in the ACT-R cognitive                         automatically, to produce just a condensed version of the
architecture, and we describe the resulting hybrid system             model:
below. The framework, which we call mReactr (mReasoner
+ ACT-R), imbues the model theory with a more robust                               artist      bohemian               (chunk 1’)
account of how models are represented and manipulated. It                          artist                             (chunk 3’)
also stands as a novel application of the ACT-R system,                                        bohemian               (chunk 5’)
which has had only limited success in accounting for
behavior on high-level deductive tasks (e.g., Emond, 2003,            By merging the chunks, the underlying architecture
and Ragni, Fangmeier, & Brüssow, 2010).                               automatically produces a minimal mental model, i.e., a
                                                                      model that only retains information about the different types
         mReactr: Mental models in memory                             of individuals. The process of minimizing mental models is
   The ACT-R cognitive architecture is a modular                      not something that is built into mental model theory as yet;
computational theory of human cognition (Anderson et al.,             the basic mechanisms of memory management within ACT-
2004). It is a collection of interoperating modules that store        R provide a way to efficiently store and retrieve models.
and retrieve information relevant to a particular task. The           But, is there any evidence that reasoners minimize models?
central control system, called the procedural module, directs         And if so, do they minimize models at the outset, or at a
the way the system accesses capacity-limited buffers. The             later stage of processing? To answer both of these questions,
system also contains a declarative module for storing                 we compared mReactr’s accuracy and latency predictions
knowledge of facts and procedures. Facts are stored in                against data from a recent reasoning experiment.
structures called chunks, and procedures are represented by
productions, i.e., condition-action pairings. The productions                         An assessment of the model
direct the procedural model to monitor the buffers for the               We assessed whether the mReactr system could model
existence of certain sorts of chunks, and if a chunk appears          that data from a recent study on so-called “immediate”
in a buffer in the manner that a production expects, the              deductive inferences akin to our introductory example above
relevant action will be initiated. Each chunk has an                  (1). Psychologists have investigated immediate inferences
associated level of activation. If the chunk’s activation is          for many years (e.g., Begg & Harris, 1982; Newstead &
low, ACT-R will take longer to retrieve it, but if it is high, it     Griggs, 1983; Wilkins, 1928), but have yet to resolve how
will be retrieved quickly. Accordingly, the system                    logically untrained individuals make them. The inferences
automatically calculates the time it takes to trigger                 are based on singly-quantified assertions in four different
productions, modify goals, retrieve chunks, and clear                 moods of the premise:
buffers.
   The architecture efficiently manages chunks in declarative            All the Xs are Ys
memory. In particular, if it detects that two chunks are                 Some of the Xs are Ys
identical in every respect, it merges those chunks into one              None of the Xs are Ys
chunk. The merged chunk will then have a higher activation               Some of the Xs are not Ys
than either individual chunk. This “chunk-merging” feature
of the system is particularly important for how mental                and 8 different sorts of conclusion (4 moods by 2 figures,
models are handled.                                                   i.e., arrangements of terms ‘X’ and ‘Y’). Therefore, there
   The mReactr system is an implementation of mental                  are 32 possible immediate inference problems based on
model theory in ACT-R. The system can build initial                   these premises. A typical problem looks like this:
models and assess putative conclusions (system 1) and
likewise it can modify those models to search for alternative            Suppose that some of the students are Virginians.
models (system 2). It stores models in declarative memory                Is it possible that all of the Virginians are students?
by assigning each individual to a separate chunk. Thus, the
system will store the model of all the artists are bohemians          Immediate inferences were chosen because the model theory
as five separate chunks:                                              and mReactr distinguish between the relative difficulties of
                                                                      three sorts of immediate inference: a) zero-model
            artist     bohemian              (chunk 1)                inferences, b) one-model inferences, and c) multiple model
            artist     bohemian              (chunk 2)                inferences.
            artist                           (chunk 3)                   Zero-model inferences are those in which the conclusion
            artist                           (chunk 4)                is identical to the premise, and so individuals needn’t even
                       bohemian              (chunk 5)                build a model to be able to solve the problem. For instance,
                                                                      consider the following problem:
The system therefore represents the model in a distributed
fashion, as a collection of chunks with similar properties.              All the aldermen are barters.
However, several of the separate chunks are identical to one             Is it possible that all the aldermen are barters?
another, and so ACT-R will try to merge those chunks
                                                                  583

Reasoners should realize that the answer is true                    tracking ability so that it could track 10 individual chunks
immediately; however, they should nevertheless need to              (i.e., the :declarative-num-finsts parameter).
extract the meanings from the assertions, and they need to             Second, we attempted to examine whether mReactr could
establish a set of subgoals in order to infer a conclusion.         fit the data better when it actively engaged in minimizing
  One-model inferences are those in which the conclusion            models by merging chunks. We created three separate
holds in the initial model of the premise, and so individuals       versions of mReactr:
can rapidly determine that an assertion is possible. For
example:                                                               1) no chunk-merging version
                                                                       2) system 1 chunk-merging version
  All the aldermen are barters.                                        3) system 2 chunk-merging version
  Is it possible that some of the barters are aldermen?
                                                                    In the no chunk-merging version, chunks were kept separate
Reasoners have to construct the meanings of the assertions,         and ACT-R’s automated chunk-merging capability was
use them to build a model, and evaluate the truth of the            disabled. In the system 1 chunk-merging version, chunks
conclusion in the model.                                            were merged before the system engaged in any inferential
  When the conclusion fails to hold in the initial model, but       processes. And in the system 2 chunk-merging version,
does hold in an alternative to it, then participants have to        chunks were kept separate in the initial model. They were
search for that alternative model. We refer to such problems        merged only when mReactr initiated a search for alternative
as multiple-model inferences. For instance:                         models. The best performing version of the theory can help
                                                                    establish whether and when models should be minimized.
  All of the aldermen are barters.
  Is it possible that some of the barters are not aldermen?         Results and discussion
                                                                       The results of the experiment corroborated the theory’s
For multiple-model inferences, mReactr predicts that                predictions of difficulty (Khemlani et al., in revision), and
reasoners extract the meaning of the assertion and build an         they yielded the following trend: reasoners were 98%
initial model, but their initial model suggests an erroneous        correct for zero-model problems, 85% correct for one-model
evaluation of whether or not the conclusion is possible. To         problems, and 71% correct for multiple-model problems
obtain a correct evaluation, reasoners have to modify their         (Page’s trend test, L = 340.0, z = 3.88, p < .0001).
initial model to produce an alternative model. The theory           Immediate inferences are relatively easy to deduce,
therefore predicts that zero-model inferences should be             nevertheless participants exhibit predictable patterns of
easier than one-model inferences, and one-model inferences          difficulty. The mean latencies also corroborated the
should be easier than multiple-model inferences. Likewise,          predicted trend: 4.30 s for zero-model problems, 5.17 s for
mReactr provides precise latency predictions for how long           one-model problems, and 5.41 s for multiple-model
zero-, one-, and multiple-model inferences should take.             problems (Page’s trend test, L = 336.0, z = 3.33, p < .0005).
  We used mReactr to simulate an experiment conducted by               Figure 1 illustrates the empirical latencies and the
Khemlani, Lotstein, & Johnson-Laird (in revision). In the           predicted latencies from the different versions of mReactr.
study, the participants carried out all 32 problems (4 sorts of     As the figure shows, the system yielded the closest match to
premise x 8 sorts of conclusion), and they responded “yes”
or “no” to a conclusion about a possible conclusion to each
problem. The contents of the problems were based on nouns
referring to common occupations. The instructions stated
that the task was to respond to questions about a series of
assertions concerning what was possible given the truth of
the assertion.
Simulation
  Our goals in simulating immediate inference data were
two-fold. First, we sought to test the fidelity of the mReactr
system as an instantiation of the model theory. We restricted
our simulation to valid immediate inferences, i.e., 22 of the
32 problems. The theory distinguishes between three sorts
of problem, and so mReactr should reflect the same
distinction. A failure of the computational model to capture
those data indicates a poor implementation of the model
theory. We retained all of the default values of the ACT-R          Figure 1: Participants’ mean latencies (in s) to solve zero-, one-,
                                                                    and multiple-model problems, and the latencies predicted by the
architecture, except we increased the architecture’s default
                                                                    three separate versions of mReactr.
                                                                584

                                           Model fits                the model theory’s predictions of difficulty, and it
                                                                     distinguished between zero-, one-, and multiple-model
                                                Goodness of fit      problems. However, the system performed best only when it
                                   2                                 initiated chunk-merging before it began a search for
mReactr version                  R     RMSE       D         p        alternative models. The results have important implications
a) By problem type                                                   for an overlooked process in the psychology of reasoning:
  No chunk-merging              .99      .40     .67       .60       representational minimization.
  System 1 chunk-merging        .94      .54     .67       .60
  System 2 chunk-merging        .99      .18     .67       .60
                                                                                          General Discussion
b) By immediate inference                                               The computational theory, mReactr, is system
                                                                     implemented in the ACT-R cognitive architecture that
  No chunk-merging              .45      .70     .41       .05
                                                                     simulates the construction of mental models in order to
  System 1 chunk-merging        .23      .86     .50      .008       draw immediate inferences from singly-quantified premises.
  System 2 chunk-merging        .45      .57     .18       .86       The cognitive architecture comes equipped with the ability
Table 1: Model fits for the three versions of mReactr by problem     to manage its declarative memory efficiently, namely by
type (zero-, one-, and multiple-model problems) and by the 22        merging identical chunks. mReactr repurposes this chunk-
valid immediate inferences. Note: a lack of significance for the     merging functionality to produce minimal mental models at
Kolmogorov-Smirnov D statistic indicates a good fit.                 a particular stage of inference. At the outset, mReactr uses
                                                                     the same collection of iconic representations as is specified
the data when chunk-merging was initiated at a later stage           in the model theory. However, the full representation is
of processing, i.e., the system 2 chunk-merging version (R2          ephemeral, and it lasts only until the system starts to modify
= .99, RMSE = .18). When chunk-merging was disabled in               the model. If and until the system initiates a search for
the no chunk-merging version, the system did well, but it            alternative models, it minimizes the model. This process
took too long to search for alternative models, (R2 = .99,           maps onto the psychological strategy of abstracting over the
RMSE = .40). In the system 1 chunk-merging version,                  different sorts of individuals.
mReactr performed faster than participants tend to perform,             The theory predicts that individuals should be faster and
yielding a poorer fit of the data (R2 = .94, RMSE = .54).            more accurate when an inference can be drawn from an
  Across all three simulations, the system negatively                identity in the meanings of the assertions, i.e., when they do
correlated with participants’ accuracy (r’s < -.90, p’s <            not need to consult a mental model. They should be next
.0001). Likewise, the simulations fit the latencies well.            fastest and accurate when an inference can be drawn from
Table 1a gives the model fits for the three separate versions        the initial model constructed in system 1. And they should
of the system across the three types of problems as a whole,         be slowest and least accurate when an inference can be
as well as across the 22 different problems separately.              drawn only from the discovery of an alternative model
  We ran a separate set of analyses to examine how the               constructed in system 2. These rank-order predictions were
three versions of the system modeled the 22 valid immediate          borne out in the data from an experiment that tested all 22
inferences separately (see Table 1b). This set of analyses           valid inferences about possible conclusions in the set of 32
would by definition yield poorer model fits as a result of the       inferences.
inherent variation between different problems, and so any               The system we describe is limited, however, and it can be
significant correlation can be construed as support for the          improved to yield a more fine-grained processing account of
theory. The analysis replicated and elaborated upon the              the data. We suggest two separate ways of proceeding. One
aggregated results. The system fit the data moderately well          way to improve the fit of the system is to make the system
with chunk-merging turned off, but its RMSE was relatively           sensitive to the direction in which it scans models. For
high (R2 = .45, RMSE = .70), and a Kolmogorov-Smirnov                instance, if reasoners read a particular premise, e.g., all
goodness of fit analysis indicated that the system exhibited         artists are bohemians, they may be biased to scan the model
reliably different distributional properties than that of the        in the opposite directions by considering bohemians before
experiment (D = .41, p = .05). Likewise, the system                  artists. This figural bias is widely documented in syllogistic
provided a relatively poor fit of the data when models were          reasoning (Khemlani & Johnson-Laird, 2012) and it is likely
minimized at the outset (R2 = .23, RMSE = .86) and so                to make a difference when reasoning about immediate
mReactr produced results that came from a separate                   inferences as well.
distribution (Kolmogorov-Smirnov test, D = .50, p = .008).              Another way to improve the system’s overall performance
Only when models were minimized before the system                    is to consider the process of model minimization as
searched for alternative models did the system fit the data          something that may or may not occur depending on strategy
well (R2 = .45, RMSE = .57), and the goodness-of-fit                 and individual differences (Bucciarelli & Johnson-Laird,
analysis indicated a close match between mReactr and the             1999). Some reasoners may be more likely to minimize their
data (Kolmogorov-Smirnov test, D = .18, p = .86).                    models, and others might prefer to keep the full model
  The results of the simulations showed that across all three        representation in mind.
version of mReactr, the system successfully implemented
                                                                 585

  In sum, model minimization is an important way in which           conscioussness. Cambridge: Cambridge University Press.
individuals can optimize the storage and retrieval of mental        Cambridge, MA: Harvard University Press.
models. It is embodied in the computational system of             Johnson-Laird, P. N. (2006). How we reason. Oxford, UK:
deductive reasoning that we developed.                              Oxford University Press.
                                                                  Johnson-Laird, P.N., & Byrne, R.M.J. (1991). Deduction.
                    Acknowledgments                                 Hillsdale, NJ: Erlbaum.
This research was funded by a National Research Council           Kahneman, D. (2011). Thinking, fast and slow. New York,
Research Associateship awarded to SK and ONR Grant #s               NY: Farrar, Strauss, Giroux.
N0001412WX30002 and N0001411WX20516 awarded to                    Khemlani, S., & Johnson-Laird, P.N. (2012). Theories of
JGT. We are also grateful to Len Breslow, Magda Bugajska,           the syllogism: A meta-analysis. Psychological Bulletin, in
Hua Gao, Tony Harrison, Cathy Haught, Laura Hiatt, Phil             press.
Johnson-Laird, Gorka Navarrete, Marco Ragni, and Tobias           Khemlani, S., Lotstein, M., & Johnson-Laird, P.N. (in
Sonntag for their helpful comments.                                 revision). Immediate inferences from quantified
                                                                    assertions. Manuscript in revision.
                                                                  Khemlani, S., Lotstein, M., & Johnson-Laird, P.N. (under
                        References                                  review). A unified theory of syllogistic reasoning.
Anderson, J. R. (1990). The adaptive character of thought.          Manuscript under submission.
  Hillsdale, NJ: Erlbaum.                                         Newstead, S.E., & Griggs, R.A. (1983). Drawing inferences
Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S.,           from quantified statements: A study of the square of
  Lebiere, C., & Qin, Y . (2004). An integrated theory of           opposition. Journal of Verbal Learning and Verbal
  the mind. Psychological Review 111, 1036-1060.                    Behavior, 22, 535–546.
Begg, I., & Harris, G. (1982). On the interpretation of           Peirce, C.S. (1931-1958). Collected papers of Charles
  syllogisms. Journal of Verbal Learning and Verbal                 Sanders Peirce. 8 vols. Hartshorne, C., Weiss, P., &
  Behavior, 21, 595–620.                                            Burks, A. (Eds.) Cambridge, MA: Harvard University
Bucciarelli, M., & Johnson-Laird, P. N. (1999). Strategies in       Press.
  syllogistic reasoning. Cognitive Science, 23, 247-303.          Ragni, M., Fangmeier, T., & Brüssow, S. (2010). Deductive
Emond, B. (2003). Cognitive representations and processes           spatial reasoning: From neurological evidence to a
  in syllogistic reasoning: existential graphs and cognitive        cognitive model. In D. D. Salvucci & G. Gunzelmann
  modelling. Psychologica, 32, 311-340.                             (Eds.), Proceedings of the 10th International Conference
Evans, J.St.B.T. (2003). In two minds: Dual process                 on Cognitive Modeling (pp. 193-198). Philadelphia, PA:
  accounts of reasoning. Trends in Cognitive Sciences, 7,           Drexel University.
  454–459.                                                        Sloman, S.A. (1996). The empirical case for two systems of
Evans, J. St. B. T. (2007). Hypothetical thinking: Dual             reasoning. Psychological Bulletin, 119, 3–22.
  processes in reasoning and judgement . Hove, UK:                Stanovich, K.E. (1999). Who is rational? Studies of
  Psychology Press.                                                 individual differences in reasoning. Mahwah, NJ:
Evans, J. St. B. T. (2008). Dual-processing accounts of             Erlbaum.
  reasoning, judgment and social cognition. Annual Review         Verschueren, N., Schaeken, W., & d’Ydewalle, G. (2005).
  of Psychology, 59, 255-278.                                       A dual-process specification of causal conditional
Jeffrey, R. (1981). Formal logic: Its scope and limits (2nd         reasoning. Thinking & Reasoning, 11, 278–293.
  Ed). New York: McGraw-Hill.                                     Wilkins, M. C. (1928). The effect of changed material on
Johnson-Laird. P.N. (1983). Mental models: Towards a                the ability to do formal syllogistic reasoning. Archives of
  cognitive science of language, inference, and                     Psychology, 16, No. 102.
                                                              586

