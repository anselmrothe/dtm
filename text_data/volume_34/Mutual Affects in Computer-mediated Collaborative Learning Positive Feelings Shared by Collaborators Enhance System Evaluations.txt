UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Mutual Affects in Computer-mediated Collaborative Learning: Positive Feelings Shared by
Collaborators Enhance System Evaluations
Permalink
https://escholarship.org/uc/item/5h7451mf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Yamauchi, Takashi
Ohno, Takehiko
Nakatani, Momoko
et al.
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                     Mutual Affects in Computer-mediated Collaborative Learning:
              Positive Feelings Shared by Collaborators Enhance System Evaluations
    Takashi Yamauchi,                   Takehiko Ohno, Momoko Nakatani, Yoichi Kato,                      Arthur B. Markman
     Texas A&M University                            NTT Cyber Solutions Laboratories                        University of Texas
     College Station, TX                                    Yokosuka-shi, Japan                                  Austin, TX
   takashi-yamauchi@tamu.edu                        ohno.takehiko@lab.ntt.co.jp                          markman@psy.utexas.edu
                              Abstract                                 added complexity inherent in group interaction (Grudin,
                                                                       1994).
   The authors employ behavioral theories of human motivation             Here, we propose a conjecture that psychological models
   and affect and present an explanation for why some                  of sensemaking can provide a useful framework for user
   computer-mediated collaborative learning is satisfying for a        experience in a groupware setting much in the same way
   user. In a longitudinal experiment, participants were divided
   into four groups and solved two open-ended problems
                                                                       that affordance and cognitive architecture helped the
   together using a video-conference system. Traditional metrics       evolution of single-user interfaces. We argue that the
   of usability and product acceptance were examined with              evaluation of one’s experience is basically a sensemaking
   respect to psychological variables such as personality,             process, and the variables that intervene this process
   background knowledge, and feelings toward group members             influence “user experience.”
   (mutual affect). The results show that group-level mutual              To test our framework, we developed an experimental
   affect is a strong predictor of system acceptability judgments,     study, where 29 college students were divided into four
   even after controlling for other pragmatic variables such as
   opinion convergence. It is proposed that evaluating one’s           groups and solved two problems together in a 2-month
   experience with a computer-mediated collaborative system is         period using a video-conference system. We examined
   a sensemaking process and that the variables that modulate          subjective metrics of usability and product acceptance with
   this process also influence subjective judgments of usability       respect to other psychological variables such as personality,
   and acceptability of a system.                                      background knowledge and group-coherence. The results
   Keywords: User satisfaction, user experience, mutual affect         showed that a positive mutual affect among group members
                                                                       led to increased product acceptance, even after controlling
Cultivating positive emotions among collaborators is                   for other pragmatic variables such as opinion convergence
essential for the success of groupware applications because            and communication effectiveness.
shared positive affects promote group coordination,
common ground, and group awareness—key ingredients for                 User Experience as a Sensemaking Process
successful online collaboration (Carroll et al., 2006). But            Klein et al. (2006) and Pirolli and Card (2005) provide
what design features are critical to generate positive mutual          models of sensemaking. The two models differ in specifics
affects? Do mutual affects influence user experience                   but share some basic properties. Sensemaking consists of
primarily by elevating pragmatic qualities of group                    dynamic processes of data selection and frame/schema
interaction, such as group communication and coordination?             revision. Relevant data are selected according to one’s
   To help improve computer-mediated collaborative                     frame (prior knowledge/beliefs/mindsets), the data are
learning (e.g., learning collaboratively via video                     interpreted and the frame is revised according to the
conferencing), researchers have identified important                   interpretation. Sensemaking goes through cycles of this data
variables, such as group awareness, common ground, shared              selection/interpretation and frame/schema revision loop.
visual information and teamwork coordination (Carroll et               Our central hypothesis is that user experience is a
al., 2006). However, to make a “good” collaborative                    sensemaking process. “Experience” does not come to people
learning system, these pragmatic variables should be                   unambiguously. Experience is selected, sensed, represented,
supplanted; the product should be not only useful but also             and interpreted by people (Pirolli & Card, 2005). In this
engaging and satisfying for the users (Hassenzahl &                    process, affects play critical roles as affect seeps into the
Tractinsky, 2006; Norman, 2004). But to make an engaging               evaluation of the data.
and satisfying product, it is crucial to know how users come
to evaluate their experiences with a collaborative system.             Group-level Mutual Affect The importance of affect in
   Conceptual frameworks such as information processing,               product design is well known, but affect in human-computer
affordance, and cognitive architecture have generated                  interaction has pertained to a specific product. We think that
testable hypotheses and guidelines instrumental for single-            group-level mutual affect (e.g., feeling of closeness of group
user product design. However, these pragmatic variables are            members) can also be an important factor because affects
not entirely feasible in collaborative settings because of             are contagious and affects coming from unrelated sources
                                                                       can be easily fused into the evaluation of a product.
                                                                   1179

   Much research has shown that relatively simple                  level variables such as opinion convergence                     and
manipulations of inducing a positive affect, such as viewing       communication effectiveness are controlled for.
a comedy film for a few minutes or writing about happy
events, influence subsequent decision making of unrelated                                                    The rationales for this
objects (Clore & Huntsinger, 2007). Schwarz and Clore                                                     hypothesis         are     as
(1983) present one of the most stunning demonstrations of                                                 follows.             Because
affect contamination. In their experiment, the researchers                                                assessing               one’s
interviewed subjects about their general happiness with their                                             experience         with     a
lives. Subjects were selected randomly and telephone-                                                     computer system is a
interviews were conducted on either a sunny day or a rainy                                                sensemaking          process,
day. Those who had an interview on a sunny day gave                                                       group-level mutual affect
higher happiness ratings than those who had an interview on             Figure 1. MeetingPlaza.           can be easily fused into
a rainy day. When the link between mood and weather was                                                   the evaluation of the
made clear to subjects, the ratings made on the rainy day          conference system, as a user makes a system evaluation
went up, indicating that subjects’ ratings about happiness         based on his/her memory of the experience with a product.
were partly due to their erroneous generalization of their         Thus, positive mutual affect will be translated into positive
unhappy mood on the rainy day.                                     product evaluation.
   A similar misattribution is likely to happen in the
judgment of usability and acceptability. Usability and                Participants. Thirty-two participants were recruited from
acceptability of a product will be judged by pragmatic,            the Texas A&M University community. They were assigned
hedonic, and aesthetic features of the product (Hassenzahl &       randomly to four groups. Three participants chose not to
Tractinsky, 2006). However, in making an actual judgment,          take part in the experiment after the first meeting. Thus, a
a user will interpret his/her memories of experience. In this      total of 29 participants completed the two problem solving
process, affective experience with group members can               sessions (Table 1). Participants received a payment of $144
contaminate their evaluation (Clore & Huntsinger, 2007).           ($12 per hour for a total of 12 hours for their involvement).
   In the experiment described below, we examined the              Bonus payments of $24~$48 were made to group members
extent to which mutual affects formed among collaborators          who produced the best and second-best white papers. In a
influence their usability and acceptability judgments of a         separate experiment, 47 undergraduate students were
video-conference system.                                           recruited from the university psychology subject pool for
                                                                   the evaluation of the white papers submitted by the four
                        Experiment                                 groups.
In our 2-month-long experimental study, four groups of                               Table 1. Participant information
participants (seven to eight participants per group) met eight        N=                          29          Major: psychology =
times using MeetingPlaza, a multi-party Web conferencing              (Male, Female)           (14, 15)    16; public health = 2;
and collaboration system (http://www.meetingplaza.com);               Freshman                     1       political science,
each group worked together to solve two different open-               Junior                       5       history, general studies,
ended problems (i.e., how to improve the university and               Sophomore                    6       telecommunication,
recommendations for freshman job search) [15], and wrote              Senior                      12       management,
two one-page white paper proposals together as a group                Graduate student             4       accounting, industrial
using MeetingPlaza.                                                   Staff                       1        engineering, electrical
   MeetingPlaza has web-, file-, whiteboard- and                      Average age                21.1      engineering, chemical
application-sharing functions that facilitate collaborative           Note. Three participants dropped engineering, nursing,
                                                                   after the first meeting and the data nutrition = 1
communication. For example, the web-share function allows
                                                                   from 29 participants were analyzed.
participants in different locations to view the same web site
                                                                      Note. The participants received a payment of $144. Bonus
on their own computers at the same time. The file-sharing          payments of $24~$48 were made to group members who produced
and application-sharing functions help people in remote            the best and second-best white papers.
locations to view and manipulate the same file together
(e.g., an MS Word file). The participants were encouraged             Materials. We employed five questionnaires to assess
to write papers together using these sharing functions.            participants’ mindsets (implicit beliefs on intelligence,
                                                                   morality and world), personality (neuroticism, extraversion
Hypothesis. On the basis of the theoretical background             and psychoticism), technological literacy (computer-literacy
discussed previously, we formed the following hypothesis.          and Internet-literacy), and expectations (expected ease of
Group-level mutual affect (e.g., feelings of closeness toward      use and expected usefulness of the product). These
group members) influences subjective judgments of system           questionnaires, which were given at the orientation meeting,
usability and acceptability. In particular, those who have         were adopted to isolate the effect of group-level mutual
high positive group-level affect should give high                  affect as much as possible.
acceptability and usability ratings even when other group-
                                                               1180

               Expectations (usability /      Usability       Usability         Model (TAM) (Davis, 1989) and developed questionnaires
  Mindsets     acceptability)                 acceptability   acceptability     assessing expected ease of use and expected usefulness of
                                                                                the product (six questions for each). We included the term
                                                                                “expected” because our questionnaires were given shortly
                                                                                after MeetingPlaza was introduced to the participants but
                                                                                before they actually used the system.
                                                                                   Usability. We employed Lewis’s Computer System
                                                                                Usability Questionnaire (CSUQ; 19 questions) (Lewis,
  Personality      Group‐level affect (4    Group‐level affect (4               1995). The CSUQ consists of three factors, system
  Tech. literacy   times)                   times)
                                                                                usefulness, information quality, and interface quality. The
  Orientation Session 1 (4 meetings) Session 2 (4 meetings)                     pre-usability questionnaire was given at the orientation
                                                                                meeting shortly after participants were introduced to the
                 Figure 2.The logistics of the experiment.
                                                                                system but before using the system. The post-usability
   Group-level coherence (affect, communication and                             questionnaire was given twice at the end of session 1 and at
opinion) was measured by electronic questionnaires given at                     the very end of the experiment.
the end of each meeting. Participants’ subjective judgments                        Acceptability. To measure participants’ behavioral
of system usability and acceptability were collected three                      intention of adopting the video-conference system, we
times in a two-month period, before using the system (at the                    created 10 acceptability questions based on Davis et al.,
orientation meeting), in the middle of using the system                         (1989) and Venkatesh and Morris (2003). These questions
(after the fourth meeting), and at the end of the experiment                    assessed participants’ intention to continue to use
(after the eighth meeting) (Figure 2). Participants’                            MeetingPlaza if the system were made available to them.
subjective judgments of system usability and acceptability                         Group-level coherence. We measured group-level
were collected three times in a two-month period, before                        coherence of individual members with three dimensions,
using the system (at the orientation meeting), in the middle                    mutual affect (e.g., how close do you feel with each member
of using the system (after the fourth meeting), and at the end                  of your group?), opinion convergence (e.g., how close was
of the experiment (after the eighth meeting) (Figure 2).                        your opinion with that of each member of your group?), and
   Below we explain the questionnaires used in the                              communication effectiveness (e.g., how effectively did you
experiment.                                                                     communicate with each member of your group?). Every
   Implicit belief. The implicit belief questionnaire assesses                  participant rated how he/she felt about each group member
the extent to which people conceptualize intelligence,                          at the end of every group meeting (a total of eight meetings),
morality, or the world as a dynamic or fixed construct                          the ratings he/she gave to all group members were averaged
(Dweck, 1999). This questionnaire was included because                          over affect, communication effectiveness and opinion
people’s implicit beliefs are known to influence their goal                     convergence dimensions, and these average values were
setting and learning experience.                                                treated as his/her group-level affect, communication
   Personality. Francis et al.                 (1992) developed an              effectiveness and opinion convergence (Strauss, 1997).
abbreviated version of the Eysenck personality                                     Procedure. The experiment consisted of four segments:
questionnaire (EPQR), which has four dimensions                                 orientation, session 1, session 2, and paper evaluation.
(extraversion, neuroticism, psychoticism, and lie scale) with                   Below, we describe the segments in chronological order
six questions each. The questionnaire assesses personality of                   (Figure 3).
a person with three dimensions, extraversion (high-low                             Orientation. The orientation meeting was held in a large
tendency to seek external stimulation), neuroticism (high-                      classroom. First, participants indicated their implicit beliefs,
low level of negative affect), and psychoticism (high-low                       personality and technology literacy, and then the
level of impulsiveness). Following the suggestion by                            experimenter introduced MeetingPlaza. At this stage,
Francis et al. (1992) we did not analyze lie-scale scores in                    participants were allowed to view MeetingPlaza, but they
the present experiment.                                                         were not allowed to use the system. After this brief
   Technology          literacy.        The      technology        literacy     instruction, participants indicated their expected ease of use
questionnaire was developed for this experiment based on                        and expected usefulness of MeetingPlaza, along with their
the digital literacy questionnaire by Hargittai (2009). Our                     expected usability of the product (pre-usability) and their
questionnaire consists of two categories, computer literacy                     intention of using the product in the future (acceptability).
and Internet literacy, and a total of 10 questions. The                            Sessions 1 & 2. Approximately 1 week after the
computer literacy measure has four items related to                             orientation meeting, participants were assigned to four
knowledge about software (e.g., PowerPoint) and                                 groups, and each group had its first on-line meeting using
programming language (e.g., Java). Internet literacy consists                   MeetingPlaza. In this segment, participants received
of six items related to common Internet-based activities (e.g.,                 extended instruction and demonstrations of MeetingPlaza
tweeting or on-line shopping).                                                  functions and tested MeetingPlaza by themselves. Each
   Expected ease of use and expected usefulness of the                          group met twice a week, and discussed solutions for the
product. We modified Davis’s Technology Acceptance                              assigned problems using MeetingPlaza. In one session,
                                                                            1181

participants as a group were required to write a one-page
white paper describing ways to improve the university; in
the other session participants as a group were required to
write another white paper describing recommendations for
job search for college freshmen. Each group was required to
submit a paper at the end of the fourth meeting of each
session. Each meeting lasted about 1 hour.
                 Session 1 :        Session 2:          Paper
  Orientation    Instruction,       Instruction,        Evaluation
                 4 meetings,        4 meetings                               Note. The central mark and the edges of a box are the median
                 closing 1          Closing 2                               and the 25th and 75th percentiles, respectively. The whiskers are
                                                                                             the most extreme data points.
            Figure 3. Four segments of the experiment
                                                                                     Figure 4. Boxplots for questionnaire responses.
  Session 2 was given 1 week after the end of session 1.
                                                                                                                     Acceptability and
The procedure of session 2 was identical to that described in                                                 Longitudinal Shifts in Usability and
                                                                            Usability & Acceptability
                                                                                                          1                   usability.
session 1.                                                                                                         Acceptability Judgment
                                                                                                        0.9        Participants’ initial
  Closings 1 & 2. Two closing meetings, closing 1 and                                                Usability
                                                                                                        0.8        reactions          to
closing 2, were held at the end of sessions 1 and 2,                                                 Acceptability
                                                                                                        0.7        MeetingPlaza were
respectively. In closings 1 and 2, participants filled out the
                                                                                                        0.6            overwhelmingly
usability and product acceptance questionnaires. Closing 2
                                                                                                        0.5        positive. At the end
was the final meeting.
                                                                                                                   of the orientation
  Paper evaluation. In a separate experiment, 47                                Orientation Closing 1 Closing 2
                                                                                                                                session,
undergraduate students participated in the paper evaluation
                                                                             Figure 5. Usability/acceptability     MeetingPlaza was
experiment (male=23, female=23, unknown=1) and rated                                      change                   regarded        very
the eight papers written by the four groups in six categories
                                                                        favorably (usability, M=0.80, SD=0.11; acceptability,
(creativity, implementation, coherence, effectiveness, cost,
                                                                        M=0.78, SD=0.17; Figure 5). However, the ratings of
and communication) on a 0–100 scale. They were
                                                                        MeetingPlaza dropped significantly at closing 1 (usability,
encouraged to rate the papers in the same way a professor
                                                                        M=0.64, SD=0.64; acceptability, M=0.63, SD=0.21) and
grades their papers in a classroom.
                                                                        closing 2 (usability, M=0.61, SD=0.18; acceptability,
                                                                        M=0.63, SD=0.22). Two 3 (sequence: orientation, closing
Results
                                                                        1, closing 2) x 4 (group: 1, 2, 3, 4) ANOVAs revealed that
All questionnaire responses were converted to a 0-1 scale               this drop occurred uniformly in all groups: usability, F(2,
such that the direction of the observed scores corresponded             50)=18.61, MSE=0.02, p<0.01; acceptability, F(2,
to the direction of the psychological dimensions in question.           50)=9.70, MSE=0.02, p<0.01. Neither the main effect of
Thus, a high score corresponded to a high degree of the                 group nor the interaction between sequence and group was
given dimension. This section begins with a summary of                  observed in both usability and acceptability measures:
questionnaire responses, followed by a description of the               F’s<1.5, p>0.24. These results suggest that MeetingPlaza
longitudinal shifts of usability, product acceptability and             created a positive impression on the college-age
group-coherence, and concludes with statistical analyses                participants but the excitement dropped considerably once
that examine the relationship between group-coherence and               the participants used the product for problem solving,
system evaluation.                                                      indicating that using the collaborative video-conferencing
   User profiles. The responses on the 10 dimensions of the             system was much more challenging than anticipated.
questionnaires (Figure 4) show that there were no ceiling or               Longitudinal shifts of group coherence. The group-
floor effects, except for the responses regarding expected              coherence scores (mutual affect, opinion convergence,
ease of use and expected usefulness. This problem will be               communication effectiveness) all increased as the
discussed in the next paragraph and later in the Results                collaborative sessions progressed (Figure 6). Three sets of
section. ANOVAs (analysis of variance) comparing the four               linear contrast analyses (shift; beginning, middle, end of the
groups in each of the ten user profile dimensions showed                experimental sessions) x (group; 1-4) applied to the three
that the mean profile scores of the four groups were not                group-coherence measures revealed significant linear
statistically different: F’s(3, 25)<2.2, p’s>0.11.                      upward trends: communication effectiveness, F(1,
                                                                        25)=7.72, MSE=.01, p<.05; opinion convergence, F(1,
                                                                        25)=26.2, MSE=.01, p<.001; mutual affect, F(1, 25)=35.8,
                                                                     1182

MSE=.01, p<.001, suggesting that our online meetings were                       participants in each group and the white paper evaluation
indeed effective in developing a sense of common ground,                        score that each group received (Table 2).
better communication, and positive feelings. There was no
interaction effect of group and shift: F’s<1.0.                                        Table 2. Hierarchical Linear Regression Model
                                                          Note. Beginning           Individual layer:                  Group layer:
                    0.8
                              Longitudinal shift       =meetings 1-3 of         Yij = β0j + β1j Xij + u ij       β0j = γ00 + γ01Wj + u0j
                                                       session 1; middle
                                                                                                                 β1j = γ10 + γ11Wj + u1j
  Group coherence
                    0.7                                =meeting 4 and
                                                       meeting       1  of
                                                                                Note. Subscript j denotes group ID and Yij represents the
                    0.6                                sessions 1 & 2,
                                                       respectively;   and      acceptability score obtained from participant i of group j. β0j
                                       communication
                                                       end=meetings 2-4         and β1j are intercepts and slopes of the regression line of
                    0.5                mutual affect
                                                       of session 2.            group j, respectively. u’s are error terms. γ00 is the overall
                                       opinion                                  mean of the acceptability scores and γ10 is the mean of the slopes
                    0.4                                                         of the four groups. Wj represents group-specific values (e.g.,
                          beginning middle      end
                                                                                either the female-male ratio of group j or the problem solving
                             Collaborative sessions                             score of group j) and γ11 is the coefficient for predictor Wi.
                    Figure 6. Longitudinal shifts of group coherence
                                                                                                                           Our hierarchical
   Evaluation of the hypothesis. Regression analyses were                                                                models had two
employed to investigate the link between group-level affect                                                              layers,    individual
and system evaluation. Both step-wise regression and                                                                     and group (Table 2).
regular multiple regression were adopted to ameliorate the                                                               The model assumes
problem of multicollinearity. In the step-wise regression                                                                that the coefficients
procedure, the forward selection method was applied with                                                                 β1j of mutual affects
the entry criterion of 0.1 to ensure that all relevant                                                                   (Xij) vary for each
predictors were included in the regression models.                                                                       group      and     are
   The step-wise regression analyses using group coherence                                                               modulated by a
variables suggest that mutual affects influenced system                                                                         group-specific
acceptability scores significantly; β=.52, p<0.01, R2 =.27;                                                                          properties
but other group coherence variables—opinion convergence                                                                      (problem-solving
and communication effectiveness—did not influence                               Note. The problem-solving performance    scores or female-
acceptability scores, p>.1. The impact of the mutual affect                     was measured by the average paper        male ratios). Note
variable remained strong on the system acceptability                            evaluation score that each group         that the “group-
measure even after controlling for the effects of all other                     received in a separate experiment.       level mutual affect”
personal variables [mindsets (intelligence, morality, world);                    Figure 7. 95% high density intervals of variable Xij was
personality (neuroticism, extraversion, psychoticism),                                β1j estimated for each group       included in the
technology literacy (computer-literacy, Internet-literacy)]; β                                                           individual      layer
=0.48, p=.05; but not the usability scores; β =0.35, p=.15.                     because the values of this variable were calculated for
   The results from multiple regression analyses were                           individual participants. The values of group-specific
analogous to those found in the step-wise regression                            variable Wj (e.g., problem-solving scores or female-male
analyses. Even after the communicative variables—                               ratios) were calculated for each group, not for each
communication effectiveness and opinion convergence—                            participant. Because we had only four groups, the intervals
were forced into the models, the strongest predictors were                      of β1j were estimated by a Bayesian method where the
still mutual affect; the correlation between mutual affect and                  coefficients (γ.) in the group layer were treated as non-
acceptability was significant after the effects of                              informative hyper-parameters and posterior distributions
communication effectiveness and opinion convergence were                        were obtained by the Markov Chain Monte Caro algorithm
partialed out (r=0.45, p<0.05).                                                 with 1000 iterations (Gelman & Hill, 2007).
   Cohort effects. The predictor, group-level mutual affect,                       The results, which are summarized in Figure 7, suggest
was evaluated with the data obtained from individual                            that even after the two group-specific properties (female-
participants. Because MeetingPlaza is a collaboration tool,                     male ratios and problem-solving scores) were taken into
the impact of this variable should be scrutinized with                          account, the impact of mutual affect remained robust, as the
respect to the properties obtained from each group. For this                    95% high density intervals of the coefficients β1j were above
reason, we employed hierarchical linear regression models                       0 in all cases, suggesting that the effect of mutual affect
and estimated the beta coefficients of the mutual affect                        occurred on top of the group-specific properties.
variable for each group and investigated if the impact of
mutual affects remain robust after controlling for other
group-specific properties—the ratio of female and male
                                                                             1183

                        Discussion                                  Davis, F. D., Bagozzi, R. P., & Warshaw, P. R. (1989). User
                                                                      acceptance of computer technology: A comparison of two
In computer-mediated collaborative learning, the focus has
                                                                      theoretical models. Management Science, 35(8), 982-
been to enhance pragmatic functionality of the system. The
                                                                      1003.
present study shows that fostering positive emotions among
                                                                    Dweck, C. S. (1999). Self-theories: Their role in motivation,
collaborators is no less important. The results suggest that
                                                                      personality and development. Ann Arbor, MI: Psychology
mutual affects shared among collaborators influence the
                                                                      Press.
evaluation of product acceptability even after personal
                                                                    Francis, L. J., Brown, L. B., & Philipchalk, R. (1992). The
variables, such as personality and background knowledge,
                                                                      development of an abbreviated form of the revised
were taken into account, implying that the influence of
                                                                      Eysenck Personality Questionnaire (EPQR-A): Its use
mutual affect on a video-conferencing system is far reaching
                                                                      among students in England, Canada, the U.S.A. and
than previously thought. Because the effect of mutual affect
                                                                      Australia. Personality and Individual Differences, 13,
was stronger than that of pragmatic variable such as group-
                                                                      443-449.
level communication and opinion convergence, it is likely
                                                                    Gelman, A., & Hill, J. (2007). Data Analysis Using
that mutual affects were fused into users’ experience with
                                                                      Regression and Multilevel/Hierarchical Models. New
the system.
                                                                      York: Cambridge University Press
   Note that the fact that affective experience can be
                                                                    Grudin, J. (1994). Groupware and social dynamics: Eight
misattributed does not mean that affect is irrelevant in
                                                                      challenges for developers. Communication of the ACM,
enhancing the functionality of a collaborative learning
                                                                      37(1), 92-105.
system. Positive emotions can unleash creative and flexible
                                                                    Hargittai, E. (2009). An update on survey measures of web-
thinking (Isen, 2008) and shared feelings have a
                                                                      oriented digital literacy. Social Science Computer Review,
multiplicative effect on collaborators because emotions are
                                                                      27(1), 130-137.
highly contagious.
                                                                    Hassenzahl, M., & Tractinsky, N. (2006). User experience –
   A considerable progress has been made in the area of
                                                                      research agenda. Behaviour & Information Technology,
affective computing of intelligent tutoring systems,
                                                                      25, 91-97.
primarily thanks to the pioneering studies by D’Mello,
                                                                    Isen, A. M. (2008). Some ways in which positive affect
Graesser, and Conati (Conati & Maclaren, 2009; D’Mello et
                                                                      influences decision making and problem solving
al., 2007). We suggest that similar affect detection
                                                                      Handbook of emotions (pp. 548-573). New York:
technologies help advance group-ware applications. In a
                                                                      Guilford Press.
large computer-based collaborative situation, it is difficult to
                                                                    Klein, G., Moon, B., & Hoffman, R. R. (2006). Making
assess participants’ affective states in real time. A
                                                                      sense of sensemaking 2: A macrocognitive model. IEEE
collaborative groupware system that can trace users’
                                                                      Intelligent Systems, 21(5), 88–92.
affective state can facilitate group participation and
                                                                    Lewis, J. R. (1995). IBM computer usability satisfaction
learning.
                                                                      questionnaire: psychometric evaluation and instructions
                                                                      for use. International Journal of Human-Computer
                   Acknowledgments                                    Interaction, 7, 57-78.
This study was supported by a grant from NTT Cyber                  Norman, D. A. (2004). Introduction to this special section
Solutions Laboratories.                                               on beauty, goodness, and usability. Human-Computer
                                                                      Interaction, 19, 311-318.
                        References                                  Pirolli, P., & Card, S. K. (2005, May). The sensemaking and
Carroll, J. M., Rosson, M. B., Convertino, G., & Ganoe, C.            leverage points for analyst technology as identified
   H. (2006). Awareness and teamwork in computer-                     through cognitive task analysis. Paper presented at the
   supported collaborations. nteracting with Computers, 26,           International Conference on Intelligence Analysis,
   21-46.                                                             McLean, VA.
Clore, G. L., & Huntsinger, J. R. (2007). How emotions              Schwarz, N., & Clore, G. L. (1983). Mood, misattribution,
   inform judgment and regulate thought. Trends in                    and judgments of well-being: informative and directive
   Cognitive Sciences, 11, 393-399.                                   functions of affective states. Journal of Personality and
Conati, C., & Maclaren, H. (2009). Modeling User Affect               Social Psychology, 45, 513–523.
   from Causes and Effects. In G.-J. H. et al. (Ed.), UMAP          Straus, S. G. (1997). Technology, group process, and group
   2009, LNCS 5535 (pp. 4-15). Berlin Heidelberg: Springer-           outcomes: Testing the connections in computer-mediated
   Verlag.                                                            and face-to-face groups. Human-Computer Interaction,
D’Mello, S., Graesser, A., & Picard, R. (2007). Towards an            12, 227-266.
   Affect-Sensitive AutoTutor. IEEE Intelligent Systems, 22,        Venkatesh, V., & Morris, M. G. (2003). User acceptance of
   53-61.                                                             information technology: Toward a unified view. MIS
Davis, F. D. (1989). Perceived usefulness, perceived ease of          Quarterly, 27, 425-478.
   use, and user acceptance of information technology. MIS
   Quarterly, 13, 319-340.
                                                                1184

