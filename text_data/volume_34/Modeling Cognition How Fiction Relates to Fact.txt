UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Cognition: How Fiction Relates to Fact

Permalink
https://escholarship.org/uc/item/24z1257h

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Rusanen, Anna-Mari
Lappi, Otto

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Modeling Cognition: How Fiction Relates to Fact
Anna-Mari Rusanen (anna-mari.rusanen@helsinki.fi)
Philosophy of Science Group/
Department of Philosophy, History, Art and Culture Studies, PO BOX 24
00014 University of Helsinki, FINLAND

Otto Lappi (otto.lappi@helsinki.fi)
Cognitive Science
Institute of Behavioural Sciences, PO BOX 9
00014 University of Helsinki, FINLAND

properties and their causal relations - gives rise to or
produces the phenomenon. Constructing an explanatory
mechanistic model involves mapping elements of a
mechanistic model to the system of interest, so that the
elements of the model correspond to identifiable constituent
parts with the appropriate organization and causal powers to
sustain that organization.
The mechanistic account of explanation is a typical
example of the realist interpretation of scientific models.
According to realism, a model explains the behavior of a
target system, if and only if it is a correct account of the
target’s behavior underlying observed phenomena – i.e. the
model must correspond to, depict or represent the target
system in a sufficiently correct way. In addition, many
current realist accounts require that the target systems are
actual or real – i.e. have causal power to generate
observable phenomena and data.
However, models are always more or less abstract,
simplified and idealized descriptions of their real world
target systems. Target systems are just too complicated to be
studied in a full fidelity, and thus all kinds of assumptions
are made to reduce the complexity of a model. Thus most (if
not all) models used in science are unrealistic. Often models
are nevertheless considered useful, even if they are known
to be false, and they are known to contain assumptions that
are not even approximately true, but highly idealized. For
this reason, it has been argued that this feature of modeling
seriously undermines the realist interpretation of models. If
all models involve unrealistic elements, how is it possible
that they could correspond, depict or describe the real world
target system in a correct or truthful way? If they do not,
where does their explanatory force come from?
Sometimes models involve assumptions about fictional
entities and processes that are known not to exist in the real
world. These fictional models describe systems that (i) do
not exist in the real world or (ii) have elements that do not
exist in the real world. Obvious examples of fictional
models in cognitive science are for instance the models of

Abstract
The increasing use of computational modeling and simulation
methods offers interesting epistemic and theoretical
challenges for the philosophy of science. One of the main
questions discussed in the philosophical literature relates to
the explanatory role of false, unrealistic and sometimes even
fictional models. In this paper we argue that (i) some fictional
models can offer explanations known as structural model
explanations, and (ii) at least some variants of realism, such
as the information semantic account of scientific models, can
consistently hold that this subset of fictional models are
explanatory.
Keywords: Models;
information semantics

fictional

models;

explanation;

Introduction
For a philosopher of science interested in the philosophical
issues of modeling, cognitive science is a wonderful source
of case studies. Cognitive science utilizes modeling in a
unique way, both methodologically and theoretically. The
increasing use of computational modeling and simulation
methods offers interesting methodological challenges for
scientists, but also philosophers of science find many things
of interest in the theoretical and epistemic status of
modeling methods.
One of the main questions discussed in the philosophical
literature relates to the explanatory role of models. A
growing number of philosophers have proposed that
explanation of the behavior and capacities of complex
systems (such as those found in the cognitive, biological and
neurosciences) does not typically involve natural laws, but
specific models of particular mechanisms (Bechtel and
Richardson, 1993; Craver, 2006, 2007; Machamer, Darden,
and Craver, 2000). It has also been argued that this
mechanistic account of explanation could be extended to
cover explanations in cognitive science (Kaplan & Craver,
2011, Sun, 2008) and computer sciences, as well as
computational neuroscience (for instance, Piccinini, 2007).
According to this account, to explain a phenomenon is to
construct a model of how a causal mechanism - a
hierarchical system composed of component parts, their

941

artificial intelligence1. These hypothetical (at the time of
their conception) systems offer an example of modeling,
which starts with explicitly fictitious entities – non-existing,
imaginary cognitive systems - and then converts these
fictions into the fact-like platforms from which further
research can be done.
Although there is a growing consensus among
philosophers that fictions have a legitimate role to play in
science, traditionally those philosophers who endorse
realism have denied that fictional models could explain. For
a realist, the main obstacle to admitting that also fictional
model can be explanatory is that it is difficult to imagine
how a model without an existing target system could be
explanatory. Instead, fictional models have been treated as,
for example, only tools for generating and calculating
predictions.
However, it seems to us that for example the models
offered by AI are more than mere “tools for prediction”.
That these fictional models can be converted into real
working systems does require that they get some principles
of cognition “right” (a fictional AI model that is completely
unrealistic has little hope of successful implementation).
And they do seem to work more like blueprints or
instructions for a design than simply devices for predictions.
Not only do they offer structural information about the
constitution of a model system, but they also restrict and
guide the construction process itself – and not in an arbitrary
manner.
For this reason it seems intuitively plausible to think that
these models do hold a potential to represent or explain
something about cognitive systems. In this paper, we argue
that (i) these models explain by showing how the structure
of a model limits what sorts of objects, properties, states, or
behaviors are admissible within that model, and they offer
explanations known as structural model explanations
(Bokulich, 2008, 2009). In addition, we argue that (ii) at
least some variants of realism, such as the information
semantic account of scientific models, can consistently hold
that this subset of fictional models are explanatory.
However, (iii) whether or not a fictional model can be
explanatory, depends also on the relationship of the fictional
models and the real world 2.

produce predictions, and the question whether or not models
are realistic or unrealistic, does not arise.
In contrast to instrumentalism, the realist interpretation of
explanatory models holds that entities/processes the model
posits actually exist and that there is an objective
relationship between the model and its target system. In
addition, many current realist accounts of explanatory
models require that the target system must be actual or real.
Following Salmon, many philosophers of science agree that
to explain a phenomenon is to describe the actually
existing/causal processes that constitute the phenomenon
(Salmon, 1984). According to this view, only descriptions
of actually existing genuinely causal processes can lead to
scientific explanations3 (Salmon, 1984).
Aboutness. A realist typically thinks that the relationship
between a model and its target, the aboutness of scientific
models, is essential to their explanatory power. A scientific
model can explain the behavior of a target system if and
only if it depicts, describes or represents the target system.
For example, the mechanist account of explanation is a
typical variant of realism in this sense. According to it
explanation involves constructing a model of such
mechanisms that correctly depicts or describes the causal
interactions among their parts that enable them to produce
the phenomena under various conditions. The relationship
between a model and its target is seen, for example, as “one
of approximate similarity” (Glennan, 2000) in a way, where
“the behavior of the system in nature is described (to
varying degrees of approximation) by the model's
behavioral description and the internal structure of the
system is described (again to varying degrees of
approximation) by the model's mechanical description”, or
as “correspondence” (Craver), because (emphasis added) “
in succesfull explanatory models… (a) the variables in the
model correspond to components, activities, properties and
organizational features of the target mechanism that
produces, maintains, or underlies the phenomenon, and (b)
the… dependencies posited among these variables in the
model correspond to the… causal relations among the
components of the target mechanism” (Kaplan & Craver,
2011; see also Craver, 2006).
Following Giere (1988), both Glennan (2000) and Craver
& co (2006, Kaplan & Craver, 2011) seem to think that the
relationship - “the aboutness”- is some kind of similarity or
correspondence relation. But as Quine (1969) pointed out,
similarity is a vague notion, and correspondence is actually
not much better. In order to specify these concepts, many
philosophers of science have appealed various “morphisms”
– iso-, partial- or homomorphisms. However, all these
various morphisms, similarities and correspondences are
usually discussed only intuitively and philosophically
problematic4. They have been critized on logical and

Requirements for Realistic Interpretation
Scientific models can be interpreted realistically and
instrumentally. The instrumental interpretation, roughly,
holds that scientific models are instruments for generating
predictions about the system´s behavior. According to the
instrumentalist interpretation, the models are only used to
1

The aim of AI is not only to help us investigate the existing
cognitive systems by simulating them, but also to help us to
investigate and understand the structure of cognitive systems by
producing or to creating artificially new kind of cognitive systems.
2
Not all fictional models are explanatory, and some of them are
useful as calculational devices, other as prototheories and some are
useful in generating predictions etc., but not explanation.

3

For example, the ontic version of mechanistic explanation
requires that the mechanistic organization of the target system
causally produces the phenomenon to be explained.
4
There is a huge debate on this issue in philosophy of modeling.
See for instance, Suárez, 2003; Frigg, 2006.

942

substantial grounds5. One particularly difficult problem for
these accounts is the problem of relevance: a model
typically cannot be perfectly “similar” or “isomorphic” with
respect to every entity and every relation in the target
system, since almost any target system is too complex. This
implies that models should be “sufficiently isomorphic” or
“sufficiently similar” to the target “in the relevant respects”.
However, it is quite tricky to characterize “sufficiency” and
“relevance” in a non-circular and precise manner 6.
There are also some other variants of realism in which
the relationship between a model and its target is defined in
a different way. According to the information semantic
account7, models depict, describe, represent or are about
their target systems, if and only if there is an appropriate
information-content relationship between a model system
and its target. The information connection is implemented in
a model building process, in which data about the world is
incorporated to the model i.e. the information relationship
between a model system and its target is implemented in
empirical data, which carries the information about the
target system into the model.
The actual existence of target systems. As the variants of
realism typically do, also the information semantic account
requires the target systems must be actual or real. Because
in information semantics “carrying information” is
understood in terms of statistical dependence (Shannon,
1948; Usher, 2001), and statistical dependence is usually
understood in causal terms, target systems must be “actual”
or “real”: they must have causal power to produce the data,
which carries the information which is incorporated into the
model during the model building process.
To summarize, the realist interpretation of explanatory
models requires that an explanatory model (i) represents,
depicts or describes the explanatorily relevant features of
target systems in a “correct” way, and that (ii) target
systems are real and actual. Some variants of realism, such
as the information semantic account, require also that (iii)
the target systems have appropriate causal properties.
However, most, if not all, models used in science are
unrealistic, and sometimes even known to be strictly false
because of the abstraction, simplification and idealization
and the postulation of fictional entities that goes on in the
model building process. This raises the epistemic problem
for realism: if models include all these kinds of sources of
false assumptions, how can they be explanatory? How,
exactly, are these models are used to gain information or
knowledge about the real world phenomena?

system, and this model system is, or is thought to be, a
hypothetical representation of a real world target system.
These model systems are always more or less unrealistic
descriptions of their real world target systems, because
target systems are too complicated to be studied in every
detail. This is typically motivated, rhetorically, on pragmatic
grounds. If all the parameters were included in models, they
would become too complicated to be understandable,
tractable or useful. As McClelland (2009) puts it, “the more
detail we incorporate, the harder the model is to
understand.”
There are at least four different ways to make models
unrealistic: abstraction, simplification, idealization and
fictionalization. In practice, this distinction between these
types is not always entirely clear. Moreover, these classes
are not exclusive. Models can, and often are, abstracted and
idealized at the same time9. For example, a Turing Machine
can be seen as an abstraction of real computations 10,
because it neglects many computationally irrelevant features
of computational systems, such as the material basis of the
implementing mechanisms. If a Turing Machine is also
defined to have properties that are not implemented in any
real computational system (unlimited memory, unlimited
processing time), it is assumed to never break down and so
on, it also involves idealization.
Abstraction and simplification can be considered to be
species of information reduction. Roughly speaking, an
abstract model is the result of the process of abstraction, in
which information about domain-external factors is
disregarded11 (e.g. a model of a ball rolling on an inclined
plane may abstract away the color of the ball, which is not
in the domain of Newtonian dynamics). A simplified model
is a model, in which some domain-internal factors are given
a simplified description (e.g. the ball may be considered a
perfect sphere, with the center of gravity in perfectly in the
middle). Although abstracted or simplified models do not
describe all the factors, they describe correctly or
approximately certain features of their target systems.
Abstracted and simplified models can thus be genuinely
explanatory, if they accurately depict the relevant properties
of their target systems. These models tell us how
phenomena behave in a simpler world than our own 12, or
these models can work as surrogate systems13 for
understanding, how fundamental properties of a system

9

See Thomson-Jones (2005) for the distinction between
abstraction and idealization.
10
See Piccinini, 2007.
11
An abstract model is sometimes described as a model, in
which only some factors or only some of potentially many factors
of target system are included into a model system. A simplified
model is a model, in which only some factors of the potentially
many factors that are relevant to the behavior of a target system
are included into a model or some factors are given a simplified
description.
12
This idea is explicated by Stephan Hartmann, but the authors
did not find the article, in which this idea was presented.
13
The term “surrogate” is borrowed from Uskali Mäki (2009).

The different ways to make a model
unrealistic
In practice, when scientists present a model, they offer a
model system8 which is a description of a hypothetical
5

See Suárez, 2003; Frigg,2006; See also Rusanen and Lappi,
2011.
6
Suárez, 2003; Frigg,2006, see also Rusanen & Lappi, 2011.
7
Rusanen & Lappi, 2011.
8
The term “model system” is from Frigg (2006, 2010).

943

generate or produce the certain phenomenon of interest by
helping scientists to formulate correct what if- inferences.
However, philosophers of science disagree on the
question, whether or not abstracted and simplified models
have more explanatory power than non-abstracted models.
There are at least two different views about the explanatory
power of abstracted models. One of them is the so-called
“traditional view”14, according to which the more exact,
more detailed, more complete and more realistic the model
is, better it is. The most explanatory model is the model,
which offers the complete description of the phenomenon of
interest. The non-traditional view maintains that in some
cases the abstracted model can explain better the dominant
and significant features of the target system, because it
isolates and emphasize the crucial elements in a tractable
way.
The third way to make a model unrealistic is idealization.
In idealization one is not only excluding parameters.
Instead, idealization involves distorting theories or models,
because at least one of the parameters of the target system is
represented in a way that makes the model false. For
example, if a model in cognitive science is used to analyze
the processing of a perceptual system scientists may
stipulate that all processing is described in the model as
linear and strictly feedforward15, even if in reality the
processing would be non-linear and have backforwarding
properties.
The fourth way to make models unrealistic is
fictionalization. Wide fictionalism16 states that idealization
and abstraction are subspecies of fiction (Suárez, 2009).
However, there are reasons to argue that models that are
only simplified, idealized and abstracted representations of
real entities (about which they make counterfactual claims)
should be distinguished from those which refer to fictional
entities which do not actually exist. Logically speaking,
there is a difference in kind between a representation of real
entity and a representation of an imaginary entity (Russell,
1905, Suárez, 2009)17.
Narrow fictionalism takes it that only those models which
involve or describe explicitly fictional or imaginary entities,
systems and situations that do not actually exist in real
world, are fictional (Suaréz, 2009). Such models do not only
involve idealization, simplification or abstraction, but they
are, and also known to be false, for a further reason: because
they describe fictional or imaginary entities, systems and
situations that do not actually exist in real world.

Completely fictional models refer to model systems that
do not actually exist in the real world and do not have any
real components. It is difficult to find a genuine example of
a completely fictional model in natural or behavioral
sciences, because in these sciences most (and probably all)
fictional models include at least some real world elements at
some level of analysis.
Actually, fictional models are typically only partially
fictional models. Often partially fictional scientific models
are combinations of real and fictional components.
Sometimes these models refer to real target systems, but
they are fictional, because they include some components or
system level descriptions that are taken to represent nonexisting entities. For example, the frequency components in
the wavelet analysis of EEG components, which are used to
explain the synchronization properties of neuron population
in neurosciences are typically interpreted as non-existing
entities.
Some of partially fictional models consist of realistic
constituents, but the combination of constituents is known
to be unreal. Some of these model systems may describe
systems that are in principle physically possible, or
sometimes they are physically impossible, because they
violate natural laws etc. Typically these models are used to
test the possible behavior of a complex system by creating
all kinds of what-if simulations. An example of a model of
this sort is the model of xDNA18. All of the components of
model can be given a real world interpretation, but the
combination of these components, xDNA, is unrealistic.
The study of artificial intelligence offers another example
of modeling of this sort. For example, if a cognitive scientist
wanted to build synthetic brains, she might end up building
a model system that does not mimic or simulate any existing
brains. Although the design or the computational layout of
the artificial brains was novel, the model system might
involve elements, which refer to real world entities, such as
cells, cell organs, transmitters, or depending on the material
implementation, silicon chips, batteries and so on. In
addition, if the model system would then be implemented in
a concrete way, then a model system of a fictitious entity
would have been converted into an actual model organism.
Although the current study of artificial intelligence is not
developed to that point, are already existing artificial
cognitive systems examples of modeling, which starts
explicitly fictitious, non-existing entities – the imaginary
cognitive systems - and then convert these fictions into
the fact-like platforms from which further research can
be done. Because these fictional models can be converted
into fact-like platforms, fictional models seem to work
more like blueprints or instructions for a design than
simply devices for predictions. Not only do they offer
structural information about the constitution of a model
system, but they also restrict and guide the construction
process itself. For this reason it seems intuitively to think

14
The terms “traditional view” and “non-traditional” are from
Batterman, 2009.
15
See, for example, McLelland (2009) for a detailed analysis of
simplification and idealization of this sort.
16
About the difference between wide and narrow factionalism, see
Suarez 2009.
17
As Suárez (2009) has proposed, one way to describe the
distinction is to emphasize the difference between ”fictional” and
”fictive” representations. A fictional representation is a
representation of a non-existing entity, and a fictive representation
is an inaccurate representation of a real entity (Suárez, 2009).

18

This example is from Michael Weisberg`s presentation in
Helsinki in May 2009. Actually, as also Weisberg mentioned in his
talk, there is no such a model in biology.

944

that these models do explain. They seem to explain by
showing how the structure of a model limits what sorts of
objects, properties, states, or behaviors are admissible
within that model. They also show that whatever the system
can do is in fact a consequence of that structure and they
also offer information about how the converted system
will behave before it has been converted

However, Bokulich´s characterization may be a bit too
broad. For this reason, we´d like to add one crucial
requirement for model explanations. In order to count as
genuinely explanatory a model explanation must also be
credible. Characterizing the credibility is, of course, a
challenging task, and there are different suggestions in the
literature. For example, according to Sugden (2000) models
are artificial "worlds" i.e. "surrogate systems’", and their
epistemic dimension is based on inductive extrapolation
from these artificial worlds to the real world. In Sugden´s
account the relationship between models and the world can
be evaluated in terms of similarity; more similar to the real
world a model is judged to be, more credible it is. However,
similarity alone is usually not sufficient for establishing
credibility20.
For this reason, credibility considerations must be based
on more fundamental claims. According to the information
semantic account (Rusanen & Lappi, 2011) the credibility of
a model explanation requires that there is, or it is at least
possible to imagine, a causally implemented information relationship between a model and its target and a credible data
gathering method for that particular model. Information
semantic account requires that there is an appropriate
information relation between a model and its target. For this
reason, if a model is credible, there must exist or it must be
possible to imagine a causally implemented information
relationship between a model and its target. Because of this,
from an information semantic view, completely fictional
models, arbitrary models or models, which have only unrealistic constituents, are not explanatory. Instead, only such
partially fictional models can offer model explanations, in
which the constituents of a model system are realistic. These
constituents should (at least to certain extent) refer to/ carry
information about real world elements and this information
relationship could be, in principle, implemented in data.
So, the final problem is: How is it possible that a fictional
model can carry information about the real world? As
philosophers of cognitive science know, a structurally
similar problem, the problem of uninstantiated properties,
plagued the early versions of information semantics in
philosophy of mind. In a nutshell, the problem was the
following: If A does not carry information about B, it is not
a representation of B. So, if B is a non-existing,
uninstantiated entity or a property, A cannot carry
information about it, and thus A is not, strictly speaking, a
representation of B. However, there are still terms, such as
unicorns or pegasuses, which clearly have semantic content,
even if their referents do not exist. We can attribute
properties to these non-existing entities; we can make
thought experiments on them and so on. So, if these terms
have no existing targets, how do these terms have their
semantic properties? What is the basis for the meaning of
these terms?
Jerry Fodor proposed (1991) one possible solution for this
problem. On his view, these terms, such as “pegasus”, could
be seen as complex terms, which can be decomposed into its

Do Fictional Models Explain?
Alisa Bokulich (2008, 2009) has recently developed an
interesting account of scientific explanation, called “model
explanations” to describe the sort of explanation that is
being offered by fictional models.
Bokulich (2008;2009) characterizes these model
explanations as follows: First, the explanans of explanatory
fictions must make a reference to scientific model, which
involves some idealization and/or fictionalization. Second,
that model is taken to explain the explanandum by showing
that the pattern of counter-factual dependence in the model
mirrors the relevant respects of counterfactual dependences
in the target system. Following Woodward (2003), in
Bokulich´s account this pattern of counterfactual
dependence can be explicated in terms of “what if things
have been different- questions”19. That is, the explanation
must enable us to see what sort of difference it would have
make to explanandum if the factors cited in explanans had
been different in various possible ways. The third feature of
model explanations is that they must specify what the
domain of applicability of the model is and show that the
phenomenon in a real world to be explained falls within that
domain. If model explanations are characterized in this way,
one subspecies of model explanations are structural model
explanations (Bokulich, 2009).
A structural model explanation is one in which the the
explanandum is explained by showing how the structure of a
model limits what sorts of objects, properties, states, or
behaviors are admissible within that model, and then
showing that the explanandum is in fact a consequence of
that structure. A structural model explanation is thus an
explanation, in which the explanandum exhibit a pattern of
counterfactual dependence on the elements represented in
the model, and this dependence is a consequence of the
structural features of the model.
It seems to us that those partially fictional models that are
combinations of realistic parts offer structural model
explanations as Bokulich proposes. For example, a model of
artificial cognitive system characterizes why certain
cognitive processes are possible for a certain kind of
cognitive architecture, or how a possible computational
structure of certain type architecture will limit its possible
cognitive and computational capacities, before the system is
actually implemented.
19

While in Woodward´s manipulationist construal explanations
are restricted purely to causal explanations, Bokulich adds that not
all scientific explanations must be causal.

20

945

Kuorikoski and Lehtinen (2009) make a similar point.

Bokulich, Alisa (2008). “How Scientific Models Can
Explain”, Synthese 180 (1): 33-45 (2011).
Bokulich, Alisa. (2009). "Explanatory Fictions", in M.
Suarez (Ed.) Fictions in Science: Philosophical Essays on
Modeling and Idealization (Routledge, 2008: 91-109).
Craver, Carl (2006). When mechanistic models explain.
Synthese, 153: 355–376.
Dretske, Fred. (1981). Knowledge and the Flow of
Information. Cambridge, Massachusetts: MIT Press.
Fodor, Jerry A. (1991). Modal Argument for Narrow
Content. Journal of Philosophy 88 (1):5-26.
Frigg, Roman. (2006). “Scientific Representationand the
Semantic View of Theories.” Theoria 55: 49-65
Frigg, Roman (2010). “Models and Fiction”. Synthese
172(2), 2010, 251-268
Giere, Ronald. (1988). Explaining Science: A Cognitive
Approach. Chicago: University of Chicago Press.
Glennan, Stuart. (2000). “A Model of Models”.
Unpublished.
Kaplan, D.M. and Craver, C.F. (2011) “The Explanatory
Force of Dynamical Models” Philosophy of Science 78
(4): 601-627
Kuorikoski, Jaakko & Lehtinen, Aki (2009): Incredible
World, Credible Results. Erkenntnis 70: 119-131.
Mäki, Uskali (2009). "MISSing the world: Models as
isolations and credible surrogate systems", Erkenntnis,
vol. 70, no.1, 29-43
Piccinini, G. (2007). Computing mechanisms. Philosophy of
Science, 74: 501–526.
Rusanen, Anna-Mari & Lappi, Otto (2011). ”Information
Semantic account of Scientific Models”. In H.W. de
Regt, S. Hartmann and S. Okasha (eds) "EPSA
Philosophy of Science: Amsterdam 2009", Springer.
Russell, Bertrandt. (1905).”On denoting.”
Salmon, Wesley. (1984). Scientific Explanation and the
Causal Structure of the World, Princeton: Princeton
University Press.
Suárez, Mauricio (2003). “Scientific Representation:
Against Similarity and Isomorphism.”International
Studies in the Philosophy of Science, 17: 3, October 2003,
pp. 225-244.
Suárez, Mauricio. (2009b). “Fictions in Scientific Practice",
in M. Suarez (Ed.) Fictions in Science: Philosophical
Essays on Modeling and Idealization (Routledge, pp. 115.).
Sugden, Robert (2000): "Credible Worlds: The Status of
Theoretical Models in Economics", Journal of Economic
Methodology, vol. 7, no. 1, pp. 169-201.
Thomson-Jones, Martin. (2005). Idealization and
Abstraction: A Framework. In Jones, M. & Cartwright, N.
(eds). Idealization XII: Correcting the Model-Idealization
and Abstraction in the Sciences (Poznañ Studies in the
Philosophy of the Sciences and the Humanities 86)
Amsterdam/New York, NY, 2005.
Usher, Marius. (2001). “A Statistical Referential Theory of
Content: Using Information Theory to account for
Misrepresentation”. Mind & Language 16:311-334.

constituents (a horse and wings), and these constituents refer
to/carry information about the real world components. So,
these terms can have a meaning, because the constituents of
the terms can carry information about the real world.
Partially fictional models can be treated in a same way.
They are complex constructions, which can be decomposed
into constituents. If these constituents refer to/carry
information about the real world elements, they are realistic.
For that reason these models are not completely fictional,
although the complex composition of constituents would be
fictional. Because the constituents of partially fictional
models carry information about/refer to real world elements,
these models may indeed offer structural model
explanations.

Concluding Remarks
There are at least four different ways – simplification,
abstraction, idealization and fictionalization - to make
models unrealistic, not all of them make models false in a
way that is problematic for the realist. Even if in practice the
difference between these types is not always clear, they
should be treated separately. They have different
implications for the explanatory power of a model. For
example, although simplified or abstracted models do not
describe all the factors or all the relevant factors of target
systems, they describe certain some features of their target
systems. Depending on their degree of truthlikeness they
can be more or less explanatory. In this paper we argued
that also fictional models may explain by showing how the
structure of a model limits what sorts of objects, properties,
states, or behaviors are admissible within that model, and
they offer explanations known as structural model
explanations (Bokulich, 2008, 2009). However, whether or
not a fictional model is explanatory, depends also on the
relationship of the fictional model and the real world. Only
such partially fictional models that have constituents, which
can carry information/refer to real world elements, can be
explanatory. Completely fictional models, arbitrary models,
or models with only unrealistic constituents do not explain.

Acknowledgements
The members of POS and TINT, the audience of EPSA
2011 and the anonymous referees for commenting an earlier
draft of this paper.

References
Ankeny, Rachel (2009). “Model Organisms as Fictions”. In
M. Suarez (Ed.) Fictions in Science: Philosophical Essays
on Modeling and Idealization (Routledge, pp. 158-178.)
Batterman, Robert. (2009). Idealization and Modeling.
Synthese 169 (3):427 - 446.
Bechtel, William & Richardson, Robert (1993). Discovering
Complexity, Decomposition and Localization as
Strategies in Scientific Research. New Jersey: Princeton
University Press.

946

