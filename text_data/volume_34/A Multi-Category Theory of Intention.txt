UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Multi-Category Theory of Intention
Permalink
https://escholarship.org/uc/item/5hs5d1wm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Admoni, Henny
Scassellati, Brian
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                        A Multi-Category Theory of Intention
                      Henny Admoni (henny@cs.yale.edu) and Brian Scassellati (scaz@cs.yale.edu)
                                           Department of Computer Science, 51 Prospect Street
                                                          New Haven, CT 06511 USA
                              Abstract                                    in these different ways, we introduce two novel terms, re-
                                                                          ferring to intention attributions made from low-level cues as
   People excel at attributing intentionality to other agents,            L-intentionality and to attributions made from high-level cues
   whether in simple scenarios such as shapes moving in two di-
   mensions or complex scenarios such as people interacting. We           as H-intentionality. To date, little work has explored such cat-
   note that intentionality attributions seem to fall into two cat-       egorical differences of intentionality. In the Types of Inten-
   egories: low-level intentionality in which an observer has a           tionality section, we use examples from previously published
   theory of mind about an agent, and high-level intentionality
   in which an observer believes the agent has a theory of mind           research to define our hypothesis that L-intentionality and H-
   about something else. We introduce the terms L-intentionality          intentionality are separate kinds of intention attributions.
   and H-intentionality to refer to these attributions, respectively,
   and describe this division by using examples from previous re-            Robotics has provided a valuable experimental platform
   search. Social robots provide a particularly good platform for         to test perceptions of intentionality. Because robots are ex-
   evaluating the presence of different types of intentionality, and      tremely flexible (in terms of appearance, motions, sounds,
   we discuss how robots can help distinguish the relationship be-
   tween H- and L-intentionality, based on a number of possible           and so on), researchers can manipulate specific variables of a
   models that we enumerate. We conclude by highlighting some             human-robot interaction to test specific features of intention-
   interesting questions about intentionality in general and the in-      ality attributions. In the Social Robots as Experimental Plat-
   terplay between H- and L-intentionality in particular.
                                                                          forms section, we describe past work with robots and other
   Keywords: intention; animacy; computer model; human-
   robot interaction; robotics                                            computational models of intentionality, and we discuss the
                                                                          benefits social robotics can offer intentionality research.
                          Introduction                                       The next section, Models of Intentionality, enumerates pos-
                                                                          sible models for the relationship between H-intentionality and
Much research in psychology has focused on people’s                       L-intentionality based on the hypothesis that these are distinct
ability—and eagerness—to attribute intentions and animacy                 observations. We describe what each model implies about
to simple shapes based on motion. From Michotte’s (1963)                  real-world intentionality attributions, and we note how each
and Heider and Simmel’s (1944) experiments with animacy                   model can be tested to confirm or deny our hypothesis.
and intention to recent work decomposing intentional actions
                                                                             We conclude this paper by discussing some likely starting
such as chasing (Gao, Newman, & Scholl, 2009), psycholo-
                                                                          points for research on the different categories of intention,
gists have found that intention attributions to moving shapes
                                                                          and describing some interesting questions about intentional-
appear to be immediate and irresistible. Animacy is often ob-
                                                                          ity that have yet to be addressed.
served in a display of simple shapes when the motion in the
display cannot be explained as ordinary inanimate motion,
for instance when speed and direction change without direct                                 Types of Intentionality
contact with other objects (Tremoulet & Feldman, 2000).
   At the same time, evidence shows that people attribute in-             In this paper, we define an intentional action as a goal-
tentions based on high-level behavioral evaluations, as well.             directed action that is performed deliberately. Intentional-
For instance, 18-month-old toddlers can recognize and imi-                ity is the capacity to express or perform intentional actions.
tate intentional actions performed by adults, even if those ac-           A theory of mind for other agents enables us to attribute
tions are unsuccessful (Meltzoff, 1995). By pre-school age,               intentionality to those agents (Leslie, 1987; Baron-Cohen,
children begin to represent others’ beliefs, even when those              1995), an ability that develops early in life (Meltzoff, 1995).
beliefs are mistaken, in order to correctly predict a person’s            Note that for our purposes, animacy and intentionality are
intentional action (Wellman, Cross, & Watson, 2001). As                   strongly correlated, in that it is impossible to attribute ani-
adults, neurological evidence indicates that a certain region of          macy without the presence of intentional, goal-directed be-
the brain is sensitive to whether peoples’ motions are consis-            havior (Tremoulet & Feldman, 2006).
tent or inconsistent with their purported intentions (Pelphrey,              In this section, we distinguish L-intentionality and H-
Morris, & McCarthy, 2004).                                                intentionality as distinct but related categories. We can define
   While abundant evidence demonstrates peoples’ attribu-                 each category by how an observer perceives and recognizes
tions of intentionality, the types of attributions they make              intentionality. To put the categorical difference simply, L-
seem to differ. Cues that prompt intention attributions come              intentionality in an agent involves an observer having a theory
in two categories: low-level, perceptual cues, such as mo-                of mind for that agent; H-intentionality involves an observer
tion, and high-level cues that must be reasoned about, such               believing that the agent has a theory of mind for something
as facial expression. To distinguish between intentions cued              else (Figure 1).
                                                                      1266

                                                                        ered cubby. While his mother looks away, Billy retrieves the
                                                                        shoes, walks to the chest, looks to make sure his mother is not
                                                                        watching and puts his shoes in the closed chest. The action
                                                                        of watching his mother put the shoes in one place, and then
                                                                        covertly moving them to another, suggests that Billy has a
                                                                        theory of mind for his mother, understanding that she has her
                                                                        own (mistaken) beliefs; Billy is displaying H-intentionality.
                                                                           While L-intentionality is based on a theory of mind for the
                                                                        agent in question, H-intentionality is based on that agent’s
                                                                        theory of mind for others. Therefore, H-intentionality is
                                                                        seen in more complex visual scenes than the simple mov-
                                                                        ing shapes of L-intentionality; it is often be cued by a com-
                                                                        bination of stimuli such as facial expression, vocal prosody,
Figure 1: Low-level intentionality (left) is attributed when            and physical motion. H-intentionality does not “pop out” in
an agent has a theory of mind for another agent. High-level             the same way as L-intentionality because attributions of H-
intentionality (right) is attributed when an agent believes an-         intentionality require additional cognitive processing to ac-
other agent has a theory of mind for something else.                    count for the agent’s beliefs about its environment.
                                                                             Social Robots as Experimental Platforms
L-Intentionality
                                                                        Experiments with human-robot interaction are a particularly
To illustrate the different types of intentionality, picture a pre-     rich source of intentionality attributions. In one experiment,
school boy named Billy. Billy is good at putting away his               a robot received greater attributions of animacy and intelli-
toys: he readily brings them to the toy chest whenever it               gence when it cheated at a game of rock-paper-scissors than
is time to clean up. This kind of goal-directed behavior—               when it played the game correctly (Short, Hart, Vu, & Scas-
carrying toys directly to the toy chest and depositing them—            sellati, 2010). In each round of the game, a human partici-
involves a series of coordinated actions and knowledge, but             pant and the robot both selected an item (rock, paper or scis-
it can occur independently of theories of mind about others             sors) in secret, then simultaneously displayed their selection
in the environment. Observing this, we might attribute L-               through hand signals. Each of the items loses to one other
intentionality to Billy. (Assume for the sake of the example            item and wins over one other item, so that one’s performance
that we cannot infer that Billy is H-intentional based solely           in the game depends on the opponent’s selection as well as
on what we know about human beings.)                                    one’s own. In conditions where the robot verbally cheated—
   Actions that cue L-intentionality reveal goal-directed, de-          declaring “I win!” when it had lost—participants tended to
liberate behavior. L-intentionality is often elicited from low-         report that the robot was broken and less intelligent; in condi-
level perceptions, such as those arising from visual displays           tions where the robot physically cheated—changing its los-
of moving shapes. The perception of intentionality and ani-             ing hand signal after viewing the participant’s selection—
macy from simple moving shapes has been well-established                participants were significantly more likely to use active verbs
in psychology literature (see (Scholl & Tremoulet, 2000) for            when describing the robot. In other words, a small change in
a review); even when people do not know the type of in-                 behavior (switching hand signals) led to a dramatic increase
tentional action they are looking for, they show high valid-            in intentionality attributions.
ity with the ground truth and high reliability with each other             Social robots are a valuable platform for experiments in-
when evaluating the motion of animated shapes (Pantelis et              volving intentionality. Robots are available in a huge vari-
al., 2011). Most often, these shapes exhibit basic actions such         ety of appearances (from anthropomorphic to simple shapes)
as chasing, fighting, or foraging.                                      and motion abilities (fully mobile to stationary; with a broad
   For example, in Gao et al. (2009), an animated “wolf”                range of physical capabilities). Being programmable, robot
chases after an animated ”sheep” by moving toward the sheep             behavior can be carefully manipulated to alter individual fea-
within some degree of direct heat-seeking behavior. When                tures (such as moving an arm at a particular speed) and to
the degree of chase is sufficiently small, participants identify        ignore subtle (and potentially subconscious) social cues from
chasing consistently. When the wolf deviates more strongly              others, a feat that a human experimenter might find difficult.
from direct heat seeking, however, the perception of inten-             As machines, robots can perform exactly the same action
tionality disappears. In these L-intentionality experiments,            again and again, but as social tools, robots appear socially
goal-directed motion leads to an attribution of intentionality.         neutral: while most participants in experiments from our lab-
                                                                        oratory have seen or heard about robots, most have no expe-
H-Intentionality                                                        rience with actual robot capabilities, allowing robots to act a
Now imagine that we observe Billy hiding his shoes inside               blank slate on which social characteristics (such as intention-
the toy chest. He watches his mother place his shoes in a cov-          ality) can be drawn at will.
                                                                    1267

    Animations or videos of people provide many of the same
benefits as robots, but they lack an embodiment that may
affect interactions. Research has shown that people follow
commands more consistently from physically present robots
than from virtual robots, even when the virtual robot looks
and acts exactly like the embodied robot (Bainbridge, Hart,
Kim, & Scassellati, 2011). This reflects the common wisdom
of sales, which asserts that you should visit someone in per-
son to close a deal. For intentionality research, in which sub-
tle features may make a difference in intention attributions,                                     (a) Disjoint
having an embodied agent observed in real time allows for
highly realistic experimental setup while maintaining strict
control over experimental variables.
    H-intentionality has been of particular interest to social
robotics researchers, who are motivated to design human-
robot interactions that are natural and communicative. One
part of natural interaction is identifying and displaying a the-
ory of mind for others through non-verbal intentional be-
havior, whether with gaze (Mutlu, Yamaoka, Kanda, Ishig-
                                                                                           (b) Partially overlapping
uro, & Hagita, 2009), hand gestures (Nehaniv, Dauten-
hahn, Kubacki, Haegele, & Parlitz, 2005), or facial expres-
sion (Breazeal & Scassellati, 1999). Therefore, understand-
ing intentionality is important for the design of robots that
will interact with people, such as service or assistive robots.
                 Models of Intentionality
In this section, we enumerate the possible relationships be-
tween H-intentionality and L-intentionality (Figure 2); in the
following Discussion section, we explain which models we                              (c) Nested, bottom-up perception
believe are most viable. To better describe the models, we
will return to the previous example with Billy and his toys.
    Researchers have attempted to computationally recognize
intentions through Bayesian models (Baker, Tenenbaum, &
Saxe, 2006; Schrempf, Albrecht, & Hanbeck, 2007), hid-
den Markov models (Aarno & Kragic, 2006), and algorithmic
methods (Feldman & Tremoulet, 2008). As observed actions
and possible intentions become more complex, specifying a
reasonably-sized state space for intention-action mapping be-
comes increasingly challenging, which limits the power of                             (d) Nested, top-down perception
current computational models of intention recognition. The
models in this paper are intended to be abstract, high-level
views of how intention attributions can be conceptually orga-
nized, not algorithmic specifications for functional programs.
    The descriptions of the models in this section are based on
features of intentionality—observations that can be empiri-
cally measured. For instance, goal-directed movement toward
another agent in an approximately heat-seeking manner (as in
Gao et al. (2009)) is one feature of chasing, an L-intentional
action. Behavior based on anticipation of others’ responses,                                       (e) Equal
as when Billy looked to see whether his mother was watch-
                                                                     Figure 2: Potential models of the interaction between H- and
ing him hide his shoes, is a feature of H-intentional actions.
                                                                     L-intentionality. Each labeled circle represents the set of fea-
Many features for each type of intention have yet to be iden-
                                                                     tures that cue that type of intentionality. Set notation be-
tified, and are part of the novelty of this area of research.
                                                                     low each image mathematically describes the relationship be-
    Of all of the models for the relationship between H- and         tween H, the set of features that cue H-intentionality, and L,
L-intentionality, the simplest option is that there is no cor-       the set of features that cue L-intentionality.
                                                                 1268

relation between the two (Figure 2a). In this model, the                distinct types of intention attributions, if proven, might indi-
two types of perceptions share no features. Seeing Billy                cate a categorical distinction that runs more deeply in peo-
put his toys in the chest (and subsequently attributing L-              ples’ cognitive systems. H-intentionality and L-intentionality
intentionality to Billy) would not affect later judgements              may not only be perceived differently; they may be under-
about H-intentionality, and vice versa. In the disjoint case,           stood and processed in different ways as well. After all, if the
recognizing a feature of one type of intentionality would im-           perceptual pathways for the two types of intentionality are
mediately identify the type of intentionality present, because          different, perhaps the cognitive pathways that process them
that feature could not correspond to the other type of inten-           are also different. Perhaps there are distinct brain regions or
tionality. To falsify this model, researchers must to show that         neural pathways that process L-intentional and H-intentional
both H- and L-intentionality are cued by some feature.                  stimuli. Perhaps, even, there is a different developmental
   A second possibility is that the two types of intentions             time course for each type of intentionality, and infants can
share some features, but do not overlap completely (Figure              perceive one type of intentionality before the other. This dif-
2b). In this case, seeing shared features would cue both types          ference might even extend to the perception of one agent as
of intentionality attributions, though not every feature would          more complete or more animate than another, based on the
be a shared feature. Identification of shared features would            type of cues that were used to establish its intentionality. All
not confirm which type of intention is being perceived, but             of these possibilities are consequences of our two-intention
identification of disjoint features would allow experimenters           hypothesis, and will need to be further explored.
to pinpoint the type of intention present. To prove that this              Understanding intentionality is also important for design-
model is correct, researchers would have to identify one fea-           ing human-robot interactions. For robots that must interact
ture that is unique to each type of intentionality, and one fea-        naturally with people, being able to both recognize and per-
ture that is shared by both types.                                      form intentional behavior is essential. To date, most computa-
   Another possibility is that the types of intention are nested,       tional approaches for intention recognition rely on statistical
so that one is wholly contained in the other. In the first              or probabilistic methods that do not scale well with increas-
form of nesting, which we’ll call bottom-up perception, H-              ing actions and intentions. Our model is a first step toward
intentionality features are a strict subset of L-intentionality         comprehensive understanding of intentionality that may lead
features (Figure 2c). In this case, L-intentionality is cued            to more complete and flexible computational models.
whenever H-intentionality is perceived, though the former                  If cognitive differences underlie the different kinds of in-
can be present without the latter. In our example with                  tentional attributions, these differences can be manipulated
Billy, merely perceiving H-intentionality—from watching                 in interesting ways for human-robot interactions. Because
Billy hide his shoes—would be enough to perceive L-                     robots are programmable, they can be made to display only
intentionality, even without watching Billy put away his toys.          cues from one type of intention, leading an observer to cog-
This model can be falsified by identifying a scenario in which          nitively categorize them in a particular way. For instance,
H-intentionality but not L-intentionality is perceived.                 suppose researchers establish that unfamiliar L-intentional
   The complementary model posits that L-intentionality fea-            agents do not invoke as much shyness or fear as H-intentional
tures are a strict subset of H-intentionality features (Figure          agents, by virtue of their apparently less complicated mental
2d). We call this top-down perception, because the more com-            structure. Robots that interact with children can then be ma-
plex H-intentionality can be cued without L-intentionality.             nipulated to display only L-intentionality cues, reducing the
In this model, H-intentionality is automatic whenever L-                likelihood that children will be afraid of them by controlling
intentionality is perceived. This model can be falsified by             how they are perceived. The ability to craft human-robot in-
identifying a feature of L-intentionality that does not cue H-          teractions in a completely unprecedented way becomes pos-
intentionality.                                                         sible if the categorical difference between intention types ex-
   A final possibility is that the feature sets of H-intentionality     tends to cognitive processing levels.
and L-intentionality are equal; that is, there is no difference
between the features involved in cueing each type of inten-                                       Discussion
tionality. In this model, H-intentionality arises whenever L-
                                                                        Based on our distinction between H- and L-intentionality,
intentionality is cued, and vice versa. To falsify this model,
                                                                        some models are more likely than others. Clearly, a model in
researchers would need to identify at least one feature from
                                                                        which the feature sets for both intentionality types are identi-
one type of intentionality that does not cue the other. Fail-
                                                                        cal is impossible if we are to maintain the distinction between
ing to falsify this model would challenge the hypothesis that
                                                                        the two. We previously defined attributing H-intentionality
H-intentionality and L-intentionality are separate processes.
                                                                        to an agent as believing that the agent has a theory of mind
                                                                        for some other target. Inherent in this definition is the idea
       The Importance of Intentional Duality
                                                                        that we also believe the agent in question has its own goals
Researchers have long established that people attribute inten-          and is capable of intentional actions to achieve those goals;
tionality to other people and to simple moving shapes under             in other words, that we have a theory of mind for that agent.
some conditions. The existence of H- and L-intentionality as            Therefore, L-intentionality seems to be inherent in attribu-
                                                                    1269

tions of H-intentionality. For this reason, the disjoint model           Along the same vein, observing intentional actions from
and the overlapping model seem unlikely candidates for our            an outsider’s perspective may be different from identifying
purposes. If L-intentionality is inherent in H-intentionality,        intentionality based on actions that personally affect one’s
then it would be impossible for the latter to be perceived with-      self. Are attributions of intentionality different based on
out the former, which rules out the top-down model. In fact,          whether the effect of the action is personally relevant? Does
we believe that the bottom-up model (Figure 2c), in which             it matter if the personally relevant effect is positive or nega-
all features of H-intentionality are also features that cue L-        tive? Are there differences between H-intentionality and L-
intentionality, has the most promise as a model of intention          intentionality in these cases?
attributions. In this model, L-intentionality can be present             Animals, like robots, present an interesting boundary con-
on its own—as supported by the many intention-from-motion             dition for intentionality. Animals are clearly sentient and are
studies described in the Introduction—but the presence of             generally attributed beliefs and goals. Whether animals can
H-intentionality presupposes the presence of L-intentionality.        be said to be intentional, however, is open to debate (Heyes
For completeness, we have listed all possible models in this          & Dickinson, 1990). It would be interesting to determine
paper, but only the bottom-up model really serves the distinc-        whether animals fall into the L-intentional or H-intentional
tion we draw between H- and L-intentionality.                         category, and whether this separation of intention types might
   Though we distinguish between H- and L-intentionality,             make it easier to attribute intentionality to animals.
we have not made any claims about how these types of inten-              Descriptions of models in the previous section refer to fea-
tionality might be treated differently once they are perceived.       tures that cue intentionality, but the precise nature of these
Because our distinction is novel, we do not yet have evidence         features is still to be determined. These features need not
to ascertain whether or not H-intentionality affects peoples’         be exclusively visual; they might include auditory features
reasoning differently from L-intentionality. The characteris-         like prosody or kinesthetic features like heat. Some features,
tics of intentionality described here might vary based on the         such as “approaches a target with a velocity between x and
type of intentionality that is perceived.                             y” may be quite specific; these are often used in rule-based
   One characteristic that has yet to be explored is whether in-      intention detectors, but lack flexibility to account for novel
tentionality is revokable. Though many experiments identify           or stochastic situations. Other features might be more gen-
the presence of intentionality, very few explore conditions un-       eral, such as “orients eyes toward the target.” Enumerating
der which intentionality disappears. It is possible that once in-     and sorting these features into H- and L-intentionality cues
tentionality is perceived, it remains for the duration of the ex-     is a significant task, but it has the potential to dramatically
posure; on the other hand, perception of intentionality might         increase understanding about intention perception.
also fade or be removed through some mechanism, such as                  Identifying and evaluating features of intentionality will
time since the last intentional action. Anecdotal evidence            require carefully designed experiments, and robots as inten-
from our lab suggests that attributions of H-intentionality are       tional actors may be useful in teasing apart attributions of in-
hard to remove, while attributions of L-intentionality may            tentionality. Establishing features of intentionality will also
not be. In the rock-paper-scissors experiment described ear-          help those who design interactions between people and ob-
lier (Short et al., 2010), once participants made attributions of     jects, such as those working with social robots. By under-
H-intentionality to the robot, those attributions persisted de-       standing features of intentionality, roboticists will be able to
spite the absence of additional H-intentional behavior. On the        design robots that detect and exhibit relevant intentional be-
other hand, in the chasing studies (Gao et al., 2009), it seems       haviors, which would strengthen non-verbal communication
easy to imagine that an agent that no longer chases would stop        in human-robot interactions.
appearing L-intentional after some time.
                                                                                               Conclusions
   Philosophers have identified yet another interesting char-
acteristic of intentionality attributions: actions with harmful       This paper presents a new representation and vocabulary for
side-effects seem to be perceived as more intentional than ac-        classifying different types of intentionality. Using examples
tions with beneficial side-effects. For instance, if a company        from the extensive psychology literature on intention recog-
owner institutes a new manufacturing process that increases           nition, we hypothesize that intention attributions can be cate-
profits but damages the environment, the owner is seen as in-         gorized into two types, L-intentionality and H-intentionality,
tentionally harming the environment. On the other hand, if            based on the kinds of perceptions that cue those attribu-
the owner institutes a process that increases profits and helps       tions. We describe the benefit of social robotics as a plat-
the environment, the owner is not seen as intentionally help-         form for experimenting with intentionality perceptions, and
ing the environment (Knobe, 2005). Does this type of dispar-          we mention some past research from robotics that explores
ity hold for both types of intentionality? Would a side-effect        intention attributions under various conditions. We then out-
from an L-intentional action be seen as equally harmful to            line possible models for the relationship between H- and L-
the same side effect from an H-intentional action? Or does            intentionality based on the set of features that elicit the per-
the complexity of reasoning perceived in H-intentional agents         ception of each: completely disjoint, partially overlapping,
endow them with more responsibility for side effects?                 nested with H-intentionality as a proper subset, nested with
                                                                  1270

L-intentionality as a proper subset, and identical. Along with        gins of “theory of mind”. Psychological Review, 94(4),
each model description, we specify how that model could be            412–426.
falsified. We posit some important consequences of proving          Meltzoff, A. N. (1995). Understanding the intentions of oth-
our intention duality hypothesis, and we discuss the potential        ers: Re-enactment of intended acts by 18-month-old chil-
validity of these models, identifying that bottom-up process-         dren. Developmental Psychology, 31(5), 838–850.
ing is the most likely model given our separation of H- and         Michotte, A. (1963). The perception of causailty. Oxford,
L-intentionality. We discuss characteristics of intentionality        England: Basic Books.
that might vary between H- and L-intentionality, and we pose        Mutlu, B., Yamaoka, F., Kanda, T., Ishiguro, H., & Hagita,
questions for future exploration of this area of research.            N. (2009, March). Nonverbal leakage in robots: Com-
                                                                      munication of intentions through seemingly unintentional
                     Acknowledgments                                  behavior. In Human robot interactions (HRI’09). La Jolla,
Thanks to Greg Trafton for inspiring conversations, to Brad           California: ACM.
Hayes for help with diagrams, and to anonymous reviewers            Nehaniv, C. L., Dautenhahn, K., Kubacki, J., Haegele, M., &
for helpful comments. This material is based upon work sup-           Parlitz, C. (2005). A methodological approach relating the
ported by grants from the National Science Foundation under           classification of gesture to identification of human intent
contracts No. 1139078, No. 1117801, and No. 0835767. The              in the context of human-robot interaction. In Proceedings
first author is supported by an National Science Foundation           of the IEEE international workshop on robot and human
Graduate Research Fellowship.                                         interactive communication (ROMAN 2005) (pp. 371–377).
                                                                    Pantelis, P. C., Cholewiak, S., Ringstad, P., Sanik, K., Wein-
                         References                                   stein, A., Wu, C.-C., et al. (2011). Perceptions of intentions
                                                                      and mental states in autonomous virtual agents. Journal of
Aarno, D., & Kragic, D. (2006). Layered HMM for mo-                   Vision, 11(11), 1990–1995.
   tion intention recognition. In Proceedings of the IEEE/RSJ       Pelphrey, K. A., Morris, J. P., & McCarthy, G. (2004). Grasp-
   international conference on intelligent robots and systems         ing the intentions of others: The perceived intentionality
   (IROS 2006) (pp. 5130–5135). Beijing, China.                       of an action influences activity in the superior temoral sul-
Bainbridge, W. A., Hart, J. W., Kim, E. S., & Scassellati, B.         cus during social perception. Journal of Cognitive Neuro-
   (2011). The benefits of interactions with physically present       science, 16(10), 1706–1716.
   robots over video-displayed agents. International Journal        Phillips, W., Baron-Cohen, S., & Rutter, M. (1998). Under-
   of Social Robotics, 3, 41–52.                                      standing intention in normal development and in autism.
Baker, C. L., Tenenbaum, J. B., & Saxe, R. R. (2006).                 British Journal of Developmental Psychology, 16, 337–
   Bayesian models of human action understanding. In                  348.
   Y. Weiss, B. Schölkopf, & J. Platt (Eds.), Advances in neu-     Scholl, B. J., & Tremoulet, P. D. (2000, August). Perceptual
   ral information processing systems 18. MIT Press.                  causality and animacy. Trends in Cognitive Sciences, 4(8).
Baron-Cohen, S. (1995). Mindblindness: An essay on autism           Schrempf, O. C., Albrecht, D., & Hanbeck, U. D. (2007).
   and theory of mind. Cambridge, MA: MIT Press.                      Tractable probabilistic models for intention recognition
Breazeal, C., & Scassellati, B. (1999). How to build robots           based on expert knowledge.           In Proceedings of the
   that make friends and influence people. In Proceedings             IEEE/RSJ international conference on intelligent robots
   of the IEEE/RSJ international conference on intelligent            and systems (IROS 2007) (pp. 1429–1434). San Diego,
   robots and systems (IROS ’99) (Vol. 2, pp. 858–863). Ky-           CA.
   ongju, South Korea.                                              Short, E., Hart, J., Vu, M., & Scassellati, B. (2010). No fair!!
Feldman, J., & Tremoulet, P. D. (2008). The attribution of            an interaction with a cheating robot. In 5th ACM/IEEE
   mental architecture from motion: Towards a computational           international conference on human-robot interaction (pp.
   theory (Tech. Rep. No. 87). Rutgers University Center for          219–226).
   Cognitive Science (RuCCS).                                       Tremoulet, P. D., & Feldman, J. (2000). Perception of an-
Gao, T., Newman, G. E., & Scholl, B. J. (2009). The psy-              imacy from the motion of a single object. Perception, 29,
   chophysics of chasing: A case study in the perception of           943–951.
   animacy. Cognitive Psychology, 59, 154–179.                      Tremoulet, P. D., & Feldman, J. (2006). The influence of
Heider, F., & Simmel, M. (1944, April). An experimental               spatial context and the role of intentionality in the inter-
   study of apparent behavior. The American Journal of Psy-           pretation of animacy from motion. Perception and Psy-
   chology, 57(2), 243–259.                                           chophysics, 68(6), 1047–1058.
Heyes, C., & Dickinson, A. (1990). The intentionality of            Wellman, H. M., Cross, D., & Watson, J. (2001, May/June).
   animal aciton. Mind and Language, 5(1).                            Meta-analysis of theory-of-mind development: The truth
Knobe, J. (2005, August). Theory of mind and moral cog-               about false belief. Child Development, 72(3), 655–684.
   nition: exploring the connections. Trends in Cognitive Sci-
   ences, 9(8).
Leslie, A. M. (1987). Pretense and representation: The ori-
                                                                1271

