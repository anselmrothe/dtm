UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
From Hands to Minds: Gestures Promote Action Understanding
Permalink
https://escholarship.org/uc/item/83s258kv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Kang, Seokmin
Tversky, Barbara
Black, John
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                From Hands to Minds: Gestures Promote Action Understanding
                                          Seokmin Kang (sk2587@columbia.edu)
                                             Teachers College, Columbia University
                                                    New York, NY 10027 USA
                                        Barbara Tversky (btversky@stanford.edu)
                                                    Columbia Teachers College
                                                     New York, NY 10027 USA
                                                         Stanford University
                                                      Stanford, CA 94305 USA
                                           John B. Black (jbb21@columbia.edu)
                                             Teachers College, Columbia University
                                                    New York, NY 10027 USA
                           Abstract                                 point to places or things in the world or in a virtual world.
  Understanding dynamic concepts is more difficult than
                                                                    Iconic gestures show what something looks like or acts like
  understanding static ones. The present study showed that          (e.g., McNeill, 1992; Goldin-Meadow, 2003). Together,
  understanding dynamic concepts can be enhanced by gestures        these kinds of gestures can carry rich semantic content. A
  that convey action. Participants learned how an engine            train of integrated deictic and iconic gestures can be used on
  worked from one of two videos, with identical verbal scripts      virtual stages to create detailed models of situations, such as
  and identical diagrams. One video was accompanied by              environments (e. g., Emmorey, Tversky, & Taylor, 2000)
  gestures showing the structure of the system; the other was       and actions, such as how a lock works (e. g., Engle, 1998).
  accompanied by gestures showing the actions of the system.
  Both groups learned the basics of the system. Participants        Are such gestures successful in communicating knowledge
  who saw the action gestures depicted more dynamic                 as well as in representing it?
  information in their visual explanations of the system and                          Knowledge on the page
  included more dynamic information in their verbal                    As such, sequences of organized gestures can serve much
  explanations of the system. Because they are inherently           like diagrams. In fact, many kinds of gestures can be
  dynamic, gestures appear to be especially suited for
  conveying dynamic information.
                                                                    mapped to kinds of diagrammatic features; that is, they
                                                                    carry the same meanings (Tversky, Heiser, Lee, & Daniel,
  Keywords: gesture; diagram; complex systems; knowledge            2009). Diagrams have some advantages over gestures as a
  construction                                                      means of representing knowledge. Diagrams have
               Knowledge in the hands                               permanence, so they can be inspected and reinspected.
  When people explain something, they typically use                 Because they are external and persist, they do not need to be
gestures as well as speech. Gestures can carry information          kept in mind, so the mind is free to use the diagram as a
that is redundant with speech, reinforcing the message by           basis for reorganization, for inference, and for discovery.
presenting information in two modalities. Importantly,              Diagrams use elements and spatial relations on a page to
gestures sometimes carry information that is not carried in         represent elements and relations that are actually spatial, as
speech (e. g, Bavelas, 1994; Church & Goldin-Meadow,                in maps or architectural plans, or that are metaphorically
1986; Perry, Church, & Goldin-Meadow, 1988). In some                spatial, as in the periodic table or organization charts (e. g.,
cases, speech refers listeners to gesture, as in “turn this         Tversky, 2011; Tversky, et al., 2009). Gestures, like
way,” but in other cases, there is no cuing of the gestures.        language, are external, but lack permanence. A series of
Nevertheless, the information carried solely in gesture can         gestures used to create a model of a situation requires
reveal the thought of speakers and affect the thought of both       working memory to create, understand, and remember, and
those who make gestures and those who watch them (e.g.,             can tax working memory. On the other hand, diagrams are
Beattie & Shovelton, 1999; Chu & Kita, 2011; Goldin-                static, so it can be challenging to convey action, change, and
Meadow, Cook, & Mitchell, 2009; Goldin-Meadow, Kim, &               process in diagrams. Typically, arrows are used, but they
Singer, 1999; Hegarty, Mayer, Kriz, & Keehner, 2005;                can be ambiguous (e. g., Heiser & Tversky 2006; Tversky,
Kessell & Tversky, 2006; Singer & Goldin-Meadow, 2005;              2011; Tversky, Heiser, MacKenzie, Lozano, & Morrison,
Mcgregor, Rohlfing, Bean, & Marschner, 2009; Ping &                 2007). Gestures are by nature dynamic, so they can portray
Goldin-Meadow, 2008; Schwartz & Black. 1996;                        action, if schematically (e. g., Kita & Özyürek, 2003;
Thompson, Driscoll, & Markson, 1998; Valenzeno, Alibali,            Rizzolatti & Arbib, 1998). In fact, when gestures are used
& Klatzky, 2003).                                                   with diagrams in explanations, diagrams are often used to
  It is primarily iconic and deictic gestures that reveal the       convey structure, and gestures to portray action (e. g.,
thought of those who make them and affect the thought of            Engle, 1998).
those who make them or observe them. Deictic gestures
                                                                551

                      Complex systems                               Materials We created two videos explaining how a four-
Many explanations, in conversational as well as learning            stroke engine works. The videos were identical in language
situations, are of complex systems, scientific, mechanical,         and number of gestures but differed in kinds of gesture. A
social, athletic, or political. Complex systems typically have      diagram typical of those in science and engineering showing
elements--actors or agents or object--that have properties          the labeled parts and configuration of the system was
and structure, social or geographic or other relations. They        superimposed in front and to the side of the explainer. The
also have action or behavior: the actors or agents or objects       explanations began with an introduction overviewing the
act or are acted on in some sort of systematic ways usually         structure using deictic gestures. The core portion of the
associated with their properties and their relationships or         explanation was a step-by-step explanation of the processes
structure. Many complex systems, from traffic patterns to           comprising the workings of the system. The final portion of
election procedures, from spread of disease to workings of          the explanation explained how the process caused the car’s
the nervous system, from the operation of an engine to a            wheels to rotate. Because the diagram showing the structure
court of law, can be explained, especially when                     was always in view and because the introduction to both
accompanied by deictic and iconic gestures. They can also           explanations overviewed the system structure, the gestures
be diagrammed, and, as noted, diagrams readily portray the          emphasizing structure served as a control and were not
structural relations of agents, actors, and objects, but do not     expected to affect performance on the questions.
easily portray the action or behavior of systems. Yet, it is           For the core portion of the explanation, in the action
the action of a system and its outcomes that is hardest for         video, the explainer used only gestures that portrayed the
novices to comprehend (e. g., Hmelo-Silver and Pfeffer,             action of each part, always in the same location, so no
2004). Making inferences about action or function separates         structural information was provided. In the control structure
novices and experts across domains (e.g., Suwa & Tversky,           video, the explainer used only gestures that pointed to the
1997). Here we ask whether gestures showing action can              location of the parts of the system and showed the shape of
promote understanding of the behavior of complex systems.           each part as the process was explained. The accompanying
   To ask whether iconic gestures that convey action can            verbal script explained both the locations of the parts and
promote understanding of explanations of complex systems,           the actions of the parts identically. Figure 1 shows snapshots
we compared explanations that were identical except for             of two instructional videos.
gesture. One explanation was accompanied by gestures that
portrayed action, and a control explanation used gestures to
convey the form and structure of the parts of the system.
Students viewed one of two videos of explanations of the
operation of a four-stroke engine, the typical engine in an
automobile. The language of the explanations was identical,
and each explanation was based on a diagram of the
structure of the engine superimposed to the front and side of
the explainer. Because enactive gestures can convey action
                                                                    Figure 1. Still shots from the action (left) and structure
directly and information about action is more difficult, we
                                                                    (right) videos showing the superimposed diagrams.
were especially interested to know if gestures conveying
action help students comprehend action information.                    The information in the script was categorized as structure
   Performance was assessed in several ways: by questions           or action, and gestures appropriate for each were devised.
about structure and action, by diagrams, by visual                  For the action gesture video, the explainer showed the
explanations, and by live explanations of the systems by the        rotational motion of the crankshaft, the direction of the
students. The questions could be answered solely on the             piston’s movement, the flow of fuel and air, the movement
basis of the language of the explanations and served partly         of the intake and exhaust valves, and so on with his hands.
as a manipulations check. Hence, if students who view               The action gestures were performed in the same place off
action gestures have a better understanding of the action of        the diagram, avoiding any positional information.
the system than those who viewed structure gestures, they              For the structure gesture video, the explainer used his
should be more likely to include action information, in their       hand(s) successively to show the shapes of the crankshaft,
diagrams, and they should be more likely to deliver action          piston and cylinder, and showed the positions of the piston,
information and use action gestures themselves in their later       crankshaft, spark plug, intake port, intake value, exhaust
explanations to new learners.                                       port, exhaust valve, and mixture of fuel and air.
                            Method                                     To eliminate any biasing effects of lexical stress (Heuven,
Participants 59 (15 male) university students ranging in            1988; Field, 2005), the speaker practiced the script several
age from 20 to 36 with an average age of 26 (SD = 3.50),            times, making sure to stress the actions and the parts for
participated in the study. They were all native English             both videos.
speakers and did not have prior knowledge of the system to          Posttests The verbal posttest was based on the information
be learned.                                                         in the script with 20 recognition questions, 16 True/False,
                                                                    and 4 multiple-choice questions. Of the 16 True/False
                                                                552

questions, 8 queried action and 8 queried structure. Action                The means were compared using Poisson regression
questions referred to movement, or causal relations of the              analysis with the assumption that the conditional means
parts and their consequences. Structure questions referred to           equal the conditional variances.
shapes and positions of the parts of the system. Four
multiple-choice questions queried general knowledge. The
questions were presented in random order. Because the
verbal posttest was based entirely on the verbal script,
differences dependent on viewed gesture were not expected.
The test served as a manipulation check.
   The second posttest was a diagraming task. Participants
were asked to diagram a visual explanation of how a four
stroke engine works based on what they learned from the
video. Finally, participants made a video to explain the
workings of the four-stroke engine to a peer. It was expected
that participants who viewed the videos with action gestures
would include more action information in the latter two
less-constrained measures.
Procedure Participants were seated at a table with a laptop
computer with a 15.4 in screen. They were randomly                      Figure 2. Mean number of visual components in diagrams.
assigned to either the action gesture or the structure gesture          Error bars represent standard errors of the means.
video group. The participants were then told: “Today, your
job is to watch a video of how a four stroke engine works                  Overall, those who viewed action gestures used more
four times1 in a row and explain the concept in the video to            visual components than those who saw structure gestures (p
a peer coming later. However, since you are not directly                < .05). In addition, those who viewed action gestures
explaining a concept, your explanation will be videotaped               produced more action arrows (p < .05) and action effects (p
and showed later either to him or her. He or she will learn             < .05) and labeled fewer lines (p < .01) than those who saw
about the concept from your explanation.” Participants were             structure gestures. Labeled lines typically linked names and
not allowed to take notes or to pause or stop the video. The            parts; that is, structural information. Thus, for the diagrams,
experimenter left the room while participants watched the               those who saw action gestures included more information
video. After watching the video, participants were given the            about action and those who saw structure gestures included
verbal and diagrammatic posttests, and then made a video                more information about structure, showing that the viewed
explaining the system to a peer. The video camera was set               gestures affected viewers’ comprehension and later
opposite the participant 3 meters away. Participants were               production.
allowed to spend as much time as they wanted.                           Explanations to a peer Recall that after learning the system,
                                                                        participants made videos explaining the four-stroke engine
                             Results                                    to novices. Will those who saw action gestures use more of
Verbal Posttest As expected, the type of gesture viewed                 them in their own explanations? A gesture unit was defined
yielded no differences in performance on action (p = .08),              as “the period of time between successive rests of the limbs
structure (p = .85) or general (p = .92) questions, nor were            (McNeill, 1992).” If the hands did not return to a resting
there interactions between gesture viewed and question                  position between two gestures, the boundary was defined by
type, F(1, 114) = 1.70, p = .20. However, in within group               a pause in motion and an obvious change in shape or
comparisons, those who viewed action gestures performed                 trajectory. If participants used both hands simultaneously to
better on action questions than on structure questions, t(28)           describe one object, concept, or part, it was regarded as one
= 3.56, p < .01, d = 0.82. There were no differences between            gesture. If participants used one hand to describe an object,
action and structure questions for those who viewed                     a concept, or a part and the other hand a different concept,
gestures conveying structure (p = .11).                                 the gestures were coded as two different gestures.
Diagram Posttest Two coders coded the diagrams for                         For this study, only gestures conveying action or structure
action components. The reliability for action words was                 were coded. Action gestures were defined as showing the
Kappa = .56 (p < .001), for action arrows, Kappa = .63 (p <             action of a part or process of a system. Structure gestures
.001), for action effects, Kappa = .65 (p < .001), for labeling         were defined as showing the location or static properties,
arrows, Kappa = .60 (p < .001), and for labeling lines,                 notably shape, of objects or parts of the system. Inter-rater
Kappa = .73 (p < .001). Action effects were depictions of               reliability was assessed on randomly selected 240 subsets
actions, such as explosions. The means of the visual                    (18%) of the data by a second coder who was trained and
components by type of viewed gesture appear in Figure 2.                blind to the experimental design. Agreement for identifying
                                                                        gestures was 87.8% and for categorizing gestures was
   1
     A pilot study had revealed that two viewings were insufficient     99.6%.
to achieve above chance performance.                                       For the speech analysis, the participants’ verbal
                                                                        descriptions were segmented into propositions (following
                                                                    553

Heiser & Tversky, 2006). The information units were coded            The same pattern of gesture use was observed. The action
as action, structure, or other. Propositions that contained        group used 6.89 (SD = 4.13) action gestures per minute and
action such as movement of each part within a cylinder were        1.45 (SD = 1.35) structure gesture per minute. The structure
coded as action information, for example,“…that byproduct          group used 4.62 (SD = 3.49) action gestures per minute and
is pushed back up through the exhaust valve…”.                     2.51 (SD = 2.38) structure gesture per minute.
Propositions that contained ‘is-a’ or ‘has-a’ were coded as          In group comparison, there was an interaction such that
structure information unless they referred to action, for          the action group used more action gestures and the structure
example, “…then it has an exhaust valve”. Other                    group used relatively more structure gestures, F(1,112) =
information included greetings, such as “Good evening,”            8.83, p = .004, < .01, = .84. In within group comparison,
introductory information such as “I’m going to explain how         when compared to the structure group (t(28) = 3.08, p =
a four stroke engine works,” and meta-comments such as             .005 < .01, d = 0.71, r = .33), the action group (t(28) = 7.95,
“…let me tell you a little bit more about each stage…”             p < .0001, d = 1.77, r = .66) reliably used more action
Gesture analysis2 The average explanation time was 177.14          gestures than structure gestures.
sec (SD = 56.84) for the action group and 152.34 sec (SD =         Speech analysis The participants delivered a total of 2550
55.94) for the structure group (ns. p = .10). There were a         information units in their speech. Among them, 1607
total of 1306 gestures: 754 by those who had viewed action         conveyed action information, 737 structure information,
gestures, 552 by those who had viewed structure gestures           and 206 other information. Those who saw action gestures
(ns. p = .13). The means of action and structure gestures          delivered a total of 1425 information units. Among them,
produced by participants who viewed action and structure           929 conveyed action, 387 conveyed structure, and 109
videos are shown in Figure 3.                                      conveyed other information. Those who saw structure
   There was an interaction between type of gesture viewed         gestures delivered a total of 1125 information units, 678
and type of gesture produced, F(1,112) = 8.58, p = .004 <          conveying action, 350 conveying structure and, 97
.01,  = .84. In within group comparison by paired sample          conveying other information. Figure 4 shows mean number
t-test, even though participants in both groups delivered          of information units delivered by two groups.
more action gestures than structure gestures, the action             Overall, those who viewed action gestures (M = 49.14, SD
group (t(28) = 7.15, p < .0001, d = 1.49, r = .60) reliably        = 20.81) delivered more information units than those who
used more action gestures, when compared to the structure          viewed structure gestures (M = 38.79, SD = 17.22), F(1,56)
group (t(28) = 2.88, p = .008 < .01 , d = 0.58, r = .28).          = 4.25, MSE = 364.75 , p = .044 < .05. In addition, those
                                                                   who viewed action gestures delivered more action
                                                                   information than the structure group, F(1,56) = 6.87, MSE =
                                                                   158.03, p = .01 < .05. There were no differences in the
                                                                   quantity of structural information (p = .52) or other
                                                                   information (p = .66), but there was an interaction between
                                                                   kind of information and kind of viewed gesture (p = .02 <
                                                                   .05). Post hac tests (Tukey HSD) showed that more action
                                                                   information was given than structural information (p < .001)
                                                                   and more structure information than other information (p <
                                                                   .001).
Figure 3. Mean number of type of produced gesture by type
of viewed gesture. Error bars represent standard errors of
the means.
   It is possible that the number and the pattern of gestures
differed by length of explanation. Although there were no
significant differences in the overall gesture use,
explanations in the action group were longer. Consequently,
the next section presents more detailed analyses of the
results by gesture rate, that is, gestures per minute.             Figure 4. Mean kinds of information units by viewed
                                                                   gestures. Error bars represent standard errors of the means.
   2
     One participant’s explanation was not recorded because of     Proportion of information types in speech Although there
malfunctioning of a video camera. Therefore, 58 participants’      were no group differences in explanation time, the group
videos were analyzed.
                                                               554

who had viewed action gestures took more time and                  simply and abstractly at a pace that allows comprehension.
delivered more information units than the group who                We taught a complex system, the operation of a four-stroke
viewed structure gestures. To take that into account,              engine, to novices under two conditions. One group saw
percentages of information types were analyzed and appear          action gestures that conveyed the behaviors of the parts of
in Figure 5.                                                       the system; the other group saw structure gestures that
                                                                   conveyed static qualities of the parts of the system and their
                                                                   structure. Both groups heard exactly the same explanation
                                                                   and saw the same structure diagram of the parts of the
                                                                   system. The verbal explanation was sufficient to convey the
                                                                   basics of the structure and the dynamics of the engine. A
                                                                   number of posttests were administered: a verbal test based
                                                                   on the verbal explanation, a visual explanation task, and a
                                                                   videotaped explanation of the system to new novices.
                                                                      The verbal memory test showed that both groups
                                                                   adequately learned the essentials of the structure and the
                                                                   operation of the system. However, the diagramming and the
                                                                   explanation tasks revealed substantial differences in the
                                                                   understanding of the behavior of the systems; the group who
                                                                   had viewed the action gestures appeared to have a deeper
Figure 5. Mean percentage of kinds of information units by         understanding of the behavior of the system than the group
viewed gesture. Error bars represent standard errors of the        who had viewed the structure gestures. In the visual
means.                                                             explanation task, those who had seen action gestures
                                                                   depicted more specific actions of the system than the group
  For those who viewed action gestures, action information         who had viewed the structure gestures. Furthermore, the
accounted for an average of 66.62% (SD = 10.30), structure         group who had viewed the action gestures used more action
information accounted for an average of 25.76% (SD =               gestures in their videoed explanations than the group who
10.13), and other information accounted for an average of          had viewed the structure gestures. Although the increase in
7.61% (SD = 7.30). For those who viewed structure                  the number of action gestures in explanations might be
gestures, 59.28% (SD = 15.89) was action information,              attributable at least in part to imitation of what they had
31.59% (SD = 13.28) was structure information, and 9.14%           viewed, the increase in number of depictions of specific
(SD = 8.34) was other information. There was an interaction        actions cannot. The depictions of action must come from a
between group and information type, F(2,168) = 5.16, MSE           deeper understanding of the specific chain of behaviors of
= 126.74, p = .007 < .01. Those who viewed action gestures         the system. Moreover, many of the gestures used differed
delivered relatively more action information than those who        from those viewed.
viewed structure gestures and those who viewed structure              The effects of the viewing the gestures that conveyed the
delivered relatively more structure information than those         structure of the system were weaker but evident both in
who viewed action group. Thus, in their own explanations,          diagrams and in explanations. The structure of the system
those who had viewed action gestures produced both more            was apparent from the diagram that was displayed during
verbal information about action and showed more action in          the viewed explanation, and the structure of the system was
their gestures. Similarly, those who had viewed structure          described in the verbal portion of the explanation.
gestures used more structure gestures and included                 Furthermore, the structural information is easier than the
proportionately more verbal structure information than those       behavioral because it was apparent in the diagram.
who had viewed action gestures.                                       In both groups, gestures conveying action far
                         Discussion                                outnumbered gestures conveying structure, suggesting that
   Understanding the behavior of complex systems is                participants regarded the behavior of the system as
challenging (e. g., Hmelo-Silver & Pfeffer, 2004). Actions         paramount and regarded gesture as a good means for
are not apparent in static diagrams, and the nature of actions     conveying action, over and above language.
often has to be imagined from purely symbolic language.               Discourse in the wild, including explanations, is an
Animations are typically too complex and too fleeting to be        integrated combination of word, gesture, and props,
comprehended (e. g., Tversky, Morrison, & Betrancourt,             elements in the world (such as a diagram) or in a virtual
2002) and are not part of most natural settings for                world that can be continuously referred to during the course
explanations. There is abundant evidence that gestures             of the discourse. Each, word, gesture, prop, plays roles,
provide a rich source of information, including information        sometimes overlapping, sometimes complementary.
about structure and process (e. g., Beattie et al., 1999;          Understandably, actions, even miniature schematic ones as
Becvar, Hollan, & Hutchins, 2008). Here we asked if                those in gestures, appear to be especially effective for
gestures can successfully transmit dynamic information,            conveying action, another example of cognitive congruence
over and above verbal and diagrammatic explanations,               (e. g., Tversky, et al., 2002).
                                                               555

Acknowledgments. We are grateful to National Science                  FASE/Speech-88 Symposium, edited by W.A. Ainsworth
Foundation HHC 0905417, IIS-0725223, IIS-0855995, and                 and J.N. Holmes, 811-818. Edinburgh: Institute of
REC 0440103 for partial support.                                      Acoustics.
                                                                    Kessell, A. M. and Tversky, B. (2006). Gestures for
                         References                                   thinking and explaining. Proceedings of the meetings of
Bavelas, J. B. (1994). Gestures as part of speech:                    the Cognitive Science Society.
  Methodological implications. Research on Language and             Kita, S., & Özyürek, A. (2003). What does cross-linguistic
  Social Interaction, 27, 201-221.                                    variation in semantic coordination of speech and gesture
Beattie, G., & Shovelton, H. (1999). Do iconic hand                   reveal? Evidence for an interface representation of spatial
  gestures really contribute anything to the semantic                 thinking and speaking. Journal of Memory and Cognition,
  information conveyed by speech? An experimental                     48, 16-32.
  investigation. Semiotica, 123, 1-30.                              McGregor, K. K., Rohlfing, K. J., Bean, A., & Marschner,
Becvar, A., Hollan, J., & Hutchins, E. (2008).                        E. (2009). Journal of Child Language, 36, 807-828.
  Representational gestures as cognitive artifacts for              McNeill, D. (1992). Hand and mind. Chicago: University of
  developing theories in a scientific laboratory. In M. S.            Chicago Press.
  Ackerman, C. A. Halverson, T. Erickson, & W. A.                   Perry, M., Church, R. B. & Goldin-Meadow, S. (1988).
  Kellogg (Eds.) Resources, Co-Evolution and Artifacts:               Transitional knowledge in the acquisition of
  Theory in CSCW (pp. 117-143). London, England:                      concepts. Cognitive Development, 3, 359-400.
  Springer-Verlag.                                                  Ping, R., & Goldin-Meadow, S. (2008). Hands in the air:
Chu, M. & Kita, S. (2011). The nature of gestures’                    Using ungrounded iconic gestures to teach children
  beneficial role in spatial problem solving. Journal of              conservation of quantity. Developmental Psychology, 44,
  Experimental Psychology, 140, 102-116.                              1277-1287.
Church, R. B., & Goldin-Meadow, S. (1986). The mismatch             Rizzolatti, G., & Arbib, M. A. (1998) Language within our
  between gesture and speech as an index of transitional              grasp, Trends in Neurosciences, 21, 188-194
  knowledge. Cognition, 23, 43-71.                                  Schwartz, D. L., & Black, J. B. (1996). Shuttling between
Emmorey, K., Tversky, B., & Taylor, H. (2000). Using                  depictive models and abstract rules. Cognitive
  space to describe space: Perspective in speech, sign, and           Science, 20, 457-497.
  gesture. Journal of Spatial Cognition and Computation, 2,         Singer, M. A., & Goldin-Meadow, S. (2005). Children learn
  157-180.                                                            when their teachers’ gestures and speech differ.
Engle, R. A. (1998). Not channels but composite signals:              Psychological Science, 16, 85-89.
  Speech, gesture, diagrams, and object demonstrations are          Suwa, M., & Tversky, B. (1997). What architects and
  integrated in multimodal explanations. In M. A.                     students perceive in their sketches: A protocol analysis.
  Gernsbacher & S. J. Derry (Eds.), Proceedings of the                Design Studies, 18, 385-403.
  Twentieth Annual Conference of the Cognitive Science              Thompson, L. A., Driscoll, D., & Markson, L. (1998).
  Society (pp. 321-326). Mahwah, NJ: Erlbaum.                         Memory for visual-spoken language in children and
Field, J. (2005). Intelligibility and the Listener: The Role of       adults. Journal of Nonverbal Behavior, 22, 167-187.
  Lexical Stress. TESOL Quarterly, 39, 399-423.                     Tversky, B. (2011). Visualizations of thought. Topics in
Goldin-Meadow, S. (2003). Hearing gesture: How our                    Cognitive Science, 3, 499-535.
  hands help us think. Cambridge: Belknap Press.                    Tversky, B., Heiser, J., Lee, P., & Daniel, M.P. (2009).
Goldin-Meadow, S., Cook, S. W., & Mitchell, Z. A. (2009).             Explanations in gesture, diagram, and word. In Coventry,
  Gesturing gives children new ideas about math.                      K. R., Tenbrink. T., & Bateman, J. (Eds.), Spatial
  Psychological Science, 20, 267– 272.                                Language and Dialogue. Oxford: Oxford University
Goldin-Meadow, S., Kim, S., & Singer, M. (1999). What                 Press.
  the teacher’s hands tell the student’s mind about math.           Tversky, B., Heiser, J., MacKenzie, R., Lozano, S., and
  Journal of Educational Psychology, 91, 720-730.                     Morrison, J. B. (2007). Enriching animations. In R. Lowe
Hmelo-Silver, C. E., & Pfeffer, M. G. (2004). Comparing               and W. Schnotz, Learning with animation: Research
  expert and novice understanding of a complex system                 implications for design. NY: Cambridge University
  from the perspective of structures, behaviors, and                  Press.
  functions. Cognitive Science, 1, 127–138.                         Tversky, B., Morrison, J. B. & Betrancourt, M (2002).
Hegarty, M., Mayer, S., Kriz, S., & Keehner, M. (2005).               Animation: Can it facilitate? International Journal of
  The role of gestures in mental animation. Spatial                   Human Computer Studies. International Journal of
  Cognition and Computation, 5, 333-356.                              Human Computer Studies, 57, 247-262.
Heiser, J., & Tversky, B. (2006). Arrows in comprehending           Valenzeno, L., Alibali, M. W., & Klatzky, R. (2003).
  and producing mechanical diagrams. Cognitive Science,               Teachers’ gestures facilitate students’ learning: A lesson
  30, 581-592.                                                        in symmetry. Contemporary Educational Psychology, 28,
Heuven, V. J. van (1988). Effects of stress and accent on the         187-204.
  human recognition of word fragments in spoken context:
  gating and shadowing, Proceedings of the 7th
                                                                556

