UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Gestures in Communication through Line Graphs
Permalink
https://escholarship.org/uc/item/0hp4r2cx
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Acarturk, Cengiz
Alacam, Ozge
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                               Gestures in Communication through Line Graphs
                                        Cengiz Acartürk (ACARTURK@Metu.Edu.Tr)
                                              Özge Alaçam (OZGE@Metu.Edu.Tr)
                                                 Cognitive Science, Informatics Institute
                                       Middle East Technical University, 06800, Ankara, Turkey
                              Abstract                                    Human conceptualization through statistical graphs has
   Line graphs are widely used in communication settings, for
                                                                       been a topic of interdisciplinary research since the past 30
   conveying information about states and processes that unfold        years. The research on graph comprehension has covered a
   in time. The communication is achieved by the contribution          broad range of analyses including the investigations on
   of other modalities than graphs, such as language and               perceptual processes of graph comprehension (e.g.,
   gestures. In a set of experimental investigations, we analyzed      Cleveland & McGill, 1985), analysis from the perspective
   the production and comprehension of gestures during                 of psychology and usability (e.g., Kosslyn, 1989), cognitive
   communication through line graphs. The findings reveal a            models (Lohse, 1993; Peebles & Cheng, 2002), educational
   systematic use of gestures as well as the limitations of
   cognitive resources due to the split of attention between the       psychology and instructional design (Winn, 1987; Mautone
   modalities.                                                         & Mayer, 2007). On the other hand, the research on
                                                                       modalities that accompany graphs, such as language and
   Keywords: Gesture production; gesture comprehension;                gesture in communication through graphs, has been scarce
   graph comprehension; line graphs.
                                                                       except for a few studies (e.g., Gerofsky, 2011, on gestures
                                                                       in graphs of polynomial functions). Concerning the
              Line Graphs in Time Domain                               relationship between language and gestures, gestures have
Line graphs represent statistical data, most often the                 been considered as having a key role in organizing,
relationship between two domain variables. In line graphs,             conveying spatial information, and preventing decay in
line segments are used for representing the mapping                    visuospatial working memory (Hostetter & Alibali, 2010),
between the values. When used in time domain, line graphs              thus having the potential to promote learning in educational
represent the mapping between the values of the domain                 contexts (Goldin-Meadow, 2010). Analyzing the
variable and time. From the perspective of human                       relationship between graphical cues, language and gestures,
comprehension, line graphs in time domain have a peculiar              the present study investigates communication through line
characteristic: they represent not only statistical data but           graphs from the perspective of multimodal interaction.
also states and processes that unfold in time, by providing
perceptual cues for continuation (Figure 1).                                  Communication through Line Graphs
                                                                       Graphs are abundant both in spoken communication settings
                                                                       (e.g., classroom settings) and in written communication
                                                                       settings (e.g., newspaper articles). Communication through
                                                                       graphs is achieved by means of the contribution of several
                                                                       modalities: language (both in written form and in spoken
                                                                       form), graphical cues in written communication settings,
                                                                       and gestures in spoken communication settings. The
                                                                       previous research on multimodal comprehension reveals a
                                                                       frequent use of spatial terms that convey spatial information
                                                                       in communication through line graphs (Habel & Acartürk,
                                                                       2007). Moreover, in spoken communication, people tend to
     Figure 1: Sample population graph from PRBO (2012);               produce more gestures when they perform tasks that involve
                  redrawn based on the original.                       spatial information, compared to tasks with no spatial
                                                                       information (Alibali et al., 2001; Trafton et al., 2006;
Accordingly, the population graph in Figure 1 does not only            Hostetter & Sullivan, 2011). Consequently, in
represent the mapping between years and the population of              communication through line graphs, humans frequently
the bird species but also leads to a conceptualization of how          produce gestures that accompany spoken language.
population increases, decreases or remains stable in certain
periods of time.1                                                      graph in Figure 1 was generated by applying a local regression
                                                                       method called Loess smoothing on data points. The resulting
   1
     Line graphs are generated based on a set of assumptions that      spatial aspects of line graphs, such as smoothness, influence
specify the way the data points are represented by lines. For          humans’ interpretation of the states and processes (Acartürk et al.,
instance, according to the original source (PRBO, 2012), the line      2008), a topic beyond the scope of the present study.
                                                                   66

   Gestures in communication are of different types: the            participants. The participants were asked to imagine
most commonly used ones are deictic (or pointing) gestures          themselves in an online meeting, in which their task was to
and iconic (or representational) gestures. Deictic gestures         present single-sentence summaries of annotated graphs to
show objects, people and places, whereas iconic gestures are        the audience. According to the scenario, the audience was
representations of shape of an object or an action                  able to see the participant (i.e., the presenter) but not the
(Özçalışkan & Goldin-Meadow, 2005). In communication                graphs. Therefore, the presenter first investigated the graph
settings, deictic gestures facilitate achieving joint attention     displayed on a computer screen, then s/he turned towards
on objects, whereas iconic gestures overlap with spatial            the audience (an audience picture displayed on another
tasks (Alibali et al., 2001; Trafton, et al., 2006). In             computer screen), and then presented a single-sentence
communication through line graphs, humans may produce               summary of the graph. The participants were not informed
both deictic gestures and iconic gestures. It is also not           that their gestures were in the focus of the experiment. Each
unusual that humans emphasize certain aspects of processes          participant presented the single-sentence summaries for 14
and states represented by line graphs, such as a specific           annotated graphs, thus generating 14 video recordings per
increase, a peak or a stable period of the domain value, in         participant. The graphs represented populations of bird
addition to emphasizing an overall pattern. Graphical               species in a lagoon. Each graph involved a graphical
annotations (also called graphical cues) on graph lines are         annotation that emphasized a certain aspect of the
generally used for this purpose.                                    information represented, such as a specific increase or a
   The major focus of the present study is to investigate           peak. In particular, three types of annotations were used.
gestures in communication through line graphs, both from a               • Process annotation: A diagonal arrow that
production perspective and a comprehension perspective.                       emphasized a specific increase or a decrease.
For a systematic analysis, we limited the domain of                      • Durative state annotation: A horizontal arrow that
investigation to the relationship between gestures and                        emphasized a specific period of constant value.
graphical cues in line graphs (rather than the overall pattern           • Punctual state annotation: A point-like circle that
of the graph line). In the first step of the analysis, one group              emphasized a specific value such as a peak value.
of participants produced gestures during a verbal description       The 14 stimuli involved 2 graphs for familiarization of the
task (Experiment 1). We considered the produced gestures            participant to the task. The remaining 12 stimuli involved 6
as human interpretations of the structural aspects of the           punctual state annotations (2 for the start point of the lines,
states and processes represented by the graphs. The gestures        2 for middle and 2 for the endpoint of the lines), 4
produced by the participants of Experiment 1 were used for          (diagonal) process annotations and 2 (horizontal) durative
designing the stimuli for a comprehension experiment                state annotations (Figure 2).
(Experiment 2). This approach resembles what has been
termed the “3Ps (Preference-Production-Performance)
program” as an empirical method for selecting appropriate
representations for abstractions (Kessell & Tversky, 2011).
The two approaches are similar; in that, both aim to perform
an empirical investigation of the representations rather than
leaving the decision for selecting the appropriate
representation to intuitions of the graphic designer. Instead
of graphic representations, however, we investigated
gestures in communication through graphs in a set of
consecutive analyses (i.e., the outcome of Experiment 1 was
used for preparing the stimuli set in Experiment 2).
                       Experiment 1
In Experiment 1, the participants presented verbal                        Figure 2: Sample annotated graphs with a process
descriptions of annotated graphs. Spontaneous gestures of             annotation (upper left), a durative state annotation (upper
the participants were analyzed in terms of the relationship                right), and a punctual state annotation (bottom).
between the type of the graphical cue and the gesture type.
                                                                    Following Gerofsky (2011), we employed the coding
Participants, Materials and Design                                  scheme proposed by Creswell (2007) for the analysis of (14
A total of seven participants (Mean age = 25.4, SD = 3.78)          graphs x 7 participants) 98 experiment protocols. The
who were graduate students or teaching assistants from the          Noldus Observer XT event logging software was used for
Faculty of Education, Middle East Technical University              coding. Two coders analyzed the protocols according to the
(METU) participated in the experiment, five of which                following criteria: For each gesture in the video recording,
reported having teaching experience. The experiment                 the coder first classified the gesture in terms of its
language was Turkish, which was the native language of the          directionality: having no gesture, no direction, being
                                                                 67

vertical, horizontal, diagonal or other.2 Then the coder                Experiment 2. For this, we prepared 14 video recordings in
identified the following features of each gesture: size (small          which a narrator presented a single-sentence summary of
or big), palm direction (up, down or front), speed (slow or             annotated graphs by producing a relevant gesture
fast) and start position (low, middle or high). In the present          concurrently with the spoken description. The verbal
study, we focus on the directionality of gestures by leaving            description was a single-sentence summary for a graph with
the analysis of other features to an extended study. One                process annotation, a graph with durative state annotation or
coder initially coded the entire data, and a second coder,              a graph with punctual state annotation. For example, for a
who was blind to the hypothesis, carried out 57% of the                 graph with a process annotation, the narrator uttered the
dataset. Interrater reliability between coders was calculated           sentence “[t]he population of coot in the lagoon increased
by Cohen’s kappa. The results revealed an agreement value               between 1980 and 1985” while producing an upward
of .78. According to Landis and Koch (1977), a value above              diagonal gesture that showed an increase. She uttered the
.61 indicates substantial interrater agreement.                         sentence “[t]he sanderling population in the lagoon
                                                                        remained stable between 1975 and 1985” accompanied by a
Results                                                                 horizontal gesture for a graph with a durative state
The participants gestured in 86% of the protocols. This                 annotation. Finally, for a graph with a punctual state
number is close to what Hegarty et al. (2005) reported: the             annotation, the narrator uttered the sentence “[t]here exists
participants gestured when they described solutions to                  about 120 terns in the lagoon in the year 2010”
mental animation problems in 90% of the cases.3 Pearson's               accompanied by a pointing gesture (Figure 3). The duration
chi square test and follow-up McNemar tests were                        of the video recordings was between 5.3 seconds and 8.6
conducted to investigate the relationship between the                   seconds (M = 6.24, SD = 0.95).
annotation type and the gestures produced by the
participants. The test showed a significant effect of
annotation type on gesture, χ2 = 48.1, p < .05. In particular,
for the graphs with process annotations, the participants
produced more vertical and diagonal gestures compared to
both horizontal gestures, χ2 = 15.7, p < .05, and gestures
with no direction, χ2 = 5.88, p < .05. On the other hand, they
produced more horizontal gestures compared to other types
of gestures for durative states, χ2 = 4.08, p < .05. Finally, for           Figure 3: Snapshots from the video recordings with a
punctual annotations, more non-directed pointing gestures                diagonal gesture for a process annotation (left), a horizontal
were produced compared to vertical gestures, χ2 = 16.5, p <               gesture for a durative state annotation (middle), a pointing
.05, to horizontal gestures, χ2 = 26.0, p < .05, and to                         gesture for a punctual state annotation (right).
diagonal gestures, χ2 = 20.8, p < .05.
   These findings show that, in terms of the categorization of          Experiment 2 was conducted in three different conditions.
the gestures (cf. McNeill, 2005; Özçalışkan & Goldin-                   In the first condition, the participants played the videos on
Meadow, 2005) the participants produced iconic gestures                 the screen one by one and they listened to a single-sentence
for process annotations and durative state annotations. On              summary for each graph concurrently. In the second
the other hand, for punctual state annotations, they produced           condition, the participants played the same video recordings
pointing gestures that were ambiguous between iconic                    but the sound was muted, therefore they interpreted what
(because the pointing gesture was representational) and                 was presented on the screen only. In both the first condition
deictic (by definition).                                                and the second condition, we noted that participants’ gaze
                                                                        shifted between the gesture and the face of the narrator. We
                         Experiment 2                                   interpreted this finding as a potential source of attention
The findings obtained in Experiment 1 suggest that humans               split. Therefore, in the third condition, we provided the
produce a specific type of gesture depending on the                     participants with only gestures not the face of the narrator.
emphasized aspect of the information represented in the                 In all conditions, the participants were asked to predict the
graph. Based on the results obtained in Experiment 1, we                described graph among a set of three alternative graphs.
investigated comprehension of gestures by humans in
                                                                        Condition 1: Concurrent Interpretation of Gestures
   2
     The ‘other’ category involved beat gestures (simple up-and-        and Language
down movements without semantic information) or more complex            Participants, Material and Design. Eleven participants
gestures like the combination of vertical, horizontal or diagonal
                                                                        (Mean age = 31.8, SD =5.1), who were either graduate or
movements.
   3                                                                    undergraduate students of METU, participated in the
     A further investigation revealed that the five participants who
reported teaching experience gestured in 93% of the protocols           experiment. Each participant was presented 14 video
whereas the two participants who reported no experience in              recordings (2 trials and 12 tests). After playing each
teaching gestured in 68% of the protocols. The finding suggests a       recording, the participant was asked to choose the described
potential correlation between teaching experience and gesturing.
                                                                     68

graph among three alternatives (the alternate graphs were        rate for punctual states (M = .55, SD = .22), F(2, 34) = 25.4,
the same except for the graphical annotation). After             η2 = .60, p < .05. The difference between processes and
submitting each choice, the participant reported a subjective    durative states was not significant. The lack of the language
evaluation for confidence (“How confident are you about          modality resulted in significant differences between the
your judgment?”) by using a 1 to 3 scale (1 showing a low        three gesture types in confidence scores, F(2, 34) =18.1, η2
confidence, 3 showing a high confidence; Beattie and             = .51, p < .05. The participants reported lower confidence
Shovelton, 1999). The stimuli were displayed on a Tobii          scores for punctual states (M = 2.01, SD = 0.42) compared
non-intrusive 120 Hz eye tracker, integrated into a 17” TFT      to both processes (M = 2.61, SD = 0.33) and durative states
monitor with a resolution of 1024x768 pixels. The spatial        (M = 2.61, SD = 0.47). As in Condition 1, the mean
resolution and the accuracy of the eye tracker were 0.25°        response time of the participants in punctual states (M =
and 0.50° respectively. No time limit was set for the            4.34 seconds, SD = 1.74) was longer than both processes (M
answers. The order of presentation of the stimuli was            = 2.66 seconds, SD = 0.80) and durative states (M = 2.88
randomized.                                                      seconds, SD = 1.44), F(2, 34) =10.5, η2 = .38, p < .05,
                                                                 without a significant difference between the last two.
Results. The participants exhibited high success rates in
predicting the annotated graphs, for all three types of          Condition 3: Attention Split between Gestures and
gestures, i.e. the process gesture (M = 1.0, i.e. 100%), the     Face
durative state gesture (M = 1.0) and the punctual state          The findings obtained in Condition 1 and Condition 2 show
gesture (M = .93, SD = 0.01). The results of an ANOVA test       that the lack of linguistic information results in lower
revealed a significant difference between the gesture types,     success rates in predicting the answers; in particular, in
F(2, 20) = 5.17, η2 = .36, p < .05: the success rate in          punctual states. The analysis of the eye movements of
punctual states was lower than the other two gesture types.      participants revealed another finding about inspection
A comparison of the confidence scores reported by the            patterns on the video recordings: the participants shifted
participants, however, revealed no significant difference        their gaze between narrator’s gestures and face both in
between the gesture types F(2, 20) =1.86, η2 = .16, p > .05.     Condition 1 (M = 2.55, SD = 0.28) and in Condition 2 (M =
Finally, the participants spent the longest time to answer       2.68, SD = 0.35), without a significant difference between
punctual state questions (M = 7.03 seconds, SD = 2.97),          the two groups of participants, F(1, 26) = 0.83, p > .05, thus
which was longer than both processes (M = 5.27 seconds,          suggesting a potential source of attention split during
SD = 1.69) and durative states (M = 6.65 seconds, SD =           comprehension. Therefore, a third group of participants
2.97), F(2, 20) = 3.61, η2 = .27, p < .05, without a             were presented narrator’s gestures only, without face and
significant difference between the last two.                     sound.
Condition 2: Interpretation of Gestures                          Participants, Material and Design. Twenty-one
The first condition of the experimental investigation            participants (Mean age = 21.2, SD = 2.37) from METU
employed the most naturalistic setting for an online             participated in the experiment. The participants were
communication environment: the participants listened to the      presented the same stimuli except that the video recordings
narrator when she produced the gestures concurrently. In         were cut from the top, so that only the gestures (but not the
other words, both modalities (i.e., language and gesture)        face) of the narrator were displayed. The same experimental
were available to the participants. Therefore, it is not         procedure was applied as in the previous conditions.
possible to analyze the role of language and gestures
separately in comprehension of the presented stimuli. The        Results. The participants showed high success rates for
participants might have used the linguistic information to       processes (M = .96, SD = .10) and durative states (M = 1.0)
predict the graph without taking the gestures into account.      but a relatively lower success rate for punctual states (M =
In the second condition of the study, we asked the               .70, SD = .19), F(2, 40) =32.0, η2 = .61, p < .05, without a
participants to predict the described graphs by displaying       significant difference between processes and durative states.
the video recordings with the sound muted.                       Confidence scores for punctual states (M = 2.31, SD = 0.40)
                                                                 were also significantly lower than both processes (M = 2.69,
Participants, Material and Design. Eighteen participants,        SD = 0.30) and durative states (M = 2.76, SD = 0.37), F(2,
from METU participated in the experiment (Mean age =             40) = 14.7, η2 = .42, p < .05. Finally, they spent the longest
21.1, SD = 1.37). They were presented the same video             time to answer punctual state questions (M = 3.52 seconds,
recordings but they did not hear the narrator. The same          SD = 1.18), significantly different than both processes (M =
experimental procedure was applied as in the previous            2.60 seconds, SD = 1.04) and durative states (M = 2.41
condition.                                                       seconds, SD = 1.02), F(2, 40) = 8.84, η2 = .31, p < .05,
                                                                 without a significant difference between the last two.
Results. The participants in Condition 2 exhibited high            A comparison between the three groups of participants in
success rates for processes (M = .93, SD = .11) and durative     the three conditions of Experiment 2 showed that the
states (M = .91, SD =. 19) but a significantly lower success     highest success rate (in predicting the correct annotated
                                                              69

graph that was described in the video recording) was              findings suggest a low efficiency of the pointing gesture (in
obtained when the participants listened to the single-            the form of a deictic pointing gesture) in conveying
sentence description of the graphs while playing the video        information about punctual states. On the other hand,
recording. The lack of the language modality, however,            vertical and diagonal gestures were efficient in conveying
resulted in a decrease in success rates. On the other hand,       information about processes. Horizontal gestures were
helping the participants to focus on gestures only (by            efficient in conveying information about durative states. An
removing narrator’s face from the view) resulted in an            explanation to these findings may be related to the major
increase in the success rates (Figure 4).                         roles of iconic gestures and deictic gestures in
                                                                  communication. In contrast to iconic gestures that convey
                                                                  spatial information, the major role of pointing gestures is to
                                                                  attract the attention of the communication partner (McNeill,
                                                                  2005; Özçalışkan & Goldin-Meadow, 2005). Consequently,
                                                                  further research is needed to identify more appropriate
                                                                  candidates for emphasizing punctual states in graphs. For
                                                                  instance, a circular movement of the index finger might be
                                                                  more appropriate for representing punctual states.
                                                                     Another finding obtained in Experiment 2 was that
                                                                  participants’ back and forth movement of their gazes
  Figure 4: Mean success rates (left) and mean confidence
                                                                  between the gestures and the face of the narrator is a
                scores (right) in Experiment 2.
                                                                  potential source of attention split during the course of
                                                                  comprehension. Although speech sound was absent
For the comparison of the results obtained in the three
                                                                  (Condition 2) and therefore no linguistically useful
conditions of Experiment 2, a Games-Howell test was
                                                                  information was provided by the narrator (except for the
applied since the number of samples for the three groups
                                                                  possibility of lip reading), the participants shifted their gaze
was not equal and the population variances were
                                                                  several times between the narrator’s face and the gestures.
significantly different. The test returned a significant
                                                                  When the narrator’s face was removed from the video
difference between the three groups of participants in their
                                                                  recordings (Condition 3), an increase in success rates was
overall success rates, F(2, 47) = 17.2, η2=.42, p < .05.
                                                                  observed compared to Condition 2, though the success rates
Finally, a comparison of the confidence scores between the
                                                                  were still lower than the ones obtained when the linguistic
participant groups showed that the lack of the language
                                                                  information was available (Condition 1). Although this is
modality resulted in lower self-confidence of the
                                                                  far from being a naturalistic setting for communication
participants about their predictions, F(2, 47) =10.3, η2=.30,
                                                                  through graphs, the analysis of such boundary cases is
p < .05 (Figure 4).
                                                                  necessary for understanding the contribution of separate
                                                                  factors in comprehension. In fact, the findings support the
                         Discussion                               likelihood of the split of attention. A possible explanation
In two experiments, we investigated how humans produce            may be sought in the domain of the intersection between
gestures (Experiment 1) and comprehend gestures                   cognitive science and instructional science, in which the
(Experiment 2) when they communicate through graphically          previous studies show that the split of attention between
annotated line graphs. In Experiment 1, the participants          information sources leads to degraded learning outcomes
produced more frequent vertical and diagonal gestures to          due to limited cognitive resources that are available for
emphasize processes (e.g., increase, decrease) whereas they       understanding the instructional material (Sweller et al.,
produced more horizontal gestures to emphasize durative           1998; Mayer & Moreno, 1998). Consequently, the findings
states (e.g., remain stable). Those two types of gesture are      suggest that tasks demands may be high in communication
known as iconic gestures and they overlap with                    through graphs; therefore, attention split should be avoided
representation of spatial information (Alibali et al., 2001;      by, for instance, using small window sizes so that the
Trafton et al., 2006). For emphasizing punctual states (e.g.,     communication partner is able to attend to both gestures and
a peak), the participants produced pointing gestures. In          face in a single fixation.
Experiment 2, three groups of participants were presented
video recordings and they were asked to predict the                            Conclusion and Future Work
described graphs: the video recordings were designed based
                                                                  In communication settings, humans produce gestures when
on the correspondence between diagonal gestures and
                                                                  they convey spatial information. As a consequence, in
processes, between horizontal gestures and durative states,
                                                                  communication through line graphs, gestures are an
and between pointing gestures and punctual states. When
                                                                  indispensable part of communication. In this study we
gestures were displayed concurrently with linguistic
                                                                  investigated how humans produce and comprehend gestures
information (Condition 1), the participants showed a high
                                                                  in communication through line graphs. We found that
success rate in all gesture types. When language modality
                                                                  vertical and diagonal gestures efficiently convey
was absent, however, they showed a lower success rate and
                                                                  information about processes such as increase and decrease,
lower self-confidence, in particular in punctual states. These
                                                               70

and horizontal gestures efficiently convey information about       framework. Journal of Memory and Language, 63, 245-
durative states. However, pointing gestures are not efficient      257.
in conveying information about punctual states, possibly         Hostetter, A. B., & Sullivan, E. L. (2011). Gesture
due to their concurrent role as deictic gestures in                production during spatial tasks: Its not all about difficulty.
communication. Our future research will address finding            In L. Carlson, C. Hoelscher & T. F. Shipley (Eds.),
more appropriate gesture candidates for punctual states. The       Proceedings of the 33rd Annual Meeting of the Cognitive
future research will also address the investigation of the         Science Society. Austin, TX.
interaction between gestures and gradable (scalar)               Kessell, A. M. & Tversky, B. (2011). Visualizing space,
adjectives, gradable adverbs and spatial prepositional             time, and agents: Production, performance, and
phrases and adverbials, e.g. from, to, and between, which are      preference. Cognitive Processing, 12, 43-52.
part of the vocabulary in communication through line             Kosslyn, S. M. (1989). Understanding charts and graphs.
graphs, in addition to state verbs and verbs of change.            Applied Cognitive Psychology, 3(3), 185-226.
                                                                 Landis, J. R., & Koch, G. G. (1977). The measurement of
Acknowledgments. We thank METU HCI Research and                    observer agreement for categorical data. Biometrics,
Application Laboratory for their technical support. We also        33(1), 159-174.
thank four anonymous reviewers for their helpful comments        Lohse, G. L. (1993). A cognitive model for understanding
and suggestions. We thank Christopher Habel for                    graphical perception. Human-Computer Interaction, 8(4),
stimulating discussions on graphical annotations.                  353-388.
                                                                 Mautone, P. D., & Mayer, R. E. (2007). Cognitive aids for
                                                                   guiding graph comprehension. Journal of Educational
                         References                                Psychology, 99(3), 640-652.
Acartürk, C., Habel, C., & Çağıltay, K. (2008). Multimodal       Mayer, R. E., & Moreno, R. (1998). A split-attention effect
   comprehension of graphics with textual annotations: The         in multimedia learning: Evidence for dual processing
   role of graphical means relating annotations and graph          systems in working memory. Journal of Educational
   lines. In J. Howse, J. Lee & G. Stapleton (Eds.),               Psychology, 90(2), 312-320.
   Diagrammatic Representation and Inference: LNCS (Vol.         McNeill, D. (2005). Gesture and thought. University of
   5223, pp. 335-343). Berlin/Heidelberg: Springer.                Chicago Press.
Alibali, M. W., Heath, D. C., & Myers, H. J. (2001). Effects     Özçalışkan, S., & Goldin-Meadow, S. (2005). Gesture is at
   of visibility between speaker and listener on gesture           the cutting edge of early language development.
   production: Some gestures are meant to be seen. Journal         Cognition, 96, B101-B113.
   of Memory and Language, 44, 169-188.                          Peebles, D. J., & Cheng, P. C.-H. (2002). Extending task
Beattie, G., & Shovelton, H. (1999). Mapping the range of          analytic models of graph-based reasoning: A cognitive
   information contained in the iconic hand gestures that          model of problem solving with Cartesian graphs in ACT-
   accompany spontaneous speech. Journal of Language and           R/PM. Cognitive Systems Research, 3, 77-86.
   Social Psychology, 18, 438-462.                               PRBO (2012). Waterbird Census at Bolinas Lagoon, Marin
Cleveland, W. S., & McGill, R. (1985). Graphical                   County, CA. Public report by Wetlands Ecology Division,
   perception and graphical methods for analyzing scientific       Point Reyes Bird Observatory (PRBO) Conservation
   data. Science, 229, 828-833.                                    Science.      http://www.prbo.org/cms/366, retrieved on
Creswell, J. W. (2007). Qualitative inquiry and research           January 29, 2012.
   design: Choosing among five approaches (2nd ed.). Sage        Sweller, J., van Merriënboer, J. J. G., & Paas, F. G. W. C.
   Publications.                                                   (1998). Cognitive architecture and instructional design.
Gerofsky, S. (2011). Mathematical learning and gesture:            Educational Psychology Review, 10(3), 251-296.
   Character viewpoint and observer viewpoint in students'       Trafton, J. G., Trickett, S. B., Stitzlein, C. A., Saner, L.,
   gestured graphs of functions. Gesture, 10(2-3), 321-343.        Schunn, C. D., & Kirschenbaum, S. S. (2006). The
Goldin-Meadow, S. (2010). When gesture does and does not           relationship between spatial transformations and iconic
   promote learning. Language and Cognition, 2(1), 1-19.           gestures. Spatial Cognition and Computation, 6(1), 1-29.
Habel, C., & Acartürk, C. (2007). On reciprocal                  Winn, B. (1987). Charts, graphs, and diagrams in
   improvement in multimodal generation: Co-reference by           educational materials. In D. M. Willows & H. A.
   text and information graphics. In I. van der Sluis, M.          Houghton (Eds.), The psychology of illustration (Vol. 1,
   Theune, E. Reiter & E. Krahmer (Eds.), Proceedings of           pp. 152-198). New York: Springer-Verlag.
   the workshop on multimodal output generation (pp. 69-
   80). University of Aberdeen, UK.
Hegarty, M., Mayer, S., Kriz, S., Keehner, M. (2005). The
   role of gestures in mental animation. Spatial Cognition
   and Computation, 5, 333-356.
Hostetter A. B., Alibali M. W. (2010). Language, gesture,
   action! A test of the gesture as simulated action
                                                              71

