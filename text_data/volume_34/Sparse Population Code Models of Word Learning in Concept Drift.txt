UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Sparse Population Code Models of Word Learning in Concept Drift
Permalink
https://escholarship.org/uc/item/12h612c9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Zhang, Byoung-Tak
Ha, Jung-Woo
Kang, Myunggu
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

              Sparse Population Code Models of Word Learning in Concept Drift
                                        Byoung-Tak Zhang1,2 (btzhang@bi.snu.ac.kr)
                                               Jung-Woo Ha1 (jwha@bi.snu.ac.kr)
                                           Myunggu Kang1 (mgkang@bi.snu.ac.kr)
                                            1
                                              School of Computer Science and Engineering
                                           2
                                            Cognitive Science and Brain Science Programs
                                          Seoul National University, Seoul 151-744, Korea
                             Abstract                                probabilistic model of word learning. The Bayesian account
Computational modeling has served a powerful tool for studying
                                                                     aims to explain inductive learning at the level of
cross-situational word learning. Previous research has focused on    computational theory rather than to describe psychological
convergence behaviors in a static environment, ignoring dynamic      processes involved. Fazly et al. (2010) uses a probabilistic
cognitive aspects of concept change. Here we investigate concept     framework to propose an incremental associative model that
drift in word learning in story-telling situations. Informed by      deals with referential uncertainty. The proposed model is
findings in cognitive neuroscience, we hypothesize that a large      demonstrated to converge over time on the most likely
ensemble of sparse codes flexibly represents and robustly traces     meaning of the word in CHILDES data sets. However, this
drifting concepts. We experimentally test the population coding      model does not incorporate alignment ambiguity and it is
hypothesis on children’s cartoon videos. Our results show that       not clear how the model behaves if the concept drifts in the
learning the meanings of words over time is hard, especially when
the concept evolves slowly, but the sparse population coding can
                                                                     course of learning.
handle the concept drift problem effectively while hypothesis           Concept drift is a fundamentally important phenomenon
elimination and simplistic parametric models have difficulty.        in language acquisition. It means that the statistical
                                                                     properties of the target concept, which the learner is trying
   Keywords: Cross-situational word learning; statistical            to learn, change over time (Widmer & Kubat, 1996). For
   language learning; concept drift; meaning change; population
   coding.                                                           example, a child might think that all birds can fly until
                                                                     he/she observes an ostrich, at which time the child revises
                         Introduction                                the concept of bird. This causes problems because the
                                                                     learning process needs some mechanisms to unlearn or
Children learn the meaning of words rapidly and robustly             revise the learned concepts. Simple hypothesis elimination
across multiple situations (Smith & Yu, 2008).                       cannot account for this since it lacks a mechanism for
Computational modeling has served a powerful tool for                recovering the eliminated concepts. Both the associative
precise investigation of the hypothesized mechanisms of              learning and its probabilistic versions have difficulties since
word learning. Many computational models of word                     they strive to model global patterns, not modeling local
learning have been used to simulate and account for the              patterns that might be necessary at a later stage.
observed patterns such as reference disambiguation,                     Here we propose a computational model of word learning
blocking, and long-term memory (Frank et al., 2009,                  that deals with concept drift under alignment ambiguity and
Kachergis et al., 2010; Vlach & Sandhofer, 2010).                    referential uncertainty. The model borrows ideas from
   Existing computational models for word learning can be            neuroscience and uses a population coding (Pouget et al.,
broadly divided into hypothesis elimination and associative          2000; Ma et al., 2006). We propose a sparse population-
learning (Fazly et al., 2010). In the hypothesis elimination         code network in which meanings of the words are
approach the learning process consists of eliminating                represented as a large collection of sparse microcodes. Since
incorrect hypotheses about word meaning, on the basis of a           each microcode is sparse, it describes a general concept.
combination of a priori knowledge and observations of how            There are many of the microcodes and, thus statistically,
words are used to refer to aspects of experience, until the          only a few parts of them are updated on a single observation,
learner converges on a single consistent hypothesis. For             maintaining stability by the remaining microcodes in the
instance, Siskind (1996) presented an efficient algorithm for        population. We test this population coding hypothesis on
keeping track of just the necessary and possible components          naturalistic children’s cartoon video data. To make the
of word-meaning hypotheses consistent with a set of                  experiments more realistic, we use state-of-the-art image
examples. A weakness of this approach is that some                   processing techniques to represent the scene as a bag of
logically possible hypotheses may be ruled out a priori or           image patches. This is contrasted with the previous studies
the concepts cannot be recovered once they are eliminated.           of cross-situational word learning in which the scene
   Another approach to computational modeling of word                representation adopts hand-coded semantic features. Our
learning is associative learning. Yu (2005), for example,            experimental results show that learning the meaning of
studied a word-object association model in a unified                 words over time is hard, especially when the concept is
framework of lexical and category learning. This model               drifting slowly. We demonstrate that the sparse population
demonstrated the emergence of patterns observed in early             coding can handle the concept drift problem effectively
word learning. Xu and Tenenbaum (2007) proposed a
                                                                  1221

while simplistic parametric models have difficulty in                           Image Processing
dealing with the problem.                                                       We extracted image frames from the video, one frame for
                                                                                each of the 972 sentences extracted by language processing.
         Materials and Experimental Setup                                       Out of a stream of image frames played for the duration of
                                                                                speech of an utterance, we chose the image frame
Video Data Sets                                                                 corresponding to the start of the utterance. This results in an
We used a series of children’s cartoon videos, Maisy,                           image corpus of 972 scenes. Each scene was described by a
consisting of 6 episodes. Each episode plays for 48 to 105                      subset of 7,520 image patches (i.e., visual words), each
minutes and the total play time is 475 minutes. From this                       composed of the SIFT (scale-invariant feature transform)
video set, we prepared a total of 972 utterance-scene pairs as                  features and the color histogram extracted as follows. To
described in the following subsections. Cartoon videos                          define the visual words, we first used the MSER (maximally
provide naturalistic story-telling situations that children face                stable extremal region) feature extractor to segment and
in language acquisition (Zhang & Kang, 2011). An                                extract salient and informative regions from the images.
additional advantage of cartoons is that its image processing                   SIFT was then used to find salient features in the extracted
is relatively easy, allowing for automated generation of a                      regions. The resulting features are grouped by K-means
large data set to study the long-term learning behavior in                      clustering to remove redundancy.
situated word learning.
                                                                                Experimental Paradigm
                                                                                Given         the        set        of     learning       examples
                                                                                 DN  {(w(t ), v(t )) | t  1,..., N}, the goal of the learner is to
                                                                                form the concepts in the training set by finding the
                                                                                relationships between the words and the visual words (i.e.
                                                                                image patches). Learning proceeds incrementally, i.e. the
                                                                                examples are presented in sequence. Each time an example
                                                                                is presented the learner updates its model before the next
                                                                                example comes in.
                                                                                   Figure 2(b) shows the paradigm we adopt in this study.
                                                                                As indicated by the connections between textual words and
     Figure 1: Examples of utterance-scene representation                       those between visual words, we consider the fully
                                                                                interconnected relationship between different words and
Utterance-Scene Representation                                                  visual words. Note that this paradigm is contrasted with the
                                                                                standard paradigm shown in Figure 2(a), where the learner
The material for cross-situational learning consists of                         is to learn the relationship between the words and the
utterance-scene pairs, where each pair is represented as a                      referents or meanings, but do not attempt to learn the
vector of the form                                                              relationship among the words or among the referents.
       x(t )  (w(t ), v(t ))  ( w1 ,..., w|w (t )| , v1 ,..., v|v (t )| ) .
Here, | w(t ) | and | v(t ) | are the number (vocabulary size) of
textual words and visual words in the t-th example,
respectively. Figure 1 shows the examples of utterance-
scene pairs extracted from the original videos. The
following subsection describes how the textual words were
processed.
Language Processing
We collected all utterances in the text captions of the video
set, which amounts to approximately 2,800. Removing                                     Figure 2: Experimental paradigms in comparison
simple utterances such as ‘Hi’ gives a total of 972 sentences.
We determined the vocabulary for textual words by
computing the standard TF-IDF (term-frequency and                                                           The Model
inverse-document-frequency) values. TF-IDF gives higher
weights to the terms that frequently occur and are                              Concept Representation
uncommon between episodes. This results in 1,049 words.
                                                                                Meaning of words can be defined as a set of contexts in
We chose the top 448 textual words which defines the
                                                                                which word occurs in running text (Burgess & Lund, 1998)
utterance vocabulary. The sound modality was not used in
                                                                                or represented in network connectivity revealed by
the experiments.
                                                                                statistical analysis of a text corpus (Steyvers & Tenenbaum,
                                                                              1222

2005). The textual domain can be extended to include the         coding scheme. Typically we use a large number of
visual domain by taking into account the full contexts in        microcodes to describe complex concepts.
which the word and images (visual words) co-occur in                The population of sparse microcodes can be considered as
scenes (Zhang, 2008). Figure 3 illustrates this type of          a three-layer network as shown in Figure 4. The first
concept representation we adopt in this work. Here, the          (bottom) layer consists of the w-nodes for words (e.g.
concept of MOUSE, for example, is defined as a                   “white”) and the v-nodes for visual words (image patches).
collection of words (w-nodes), i.e. {yellow, run, dark,          The second (middle) layer represents the h-nodes for
tall}, and a collection of visual words or visual patches        microcodes or micro-concepts such as HEAD1. A formal
(v-nodes) linked to the ‘mouse’-node in the figure. Thus,        concept is represented as an ensemble of micro-concepts (or
we consider the learner to acquire the visually-grounded         microcodes), as indicated by c-nodes at the third (top) layer
linguistic concepts or the joint vision-language concepts,       of the network. This network can be learned from the data.
similar to the perceptual symbol systems a la Barsalou           Before describing the learning procedure we see the
(1999).                                                          statistical background underlying this representation.
                                                                 Finite Mixture Model Formulation
                                                                 Formally, a large collection of microcodes represents the
                                                                 empirical distribution of the concepts in the form of a finite
                                                                 mixture model (McLachlan & Peel, 2000). To see this, we
                                                                 suppose that the density of data x = (w,v) can be written in
                                                                 the form:
                                                                                        M
                                                                          P(x |  )    f  x | h 
                                                                                        j 1
                                                                                               j  j         j                        (1)
   Figure 3: The concept of a word is defined by other words     where fj(x|hj) are densities and j are nonnegative quantities
w as well as visual words v. In this representation the          that sum to one:
concepts are defined as a relationship among the primitives                                                          M
(words and visual words).                                              0   j  1 ( j  1,..., M )         and     
                                                                                                                     j 1
                                                                                                                            j  1.
                                                                 Equation (1) is called M-component finite mixture density.
                                                                 Roughly, the configuration of the microcode defines the
                                                                 shape of the mixture component fj(x|hj) and the weight
                                                                 associated with the microcode defines the mixing weight j.
                                                                 We denote the complete collection of all distinct parameters
                                                                 occurring in the mixture model by θ = (,h), where  =
                                                                 (1,…,M) and h = (h1,…,hM). We note that by designing
                                                                 the microcodes hj appropriately to be the parameters of the
                                                                 component density fj(x|hj), the mixture density can be
                                                                 represented by the sparse population code.
                                                                    In other words, if the microcode has an associated
                                                                 component density fj(x|hj), the distribution of the data set
          Figure 4: Sparse population coding scheme               DN  {x(1),..., x( N )} can be represented by the population
Sparse Population Coding                                         code:
We represent the joint vision-language concept using sparse          P(w (1), v(1),..., w ( N ), v( N ) |  )
population codes. Figure 4 shows the basic units of the                                              N   M
coding scheme, i.e. microcodes. Each microcode represents
a prototype, exemplar, or common pattern for a set of
                                                                      P(x(1),..., x( N ) |  )    
                                                                                                    t 1 j 1
                                                                                                                j f j (x(t ) | h j )     (2)
similar examples. For instance, a microcode h = {‘white’,                                      N
‘eye’, v1, v4} represents a class of objects (or concept         which is a sum of M products of component densities.
HEAD1 as indicated in the figure) that have white eyes and       Each term in the summation is interpreted as the probability
                                                                 of obtaining a given one of the MN possible divisions of the
image features of v1 and v4, where v1 and v4 are image
                                                                 observations among the groups.
patches. The textual words, ‘white’ and ‘eye’, and the visual
words, v1 and v4, are instances of the textual and visual word
                                                                 Learning Algorithm
vocabulary, respectively. Since the number of words or
visual words chosen to define the specific microcode is          Learning proceeds incrementally by observing each
small compared to their vocabulary size, this is a sparse        utterance-scene pair in sequence. On each observation of an
                                                               1223

example (w, v) the learner predicts and updates the                                 microcode (line 4). For each utterance-scene pair, a number
meanings or concepts θ. This is an inductive process and                            m of microcodes are generated randomly and repeatedly
can be formally described as Bayesian inference:                                    (line 4). Duplications are permitted and, in fact, the number
                                                                                    of duplications represents the strength of the code (we will
                                  P (w , v |  ) Pt 1 ( )                         use this later on in decoding the referents or meanings of the
           Pt ( | w , v )                                                  (3)    words). The set E of new microcodes is then added to the
                                          P(w, v)
At each time step t, the prior distribution Pt-1(θ) of the                          existing set H of microcodes (line 6). This step is equivalent
hypothesis θ is updated to the posterior distribution                               to accommodating new memory elements. Then the model
Pt(θ|w,v) of the hypotheses by computing the likelihood                             is trained to tune or assimilate the incoming concepts into
                                                                                    the existing concepts (lines 7-12). First, a collection H’’ of
function P(w, v |  ) and normalizing by                                            the microcodes is sampled to be used to generate an
                                                                                    example x’. The generated example is then compared to the
                     P(w, v)         
                                           P(w, v |  ') P  t 1 ( ')        (4)   training example. The difference is used to correct the
                                         '
                                                                                    model H or the population code. This results in the update
to make Pt(θ|w,v) back to a probability distribution. The                           of the posterior distribution (line 13).
posterior is then used as the prior for the next time step.                            The algorithm consists of basically three steps: i)
Making the data set explicit, we can rewrite (3) in a                               sampling new microcodes (line 4), ii) merging them with
recursive form:                                                                     the old (existing) population of microcodes (line 6), and iii)
   Pt ( | w (t ), v (t ), w (1: t  1), v (1: t  1))                              resampling of the whole microcode population (line 10) to
                                                                                    correct the conflicts and interferences. To correct predictive
      P (w (t ), v (t ) |  ) Pt 1 ( | w (1: t  1), v (1: t  1))
                                                                      ,      (5)   errors in an unsupervised way, the algorithm test-generates
            P (w (t ), v (t ) | w (1: t  1), v (1: t  1))                         the samples from the current model (lines 8 and 9) and
where w(t) and w(1:t-1) denote the word vector at time step                         compare the resulting data with the perceived data (line 10).
t and the sequence of word vectors from time step 1 to t-1,
respectively.          Expectation-maximization                     (EM)    style   Connection to Probabilistic Models of Cognition
algorithms are usually used to solve the estimation problem                         and Monte Carlo
(McLachlan & Peel, 2000). In the following we describe the                          Recall that the population of sparse codes approximates the
method we implemented as a sparse population coding                                 probability distribution of the examples if the population
network. Recall that θ = (,h), i.e. the concepts are                               size is big. Recall also that the learning algorithm is
represented as a collection of microcodes h with weights α                          implemented by repeatedly sampling the sparse codes
in the network. The population code is a mechanistic                                (microconcepts or hypotheses) like a Monte Carlo
representation for psychological processes since it describes                       simulation does. In terms of Bayesian inference the learning
the memory encoding and decoding mechanisms more                                    algorithm updates the distribution of the concepts from prior
explicitly than simplistic parameter tuning models.                                 to posterior distribution by Monte Carlo simulation. Shi et
  We first describe the learning algorithm in pseudocode                            al. (2010) suggested that exemplar models are a successful
and then explain it.                                                                class of psychological process models that can be used to
                                                                                    perform a sophisticated form of Monte Carlo approximation.
1  H(0)  {}, VT  {}, VI  {}                                                      The similarity of the sparse coding representation with the
2  t1                                     ; prior Pt 1 ( )                       exemplar model suggests that our sparse population code
3  Perceive x(t) = (w(t), v(t))                                                     model offers a concrete process model of Bayesian
4  E = {h1,…, hm}  Sample(x(t)) ; microcodes                                       cognition.
5  VT  VT + {new w’s}, VI  VI + {new v’s}
6  H’  H + E                                       ; accommodation                                 Simulations and Results
7  Repeat
8       H’’  Predict(H’)                            ; sampling prior Pt 1 ( )    Parameter Setting for Experiments
9       x’  Generate(H’’)                          ; likelihood P(x |  )          Experiments were performed using the following parameter
                                                                                    settings. Given a new observation, 10 new sparse codes
10      H’’’  Correct(H’’, x’, x(t)) ; assimilation                                were sampled and added to the population. Each microcode
                                                      (resampling)
                                                                                    consists of three textual words and one visual word. 5
11      H’  H’’’
                                                                                    iterations of error correcting steps were executed to tune the
12  Until reconstruction_satisfactory(x(t))
                                                                                    whole population code to the new observation. To see the
13  H(t)  H’                                         ; posterior Pt ( | x(t ))    effects of memory capacity we experimented with two sizes
14  t  t+1                                                                         of populations: |H| = 100, 500. When the population size
15  Go to 3                                                                         exceeds the memory capacity, we replace 10 microcodes
                                                                                    with the lowest weight values by 10 new microcodes. We
   Given an utterance-scene instance (line 3), a subset of                          define two scores for measuring the similarity between
words and a subset of visual words are selected to build a                          visual and textual concepts as follows:
                                                                                  1224

                                      1                                           suggesting the difficulty of the problem, especially if the
                            Hw        (h) and S (w)    (h)
                   1
 S ( w, v)                           2
                (h)
             hH w
                                           hH v                          hH w
                                                                                  memory capacity is small. However, this problem can be
                                                                                  solved by dynamically varying the population size to
where (h) is the weight of microcode h, and Hw and Hv are                        balance exploration and exploitation. In contrast to this
the subsets of H consisting of the microcodes with textual                        sparse population coding approach, a localist, eliminative
word w and visual patch v, respectively.                                          method would have a fundamental difficulty in recovering
                                                                                  once-eliminated concepts due to its lack of associative
Vocabulary Growth                                                                 connections between concepts.
                                                                                    S(v)
                                                                                   0.6
Figure 5 shows the growth of visual and textual                                                   Max(|H|) = 500
vocabularies as learning proceeds. When the memory size is                                        Max(|H|) = 100
                                                                                   0.5
unlimited (left), the size of both visual words and textual
                                                                                   0.4
words increases continuously (linearly). When the
maximum memory capacity is set to be limited to 500                                0.3
(right), the size of visual words increases first and then
                                                                                   0.2
decreases while the number of textual words grow
continuously but in two stages of fast growth and then                             0.1
slow growth. The difference in vocabulary growth pattern
                                                                                     0
seems in part due to the difference in vocabulary size of                                0    300 t 600       900
visual and textual words, i.e. in this experimental setting,
7520 visual words and 448 textual words were used for                                 Figure 7: (left) Emergence patterns of concepts for
candidates.                                                                       different memory size. Plotted are the weight values for the
 |V| (×103)                               |V| (×102)                              specific visual concept shown. (right) Emergence of
   8                                        5                                     different visual concepts for given three textual concept
                                                                      textual
                                            4                         visual      (rabbit, bird, and mouse).
   6
                                            3
                                                                                          Figure 7 shows the change of concepts in the course of
   4                                                                              learning. (left) shows the change of weight distribution for
                           textual          2
   2                       visual
                                                                                  the specific visual concept (patch 2 in Figure 6) shown.
                                            1
                                                                                  (right) is the reverse, i.e. the query is given by a textual
   0                                        0                                     word (rabbit) and the graph shows how the corresponding
       0     300   t   600      900            0        300   t   600      900
                                                                                  image concept changes as learning proceeds. It can be
   Figure 5: Growth of vocabulary. (left) unlimited memory                        observed that, since the concept of rabbit drifts, different
size. (right) limited memory size.                                                types of rabbit images and, sometimes very different (and
                                                                                  wrong) images, are retrieved by the same word.
Word Learning in Concept Drift
                                                                                  Concept Generalization and Specialization
Figure 6 shows the trace of concept memory for the 4
separate focus objects which appear in all episodes.                              Figure 8 shows the joint vision-language concept maps
                                                                                  around the ‘rabbit’ as they evolve over the 6 episodes. The
       S(v)                          S(v)
      0.5
               Patch 1     Patch 2
                                     0.6
                                                  Patch 1     Patch 2
                                                                                  maps (a)-(d) are the snapshots after watching 1, 2, 4, 6
               Patch 3     Patch 4                Patch 3     Patch 4             videos, respectively. Note that the map contains visual
                                     0.5
      0.4
                                     0.4
                                                                                  words as well as textual words. We observe that the
      0.3                                                                         connectivity of the visual-linguistic map grows as more
                                     0.3
      0.2
                                                                                  episodes are learned. Careful examination of the map shows
                                     0.2
                                                                                  the role of visual words or concepts for the specialization
      0.1                            0.1
                                                                                  and generalization of the textual concepts and vice versa.
        0                              0                                          For example, in Figure 8(a) we observe that a visual word
           0  300  t  600     900         0      300   t  600    900
                                                                                  connects the three textual words of ‘enjoy’, ‘lunch’, and
   Figure 6: Emergence, extinction, and re-emergence of                           ‘rabbit’ together. This adds an additional, visually-grounded,
concepts in drift. (left) larger memory capacity (|H| = 500).                     connection (association) between the words ‘enjoy’ and
(right) smaller memory capacity (|H| = 100).                                      ‘lunch’. We also observe that the word ‘rabbit’ is connected
                                                                                  to multiple images, again grounding and refining the
The results show the emergence, extinction, and re-                               meaning of the textual word. Formally, the former is the
emergence of different visual concepts as the video runs. If                      one-image to many-words relationship and the latter is the
the memory size is relatively big (500 in this case), the                         many-images to one-word relationship. This again shows
concepts do not extinct totally and remain in the backend to                      the effect of visual generalization of the textual words and
re-emerge when new similar observations are made. In                              that of visual specialization, respectively, which cannot be
contrast, when the memory size is small (100 in this case),                       observed in language-only concept maps (Zhang & Kang,
the concepts disappear entirely from the memory,                                  2011).
                                                                                1225

                                                                                     Acknowledgments
                                                              This work was supported by the National Research Foundation
                                                              (NRF) grants (0421-20110032-Videome, 2010-0018950-
                                                              BrainNet), the IT R&D Program of KEIT (10035348-mLife),
                                                              and the BK21-IT Program.
                                                                                          References
                                                              Barsalou, L. W. (1999). Perceptual symbol systems. Behavioral
                                                                and Brain Sciences, 22, 577-609.
        (a) episode 1                 (b) episodes 1-2        Burgess, C. & Lund, K. (1998). The dynamics of meaning in
                                                                memory. In Dietrich & Markman (Eds.), Cognitive Dynamics:
                                                                Conceptual Change in Humans and Machines.
                                                              Fazly, A., Alishahi, A., & Stevenson, S. (2010). A probabilistic
                                                                computational model of cross-situational word learning.
                                                                Cognitive Science, 34, 1017-1063.
                                                              Frank, M.C., Goodman, N.D., & Tenenbaum, J.B. (2009).
                                                                Using speakers’ referential intentions to model early cross-
                                                                situational word learning. Psychological Science, 20, 579-
                                                                585.
       (c) episodes 1-4                (d) episodes 1-6       Kachergis, G., Yu, C., & Shiffrin, R. M. (2010). Adaptive
                                                                constraints and inference in cross-situational word learning.
   Figure 8: Evolution of the vision-language concept map       Proceedings of 2010 Annual Conference of the Cognitive Science
for ‘rabbit’.                                                   Society (pp. 2464-2469).
                                                              Ma, W., Beck, J., Latham, P., & Pouget, A. (2006). Bayesian
                        Discussion                              inference with probabilistic population codes. Nature
                                                                Neuroscience, 9 (11), 1432-1438.
We have presented a sparse population code model of cross-    McLachlan, G.J., & Peel, D. (2000). Finite mixture models.
situated word learning in concept drift. The sparse             Wiley.
population coding was utilized to flexibly represent and      Pouget A, Dayan P, & Zemel, R. (2000). Information processing
learn the meanings of words over time. We examined the          with population codes. Nature Reviews Neuroscience, 1(2), 125-
concept drift in word learning using the story-telling          32.
                                                              Shi, L., Griffiths, T. L., Feldman, N. H., & Sanborn, A. N. (2010).
situations in cartoon videos. The experimental results          Exemplar models as a mechanism for performing Bayesian
demonstrate that the model is effective in learning the         inference. Psychonomic Bulletin & Review, 17(4), 443-464.
dynamically changing meanings of the words.                   Siskind, J. M. (1996). A computational study of cross-situational
   We adopted a distributed, relational representation of       techniques for learning word-to-meaning mappings. Cognition,
word meaning which is naturally realized as a population of     61(12), 1–38.
sparse codes. The learning process constructs visually-       Smith, L., & Yu, C. (2008). Infants rapidly learn word-referent
                                                                mappings via cross-situational statistics. Cognition, 106(3),
grounded linguistic knowledge structure from a series of        1558–1568.
cross-situational language experience. This situated          Steyvers, M., & Tenenbaum, J. B. (2005). The large-scale structure
conceptualization process (Barsalou, 1999) is known to          of semantic networks: statistical analyses and a model of
build a foundational mechanism in language learning             semantic growth. Cognitive Science, 29, 41-78
(Zwaan & Kaschak, 2008). We analyzed the “evolution” of       Vlach, H. A., & Sandhofer, C. M. (2010). Desirable difficulties in
joint vision-language maps and compared them to the             cross-situational word learning. Proceedings of 2010 Annual
                                                                Conference of the Cognitive Science Society (pp. 2470-2475).
language-only concept maps. We found that the visual          Widmer, G. & Kubat, M. (1996). Learning in the presence
modality adds additional semantics to the linguistic            of concept drift and hidden contexts, Machine Learning, 23, 69-
concepts as well as generalizing and/or specializing the        101.
linguistic terms.                                             Xu, F., & Tenenbaum, J. B. (2007). Word learning as Bayesian
   There are several directions of future research that can     inference. Psychological Review, 114(2), 245-271.
extend the current work. One is to define the vocabulary      Yu, C. (2005). The emergence of links between lexical acquisition
                                                                and object categorization: A computational study. Connection
incrementally. The current experiments have used a set of       Science, 17(3–4), 381–397.
words and visual words which are defined at the outset.       Zhang, B.-T. (2008). Hypernetworks: A molecular evolutionary
Children learn the new words on the fly. A more natural         architecture for cognitive learning and memory, IEEE
approach would employ a component that evaluates the            Computational Intelligence Magazine, 3(3), 49-63.
novelty and decide the introduction of new terms. Another     Zhang, B.-T., & Kang, M.-G. (2011). Bayesian mixture modeling
                                                                of joint vision-language concepts from videos, NIPS-2011
direction involves extending the current population-code
                                                                Workshop on Integrating Language and Vision.
network model by introducing another layer of latent          Zwaan, R.A. & Kaschak, M.P. (2008) Language in the brain,
variables. This layer can be learned to build more abstract     body, and world. Chap.19. Cambridge handbook of situated
concept categories using, for example, non-parametric           cognition.
Bayesian methods.
                                                            1226

