UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Rationality-Guided AGI as Cognitive Systems
Permalink
https://escholarship.org/uc/item/7xd1940g
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Abdel-Fattah, Ahmed M.H.
Besold, Tarek R.
Gust, Helmar
et al.
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                  Rationality-Guided AGI as Cognitive Systems
                                      Ahmed Abdel-Fattah, Tarek R. Besold, Helmar Gust,
                                     Ulf Krumnack, Martin Schmidt, Kai-Uwe Kühnberger
                        ({ahabdelfatta | tbesold | hgust | krumnack | martisch | kkuehnbe}@uni-osnabrueck.de)
                                          Institute of Cognitive Science, University of Osnabrück,
                                                 Albrechtstr. 28, 49076 Osnabrück, Germany
                                                                   Pei Wang
                                                           (pei.wang@temple.edu)
             Department of Computer and Information Sciences, College of Science & Technology, Temple University,
                                            1805 N. Broad Street, Philadelphia, PA 19122 USA
                               Abstract                                   methodologies (Baum, Hutter, & Kitzelmann, 2010). Here,
   The integration of artificial intelligence (AI) within cogni-          we approach cognition in AGI systems by particularly pro-
   tive science (CogSci) necessitates further elaborations on, and        moting “rationality” as one of such indispensable criteria, and
   modelings of, several indispensable cognitive criteria. We ap-         analyze some divergent, sometimes seemingly irrational, be-
   proach this issue by emphasizing the close relation between ar-
   tificial general intelligence (AGI) and CogSci, and discussing,        haviors of humans.
   particularly, “rationality” as one of such indispensable criteria.        In this article, our goal is twofold. We first concern
   We give arguments evincing that normative models of human-             ourselves with explicitly allocating ideas from AGI within
   like rationality are vital in AGI systems, where the treatment
   of deviations from traditional rationality models is also nec-         CogSci. Second, we give a conceptual account on some prin-
   essary. After conceptually addressing our rationality-guided           ciples in normative rationality-guided approaches. After ex-
   approach, two case-study systems, NARS and HDTP, are dis-              plaining our approach at a general level, we explain how two
   cussed, explaining how the allegedly “irrational” behaviors can
   be treated within the respective frameworks.                           cognitively inspired systems, namely NARS and HDTP, have
   Keywords: Rationality; intelligence; AGI; HDTP; NARS                   the potential to handle (ir)rationality. We conclude by giving
                                                                          some remarks and future speculations.
               Motivations and Background
                                                                          Why AGI?
For more than five decades, artificial intelligence (AI) has
always been a promising field of research on modeling hu-                 In current AGI research, there are approaches following dif-
man intelligence. The success of projects like IBM’s Watson               ferent paths, including those (1) inspired by the structure of
(Ferrucci et al., 2010), for instance, increases the hopes in             human brain or the behavior of human mind, (2) driven by
achieving not only language intelligence but also inference               practical demands in problem solving, or (3) guided by ratio-
mechanisms at a human-level and paves the way for solving                 nal principles in information processing. We are concerned
more baffling tasks. However, AI has turned into a vague, un-             with the latter approach, which has at least three essential ad-
specific term, in particular because of the tremendous num-               vantages. One advantage of the rationality-guided approach,
ber of applications that belong, in fact, to seemingly orthogo-           from an AGI perspective, is that it is less bound to exactly
nal directions. Philosophers, psychologists, anthropologists,             reproducing human faculties on a functional level. Another
computer scientists, linguists or even science fiction writers            advantage is that it gives AI the possibility of being estab-
have disparate ideas as to what AI is (or should be). The                 lished in a way similar to other disciplines, where it can give
challenge becomes more obvious when AI is looked at from                  a theoretical explanation to intelligence as a process that can
a CogSci perspective, where the focus is mainly on explain-               be realized both in biological systems and computational de-
ing processes of general cognitive mechanisms (not only on                vices. The third advantage of the rationality-guided approach
how one or another intelligence task can be solved by a com-              is that it is not limited to a specific domain or problem.
puter). We think that from a CogSci perspective the kind of
intelligence characterizing classical AI problems is not yet                                         Rationality
exhaustive enough. Solutions to most of the problems are not              The term rationality is used in a variety of ways in various
cognitively inspired: neither do they consider essential cogni-           disciplines. In CogSci, rationality usually refers to a way
tive mechanisms (or general intelligence results) nor do they             a cognitive agent deliberatively (and attentively) behaves in,
show the biological plausibility of the solutions.                        according to a specific normative theory. The prototypical in-
   Artificial General Intelligence (AGI) refers to a research             stance of cognitive agents that can show rational behavior is
direction that takes AI back to its original goals of confronting         humans, who so far are also the ultimate exemplar of gener-
the more difficult issues of human-level intelligence as a                ally intelligent agents. When modeling intelligence, it is rea-
whole. Current AGI research explores all available paths, in-             sonable to initially take the remarkable abilities of humans
cluding theoretical and experimental computer science, cog-               into account with respect to rational behavior, but also their
nitive science, neuroscience, and innovative interdisciplinary            apparent deficiencies that show up in certain tasks.
                                                                      1242

   Surprisingly little attention has been paid so far in AI to-          In order to make such challenges of rationality theories
wards a theory of rationality. A reason might be that the con-       more precise, we discuss some aspects of the famous Wason
cept of rationality was too broad in order to be of interest         selection task and the Linda problem in more detail.
to AI, where for a long time usually relatively specific cog-
                                                                     Wason Selection Task This task shows that a large major-
nitive abilities were modeled and heuristics were suggested.
                                                                     ity of subjects are seemingly unable to evaluate the truth of
Moreover, an artificial cognitive agent is usually intended to
                                                                     a simple rule of the form “if p then q” (Wason & Shapiro,
reproduce rational behavior, not to act in seemingly irrational
                                                                     1971). In the version depicted in Table 1.a, this rule is rep-
ways. Consequently, AI researchers are not interested in re-
                                                                     resented by: “If on one side of the card there is a D, then on
sults of some classical rationality puzzles. Still, we think that
                                                                     the other there is the number 3”. According to classical logic,
a move towards integrating AGI in CogSci cannot ignore ra-
                                                                     in order to assign a truth-value to this rule, subjects need to
tionality issues, neither the remarkable abilities nor the origi-
                                                                     turn D and 7. What is interesting is the fact that a slight mod-
nalities human subjects show in rationality tasks.
                                                                     ification of the content of the rule to a setting more familiar
Traditional Models of Rationality                                    from daily life, while keeping the structure of the problem
                                                                     isomorphic, makes subjects perform significantly better, as
Different models of rationality use significantly different
                                                                     e.g. shown in (Cosmides & Tooby, 1993).
methodologies. Clustering such models according to the
underlying formalism usually results in at least the follow-
ing four classes: (1) logic-based models (Evans, 2002), (2)          Table 1: a. A description of the Wason selection task. b. An
probability-based models (Griffiths, Kemp, & Tenenbaum,              abbreviated version of the Linda problem setting.
2008), (3) heuristic-based models (Gigerenzer, 2008), and
(4) game-theoretically based models (Osborne & Rubinstein,             a. Wason Selection Task (Wason & Shapiro, 1971):
1994). Several of these models have been proposed for estab-           Every card which has a D on one side has a 3 on the other side
lishing a normative theory of rationality, normally by judging         (and knowledge that each card has a letter on one side and a
                                                                       number on the other side), together with four cards showing
a belief as rational if it has been obtained by a formally cor-        respectively D, K, 3, 7, hardly any individuals make the correct
rect application of the respective reasoning mechanism, given          choice of cards to turn over (D and 7) in order to determine the
some background beliefs or knowledge (cf. e.g. also (Gust et           truth of the sentence. This problem is called “selection task”
                                                                       and the conditional sentence is called “the rule”.
al., 2011; Wang, 2011)). Therefore, such theories of rational-
ity are not only intended to model “rational behavior” of hu-           b. Linda Problem (Tversky & Kahneman, 1983):
mans, but to postdictively decide whether a particular belief,          Linda is 31 years old, single, outspoken and very bright. She
action, or behavior is rational or not. Nonetheless, although a         majored in philosophy. As a student, she was deeply concerned
                                                                        with issues of discrimination and social justice, and also partic-
conceptual clarification of rational belief and rational behav-         ipated in anti-nuclear demonstrations.
ior is without any doubts desirable, it is strongly questionable        (F): Linda is active in the feminist movement.
whether the large number of different (quite often orthogo-             (T): Linda is a bank teller.
nal) frameworks makes this task easier, or if the creation of           (T&F): Linda is a bank teller and is active in the feminist move-
a more unified approach wouldn’t be recommendable. From                 ment.
our perspective, basic cognitive mechanisms seem to offer a
basis for such an endeavor.
                                                                     Linda Problem With respect to the Linda problem
Some Rationality Challenges and Puzzles                              (Tversky & Kahneman, 1983) it seems to be the case that sub-
Although the models mentioned above have been proven to be           jects have problems to prevent the so-called conjunction fal-
quite successful in modeling certain aspects of intelligence,        lacy: subjects are told a story specifying a particular profile
all four types of models have been challenged. For example,          about someone called Linda. Then, some statements about
in the famous Wason selection task (Wason & Shapiro, 1971)           Linda are shown and subjects are asked to order them accord-
human subjects fail at a seemingly simple logical task (cf.          ing to their probability (cf. Table 1.b). 85% of subjects decide
Table 1.a). Similarly, Tversky and Kahneman’s Linda prob-            to rank the statements “Linda is a bank teller and is active in
lem (Tversky & Kahneman, 1983) illustrates a striking viola-         the feminist movement” (T & F) as more probable than the
tion of the rules of probability theory in a seemingly simple        statement “Linda is a bank teller” (T). This ranking conflicts
reasoning problem (cf. Table 1.b). Heuristic approaches to           with the laws of probability theory, because the probability of
judgment and reasoning try to stay closer to the observed be-        two events (T & F) is less than or at most equal to the proba-
havior and its deviation from rational standards (Gigerenzer,        bility of one of the events (e.g. (T)).
2008), but they fail in having the formal transparency and
clarity of logic-based or probability-based frameworks with          Classical Resolution Strategies of Irrationality
regard to giving a rational explanation of behavior. Game-           Many strategies have been proposed to address the men-
based frameworks can be questioned due to the various forms          tioned challenges, ranging from the use of non-classical log-
of optimality concepts in game-theory that can support differ-       ics to model subjects’ behavior in the Wason selection task
ent “rational behaviors” for one and the same situation.             (Stenning & van Lambalgen, 2008), to considerations involv-
                                                                 1243

ing reasoning in semantic models instead of (syntactic) de-           (with respect to the problems to be solved), an axiomatic
ductions (Johnson-Laird, 1988) in the case of the Wason se-           logic (such as classical logic) can be used, which treats the
lection task. With respect to the Linda problem it has been           available knowledge as axioms, and derives theorems from
argued that pure probability theory is not appropriate for ad-        them to solve a given problem. When the system has insuf-
dressing the problem properly, but a foundation of the anal-          ficient knowledge, it has no absolute truth to be used as ax-
ysis of this problem in coherence theories would be neces-            ioms, so has to follow some “non-axiomatic” logic, whose
sary (Pfeifer, 2008). Another resolution strategy applicable to       premises and conclusions are all revisable by new evidence.
both puzzles is to question whether tasks were appropriately          In Wason’s task, the expected results are the ones assuming
phrased in the respective experiments. In the Wason selection         an axiomatic system, while the actual results may be con-
task the “if-then” rule presented in natural language is usu-         sistent with a non-axiomatic one. Therefore, the “mistake”
ally not equivalent to its interpretation in classical logic, and     here is mainly the misunderstanding between the psycholo-
in the Linda puzzle the term “probable” can be interpreted            gists who run the tests and the subjects who take the tests.
differently by the subjects (Gigerenzer, 2005). In any case,          In this artificially structured experiment, it is valid for the
although there are many proposals to address the challenges,          psychologists to assume sufficient knowledge and resources,
there is no generally accepted rationality concept available          therefore to expect the application of an axiomatic type of in-
yet. Moreover, specific frameworks can address specific chal-         ference mechanism. Their mistake, however, is the failure to
lenges, but do not generalize to the breadth of the mentioned         see the result as coming from another type of inference. On
problems.                                                             the side of subjects, since non-axiomatic reasoning is used
   For a generally intelligent cognitive system a question that       more often in everyday life, most of them fail to understand
can be raised is: which principles of rationality can be trans-       the experiment setting as a testing of their capacity of us-
ferred to and modeled in AGI systems, in order to achieve             ing an axiomatic inference mechanism. This explains why
intelligence on a human scale? We will argue for models that          many subjects admit their mistake afterwards, and do better
link rationality to the ability of humans to establish analogical     in the content-change task (as soon as they realized that the
relations (continuing a line of reasoning started in (Besold et       expected way of reasoning is not their default one, they have
al., 2011)), and to the ability to adapt to the environment by        less problem to adapt to follow it).
making good use of previously obtained experiences.                   Resolving the Linda Problem by Cognitive Mechanisms
                                                                      Here, a natural explanation of subjects’ behavior is that there
Non-Standard, CogSci-Based Approaches
                                                                      is a lower degree of coherence of Linda’s profile plus the
The two examples discussed above definitely show that hu-             statement “Linda is a bank teller” in comparison to the degree
mans have sometimes problems to apply rules of classical              of coherence of Linda’s profile plus the statement “Linda is
logic correctly (at least in rather abstract and artificial situ-     a bank teller and is active in the feminist movement”, as in
ations), and to reason according to the Kolmogorov axioms             the conjunctive statement, at least one conjunct of the state-
of probability theory. Nonetheless, the most that can be con-         ment fits quite well to Linda’s profile. Coherence (Thagard,
cluded from the experiments is that human agents are nei-             2002) is a complicated concept that needs to be discussed in
ther classical deduction machines nor probability estimators,         more detail (as does its connection to notions like the idea of
but perform their indisputable reasoning capabilities by other        representativeness proposed as an explanation for the Linda
means, necessarily linked to their cognitive capacities.              problem by Tversky and Kahneman themselves), but it can
Resolving the Selection Task by Cognitive Mechanisms                  be mentioned that coherence is important for the successful
As mentioned above, subjects perform better (in the sense of          establishment of an analogical relation, as well as for guiding
more according to the laws of classical logic) in the Wason se-       adaptation of obtained knowledge and experiences. In order
lection task, if content-change makes the task easier to access       to make sense out of the task, subjects tend to rate statements
for subjects. We think that the performance of subjects has a         with a higher probability where facts are arranged in a theory
lot to do with the ability of subjects to establish appropriate       with a higher degree of coherence. Also, this can be thought
analogies. Subjects perform badly in the classical version of         of as a form of coherently adapting beliefs, which also de-
the Wason selection task, probably because they fail to estab-        pends heavily on subjects’ experiences rather than on their
lish a correct analogy. Therefore, subjects fall back to other        knowledge of Kolmogorov axioms of probability theory.
(less reliable) strategies to solve the problem. In a content-
change version of the task the situation is different, because                 Modeling Rationality: Case Studies
subjects can do what they would do in an everyday analogous           Formal and computational models in CogSci can be roughly
situation. In short, the success or failure of managing the task      divided into two major types: descriptive and normative. A
is crucially dependent on the possibility to establish a mean-        descriptive model explains how a system actually works, and
ingful analogy.                                                       its establishment is based on empirical data. A descriptive
   Another related resolution is to study the mode of the in-         model’s quality is evaluated according to its behavior’s sim-
ference that should underly a normative theory of rational-           ilarity to that of humans. A normative model, on the other
ity. When a system has sufficient knowledge and resources             hand, specifies how a system should work, and its estab-
                                                                  1244

lishment is based on certain general principles or postulates.         the truth-value of a statement only depends on the existence
Such a normative model’s quality is evaluated according to its         of negative evidence, and whether there is positive evidence
behavior’s coherence with these basic assumptions. Though              does not matter. Furthermore, classical logic does not con-
the two types of models are closely related, they are still built      sider resource restriction at all. For a detailed discussion on
and evaluated differently (Wang, 2011). When building a                evidence and truth-value in NARS, see (Wang, 2009).
model of rationality, a central issue is the selection of the as-         In NARS, the meaning of a concept, such as “Linda” or
sumptions on which the model is based, since all conclusions           “feminist bank-teller”, is determined by the available infor-
about the model are derived from, and justified against, these         mation about it, in terms of how it relates to other concepts,
assumptions.                                                           as far as the system knows. For a given concept, such infor-
   In the following, we give two examples for cognitively              mation may be either extensional (indicating its instances or
inspired systems: NARS and HDTP. Both stand in a cer-                  special cases) or intensional (indicating its properties or gen-
tain tradition to classical cognitive architectures like the well-     eral cases). To decide the extent to which a concept, “Linda”,
known models ACT-R (Anderson & Lebiere, 1998) and                      is a special case of another one, “bank-teller” or “feminist
SOAR (Laird, Newell, & Rosenbloom, 1987), because they                 bank-teller”, the system will consider all available evidence.
attempt to model cognition in breadth and not relative to              In this example, the most accessible evidence about all three
highly specialized abilities. Nevertheless, because NARS and           concepts are intensional (i.e., about their properties), so the
HDTP stand in a tradition of modeling the competence as-               system reaches its conclusion by checking if Linda has the
pect of general intelligence, they attempt to integrate a bunch        properties usually associated with “bank-teller” and “feminist
of different human-inspired reasoning abilities, and they try          bank-teller”, respectively. Since according to the given in-
to integrate these abilities in uniform models, they also differ       formation Linda has more common properties with “feminist
significantly from the mentioned classical cognitive architec-         bank-teller” than with “bank-teller”, her “degree of member-
tures. We briefly introduce NARS and HDTP and discuss                  ship” is higher to the former than to the latter. This is judged
how they can account for “irrational” behaviors in tasks, such         as a “fallacy” when probability theory is applied extension-
as the Selection Task and the Linda problem.                           ally to this situation, so only the base rates matters, while the
AGI with Relative Rationality (NARS) NARS (Non-                        properties do not. For a detailed discussion on the categoriza-
Axiomatic Reasoning System) is an AGI system designed                  tion model in NARS, see (Wang & Hofstadter, 2006).
under the assumption that the system usually has insufficient             In summary, as soon as a normative model of rationality or
knowledge and resources with respect to the problems to be             intelligence makes more realistic assumptions, many “heuris-
solved, and must adapt to its environment. Therefore, the              tics”, “bias”, and even “fallacies” follow from them. In the
system realizes a “relative rationality”, that is, the solutions       above examples, there are strong reasons for assuming that
are the best the system can get under the current knowledge–           the truth-value of a statement should depend on both posi-
resource restriction (Wang, 2011). Since this system has been          tive and negative evidence (rather than negative only), and
described in a book (Wang, 2006) and many papers (most of              the meaning of a concept should depend on both extensional
which are available at the the last author’s website1 ), here we       and intensional relations (rather than extensional only). We
only briefly explain the treatment of the “Selection Task” and         believe these examples mainly show the limitations of tradi-
“Conjunction Fallacy” in NARS.                                         tional models (classical logic, probability theory), rather than
   Since NARS has insufficient knowledge and resources,                human errors. The practice of NARS and similar systems
its beliefs are not “absolute truth” but summary of the sys-           shows that it is possible for a new normative model to explain
tem’s experience. Especially, the truth-value of a statement           and reproduce similar results in a unified way.
measures its evidential support, and the evidence can be ei-           Rationality Through Analogy (HDTP) As a second case
ther positive or negative, depending on whether the evidence           study, we want to sketch how Heuristic-Driven Theory Pro-
agrees with the statement. Concretely, for statement “If on            jection (HDTP), an analogy-engine, can be used to imple-
one side of the card there is a D, then on the other there is          ment some crucial parts of our cognitively-based theory of
the number 3”, the D card always provides evidence (posi-              rationality (for an expanded elaboration cf. e.g. (Besold et
tive if the other side is 3, otherwise negative); the 3 card may       al., 2012)). HDTP is a framework for computing analogical
provide positive evidence (if the other side is D); the 7 card         relations between two domains that are axiomatized in many-
may provide negative evidence (if the other side is D); the K          sorted first-order logic (Schwering, Krumnack, Kühnberger,
card provides no evidence. To determine the truth-value of             & Gust, 2009). It provides an explicit generalization of the
the statement, all cards except K should be checked, but due           two domains as a by-product of establishing an analogy. Such
to insufficient resources, the system may fail to recognize all        a generalization can be a base for concept creation by abstrac-
evidence. In this case, D is the easiest, while 7 the hardest.         tion. HDTP proceeds in two phases: in the mapping phase,
This result is consistent with the common responses of human           the source and target domains are compared to find struc-
beings. It is labeled as “irrational”, because in classical logic      tural commonalities, and a generalized description is created,
                                                                       which subsumes the matching parts of both domains. In the
    1 At http://www.cis.temple.edu/∼pwang/papers.html.                 transfer phase, unmatched knowledge in the source domain
                                                                   1245

is mapped to the target domain to establish new hypothe-             experiment and a standard situation in daily life, in which
ses. HDTP is therefore similar in spirit to the well-known           they would simply do the necessary actions to check whether
Structure-Mapping Engine (SME) (Falkenhainer, Forbus, &              there is someone who is drinking beer in the bar without being
Gentner, 1989), e.g. with respect to the mentioned mapping           older than 21: check people who are drinking beer, and check
and transfer phases and the symbolic representation of do-           what people are drinking who are 16. As both situations are
mains. Nevertheless, HDTP also differs significantly from            very similar to each other, the generalization is straightfor-
SME, e.g. with respect to the strong expressive power of the         ward, substitutions length are minimal, and coverage is high.
underlying domain theories (many-sorted first-order logic in            The Linda problem is structurally different in comparison
HDTP vs. propositional logic in SME), the establishment of           to the Wason selection task. In an analogy making context,
the analogy relation as a by-product of an abstraction, and the      an explanation of subjects’ behavior in terms of coherence
massive usage of heuristics differ from the ones used in SME.        maximization is promising. Coherence aspects of input the-
   HDTP implements a principle (by using heuristics) that            ories are crucial for establishing analogies in several ways.
maximizes the coverage of the involved domains (Schwering            Roughly speaking, the statement “Linda is a bank teller”
et al., 2009). Intuitively, this means that the sub-theory of the    has less coherence with Linda’s profile than the statement
source (or the target) that can be generated by re-instantiating     “Linda is a bank teller and is active in the feminist move-
the generalization is maximized. The higher the coverage the         ment”. Therefore, it is easier to establish an analogy between
better, because more support for the analogy is provided by          Linda as given in Linda’s profile and Linda as described in
the generalization. A further heuristics in HDTP, for which          “Linda is a bank teller and is active in the feminist move-
the motivation is to prevent arbitrary associations, is the min-     ment” than in the pure “bank teller” case. Notice that from
imization of substitution lengths in the analogical relation,        an abstract point of view the coherence-based resolution of
i.e. the simpler the analogy the better (Gust, Kühnberger,          the task is rather similar with the intensional interpretation of
& Schmid, 2006). There is a trade-off between high cover-            the task in NARS, where “feminist bank teller” has a higher
age and simplicity of substitutions: An appropriate analogy          degree of membership with Linda’s profile than “bank teller”.
should intuitively be as simple as possible, but also as gen-
eral and broad as necessary, in order to be non-trivial. This                     Conclusion and Future Work
kind of trade-off is similar to the trade-off that is usually the    There are multiple models of rationality, each with its own as-
topic of model selection in machine learning and statistics.         sumptions and applicable situations. The traditional models
   The modeling of the Wason selection task with HDTP is             are based on certain idealized assumptions, and thus are lim-
quite simple as long as appropriate background knowledge             ited to the domains where the latter are satisfied. Since human
is available, in case an analogy should be established, or the       cognition has evolved in and is usually used in realistic situ-
lack of appropriate background knowledge prevents analogy            ations where those idealized assumptions do not hold, those
making, in case no analogy should be established. In other           models of rationality are not universally applicable, and vio-
words, the availability of appropriate resources in form of          lations should not be deemed “irrational” per se. The seem-
background knowledge is crucial. If appropriate background           ingly irrational behaviors are there not because the intelligent
knowledge for an analogous case is missing, then there is            systems (e.g. humans) are irrational, but because the tradi-
no chance to establish an analogical relation or a potential         tional normative theories do not cover rationality very well.
analogy (with low coverage and complex substitutions) is                Instead, we believe what is needed are new models of ra-
misleading the subject. Hence, subjects have to apply other          tionality that are based on more realistic assumptions and de-
strategies. This is the situation when subjects are confronted       veloped in a more holistic framework. Such models should be
with the original Wason selection task based on properties of        able to provide an adequate and feasible positive account of
cards. Most subjects have problems to establish a meaning-           actual human rationality, also accommodating particularities
ful analogy with a well-known domain due to the high degree          of human-style reasoning. Such a framework could form a
of abstractness of the task itself. In the other case, if there      cornerstone of a closer connection between AGI and CogSci,
is a source theory with sufficient structural commonalities,         embedding important parts of the AGI program within a
then the establishment of an analogical relation is straightfor-     CogSci context, whilst making the more general methods and
ward. This happens if the task is changed in the following           theories of AGI accessible to the CogSci side.
way: the rule that needs to be checked is now: “If some-                The overall appeal for a “more cognitive” view on ratio-
one is drinking beer in a bar, he / she must be older than           nality models and systems is infrequent, but not unusual.
21”. In the experiment, subjects can choose between “drink-          Amongst others, already Kokinov (2003) reaches the conclu-
ing beer”, “drinking coke”, “25 years old”, and “16 years            sion that the concept of rationality as a theory in its own right
old” (Cosmides & Tooby, 1993). In the corresponding exper-           ought to be replaced by a multilevel theory based on cognitive
iments, subjects behave significantly better than in the orig-       processes involved in decision-making. On the more techni-
inal selection task. With analogy making the improvement             cal side, there is a growing body of evidence that analogy
of the subjects in mastering the task can be explained. They         engines (like HDTP) and general-purpose reasoning engines
can establish an analogy between the sketched set-up of the          (like NARS) can be used for implementing these cognitive
                                                                 1246

mechanisms and, thus, also as foundations of a rationality-       Gigerenzer, G. (2005). I think, therefore I err. Social Re-
guided approach to general intelligence.                            search, 72(1), 195–218.
   This paper should merely be considered as a point of depar-    Gigerenzer, G. (2008). Rationality for Mortals: How People
ture, leaving questions for future research galore. For exam-       Cope with Uncertainty. Oxford University Press.
ple with respect to the present proposal concerning HDTP, it      Griffiths, T., Kemp, C., & Tenenbaum, J. (2008). Bayesian
seems recommendable to figure out to which extent different         Models of Cognition. In R. Sun (Ed.), The Cambridge
types of coherence concepts can be integrated into the frame-       Handbook of Computational Cognitive Modeling. Cam-
work. In particular, the challenges mentioned above need to         bridge University Press.
be addressed, and a formal treatment of coherence needs to        Gust, H., Krumnack, U., Martı́nez, M., Abdel-Fattah, A.,
be fleshed out. Furthermore, an implementation of coher-            Schmidt, M., & Kühnberger, K.-U. (2011). Rationality and
ence principles for retrieval, mapping, and re-representation       General Intelligence. In J. Schmidhuber, K. Thorisson, &
purposed in the analogy making process needs to be formu-           M. Looks (Eds.), Artificial General Intelligence (pp. 174–
lated. Concerning NARS, amongst others the following is-            183).
sues would merit work and effort: real-time temporal in-          Gust, H., Kühnberger, K.-U., & Schmid, U.              (2006).
ference, procedural inference, and self-control. Regarding          Metaphors and Heuristic-Driven Theory Projection
competing theories for rationality, clarifying to what extent       (HDTP). Theor. Comput. Sci., 354, 98–117.
cognitive capacities and limitations have already been taken      Johnson-Laird, P. (1988). Cognitive science. Cambridge
into account (implicitly as well as explicitly) when designing      University Press.
the theories, and to what extent the classical frameworks can     Kokinov, B. (2003). Analogy in Decision-Making, Social In-
be re-instantiated by a cognitively-based approach, has to be       teraction, and Emergent Rationality. Behavioral and Brain
considered one of the principal questions for future research.      Sciences, 26(2), 167–168.
Finally, on a fundamental conceptual level, a broader defini-     Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987). SOAR:
tion of rational beliefs is still needed.                           An Architecture for General Intelligence. Artificial Intelli-
                                                                    gence, 1–64.
                          References                              Osborne, M., & Rubinstein, A. (1994). A Course in Game
                                                                    Theory. MIT Press.
Anderson, J. R., & Lebiere, C. (1998). The Atomic Compo-          Pfeifer, N. (2008). A Probability Logical Interpretation
   nents of Thought. Mahwah, NJ: Erlbaum.                           of Fallacies. In G. Kreuzbauer, N. Gratzl, & E. Hiebl
Baum, E., Hutter, M., & Kitzelmann, E. (Eds.). (2010). Arti-        (Eds.), Rhetorische Wissenschaft: Rede und Argumentation
   ficial General Intelligence. Lugano, Switzerland: Atlantis       in Theorie und Praxis (pp. 225–244). LIT-Verlag.
   Press.                                                         Schwering, A., Krumnack, U., Kühnberger, K.-U., & Gust,
Besold, T. R., Gust, H., Krumnack, U., Abdel-Fattah, A.,            H. (2009). Syntactic Principles of Heuristic-Driven Theory
   Schmidt, M., & Kühnberger, K. (2011, July). An Argument         Projection. Journal of Cognitive Systems Research, 10(3),
   for an Analogical Perspective on Rationality & Decision-         251–269.
   Making. In J. van Eijck & R. Verbrugge (Eds.), Proc.           Stenning, K., & van Lambalgen, M. (2008). Human Reason-
   of the Workshop Reasoning About Other Minds (RAOM-               ing and Cognitive Science. MIT Press.
   2011). CEUR-WS.org, Vol. 751.                                  Thagard, P. (2002). Coherence in Thought and Action. MIT
Besold, T. R., Gust, H., Krumnack, U., Schmidt, M., Abdel-          Press.
   Fattah, A., & Kühnberger, K.-U. (2012). Rationality           Tversky, A., & Kahneman, D. (1983). Extensional Versus In-
   Through Analogy - Towards a Positive Theory and Im-              tuitive Reasoning: The Conjunction Fallacy in Probability
   plementation of Human-Style Rationality. In I. Troch &           Judgment. Psychological Review, 90(4), 293–315.
   F. Breitenecker (Eds.), Proc. of MATHMOD 12 Vienna.            Wang, P. (2006). Rigid Flexibility: The Logic of Intelligence.
Cosmides, L., & Tooby, J. (1993). Cognitive adaptations for         Dordrecht: Springer.
   social exchange. In J. H. Barkow and L. Cosmides and J.        Wang, P. (2009). Formalization of Evidence: A Comparative
   Tooby (Ed.), The Adapted Mind: Evolutionary Psychology           Study. Journal of Artificial General Intelligence, 1, 25–53.
   and the Generation of Culture (pp. 163–228). Oxford.           Wang, P. (2011). The Assumption on Knowledge and Re-
Evans, J. (2002). Logic and Human Reasoning: An Assess-             sources in Models of Rationality. International Journal of
   ment of the Deduction Paradigm. Psychological Bulletin,          Machine Consciousness (IJMC), 3, 193–218.
   128, 978–996.                                                  Wang, P., & Hofstadter, D. (2006). A Logic of Categoriza-
Falkenhainer, B., Forbus, K., & Gentner, D. (1989). The             tion. Journal of Experimental & Theoretical Artificial In-
   Structure-Mapping Engine: Algorithm and Example. Arti-           telligence, 18(2), 193–213.
   ficial Intelligence, 41, 1–63.                                 Wason, P. C., & Shapiro, D. (1971). Natural and Contrived
Ferrucci, D., Brown, E., Chu-Carroll, J., Fan, J., Gondek,          Experience in a Reasoning Problem. Quarterly Journal of
   D., Kalyanpur, A., et al. (2010). Building Watson: An            Experimental Psychology, 23, 63–71.
   Overview of the DeepQA Project. AI Magazine, 31(3), 59–
   79.
                                                              1247

