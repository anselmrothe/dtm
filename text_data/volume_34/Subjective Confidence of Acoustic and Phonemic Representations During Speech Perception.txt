UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Subjective Confidence of Acoustic and Phonemic Representations During Speech Perception
Permalink
https://escholarship.org/uc/item/44d31767
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Schoenherr, Jordan
Logan, John
Winchester, Amy
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    Subjective Confidence of Acoustic and Phonemic Representations
                                                  During Speech Perception
                                   Jordan Schoenherr (psychophysics.lab@gmail.com)
                                             John Logan (john_logan@ carleton.ca)
                                     Amy Winchester (awinches@connect.carleton.ca)
                                            Department of Psychology, Carleton University
                                        1125 Colonel By Drive, Ottawa, ON K1S5B6 Canada
                             Abstract                                   sounds from two phonemic categories relative to those from
                                                                        the same phonemic category even when the absolute
Although many speech perception studies have suggested that
long-term memory representations of phonemes induce categorical         acoustic differences are equivalent. Collectively, these ID
perception along an acoustic continuum (e.g., voice-onset time;         and discrimination results constitute the phenomenon of
VOT) when identifying speech sounds, other studies have                 categorical perception.
suggested that acoustic information is preserved and that graded            Categorical perception is a robust phenomenon.
responses can be observed in within-category comparisons. Using         However listeners also retain some with-category acoustic
subjective confidence reports, we present findings that support the     information (Pisoni & Tash, 1974) and can show graded
use of both acoustic and phonemic cues during speech perception.        responses within a phonemic category (e.g., McMurray,
Replicating earlier findings, we observed evidence for two well-        Tanenhaus, Aslin, & Spivey, 2003; Miller, J. L., & Volaitis,
defined phoneme categories along the voice-onset time continuum.
Additionally, we also observed overconfidence in responses
                                                                        1989). Using an AX task, Pisoni (1973) found that when two
suggesting that the explicit representation of phonemes differs         speech sounds were presented with a long inter-stimulus
from the representations used to make identification and                interval (ISI), participants perceived could not discriminate
discrimination responses. Taken together with results from other        between stimuli. When stimuli were presented with shorter
studies, our findings support the claim that listeners can access       ISIs, however, participants’ accuracy at making within-
both phonemic and acoustic representations, with explicit               category comparisons improved (cf. Werker & Logan,
knowledge of the former but not the latter.                             1985). Pisoni (1973) used these findings to suggest a two-
   Keywords: speech perception,           category   boundaries,        stage model for speech perception with an initial stage that
   confidence processing                                                processes acoustic information and a second stage that
                                                                        retrieves categorical cues from long-term memory (see also
                          Introduction                                  Pisoni & Tash, 1974). Further support for multiple
Listeners presented stimuli from a continuum of sounds                  representations also comes from studies of so-called sine-
varying in an acoustic cue such as voice-onset time respond             wave speech wherein a participant will identify the stimuli
as though they perceive sharp discontinuities or category               as either noise or speech depending on their prior
boundaries when tested in identification and discrimination             expectations (e.g., Remez, Rubin, Pisoni, & Carrell, 1981;
tasks. On their own, however, measures of identification                Davis & Johnsrude, 2007; for other top-down effects, see
(ID) and discrimination (e.g., AX) do not indicate the extent           also Davis, Johnsrude, Hervais-Adelman, Taylor, &
to which participants are aware of these categories or their            McGettigan, 2005).
boundaries. In order to examine subjective awareness of                     One possible account of these findings is that
categories and category boundaries, we used post-decisional             participants only have explicit access to phonemic
confidence reports after the ID and discrimination responses            information and are insensitive to acoustic properties of the
to examine how response certainty varies across the                     stimuli that could be used to parse the continuum in an
continuum.                                                              alternative manner. If an effective measure of explicit
                                                                        knowledge about category structure can be obtained that can
Categorical Perception of Speech Sounds                                 be contrasted with performance on perceptual tasks, we
    Results from speech perception studies were originally              should be capable of determining the extent to which
interpreted as indicating speech sounds are perceived as                listeners are aware of stimulus properties beyond explicit
members of discrete phonemic categories (e.g., Liberman,                phonemic categories.
Harris, Hoffman, Griffith, 1957). In such studies an acoustic
cue such as VOT is varied to generate a continuum of                    Subjective Awareness and Confidence Reports
stimuli (e.g., Pisoni, 1973; for a review, see Raphael, 2005).              Whether participants can maintain a representation and
Participants then identify items using two categories such              yet have little or no awareness of it is a controversial issue.
as /ba/ and /pa/. Importantly, the resulting ID functions show          For instance, in a typical experiment assessing such
a well-defined category boundary that partitions the                    awareness, participants perform a task and indicate how
continuum into two phonemic categories. Moreover, in the                certain they are in their response on a subjective probability
accompanying discrimination task, participants exhibit                  scale (e.g., with 50% representing a guess and 100%
greater accuracy when discriminating between speech                     representing complete certainty). In these tasks participants’
                                                                     1
                                                                    971

confidence reports typically deviate from their actual             categorization, if acoustic information is available from a
performance, i.e., they are miscalibrated. Calibration             perceptual process and phonemic representations are
assesses the difference between the subjective probability of      available from the activation of long-term memory
an event (confidence level) and the observed probability of a      representations, then both sources of information should
correct response (proportion correct; for formulae, see            influence confidence reports. Substantial differences in the
Baranski & Petrusic, 1994). In this way, calibration               patterns observed between accuracy and confidence would
represents the extent to which participants are aware of their     suggest the existence of acoustic and phonemic
primary decision on a trial-to-trial basis. When assessing         representations.
average confidence and accuracy in a given condition,
participants are typically either overconfident [confidence >                              Present Study
p(cor)] or underconfident [confidence < p(cor)]. These                 In order to assess whether participants have explicit
systematic deviations have been argued to be evidence for          knowledge of acoustic information and phonemic category
both implicit and explicit representations of knowledge            boundaries, the present study compares confidence reports
(e.g., Dienes & Berry, 1997). For instance, if                     to performance in ID and discrimination (AX) tasks. In the
overconfidence is observed, this suggests an explicit              ID task, awareness of acoustic cues would be evidenced if
representation that is less accurate than the implicit             certainty increases as a function of the distance from the
representation used to classify stimuli. Confirming this,          category boundary. This would suggest that the ID function
recent studies do find overconfidence bias in perceptual           is merely an artifact of the requirement that participants use
tasks and no overconfidence bias in conceptual tasks               only two labels to categorize stimuli when they have in fact
thought to involve information stored in long-term memory          encoded and stored (temporarily) acoustic information. If,
(e.g., Kvidera, & Koustaal, 2008). Such effects suggest two        on the other hand, there is no systematic deviation of
representations, with moderate calibration suggesting at           confidence and ID performance, then it seems reasonable to
least some explicit awareness but with overconfidence              conclude that participants are only using phonemic
suggesting a well-defined explicit representation that does        information to identify stimuli. Alone, however, ID
not reflect the actual representation used to discriminate and     performance might not be capable of differentiating.
classify stimuli. If a multiple-representation account of              In order to determine whether participants have access to
speech perception is correct (e.g., Pisoni, 1973) then a           both acoustic and phonemic representations, we replicated
confidence report methodology might be capable of                  Pisoni and Tash’s (1974) paradigm wherein response times
assessing these different representations.                         in the AX task were used to suggest different levels of
    An important concern related to the existence of               processing. In addition, the present study also used
multiple sources of information is how confidence reports          postdecisional confidence reports. Again, deviations
are generated. Traditional approaches to confidence                between performance and confidence reports would suggest
processing have been agnostic about the nature of the              that two representations are used to classify and
representations used to make the primary decision and              discriminate speech sounds. If participants only perceive
report confidence. Early models of confidence assumed a            speech sounds as exemplars of discrete phonemic
decisional-locus (e.g., Ferrel & McGooey, 1980;                    categories, then they should be reasonably well-calibrated
Gigerenzer, Hoffrage, & Kleinbolting, 1991; Pleskac &              on a trial-to-trial basis and exhibit little or no
Buseymeyer, 2010) wherein confidence reports are based             over-/underconfidence bias. If participants exhibit poor
solely on information used by the primary decision process         calibration and overconfidence in the AX task, then this
thereby requiring no additional processing, a post-decisional      suggests that despite the availability of acoustic properties
locus wherein confidence is computed following the                 within the implicit system the explicit representation is
primary decision (e.g., Audley, 1960; Vickers & Packer,            phonemic. More specifically, such a finding suggests that
1980), or an alterable locus wherein confidence processing         participants have an explicit representation of the phonemic
can occur during or after the primary decision depending on        category but also maintain graded acoustic information from
speed or accuracy stress (Baranski & Petrusic, 1998). For          stimuli along a continuum. Given the intuitive saliency of
instance, in a study conducted by Baranski and Petrusic            the phoneme, we assume that category boundaries are an
(2001) participants were given blocks of trials wherein they       explicit representation but that some acoustic information
were required to simply make a decision or make a decision         must remain available (e.g., Pisoni, 1973).
followed by a post-decisional confidence report. They found
that response latencies for the primary decision were                                       Experiment
significantly longer when confidence was required relative         The goals of this experiment were threefold. First, we
to a no confidence condition indicating an additional set of       sought to validate the use of subjective confidence reports in
operations was required to compute confidence. More                a speech perception task by comparing a confidence and no
recently, Schoenherr, Leth-Steensen, and Petrusic (2010)           confidence condition. Second, using subjective calibration
found that information that is nondiagnostic of the primary        measures, we examined whether participants had explicit
decision can create variations in confidence reports               awareness of the phonemic category boundary. Third, we
independently of accuracy. Applied to phonemic                     examined whether this awareness was task-dependent by
                                                                   using both ID and AX tasks.
                                                                2
                                                               972

Participants                                                                        Calibration was computed by obtaining the average
   Listeners were 15 Carleton University students who                           differences between proportion correct for each confidence
received course credit for their participation. All participants                category with calibration scores range from 0.0 (perfect
reported normal hearing and no speech pathologies.                              calibration) and 1.0 (perfect miscalibration). Notably,
                                                                                calibration scores above 0.10 are rare. Under-
Materials
                                                                                /Overconfidence was computed by taking the difference
     Using the paradigm developed by Pisoni and Tash
                                                                                between mean confidence and mean accuracy for each
(1974) participants were presented with /b/ and /p/ stimuli
                                                                                condition, with positive values representing overconfidence
that varied along the VOT continuum. Seven speech stimuli
                                                                                and negative values representing underconfidence (for
corresponding to 0 to 60 ms VOT, originally synthesized by
                                                                                further details see, Baranski & Petrusic, 1994).
Lisker and Abramson (1967), were obtained from the
                                                                                    For all ID and AX analyses, repeated measures ANOVAs
Haskins Laboratories website (HL, 2011). The sounds were
                                                                                were conducted using dependent variables for the primary
originally recorded on reel-to-reel tape and later converted
                                                                                decision and confidence reports. Greenhouse Giesser
into AIFF format. Stimuli were pre-processed using a DC
                                                                                adjusted values are reported with unadjusted degrees of
offset correction to eliminate high frequency noises present
                                                                                freedom. Bonferroni pairwise comparisons were also
in the AIFF versions and converted into WAV files. These
                                                                                performed as a post-hoc test.
stimuli were used in both the ID and AX tasks.
                                                                                Identification Task
Procedure
                                                                                    Proportion Identification. Figure 1 shows the mean
     Trials in the ID task had one or two components
                                                                                response frequency for each category label in the ID task in
depending upon block. In both blocks of trials participants
                                                                                the confidence report condition. Participants clearly
reported whether the stimulus was a /b/ or /p/ using the ‘V’
                                                                                identified two discrete categories for /ba/ and /pa/,
or ‘N’ key, respectively. For one block participants also
                                                                                respectively, with a category boundary situated between +20
rated the confidence they had in their ID responses using a
                                                                                and +30 ms VOT. This pattern replicates the findings
6-point scale, with 50% representing a guess and 100%
                                                                                obtained by Pisoni and Tash (1974) as well as other studies
representing certainty. Participants completed a total of 180
                                                                                (e.g., Experiment 1 in McMurray et al., 2003).
trials in each block of the ID task.
                                                                                    The proportion of correct ID responses was analyzed for
     Trials in the AX task also had one or two components
                                                                                each VOT stimulus and whether a confidence report was
depending on block. In both blocks of trials participants
                                                                                provided or not. The only significant finding observed was
decided whether two stimuli separated by a 250 ms ISI were
                                                                                the location of the stimuli along the VOT continuum,
the same or different, using the ‘D’ and ‘K’ key,
                                                                                F(6,84) = 6.394, MSE = .019, p = .02, η2 = .314. The
respectively. Replicating Pisoni and Tash (1974), stimulus
                                                                                absence of a main effect or interaction of confidence reports
pairs differed in either 0-, 2-, 4- or 6-steps and were either
                                                                                is important as it suggests that the addition of confidence
selected from the same phonemic category or different
                                                                                reports did not significantly affect ID performance thereby
phonemic categories. Three replications of the eight within-
                                                                                permitting a straightforward interpretation of the remaining
category comparisons and four replications of the six
                                                                                results.
between-category comparisons were presented in a block of
48 trials. For one block of AX trials participants also
provided a confidence rating of their AX decision using the                                          1.00
same scale described above.
                                                                       P(Identification Responses)
                                                                                                                                                          1400
     Half of the participants performed the ID task first                                                                               /B/
whereas the other half performed the AX task first. Half of                                          0.75
                                                                                                                                        /P/               1200
the blocks of trials required participants to provide                                                                                   Confidence
                                                                                                                                                                 RT (ms)
confidence reports whereas the other half only required                                              0.50                                                 1000
participants to complete the ID and AX tasks alone.
Presentation of confidence and no confidence blocks was                                                                                                   800
counterbalanced as were the responses keys for the AX task.                                          0.25
The experiment required approximately 30 minutes to                                                                                                       600
complete. Stimuli were presented via headphones using                                                0.00
PsychoPy software (Peirce, 2007).                                                                           0   10   20    30     40       50        60
                          Results                                                                                    Voice-Onset Time
    In the following analyses we use two sets of                                Figure 1. Mean identification functions, response times for
assumptions. Following Pisoni and Tash (1974), we assume                        confidence (unfilled circles) and no confidence (filled
that stimuli 1-3 are assigned to the /ba/ category whereas                      circles) conditions and mean confidence across VOT
stimuli 4-7 are assigned to the /pa/ category. From this we                     continuum. Identification function uses performance in
derive measures of accuracy. In the AX task we additionally                     confidence condition to allow comparison with mean
assume that accuracy is determined by acoustic properties                       confidence.
when making paired comparisons.
                                                                   3
                                                                   973

Mean Confidence. Figure 1 also demonstrates the effect of           Table 2. Mean dependent measures for correct and incorrect
confidence measures. Like ID accuracy, we found that                responses for within- and between-category comparisons
subjective confidence varied along the VOT continuum,               collapsed across confidence condition.
F(1,14) = 6.55, MSE = 44.11, p = .008, η2 = .319. Pairwise                                 /ba/                      /pa/
comparisons revealed that this effect arose from the                                AA/Aa        All AB      AA/Aa        All AB
difference in confidence between stimuli located at 20 and          Mean RT          753 ms       809 ms      693 ms       734 ms
30 ms VOT (p = .035), which corresponds to the stimuli              % Error              7.6          5.6         1.1           7.2
adjacent to the category boundary.                                  % Conf              96.6         96.4        99.6         97.3
    Calibration Indices. An analysis of subjective                    Mean Confidence. Our analysis of mean confidence
calibration revealed only a marginally significant difference       revealed a pattern similar to that of the accuracy analysis.
across the VOT continuum, F(6,84) = 3.401, MSE = .013, p            We found an a marginally significant interaction of
= .085, η2 = .195. This suggests that the greatest difference       phoneme category and comparison type, F(1,13) = 4.589,
between subjective awareness and performance occurs for             MSE = 3.8393, p = .052, η2 = .261. The only significant
the 20 ms VOT stimulus. Our comparison of                           effect was for phonemic category, F(1,13) = 5.895, MSE =
over/underconfidence bias did not reveal any significant            9.627, p = .030, η2 = .312. Participants expressed more
effects, F(6,84) = 1.948, MSE = .035, p = .183, η2 = .122.          confidence when responding to stimuli from the /pa/
Together, these findings suggest that participants are only         category (M = 98.456) relative to those from the /ba/
explicitly aware of the phonemic representation.                    category (M = 96.507). Taken together with the results of
Table 1. Mean dependent measures for “Same” responses to            the ID task, this suggests that the representation of the /pa/
Within-Category Paired Comparisons                                  category is more well-defined than the /ba/ category for
                          /ba/                    /pa/              these VOT stimuli.
                   A-A          A-a        A-A          A-a           Calibration Indices. As with the mean confidence
Mean RT           756 ms       818 ms      693 ms      737 ms       analysis, the interaction of phoneme category and
% Error                4.4        11.1         1.1         1.1      comparison type was only marginally significant when
Conf                97.44        98.67      99.67        99.56      using category coding, F(1,13) = 3.613, MSE =.0004, p = .
                                                                    080, η2 = .217. However, when responses are scored with
    Identification Response Time. Analysis of our RT data
                                                                    acoustic coding we find significant miscalibration, F(4,52)
also replicated Pisoni and Tash’s (1974) findings (see Figure
                                                                    = 776.8, MSE =.019, p < .001, η2 = .984. Like the ID task,
1). Specifically, we observed significant changes in RT
                                                                    we did not observe any overconfidence bias in the AX task
across the VOT continuum, F(6,84) = 8.323, MSE = .030, p
                                                                    when category coding of accuracy was used, all Fs < 2.5.
< .001, η2 = .373. We found that responses to the stimulus
                                                                    Again this suggests that participants access a phonemic
located at 20 ms VOT were longer than those for stimuli at
                                                                    representation to make their confidence decision.
0, 10, 50, and 60 ms VOT. Moreover, replicating Baranski
                                                                    Confirming this, significant overconfidence was observed
and Petrusic (2001), we also observed a significant main
                                                                    when acoustic coding of accuracy was used to compute
effect of confidence condition, F(6,66) = 4.701, MSE = .
                                                                    overconfidence, F(4,52) = 1709, MSE = .007, p < .001, η2 =
041, p = .021, η2 = .572. Participants took longer to identify
                                                                    .992. Post-hoc paired comparisons on these means (see
stimuli when confidence reports were required (M = 871
                                                                    Table 3) revealed that AA pairs differed from all other pairs
ms) relative to the no confidence condition (M = 698 ms).
                                                                    (p < .001) but no other differences were observed.
Discrimination Task
                                                                    Table 3. Mean calibration and overconfidence for
    Proportion “Same” Responses. AX responses were
                                                                    comparison type using acoustic coding for response
assessed based on a category criterion such that ‘same’
                                                                    accuracy.
responses were considered correct for within category
                                                                                                      Comparison Type
comparisons and incorrect for between category
comparisons. Table 1 provides a point of comparison with                          AA         Aa        AB        AB’        AB’’
Pisoni and Tash (1974), wherein AA and Aa represent,                OU             .013       .976       .950      .962       .994
acoustically      and     phonemically    identical    stimuli,     CAL            .008       .959       .913      .936       .988
respectively. Table 2 provides mean dependent measures for              Discrimination Response Time. Following Pisoni and
within (AA, Aa) and between (AB through AB’’ for 2-step             Tash (1974), response latencies across comparison pairs
through 6-step, respectively) category comparisons.                 were also analyzed. Only correct response latencies were
    Using a category criterion, we observed an interaction          analyzed (i.e., “Same” responses for within-category
between phoneme category (/ba/ v. /pa/) and the comparison          comparisons and “Different” responses for between-
type (within v. between), F(1,13) = 13.421, MSE = .004, p           category comparisons). Replicating their findings, the type
= .003, η2 = .508. Participants were far more accurate in           of comparison affected response latencies, F(4,52) = 5.976,
making within-category comparisons from the /pa/ category           MSE = .088, p = .007, η2 = .315. Importantly, an interaction
relative to all others (see Table 2).                               was also observed between the confidence condition and
                                                                    comparison type, F(1,13) = 9.072, MSE = .029, p = .01, η2
                                                                 4
                                                                974

= .315. As Figure 2 indicates, participants were fastest when                         a confidence report did not appear to adversely affect ID or
responding to acoustically similar stimuli and slowest to                             AX performance.
compare stimuli between categories separated by small steps                               Confidence performance complimented ID and AX
along the VOT continuum. The additional requirement of                                performance: participants expressed the most uncertainty in
confidence increased response latencies for acoustically                              the /ba/ category, and more specifically in the stimulus at the
dissimilar pairs.                                                                     category boundary (20 ms VOT). An absence of
                                                                                      overconfidence bias and excellent calibration in the category
              1100                                                                    analysis of both ID and AX tasks suggests that participants’
              1000                                                                    explicit knowledge of phoneme categories guides their
                                                    AB                                classification. Supporting this interpretation, when we
                   900                                       AB'
   Response Time
                                       Aa                             AB''            reanalyze discrimination accuracy in terms of acoustic
                   800
                             AA                                                       properties we found that mean indices of overconfidence
                   700                                                                and miscalibration were at ceiling for all stimuli other than
                   600                                                                AA pairs, indicating an inability to discriminate acoustically
                   500                                                                dissimilar pairs within the same phonemic category.
                   400
                                                                                                               Conclusions
                         0         2            2        4         6                      The present study replicated findings in both the speech
                         Distance along VOT continuum (10-ms Steps)                   perception and confidence processing literatures.
Figure 2. Discrimination response time for paired-                                    Participants’ responses indicated categorical perception of
comparisons within and between phonemic categories for no                             acoustically dissimilar stimuli along a voicing continuum
confidence (bars) and confidence (points) responses. Error                            and confidence reports required additional time to process.
bars represent standard error of the mean.                                            Moreover, confidence reports revealed that participants do
   As in the ID task, we also observed a main effect of                               not appear to be aware of acoustic information used to
confidence condition, F(1,13) = 4.92, MSE = .352, p = .045,                           activate phoneme representations under the presentation
η2 = .275. More time was required to discriminate stimuli                             conditions. Although the present study used only one ISI,
when confidence was required (M = 861 ms) relative to the                             follow-up studies will vary ISI in an AX task to further
no confidence condition (M = 696 ms)1.                                                differentiate subjective awareness from performance.
                                                                                      Moreover, phoneme categories that participants might have
                          Discussion                                                  less familiarity with (e.g., Pisoni et al., 1982) should
    Results generally replicated those observed by Pisoni                             demonstrate larger differences in overconfidence and
and Tash (1974): participants perceived two distinct                                  calibration. In short, our findings suggest that confidence
phonemic categories along the VOT continuum. In addition,                             reports can be used along with other measures (see also
we also found that stimuli could be discriminated with                                McMurray et al., 2003; Miller & Volaitis, 1989) to assess
greater speed and accuracy when they were selected from                               metalinguistic awareness in the context of speech
two contrasting phoneme categories rather than within a                               perception.
category. However, although our results suggest participants                              Several caveats remain. First, VOT represents one
represented stimuli as phonemic categories, the /ba/                                  among many physical cues that have been implicated in
category was not as well defined as the /pa/ category. This                           speech perception. In as much as the processing of speech in
was evidenced in a shallower portion of slope between                                 a natural environment requires multiple cues, the findings of
stimuli at 10 and 20 ms VOT in the ID function and the                                the present study might be limited to this continuum. One
reduced accuracy and confidence when comparing                                        possibility is that with a greater number of cues subjective
acoustically dissimilar stimuli within that category.                                 certainty might increase. This concern about the limits of
    Of equal importance, the experiment also replicated                               using synthesized speech has been a recurrent theme in
findings in the confidence processing literature: participants                        speech perception research (Raphael, 2005). Second, space
were faster when they made ID and AX decisions alone                                  limits prevent inclusion of an analysis of individual
compared to when they were additionally required to report                            differences, such as working memory capacity and
confidence post-decisionally (e.g., Baranski & Petrusic,                              individual ID functions. Finally, studies will need to assess
2001). Such a finding suggests that confidence processing                             whether these findings generalize to non-speech sounds that
requires a secondary set of operations to generate a                                  share similar properties such as the relative onset of two
confidence report. Importantly, however, the requirement of                           tones (Pisoni, 1977) or whether overconfidence is limited to
                                                                                      only speech sounds. Despite these caveats, the results of the
                                                                                      current work suggest that the application of a confidence
      1                                                                               report methodology holds considerable promise in clarifying
       An analysis of all (correct and incorrect) responses also revealed the
                                                                                      the nature of the representations used for speech perception
effect of comparison type, F(4,52) = 7.729, MSE = .037, p < .001, η2 = .
373, and the requirement of confidence, F(1,13) = 5.07, MSE = .247, p = .             and how these representations are accessed. Calibration can
042, η2 = .281. Post hoc paired comparisons revealed that AA differed from            be used to assess whether one or multiple acoustic cues are
both Aa and AB (all ps < .035).
                                                                                5
                                                                                975

used whereas under-/overconfidence suggests the extent to               Pisoni, D. B., & Tash, J. B. (1974) Reaction times to
which phonemic and acoustic information is available to                   comparisons within and across phonetic categories.
listeners.                                                                Perception & Psychophysics, 15, 285-290.
                                                                        Raphael, L. J. (2005). Acoustic cues to the perception of
                            References                                    segmental phonemes. In D.B. Pisoni & R.E. Remez (Eds.),
                                                                          The handbook of speech perception (pp. 182-206). Oxford:
                                                                          Blackwell.
Baranski, J. V., & Petrusic, W. M. (1994). The calibration and
                                                                        Remez, R.E., Rubin, P.E., Pisoni, D.B., Carrell, T.D.
   resolution of confidence in perceptual judgements.
                                                                          (1981). Speech perception without traditional speech
   Perception & Psychophysics, 55, 412-428.
                                                                          cues. Science, 212, 947-949.
Baranski, J. V., & Petrusic, W. M. (1998). Probing the locus of
                                                                        Vickers, D., & Packer, J. S. (1982). Effects of alternating set for
   confidence judgments: Experiments on the time to determine
                                                                          speed or accuracy on response time, accuracy, and
   confidence. Journal of Experimental Psychology: Human
                                                                          confidence in a unidimensional discrimination task. Acta
   Perception and Performance, 24, 929-945.
                                                                          Psychologica, 50, 179-197.
Baranski, J. V., & Petrusic, W. M. (2001). Testing the
                                                                        Werker, J. F., & Logan, J. S. (1985). Cross-language evidence
   architectures of the decision-confidence relation. Canadian
                                                                          for three-factors in speech perception. Perception &
   Journal of Experimental Psychology, 55, 195-206.
                                                                          Psychophysics, 37. 35-44.
Davis, M.H., Johnsrude, I.S., Hervais-Adelman, A., Taylor, K.
   & McGettigan, C.M. (2005). Lexical information drives
   perceptual learning of distorted speech: Evidence from the
   comprehension of noise-vocoded sentences. Journal of
   Experimental Psychology: General, 134, 222-241.
Dienes, Z., & Berry, D. (1997). Implicit learning: Below the
   subjective threshold. Psychonomic Bulletin & Review, 4, 3-
   23.
Gigerenzer, G., Hoffrage, U., & Kleinbölting, H. (1991).
   Probabilistic mental models: A Brunswikian theory of
   confidence. Psychological Review, 98, 506-528.
Haskins Laboratories (2011). Abramson/Lisker VOT Stimuli.
   Retrieved                    01/12/2011.                   From
   http://www.haskins.yale.edu/featured/demo-
   liskabram/index.html /.
Kvidera, S., & Koustaal, W. (2008). Confidence and decision
   type under matched stimulus conditions: overconfidence in
   perceptual but not conceptual decisions. Journal of
   Behavioral Decision Making, 21, 253–281.
Liberman, A.M., Harris, K. S., Hoffman, H. S., & Griffith, B.
   C. (1957). The discrimination of speech sounds within and
   across phoneme boundaries. Journal of Experimental
   Psychology, 54, 358-368.
Lisker, L, & Abramson, A. S. (1967). The voicing dimension:
   Some experiments in comparative phonetics. Proceedings of
   the 6th International Congress of Phonetic Sciences. Prague:
   Academia.
McMurray, B., Tanenhaus, M. K., Aslin, R. N., & Spivey, M. J.
   (2003). Probabilistic constraint satisfaction at the
   lexical/phonetic interface: Evidence for gradient effects of
   within-category VOT on lexical access. Journal of
   Psycholinguistic Research, 32, 77-97.
Miller, J. L., & Volaitis, L. E. (1989). Effect of speaking rate on
   the perceptual structure of a         phonetic         category.
   Perception & Psychophysics, 46, 505-512.
Peirce, J. W. (2007) PsychoPy - Psychophysics software in
   Python. Journal of Neuroscience Methods, 162, 8-13.
Pisoni, D. B. (1973). Auditory and phonetic memory codes in
   the discrimination of consonants and vowels. Perception &
   Psychophysics, 13, 253-260.
Pisoni, D. B. (1977) Identification and discrimination of the
   relative onset of two component tones: Implications for
   voicing perception in stops. Journal of the Acoustical Society
   of America, 67, 1352-1361.
                                                                     6
                                                                    976

