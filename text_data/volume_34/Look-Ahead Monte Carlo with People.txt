UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Look-Ahead Monte Carlo with People
Permalink
https://escholarship.org/uc/item/8dc135m2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Blundell, Charles
Sanborn, Adam
Griffiths, Tom
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                        Look-Ahead Monte Carlo with People
                                          Charles Blundell (c.blundell@gatsby.ucl.ac.uk)
                        Gatsby Computational Neuroscience Unit, University College London, London, UK
                                          Adam Sanborn (a.n.sanborn@warwick.ac.uk)
                                    Department of Psychology, University of Warwick, Coventry, UK
                                        Thomas L. Griffiths (tom griffiths@berkeley.edu)
                          Department of Psychology, University of California, Berkeley, Berkeley, CA USA
                               Abstract                                 People (MCMCP), focused trials on informative regions of
                                                                        stimuli – greatly reducing the number of trials a participant
   Investigating people’s representations of categories of compli-
   cated objects is a difficult challenge, not least because of the     needs to perform.
   large number of ways in which such objects can vary. To make            While MCMCP exploited the local nature of categories, it
   progress we need to take advantage of the structure of ob-           could not exploit the way that many categories lie on man-
   ject categories – one compelling regularity is that object cate-
   gories can be described by a small number of dimensions. We          ifolds. Many seemingly complex stimulus representations
   present Look-Ahead Monte Carlo with People, a method for             possess a simpler embedded representation. For example,
   exploring people’s representations of a category where there         images, when represented as a grid of pixel values, inhabit
   are many irrelevant dimensions. This method combines ideas
   from Markov chain Monte Carlo with People, an experimental           a high-dimensional space, typically hundreds to hundreds
   paradigm derived from an algorithm for sampling complicated          of thousands of dimensions. Yet modifications to these im-
   distributions, with hybrid Monte Carlo, a technique that uses        ages, such as changing a facial expression or moving a limb,
   directional information to construct efficient statistical sam-
   pling algorithms. We show that even in a simple example, our         require simultaneously modifying only some of the dimen-
   approach takes advantage of the structure of object categories       sions. Thus often stimuli possess many irrelevant dimensions
   to make experiments shorter and increase our ability to accu-        and many “linked” dimensions, where changing one implies
   rately estimate category representations.
                                                                        proportionally changing many other connected dimensions.
   Keywords: category representation; Markov chain Monte
   Carlo; directional judgements                                        Since such relationships are often smooth among dimensions,
                                                                        suggesting a manifold structure.
                          Introduction                                     In this paper, we present an extension to MCMCP that
Categories are an essential component of how people reason              is able to take advantage of the manifold structure of
about the world, allowing us to act intelligently when we en-           continuous-valued stimuli and apply it to a low-dimensional
counter new objects, new people, or new situations. Natu-               stimulus. We take inspiration from the large literature in sta-
ral stimuli, such as images or text, tend to be very compli-            tistical computing that has explored how MCMC algorithms
cated. In contrast, much of our understanding of categori-              can be modified to increase their efficiency in solving specific
sation behaviour has been built on experiments using well-              problems. For example, Hybrid Monte Carlo (Neal, 1996) is
controlled stimuli that vary along only one or two dimensions           a successful method for sampling in high-dimensional spaces
(e.g., Nosofsky, 1986). A major driver of the disconnect be-            that incorporates directional information into MCMC meth-
tween experimental investigations and real-world behaviour              ods. We adapt MCMCP to include directional information,
is that standard experimental methods do not allow the exper-           allowing participants to “look ahead” at the consequences of
imenter to adaptively focus on informative stimuli. Attempt-            their decisions so they can guide stimulus generation, increas-
ing to map out a complicated category with standard methods             ing the efficiency with which we can investigate categories.
would require participants to complete an unendurable num-                 The remainder of this paper is organised as follows. We
ber of trials.                                                          first introduce the MCMC and explain how it was adapted to
   Identifying connections between cognitive science and                people. Next we introduce Look-Ahead Monte Carlo with
statistics can help us develop new methods to extend our ex-            People (LAMCP), first motivating it intuitively and then pre-
perimental reach. Many of the computational models of cat-              senting the technical justification of our method. We com-
egorisation developed from carefully-controlled laboratory              pare LAMCP to MCMCP empirically in an experiment ex-
studies can be interpreted as representing categories as prob-          ploring the golden ratio in rectangles–a simple example of a
ability distributions over their constituent stimuli (Ashby &           low-dimensional manifold in a higher-dimensional space. We
Alfonso-Reese, 1995). Statisticians have developed sophisti-            then conclude with a brief discussion how our method relates
cated methods to sample from high-dimensional distributions             to hybrid Monte Carlo and other sampling techniques.
and Sanborn and Griffiths (2008) identified how to use one
of these methods, Markov Chain Monte Carlo (MCMC), to                              Background: MCMC with People
draw samples from categories that were represented in the               Using the connection between computational models of cat-
mind. This method, termed Markov Chain Monte Carlo with                 egorisation and probability distributions (Ashby & Alfonso-
                                                                    1356

Reese, 1995), let p(x|c) denote the probability of stimulus x            tween the ratio rule of human decision making (Luce, 1963)
under the distribution associated with category c. We could              and a valid acceptance function for use with Metropolis sam-
attempt to elicit people’s category representation by asking             pling, namely the Barker acceptance function (Barker, 1965):
them to rate the typicality of item x in category c, but that
would require us to present participants with every stimu-                                                       π(xt? )
                                                                                         A(xt? , xt−1 ) =                             (1)
lus of interest. Instead we would like to draw samples from                                               π(xt? ) + π(xt−1 )
p(x|c).
                                                                         Assuming participants’ choices are Markov, the paradigm
    The Metropolis sampling scheme (Metropolis, Rosenbluth,              forms a Metropolis sampling scheme whose states are sam-
Rosenbluth, Teller, & Teller, 1953) is a commonly used algo-             ples from people’s distribution of objects in a particular cate-
rithm for generating a sequence of samples from a designer-              gory at the equilibriation of the Markov chain.
supplied probability distribution. It constructs a Markov
                                                                            The proposal distribution used by MCMCP is fixed and
chain whose stationary distribution is the provided probabil-
                                                                         provided by the experimenter; typically it is an isotropic
ity distribution and then uses this Markov chain to, eventually,
                                                                         Gaussian distribution. This induces a random-walk Markov
generate a sequence of samples from the stationary distribu-
                                                                         kernel, which, as Neal (1993) notes for general MCMC, and
tion. The algorithm has two parts that are provided by the
                                                                         as Martin, Griffiths, and Sanborn (2012) note for MCMCP,
designer: a proposal distribution q(x? |x), and an acceptance
                                                                         can be inefficient for exploring large, correlated spaces.
function A(x? , x). The proposal distribution is typically a sim-
                                                                         Gains in efficacy are to be had by removing this random walk,
ple distribution (such as a Gaussian or uniform distribution)
                                                                         whilst maintaining the properties that allow it to converge to
and is used to propose possible samples, x? , given the current
                                                                         the category distribution.
sample, x. The acceptance function tests how similar sam-
ples from this proposal distribution are to the desired station-            An Intuitive View of MCMCP and LAMCP
ary distribution, guiding the algorithm towards this distribu-
tion. Both the proposal distribution and acceptance function             Before presenting our novel Look-Ahead Monte Carlo with
must be carefully selected to ensure the Markov chain con-               People (LAMCP) method, we will provide some intuitions
verges correctly (see Neal, 1993). At each step t of the algo-           as to how it differs from MCMCP. Intuitively, we can
rithm, a new state of the chain is proposed, xt? , by sampling           think about exploring a probability distribution by follow-
it from the proposal distribution, q(xt? |xt−1 ). With probability       ing a Markov chain in terms of a hiker attempting to travel
A(xt? , xt−1 ), the state of the Markov chain at step t is the pro-      along a ridge path. The ridge represents an interesting
posal xt? , otherwise it is the previous state, i.e., xt = xt−1 . The    low-dimensional manifold embedded in a largely irrelevant
initial state x0 of the Markov chain is picked at random. It can         higher-dimensional space, and we wish participants to ex-
be shown that if this procedure is repeated for long enough,             plore this manifold efficiently.
the Markov chain it defines will eventually converge on the                 Suppose our hiker is standing upon a bumpy ridge in an
desired stationary distribution.                                         otherwise large flat landscape. He wishes to explore the ridge,
                                                                         whilst only descending into the lower parts of the landscape
    MCMCP (Sanborn & Griffiths, 2008; Sanborn, Griffiths, &              fleetingly. Suppose also that the he cannot see anything, and
Shiffrin, 2010) transformed the Metropolis sampling scheme               must be told about the terrain by MCMCP or LAMCP.
into an experimental method for cognitive science. MCMCP
                                                                            MCMCP allows our hiker to know about the terrain where
is a sequential paradigm in which participants construct the
                                                                         he currently stands and also at another location, picked at ran-
stimuli themselves, in small, manageable steps. The equi-
                                                                         dom by MCMCP. He must then choose whether he wishes to
librium distribution of interest is the distribution over stimuli
                                                                         step to this new location or stay where he is. MCMCP does
belonging to a single category p(x|c), which we shall write as
                                                                         not know of our hiker’s intention to follow the ridge, and so
π(x) for short-hand, the particular category being implicit.
                                                                         when MCMCP proposes locations far away from him, the
    On each trial of the MCMCP procedure, a new stimulus                 new location is likely to be in the flat and so he will often
sample xt? is generated by a computer from an experimenter-              elect not to move. Proposed locations very close to our hiker
provided proposal distribution, such as a Gaussian or uniform            are likely to be on the ridge so he will be willing to make a
distribution. Participants are presented with a choice of two            step. Walking along the ridge in this random fashion will take
possible samples; the current state, xt−1 , or the proposed new          a great many small steps.
state, xt? . Their selection becomes the new state of the Markov            LAMCP gives our hiker a guide. This guide walks away
chain, xt+1 . The next trial has the same form, and the proce-           from the hiker along a randomly oriented straight line. The
dure repeats until the Markov chain is deemed to have equi-              guide then returns to the hiker and tells him on average, how
libriated.                                                               much of the ridge she saw on her travels. If the hiker feels
    If participants choose xt? according to a valid acceptance           that the guide saw a lot of the ridge, then LAMCP randomly
function, then one can show that, just like Metropolis sam-              picks a location along this straight line. The hiker can then
pling, this scheme forms a Markov chain whose stationary                 either stay where he is, or walk to this new location offered
distribution is the distribution over stimuli in a particular cat-       by LAMCP. With LAMCP, the hiker can take advantage of
egory π(x). Fortunately there is an exact correspondence be-             a longer view. In addition, our guide will propose the same
                                                                     1357

direction in which our hiker just travelled, which will be ad-            affect the proposal of stimuli during future stimulus trials.
vantageous in following a straight ridge path. Both aspects               Participants can decide to continue along a single direction
allow our hiker to travel more quickly.                                   for multiple stimulus trials by continuing to select the cur-
                                                                          rent direction during a direction trial.
       Look-Ahead Monte Carlo with People
                                                                          Suppose N frames are to be generated for a proposed
Look-Ahead Monte Carlo with People (LAMCP) is a sequen-                   direction dt? . First N values of εt are selected, typi-
tial paradigm that, like MCMCP, samples from a participant’s              cally uniformly spaced within some task-specific interval:
distribution over stimuli for a particular category. Unlike               εt1 , εt2 , . . . , εtN . Then frame n ∈ {1, . . . , N} is the stimulus
MCMCP, LAMCP has two kinds of trials. The first kind                      produced by xt + εtn dt? . The animation loops, first increas-
are just like the trials of MCMCP; participants are asked to              ing the frame number n from 1 to N, then decreasing the
choose between a generated stimulus and the previous stim-                frame number from N to 1.
ulus as the next state of a Markov chain. In the second kind
of trial, however, participants are asked to choose a direction           Participants are presented with two animations: one corre-
in the stimulus space to explore. This directional information            sponding to the proposed direction dt? and another for the
is then used to generate a stimulus to be presented to the par-           previous direction dt−1 . Participants are asked to select the
ticipant in the first kind of trial. Thus LAMCP produces two              animation in which the stimuli look most like they belongs
kinds of samples; stimuli, which we shall denote x, and also              to the category of interest. By doing so, participants are
directions, which we shall denote with d.                                 picking the direction that is most likely to offer a stimulus
   LAMCP alternates between proposing stimuli using the                   belonging to the category during the next stimulus trial.
current direction and previous stimulus and proposing direc-              Again, as in MCMCP, we assume this choice is made
tions using the current stimulus and previous direction. In this          by participants according to the ratio rule and thus corre-
way, LAMCP is able to capture and to some extent remember                 sponds to the Barker acceptance function (Equation 1).
local manifold structure when generating stimuli.
                                                                          In summary, the LAMCP paradigm is as follows:
   Recalling the analogy of the hiker trying to follow a ridge;
new stimuli are generated from directions by starting at the           1. Generate new direction proposal from direction proposal
current stimulus and advancing some distance according to                 distribution qd :
the current direction. The distance advanced is sampled at
random. More precisely, the two kinds of trials of LAMCP                                                 dt? ∼ qd (dt? |dt−1 )                (2)
operate as follows:
                                                                          The experimenter provides qd : the distribution is re-
Stimulus trial: Suppose that a direction dt has been sampled              quired by the Barker acceptance function to be symmetric,
   already. The direction has an additive effect upon the cur-            qd (d ? |d) = qd (d|d ? ).
   rent stimulus and so the proposal for the new stimulus, xt? ,
   is:                                                                 2. Generate an N-frame animation of the resulting samples:
                                                                          xt? = xt−1 + εn dt? for each n ∈ {1, 2, . . . , N}.
                             xt? = xt−1 + εt dt
                                                                       3. Participants asked to choose between dt? and dt−1 for the
   where εt is a random value, sampled once for each stimulus             new direction dt , based upon the animated stimuli. In par-
   trial, with distribution which we shall denote qε (εt ), deter-        ticular they select the new direction with probability:
   mining for how far the direction dt should be followed. The
                                                                                                              π(dt? |xt−1 )
   variable εt is the distance travelled, in direction dt to obtain                                     ?
   the new stimulus.                                                                                 π(dt |xt−1 ) + π(dt−1 |xt−1 )
   Participants are then presented with the previous stimulus          4. Generate new stimulus proposal from direction dt and pre-
   xt−1 and the proposal xt? and asked which of these stimuli             vious stimulus xt−1 :
   looked like they belonged more to the category of inter-
   est π(x). As in MCMCP, we assume this choice is made                                                    εt ∼ qε (εt )                      (3)
   by participants according to the ratio rule and thus corre-                                            xt? = xt−1 + εt dt                  (4)
   sponds to the Barker acceptance function (Equation 1).
                                                                          The experimenter provides qε . Typically it will be a Gaus-
Direction trial: In this step, participants pick a suitable di-           sian distribution or a scale mixture of Gaussian distribu-
   rection for advancing the current stimulus x. A direc-                 tions.
   tion proposal is sampled from the direction proposal dis-
   tribution qd (dt? |dt−1 , xt−1 ). Direction values are presented    5. Participants are asked to choose between xt? and xt−1 as the
   to participants as animations, showing how the proposed                new stimulus xt , choosing xt? with probability:
   stimuli will be derived from the direction. This is the look-
   ahead part of our paradigm: this animation provides par-                                                      π(xt? )
   ticipants with insight into how selecting a direction would                                            π(xt? ) + π(xt−1 )
                                                                    1358

     In terms of Markov chains, LAMCP is a Metropolis sam-                that varies from trial to trial. In our experiment, we shall only
pler, where each kind of trial can be understood to be updates            use this new regime for direction trials, where we do not need
to either the stimulus or the direction. The overall stationary           to sample from a stable distribution. In future, however, it
distribution is π(x, d) = π(x)π(d|x). Participants are asked              would be interesting to explore how robust MCMCP is to the
to pick directions whose animation show a high probability                deviations from the ratio rule that people display.
stimulus for the longest. Stated more formally, the stationary
distribution for directions is:                                                        Experiment: Testing LAMCP
                                                                          We evaluated whether LAMCP is able to produce proposals
                          Z Z
             π(d|x) ∝           π(x? )δ(x? = x + εd)dx? dε         (5)
                                                                          that are more commonly accepted than MCMCP, generated
                                                                          higher quality samples than MCMCP, and use fewer trials
where x? are the look-ahead points and π(x? ) is the stimulus             to achieve the same quality of estimates as MCMCP. Each
distribution evaluated at these look-ahead points, whilst ε is            trial shall correspond to one decision made by a participant.
their distance along the direction d from the original stimulus           For LAMCP, this means it will take two trials to produce one
x.                                                                        stimulus.
                                                                             We applied LAMCP and MCMCP to a simple task where
          Extending LAMCP to Many Choices
                                                                          stimuli are parameterized by two dimensions—rectangles
As originally developed, MCMCP and LAMCP consisted of                     with width and height. Our aim is to elicit from participants
two alternative forced choice (2AFC) trials. This follows                 samples from the category of golden rectangles, where the
naturally from the Barker acceptance function (Equation 1).               height is equal to the golden ratio (1.618) times the width.
However, a larger number of alternatives could provide even               This scenario is a manifestation the ridge example that we
more informative judgements.                                              motivated our approach with earlier. The golden ratio lies
     At the start of each trial, instead of generating one proposal       along a ridge in the two dimensional space form by all widths
                                                   p
xt? , a set of n proposals is generated {xt : p ∈ {1, . . . , n}}.        and heights.
Let c denote the index of the selected choice; instead of the                Participants were asked to select the rectangle that looked
Barker acceptance function in Equation 1, we use:                         most like a golden ratio rectangle on stimulus trials, or in the
                                                                          case of direction trials, to pick the animation that looked most
                                           π(xtc )
                A(xtc , xt−1 ) =                      p            (6)    like a golden ratio rectangle for the longest amount of time.
                                 π(xt−1 ) + ∑np=1 π(xt )                  We evaluated how their output deviated from ideal golden ra-
                                                                          tio rectangles.
Just as the Barker acceptance function (Equation 1) naturally
arises in people’s decision making from the Luce’s choice ax-
iom (Luce, 1963), so too does Equation 6.                                 Participants. A total of 43 participants were recruited from
     It is not obvious, however, whether such an acceptance               Amazon Mechanical Turk: each having at least a 95% task
function leads to a valid Markov chain Monte Carlo sampler.               approval rate, and had at least 100 approved tasks. Each par-
By considering the multiple choice Markov transition kernel,              ticipant was required to contribute at least 100 decisions to the
one can show that the condition of detailed balance is satis-             task to be paid $0.05. To check for consistency among par-
fied by this acceptance function, and hence the above accep-              ticipants, approximately 10% of participants’ decisions were
tance function maintains the equilibrium distribution π(x). In            repeats of their own or other participants’ decisions. These
particular, the Markov transition kernel is:                              repeats were not used in the analysis. Participants’ decisions
                     n                                                    were incorporated in real-time, and so some participants dis-
   T (x → x0 ) =   ∑ δ(x0 , x p )A(x p , x)S(x, x p )                     continued the experiment before 100 decisions but their re-
                   p=1                                                    sults were still included (five participants for LAMCP, six for
                               "
                                      n  Z
                                                                 #        MCMCP24, and two for MCMCP).
                          0                      p        p    p
                  + δ(x , x) 1 −     ∑      A(x , x)S(x, x )dx     (7)
                                     p=1
                                                                          Stimuli. Stimuli were black rectangles rendered in the par-
where S is the symmetric proposal distribution for generating             ticipant’s web browser. Each stimulus was drawn in a 232
new proposals. Detailed balance requires one to show that                 pixel by 232 pixel light grey box, with an internal border of 5
π(x)T (x → x0 ) = p(x0 )T (x0 → x) holds for all x and x0 , which         pixels. The light grey box had a border of 5 pixels surround-
is easily achieved by substitution of definitions and algebra.            ing it, and was on a white background. For animated stimuli,
     Though we have shown that the connection between the                 25 frames were generated, and the frame was advanced, in a
ratio rule and a valid acceptance function holds for more                 loop, changed approximately every 100 ms. For 2AFC tri-
than two choices, there is evidence that people do not fol-               als, stimuli were shown side by side. For 4AFC trials, stimuli
low the ratio rule in this case (Wills, Reimers, Stewart, Suret,          were shown in a grid of two rows and two columns. The
& McLaren, 2000). Rouder (2004) suggests that behaviour is                stimuli parameters (width and height) were generated by ei-
better explained by raising the choice probabilities to a power           ther MCMCP or LAMCP, using truncated Gaussians for the
                                                                      1359

initial stimulus and proposal distributions to ensure the pa-       ing LAMCP quickly find the golden ratio and are easily able
rameters remained within the range 0 to 1. For MCMCP, the           to explore and follow this correlation in the stimulus param-
variance of the truncated Gaussians was randomly chosen at          eters, compared to MCMCP participants. The bottom row of
each trial to either be 0.01 or 0.25. For LAMCP, the variance       Figure 1 shows that throughout the evolution of both Markov
of the truncated Gaussians was randomly chosen at each trial        chains, LAMCP participants generate samples that are closer
to either be 0.1 or 0.5. Variance parameters for LAMCP were         to the golden ratio than MCMCP participants.
higher than those for MCMCP.                                           We recorded the time between trials for each partici-
                                                                    pant, and for LAMCP, compared the difference between
Procedure. Participants were asked to study 24 examples             these times for stimulus and direction trials. We could find
of rectangles, six of which were golden ratio rectangles and        no significant difference in these times under a variety of
18 non-golden ratio rectangles. Six of the counter-examples         two-sample tests (Wilcoxon rank-sum, t-, and Kolmogorov-
were the six examples rotated by 90 degrees, with explicit          Smirnov tests; p > 0.05, n = 500). A likely explanation for
instructions highlighting that golden ratio rectangles are tall     this is that network transmission time dominates participants
and thin, not short and wide.                                       decision time: the median time between trials was 2.8 sec-
   We ran three regimes—MCMCP with just 2AFC trials,                onds (± 1 second semi-interquartile range). Thus for Me-
MCMCP with alternating 2AFC and 4AFC trials (to account             chanical Turk experiments, using directional trials do not ap-
for the effects of including alternating 2AFC/4AFC trials,          pear to take more of a participants’ time than stimulus trials.
which we shall call MCMCP24), and LAMCP with 2AFC
for stimulus trials and 4AFC for direction trials. For each                                   Discussion
regime, we ran 10 chains, each chain being 100 trials long.
Each trial consisted of choosing between either the stimulus        Look-Ahead Monte Carlo with People is an extension to
selected by the previous trial and one or three new stimuli.        MCMCP that exploits local manifold structure found in con-
                                                                    tinuous valued stimuli by soliciting direction judgements
Results. The median acceptance rates of MCMCP and                   from participants. This method will allow us to more ef-
MCMCP24 were 38% (± 2%; semi-interquartile range) and               ficiently explore and understand complicated categories in
37% (± 4%), respectively, whilst the median acceptance rate         higher dimensions than previously attempted, by extracting
of stimulus for LAMCP was 46% (± 2%), suggesting that               more useful information per trial from participants. Whilst
the proposals generated by LAMCP were typically more rep-           our simple experiment demonstrated the efficacy of our tech-
resentative than those generated by MCMCP.                          niques in even the simplest case, for tasks such as images of
   The median absolute difference between the estimated             faces, similar local structure likely exists in stimuli and so we
golden ratio and the true golden ratio was 0.72 (±0.44              can hope for similar gains.
semi-interquartile range) and 0.92 (±2.73) for MCMCP and               Compared to other procedures for eliciting distributions
MCMCP24, respectively. The median absolute difference of            from people, LAMCP’s two kind of trial paradigm is also
LAMCP, 0.52 (±0.38) is closer to the golden ratio than both         similar to iterated learning (Kirby, 1998; Griffiths & Kalish,
MCMCP methods. The absolute differences of MCMCP and                2007) where people either sample an internal representation
MCMCP24 are significantly (p < 0.001) different to the ab-          or a physical manifestation of that representation. Direc-
solute differences of LAMCP under the Wilcoxon rank-sum             tions are akin to an internal representation of what lies ahead,
test.                                                               whilst the stimuli are the manifestations of the directions. The
   Effective sample size is a heuristic for determining the         analogy is particularly apt if different people participate in
number of independent samples yielded by an MCMC                    each pair of LAMCP trials.
procedure. We compared effective sample size estimates                 LAMCP not only produces samples from people’s stimu-
of LAMCP, MCMCP and MCMCP24 using R-CODA                            lus distribution, but also samples from their distribution over
(Plummer, Best, Cowles, & Vines, 2006). We found that the           directions in stimulus space. Whilst our motivation for sam-
median effective sample size for LAMCP was 5 (±1) whilst it         pling from this distribution is purely incidental—we wish to
was 11 (±4) and 19 (±15) for MCMCP and MCMCP24, re-                 obtain directions in some principled fashion so as to inform
spectively. This suggests that whilst LAMCP produces more           the stimulus generation process—the directions give a direct
favourable samples, the samples are more correlated with one        hint as to what people estimate to be the shape of the manifold
another than those produced by MCMCP. This could be a               in which samples lie. This extra piece of statistical informa-
consequence a linear correlation introduced by the genera-          tion may be useful in gaining a better estimate of structure of
tive process of the stimuli used by LAMCP. Interestingly the        stimuli, as well as aiding the estimation process.
effective sample size for directional samples was 15 ± 3 with
an acceptance rate of 75% ± 2%.
   Figure 1 shows the estimated golden ratio and distance
of samples to the golden ratio produced by MCMCP and                Acknowledgements: We wish to thank Peter Dayan and
LAMCP. The top row of Figure 1 shows that participants us-          Charles Sutton for several useful discussions.
                                                                1360

                                                Evolution of golden ratio estimate over trials                                                        Evolution of golden ratio estimate over trials                                                        Evolution of golden ratio estimate over trials
                                      12                                                                                                    12                                                                                                    12
                                      10                                                                                                    10                                                                                                    10
                                       8                                                                                                    8                                                                                                      8
  stimulus ratio                                                                                        stimulus ratio                                                                                        stimulus ratio
                                       6                                                                                                    6                                                                                                      6
                                       4                                                                                                    4                                                                                                      4
                                       2                                                                                                    2                                                                                                      2
                                       0                                                                                                    0                                                                                                      0
                                           0    20            40             60            80     100                                            0    20            40              60           80     100                                            0    20            40             60            80     100
                                                                     trial                                                                                                 trial                                                                                                 trial
                                                Distance of estimate from golden ratio manifold                                                       Distance of estimate from golden ratio manifold                                                       Distance of estimate from golden ratio manifold
                                      0.5                                                                                                   0.5                                                                                                   0.5
  stimulus distance to golden ratio                                                                     stimulus distance to golden ratio                                                                     stimulus distance to golden ratio
                                      0.4                                                                                                   0.4                                                                                                   0.4
                                      0.3                                                                                                   0.3                                                                                                   0.3
                                      0.2                                                                                                   0.2                                                                                                   0.2
                                      0.1                                                                                                   0.1                                                                                                   0.1
                                      0.0                                                                                                   0.0                                                                                                   0.0
                                            0    20            40            60             80    100                                             0    20            40              60           80    100                                             0    20            40            60             80    100
                                                                     trial                                                                                                 trial                                                                                                 trial
Figure 1: Estimates of the golden ratio (top) and distance of samples to the golden ratio manifold (bottom) under three regimes:
MCMCP (left), MCMCP24 (middle), and LAMCP (right). Heavy solid lines correspond to the median over 10 chains, whilst
lighter solid lines are the interquartile range. Dashed straight lines in the top plots correspond to the golden ratio (top) and its
reciprocal (bottom).
                                                                        References                                                                                                   Physics, 21, 10871092.
                                                                                                                                                                                   Neal, R. M. (1993). Probabilistic inference using Markov
Ashby, F. G., & Alfonso-Reese, L. A. (1995). Categorization
                                                                                                                                                                                     chain Monte Carlo methods (Tech. Rep. No. CRG-TR-
  as probability density estimation. Journal of Mathematical
                                                                                                                                                                                     93-1). Department of Computer Science, University of
  Psychology, 39, 216-233.
                                                                                                                                                                                     Toronto.
Barker, A. A. (1965). Monte Carlo calculations of the radial
                                                                                                                                                                                   Neal, R. M. (1996). Bayesian learning for neural networks.
  distribution functions for a proton-electron plasma. Aus-
                                                                                                                                                                                     Lecture Notes in Statistics, 118.
  tralian Journal of Physics, 18, 119133.
                                                                                                                                                                                   Nosofsky, R. M. (1986). Attention, similarity, and the
Belisle, C. E., Romeijn, H. E., & Smith, R. L. (1993).                                                                                                                               identification-categorization relationship. Journal of Ex-
  Hit-and-run algorithms for generating multivariate distri-                                                                                                                         perimental Psychology, 115(1), 39–57.
  butions. Mathematics of Operations Research, 18(2).                                                                                                                              Plummer, M., Best, N., Cowles, K., & Vines, K. (2006).
Griffiths, T. L., & Kalish, M. L. (2007). Language evolu-                                                                                                                            CODA: Convergence diagnostics and output analysis for
  tion by iterated learning with Bayesian agents. Cognitive                                                                                                                          MCMC. R News, 6(1), 7-11.
  Science, 31, 441–480.                                                                                                                                                            Rouder, J. N. (2004). Modeling the effects of choice-set
Kirby, S. (1998). Language evolution without natural selec-                                                                                                                          size on the processing of letters and words. Psychological
  tion: From vocabulary to syntax in a population of learn-                                                                                                                          Review, 111, 80-93.
  ers (Tech. Rep.). Language Evolution and Computation                                                                                                                             Sanborn, A. N., & Griffiths, T. L. (2008). Markov chain
  Research Unit, University of Edinburgh.                                                                                                                                            Monte Carlo with people. In J. C. Platt, D. Koller,
Luce, R. D. (1963). Detection and recognition. In R. D. Luce,                                                                                                                        Y. Singer, & S. Roweis (Eds.), Advances in neural informa-
  R. R. Bush, & E. Galanter (Eds.), Handbook of mathemat-                                                                                                                            tion processing systems 20 (pp. 1265–1272). MIT Press.
  ical psychology, i (p. 103-189). Wiley.                                                                                                                                          Sanborn, A. N., Griffiths, T. L., & Shiffrin, R. M. (2010). Un-
Martin, J. B., Griffiths, T. L., & Sanborn, A. N. (2012). Test-                                                                                                                      covering mental representations with Markov Chain Monte
  ing the efficiency of Markov Chain Monte Carlo with Peo-                                                                                                                           Carlo. Cognitive Psychology, 60, 63-106.
  ple using facial affect categories. Cognitive Science, 36,                                                                                                                       Wills, A. J., Reimers, S., Stewart, N., Suret, M., & McLaren,
  150-162.                                                                                                                                                                           I. P. L. (2000). Tests of the ratio rule in categorization.
Metropolis, A. W., Rosenbluth, A. W., Rosenbluth, M. N.,                                                                                                                             The Quarterly Journal of Experimental Psychology, 53(4),
  Teller, A. H., & Teller, E. (1953). Equations of state calcu-                                                                                                                      983-1011.
  lations by fast computing machines. Journal of Chemical
                                                                                                                                                                      1361

