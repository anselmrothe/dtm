UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Interplay between Feature-Saliency and Feedback Information in Visual Category
Learning Tasks
Permalink
https://escholarship.org/uc/item/8hg51981
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Hammer, Rubi
Sloutsky, Vladimir
Grill-Spector, Kalanit
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

              The Interplay between Feature-Saliency and Feedback Information
                                          in Visual Category Learning Tasks
                                               Rubi Hammer1 (rubih@stanford.edu)
                                       Vladimir Sloutsky2 (sloutsky@psy.ohio-state.edu)
                                         Kalanit Grill-Spector1 (kalanit@stanford.edu)
                                              1. Department of Psychology, Stanford University
                           2. Department of Psychology and Center for Cognitive Science, Ohio-State University
                             Abstract                                   Learning trajectories in both attentional and perceptual
  What is the role of feedback information in different visual
                                                                        learning tasks are also determined by the availability of
  category learning (VCL) scenarios? To address this question           informative feedback. In this study we examine the
  we tested participants’ performance in VCL tasks in which             interaction between perceptual and attentional learning by
  stimuli varied in three feature dimensions, one of which was          testing the interaction between feature-saliency and
  relevant for the task and the other two were irrelevant. The          feedback information in visual category learning (VCL)
  relevant feature could be identified based on trial-by-trial          tasks of complex visual stimuli.
  feedback. In one condition the task relevant and irrelevant              We define feature-saliency as the physical dissimilarity
  features were highly-salient. In the second condition all             between stimuli in a given feature dimension. When objects
  features had low-visual-saliency. Feedback information was            are perceived as highly dissimilar across a feature
  also manipulated: In the high-information condition the task
  relevant feature could be identified by the information
                                                                        dimension, this feature is perceived as more diagnostic than
  provided in each trial whereas in the mid-information                 lower-saliency feature dimensions (Chin-Parker & Ross,
  condition the feedback was ambiguous and information from             2004). In each VCL task in our experiment stimuli differed
  several learning trials was required in order to confidently          from one another in three feature dimensions, yet only one
  identify the relevant feature. Surprisingly, our data shows that      was relevant for correctly categorizing the stimuli. In each
  mid- and high-information feedback are similarly effective in         task we kept the relative feature saliency (low or high)
  high-saliency VCL tasks. In contrast, in low-saliency VCL             similar across all three feature dimensions making them
  tasks, mid-information feedback impairs learning. We suggest          equal candidates for being perceived as task relevant.
  that VCL can be done effectively either when feedback is              Therefore, the diagnostic value of each feature could be
  ambiguous or in low-saliency conditions, but not in scenarios
  when both challenges occur concurrently.
                                                                        determined only by the information provided by feedback.
                                                                           We define the feedback information level based on its
  Keywords: Visual category learning; Feedback information;             ambiguity. In each learning trial we presented a pair of
  Attentional learning; Perceptual learning; Feature-saliency.          stimuli and the participant had to determine if these stimuli
                                                                        belong to the same category or different categories. We used
                         Introduction                                   two levels of feedback information: 1) In the high-
Humans are capable of effectively managing a vast amount                information learning condition the feedback in each and
of sensory information, rapidly rendering it into a coherent,           every trial provided sufficient information for learning the
reliable and meaningful representation of objects and                   rule as same-category pairs were identical only in the task
events. This capability depends on two fundamental                      relevant feature and differed in the two irrelevant ones,
learning processes: One is perceptual learning which allows             whereas different-categories pairs were different only in the
identifying subtle, initially hard to detect, differences               task relevant feature (and identical in the two irrelevant
between stimuli (Goldstone & Barsalou, 1998; Kourtzi,                   ones). If A denotes the relevant feature, B and C the
2010). The other is attentional learning which requires                 irrelevant features, and X is the outcome of a categorization
shifting attention to relevant attributes while at the same             decision, the only possible trial-by-trial inferred causality (a
time filtering out irrelevant, even if salient, visual attributes       feasible feature-decision association) in the high-
(Blair, Watson & Meier, 2009; Kalish & Kruschke, 2000;                  information condition was A  X  A  X  A  X ...
Rehder & Hoffman, 2005). It is known that these two forms               2) In the mid-information condition each trial was
of learning allow reducing the probability of future decision           ambiguous as same-category pairs were identical in the task
errors by improving discriminability among similar objects              relevant feature and one of the two irrelevant features
from different categories, and allowing effective                       (randomly alternating between the two), whereas different-
generalization to novel stimuli. To date, it is not clear how           categories pair were different in the task relevant feature
these processes interact in different learning scenarios.               and one of the irrelevant features. The causality here was
   Difficulty in perceptual learning tasks is determined by             ( A  B  X )  ( A  C  X )  ( A  C  X )  ( A  B  X )...
feature-saliency. Difficulty in attentional learning tasks is           This learning scenario is more likely to require distributing
determined by the numbers of simultaneous perceptual                    attention between features and integrating information
features one has to process when categorizing objects.                  across more trials in order to learn the categorization rule.
                                                                    420

   We expect VCL efficiency to depend both on feature-             categories differences had high-saliency. In low-saliency
saliency and the level of feedback information. Specifically,      VCL tasks both within-category and between-categories
we hypothesize that when differences across visual feature         differences had low-saliency. In each VCL task participants
dimensions are hard to detect, shifting attention from one         were trained with one of three levels of feedback
feature to the other will not be effective due to the poor         information: 1) High-level information feedback that
representation of features. This will become a greater             potentially enabled identifying the diagnostic feature within
challenge when feedback is ambiguous, making it harder to          each learning trial; 2) mid-level information feedback, in
associate a feature representation with the corresponding          which each learning trial provided ambiguous information
decision outcome (Nosofsky & Palmeri, 1996). In contrast,          regarding which feature was the relevant one; 3) In addition
when feature-saliency is high, relevant visual information is      to these two feedback-based learning conditions, we also
readily available, enabling to rapidly shift attention away        tested participants in a control condition in which no
from irrelevant features. This may allow effective learning        feedback was provided to the participants. This provided a
even in the face of ambiguous feedback. Therefore, we              useful benchmark for assessing the contribution of feedback
expect an interactive effect of feature-saliency and feedback      information to learning.
information. Nevertheless, based on current knowledge, we             Each VCL task was based on a different stimulus set and
cannot predict whether this interaction will manifest as an        a unique combination of feature-saliency and feedback
additive effect or as an augmented interference in which the       information level. In order to prevent cross-conditions
effect of feedback ambiguity on learning efficiency will be        differences in categorization performances that derive from
more profound in low-saliency learning conditions.                 differences between stimulus sets, we counterbalanced the
                                                                   tasks across participants such that each one of the four
                          Methods                                  stimulus sets was used in each one of the six experimental
Participants                                                       conditions the same number of times.
Sixty paid adults (36 females), with normal or corrected to
normal vision, participated in the experiment. The
experiment was approved by the Stanford University IRB.
Materials and setting
We ran the experiment using Psychtoolbox (MATLAB®)
on 1920X1200 pixels computer display. Participants’ head
was located about 70 cm (~2 feet) from the computer screen
such that each one of the two simultaneously presented
stimuli occupied approximately 14 of the visual field.
Stimuli
We used four distinct sets of novel creature-like stimuli. In
each set the stimuli varied in three feature dimensions (see
examples in Figure 1). Exemplars for each stimulus set were
produced from one standard object and three morph targets,
each differed from the standard in one feature dimension.
For VCL tasks with high-feature-saliency we used high
morph values (at least 77%). Low-saliency exemplar pairs
differed by small morph values (22-33%). The morphing
values we used were determined based on pilot tests such
that within each stimulus set differences in all feature
                                                                   Figure 1: Examples of pairs of creatures from the four
dimensions were similarly likely to be detected. We also
                                                                   stimulus sets. Each row shows examples from a different
ensured that in the low-saliency condition differences within
                                                                   stimulus set. Left: high-saliency pairs; Right: low-saliency
each feature dimension will be not detected easily without
                                                                   pairs. Green arrows indicate high-saliency differences in the
feedback. For each stimulus set we determined two
                                                                   three feature dimensions in which the paired creatures differ
categories. Members of each category varied in the two
                                                                   (e.g., in the upper row the two creatures differ in horns,
irrelevant feature dimensions and were identical in the third.
                                                                   limbs and body-with). In each stimulus set, the same
This third feature-dimension was the diagnostic feature-
                                                                   diagnostic feature was used for both the low- and high-
dimension differentiating between the two categories.
                                                                   saliency tasks. From top to bottom, the task relevant feature
                                                                   was body-width, head-spikes, horns and body curvature.
Design
Tasks differed in feature saliency (high-saliency vs. low-
                                                                      Each VCL task included seven blocks: four test blocks
saliency), and three levels of feedback information. In high-
                                                                   (denoted as T1-T4) that alternated with three learning
saliency VCL tasks both within-category and between-
                                                                   blocks (L1-L3). Each block consisted of 24 trials. In each
                                                               421

trial two creatures were presented simultaneously on a             ignored. Before starting the experimental tasks, participants
computer screen for 2.2 seconds during which the                   performed a warm-up VCL task (with a different stimulus
participant had to decide if they belonged to the same or          set). This enabled the participant to become familiarized
different categories by pressing one of two keyboard keys.         with the experimental tasks.
Feedback was given during the 0.8 seconds inter-trial
interval: In the mid- and high-information feedback
conditions, a green square indicated a correct answer and
red square an incorrect one. In the control, no feedback,
learning blocks and in the test blocks, a yellow square
indicated that the response was recorded (Figure 2a).
   During test blocks, creature pairs always differed in two
feature dimensions. Same-category pairs differed in the two
irrelevant feature dimensions and were identical in the
relevant one (as the right upper pair in Figure 2b). Different
categories pairs differed in the relevant feature dimension
and in one of the irrelevant feature dimensions, but were
identical in the other irrelevant dimension (see left lower
pair in Figure 2b). This design prevents participants from
making the same/different categorization decision based on
the overall similarity between stimuli. It also allowed us to
keep the statistics of the three features and their pair-wise
covariance identical.
   For feedback-based learning blocks, pairs of creatures
were selected in the following way: 1) In the high-
information feedback condition same-category pairs were
identical in the relevant feature dimension and differed in
the two irrelevant feature dimensions. Different-categories
pairs differed in the relevant feature dimension and were
identical in the two irrelevant ones. Thus, each trial             Figure 2: Experimental design. (a) An illustration of an
indicates either all the within-category variability (same-        experimental trial. A pair of stimuli presented for 2.2
category pairs), or only the diagnostic feature dimension          seconds during which the participant had to judge if the
discriminating between categories (different categories            creatures are from same or different categories. This was
pairs). 2) For mid-information feedback, same-category             followed by 0.8 seconds of feedback presentation (e.g.,
pairs were identical in the relevant dimension and in one of       green square indicates a correct answer) after which the next
the two irrelevant dimensions (alternating between the two         trial started. (b) Examples of different-categories (left) and
across different trials). Different-category pairs differed in     same-category (right) pairs, high-information (top) and mid-
two features: the relevant one and an irrelevant one (again,       information (bottom) condition. In each of the feedback
randomly alternating across trials between the irrelevant          based learning blocks, the category relation between the
two). Although in this case each trial was ambiguous, it was       paired stimuli could be derived from the feedback. In High-
still possible to learn the categorization rule based on the       information trials different-categories pairs differ only in the
information provided across several trials. Such ambiguity         relevant feature, and same-category pairs are identical only
in the feedback keeps the attentional learning aspect of the       in this feature. Such a trial enables effectively pinpointing
task more challenging by increasing the probability that           the relevant feature dimension by eliminating 2 out of three
participants will divide attention, in each trial, between two     possible hypotheses. Mid-informative trials provide less
feature dimensions that are equally perceived as relevant. 3)      information since such a trial always leaves two options (out
The composition of the trials in the learning blocks with no       of three). (c) A table describing all possible hypotheses for a
feedback was similar to the one used in the test blocks.           given VCL task. When all feature dimensions are salient the
                                                                   participant is only required to decide which feature is
Procedure                                                          relevant (H1 – H3). When features are not salient, VCL
To keep the duration of the experimental session short (~ 75       requires shifting from H0 (represent a case in which the
minutes), each participant performed a combination of three        participant is unaware of either one of the potentially
out of six conditions; [2 feature-saliency] X [3 feedback          relevant feature dimensions) to the correct hypothesis
information]. Participants were informed that in each VCL          signaling the relevant feature dimension.
task they have to learn to classify unfamiliar creatures from
two distinct subspecies based on one attribute (feature            Performance measurements
dimension). Participants were also told that any variability       We define a “Hit” as correctly deciding that two creatures
in other attributes should be considered as irrelevant and         are members of the same category, and a “False-Alarm” as
                                                               422

incorrectly deciding that creatures of different categories are     ended with similarly high performance level in both
members of the same category. Based on the Hit and False-           saliency conditions, yet in the low-saliency condition it
Alarm rate we calculated participants’ sensitivity using the        required more learning trials.
non-parametric measure A-prime (Grier, 1971; Formula 1).               Separate two-way ANOVAs, one for the high-saliency
A’=1 indicates perfect performance and A’=0.5 indicates             condition and one for the low-saliency condition, with
chance level. 0≤A’<0.5 represent a response confusion.              feedback information (mid/high) as the between participants
                                                                    independent variable, learning trial number (1-72) as a
Formula 1: A-prime calculation. H denotes the Hit rate, and         within participant independent variable, and participants’
F the False-Alarm rate (Hit and False-Alarm rates are               percent correct as the dependent variable, show a significant
calculated based on the 24 trials in each test/learning block).     difference in the linear contrast between mid- and high-
                                    ( H  F )2  | H  F |        information feedback learning conditions in the low-
       A'  0.5  sign(H  F )                                   saliency condition, F(1, 46) = 4.73, p < 0.04, but not in the
                                 4  max(H , F )  4  H  F      high-saliency condition, F(1, 46) = 0.29.
Benchmarks                                                             Indeed, a three-way ANOVA with feature-saliency,
We evaluated participant performances according to the              feedback information and learning trial number as
following benchmarks: Chance performance, A’=0.5;                   independent variables, and participants’ percent correct as
Perfect performance, A’=1; Performance based on                     the dependent variable, confirm that the interaction between
systematically referring to an irrelevant feature during a test     feature-saliency and feedback information is significant,
block or during a no-feedback “learning” block, A’= 0.12;           F(3, 92) = 2.73, p < 0.02, partial η2 = 0.029 (Figure 3).
Performance based on systematically referring to an
irrelevant feature during a learning block with mid-
information feedback, A’=0.5; Performance based on
systematically referring to an irrelevant feature during a
learning block with high-information feedback , A’= 0.
                           Results
Reported data is based on 24 participants in each condition.
Excluded from this analysis are cases in which performance
level was inconsistent between the test vs. the learning trials
within a given VCL task (evident as high performance in the
learning blocks, where feedback was available, contrasted
with near-chance performance in the following test blocks,
where feedback was not available).
Pre-learning performance
First, we confirmed that the initial performance level, in
each of the two feature-saliency conditions, is similar. A
two-way analysis of variance (ANOVA) with feature-
saliency and feedback information as independent variables,
and participants’ sensitivity (A’) in the first, pre-learning,
test block (T-1) as the dependent variable shows no
significant interaction F(2, 144) = 0.93, no main effect of         Figure 3: Participants’ mean percent correct in the high-
feedback information F(2, 144) = 0.91, and no main effect           saliency (a) and low-saliency (b) conditions in each of the
of feature-saliency F(1, 144) = 2.12, p = 0.15.                     72 learning trials. The value in each bin is based on moving
                                                                    average with a window of 6 trials (error bars represent
Trial-by-trial, feedback-based, learning dynamics                   standard error of the mean across 24 participants). Gray dots
We assessed categorization improvement in the mid- and              represent the significance level (p-value) of the difference
high-feedback information conditions based on learning              between mid- and high-information learning in each trial
trajectories across 72 learning trials (across the three            (based on independent sample t-tests; Dashed line marks a
learning blocks, L1 to L3). We calculated performance               significance level of p = 0.05). This illustrates a consistent
based on a moving average with a window of six trials.              significant difference between the mid- and high-
Figure 3 shows rapid learning, with almost identical                information conditions, particularly in the second half of the
trajectories, both with mid- and high-information feedback          learning process, only in the low feature-saliency condition.
in the high-saliency condition. In contrast, in the low-
saliency condition mid-information feedback resulted with           Between test blocks dynamics
significantly lower improvement compared with high-                 To further assess participants learning, we examined their
information feedback. Note that high-information feedback           performance in the test blocks where no feedback was given
                                                                423

and all trials had the same composition irrespective of the         (low/high), feedback information (mid/high) and test block
feedback information condition (paired creatures always             order (T1 to T4) as independent variables, and participants’
differed in 2 features; see Methods). Results are shown in          sensitivity (A’) as a dependent variable, confirm that the
Figure 4. Our analysis shows significant improvement in all         interaction between feature-saliency and feedback
learning conditions (all p < 0.01). Importantly, we found a         information is close to significant, F(3, 92) = 2.84, p = 0.06,
significant difference in the learning trajectories between the     partial η2 = 0.030.
mid- and high-information feedback conditions in the low-              Next, we examined if differences in sensitivity between
saliency condition but not in the high-saliency condition.          the high- and low-saliency conditions are driven mostly by
                                                                    participants’ Hit rate or by their False-Alarm rate. We found
                                                                    no significant effect in the False-Alarm rate and a trend in
                                                                    Hit rate: Two-way ANOVAs, one for the high-saliency and
                                                                    one for the low-saliency condition, with feedback
                                                                    information and test block order as independent variables
                                                                    and participants’ Hit rate (in the test blocks) as the
                                                                    dependent variable, show a close to significant difference
                                                                    between the mid- and high-information feedback conditions
                                                                    in the low-feature-saliency condition, F(1, 46) = 3.65, p =
                                                                    0.06, but not in the high-feature-saliency condition, F(1, 46)
                                                                    = 0.57. A similar analysis with False-Alarm rate as the
                                                                    dependent variable, shows no significant difference between
                                                                    mid- and high-information learning, neither in the low-
                                                                    saliency condition, F(1, 46) = 1.49, p = 0.23, or in the high-
                                                                    saliency condition, F(1, 46) = 1.94, p = 0.17.
                                                                       These findings are surprising since the main challenge in
                                                                    low-saliency tasks is to learn to identify subtle important
                                                                    differences between similar categories (i.e. avoiding False
                                                                    Alarms) rather than deciding correctly that two apparently
                                                                    similar objects are from the same category (i.e. avoiding
                                                                    Misses). Nevertheless, our findings shows that higher
                                                                    information feedback in low-saliency conditions is mostly
                                                                    helpful in assisting participants performing better by
                                                                    avoiding Misses. We suggest that the lack of significant
Figure 4: Participants’ mean sensitivity (error bars represent      differences in False-Alarms rate represent, in fact, a
standard error of the mean) in the (a) high-saliency and (b)        response bias exhibited by participants in low saliency
low-saliency conditions. Feedback information levels are            conditions – instead of discriminating between categories
marked by different colors. T-1 to T-4: Performance in the          based on the relevant feature dimension, in the low-saliency
test blocks (data points connected with lines); L-1 to L-3:         tasks participants are more likely to react to any apparent
Performance in the learning blocks. When feature-saliency           subtle difference among paired creatures as if it is relevant,
is high, there are no significant differences in VCL                perhaps due to poor capacity in pinpointing the relevant one.
efficiency between the mid- and high-information                       This interpretation is consistent with the apparent
conditions. On the other hand, when the feature-saliency is         “superior” performance in the first few learning trials in the
low and participants were provided with mid-information             low-saliency mid-information condition (Figure 3b) where
feedback, performance was lower as compared with the                the participants seem to perform better than in the low-
high-information feedback condition.                                saliency high-information condition. In mid-information
                                                                    tasks, a strategy based on deciding “different categories”
   High-feature-saliency VCL: A two-way ANOVA for the               whenever identifying any difference, is with advantage
high-saliency condition, with feedback information and test         since the task diagnostic feature is always coupled with an
block order (T-1 to T-4) as independent variables and               irrelevant one (whereas same-category pairs differ in only
participants’ sensitivity (A’) as a dependent variable shows        one, irrelevant, feature-dimension). That is, in low-saliency
no significant linear contrast between the mid- and high-           mid-information learning conditions people are likely to
information conditions, F(1, 46) = 0.04 (Figure 4a).                effectively avoid False-Alarms but for the wrong reason.
   Low-feature-saliency VCL: In contrast to the above, in
the low-saliency condition there was a significant linear           Performance in the control, no feedback, tasks
contrast between the mid- and high-information feedback             Finally, we confirmed that without feedback there is no
conditions, F(1, 46) = 6.09, p < 0.02 (Figure 4b).                  significant learning in our VCL tasks: A two-way ANOVA
   Comparing high-feature-saliency and low-feature-                 conducted for the no feedback VCL tasks with feature-
saliency VCL: A three-way ANOVA with feature-saliency               saliency (high/low) and test block order (T1 to T4) as
                                                                424

independent variable, and participants’ sensitivity (A’) as         learning process. This is evident as significantly less
the dependent variable, shows no significant interaction            effective learning compared with cases where the relevant
between feature-saliency and test block F(3, 46) = 1.73, p =        feature and irrelevant features are consistently anticorrelated
0.20, and no test block order learning effect F(3, 46) = 0.36.      (as in high-feedback-information learning scenarios).
Note that mean performance in the no-feedback tasks never               We conclude that the role of attention in visual learning
significantly exceeded values of A’=0.5.                            tasks depends on the correlations between relevant and
                                                                    irrelevant features, the nature of information provided by
                         Discussion                                 available feedback, and feature-saliency. This suggests that
We tested the interaction between feature-saliency and              in everyday life scenarios, when making judgments on
feedback information in visual category learning (VCL)              complex objects in cluttered scenes, the relative contribution
tasks as a mean to explore the nature of the interaction            of attentional learning and perceptual learning can change
between perceptual learning and attentional learning.               quite substantially from one learning scenario to the other.
Simply speaking, perceptual learning is a process that              Thus, perceptual learning and attentional learning should
involves improvement in the ability to identify important           not be construed as mutually exclusive processes but rather
fine differences between categories, whereas attentional            as complementary processes, and visual learning tasks
learning improves the ability to filter out irrelevant (even if     should be considered as a mixture of these two processes.
salient) within category differences (Hammer et al., 2009).
Here we show that the interaction between these two                                          References
processes is more complex than this simplistic view.                Ahissar, M. & Hochstein, S. 1993 Attentional control of
   We report two important findings: First, perhaps                    early perceptual learning. PNAS, 90, 5718–5722.
surprisingly, we show that mid-information and high-                Blair, M. R., Watson, M. R., & Meier. K. M. (2009). Errors,
information feedback are equally effective for learning                efficiency, and the interplay between attention and
when stimuli have marked visual differences as in the high-            category learning. Cognition, 112(2), 330-336.
saliency condition. This suggests that when diagnostic              Chin-Parker, S., & Ross, B. H. (2004). Diagnosticity and
visual information is readily accessible, ambiguity in                 prototypicality in category learning: A comparison of
feedback (which is associated with higher attention load)              inference learning and classification learning. JEP: LMC,
can be resolved with no apparent effort (at least in simple            30(1), 216-226.
rule learning tasks and when testing typical adults). Second,       Goldstone, R. L., & Barsalou, L. (1998). Reuniting
importantly, there are substantial differences between mid-            perception and conception. Cognition, 65, 231-262.
information and high-information feedback when stimuli are          Grier, J. B. (1971). Nonparametric indexes for sensitivity
only subtly different. This suggests that low-saliency VCL             and bias: Computing formulas. Psychol Bull, 75, 424-429.
depends more on informative feedback that serves to orient          Hammer, R., Diesendruck, G., Weinshall, D., Hochstein, S.
attention to the relevant feature. Unlike in high-information          (2009). The development of category learning strategies:
learning trials, in mid-information learning trials with low-          what makes the difference? Cognition, 112 (1), 105–119.
saliency features, participants may not only face difficulties      Herzog, M. H., & Fahle, M. (2002). Effect of Grouping in
in noticing the relevant feature, but also have difficulties in        contextual modulation. Nature, 415(6870), 433-436.
disassociating it from irrelevant ones. Therefore,                  Kurtzi, Z. (2010). Visual learning for perceptual and
participants may have been unaware of the relationship                 categorical decisions in the human brain. Vision Res
between the feedback and the relevant feature-dimension,               50(4), 433-440.
which consequently lowered learning effectiveness.                  Nosofsky, R. M., & Palmeri, T. J. (1996). Learning to
   These findings are relevant to the developing debate on             classify integral-dimension stimuli. Psychonomic Bull &
the role of attention in perceptual learning: Most findings            Rev, 3, 222-226.
suggest that perceptual learning requires attention to a target     Rehder, B., & Hoffman, A. B. (2005). Thirty-something
visual feature (Ahissar & Hochstein, 1993; Schoups et al.,             categorization results explained: Selective attention,
2001), or the presence of informative feedback associated              eyetracking, and models of category learning. JEP: LMC,
with an attended visual feature (Herzog & Fahle, 2002). In             31(5), 811-829.
contrast, recent findings show that “accidental” perceptual         Schoups, A., Vogel, R., & Orban, G. (2001). Practicing
learning can occur (Seitz, Kim & Watanabe, 2009).                      orientation identification improves orientation coding in
Nevertheless, this seems to be restricted to learning                  V1 neurons. Nature, 412(6846), 549-553.
scenarios with informative feedback where unattended                Seitz, A. R., Kim, D., & Watanabe, T. (2009). Rewards
features are strongly correlated with an attended one.                 evoke learning of unconsciously processed visual stimuli
   Here we show that when there is only a partial positive             in adult humans. Neuron, 61(5), 700-707.
correlation between the presentation of a task relevant
feature and the presentation of irrelevant features (as it is                           Acknowledgments
inherently the case in mid-information feedback conditions),        This research was supported by grants from the NSF (BCS-
together with lack of explicit information regarding which          0720135) and NIH (R01HD056105) to Vladimir Sloutsky, and
feature is relevant, there is significant interference with the     NIH (R01EY019279-01A1) to Kalanit Grill-Spector.
                                                                425

