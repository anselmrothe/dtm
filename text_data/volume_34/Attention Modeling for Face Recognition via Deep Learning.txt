UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Attention Modeling for Face Recognition via Deep Learning
Permalink
https://escholarship.org/uc/item/4br120rx
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Zhong, Sheng-hua
Liu, Yan
Zhang, Yao
et al.
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    Attention Modeling for Face Recognition via Deep Learning
                                    Sheng-hua Zhong (csshzhong@comp.polyu.edu.hk)
                                          Department of Computing, Hung Hom, Kowloon
                                                      Hong Kong, 999077 CHINA
                                              Yan Liu (csyliu@comp.polyu.edu.hk)
                                          Department of Computing, Hung Hom, Kowloon
                                                       Hong Kong, 99907 CHINA
                                        Yao Zhang (csyaozhang@comp.polyu.edu.hk)
                                          Department of Computing, Hung Hom, Kowloon
                                                       Hong Kong, 99907 CHINA
                                        Fu-lai Chung (cskchung@comp.polyu.edu.hk)
                                          Department of Computing, Hung Hom, Kowloon
                                                       Hong Kong, 99907 CHINA
                             Abstract                                  validations have demonstrated that attention models have
                                                                       notable ability in various tasks, such as content aware
   Face recognition is an important area of research in cognitive
   science and machine learning. This is the first paper utilizing     resizing (Avidan et al., 2007), quality assessment (Zhong et
   deep learning techniques to model human’s attention for face        al., 2010), and face recognition (Cappelli, et al., 2007)
   recognition. In our attention model based on bilinear deep          (Fang, et al., 2011).
   belief network (DBDN), the discriminant information is                 This paper models human’s attention for face recognition
   maximized in a frame of simulating the human visual cortex          via deep learning technique. Deep learning models the
   and human’s perception. Comparative experiments                     learning tasks using deep architectures composed of
   demonstrate that from recognition accuracy our deep learning
   model outperforms both representative benchmark models
                                                                       multiple layers of parameterized nonlinear modules. Deep
   and existing bio-inspired models. Furthermore, our model is         model is selected in this paper because of two
   able to automatically abstract and emphasize the important          considerations. First, the multiple layers deep architecture is
   facial features and patterns which are consistent with the          consistent with the laminar structure of human’s brain
   human’s attention map.                                              cortex and the information delivery in deep model simulates
   Keywords: face recognition; attention model; deep learning.         human’s visual cortex. Second, deep learning has
                                                                       demonstrated distinguished ability of information
                         Introduction                                  abstraction and robust performance of data classification in
                                                                       various visual data analysis tasks (Hinton, et al., 2006).
Face recognition plays an important role in the social life
                                                                          This is the first paper utilizing deep learning techniques to
and attracts interest from a very broad range of researchers
                                                                       model human’s attention for face recognition. Compared
and scientists (Anderson, 1998). In machine learning and
                                                                       with existing face recognition models, our proposed bilinear
computer vision areas, face recognition using computational
                                                                       deep belief network (BDBN) has several attractive
models is a classical problem. The representative models
                                                                       characters:
include: Eigenface (Turk, et al., 1991), Fisherfaces
(Belhumer, et al., 1997), support vector machine (SVM)                 1) BDBN maximizes the discriminant information in a
(Müller, et al., 2001), and so on.                                     frame of simulating the human visual cortex and human’s
   In cognitive science, face recognition is a vividly                 perception. As we known, nearly all existing machine
researched area (Gauthier, et al., 2000) (Afraz, et al., 2006)         learning models aims to find the discriminant solution to
(Civile, et al. 2011). It is argued that face perception is            face recognition applications. Existing computational
involved in a unique cognitive process compared with non-              cognitive model emphasizes the identity between the model
face object or scene perception. Researchers in cognitive              and the human visual system. Our model attempts to
science seek to understand how the visual system transforms            integrate the advantages of both techniques and provide a
a face image from an initial, pixel-like representation, to a          new thought of this problem.
new powerful form of representation, and finally induce the
                                                                       2) Compared with existing computational face recognition
selectively response of the neurons in inferior temporal
                                                                       models or representative attention models, BDBN has the
cortex (Afraz, et al., 2006). Hence, the researchers have
                                                                       ability to automatically extract and emphasize the important
utilized some signal processing techniques to simulate the
                                                                       facial features and patterns which are consistent with the
response of human visual system, such as human’s attention
                                                                       human attention map.
allocation. Computational attention model is utilized to
measure of the conspicuity and provide the predictions                 3) BDBN includes three learning stages: semiconducting
about which regions are likely to attract observers’ attention         bilinear discriminant initialization, greedy layer-wise
(Koch et al., 1985) (Parkhurst et al., 2002). Many empirical           reconstruction, and global fine-turning. The rational of
                                                                   2609

three-stage learning comes from the phenomenon of two               includes input layer H 1 , hidden layer H 2 ,…, H N , and one
peaks activation in visual cortex areas. With regard to object      label layer La at the top. The input layer H 1 has I  J units,
recognition, the early peak is related to the activation of an      and this size is equal to the dimension of the input features.
“initial guess” based on the acquired discriminative                In our model, we use the pixel values of sample datum X k
knowledge, while the late peak reflects the post-recognition
                                                                    as the original input features. In the top, the label layer has
activation of conceptual knowledge related to the
                                                                     C units, which is equal to the number of classes. The search
recognized object.
                                                                    of the mapping function from X to Y is transformed to the
                                                                    problem of finding the optimum parameter space  * for the
                               Model
                                                                    deep architecture.
In this section, we design a deep learning algorithm with a           In our deep learning architecture, X is a set of data
deep architecture for the task of face recognition, includes        samples, X  [X1, X2 ,..., Xk ,..., XK ] . X k is a sample datum in
bilinear discriminant initialization, greedy layer-wise
reconstruction and global fine-tuning. The strategy of              the image space IJ and K is the number of sample data.
                                                                    Y is a set of labels corresponding to X ,
bilinear discriminant projection is utilized to construct a
projection to map the original data into a discriminant             Y  [y1 ,y 2 ,...,yk ,...,y K ] . y k is the label vector of X k in C ,
preserving subspace. And it determines the initial                             1 if Xk  c th class
                                                                        y kc                       , where C is the number of classes.
parameters and sizes of the upper layer. To human, this                        0 if Xk  c th class
strategy is consistent with the early peak related to the           Based on the given training set, the aim in face recognition
activation of “initial guess”. In the stage of greedy layer-        is to learn a mapping function from the image set X to the
wise reconstruction, the parameter space is refined by the          label set Y, and then recognize the new coming face images
greedy layer-wise information reconstruction using                  according to the learned mapping function.
Restricted Boltzmann Machines (RBMs) (Smolensky, 1986)
as building blocks. In the stage of global fine-tuning, we
refine the parameter space for better face recognition
                                                                    Bilinear Discriminant Initialization
performance. And it is consistent with the late peak related        In order to preserve the discriminant information in the
to the activation of “post-recognition”. After the deep             learning procedure, the objective function of bilinear
learning model is constructed, the attention map is built           discriminant initialization could be represented as follows:
                                                                                              || U (X  X )V || ( B
                                                                                                K
based on the parameter space in the first RBM.
                                                                         arg max J (U, V) =                 T
                                                                                                                   s   t
                                                                                                                            2
                                                                                                                                st    (1   ) Wst )
              Input Label     y 1k y k2 … y C  k
                                                                             U ,V
                                                                                              s ,t 1                                                   (1)
                                                                              s.t. U U  I P , V V  I Q
                                                                                    T                   T
               La                       …
                                                                    where balance weight   [0,1] is the parameter used to
      N                               …
              H   N
                              …                                     balance the between-class weights B st and the within class
                                   …      …
       N1                       …        …
                                                                    weights Wst , which are defined as follows (Yan, et al., 2007)
              H N1       …    …          …   …                     (Sugiyama, 2007).
                               …           …                          By simultaneously maximizing the distances between data
              …                       …                             points from different classes and minimizing the distances
                                  …       …                         between data points from the same class, the discriminant
               Hn
                          …
                                   … …        …                     information is preserved to the greatest extent in the
       n1                   …     …  …                            projected feature space. Solving U (or V ) with fixed V
              H n1       …       …       …    …                    (or U ) is a convex optimization problem. Let
                                  …        …                        Est   Bst  (1   )Wst , with the fixed V. The optimal U is
              …                       …                             composed of the first P eigenvectors of the following
                                  …        …
                  2           …           …        …                eigendecomposition problem:
              H       …       …        …                                                            DVu  λu                    (2)
         1
                  1
                               …          …        …                where DV   st Est ( Xs  Xt )VVT ( Xs  Xt )T . Similarly, with the
              H       …       …       …       …    …                fixed U, the optimal V is composed of the first Q
                                              …                     eigenvectors of the following eigendecomposition problem:
                              Input Image Xk                                                                    DU v  λv                               (3)
                                                                    where DU   st Est ( Xs  Xt )T UUT ( Xs  Xt ) .
Figure 1: Architecture of the bilinear deep belief network.
                                                                      The above steps monotonically increase J (U,V) and
  Figure 1 shows the architecture of our bilinear deep belief       since the function is upper bounded, it will converge to a
network. A fully interconnected directed belief network             critical point with transformation matrices U , V .
                                                                 2610

  By bilinear discriminant initialization, we obtain the                                                                                  To every neuron in the input layer, the weight value to the
discriminant initial connections in layer pair and utilize the                                                                            one in the first hidden layer is calculated as feature map.
optimal dimension to define the structure of the next layer.                                                                              Then, the weight value of every neuron is normalized and
                          Aijn, pq (0)  (U nip )T V jqn    (4)                                                                           combined into an attention map.
                                             Pn1  row(Un ) , Qn1  column(Vn )                                                 (5)                                                         Feat
                                                                                                                                                                                                   e
                                                                                                                                                                                                 ur
                                                                                                                                                                                                      ap
Greedy Layer-Wise Reconstruction                                                                                                                                                  …
                                                                                                                                                                                                     M
In this section, we describe how to construct the first RBM
between the input layer H 1 and the first hidden layer H 2 .                                                                                                                              …
                                                                                                                                                                                                       Attention Map
The energy of the state ( h1 , h 2 ) in the first RBM is:                                                                                                          …           …
                                                                                                                                                                …            …        …
                                                                                                                                                   H2   …       …
                                   E  h , h ;
                                         1    2       1
                                                            (h A h      1   1       2
                                                                                           bh ch )
                                                                                             1 1        1   2
                                                                                                                                  (6)                                      …
where  1   A1 ,b1 ,c1  are the model parameters between the                                                                               1                 …            … …
                                                                                                                                                   H1   …      …        …         …       …
input layer H 1 and first hidden layer H 2 . Therefore, the log-                                                                                                                  …
likelihood probability of the model assigned to h1 in H 1 is:
                                                                                  log                                    
                   log P  h1   log               e                                       e
                                                                 E h1, h2 ;1                               E h1, h2 ;1
                                                                                                                                  (7)
                                                                                                                                                                    Input Image
                                                      h2                                      h1   h2
                                                                                                                                          Figure 2: Construct attention model by first RBM in bilinear
      By calculating the derivative of Equation (8), we could                                                                             deep belief network.
update the parameter space with respect to the parameter
 1   A1 , b1 , c1  .                                                                                                                      Experiment 1: Recognition Accuracy Analysis
           log p(h1 (0))                                                                   E (h 2 (0), h1 (0))
                1
                                                 p(h (0) | h (0))
                                                  h 2 (0)
                                                                  2                1
                                                                                                     1
                                                                                                                 
                                                                                                                                          Dataset
                                                                                                                                          The CMU PIE face dataset collected between October and
                                                                                                                                 (8)      December 2000 contains 68 subjects with a total of 41,368
                                                            E (h (t ), h (t ))
           p(h (t), h (t))
                                                                       2           1
                                     2         1
                                                                                                                                          face images (Sim, et al., 2002). The face images were
                                                                   1
          h 2 ( t ) h1 ( t )                                                                                                              captured by 13 synchronized cameras and 21 flashes, under
                                                                                                                                          varying pose, illumination and expression. In the first
      The above discussion is the greedy layer-wise
                                                                                                                                          experiment, we use all the images under different
abstraction for the first layer H 1 with its next adjacent layer
                                                                                                                                          illuminations and expressions with five near frontal poses
 H 2 . Similar operations can be performed on the higher                                                                                  (C05, C07, C09, C27, C29). Thus we obtain 170 images for
layer pairs.                                                                                                                              each individual.
Global Fine-Tuning
                                                                                                                                          Procedure
In this section, we use backpropagation to adjust the entire
deep network to find good local optimum parameters                                                                                        For the CMU PIE face dataset, the preprocessing is applied
 [A,b,c] by minimizing the recognition error                                                                                            following the general setting of experiment (He, et al.,
                                                                                                                                          2005). Original images are normalized (in scale and
      y log y ] , where y
                                                                          
[             l               l                            l   and y l are the correct recognition                                       orientation) so that the two eyes are aligned at the same
      l
                                                                                                                                          position. Then, the facial areas are cropped into the final
label and the output recognition label value of labeled                                                                                   images for matching. The size of each cropped image in all
sample datum X l in X L .                                                                                                                 of the experiments is 32×32 pixels. Sample images after
  Above, we utilize the greedy layer-by-layer algorithm to                                                                                preprocessing are shown in Figure 3.
learn a deep model with the help of discriminant
information obtained from bilinear discriminant projection.
Therefore, the convergence in our algorithm obtained from
                                                                                                                                                                    (a) Different poses
backpropagation is not slow. And the result generally
converges to a good local minimum on the error surface.
Attention Modeling                                                                                                                                          (b)Different illumination conditions
The weights of first layer of BDBN are oriented, Gabor-like
and resemble the receptive fields of V1 simple cell (Zhong,
et al., 2011). Therefore, the first RBM is utilized to                                                                                                        (c) Different facial expressions
construct the attention model which is shown in Figure 2.                                                                                 Figure 3: Sample images after preprocessing from CMU
                                                                                                                                          PIE.
                                                                                                                                       2611

   In our experiments, the balance weight of our model is set       Experiment 2: Face Feature Points Emphasis
as 0.5 for simplicity. For parameters such as the learning
rate and the momentum, we simply follow the general               Dataset
setting of previous work on computational deep networks
(Bengio, et al., 2006), although more careful choice may          The BioID face dataset consists of 1521 gray level images
lead to better performance. In the fine-tuning stage, the         collected contains 23 subjects (HumanScan, 2003). The face
method of conjugate gradients is utilized and three line          images in BioID are under a large variety of illumination,
searches are performed in each epoch until convergence.           background.
   To adapt the real-world face recognition tasks, our               In this dataset, the x and the y coordinate of the left eye
computational neuroscience model BDBN is applied under            and the right eye are provided. Furthermore, the 20
a semi-supervised learning framework. It makes face               important facial feature points are manually placed,
recognition work well when labeled images are insufficient.       including: right eye pupil, left eye pupil, right mouth corner,
120 images are randomly selected for each person to form          left mouth corner, outer end of right eye brow, inner end of
the training set and the rest to form the test set. Of the 120    right eye brow, inner end of left eye brow, outer end of left
images for each person, different numbers of images are           eye brow, right temple, outer corner of right eye, inner
randomly selected and labeled while the others remain             corner of right eye, inner corner of left eye, outer corner of
unlabeled. The number of labeled data per subject is equal        left eye, left temple, tip of nose, right nostril, left nostril,
to 5, 10, 20 and 40, respectively. We perform 10 random           centre point on outer edge of upper lip, centre point on outer
splits and report the average results over the 10 trials.         edge of lower lip, and tip of chin. These facial feature points
                                                                  are thought to be very useful for facial analysis and gesture
Experimental Results                                              recognition (Jesorsky, et al., 2001) (Wang, et al., 2002)
                                                                  (Cappelli, et al., 2007).
In the first experiment, we compare three representative face
recognition models, including: Eigenface (Turk, et al., 1991),    Procedure
Fisherfaces (Belhumer, et al., 1997), SVM (Müller, et al.,
2001), and existing bio-inspired Sparse Localized Features        As a deep learning model for face recognition, BDBN has
(SLF) model (Mutch and Lowe, 2008).                               demonstrated the impressive recognition performance in this
   SVM, Eigenface, and Fisherfaces both are representative        first experiment. In this experiment, we intend to investigate
benchmark machine learning models for the task of face            the consistency between the emphasized regions in BDBN
recognition. The bio-inspired Sparse Localized Features           and the attention map of human being.
(SLF) (Mutch and Lowe, 2008) are an extensions of the C2             The number of images in every category of BioID is
features from the Serre et al. HMAX model (Serre, et al.,         varied, from 35 to 118. Therefore, firstly, we choose the
2007). For this representation, we took advantage of the          categories with more than 50 face images as the subset we
MATLAB code provided by the authors. Here, the SVM                work on. Then, just like the procedure on face datasets, the
classification was based on a linear kernel with normalized       original images are normalized (in scale and orientation) so
training and testing data (zero-mean and unit-variance            that the two eyes are aligned at the same position. Finally,
feature-wise).                                                    the facial areas are cropped and downsampled into the final
   The recognition accuracy rate with different numbers of        images. The size of each final image in all of the
labeled data is shown in Table 1. As shown in Table 1, the        experiments is 32×32 pixels, with 256 gray levels per pixel.
recognition accuracy rate of bio-inspired models SLF+SVM          Some sample images after preprocessing are shown in
and BDBN is better than machine learning models                   Figure 4.
Eigenfaces and SVM. And our proposed BDBN has the best
performance than others.
Table 1: Recognition accuracy rate (%) on the test data with
different numbers of labeled data per category on CMU PIE.
Num./Cat.          20         30           40          50
Eigenfaces      61.9±0.7   72.1±0.6    78.2±0.5     83.8±0.4
Fisherfaces     84.5±0.7   92.0±0.6    93.1±0.5     94.8±0.3
SVM             73.5±0.6   80.4±0.5    82.9±0.5     87.1±0.3
SLF+SVM         80.5±0.6   86.8±0.5    89.5±0.5     90.2±0.3
Semi_DBN        85.4±0.7   92.4±0.6    93.5±0.5     95.0±0.3
BDBN            88.4±0.7   93.9±0.6    94.3±0.5     96.6±0.3
                                                                  Figure 4: Sample images after preprocessing from BioID.
                                                                     Then, to every image in BioID face dataset, we directly
                                                                  input the original pixel value to the BDBN model. After
                                                              2612

bilinear discriminant initialization and layer wise                 also emphasized in the parameter space of proposed model.
reconstruction, we evaluate the consistency between the             Therefore, if the importance from other important regions
constructed attention model and human’s attention map.              for face recognition is excluded, the facial feature points
                                                                    cover percentage in saliency map will be much better.
Experimental Results                                                   In Figure 6, the comparison of different computational
Computational attention model was called saliency map first         attention maps are provided, including Graph Gabor
appeared in (Koch, et al., 1985). Typically, multiple low-          attention map (Harel, et al., 2006), Itti classical attention
level visual features such as intensity, color, orientation,        map (Itti & Koch, 2000) and BDBN attention map. It is
texture and motion are extracted at multiple scales. After a        obviously that BDBN has better coverage than other models.
feature map is computed for each of the features, they are          It proves that BDBN provides a human-like judgment by
normalized and combined into a master saliency map that             referencing the human visual system.
represents the saliency of each pixel.
   To face images, some facial areas are assessed to be
attracted more attention and helpful to face recognition, for
example eye, ear, nose and mouth (Hickman, et al., 2010).
Fortunately, in this dataset, 20 important facial feature
points are manually selected out and placed. Therefore, with
marked facial feature points, the attention model based on              (a)Sample face image         (b) Face image with facial
deep learning model could be evaluated without eye                                                          feature points
tracking recordings.
   Different from representative attention map which utilizes
various features such as intensity, color, orientation, only
the gray level pixel values are input into our model. Our
attention model automatically extracts and emphasizes
important features and patterns to construct facial attention
model.
   To demonstrate the effectiveness of our model, firstly, the
visualization of the parameter space of proposed model is
observed. Figure 5 (a) shows a sample image, and Figure 5
(b) shows the sample image with the facial feature points.
Figure 5 (c) visualizes the parameter spaces between the
input layers and the first hidden layer in BDBN. Each
picture shown below represents one neuron in the hidden
layer and each pixel quantizes the weight value between that
neuron and the one in the input layer. Obviously, the
proposed BDBN can automatically extract and emphasize
the important areas of human’s face, such as the eyes,
eyebrows, noses, cheeks, mouths and chins.
                                                                            (c) Emphasized regions of BDBN corresponding
   Then, we construct the saliency regions based on the
                                                                                        to facial feature regions
emphasized regions of BDBN. Just like the Figure 5 (c), the
weight value between each neuron in the input layer to the          Figure 5: Samples of first layer weights learned by BDBN,
one in the first hidden layer is calculated at first. Then, the     and the consistency of these weights with facial feature
weight value of every neuron is normalized and combined             points.
into a saliency map. According to the x and the y
coordinates of the 20 important facial feature points of every
face image in the dataset, we statistically analyze the
percentage of all facial feature points located in the saliency
                                                                            (a)Sample face image with facial feature points
regions of the saliency map.
   There are 63.71% facial feature points are located inside
30% most saliency regions and only about 1% facial feature
points are located outside 80% most saliency regions. It is
obviously that proposed BDBN covers most of important
facial feature points. From Figure 4, some of other                 (b) Graph Gabor map (c) Itti map              (d) BDBN map
information and regions are useful to recognize people, such
                                                                    Figure 6: The comparison of different attention maps with
as the hairstyles and the face contour, although they are not
                                                                    facial feature points.
belong to the 20 important facial feature points. And as
shown in Figure 5 (c), these information and regions are
                                                                2613

              Conclusion and Future Work                                 Hickman, L. Firestone, AR, Beck, FM, and Speer, S., (2010). Eye
                                                                            fixations when viewing faces. Journal of the american dental
In this paper, we make an attempt to construct an attention                 association jada electronic resource, (pp. 40–46).
model for face recognition in a frame of simulating the                  Hinton, G.E., and Salakhutdinov, R.R. (2006). Reducing the
human visual cortex and human’s perception. To evaluate                     dimensionality of data with neural networks. In Science.
proposed face recognition models, we do experiments on                   Hinton, G. E., (2007). Learning Multiple Layers of Representation.
two face images’ datasets, CMU PIE and BioID.                               In Trends. Cogn. Sci.
Experiments results not only show the distinguishing                     HumanScan,            (2003).       BioID         face        database.
recognition ability of our deep model but also clearly                      https://www.bioid.com/download-center/software/bioid-face-
                                                                            database.html.
demonstrate our intention of providing a human-like face
                                                                         Itti, L. and Koch, C. (2000). A saliency-based search mechanism
image analysis by referencing the human visual cortex and                   for overt and covert shifts of visual attention. In Vision Res..
perception procedure.                                                    Jesorsky, O., Kirchberg, K., Frischholz, R.. (2001). Robust face
  It is the general opinion that advances in cognitive science              detection using the hausdorff distance. In Proceedings of the 3th
especially neuroscience will provide useful insights to                     International Conference on Audio- and Video-based Biometric
computer scientists into how computer models construct,                     Person Authentication.
and vice versa. To a certain extent our attempt is an example            Koch, C. & Ullman, S.. (1985). Shifts in Selective Visual Attention:
to prove that the computational models are not only applied                 Towards the Underlying Neural Circuitry, In Human
into the tasks of classification and recognition just as the                Neurobiology. pp. 219-227.
                                                                         Müller, KR, Mika, S., Rätsch, G., Tsuda, K., and BSchölkopf,
optimal classifier, they also can provide human-like
                                                                            (2001). An introduction to Kernel-based learning algorithms,
response by referencing the human visual system. In future,                 IEEE Transactions on Neural Networks, vol. 12, no. 2, (pp 181-
we will go on this direction to propose novel computational                 201).
model by referring more characters of human visual system.               Mutch, J. and Lowe, DG, (2008). Object class recognition and
And vice versa, in cognitive science, we will explore                       localization using sparse features with limited receptive fields,
whether the human visual system possess the related                         International Journal of Computer Vision.
mechanism which is consistent with the computational                     Parkhurst, K. Law, and Niebur, E. (2002). Modeling the role of
model from the viewpoint of mathematics.                                    salience in the allocation of overt visual attention. In Vision Res..
                                                                         Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M., and Poggio, T.,
                                                                            (2007). Robust object recognition with cortex-like mechanisms.
                           References                                       IEEE Transactions on Pattern Analysis and Machine
Anderson, JR, (1998). Social stimuli and social rewards in primate          Intelligence.
  learning and cognition. Behavioural Processes (pp. 159–175).           Sim, T., Baker, S., and Bsat, M., (2002). The CMU Pose,
Afraz, SR, Kiani, R. and Esteky, H., (2006) Nature, 442, (pp. 692–          Illumination, and Expression (PIE) Database, Proceedings of
  695).                                                                     IEEE International conference on Automatic Face and Gesture
Avidan, S. and Shamir, A. (2007). Seam carving for content-aware            Recognition.
  image resizing”, In ACM Transactions on Graphics.                      Smolensky, P.. (1986). Information processing in dynamical
Belhumer, P., Hespanha, P., and Kriegman, D., (1997). Eigenfaecs            systems: foundations of harmony theory. In Parallel Distributed
  vs. fisherfaces: Recognition using class specific linear                  Processing: Explorations in The Microstructure of Cognition,
  projection, IEEE Transactions on Pattern Analysis and Machine             vol. 1: Foundations, MIT Press, (pp. 194-281).
  Intelligence, vol. 19, no. 7, (pp.711-720).                            Sugiyama, M., (2007). Dimensionality reduction of multimodal
Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., (2006).              labeled data by local fisher discriminant analysis. In JMLR.
  Greedy layer-wise training of deep networks, Advances in               Turk, M. and Pentland, A. (1991). Face recognition using
  Neural Information Processing Systems.                                    eigenfaces. In Proceedings of the Computer Society Conference
Cappelli, R., Franco, A. Maio, D. (2007). Gabor Saliency Map for            on Computer Vision and Pattern Recognition, Lahaina, Maui,
  Face Recognition, In Proceedings of the 14th International                Hawaii, (pp. 586–591).
  Conference on Image Analysis and Processing, 443-447.                  Yan, S., Xu, D. Zhang, B., Zhang, H.J., Yang, Q., and Lin, S.,
Civile, Ciro, McLaren, R.P., McLaren, L.P.L., (2011), Perceptual            (2007). Graph embedding and extension: a general framework
  learning and face recognition: Disruption of second order                 for dimensionality reduction. In PAMI.
  relational information reduces the face inversion effect. In 33th      Yang, P., Shan, SG, Gao, W., Li. SZ, Zhang, D. (2004). Face
  annual meeting of the Cognitive Science Society, 2083-2088.               recognition using Ada-Boosted Gabor features, Automatic Face
Fang, F., Qing, L.Y., Wang, C.X., Miao J., Chen X.L., Gao, W..              and Gesture Recognition, (pp. 356-361).
  (2011). Attention Driven Face Recognition, Learning from               Wang, Y. Chua, C., Ho,Y., (2002). Facial feature detection and
  Human Vision System, In International Journal of Computer                 face recognition from 2D and 3D images, In Pattern
  Science Issues.                                                           Recognition Letters. 1191–1120.
Felleman, D. J., Van Essen, D. C., (1991). Distributed hierarchical      Zhong, S.H., Liu, Y., Liu, Y. and Chung, F.L.. (2010). A semantic
  processing in the primate cerebral cortex. In Cereb. Cortex.              no-reference image sharpness metric based on top-down and
Gauthier, I., Skudlarski, P., Gore, J.C., & Anderson, A.W. (2000).          bottom-up saliency map modeling. In IEEE International
  Expertise for cars and birds recruits brain areas involved in face        Conference on Image Processing.
  recognition. Nature Neuroscience, 3 (2): 191–197.                      Zhong, S.H., Liu, Y., Liu, Y..(2011). Bilinear deep learning for
Harel, J., Koch, C. and Perona, P.. (2006). Graph-Based Visual              image classification. In Proceedings of the 19th ACM
  Saliency In NIPS.                                                         International Conference on Multimedia.
He, XF, Cai, D., and Niyogi, P., (2005). Tensor subspace analysis,
  Advances in Neural Information Processing Systems.
                                                                     2614

