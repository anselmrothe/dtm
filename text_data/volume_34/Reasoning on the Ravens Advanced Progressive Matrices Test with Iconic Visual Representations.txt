UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reasoning on the Raven’s Advanced Progressive Matrices Test with Iconic Visual
Representations
Permalink
https://escholarship.org/uc/item/8dh100h9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Kunda, Maithilee
McGreggor, Keith
Goel, Ashok
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                   Reasoning on the Raven’s Advanced Progressive Matrices Test
                                          with Iconic Visual Representations
                                   Maithilee Kunda*, Keith McGreggor*, and Ashok Goel
               Design & Intelligence Laboratory, School of Interactive Computing, Georgia Institute of Technology
                                               85 Fifth Street NW, Atlanta, GA 30332 USA
                                    {mkunda,keith.mcgreggor}@gatech.edu, goel@cc.gatech.edu
                                                 *these authors contributed equally to this work
                             Abstract                                    Verbal strategies use amodal propositional mental
                                                                         representations, such as linguistic description.
   Although the problems on Raven’s Progressive Matrices
   intelligence tests resemble geometric analogies, studies of              From factor analyses of both the SPM (Lynn et al., 2004;
   human behavior suggest the existence of two qualitatively             van der Ven & Ellis, 2000) and the APM (Dillon et al.,
   distinct types of strategies: verbal strategies that use              1981; Mackintosh & Bennett, 2005; Vigneau & Bors, 2005)
   propositional representations and visual strategies that use          as well as from fMRI data (Prabhakaran et al., 1997) comes
   iconic representations. However, all prior computational              evidence for various categories of RPM problems
   models implemented to solve these tests have modeled only             differentially eliciting from people either visual or verbal
   verbal strategies: they translate problems into purely                strategies. Studies of patients with focal brain lesions have
   propositional representations. We examine here the other half         also found linkages between brain regions associated with
   of what may be a dual-process mechanism of reasoning in               visual or verbal processing and successful performance on
   humans: visual strategies that use iconic representations. In
                                                                         certain RPM problems (Berker & Smith, 1988; Villardita,
   particular, we present two different algorithms that use iconic
   visual representations to address problems found on the               1985). Individuals with autism, who may exhibit a general
   Advanced Progressive Matrices test, the best of which yields          bias towards using visual strategies over verbal ones (Kunda
   performances at levels equivalent to the 75th percentile for          & Goel, 2007, 2011), tend to do particularly well on the
   human test takers aged from 20 to 62 years-old. We discuss            RPM (Bölte et al., 2009; Dawson et al., 2007) and have
   implications of our work for understanding the computational          been observed with fMRI to prefer predominantly visual
   nature of Raven’s and visual analogy in problem solving.              strategies on the RPM (Soulières et al., 2009).
   Keywords: Analogy; intelligence tests; knowledge                         Despite this breadth of evidence for the existence of both
   representations; mental imagery; Raven’s Progressive                  visual and verbal RPM strategies, most computational RPM
   Matrices; visual reasoning.                                           accounts have presumed to translate visual inputs into
                                                                         propositional representations, over which various kinds of
                          Introduction                                   reasoning then take place. One reason for this may be the
                                                                         general preponderance of propositional representations in
The Raven’s Progressive Matrices (RPM) test is a                         computational accounts of cognition; in many models of
standardized intelligence test. The test consists of geometric           visual reasoning across various task domains, visual
analogy problems in which a matrix of geometric figures is               knowledge too is represented using propositions (Carpenter
presented with one entry missing, and the correct missing                et al. 1990, Lovett et al. 2010, Davies et al. 2008).
entry must be selected from a set of answer choices. Figure
1 shows an example of a matrix problem of this kind.
   There are currently three published versions of the RPM:
the original Standard Progressive Matrices (SPM), the
Advanced Progressive Matrices (APM), developed as a
more difficult test than the SPM for individuals in high IQ
ranges, and the Colored Progressive Matrices (CPM),
intended as a simpler test than the SPM to be used with
children, the elderly, or other individuals falling into lower
IQ ranges (Raven et al., 2003). The RPM tests are
considered to be the single best psychometric measures of
general intelligence, outside of multi-domain IQ tests like
the Wechsler scales (Snow et al., 1984), and all three
versions of the RPM are widely used in clinical,
educational, occupational, and scientific settings.
   Neuroimaging and behavioral studies suggest that humans
recruit qualitatively different strategies on the RPM
regarding what types of mental representations are used,
specifically in terms of visual versus verbal strategies.                                  Figure 1: Example RPM Problem.
Visual strategies use iconic mental representations rooted in
the visual perceptual modality, such as mental imagery.
                                                                    1828

   Another reason may stem from the practice of using                rules and a goal monitor. Both systems were tested against
verbal reporting protocols to study RPM problem solving.             34 of the 48 problems from the APM and solved 23 and 32
By their very nature, verbal reports are better suited to            problems, respectively.
describing verbal strategies than visual strategies, which              Model 2 Bringsjord and Schimanski (2003) used a
may introduce bias into the results of such protocols. Of            theorem-prover to solve selected RPM problems stated in
even greater significance are findings across multiple task          first-order logic, though no specific results were reported.
domains that the act of verbal reporting actually biases                Model 3 Lovett, Forbus, and Usher (2010) combined
individuals towards using verbal strategies and/or impairs           automated sketch understanding with the structure-mapping
their use of visual strategies, a phenomenon known as                analogy technique to solve SPM problems. Their system
“verbal overshadowing” (Schooler & Engstler-Schooler,                took as input problem entries sketched in Powerpoint as
1990; Schooler et al., 1993). DeShon, Chan, and Weissbein            segmented shape objects and then automatically translated
(1995) found that a verbal reporting protocol on the APM             these shapes into propositional descriptions, using a sketch
significantly impaired accuracy on about half of the                 understanding system based on work by Biederman (1987).
problems, and specifically on those typically solved using           A two-stage structure-mapping process, following the theory
visual strategies.                                                   of Gentner (1983), was then used to select the answer that
   The goal of our work is to develop computational models           most closely fulfilled inferred analogical relations from the
of a dual cognitive strategy that uses both verbal and visual        matrix. This system was tested against 48 of the 60
representations. This first requires the development of              problems on the SPM and solved 44 of these 48 problems.
computational models of the visual strategy itself. Once                Model 4 The system of Cirillo and Ström (2010), like
such computational models have been developed, they then             that of Lovett et al. (2010), took as input hand-drawn vector
may potentially be coupled with existing models of the               graphics representations of test problems and automatically
verbal strategy. We have developed two such computational            generated propositional representations. Then, like the work
models of reasoning on the RPM using iconic visual                   of Carpenter et al. (1990), the system drew from a set of
representations. In earlier work, we tested these models             predefined patterns, derived by the authors from an a priori
against the SPM (Kunda, McGreggor, & Goel, 2010). In this            inspection of the SPM, to find the best-fit pattern for a given
paper, we apply these computational models to the APM.               problem. This system was tested against 36 of the 60
   In so far as we know, this work represents several firsts: it     problems on the SPM and solved 28 of these 36 problems.
is the first report of any computational model addressing the           Model 5 Rasmussen and Eliasmith (2011) used a spiking
entirety of the APM test, the first in which the problems are        neuron model to induce rules for solving RPM problems.
attempted using purely iconic visual representations, and the        This system took as input hand-coded vectors of
first to tackle the test using scanned images of each test           propositional attribute-value pairs. While the system was
page, without any re-rendering or representational change of         said to correctly solve RPM problems, no specific results
inputs from those presented to a human test-taker.                   were reported.
        Computational Accounts of the RPM                            Our Approach
Hunt (1974) proposed the existence of two different RPM              As mentioned above, despite considerable differences in
strategies that varied primarily in how problem inputs were          architecture and problem-solving focus, all five of these
represented. The “Analytic” algorithm used propositions to           computational models of the RPM have reasoned over
represent problems as lists of features and logical operations       amodal propositional representations of test inputs. We
to evaluate rules such as constancy and addition/subtraction.        believe that Raven’s problems may be solved via
The “Gestalt” algorithm, akin to mental imagery, used                computational models that use purely iconic visual
iconic representations and perceptual operations like                representations of test inputs, and we present these models
continuation and superposition. However, neither algorithm           as a complementary view of reasoning on the RPM.
was actually implemented. All of the computational RPM                  The two models that we have developed are the affine
models that have since been developed resemble Hunt’s                model and the fractal model, both of which use image
Analytic algorithm in that they rely on a conversion of              transformations to solve RPM problems without converting
problem inputs into amodal propositional representations.            the input images into any sort of propositional form.
   Model 1 Carpenter, Just, and Shell (1990) used a                  Previously, we described each of the models along with an
production system that took hand-coded symbolic                      analysis of their performance on all 60 problems from the
descriptions of certain problems from the Advanced                   SPM (Kunda, et al., 2010).
Progressive Matrices (APM) test and then selected from a
set of predefined rules to solve each problem. The rules                             Iconic Visual Reasoning
were generated by the authors from a priori inspection of the        The affine and fractal methods differ in important ways, but
APM. The rules were experimentally validated using a                 share two intuitions: comparing images under a variety of
verbal reporting protocol, but the potential confound of a           transformations, and judging the similarity based upon
verbal overshadowing effect was not addressed. Differences           features which arise from the images.
between low- and high-scoring participants were modeled
by developing two different versions (FairRaven and                  Similitude Transformations
BetterRaven) of the production system; the more advanced             Each of our algorithms compares images (or fragments of
system (BetterRaven) contained an increased vocabulary of            images) under a variety of transformations.            We use
                                                                 1829

similitude transformations, similarity-preserving                              fractal representation of the image comparison (McGreggor,
t r a n s f o r m a t i o n s w h i c h a r e a s u b s e t o f a ff i n e     Kunda, & Goel, 2010).
transformations.              Similitude transforms are a linear
composition of a dilation, an orthonormal transformation,
and a translation. Our implementation presently examines                             For each base transform ti:
images under eight orthonormal transformations,
specifically dihedral group D4, the symmetry group of a                              ·  Apply ti to image A to create image ti(A).
square. The translation is determined as a consequence of
                                                                                     ·  Search all possible translation offsets between images ti(A)
                                                                                        and B to find single offset (x,y) yielding highest similarity
the searching each algorithm performs. The affine method                                between them.
restricts dilation to a value of one, i.e. no scaling, whereas                       ·  Calculate similarity s between images ti(A)(x,y) and B
the fractal method uses a short sequence of progressively                            ·  For set-theoretic addition and subtraction, determine image
smaller dilation values.                Thus, the fractal method’s                      composition operation ⊕ and operand X as follows:
similitude transformations are contractive.                                                ·  If ∑(A-B) = 0, then ⊕ and X are null.
    There is evidence that human visual processing can apply                               ·  If ∑(A-B) = ∑(B-A), then ⊕ refers to image addition
                                                                                              and X = B - ti(A)(x,y).
some of these types of transformations to mental images, or
at least operations that are computationally isomorphic in                                 ·  If ∑(A-B) > ∑(B-A), then ⊕ refers to image
                                                                                              subtraction and X = ti(A)(x,y) - B.
some sense. In the theory of mental imagery proposed by
Kosslyn, Thompson, and Ganis (2006), transformations of                              The composition transformation Ti is thus defined as precisely
mental images include scanning (i.e. translation), zooming                           the transformation that changes image A into image B:
(i.e. scaling), and rotation, among others.                                                             Ti(A) = ti(A)(x,y) ⊕ X = B
A Model of Similarity
Our models must judge the similarity between images. The                                   Algorithm 1. Inducing a composite transform
nature of this similarity may be determined by any number
of means, many of which might associate visual or                              The Affine Model
geometric features to points in a coordinate space, and                        Given a matrix problem, the affine model makes two basic
compute similarity as a distance metric (Tversky 1977).                        assumptions: (a) that collinear elements are related by a
Tversky developed an alternate approach by considering                         composition of a similitude and/or set-theoretic transform,
objects as collections of features, and similarity as a feature-               and (b) that parallel sets of elements share identical or
matching process. We adopt Tversky’s interpretation, and                       analogous transforms. The model proceeds in three steps:
seek to derive a set of features for use in our matching                            1) Induce a best-fit composite transform for a
process.                                                                                 set of collinear elements in the matrix.
    We desire a metric of similarity which is normalized, one                       2) Apply this transform to the parallel set of
where the value 0.0 means entirely dissimilar and the value                              elements containing the empty element; the
1.0 means entirely similar. We use the ratio model of                                    result is a predicted answer image.
similarity as described in (Tversky 1977), wherein the                              3) Compare this predicted image to the given
measure of similarity S between two representations A and                                answer choices for maximum similarity.
B is calculated by the formula:
                                                                                  Algorithm 1 shows how, for a pair of images A and B, the
          S(A,B) = f(A ∩ B) / [f(A ∩ B) + αf(A-B) + βf(B-A)]                   “best-fit” composite transform is induced. The base unary
                                                                               transforms are the eight orthonormal symmetry transforms
where f(X) is the number of features in the set X. Tversky                     mentioned above (image rotations and mirrors), along with
notes that the ratio model for matching features generalizes                   image addition (union of sets) and image subtraction
several set-theoretical models of similarity proposed in the                   (complement of sets). The base binary transforms are the
psychology literature, depending upon which values one                         five set operations of union, intersection, subtraction (both
chooses for the weights α and β.                                               directions), and exclusive-or.
    Although the same equation is used for similarity                             There are two places at which the affine model computes
calculations, each of our models has its own interpretation                    visual similarity, first in the induction of a best-fit composite
of what constitutes a feature. In the affine method, a feature                 transform, and second in the selection of the answer choice
is defined to be a single pixel, and intersection, union, and                  that most closely matches the predicted image. In addition
subtraction operations are defined as the minimum,                             to using Tversky’s ratio model of similarity, as defined
maximum, and difference of pixel values. This formulation                      above, we also implemented a sum-squared-difference
assumes that pixels are independent features within the pixel                  measure, which we converted to a measure of similarity
sets represented by images A and B. While this notion of                       (with minimum value of 0.0 and maximum value of 1.0) as:
pixel independence is a strong simplification, it matches
assumptions made by basic template theories of visual                                                SSDsimilarity = 1 / (1 + SSD)]
similarity that define similarity based purely on evaluations
of the extent of overlapping figural units (Palmer, 1978),                        These two similarity measures exhibit different behaviors.
e.g. individual pixels. The fractal method uses features                       The Tversky measure privileges matches that share more
derived from different combinations of elements from the                       pixel content. In contrast, the SSD similarity measure
                                                                           1830

effectively ignores any pixel content that is shared;
similarity is calculated only as a function of pixels that are            First, systematically partition D into a set of smaller
different.                                                                images, such that D = {d1, d2, d3, … }.
   Once the transformation is found that maximizes                        For each image di:
similarity, the transformation is applied to the first entry or
entries in the last row or column, as shown in Figure 2. The              ·  Examine the entire source image S for an equivalent image
resulting image represents the algorithm’s best guess as to                  fragment si such that an affine transformation of si will likely
                                                                             result in di.
the missing entry. This image is compared to the answer
choices, and the best match is chosen as the final answer.                ·  Collect all such transforms into a set of candidates C.
                                                                          ·  Select from the set C that transform which most minimally
                                                                             achieves its work, according to some predetermined metric.
                                                                          ·  Let Ti be the representation of the chosen transformation
                                                                             associated with di.
                                                                          The set T = {T1, T2, T3, … } is the fractal representation
                                                                          of the image D.
                                                                               Algorithm 2. Fractal Representation of D from S
                                                                       To determine which candidate image results in the most
                                                                    analogous transform to the original problem transform T,
                                                                    we first fractally encode that relationship between the two
                                                                    images A and B. Next, using each fractal feature associated
                                                                    with that encoding, we retrieve from the memory system
                                                                    those transforms previously stored as correlates of that
                                                                    feature (if any). Considering the frequency of transforms
                                                                    recalled, for all correlated features in the target transform,
   Figure 2. Sets of elements examined by the affine method         we then calculate a measure of similarity.
                                                                       Determining Fractal Similarity The metric we employ
                                                                    reflects similarity as a comparison of the number of fractal
The Fractal Method                                                  features shared between candidate pairs taken in contrast to
                                                                    the joint number of fractal features found in each pair
Like the affine method, the fractal method seeks to find a re-      member (Tversky 1977). The measure of similarity S
representation of the images within a Raven’s problem as a          between the candidate transform T′ and the target transform
set of similitude transformations. Unlike the affine method,        T is calculated using the ratio model. This calculation
the fractal method seeks these representations at a                 determines the similarity between unique pairs of
significantly finer partitioning of the images, and uses            transforms. However, the problems from the Raven's test,
features derived from these representations to determine            even in their simplest form, poses an additional concern in
similarity for each possible answer, simultaneously, across         that many such pairs may be formed.
the bulk of relationships present in the problem.                      Reconciling Multiple Analogical Relationships In 2x2
   For visual analogy problems of the form A : B :: C : ?,          Raven’s problems, there are two apparent relationships for
each of these analogy elements are a single image. Some             which analogical similarity must be calculated: the
unknown transformation T can be said to transform image A           horizontal relationship and the vertical relationship. Closer
into image B, and likewise, some unknown transformation             examination of such problems, however, reveals two
T′ transforms image C into the unknown answer                       additional relationships which must be shown to hold as
image. The central analogy in the problem may then be               well: the two diagonal relationships. Furthermore, not only
imagined as requiring that T is analogous to T′. Using              must the "forward" version of each of these relationships be
fractal representations, we shall define the most analogous         considered but also the "backward" or inverse version.
transform T′ as that which shares the largest number of             Therefore for a 2x2 Raven's problem, we must determine
fractal features with the original transform T.                     eight separate measures of similarity for each of the possible
   To find analogous transformations for A : B :: C : ?, the        candidate solutions.
fractal algorithm first visits memory to retrieve a set of             The 3x3 matrix problems from the APM introduce not
candidate solution images X to form candidate solution              only more pairs for possible relationships but also the
pairs in the form <C, X>. For each candidate pair of images,        possibility that elements or subelements within the images
we generate a fractal representation of the pairing from the        exhibit periodicity. Predictably, the number of potential
fractal encoding of the transformation of candidate image X         analogical relationships blooms. At present, we consider 48
in terms of image C. We store each transform in a memory            of these relationships concurrently.
system, indexed by and recallable via each associated fractal          Relationship Space and Maximal Similarity For each
feature.                                                            candidate solution, we consider the similarity of each
                                                                    potential analogical relationship as a value upon an axis in a
                                                                1831

                                                                                                              Set of APM
         Model             Representation                Input              Strategy
                                                                                               I (12 problems)         II (36 problems)
                                                      hand-coded
        FairRaven             propositional                                 prediction                7*                      16*
                                                      propositions
                                                      hand-coded
       BetterRaven            propositional                                 prediction                7*                      25*
                                                      propositions
          Affine                 iconic             scanned images          prediction                 7                       14
         Fractal                 iconic             scanned images      estimate / refine             12                       26
                                                                                              *out of 7 and 27 problems attempted, respectively
                 Table 1: Affine and fractal results on the APM compared with results of the Carpenter et al. (1990) model.
large “relationship space.” To specify the overall fit of a            best scores were achieved using the Tversky measure on the
candidate solution, we construct a vector in this                      quantized set, with scores 6 and 12 on sets I and II
multidimensional relationship space and determine its                  respectively.
Euclidean distance length. The candidate with the longest                 Likewise, the fractal algorithm correctly solved all 12 of
vector length is chosen as the solution to the problem.                the problems on Set I, and 26 of the 36 problems on Set II.
   The fractal method is described in more detail in                   This level of performance corresponds to the 95th percentile
McGreggor, Kunda, and Goel (2010, 2011).                               for set I, and the 75th percentile for set II, for 20- to 62-year-
                                                                       olds (Raven et al. 2003). Looking at input variations
                             Method                                    individually, the scores were 10 and 21 on each set for raw
                                                                       input, and 7 and 18 on each set for quantized input. Of the
We tested our affine and fractal models on all 48 problems             groupings used by the fractal method, the best scores were
from the Raven’s Advanced Progressive Matrices test, 12 on             achieved by considering both horizontal and vertical
Set I, and 36 on Set II. To obtain visual inputs, we scanned           groupings on raw input, at 7 and 17 on sets I and II
paper copies of each test at 200 dpi and manually corrected            respectively.
for small (+/- 3°) rotational misalignments. Thus, the input              In comparison, Carpenter et al. (1990) report results of
to the models was grayscale images in the PNG format, with             running two versions of their algorithm (FairRaven and
each image containing a single problem (matrix and answer              BetterRaven) against a subset of the APM problems. Their
choices).                                                              results, and ours, are given in Table 2. On the ones not
   The models used a semi-automated procedure to extract               attempted by Carpenter et al. (1990), our methods score 4
individual sub-images from each problem image. Each 3x3                and 5 on set I (of the 5 skipped), and 4 and 7 on set II (of the
problem contained 8 sub-images (plus one target blank) for             9 skipped), for affine and fractal respectively.
the matrix entries and 8 sub-images for the answer choices.
   The models were run against two variations of the test                                          Discussion
inputs: raw inputs and quantized inputs. For the raw inputs,
grayscale values were extracted directly from the original             We have presented two different models that use purely
PNG images, and no color correction of any kind was                    iconic visual representations and transformations to solve
performed. The raw inputs contained numerous pixel-level               many of the problems on the Raven’s Advanced Progressive
artifacts and some level of noise. For the quantized inputs,           Matrices test. Our results align strongly with evidence from
each grayscale value was rounded to be either white or                 typical human behavior suggesting that multiple cognitive
black, thus turning the inputs into pure black-and-white               factors underlie problem solving on the APM, and in
images as opposed to grayscale.                                        particular, that some of these factors appear based on visual
   In addition, each model considered multiple strategies              operations. Additionally, in so far as we know, this work is
when solving the problems. The affine method used two                  the first report of any computational model addressing the
different similarity measures (Tversky and SSD). The                   entirety of the APM test, the first in which the problems are
fractal method used three different groupings of                       attempted using purely iconic visual representations, and the
relationships (horizontal, vertical or both).                          first to tackle the test using scanned images of each test
                                                                       page, without any re-rendering or representational change of
                             Results                                   inputs from those presented to a human test-taker.
                                                                          This robust level of performance calls attention to the
Across all input variations and strategies, the affine model           visual processing substrate shared by the affine and fractal
correctly solved 7 of the 12 problems on Set I, and 14 of the          algorithms: similitude transforms as a mechanism for image
36 problems on Set II. These levels of performance                     manipulation, and the ratio model of similarity as a
generally correspond to the 25th percentile for both sets, for         mechanism for image comparison. Of course, there are
20- to 62-year-olds (US norms) (Raven et al. 2003).                    many other types of visual processing that may or may not
Looking at input variations individually, the scores were 7            be important for accounts of visual analogy, such as non-
and 10 on each set for raw input, and 6 and 12 on each set             similitude shape transformations or image convolutions,
for quantized input. Of the similarity measures used, the              which certainly bear further investigation.
                                                                   1832

  While it has been shown (Davies et al. 2008) that                       Kosslyn, S., Thompson, W., & Ganis, G. (2006). The case for
visuospatial knowledge alone may be sufficient for                          mental imagery. New York, NY: Oxford U. Press.
addressing many analogy problems, the representations used                Kunda, M., and Goel, A.K. (2008). "How Thinking in Pictures can
in that work were still propositional. In contrast, the                     explain many characteristic behaviors of autism." In
                                                                            Proceedings of the 7th IEEE International Conference on
methods described here use only visual representations. We                  Development and Learning, pp. 304-309.
believe the visual methods we have presented for solving                  Kunda, M., & Goel, A. K. (2011). Thinking in Pictures as a
the APM can be generalized to visual analogy in other                       cognitive account of autism. J. Autism and Developmental
domains, such as other standardized tests (e.g. the Miller’s                Disorders. 41(9): 1157-1177.
Geometric Analogies test), as well as to tests of visual                  Kunda, M., McGreggor, K., & Goel, A. K. (2010). Taking a look
oddity. We conjecture that these methods may provide                        (literally!) at the Raven’s intelligence test: Two visual solution
insight into general visual recognition and recall.                         strategies. In Proc. 32nd Annual Conf. Cognitive Science
Cognitively, we hold that these strategies are a reflection of              Society, pp. 1691-1696.
what Davis et al. (1993) referred to as the deep, theoretic               Lovett, A., Forbus, K., & Usher, J. (2010). A structure-mapping
manner in which representation and reasoning are                            model of Raven’s Progressive Matrices. In Proc. 32nd Annual
                                                                            Conf. Cognitive Science Society.
intertwined.                                                              Lynn, R., Allik, J., & Irwing, P. (2004). Sex differences on three
                      Acknowledgments                                       factors identified in Raven's Standard Progressive Matrices.
                                                                            Intelligence, 32(4), 411-424.
This research has been supported by NSF (RI) Grant                        Mackintosh, N., & Bennett, E. (2005). What do Raven's Matrices
#1116541, entitled "Addressing Visual Analogy Problems                      measure? An analysis in terms of sex differences. Intelligence,
on the Raven's Intelligence Test," by the ONR through a                     33(6), 663-674.
NDSEG fellowship, and by the NSF GRFP fellowship                          McGreggor, K., Kunda, M., & Goel, A. K. (2010). A fractal
program.                                                                    approach towards visual analogy. In Proc. 1st Int. Conf. Comp.
                                                                            Creativity, Lisbon, Portugal, January, 2010.
                           References                                     McGreggor, K., Kunda, M., & Goel, A.K. (2011). Fractal
                                                                            analogies: Preliminary results from the Raven's test of
Biederman, I. 1987. Recognition-by-components: A theory of                  intelligence.     In Proc. Second International Conference on
  human image understanding. Psych. Rev., 94, 115-147.                      Computational Creativity, Mexico City, April 2011.
Berker, E., & Smith, A. (1988). Diaschisis, site, time and other          Palmer, S.E. (1978). Structural aspects of visual similarity.
  factors in Raven performances of adults with focal cerebral               Memory and Cognition, 6(2), 91-97.
  lesions. Int. J. Neuroscience, 38(3-4), 267-285.                        Prabhakaran, V., Smith, J., Desmond, J., Glover, G., & Gabrieli, J.
Bölte, S., Dziobek, I., & Poustka, F. (2009). Brief report: The level       (1997). Neural substrates of fluid reasoning: An fMRI study of
  and nature of autistic intelligence revisited. J. Autism and              neocortical activation during performance of the Raven's
  Developmental Disorders, 39(4), 678-682.                                  Progressive Matrices test. Cognitive Psychology, 33(1), 43-63.
Bringsjord, S., & Schimanski, B. (2003). What is artificial               Rasmussen, D., & Eliasmith, C. (2011). A neural model of rule
  intelligence? Psychometric AI as an answer. In IJCAI (Vol. 18,            generation in inductive reasoning. Topics in Cognitive Science,
  pp. 887–893).                                                             3(1), 140-153.
Carpenter, P., Just, M., & Shell, P. (1990). What one intelligence        Raven, J., Raven, J. C., & Court, J. H. (2003). Manual for Raven's
  test measures: a theoretical account of the processing in the             Progressive Matrices and Vocabulary Scales. San Antonio, TX:
  Raven Progressive Matrices Test. Psychological Review, 97(3),             Harcourt Assessment.
  404-431.                                                                Schooler, J., & Engstler-Schooler, T. (1990). Verbal over-
Cirillo, S., & Ström, V. (2010). An anthropomorphic solver for              shadowing of visual memories: Some things are better left
  Raven’s Progressive Matrices (No. 2010:096). Goteborg,                    unsaid. Cognitive Psychology, 22(1), 36-71.
  Sweden: Chalmers University of Technology.                              Schooler, J., Ohlsson, S., & Brooks, K. (1993). Thoughts beyond
Davies, J., Goel, A., & Yaner. P. (2008). Proteus: A theory of visual       words: When language overshadows insight. J. Experimental
  analogies in problem solving. Knowledge-Based Systems, 21(7),             Psychology: General, 122(2), 166-183.
  636-654.                                                                Snow, R., Kyllonen, P., & Marshalek, B. (1984). The topography
Davis, R. Shrobe H., and Szolovits, P. 1993. What is a Knowledge            of ability and learning correlations. Advances in the Psychology
  Representation? AI Magazine 14.1:17-33.                                   of Human Intelligence, 2, 47-103.
Dawson, M., Soulières, I., Gernsbacher, M. A., & Mottron, L.              Soulières, I., Dawson, M., Samson, F., Barbeau, E., Sahyoun, C.,
  (2007). The level and nature of autistic intelligence.                    Strangman, G., et al. (2009). Enhanced visual processing
  Psychological Science, 18(8), 657-662.                                    contributes to matrix reasoning in autism. Human Brain
DeShon, R., Chan, D., & Weissbein, D. (1995). Verbal                        Mapping. 30(12), 4082-107
  overshadowing effects on Raven's Advanced Progressive                   Tversky, A. (1977). Features of similarity. Psychological Review,
  Matrices: Evidence for multidimensional performance                       84(4), 327-352.
  determinants. Intelligence, 21(2), 135-155.                             van der Ven, A. & Ellis, J. (2000). A Rasch analysis of Raven’s
Dillon, R., Pohlmann, J., & Lohman, D. (1981). A factor analysis            standard progressive matrices. Personality and Individual
  of Raven's Advanced Progressive Matrices freed of difficulty              Differences, 29(1), 45-64.
  factors. Educational and Psychological Measurement, 41, 1295–           Vigneau, F., & Bors, D. (2008). The quest for item types based on
  1302.                                                                     information processing: An analysis of Raven's Advanced
Gentner, D. 1983. Structure-mapping: A theoretical framework for            Progressive Matrices, with a consideration of gender
  analogy. Cognitive Science 7(2), 155-170.                                 differences. Intelligence, 36(6), 702-710.
Hunt, E. (1974). Quote the raven? Nevermore! In L. W. Gregg               Villardita, C. (1985). Raven's Colored Progressive Matrices and
  (Ed.), Knowledge and Cognition (pp. 129–158). Hillsdale, NJ:              intellectual impairment in patients with focal brain damage.
  Erlbaum.                                                                  Cortex, 21(4), 627-634.
                                                                      1833

