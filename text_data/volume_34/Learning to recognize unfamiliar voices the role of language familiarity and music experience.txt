UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning to recognize unfamiliar voices: the role of language familiarity and music
experience
Permalink
https://escholarship.org/uc/item/6nf866c7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Bregman, Micah
Creel, Sarah
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                      University of California

                                      Learning to recognize unfamiliar voices:
                           the role of language familiarity and music experience
                                        Micah R. Bregman (mbregman@cogsci.ucsd.edu)
                            Department of Cognitive Science, UC San Diego, 9500 Gilman Dr. M/S 0515
                                                         La Jolla, CA 92093 USA
                                               Sarah C. Creel (creel@cogsci.ucsd.edu)
                            Department of Cognitive Science, UC San Diego, 9500 Gilman Dr. M/S 0515
                                                         La Jolla, CA 92093 USA
                              Abstract                                  neuroimaging results support this perspective, e.g. Belin,
   Speech not only transmits semantic information through
                                                                        Fecteau, & Bédard, 2004), several studies suggest that
   words and syntax, but also provides cues to a talker’s identity.     talker-specific acoustic cues are intertwined with speech
   Differences in a listener’s ability to recognize voices can be       recognition. For example, listeners are better able to
   attributed to their language background, and in rare cases           understand speech from familiar talkers than unfamiliar
   voice recognition can be selectively damaged in neurological         ones (Nygaard & Pisoni, 1998).
   patients. In this study we investigated a group of Korean-              While several studies have characterized severe disability
   English bilinguals and non-Korean speakers’ ability to learn         in voice identification, few have attempted to investigate
   to recognize unfamiliar Korean and English talkers by voice,
   and to generalize to utterances not heard during training. We        differences among individuals’ abilities to recognize voices,
   observed an interaction between language background and              although the existence of dramatic individual differences
   stimulus language for speed of learning, however                     has been noted for many years (Pollack, Pickett, & Sumby,
   generalization performance indicated no such interaction             1954). In clinical cases, voice recognition can be lost
   when compared to baseline performance. Bilinguals’                   completely in individuals with a neuropsychological
   performance recognizing English (but not Korean) voices,             disorder known as phonagnosia (Van Lancker, Kreiman, &
   was predicted by the age they learned English. We also
                                                                        Cummings, 1989). In a pioneering study, Goggin,
   observed that individuals who actively participated in music
   production exhibited significantly faster task learning than         Thompson, Strube, & Simental (1991) demonstrated that
   those who did not produce music. This study indicates that           monolingual English speakers were better able to identify
   language background has a gradient effect on voice learning          the voices of English-German bilinguals when listening to
   among bilinguals, and that non-linguistic auditory processing        those individuals speak English than when they spoke
   differences, such as music perception, impact voice                  German. This suggested that, despite many shared acoustic
   identification.                                                      features (both English and German stimuli shared the
   Keywords: speech perception; music perception; voice; voice          acoustic features imparted by a particular talker’s vocal
   identification; individual differences; bilingualism                 tract), the listener’s language background had a strong
                                                                        impact on their ability to recognize the voices. This study
                          Introduction                                  suggested that differences in phonological processing that
   Speech is generally studied primarily for its ability to             arise from linguistic knowledge are important in voice
communicate semantic meaning from one individual to                     recognition.
another. Many complex animal communication systems                         Goggin et al. (1991) observed no difference in
such as birdsong, however, evolved primarily to                         performance on a voice recognition task for English-Spanish
communicate more basic information, providing cues that                 bilinguals when tested on English vs. Spanish speaking
other conspecific listeners use to evaluate fitness and                 voices. They suggested that bilinguals might have equal
individual identity. Any comprehensive understanding of                 ability recognizing voices from either language since they
the evolutionary origins of speech and language will draw               have extensive phonological knowledge of both. Bilinguals,
both upon the role communication signals play in                        however, are heterogeneous in their language background,
transmitting semantic meaning, as well as their role in                 and it may be the case that late learners, or those dominant
providing cues to identity.                                             in one of their languages do exhibit the voice identification
   Human speech contains many acoustic cues that listeners              deficits identified in monolinguals.
use to recognize, for example, a talker’s age, gender,                     A recent study demonstrated that differences in
emotional state, or even their identity. Collectively, these            phonological processing within a language can also affect
elements of the speech signal are known as “indexical                   voice identification. Individuals with dyslexia are
cues”. Voice recognition, or talker identification, is an               significantly impaired in their ability to recognize voices
important aspect of speech perception, and one that has been            relative to controls, but only in their native language
relatively little studied. Although often considered separate           (Perrachione, Del Tufo, & Gabrieli, 2011). This result
from the core speech perception system (some                            implies that individual differences in phonological
                                                                    144

processing, even among those who share a language                  Procedure
background, can dramatically impact listeners’ abilities to           Voice Learning Task Participants learned to associate 20
recognize voices.                                                  training stimuli (5 sentences x 4 voices) with one of four
   Outside clinical populations, what other differences might      cartoon objects, which differed in both shape and color.
affect voice recognition accuracy? One possibility is music        Each cartoon object represented a single talker. We chose
experience. Extensive musical training may benefit the             cartoon objects rather than faces to control for differences in
neural encoding of speech by driving brain networks                face discriminability across participants. To initiate a trial,
involved in both speech and music perception to function           participants clicked a cross in the center of the screen. On
with higher precision than normally necessary for speech           each trial, audio playback began simultaneously with the
perception alone (Patel, 2011). In fact, musicians have been       display of the two cartoon objects, one on the left and one
demonstrated to outperform non-musicians on speech                 on the right, equidistant from the center cross. During each
perception tasks, including enhanced perception of speech          training trial, participants clicked one of the two objects
in noise (Parbery-Clark, Skoe, Lam, & Kraus, 2009) as well         with the computer mouse and after clicking, the correct
as enhanced second language phonological ability in                object remained on the screen to provide feedback until they
bilinguals (Slevc & Miyake, 2006). Do differences in music         made a second confirmation click.
background or music perception affect voice recognition               Training blocks of 60 trials each were presented (with
ability?                                                           stimuli randomized within each block) until participants
   In this study, we investigated these questions in a group       reached 85% correct—that is, they chose the target object
of Korean-English bilinguals and a second group of non-            on at least 51 of 60 trials in a single block (chance=50%).
Korean speakers. We examined whether differences in                After reaching criterion, participants completed two test
language and music background, as well as individual               blocks, each with 120 trials. During test blocks, no feedback
differences in music perception and phonological working           was provided and the screen was blank after making a
memory, affected participants’ abilities to learn to recognize     response. Test blocks contained 60 trials encompassing the
a set of unfamiliar voices. We also tested recognition of          20 training stimuli, as well as 60 trials containing 5 novel
novel sentences spoken by these voices.                            sentences produced by the 4 learned voices. The second test
                                                                   block contained 60 trials of the 20 stimuli learned during
                          Methods                                  training and an additional 5 novel sentences. After
                                                                   completing the training and testing process for one
Participants                                                       language, participants completed the process in the other
   We tested 48 participants, 22 of whom were bilingual,           language (English or Korean). The language of the first
and spoke Korean and English fluently. The remaining 26            block (Korean or English), the cartoon objects associated
participants had no background or experience with Korean.          with each voice, and the positions of the two images on the
All Korean-English bilingual participants learned Korean as        screen on each trial were counterbalanced across subjects.
their first language or in parallel with English, and learned         Behavioral assessments In addition to completing the
English between 1-17 years of age (mean=7.1 years). All            voice learning task, participants completed assessments to
subjects studied at UC San Diego and received course credit        identify individual differences in language and music
for participation. All procedures were part of a protocol          background and perception. They completed a questionnaire
approved by the UC San Diego Human Research                        describing their music training, including formal training
Protections Program.                                               and current performance activity. To assess their dominant
                                                                   language, bilingual subjects completed a bilingual
Stimuli                                                            dominance survey (BDS; Dunn & Fox Tree, 2009) and a
   We recorded 15 Korean sentences spoken by each of four          picture naming task assessing lexical inventory in English
female native Korean speakers and 15 English sentences             and Korean (modified from Gollan, Weissberger,
spoken by four female native American English speakers.            Runnqvist, Montoya, & Cera, 2011). All participants
English sentences were selected from the SPIN sentence set.        completed the pitch contour subtest from the Montreal
All chosen sentences were high predictability, e.g. “He            Battery for the Evaluation of Amusia (MBEA) to measure
caught the fish in his net” (Kalikow, Stevens, & Elliott,          differences in music perception ability (Peretz, Champod, &
1977). Korean sentences were simple, high predictability,          Hyde, 2003). During the MBEA test, participants heard 2
and of similar syllabic length to the English sentences,           example melody pairs followed by 31 test melody pairs. For
written by a native Korean speaker, e.g. “공책을	 집에	 놓고	             each pair, they provided a same/different judgment. All
                                                                   melody pairs had the same melodic contour and there were
왔다” (“Gongchek eul jibeh nohgo watda,” “I left the                 no out-of-key notes, making it a fairly subtle change. Each
notebook at home”). Recordings were made in a sound                participant’s score was recorded as the number of correct
isolated recording booth, and each monaural recording was          responses (observed range = 12-30, mean = 23.5).
trimmed to begin at sentence onset and normalized to a                For the Korean-English bilingual participants, language
mean of 70dB.                                                      dominance measured using the BDS ranged from -15
                                                                   (English dominant) to 20 (Korean dominant) and averaged -
                                                               145

0.22. Performance on the lexical naming task ranged from -            between language background and stimulus language
27 to 18, with a mean of -9.48. These bilingual dominance             (Figure 2a) in the maximum accuracy reached. A 2-way
measures were highly correlated (r=0.78), and both BDS                mixed ANOVA indicates no main effects of language
and MiNT scores were highly correlated with the age                   background (F(1, 46)=2.08, p=0.16) or stimulus language
English was learned (r=0.92 and r=0.75, respectively).                (F(1, 46)=1.11, p=0.30), but a strong interaction (F(1,
  Phonological working memory was estimated by                        46)=15.51, p=0.0003).
measuring each participant’s digit span. Digit span has been
                                                                                                     6
used as an index of phonological working memory in many                                                  Stimulus Language
                                                                         Number of Training Blocks
experiments (Baddeley & Hitch, 1977). Participants heard a                                                 English
                                                                                                     5
series of 16 audio recordings with a female voice reading                                                  Korean
random sequences of English digits at a rate of 1 digit per
second. Two sequences for each length were presented, in                                             4
order, from 2-9 digits. After each recording, participants
repeated the numbers they had heard. Scores were recorded                                            3
as the number of sequences correctly repeated, with a
maximum score of 16 (observed range = 7-15, mean =                                                   2
10.7). Digit spans did not differ between language groups
(Welch’s t(45.95)=0.83, p=0.41).                                                                     1
                         Results                                                                     0
                                                                                                          Korean/English        English only
Language familiarity predicts learning speed                                                                       Language Background
   Previous research suggests that familiarity with a
language is predictive of performance on voice                        Figure 1: Korean-English bilinguals required fewer training
identification tasks. However, its role predicting learning           blocks to reach 85% correct recognizing Korean speaking
rate for unfamiliar voices has not been explicitly tested. We         voices (red bars) than English speaking voices (blue bars).
contrasted 22 Korean-English bilinguals with 26 listeners             Non-Korean speakers show the opposite effect. Bars
who did not speak Korean. We measured the number of                   indicate mean number of training blocks ± s.e.
blocks required to reach a criterion of 85% correct within a
single block. A 3-way mixed model ANOVA (Figure 1)                       However, we observed no difference in performance
with Participant Language (English-only, Korean-English;              between training and generalization test trials in the 40
between-participants), Talker Language (English, Korean;              participants who reached 85% correct after a maximum of 9
within-participants) and block order (English first vs.               training blocks. For each of these participants, we calculated
Korean first; between-participants) revealed no significant           a “generalization penalty” by subtracting the proportion of
main effects of participant language background (F(1,                 correct responses to novel tokens of learned talkers with the
44)=3.19, p=0.08), stimulus language (F(1, 44)=0.44,                  proportion of correct responses to trained talkers. All stimuli
p=0.51), or block order (F(1, 44)=1.09, p=0.30). However,             were interleaved and collected in the same test block. We
there was a strong interaction between stimulus language              computed a 2-way mixed model ANOVA predicting
and language background (F(1, 44)=24.02, p<0.0001).                   participant’s generalization penalty using language
   Individually, Korean-English bilingual participants were           background (between participants) and stimulus language
faster to learn Korean talkers (M=1.9 training blocks) than           (within participants) as factors (Figure 2b). We observed no
English talkers (M=3.5 blocks; paired t-test t(21)=-3.03,             main effect of language background (Korean-English vs.
p=0.006). Similarly, English-speaking participants learned            English-only; between participants, F(1, 39)=2.45, p=0.13),
English voices (M=2.5 blocks) faster than Korean voices               no main effect of stimulus language (within participants,
(M=4.5 blocks; paired t-test t(25)=4.14, p=0.0003). No other          F(1, 39)=1.72, p=0.20) and no interaction between language
interactions were statistically significant (all Fs<0.08,             background and stimulus language (F(1, 39)=0.17, p=0.68).
ps>0.78). Together, these data show that differences in               While language background appears to be important for
learning rates are present as a function of language                  learning to distinguish unfamiliar voices, it does not appear
background.                                                           to constrain generalizing to new utterances after the voices
   We then looked at participants’ maximum accuracy on                have been learned, at least within the short retention period
training trials. Although trained to reach a criterion of 85%         required in this experiment.
correct in a block, some participants achieved higher
accuracy then others. Again we observed an interaction
                                                                146

               a.                                                                           b.
                                            1.0                                                                                        0.15
    Performance reached during training                                                      Generalization penalty (prop. correct)
                                                                                                                                                Stimulus Language
                                                                                                                                                  English
                                                                                                                                       0.12
                                            0.8                                                                                                   Korean
                                                                                                                                       0.09
                                            0.6
                                                                                                                                       0.06
                                            0.4
                                                                                                                                       0.03
                                            0.2
                                                                                                                                       0.00
                                            0.00                                                                                      -0.03
                                                       Korean/English        English only                                                            Korean/English            English only
Figure 2: (a) Korean-English bilinguals were slightly more accurate at identifying the correct voice on novel sentences for
Korean stimuli (red bars) than for English stimuli (blue bars). Non-Korean speakers show the opposite effect. (b) There
were no generalization differences between groups
                                                                                                                                      those who learned English at or before 5 years old (early
                                                                                                                                      learners, n=12, mean age=3.3 years, mean BDS=-7.8, mean
Bilinguals’ age of L2 acquisition predicts learning                                                                                   MiNT=-15.6) and those who learned after 5 years old (late
speed in L2, but not L1.                                                                                                              learners, n=10, mean age=10.7 years, mean BDS=6.9, mean
   We further explored whether individual differences in age                                                                          MiNT=-4.3). We then conducted a 2-way mixed model
of learning English or relative dominance of English or                                                                               ANOVA with factors of Participant Language (between
Korean were predictive of task performance among the                                                                                  participants; English-only, early-English Bilingual, late-
bilingual subjects. To do so, we computed the correlation                                                                             English Bilingual) and Talker Language (within
between age of English onset (which was the second                                                                                    participants). There was a main effect of language
language for all bilingual participants) with their voice                                                                             background (F(2, 45)=4.73, p=0.014), no main effect of
learning rate. Among Korean-English bilinguals, blocks to                                                                             stimulus language (F(1, 45)=1.31, p=0.26) and an
criterion on English talkers was positively correlated with                                                                           interaction between language background and stimulus
the age they began learning English (Figure 3a, r(20)=0.62,                                                                           language (F(2, 45)=15.91, p<0.0001). This interaction
p=0.002), while it is uncorrelated for Korean-language                                                                                resulted from three different patterns of talker learning.
stimuli (r(20)=0.24, p=0.28).                                                                                                         Early-learning bilinguals did not differ in their acquisition
   We then separated Korean-English bilingual participants                                                                            rate for Korean and English stimuli (paired t(11)=-1.74,
into two groups based on a median split of acquisition age:                                                                           p=0.11). However, late-English-learning bilinguals learned
 a.                                                                                         b. 6
                                                                                                                                                         Stimulus Language
     Blocks to learn English (bilinguals)
                                            10                                                                                                             English
                                                                                             Number of Training Blocks
                                                                                                                                      5                    Korean
                                             8
                                                                                                                                      4
                                             6
                                                                                                                                      3
                                             4
                                                                                                                                      2
                                             2
                                             0                                                                                        1
                                                   0         5          10          15
                                                          Age learned English                                                         0
                                                                                                                                              Bilingual             Bilingual,      English only
                                                                                                                                              late learner          early learner
Figure 3: (a) The number of blocks to learn English voices was correlated (r=0.62, p=0.002) with the age Korean-English
bilinguals learned English. (b) Number of training blocks to reach criterion of 85% on each stimulus language for Korean-
English bilinguals who learned English late (n=10), early (n=12) and English-only speakers (n=26). Each bar represents the
mean number of training blocks (60 trials/block) ± s.e.
                                                                                            147

Korean stimuli faster than English stimuli (paired t(9)=-         when the experiment was conducted (n=11; musical training
2.87, p=0.018), and, as reported above, non-Korean                averaged 12.0 years, range 6-22 years) learned to recognize
speakers learned English stimuli faster than Korean stimuli.      voices on average in fewer training blocks than those who
   Taken together, these results are consistent with prior        were not active musicians (n=37; who had less musical
work suggesting that phonological processing is an                training, averaging 5.2 years, range 0-27; Welch’s
important element of voice recognition. Our result extends        t(34.23)=-2.52, p=0.017). This difference seems to have
previous work by demonstrating a gradient effect of               been driven by musicians’ more rapid learning for voices
bilingualism. Rather than showing similar patterns of             speaking the subject’s non-dominant language. When tested
behavior in both languages, age of acquisition is an              on the non-dominant language (Korean for non-Korean
important predictor of performance recognizing voices in          speakers, English for Korean-English bilinguals), musicians
L2, but not L1.                                                   learned faster than non-musicians (mean=2.71 blocks vs.
                                                                  4.62 blocks, Welch’s t(44.28)=-3.07, p=0.004). However,
Music experience predicts learning rate                           when learning to recognize voices in their dominant
    We collected several behavioral measures of individual        language, we observed no effect of music background
differences in auditory perception from our participants (see     (mean=2.00 blocks for musicians vs. 2.40 blocks for non-
methods). Our hypothesis was that, since differences in           musicians, Welch’s t(17.02)=-0.59, p=0.56).
individuals’ language profiles (e.g. language familiarity,           As there are multiple ways of assessing music experience,
dyslexia) contribute to differences in voice learning, we         we also considered the effect of years of musical training
might also observe differences among participants due to          (this did not overlap completely with current musical
individual differences in auditory processing that are not        practice). Years of training correlated negatively with
strictly linguistic: pitch perception, music background, and      average number of training blocks to reach criterion
music perception ability. We report the correlations between      (r(46)=-0.42, p=0.0036). Again, the relationship to music
each of these measures and three performance measures:            training is driven by the non-dominant language (r(46)=-
learning rate, generalization performance, and pitch shifted      0.40, p=0.006); musical training was not significantly
generalization performance (Table 1).                             correlated with learning rate for voices in the dominant
   Several previous studies have identified perceptual            language (r(46)=-0.22, p=0.13).
advantages for individuals with extensive musical training.
In particular, musicians have shown better brainstem                                        Discussion
encoding of pitch (Wong, Skoe, Russo, Dees, & Kraus,                 Previous studies demonstrated that individual differences
2007), and high musical ability is associated with better         in phonological processing due to language background and
second language phonology (Slevc & Miyake, 2006). Is              dyslexia are important predictors of voice identification
musical experience important for learning to recognize            ability. The results of the current study extend these findings
voices?                                                           in a few important respects. In both adults and infants,
                                                                  knowledge of a language improves ability to recognize
   Table 1. Correlations between music measures and voice         voices in that language (Goggin et al., 1991; Johnson,
recognition                                                       Westrek, Nazzi & Cutler, 2011; Perrachione et al., 2011).
                                           Generalization         We extended this work by investigating both monolinguals
                                  Learning                        and bilinguals, and looking at the bilingual participant’s
            Years MBEA Tone         rate                          language dominance. Not only did we find a crossover
           Training Score Thres. (blocks) Unshifted Shifted       interaction between listeners’ native-language backgrounds
  Years                                                           and talkers’ language, but we also found that early second-
 Training 1.000    0.10   -0.02  -0.42      0.029      -0.095     language acquisition facilitated talker learning without loss
 MBEA                                                             in performance on the first language. This acquisition
  Score            1.000 -0.26   -0.19      -0.048     -0.199
                                                                  effect—if viewed as such—is particularly interesting
   Tone
  Thres.                  1.000  0.13       0.101      0.208      because it mimics acquisition of phonology: as age of
Learning                                                          acquisition increases, receptive and productive phonology
   rate                          1.000      -0.202     0.246      are less native-like (Flege et al., 2006; Oh et al., 2011).
                                                                     We also observed significantly faster voice learning for
                                                                  participants with more extensive musical training,
   We measured musical perceptual ability with the melody         particularly those actively involved in music production.
contour subtest of the MBEA (Peretz, Champod, & Hyde,             This could be associated with changes in auditory encoding
2003), and a pitch discrimination threshold task. Pitch           that have been observed among musicians that give rise to
difference threshold and MBEA did not correlate                   differences in pitch, music and speech perception. Our result
significantly with voice learning or generalization ability.      extends this area of research, suggesting that not only is
However, measures of musical activity did show a                  speech comprehension enhanced, but perception of
relationship to voice learning rate. Participants who were        indexical features in the speech signal may be enhanced as
currently active in producing music at least 1 hour per week      well. The effect of music experience appeared only to apply
                                                              148

to participants’ learning to recognize voices in a less            Spanish–English bilinguals. Bilingualism: Language and
familiar language. We point out, however, that this study          Cognition, 1-22.
does not actually manipulate music training, so we cannot            Johnson, E. K., Westrek, E., Nazzi, T., & Cutler, A.
assert that it causes improvement in learning to recognize         (2011). Infant ability to tell voices apart rests on language
voices. Perhaps some third variable—inherent or learned            experience. Developmental Science, 14, 1002-1011.
individual differences in auditory perception—confers                Kalikow, D., Stevens, K. N., & Elliott, L. (1977).
benefits to both voice recognition and music production.           Development of a test of speech intelligibility in noise using
   Further work is also needed to identify whether the kinds       sentence materials with controlled word predictability. The
of individual differences that give rise to enhanced voice         Journal of the Acoustical Society of America, 61(5), 1337.
recognition also extend to other indexical cues. Are                 Nygaard, L. C., & Pisoni, D. B. (1998). Talker-specific
individuals who performed better on individual recognition         learning in speech perception. Perception & psychophysics,
tasks also more sensitive to acoustic cues such as a talker’s      60(3), 355-76.
emotional state, age, or gender?                                     Oh, G. E., Guion-Anderson, S., Aoyama, K., Flege, J. E.,
   We explored how language experience and non-linguistic          Akahane-Yamada, R., & Yamada, T. (2011). A one-year
factors contributed to talker identification in two different      longitudinal study of English and Japanese vowel
languages. Native-language talkers were learned faster than        production by Japanese adults and children in an English-
second-language or unfamiliar-language talkers, and among          speaking setting. Journal of Phonetics, 39(2), 156-157. d
bilinguals, earlier L2 acquisition predicted faster learning.        Parbery-Clark, A., Skoe, E., Lam, C., & Kraus, N. (2009).
Further, some measures of music experience predicted faster        Musician enhancement for speech-in-noise. Ear and
learning in the less-familiar language. Our work suggests a        hearing, 30(6), 653-61.
role for early language learning, or at least extent of              Patel, A. D. (2011). Why would Musical Training Benefit
exposure, in talker identification. This is consistent with a      the Neural Encoding of Speech? The OPERA Hypothesis.
tight linkage between language processing and talker               Frontiers in psychology, 2, 142.
identification, which presents an interesting puzzle given the       Peretz, I., Champod, A. S., & Hyde, K. (2003). Varieties
evidence of specialized neural mechanisms for speech               of Musical Disorders The Montreal Battery of Evaluation of
recognition and talker identification.                             Amusia. Annals of the New York Academy of Science, 999,
                                                                   58-75.
                    Acknowledgements                                 Perrachione, T. K., Del Tufo, S. N., & Gabrieli, J. D. E.
   MRB was supported by the Kavli Institute for Brain and          (2011). Human voice recognition depends on language
Mind at UC San Diego, and SCC was supported by an NSF              ability. Science (New York, N.Y.), 333(6042), 595.
CAREER Award (BCS-1057080). We would like to                         Pollack, I., Pickett, J., & Sumby, W. (1954). On the
acknowledge the help of undergraduate research assistants          identification of speakers by voice. Journal of the
Shawn Cho and Hye Young Lee who were instrumental in               Acoustical Society of America, 26(3), 403–406.
developing Korean language stimuli and collecting data on            Slevc, L. R., & Miyake, A. (2006). Individual differences
participant’s language background.                                 in second language proficiency: Does musical ability
                                                                   matter? Psychological Science, 17(8), 675–681.
                        References                                   Van Lancker, D. R., Kreiman, J., & Cummings, J. (1989).
                                                                   Voice perception deficits: neuroanatomical correlates of
   Baddeley, A. D., & Hitch, G. J. (1977). Working                 phonagnosia. Journal of clinical and experimental
Memory. The psychology of learning and motivation:                 neuropsychology, 11(5), 665-74.
advances in research and theory.                                     Wong, P. C. M., Skoe, E., Russo, N. M., Dees, T., &
   Belin, P., Fecteau, S., & Bédard, C. (2004). Thinking the       Kraus, N. (2007). Musical experience shapes human
voice: neural correlates of voice perception. Trends in            brainstem encoding of linguistic pitch patterns. Nature
cognitive sciences, 8(3), 129-35.                                  Neuroscience, 10(4), 420-2.
   Dunn, A. L., & Fox Tree, J. E. (2009). A quick, gradient
Bilingual Dominance Scale. Bilingualism: Language and
Cognition, 12(03), 27-
   Flege, J. E., Birdsong, D., Bialystok, E., Mack, M., Sung,
H., & Tsukada, K. (2006). Degree of foreign accent in
English sentences produced by Korean children and adults.
Journal of Phonetics, 34(2), 153-175.
   Goggin, J. P., Thompson, C. P., Strube, G., & Simental,
L. R. (1991). The role of language familiarity in voice
identification. Memory & cognition, 19(5), 448-58.
   Gollan, T. H., Weissberger, G. H., Runnqvist, E.,
Montoya, R. I., & Cera, C. M. (2011). Self-ratings of
spoken language dominance: A Multilingual Naming Test
(MINT) and preliminary norms for young and aging
                                                               149

