UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Does the utility of information influence sampling behavior?
Permalink
https://escholarship.org/uc/item/0fz3d3mw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Markant, Doug
Gureckis, Todd
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

                       Does the utility of information in uence sampling behavior?
                                                Doug Markant (doug.markant@nyu.edu)
                                               Todd M. Gureckis (todd.gureckis@nyu.edu)
                                                              New York University
                                                           Department of Psychology
                                                6 Washington Place, New York, NY 10003 USA
                                Abstract                                  reasoning task where the predictions of these measures could
    A critical aspect of human cognition is the ability to actively
                                                                          be readily distinguished. Learners who could query diﬀerent
    query the environment for information. One important (but             stimulus features before making classi cation decisions were
    oen overlooked) factor in the decision to gather information is      found to prefer to learn about features that maximized prob-
    the cost associated with accessing diﬀerent sources of informa-       ability gain, a measure of how well a potential observation is
    tion. Using a simple sequential information search task, we ex-
    plore the degree to which human learners are sensitive to vari-       expected to improve classi cation accuracy.
    ations in the amount of utility related to diﬀerent potential ob-         In these studies, however, costs were not explicitly manip-
    servations. Across two experiments we nd greater support for
    the idea that people gather information to reduce their uncer-        ulated or controlled. Taking costs into account can alter the
    tainty about the current state of the environment (a “disinter-       optimal strategy in a given task, but it is unclear whether peo-
    ested”, or cost-insenstive, sampling strategy). Implications for      ple adjust their behavior in a similar way. e goal of the
    theories of rational information collection are discussed.
    Keywords: information sampling, active learning, information          present paper is to explore the impact of costs on sampling de-
    access costs                                                          cisions. We begin by evaluating two alternative objectives that
                                                                          people may adopt when deciding what information to gather.
                            Introduction                                  Like the models reviewed by Nelson (2005), the rst ignores
From controlling the movement of our eyes to determining                  the implications of task-speci c costs and casts information
which sources of news to consult, judging the quality of al-              sampling strictly in terms of uncertainty reduction (i.e., in-
ternative sources of information is a critical part of adaptive           formation gain). e second approach balances the costs and
behavior. Research exploring how people make information                  expected bene ts of information in the context of the task.
gathering (or “sampling”) decisions has shown that people can             We then describe the results of two experiments that manip-
discern subtle diﬀerences in the potential information value              ulate the concordance between these two approaches, in one
of various aspects of the environment. For example, measure-              case creating an environment where the goals of minimizing
ments of eye movements during object categorization show                  uncertainty and maximizing utility predict diﬀerent patterns
that people preferentially allocate attention to object features          of information sampling. Our results show that people tend
that are most useful for making subsequent classi cation deci-            to value information (in terms of the number of hypotheses
sions (c.f., Nelson & Cottrell, 2007; Rehder & Hoﬀman, 2005).             ruled out by a new observation) over situation-speci c costs
    One aspect that typically complicates the analysis of infor-          and bene ts. e implications of these results for theories of
mation sampling behavior is that information rarely comes for             information sampling are discussed.
free. All natural tasks involve information access costs, even
if the only cost is the time required to gather information (Fu,          e rational analysis of information sampling:
2011). In addition, diﬀerent pieces of information may be                 comparing “interested” and “disinterested” search
more useful depending on how one will be tested in the fu-
ture. Optimal search behavior must weigh the costs of collect-            How should a rational agent make information sampling deci-
ing particular bits of information against the bene t it is ex-           sions? Existing proposals fall into two broad categories which,
pected to convey (Edwards, 1965; Juni, Gureckis, & Maloney,               borrowing from Chater, Crocker, and Pickering (1998), we
2011; Tversky & Edwards, 1966), a point frequently made in                call “interested” and “disinterested.” Unlike the distinctions
research on animal foraging (Stephens & Krebs, 1986).                     explored by Nelson (2005), these two proposals diﬀer signi -
    Despite its importance, previous work on information sam-             cantly in terms of the overall goal of information sampling.
pling has oen failed to test whether people take into account            Interested (or cost sensitive) sampling e rst approach
costs related to diﬀerent sources of information. For exam-               represents a decision-theoretic approach to information sam-
ple, Nelson (2005) provides a comprehensive review of various             pling. In particular, the agent considers the cost for collecting
ways an optimal Bayesian agent might value potential infor-               a piece of evidence and weighs this against the expected bene t
mation sources in the absence of task-speci c costs (see also             it should convey with respect to the goals of the task. For ex-
Nelson et al., 2010). One conclusion from this line of work is            ample, a car shopper might decide if the possible savings avail-
that people make information search decisions that are con-               able from obtaining information contained in a vehicle history
sistent with normative measures of information value (many                report is worth the cost of the report. Similarly, preferentially
of which oen make similar predictions). For example, Nel-                  xating the features of an object that are diagnostic of its cat-
son et al. (2010) studied information sampling in a diagnostic            egory membership may be a cost-sensitive strategy under the
                                                                      719

assumption that additional xations cost time and the num-              Experiment 1: Rectangle Search
ber of xations needed to reach a correct decision should be                     Possible Shapes                            Hidden Gameboard
minimized. Sampling in this case is “interested” in that infor-
mation acquisition is focused on some purpose or goal beside
                                                                                                     random samples
acquiring the information itself. In many ways, “interested”
sampling is a fully rational strategy and this formulation is of-
ten adopted in economics research.
Disinterested (or cost insensitive) sampling e second ap-
proach values information to the degree that it reduces our
uncertainty about the world. Chater et al. liken this to ba-          Figure 1: e generative process underlying the shape search game.
sic research where the goal is learning without regard for            A xed set of possible shapes is speci ed. A hidden gameboard is
the ultimate utility of this knowledge for society. In their          created by sampling from this set of shapes and randomly arranging
                                                                      the targets in the grid. During the sampling phase the participants
words, “inquiry is valuable for its own sake, because it leads        clicks on grid locations to reveal their contents. In the painting phase,
to knowledge” (Chater et al., p.4). Disinterested inquiry can         the subject draws in the remaining squares using the mouse and is
be conveniently expressed as actions which have a high prob-          rewarded for accuracy.
ability of reducing the Shannon entropy over the agent’s be-
liefs (Lindley, 1956; Mackay, 1992). Critically, disinterested
inquiry doesn’t depend on the costs associated with collect-          than observations. e goal of the game is to nish with the
ing information or using it to make subsequent decisions.             lowest score possible, which is achieved by learning the most
    e basic premise of the experiments reported in this paper        about the hidden shapes in the fewest number of observations.
is that these two strategies or ways of valuing information can          Based on past work with this task (Gureckis & Markant,
be dissociated on the basis of observed choice behavior. We           2009), we have found that the overall objective of the game
gave participants a simple, intuitive information search task         is easily understood by the participants. A critical feature of
where they were asked to make sequences of decisions to re-           the task (which we exploit in our second experiment) is that
duce their uncertainty about a hidden target. Mathematical            it allows for arbitrarily de ned targets (i.e., the target shapes
models instantiating each of the two theories just described          may be composed of any con guration of squares) that can be
are then t to the choice patterns of individual subjects. is         manipulated to vary the complexity of the task.
  tting procedure (common in the reinforcement learning lit-
erature) allows us to evaluate which of the approaches we have        Formal task analysis
described gives the best account of participants’ choices.            In order to evaluate both “interested” and “disinterested” in-
                                                                      formation search in the task, we compare the search behav-
e Experimental Task: e Shape Search Game
                                                                      ior of subjects to that of a rational learner who updates their
Participants in our task are presented with a  by  grid that      beliefs about the gameboard in an optimal way. Formally,
contains non-overlapping hidden shapes made up of individ-            players make a sequence of observations in order to learn the
ual grid cells. e hidden targets are randomly drawn from             hidden gameboard, gh ∈ G, where G is the universe of legal
a set that is known to the participant. ere are two phases           gameboards. Each individual gameboard is de ned by an ar-
in each game: a sampling phase and a painting phase. In the           rangement of N non-overlapping shapes {r1 , r2 , ..., rN } with
sampling phase, the player learns about the form and location         unique labels {l1 , l2 , ..., lN }, and each shape consists of a set
of the hidden shapes by choosing squares in the grid to un-           of squares such that oij ∈ rn (where i and j index the x- and
cover. On each trial, they make an observation at one location,       y-coordinates of the square).
revealing either part of a hidden shape or an empty square.              On each trial the player makes an observation oij and re-
When they think they know the location and form of all the            ceives feedback in the form of a label ln , where l0 indicates the
shapes they can stop sampling and enter the painting phase.           observed square is empty, l1 means it contains part of shape
In the painting phase, the player is tested for their knowledge       r1 , and so on. Since each square in the grid is deterministi-
of the shapes by “painting” any remaining squares they believe        cally assigned to either one or zero shapes, we assume that the
belong to one of the shapes in the appropriate color.                 likelihood of a particular observation oij belonging to one of
    e player is penalized one point for every observation            the shapes (i.e., oij = ln for n > 0) for a particular gameboard
made in the sampling phase and two points for every error             g is deterministic (i.e., p(oij = ln ∣g) = 1 if the location falls
committed in the painting phase (e.g., failing to ll in a square      within a target and 0 otherwise).
that belongs to a shape). ese costs promote eﬃcient infor-              e prior belief about the likelihood of each individual
mation search in two ways. First, the observation cost dis-           gameboard is represented by p(g). In our experiments, par-
courages sampling in locations whose contents can be inferred         ticipants were instructed that the shapes were chosen at ran-
from evidence that has already been uncovered. Second, it en-         dom and that all legal gameboards were equally likely (i.e.,
courages continued sampling while there is still uncertainty          p(g) = 1/∣G∣ for all g, a uniform prior).
about the hidden shapes, since painting errors are more costly           Bayes rule can be used to compute the posterior belief
                                                                  720

about the identity of the hidden gameboard and to predict the                     A                               Experiment 1           B 1.0                    Experiment 2
marginal probability of any point in the grid having any partic-                                     1.0
ular label ln (this is a very straightforward Bayesian approach
                                                                              Cumulative Frequency                                    Cumulative Frequency
                                                                                                     0.8                                                 0.8
to the problem, see Gureckis and Markant, 2009).
Interested (cost-sensitive) Sampling e objective of the                                             0.6                                                 0.6               Information Gain
game is to minimize the number of points accumulated, where                                                                                                                Expected Savings
                                                                                                     0.4                                                 0.4
each individual observation costs Cobs points and each error                                                                                                               Random
during painting costs Cerror points. Given these constraints,                                        0.2                                                 0.2
we can quantify the value of observations with respect to the
overall goal of minimizing total costs. We assume that the like-                                     0.0                                                 0.0
lihood of labeling a point oij with label ln during the paint-                                             0     20 40 60 80 100                            0   5 10 15 20 25 30 35
                                                                                                                    Rank                                              Rank
ing phase is simply the marginal probability p(oij = ln ∣B),
and the cost associated with that action is tied to the uncer-
tainty about its label when the sampling phase ends (e.g., if                     Figure 2:      Cumulative frequency of ranks assigned to partici-
                                                                                  pants’ samples. A: In Experiment 1, the average rank of participants’
p(oij = ln ∣B) = 1, the true label is known with certainty and                    choices is higher than expected from a random sampling strategy, but
there is no chance of committing an error during painting)1 .                     there is no diﬀerence between rankings assigned by the two models.
                                                                                  B: In Experiment 2, participants’ samples are more highly ranked ac-
On each trial, the total expected cost EC(B) of ending the                        cording to EIG than ES.
sampling phase and entering the painting phase is de ned as:
EC(B) = Cerror ⋅ ∑ ∑ ∑ p(oij = ln ∣B)⋅[1−p(oij = ln ∣B)]
                      i   j   n                                                   observation and its observed outcome (oij = ln ) we can cal-
                                                          (1)                     culate information gain as:
For a new observation and its observed outcome (oij = ln )
we then calculate the resulting cost savings, or reduction in                                                     I(B, oij = ln ) = H(B) − H(B∣oij = ln )                           (4)
expected costs:
                                                                                  To account for uncertainty about the true outcome of an
          S(B, oij = ln ) = EC(B) − EC(B∣oij = ln )                  (2)          observation, information gain for each possible outcome is
                                                                                  weighted by the predicted probability of that outcome occur-
e savings achieved from feedback is oﬀset by the cost of
                                                                                  ring, giving the expected information gain for an observation
making the observation (Cobs ). To account for uncertainty
                                                                                  oij :
about the true outcome we nd the expected savings by weight-
ing the savings for each outcome by its likelihood of occurring:                                               EIG(B, oij ) = ∑ p(oij = ln ∣B) I(B, oij = ln )                      (5)
                                                                                                                                 n
 ES(B, oij ) = −Cobs + ∑ p(oij = ln ∣B) S(B, oij = ln ) (3)
                              n                                                   As above, on each trial we compute EIG(B, oij ) for all loca-
For each trial, ES(B, oij ) is calculated for all oij , giving a dis-             tions in the grid, and assume that the optimal model chooses
tribution of the expected saving for remaining observations in                    the location with the highest value on each trial2 .
the grid. An ideal learner maximizes this value by choosing                          In applying each model to human choice data, the model is
the location oij with the highest ES(oij ) on each trial.                         “yoked” to the decisions of the player. On each trial, the mod-
                                                                                  els assign a value (either EIG or ES) to each point in the
Disinterested (cost insensitive) Sampling A “disinterested”                       grid. ese utilities can be used to compute choice probabil-
sampling norm values observations according to their eﬀect                        ity of various grid locations. Aer revealing what the subject
on the learner’s beliefs without account for task-speci c costs                   actually chose on a given trial, the model updates its poste-
and bene ts. is captures the intuition that observations that                    rior beliefs about the current gameboard con guration. ese
produce a large change in the agent’s beliefs tend to be more                     new beliefs then feed into new predictions about the utility of
useful than observations that have little or no eﬀect (i.e., noth-                choosing each grid location. e process ends when the par-
ing new is learned). In our approach this was modeled using                       ticipant ends the game.
information gain, which values an observations according to
the expected reduction of uncertainty about the hidden game-                                                      Experiment 1: Rectangle Search
board. is uncertainty can be quanti ed by the Shannon en-                        e rst experiment re-analyses a previously published re-
tropy measured over the current belief distribution (H(B)).                       sult which introduced explicit task-speci c costs (Gureckis &
   Entropy is maximized when all hypothesized gameboards                              2
                                                                                        It is important to note that this represents a “greedy” policy that
are equally likely (as with our initial uniform prior), and min-                  chooses the best observation available on any given trial, but this
imized when there is only one possible hypothesis. For a given                    may not re ect the globally optimal solution. e current framework
                                                                                  could be extended to account for how participants might estimate the
    1
      For shorthand, B represents a vector of probabilities p(g∣oij =             value of sequences of observations. However, due to the computa-
ln ), for all g ∈ G, that represents the full posterior distribution over         tional complexity of nding this solution given the large number of
the entire space of gameboards. is is the agents current “belief dis-            potential observations on any trial, for the present studies we focus
tribution” about which gameboard is the current target.                           our analysis on the greedy model.
                                                                            721

                                                                      ese modi cations resulted in a much less complex hypoth-
Markant, 2009). Six participants played a series of games in          esis space (e.g., only  hypotheses were possible at the begin-
which they searched for three rectangular shapes, randomly            ning of an L/D game, and  for C/U games). Importantly,
drawn from the set shown in Figure 1. e set of shapes                because the two shapes involved in each type of game diﬀered
was displayed on screen throughout the game. Participants             in area (for example, the ‘D’ shape contained a greater number
were instructed that the three shapes in each gameboard were          of lled squares than the ‘L’), the predictions of information
non-overlapping and were shown a large number of examples             gain and expected savings diverged in the task.
gameboard con gurations prior to the experiment.
   Each observation made by a participant during the sam-             Methods
pling phase was ranked according to the predictions of both           Participants Sixteen NYU undergraduates completed the study
                                                                      for course credit or for a $ payment. e experiment was presented
models (the median rank was used when multiple observa-               on a standard Macintosh computer.
tions had equal value). Overall, the results show that people
consistently sampled points that were assigned a high value by        Materials A gameboard consisted of one of the four letter shapes
                                                                      seen in Figure 3 placed in any location on the grid. All possible game-
both models, with approximately 50% of their samples falling          boards were generated, resulting in  gameboards for each letter,
within the top 10 ranked observations available to them (see          or  for each game combination (L/D or C/U). For L/D games,
Figure 2A). In this experiment, however, the hypothesis set            gameboards were randomly selected from the pool of L and D
                                                                      gameboards. is was repeated for C/U games. e resulting total of
that was used (rectangular shapes of varying shape and size)           unique games were used for all participants. e order of games
led to highly similar predictions for both information gain and       played was randomized for each person.
expected savings, precluding a test of whether people were            Procedure Many aspects of the design were identical to Experi-
sensitive to the costs in the task.                                   ment 1 (described in Gureckis and Markant, 2009), so we highlight
   It is important to consider why the predictions of the two         diﬀerences below. In Experiment 2 we sought to reduce any reliance
                                                                      on the visual display for recalling the speci c shapes being used. Par-
models converged in this case. As discussed previously, a cost-       ticipants began the experiment with two training phases to memorize
sensitive learner should value observations that have higher          the four shapes. In the rst, a letter cue (e.g., the character ‘L’ in a
utility—that is, those that will reduce the likelihood of com-        standard computer font) was presented at the top of the screen along
                                                                      with its corresponding shape, which appeared inside a x grid. e
mitting errors in the painting phase by the greatest amount.          participant was asked to copy the same shape onto an empty x grid
Intuitively, this implies that learning about bigger shapes is        below. is was done twice for each letter (L, D, C, U) in randomized
especially useful, since it will allow one to correctly label a       order. In the second training phase, they were presented only with
                                                                      the letter cue and an empty x grid, and asked to ll in the correct
greater number of squares. is idea is illustrated in Figure 3A       letter shape from memory. is was repeated three times for each
for a simple hypothesis set made up of three rectangles in dif-       letter in random order. In order to progress from one training trial
ferent locations. While observing a “hit” on any shape de-            to the next, the participant was required to successfully reproduce
                                                                      the correct shape. Training was followed by on-screen instructions
termines the true hypothesis (middle column), observing a             which were modi ed to re ect the new hypothesis spaces.
“miss” (righthand column) has diﬀerent utilities depending                Before the sampling phase began, a -second cue was displayed
on the size of the shape it rules out. For example, ruling out        on the screen that indicated the type of game about to be played (the
                                                                      characters “L D” or “C U”). is cue was also displayed on the right
the smallest shape (top row) leaves uncertainty about how to          side of the display during the game. is ensured that participants
label eight other squares, whereas ruling out the largest shape       were aware of the shapes that were possible but that they had to use
(bottom row) leaves uncertainty about only four.                      their memory of the actual shapes to guide their observations.
                                                                          Sampling and painting phases proceeded in the same way as Ex-
   While the shape set used in Experiment 1 contained a range         periment 1. e nal score was then displayed, including how many
of sizes, the fact that the hypotheses were “nested” (i.e., the       points were the result of sampling and how many were the result of
largest shapes overlapped with a set of progressively smaller         painting errors. e lowest score obtained by the participant in any
                                                                      game so far was shown to provide motivation and a means to eval-
ones) meant that learning about larger shapes also tended to          uate their performance over time. Each participant played 30 games
rule out many hypotheses. As a result, the predicted choice           at their own pace, resulting in a total of 480 games collected.
values according to both models were highly similar. For our
second experiment we created an alternative hypothesis space          Results
in which there were clearer diﬀerences in both the size of alter-     Sample rank On each sampling trial, the ideal models were
native hypotheses and the choices that were related to shapes         used to compute the expected information gain and expected
of diﬀerent size, leading to a greater number of potential ob-        savings for all remaining observations available. A partici-
servations where the predictions of the two models diverged.          pant’s decisions were ranked according to EIG and ES (if mul-
                                                                      tiple observations had the same value, the median rank was
               Experiment 2: Letter Search                            used). e relative frequency of each sample rank was com-
In Experiment 2, we simpli ed the task to involve searching           puted for each participant across all trials, and averaged across
for a single target in the grid. For the hypothesis space we cre-     participants (see Figure 2B). e rank frequency shows that
ated a set of simple “letter” shapes (see Figure 3B). ere were       participants’ choices were more highly ranked on average ac-
two types of games: L/D games, where the hidden letter could          cording to EIG than ES. Participants’ samples were ranked
be an L or D, and C/U games, where the hidden letter could            within the top 5 observations according to EIG on approx-
be a C or U. In each game a single point belonging to the hid-        imately 57% of trials, whereas according to ES only 35% of
den shape was revealed before the participant began sampling.         samples fell in the same range.
                                                                  722

 A                    HITS             MISSES             B                              Experiment 2: Letter Search
                   x                x
                                    ? ? ?
                                                              D/L shape set
                                    ? ? ? ? ?                                  random sample
  HYPOTHESES                                                                                                         x                  x
   h1                               ?
   h2              x                x
                                                                                             Hidden target          EIG                 ES
   h3                               ? ? ? ? ?                 C/U shape set
                                                                               random sample
                                    ?
                                                                                                                     x                  x
                                    ? ? ?
                    x               x
Figure 3: A: Illustration of the divergence between information gain and expected savings. Le: A hypothesis space is comprised of three
possible rectangles, h1 , h2 , and h3 . Middle: A hit on any one rectangle leads to the same number of hypotheses being ruled out, and no uncer-
tainty about the label of any square in the grid. Right: A miss in any of the three locations rules out a single hypothesis, but the predictive utility
of the sample diﬀers based on its location. e labels for 8 squares are uncertain following a miss that rules out rectangle h1 , 6 squares following
a miss ruling out h2 , and 4 squares following a miss ruling out h3 . B: Gameboard design and example model predictions in Experiment 2. Two
types of games were possible: L/D games, where the hidden shape could be an L or D, and C/U games, where the hidden shape could be a C
or U. Predicted value distributions for EIG and ES are shown for the rst sampling trial in each kind of game, with a darker value indicating a
higher value according to the model.
                                                                              Discussion
Model ts We next computed the likelihood of participants’
                                                                              e results of our second experiment show that people per-
decisions under the two alternative models. For each trial, the
                                                                              formed well compared to the ideal searcher model, frequently
value of available observations was transformed into choice
                                                                              choosing highly ranked observations and consistently per-
probabilities using the somax function:
                                                                              forming better than expected by a random search strategy. In
                                                                              addition, participants rarely gathered more information than
                                       eβ⋅V (oij )                            necessary, which is consistent with prior work showing that
                      P (oij ) =                                      (6)     people are sensitive to costs incurred by oversampling (Fu &
                                   ∑x,y eβ⋅V (oxy )
                                                                              Gray, 2006). Most importantly, we found that participants’
e parameter β was t on an individual basis for each model                    sampling choices were better described by information gain
by maximizing the log-likelihood summed across all observa-                   than a cost-sensitive utility measure (expected savings).
tions made by a participant. In all cases, EIG provided a better                 Prior studies of human information collection have focused
  t to participants’ data than ES (Table 1).                                  to a large extent on “disinterested” accounts of sampling deci-
                                                                              sions, showing that people are sensitive to the amount of infor-
Stopping decisions Our nal analysis focused on partici-                       mation conveyed by diﬀerent sources of information (Nelson,
pant’s decisions to stop sampling. While EIG and ES make                      McKenzie, Cottrell, & Sejnowski, 2010). However, this line
the same prediction as to when sampling should stop3 , we                     of work has oen failed to consider whether people account
were interested in whether people showed any sensitivity to                   for variations in task-speci c utility when making sampling
the cost of collecting information. If people uncovered more                  decisions. In our task, we introduced penalties for informa-
squares than necessary it would suggest a failure to account                  tion access and uncertainty that altered the optimal sampling
for the cost of new observations (either in terms of ES or                    strategy. By manipulating the set of hypotheses in Exp. 2, we
EIG). We classi ed each game according to whether the per-                    showed how sampling based on an information-maximizing
son decided to stop sampling before the trial predicted by the                strategy can be distinguished from cost-sensitive sampling.
model (“early”), on the same trail (“optimal”), or aer that                  With respect to the distinction we began this paper with, our
trial (“late”). On average, participants ended sampling early                 results suggest that people (at least in this task) prefer to gather
(M = 0.46, SD = 0.14) or on the optimal trial (M = 0.50,                      information according to a “disinterested” measure of value.
SD = 0.14) on a similar proportion of games. In contrast,                        Notably, diﬀerences in value between choices were not di-
participants oversampled very rarely (M = 0.04, SD = 0.01).                   rectly observable by the participant (as opposed to when some
                                                                              observations are more costly or diﬃcult to make than others).
      3
        is convergence was due to the cost structure we used, in which       Whether a given observation was valued diﬀerently according
the penalty for stopping before the hidden target was known was               to EIG and ES depended upon the set of hypotheses remain-
greater than the cost of an additional sample. Increasing the cost of
sampling relative to the cost of errors would lead to ES predicting           ing, and this divergence could change from trial to trial in re-
earlier stopping decisions than EIG.                                          sponse to new data. As a result, establishing which model pro-
                                                                          723

vided a better account required tting them to participants’                                   Acknowledgments
decisions across a variety of choice contexts. is highlights         e authors would like to thank Dan Navarro, Jonathan Nel-
a feature of our approach in that we could evaluate diﬀerent          son, and the other reviewers for their helpful comments. is
                                                                      work was supported by the Intelligence Advanced Research Projects
sampling strategies using a set of highly variable choice se-         Activity (IARPA) via Department of the Interior (DOI) contract
quences. rough the use of a well-de ned hypothesis set and           D10PC20023. e U.S. Government is authorized to reproduce and
explicit cost structure, the “shape-search” task provides a use-      distribute reprints for Governmental purposes notwithstanding any
                                                                      copyright annotation thereon. e views and conclusions contained
ful framework for studying how information search decisions           herein are those of the authors and should not be interpreted as nec-
and task demands interact over the course of learning.                essarily representing the oﬃcial policies or endorsements, either ex-
   Of course, one potential caveat of the current study is that       pressed or implied, of IARPA, DOI, or the U.S. Government.
(due to computational demands) we evaluated a greedy deci-
sion policy such that the predicted value of a new observation
                                                                                                    References
                                                                      Chater, N., Crocker, M., & Pickering, M. (1998). e rational analy-
does not take into account the consequence or utility of subse-               sis of inquiry: the case of parsing. In M. Oaskford & N. Chater
quent actions. It is possible that fully accounting for sequen-               (Eds.), Rational models of cognition (pp. 441–468). Oxford
tial dependencies in the search problem may alter the optimal                 University Press.
                                                                      Edwards, W. (1965). Optimal strategies for seeking information:
utilities computed by the model. However, one might reason-                   models for statistics, choice reation times, and human in-
ably question if the computational demands of such a multi-                   formation processing. Journal of Mathematical Psychology, 2,
step planning process are within reach of human reasoners.                    312–329.
                                                                      Fu, W, & Gray, W. (2006). Suboptimal tradeoﬀs in information seek-
In addition, it is unclear that accounting for multi-step plan-               ing. Cognitive Psychology, 52(3), 195–242.
ning strategies would alter the choice utilities in a way that        Fu, W. (2011). A dynamic context model of interactive behavior. Cog-
would bias for or against the results we report. Also note that               nitive Science, 35(5), 874–904.
                                                                      Gureckis, T., & Markant, D. (2009). Active learning strategies in
comparing Exp. 1 and 2 illustrates that expected saving is not                a spatial concept learning game. In N. Taatgen & H. van
always at an advantage (i.e., in some choice environments the                 Rijn (Eds.), Proc of the 31st annual conference of the cogni-
models become less distinguishable).                                          tive science society (pp. 3145–3150). Cognitive Science Soci-
                                                                              ety. Austin, TX.
                                                                      Juni, M., Gureckis, T., & Maloney, L. (2011). Don’t stop ’till you get
                          Conclusion                                          enough: adaptive information sampling in a visuomotor esti-
                                                                              mation task. In L. Carlson, C. Hölscher & T. Shipley (Eds.),
So, why might human reasoners preferentially adopt “disin-                    Proceedings of the 33rd annual conference of the cognitive sci-
terested” sampling over “interested” sampling? One possibil-                  ence society. Cognitive Science Society. Austin, TX.
                                                                      Lindley, D. (1956). On a measure of the information provided by an
ity is that sampling based on information gain (or other “dis-                experiment. Annals of Mathematical Statistics, 986–1005.
interested” norms) may re ect a general purpose strategy that         Mackay, D. (1992). Information-based objective functions for active
is useful in a variety of contexts. In particular, information                data selection. Neural Computation, 4, 590–604.
                                                                      Nelson, J. (2005). Finding useful questions: on bayesian diagnostic-
gain can still be computed even when the cost of uncertainty                  ity, probability, impact, and information gain. Psychological
(i.e., not knowing which hypothesis is true at the end of sam-                Review, 114(3), 677.
pling) is diﬃcult to predict. In addition, in many natural en-        Nelson, J, & Cottrell, G. (2007). A probabilistic model of eye
                                                                              movements in concept formation. Neurocomputing, 70(13-
vironments it may be consistent with the predictions of a cost-               15), 2256–2272.
sensitive utility function, as illustrated by our rst experiment.     Nelson, J., McKenzie, C., Cottrell, G., & Sejnowski, T. (2010). Experi-
At the very least, our results highlight the need to understand               ence matters: information acquisition optimizing probability
                                                                              gain. Psychological Science, 21(7), 960–969.
the kinds of problems that lead people to adapt to task-speci c       Rehder, B., & Hoﬀman, A. (2005). Eyetracking and selective attention
costs in lieu of a general-purpose, “disinterested” approach to               in category learning. Cognitive Psychology, 51, 1–41.
information search.                                                   Stephens, D., & Krebs, J. (1986). Foraging theory. Princeton, NJ:
                                                                              Princeton University Press.
                                                                      Tversky, A., & Edwards, W. (1966). Information versus reward in bi-
                                                                              nary choices. Journal of Experimental Psychology, 71(5), 680–
                                                                              683.
                        Table 1: Model ts
          Subj    βEIG    βES      -LLH(EIG)     -LLH(ES)
          1      17.544    0.95       215.05       334.65
          2        5.18    0.88       391.77       426.18
          3        5.93    0.77       326.45       388.79
          4        6.96    0.75       325.81       403.61
          5       10.15    0.89       241.04       324.30
          6       12.34    1.06       250.17       329.72
          7        9.64    1.20       276.05       339.62
          8        7.63    0.98       308.63       373.03
          9        5.36    0.90       354.49       387.43
          10       7.79    0.91       315.92       387.56
          11       5.85    0.85       340.22       388.05
          12       6.39    0.92       328.24       373.22
          13       6.97    1.03       319.96       362.27
          14       7.02    0.86       283.32       341.79
          15       8.94    0.99       293.38       371.22
          16       10.0    0.76       293.65       403.22
                                                                  724

