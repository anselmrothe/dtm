UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Rapid entrainment to spontaneous speech: A comparison of oscillator models
Permalink
https://escholarship.org/uc/item/0c905908
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Inden, Benjamin
Malisz, Zofia
Wagner, Petra
et al.
Publication Date
2012-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

     Rapid entrainment to spontaneous speech: A comparison of oscillator models
                                                             Benjamin Inden
                                                           Faculty of Technology
                                                            Bielefeld University
                                                     binden@techfak.uni-bielefeld.de
                                                                Zofia Malisz
                                                Faculty of Linguistics and Literary Studies
                                                            Bielefeld University
                                                               Petra Wagner
                                                Faculty of Linguistics and Literary Studies
                                                            Bielefeld University
                                                             Ipke Wachsmuth
                                                           Faculty of Technology
                                                            Bielefeld University
                              Abstract                                  whereas delta band oscillations (0.5-3 Hz) correspond to typ-
   Oscillator models may be used for modeling synchrony be-             ical lengths of prosodic and metrical units. Many kinds of
   tween gestures and speech, or timing of backchanneling and           oscillators have the property of entraining to an externally
   turn-taking in dialogues. We find support for the hypothesis         provided periodic signal, i.e., they become phase-locked to
   that oscillator networks can better predict rhythmic events on
   the syllable and foot level than single oscillators, but we do       the signal. Therefore, it seems plausible that neural oscil-
   not find support for the hypothesis that phase resetting oscil-      lators might play a role in the production and perception of
   lators perform better that phase adapting oscillators. Overall,      speech by synchronizing certain systems with the speech sig-
   oscillators can be used to predict rhythmic events in speech,
   but higher level information needs to be integrated into such        nal (Buzsáki & Draguhn, 2004; Ghitza & Greenberg, 2009).
   models to reach a satisfactory performance.                          Previous research has also found that gestures may be syn-
   Keywords: speech rhythm, entrainment                                 chronized with speech rhythms (Condon, 1986; Tuite, 1993;
                          Introduction                                  Wachsmuth, 1999; Loehr, 2007). Furthermore, listeners can
                                                                        become entrained to a speaker’s rhythm, which helps them to
Spontaneous speech, like music, exhibits temporal regular-
                                                                        provide backchanneling or take turns in a dialogue at a suit-
ities, but these cannot be captured by simple descriptions.
                                                                        able moment in time (Wilson & Wilson, 2005).
Rhythm, i.e., hierarchical structured temporal regularities, is
widely believed to be an important principle for understand-               A number of oscillator models have been proposed that can
ing both music and speech (Large, 2008; Cummins & Port,                 entrain to musical rhythms. Here we focus on models pro-
1998). Regularity of timing greatly contributes to speech per-          posed by Large and McAuley (Large, 1994; McAuley, 1995).
ception and understanding. Regular sequences of, e.g., inter-           These have been shown to achieve entrainment to input sig-
stress intervals in speech or tone sequences in music speed             nals not just in a period ratio of 1:1, but also in more com-
up perception by facilitating meaningful grouping and con-              plex ratios, which makes coupling between several levels of
trast within a very rich acoustic signal. The role of rhythmic          speech rhythm possible. Furthermore, oscillator banks have
expectancies both in speech and music perception has been               been shown to reproduce empirical findings about human per-
the basis of Dynamic Attending Theory (Jones, 1990) and                 ception of rhythm: they can resonate at frequencies that are
more specific phonological models such as PolySP (Hawkins,              not present in the input signals, but perceived by human sub-
2003). Humans can even perceive rhythms in music that do                jects, too (Large, 2008; Large, Almonte, & Velasco, 2010).
not directly correspond to any frequency found in a spectral               We are interested in whether these oscillator models orig-
analysis of the signals (Large, 2008). Similarly, the timing            inally built for modeling music perception can also be used
of speech production is coordinated via rhythmic principles.            to model human entrainment to less regular speech signals.
The same principles govern the neuro-physiological dynam-               In general, we believe in the necessity to couple oscillators
ics of all motor behavior. On the syllable level, the vocalic           for different levels of the rhythmic hierarchy, so ultimately
pulse represents the basic timing coordination of the articula-         we will include this in the models discussed in this article.
tory system (Browman & Goldstein, 1992).                                However, here we focus on the question what particular fea-
   When measuring brain activity, one can easily find a num-            tures might make an oscillator model more capable of cor-
ber of prominent frequencies. Some of them are in the                   rectly predicting syllable and foot onset times when consid-
range of typical speech units: the theta band (3-12 Hz) cor-            ered separately from the other levels of the rhythmic hierar-
responds to the typical duration of a syllable (100-300 ms),            chy. After all, speech is less regular than music, so adapta-
                                                                    1721

tion to input signals should be very fast. Therefore, we will        intervocalic interval was 125 msec in this material and 365
compare two previously proposed oscillator models and then           msec for the foot. 69 phrases each from dataset 1 and dataset
make a number of changes to one of them to see whether pre-          2 were provided as input to the different oscillator models,
diction performance improves. In particular, we examine the          i.e., the resulting onset times for each vowel or foot event
following hypotheses: First, oscillators that reset their phase      served as the input pulse.
upon arrival of an input signal may be faster than those that           For each conversation, a control set of regular phrases was
adapt their phase gradually. Second, it may be better to have        created by generating completely regular pulses with frequen-
a bank of oscillators tuned to different frequencies than to         cies equal to the mean frequencies of events in the corre-
have a single oscillator that adapts its period. This would be       sponding individual phrases from the conversation data.
because period adaptation time is dependent on the amount
of change necessary whereas in banks of oscillators, the time                          Models of entrainment
for a differently tuned oscillator to become activated is con-       Phase adaptation oscillator (PAO)
stant with regards to the amount of frequency change. To
the degree these hypotheses turn out to be supported by the          This oscillator model is one of several similar models origi-
data, they can inform future modeling of human entrainment           nally proposed by Large for entrainment to musical rhythms
to speech rhythms. Besides addressing these two hypothe-             (Large, 1994). The phase of this oscillator is defined as
ses, our experiments also show how much can be learned at            ϕ(t) = t−tp x , where tx is the time of the last event (in the in-
all by oscillator models without considering the hierarchical        put or according to the oscillator’s expectation) and p is the
organization of speech, i.e., from a pure low-level approach.        period of the oscillator. The phase is reset to 0.0 when it
                                                                     reaches 1.0. The output of the oscillator is modeled as a peri-
                                                                     odic function o(t) = 1 + tanh(γ(cos(2πϕ(t)) − 1)), where the
                           The Data
                                                                     output gain parameter γ controls the sharpness of the activity
The speech data comes from a corpus of spontaneous di-               peaks. The oscillator has three adaptation rules that depend
alogue in German where one dialogue partner told a hol-              on the input signal s(t) as well as learning rates η1 , η2 , η3 .
iday story and the other was instructed to listen actively           The first rule in effect adapts the phase:
(Buschmeier, Malisz, Włodarczak, Kopp, & Wagner, 2011).
                                                                                         p
The corpus was collected for the purposes of modeling en-                 ∆tx = η1 s(t)    sech2 (γ(cos(2πϕ(t)) − 1)) sin(2πϕ(t))
trainment in dialogue, multimodal behavior of the listener,                             2π
i.e., feedback signals, head and manual gesture, as well as the         The second adapts the period:
prosody of the storyteller. The latter objective is addressed in
the present paper.                                                                       p
                                                                          ∆p = η2 s(t)     sech2 (γ(cos(2πϕ(t)) − 1)) sin(2πϕ(t))
   Audiovisual recordings were made in a sound-treated stu-                             2π
dio. Participants were positioned approximately three me-               The third adapts an estimate Ω of input variability:
ters apart to minimize crosstalk. Close talking high-quality
headset microphones were used. The signal properties were                       ∆Ω = η3 s(t)sech2 (γ(cos(2πϕ(t)) − 1))
annotated in Praat (Boersma & Weenink, 2012). Careful an-                       (cos(2πϕ(t)) + 2γ(o(t) − 1) sin2 (2πϕ(t)))
notation of the acoustic signal enables to approximate emer-
gent rhythmic phenomena (Gibbon & Fernandes, 2005). To                  This estimate in turn determines the receptive field width
represent the syllabic oscillator hypothesized for speech pro-       τ of the oscillator, i.e., the width of a window in time around
duction, we first semi-automatically extracted vowel onsets          its maximal activation where it is highly adaptive to input sig-
from the data (Cummins & Port, 1998; Barbosa, 2006).                 nals: τ = τmax +0.5(τmin −τmax )(1+tanh Ω). The output gain
                                                                                                                               −0.416
Secondly, experts annotated rhythmic feet, representing the          is inversely related to the receptive field width: γ = cos(2πτ)−1 .
slower stress oscillator, where each prominent syllable is a         So if there is less input variability, the receptive field shrinks,
pulse on that level. We also annotated interpausal units (IPUs)      and the output peaks are sharper, whereas if there is more
with a criterion that only minimally perceptible interruptions       input variability, the receptive field grows, and the output
in the flow of speech were marked (not all acoustic pauses).         peaks are softer. Finally, the output value o(t) is multi-
   For the present simulations, two conversations (henceforth        plied by a confidence value c = cmax + 0.5(cmin − cmax )(1 +
dataset 1 and dataset 2) were used. Phrases (IPUs) consisting        tanh Ω). Further explanations about the motivation behind
of at least two feet events were selected. Any phrase initial        these choices, and the behavior of the oscillator, can be found
unstressed vowel events (anacruses) were excluded as well as         in the literature. The following parameter settings were also
the phrase final vowel event. The trimmings were done to             taken from the literature: η1 = 1.0, η2 = 0.3, η3 = 0.3,
exclude any extra lengthening at the end of phrase and ex-           τmin = 0.02, τmax = 0.5, cmin = 0.0, cmax = 1.0. Because we
tra irregularity at the beginning of phrase that typically signal    expect syllable periods to be in the range [0.1, 0.25], and feet
a boundary in German. The resulting phrases consist of flu-          periods in the range [0.2, 0.5], we set the initial periods of the
ent, spontaneous, uninterrupted speech with a minimal phrase         period and feet oscillators to the middle of these ranges, i.e.
length of one second. The mean duration of a syllable-sized          0.175 and 0.35.
                                                                 1722

Phase reset oscillator (PRO)                                               ensures that only a few oscillators will consider themselves
This oscillator has been originally proposed by McAuley for                synchronous with the input signal, which again reduces blur-
the perception of music, and modified by Nerlich in the con-               ring of the network output. Period adaptation is not used in
text of human-machine interaction (McAuley, 1995; Nerlich,                 the PRN model, but phase reset works just like in the PRO
1998). Its output, like that of the PAO, is a periodic func-               model.
tion modified to modulate the sharpness of the output peaks,                  The initial periods are logarithmically distributed in the
together with a term for exponential decay of the output:                  range of [0.1, 0.25] for syllables, and [0.2, 0.5] for feet. There
                                                                           is an additional network output unit with a sigmoid output
          (                     )(1−Ω(n))γmin +Ω(n)γmax                    function n(t) = 1/(1 + exp(− ∑i oi (t − 1))), where the oi (t)
              1 + cos(2πϕ(t)                                   βtx
  o(t) =                                                exp(−       )      are the outputs of the individual oscillators. This variant of
                      2                                        pini
                                                                           the model is called PRN1. In the variant called PRN2, the
The phase ϕ(t) is always kept in the range [−0.5, 0.5], and                output unit is also connected to the network input. After an
reset to 0.0 when an input event arrives. The synchrony                    input event, its output remains zero until the sum of its input
Ω(n) = (1 − ε)Ω(n − 1) + ε(1 − 2|ϕr (n)|) is measured every                has a positive slope. Because there may be high oscillator
time an input event arrives: ϕr (n) is the phase of the oscillator         outputs immediately after an input event that could disrupt
at the reset, and ε = 0.2 is a parameter that weights the cur-             this behavior, an absolute refractory period of 5 simulation
rent impulse against the memory of earlier synchrony with                  steps after an input event is enforced unconditionally.
input events. γmin = 1 and γmax = 5 constrain the range of
                                                                                                       Results
output sharpening that is dependent on measured synchrony
with the train of input events. The final term in the output               In experiments presented elsewhere (Malisz, Inden,
equation dampens the output exponentially when no input ar-                Wachsmuth, & Wagner, 2012), we fed event signals
rives. β = 0.5 is the decay rate, pini the initial period of the           from the whole conversation into PAO and PRO models and
oscillator, and tx the time since the last input event.                    measured their internal phases when an input signal arrived.
   The period is adapted using ∆p = α∆tPM 2p , where α =                   In those experiments, we found a significant advantage of the
1 is the entrainment rate, the period coupling term P =                    PRO model over the PAO model. By contrast, here we feed
ϕr (n)(1 − Ω(n)) is dependent on the synchrony and on the                  data from individual phrases separately into the oscillators
phase at the last reset, and the impulse response function                 and measure their average output activation when an input
M = 1+exp(−Γ(ir (n)1exp(−Θt)−0.5)) (with impulse response gain             signal arrives. We also measure average output activation
                                                                           when no input signal arrives and take the difference between
Γ = 1000 and impulse response bias Θ = 2) ensures that al-
                                                                           the averages as a performance measure. As Tables 1 to 4
most all adaptation is done shortly after an input event. Like
                                                                           show, there is no significant advantage of the PRO model
in the PAO model, we set initial periods of the period and feet
                                                                           over the PAO model in this case. Furthermore, both are at or
oscillators to 0.175 and 0.35, while all other parameters are
                                                                           below random level on most of the real data sets.
taken from the literature.
                                                                              As Tables 1 to 4 also show, using a bank of oscillators like
Phase reset oscillator network (PRN)                                       PRN1 is a significant improvement over using a single oscil-
                                                                           lator (and is significantly above random level). When adding
We use a network of 20 parallel oscillators that are similar to
                                                                           the refractory period rule to the oscillator network, perfor-
the PRO model. However, we let the output decay not when
                                                                           mance further improves significantly for almost all datasets.
no input arrives as before, but when the individual oscillator
                                                                              The output trajectories of the different oscillator models for
is not synchronous with the train of input signals:
                                                                           an example phrase can be seen in Fig. 1.
                                         1 + cos(2πϕ(t)) cs
         oi (t) = exp(cd (1 − σi (t)))(                     )                                        Discussion
                                                   2
                                                                           Our experiments do provide some support to the hypothesis
   The constant cs = 20 determines the sharpness of the os-                that oscillator networks may be better suited to speech data
cillator output signal (the more oscillators we have in the                than single oscillators that adapt their period. Such insights
network for a given frequency range, the higher this con-                  can inform modeling of human rapid entrainment to spon-
stant should be to reduce blurring of the network output),                 taneous speech. However, the experiments provide no sup-
while cd = −20 determines how much the oscillator out-                     port for the hypothesis that phase resetting oscillators like
put decays depending on its asynchrony. The synchrony is                   the McAuley oscillator are better suited to the rather irregu-
measured each time an input event arrives using σi (tr ) =                 lar speech data than phase adapting oscillators like the Large
(1 − c p )σi (tr−1 ) + c p (1 − exp(ce ϕ(tr )2 ), where c p = 0.2 is a     oscillator. This might be because performance of both mod-
constant that weights the current impulse against the memory               els is so close to chance level when used in that way. More
of earlier synchrony with input events just like in the PRO                than anything else, these results show that the level of predic-
model, and ce = −200 determines how much prediction error                  tion performance that can be reached by considering just one
is still considered synchronous. Using an exponential term                 level of speech rhythm is rather low regardless of the used
here instead of a piecewise linear term as in the PRO model                oscillator models.
                                                                       1723

                                                phrase data                                    regular control data
             oscillator model
                                prediction at   prediction at    difference    prediction at       prediction at       difference
                                vowel onset     other times                    vowel onset          other times
            PAO                 0.241±0.005     0.265±0.006     -0.024±0.007   0.593±0.030         0.186±0.010        0.408±0.041
            PRO                 0.296±0.011     0.327±0.004     -0.031±0.013   0.544±0.033         0.274±0.007        0.270±0.034
           PRN1                 0.311±0.013     0.273±0.006     0.039±0.010    0.854±0.012         0.257±0.005        0.597±0.014
           PRN2                 0.311±0.013     0.168±0.006     0.143±0.011    0.854±0.012         0.139±0.005        0.715±0.014
Table 1: Prediction of vowel onsets (mean oscillator output) for different oscillator models and dataset 1.
                                                phrase data                                    regular control data
                                prediction at   prediction at    difference    prediction at       prediction at       difference
                                 foot event     other times                     foot event          other times
            PAO                 0.260±0.010     0.288±0.004     -0.028±0.013   0.474±0.029         0.230±0.008        0.244±0.036
            PRO                 0.316±0.017     0.333±0.004     -0.018±0.018   0.561±0.028         0.322±0.005        0.239±0.030
           PRN1                 0.356±0.015     0.318±0.006     0.038±0.014    0.714±0.022         0.305±0.006        0.409±0.023
           PRN2                 0.356±0.015     0.207±0.008     0.149±0.015    0.714±0.022         0.187±0.007        0.527±0.022
Table 2: Prediction of foot events (mean oscillator output) for different oscillator models and dataset 1.
                                                phrase data                                    regular control data
             oscillator model
                                prediction at   prediction at    difference    prediction at       prediction at       difference
                                vowel onset     other times                    vowel onset          other times
            PAO                 0.246±0.006     0.261±0.005     -0.015±0.007   0.689±0.023         0.146±0.008        0.543±0.030
            PRO                 0.295±0.011     0.323±0.003     -0.027±0.012   0.627±0.027         0.254±0.005        0.372±0.026
           PRN1                 0.329±0.013     0.273±0.005     0.056±0.010    0.879±0.006         0.252±0.003        0.628±0.008
           PRN2                 0.329±0.013     0.169±0.005     0.160±0.010    0.879±0.006         0.136±0.003        0.743±0.007
Table 3: Prediction of vowel onsets (mean oscillator output) for different oscillator models and dataset 2.
                                                phrase data                                    regular control data
                                prediction at   prediction at    difference    prediction at       prediction at       difference
                                 foot event      other times                    foot event          other times
            PAO                 0.307±0.011     0.293±0.004     0.015±0.013    0.344±0.019         0.281±0.006        0.063±0.024
            PRO                 0.376±0.020     0.358±0.005     0.018±0.020    0.470±0.026         0.372±0.006        0.098±0.029
            PRN1                0.255±0.021     0.236±0.016     0.019±0.012    0.558±0.031         0.245±0.014        0.313±0.024
            PRN2                0.255±0.021     0.172±0.013     0.083±0.014    0.558±0.031         0.172±0.012        0.386±0.026
Table 4: Prediction of foot events (mean oscillator output) for different oscillator models and dataset 2.
                                                                      1724

Figure 1: Example output trajectories (blue) and vowel onsets (black) for syllables in the German phrase “... eine Urlaubsreise
mit meiner Familie, also ich war mit meiner Schwester und meiner Mutter dort.” (“... a vacation trip with my family, that is, I
was there with my sister and my mother.”) (a) PAO model, (b) PRO model, (c) PRN1 model, (d) PRN2 model.
                                                            1725

   The parameters used for the oscillator models seem to be         Gibbon, D., & Fernandes, F. R. (2005). Annotation-mining
reasonable and have been found by looking at the literature                for rhythm model comparison in brazilian portuguese.
(PAO and PRO models) or preliminary experiments (PRN                       In Proceedings of interspeech.
model). However, it cannot be totally excluded that other pa-       Hawkins, S. (2003). Roles and representations of systematic
rameter settings will lead to higher performance. Therefore,               phonetic fine detail in speech understanding. Journal
we searched the space of the most important parameters of                  of Phonetics, 31, 373-405.
the PAO and PRO models for better performance on a ran-             Jones, M. R. (1990). Learning and the development of ex-
domly selected subset of the data for one conversation using               pectancies: an interactionist approach. Psychomusicol-
evolutionary algorithms (De Jong, 2006) (details and results               ogy, 9, 193-228.
not shown here). While the evolutionary algorithm found dif-        Kopp, S., Allwood, J., Grammer, K., Ahlsen, E., & Stock-
ferent parameter settings that performed better on the training            meier, T. (2008). Modeling embodied feedback with
set, the subsequent performance on the complete set of data                virtual humans. In I. Wachsmuth & G. Knoblich (Eds.),
was only marginally better in most cases, and did not change               Modeling communication with robots and virtual hu-
any of the previously mentioned conclusions.                               mans. Springer-Verlag Berlin Heidelberg.
   Future work will include using coupled syllable and foot         Large, E. W. (1994). Dynamic representation of musical
oscillators, and possibly using evidence for vocal activity                structure. Unpublished doctoral dissertation, The Ohio
rhythms, i.e., cycles in pauses and hesitations in dialogue,               State University.
to model the structure of the interpausal units (McGarva &          Large, E. W. (2008). The psychology of time. In S. Grondin
Warner, 2003; Merlo & Barbosa, 2010). Ultimately, we aim                   (Ed.), (chap. Resonating to musical rhythm: Theory
to use the output from entrained oscillators to control the                and experiment). West Yorkshire: Emerald.
timing of backchanneling and turn-taking in artificial embod-       Large, E. W., Almonte, F. V., & Velasco, M. J. (2010).
ied conversational agents (Kopp, Allwood, Grammer, Ahlsen,                 A canonical model for gradient frequency neural net-
& Stockmeier, 2008; Poppe, Truong, Reidsma, & Heylen,                      works. Physica D, 239, 905-911.
2010).                                                              Loehr, D. (2007). Aspects of rhythm in gesture and speech.
                                                                           Gesture, 7, 179-214.
Acknowledgments This research is kindly supported by
                                                                    Malisz, Z., Inden, B., Wachsmuth, I., & Wagner, P. (2012).
the Deutsche Forschungsgemeinschaft (DFG) in the Collab-
                                                                           An oscillator based modeling of german spontaneous
orative Research Center 673.
                                                                           speech rhythm. In Perspectives on rhythm and timing
                          References                                       workshop. Glasgow, UK.
                                                                    McAuley, J. D. (1995). Perception of time as phase.
Barbosa, P. A. (2006). Incursões em torno do ritmo da fala.                Unpublished doctoral dissertation, Indiana University,
       Campinas: Pontes.                                                   Bloomington.
Boersma, P., & Weenink, D. (2012). Praat: Doing phonet-             McGarva, A. R., & Warner, R. M. (2003). Attraction and
       ics by computer. version 5.3.04. Retrieved 30 January               social coordination: Mutual entrainment of vocal ac-
       2012, from http://www.praat.org/                                    tivity rhythms. Journal of Psycholinguistic Research,
Browman, C. P., & Goldstein, L. (1992). Articulatory phonol-               32, 335-354.
       ogy: An overview. Phonetica, 49, 155-180.                    Merlo, S., & Barbosa, P. A. (2010). Hesitation phenomena: a
Buschmeier, H., Malisz, Z., Włodarczak, M., Kopp, S., &                    dynamical perspective. Cognitive Processing, 11, 251-
       Wagner, P. (2011). ‘Are you sure you’re paying atten-               261.
       tion?’ – ‘Uh-huh’. Communicating understanding as a          Nerlich, U. (1998). Rhythmische Segmentierung sprach-
       marker of attentiveness. In Proceedings of Interspeech              licher Instruktionen in einem Mensch-Maschine-
       2011 (pp. 2057–2060). Florence, Italy.                              Kommunikations-Szenario. Unpublished master’s the-
Buzsáki, G., & Draguhn, A. (2004). Neuronal oscillations in                sis, Faculty of Technology, Bielefeld University.
       cortical networks. Science, 304, 1926-1929.                  Poppe, R., Truong, K. P., Reidsma, D., & Heylen, D. (2010).
Condon, W. S. (1986). Rhythm in psychological, linguistic                  Backchannel strategies for artificial listeners. In Pro-
       and musical processes. In J. Evans & M. Clynes (Eds.),              ceedings of the intelligent virtual agents conference.
       (p. 55-77). Springfield, Ill.: Thomas.                       Tuite, K. (1993). The production of gesture. Semiotica, 93,
Cummins, F., & Port, R. (1998). Rhythmic constraints on                    83-106.
       stress timing in english. Journal of Phonetics, 26, 145-     Wachsmuth, I. (1999). Communicative rhythms in gesture
       171.                                                                and speech. In Proceedings of the international gesture
De Jong, K. A. (2006). Evolutionary computation — a unified                workshop on gesture-based communication in human-
       approach. MIT Press.                                                computer interaction.
Ghitza, O., & Greenberg, S. (2009). On the possible role            Wilson, M., & Wilson, T. P. (2005). An oscillator model of
       of brain rhythms in speech perception: Intelligibility              the timing of turn-taking. Psychonomic Bulletin and
       of time-compressed speech with periodic and aperiodic               Review, 12, 957-968.
       insertions of silence. Phonetica, 66, 113-126.
                                                                1726

