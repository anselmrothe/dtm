UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Pedagogical agents that support learning by explaining: Effects of affective feedback
Permalink
https://escholarship.org/uc/item/3q92z8bz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)
Authors
Hayashi, Yugo
Matsumoto, Mariko
Ogawa, Hitsohi
Publication Date
2012-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                     University of California

                        Pedagogical agents that support learning by explaining:
                                              Effects of affective feedback
                                          Yugo Hayashi (yhayashi@fc.ritsumei.ac.jp)
                                      Mariko Matsumoto (is039081@ed.ritsumei.ac.jp)
                                      Hitoshi Ogawa (ogawa@airlab.ics.ritsumei.ac.jp)
                             College of Information Science and Engineering, Ritsumeikan University,
                                         1-1-1 Nojihigashi, Kusatsu, Shiga, 525--8577, Japan
                             Abstract                                 2001; Okada & Simon, 1997). It has also been demonstrated
                                                                      that the use of strategic utterances such as asking for
  The present study investigates how a conversational agent can
  facilitate explanation activity. An experiment was conducted        explanation or providing suggestions can stimulate
  where pairs of participants, who were enrolled in a                 reflective thinking and meta cognition involved in
  psychology course, engaged in a task of explaining to their         understanding a concept. Playing different roles during
  partners the meanings of concepts of technical terms taught in      explanation is also said to help problem solvers reconstruct
  the course. During the task, they interacted with a                 external representation and concepts (Shirouzu, Miyake, &
  conversational agent, which was programmed to provide               Masukawa; 2002).
  back-channel feedbacks and metacognitive suggestions to
  encourage and facilitate conversational interaction between
                                                                        Studies that are discussed above suggest that how well one
  the participants. Results of an experiment suggested that           can explain is the key to understanding and learning of a
  affective positive feedbacks from conversational agent              concept. However, explanation becomes successful if
  facilitate explanation and learning performance. It is              people have difficulties in retrieving and associating
  discussed that a conversational agent can play a role for           relevant knowledge required for explanation activity.
  pedagogical tutoring and triggers a deeper understanding of a       Researches on collaborative learning have reported that
  concept during an explanation.                                      these difficulties rise among novice problem solvers
  Keywords: pedagogical         agents;  explanation  activities;     (Coleman, 1998; King, 1994). Also, it may not help learn a
  affective learning.                                                 concept if people cannot communicate with each other as in
                                                                      when, for example, they use technical terms or phrases
                         Introduction                                 unknown to others (Hayashi & Miwa, 2009).
The ever-evolving information and communication                         It is assumed that one of the ways to help collaborative
technology has made it possible to support human cognition            problem solvers is to introduce a third-person or a mentor
by using systems which aids human interaction. Many                   who can facilitate the task by using prompts such as
researchers in computer science are tackling on the theme of          suggestions and back-channels. However, it is often difficult
developing embodied conversational agents to support                  for one teacher to monitor several groups of collaborators
education. Recent studies on cognitive science and learning           and to supervise their interaction during explanation in
science show that collaborative learning facilitates                  actual pedagogical situations. Recently there are studies
understanding or acquisition of new concepts depends                  which demonstrate that the use of conversational agents that
greatly on how explanations are provided. In this study a             act as educational companions or tutors can facilitate
collaborative activity of making explanation is                       learning process (Holmes, 2007; Baylor & Kim, 2005).
experimentally investigated by using a conversational agent           Unfortunately, it has not been fully understood if and what
that serves as a teaching assistant. The goal of the                  kinds of support by such agents would be more helpful for
experiment is to find out what kind of feedback from the              collaborative learners. In this paper, the author will further
agents is most conducive to successful learning performance.          investigate this question through the use affective
                                                                      expressions.
                        Related work
                                                                      Pedagogical conversational agents as learning
                                                                      advisers
Explanations during collaborative activities
                                                                      Researchers in the field of human computer interaction have
Number of studies on collaborative problem solving in
                                                                      conducted a number of experimental studies which involve
cognitive science revealed how concepts are understood or
                                                                      the use of pedagogical agents (e.g. Kim, Baylor & Shen,
learned. Researchers have shown that asking reflective
                                                                      2007; Reeves & Nass, 1996; Graesser & McNamara, 2010).
questions for clarification to conversational partners is an
                                                                      One point to be taken into consideration in studies of human
effective interactional strategy to gain a deeper
                                                                      performance is the affective factor. This factor influences
understanding of a problem or a concept (e.g. Chi, Bassok,
                                                                      people's performance in either negative or positive ways and
Lewis, Reimann, & Glaser, 1989; Miyake, 1986; Salomon,
                                                                  1650

several studies reported that such factors are especially          rest of the two words to his/her partner. This was repeated
important in learning activities (Baylor & Kim, 2005). For         but the words they explained the second time were different
example, Bower & Forgas (2001) revealed that positive              from those in the first time. All participants received the
moods can increase memory performance. Mayer & Turner              same prompts of suggestions from the agent on how
(2002) also demonstrated that positive state of mind can           explanations should be given and how questions should be
improve text comprehension.                                        asked about the concepts. After this pre-test, they took the
  Moods may affect the performance of human activities             same test in the post-test. The descriptions of the concepts
both verbally and non-verbally. In a study by Kim, Baylor,         they provided in the post-test were compared with those of
& Shen (2007), which examined how positive and negative            the pre-test to analyze if the participants gained a deeper
comments from conversational agents affect learning                understanding of the concepts after the collaborative activity.
performance, a pictorial image of an agent was programmed          The whole process of the experiment took approximately 80
to project a textual message to the participant; in the            minutes (see Figure 1).
positive condition, a visual avatar produced a short
comment like "this task looks fun", while in the negative                                               START
condition, it produced a short comment like "I don't feel like
doing this, but we have to do it anyway". The results                                                  Pre-test
showed that the conversational agents that provided the
                                                                                                   (20 minutes)
participants with comments in a positive mood furnished
them with a higher motivation of learning.                                                          Explanation
  The studies discussed above suggest that the performance                                         (10 minutes)
of explanation would also be enhanced if suggestions are
given in positive mood either verbally or through visual                                     No        For trial >= 4
feedbacks.                                                                                                 trial ++
                                                                                                                     Yes
Research Goal                                                                                       Post-test
This study investigates how conversational agents can                                             (20 minutes)
facilitate understanding and learning of concepts. This paper
will focus on an agent which has a role that assists paired                                              END
participants to explain concepts to their partners during the
collaborative peer-explanation activity. A natural language
processing agent monitored the interaction between the                                    Figure 1: Experiment flow.
participants and provided prompts to them which were
generated by pre-defined rules. The research goal of this
study is to understand if the use of positive expressions          Experimental system
provided by a conversational agent facilitates collaborative
                                                                   In the experiments, a computer-mediated chat system was
learners' understanding of concepts.
                                                                   set up through computer terminals connected via a local
                                                                   network and the interactions of the participants during the
                           Method                                  activity were monitored. The system used in the
                                                                   experiments was programmed in Java (see Figure2).
Experimental task and procedure
The experiment was conducted in a room where the
computers were all connected by a local area network.
Participants were given four technical terms presented on                                Server
the screen. They were: 'schema', 'short-term / long-term
memory', 'figure-ground reversal', and 'principle of
linguistic relativity', which had been introduced in a
psychology class. Along with the keyterms, a brief
explanation of the concept was described by a few sentences.
They were asked to describe the concepts of these words.
After this pre-test, they logged in the computer and used the
program installed in a USB flash drive (see the next section
for detail). The pairs of participants were communicated                                                                 Client program 2
                                                                       Client program 1         Pedagogical
through the chat program and one of the paired participants            (Student A)              Conversational Agent
                                                                                                                         (Student B)
was instructed to explain to their partner the meanings of the
words presented on their computer screen one by one. When
two of the four concepts were explained to their partner,                               Figure 2: Experimental Setting.
they switched the roles and the other partner explained the
                                                               1651

                                                                                                     are being used in the explanation task (e.g. "I think that a
                                                                                                     schema is some kind of knowledge that is used based on
        Concepts for                                ‘Schema’                                         one's own experience." (detected key words are shown in
        explanation                Schemata influence our attention, as we are more likely to
                                       notice things that fit into our schema. If something
                                   contradicts our schema, it may be encoded or interpreted          bold italic). Next, the extracted keywords are sent to the
  Brief explanation                as an exception or as unique. Thus, schemata are prone to
                                    distortion. They influence what we look for in a situation.      working memory in the generator and processed by the rule
  (normative description)            They have a tendency to remain unchanged, even in the
                                   face of contradictory information. We are inclined to place       base, where various types of rule-based statements such as
                                        people who do not fit our schema in a "special" or
                                   "different" category, rather than to consider the possibility     'if X then Y' are stored to generate prompt messages (if
      Dialogue history                            that our schema may be faulty.
                                                                                                     there are several candidates of matching statements for the
      (inputs and outputs                                                                            input keywords, a simple conflict-resolution strategy is
      from participants)                                                                             utilized). When the matching process is completed, prompt
                                                                                                     messages are selected and sent back to the working memory
                                                                                                     in the generator. The messages generated by the rule base
     Explanation input                                                                               are also sent to the motion handler module to activate an
                                                                                                     embodied conversation agent, a computer-generated virtual
                                                                                                     character which can produce human-like behaviors such as
                                                                                                     blinking and head-shaking. Each output message is textually
              Figure 3: Screenshot of the chat system.                                               presented in a text filed on the computer display (See next
                                                                                                     sections for details).
  The system consists of three program modules of Server,                                              Several types of output messages are presented by the
Chat Clients, and Agent, all of which are simultaneously                                             agent depending on the content of input text from the
activated. Multi-threads are used so that the server program                                         participants (see Table 1 below for examples). Only short
can send all messages to the clients' chat system and the                                            back-channels are sent when there are several related key
agent simultaneously.                                                                                words in a text (Type 1 output); Messages of
  The pedagogical agent used in this study is a simple rule-                                         encouragement are given when the agent detects some
based production system typical of artificial intelligence. It                                       keywords related to the target concept (Type 2 output, Type
is capable of meaningfully responding to input sentences                                             3 output, Type 4 output).
from users and consists of three main modules: Semantic
Analyzer, Generator, and Motion Handler (see Figure 4).                                                      Table 1: Types of output messages from the agent.
                      Generator Module                                                                    Type of messages                      Examples
                                                                                                     Input messages (Detected        "I think that a schema is some
                                                                                                     key words are in Bold)          kind of knowledge that is
                Working
                                                          Rule                                                                       used based on one’s own
                Memory                                                                                                               experience."
                                                          Base
                                                                                                     Output: type 0                  "That's the way", "Keep
                                                                                                     Back-channels                   going! ", "Um-hum"
                                                                                                     Output: type 1                  "Wow! You used a few very
                                                                                                     Positive Suggestion (Used       good keywords. That's great!
                                                                                                     in Positive condition)          It is better if you explain it
                                                                                                                                     from a different perspective!"
               Semantic                            Motion                                            Output: type 2                  "Well,     you     used    few
               Analyzer                           Handler                                            Negative Suggestion(Used        keywords. That is not enough.
                Module                            Module                                             in Negative condition)          It is not satisfactory unless
                                                                                                                                     you explain it from a different
                                                                                                                                     perspective."
                                                                                                     Output: type 3                  "You used few important
                                                                                                     Normal Suggestion (Used         keywords. Try to explain from
                                                                                                     in Neutral condition)           a different perspective."
                input                            output
                                                                                                     Participants and conditions
                                                                                                     In this study, 90 participants participated in the experiment.
           Figure 4: Architecture of message production.                                             The participants were all undergraduate students who were
                                                                                                     taking a psychology course and participated in them as part
  Textual input of all conversational exchanges produced by                                          of the course work. They were randomly assigned to three
paired participants is sent to the semantic analyzer of the                                          conditions, which varied with respect to how prompts of
conversation agent. The semantic analyzer then scans the
text and detects keywords relevant to the concepts if they
                                                                                                 1652

suggestions were presented and how conversational agents          conditions (see Figure 5). The vertical axis in Figure 5
were used (see the sections below for details).                   represents the average scores of the tests for the three
 To find out how affective factors influence the task of          groups at the times of pre- and post- tests. A statistical
explanation, three types of avatars were created: one is the      analysis was performed using a 2 x 3 mix factor ANOVA
positive agent with friendly facial expression which was          with the two evaluation period (the pre-test vs. the post-test)
used for the "positive condition", and the negative agent         and the three conditions with different feedback (Positive vs.
with unfriendly facial expression which was used for the          Negative vs. Neutral) as independent factors.
"negative condition", and finally the neutral agent with no
facial expression which was used for "neutral condition". In                                  5
the positive condition (n = 31), the participants were given                                       positive condition   negative condition
positive suggestions, which were synchronized with the                                       4.5
facial expressions of the positive agent. In the negative                                     4    nutral condition
                                                                     Average score of test
condition (n = 28), the participants were given negative
                                                                                             3.5
suggestions, which were synchronized with the facial
expressions of the negative agent. In the nutural condition (n                                3
= 31), the participants were given suggestions without                                       2.5
emotional expressions.
 The messages were given through chat dialogue and the                                        2
virtual character moved its head gestures while the                                          1.5
participants chat on the computer (For examples of
suggestion for the conversational agent see Table 1). Since                                   1
there was odd number of participants in positive and neutral                                          pre-test               post-test
condition, one group was composed by three.
Dependant variables                                                      Figure 5: Results of the quality of the performance of learning.
To evaluate the outcome of (1) quality of the performance
of learning, and (2) interaction process, two types of             There was significant interaction between the two factors
measures were used.                                               (F(2, 87) = 3.388, p < .05). First, an analysis of the simple
  First, for the learning performance, the results of the pre-    main effect was done on each level of the feedback factor.
and post- tests were compared to find out how the                 In the Positive, Negative, and Neutral condition, the average
explanation task with different conditions facilitated their      scores in post-test was higher than pre-test respectively
understanding or learning of the concepts. For the                (F(1,87) = 254.397, p < .01; F(1,87) = 172.796, p < .01;
comparison, their descriptions were scored in the following       F(1,87) = 155.812, p < .01). Next, an analysis of the simple
way: 1 point for a wrong description or no description, 2         main effect was done on each level of the period factor. In
points for a nearly-correct description, 3 points for a fairly-   the pre-test, there was no differences between conditions
correct description, 4 points for an excellent description, and   (F(2,174) = 0.202, p = .82). Although in the post-test there
5 points for an excellent description with concrete examples.     were differences between conditions (F(2,174) = 9.094, p
It was judged that the greater the difference in scores           < .01). Further analysis on the post-test was conducted using
between the two tests the higher the degree of the effect of      the Ryan's method. Results indicate that the average score of
explanation.                                                      Positive condition was higher than Negative condition and
  Second, for the analysis of explanation process, all the        the average score of Positive condition was higher than
dialogs during the task were analyzed. The main focus of          Neutral condition respectively (p < .01; p < .01). There were
the analysis was to investigate what kind of explanations         no differences between Negative condition and Neutral
were used during their interaction. Each dialog sentences         condition (p = .51).
that included explanations were coded by the following two         The overall result suggests that the collaborative activities
categories: (1) explanations that were made by using terms        facilitated the participants' understanding or learning of the
and phrases presented by the system (see Figure 3 for an          concepts more when the positive suggestions were
example of the description), and (2) explanations that were       presented to the participants.
generated based on subjective inference. The former is
called "normative explanations". On the other hand, the           Interaction process
utterance in the latter is called "subjective explanations".      Figure 6 indicates the relationships between the usage of
                                                                  normative explanations and subjective explanations. The
                          Results                                 vertical axis represents the average ratio of each
                                                                  participant’s explanation type. The horizontal axis shows
Quality of performance                                            each of the three conditions.
                                                                   The analysis of ANOVA with the factor of explanation
The results showed that the participants' understanding of        type (normative explanations vs. subjective explanations)
the concepts improved after the explanation task in all
                                                              1653

was conducted on each condition. The results show that                                                 comments. One of the interesting finding is that, the
participants in the Neutral condition and Negative                                                     learning performance of the participants in the Negative
conditions used more subjective explanations than                                                      condition and Neutral condition were the same in this
normative explanations, respectively (F(1, 27) = 7.326, p                                              experiment. It is assumed that negative affective feedbacks
< .05; F(1, 30) = 25.116, p < .01). On the other hand, there                                           were not able to trigger such motivation and enhance
were no statistical differences between the two conditions in                                          performance as much as the Positive condition. This may be
the Positive condition (F(1, 30) = 0.46, p = .50). These                                               affected by the lack of attention to the agent. This point will
results indicate that participants in the Negative and Neutral                                         be further investigated elsewhere.
conditions made explanations mostly based on subjective
explanations.                                                                                          Awareness towards the conversational agent
                                                                                                       Studies in social psychology have suggested that work
                                     100%                                                              efficiency is improved when a person is being watched by
                                      90%                                                              someone, or, that the presence of an audience facilitates the
 Average ratio of explanation type
                                      80%                                                              performance of a task. This impact that an audience has on a
                                      70%                                                              task-performing participant is called the "audience effect".
                                      60%                                                              Another relevant concept on task efficiency, but from a
                                      50%                                              normative       slightly different perspective, is what is called "social
                                      40%                                              subjective
                                                                                                       facilitation theory". The theory claims that people tend to do
                                      30%                                                              better on a task when they are doing it in the presence of
                                      20%                                                              other people in a social situation; it implies that person
                                      10%                                                              factors can make people more aware of social evaluation.
                                       0%                                                              Zajonc (1965), who reviewed social facilitation studies
                                               Positive     Negative      Neutral
                                                                                                       concluded that the presence of others have positive
                                                                                                       motivational affects.
                                     Figure 6: Results of the type of explanation activities.            Holmes (2007) is one of the experimental studies which
                                                                                                       investigated the effects of a tutoring agent. In this
                                                          Discussion                                   experiment, an agent, which played the role of an assistant,
                                                                                                       was brought in to help a participant who explained a
Affective expressions of the conversational agent                                                      concept. In the experiment, three different environments
                                                                                                       were set up for the 'explaining activity'. They were: (1) two
The results of the experiment suggested that the greater the
                                                                                                       participants working with a text-based prompt, (2) two
positive affective expressions from the conversational agent
                                                                                                       participants working with a visual image of pedagogical
the more it can facilitate explanation activities which leads
                                                                                                       agent which produced a text-based prompt (3) one
to a deeper understanding of concepts (i.e., Positive
                                                                                                       participant working with a visual image of pedagogical
condition > Negative condition, Positive condition > Neutral
                                                                                                       agent which produced a text-based prompt (in this setup,
condition). The results of the dialogue analysis somewhat
                                                                                                       participants did not have a human co-learner and directly
support these result. That is, participants in the Negative and
                                                                                                       interacted with the agent). The result showed that the
Neutral condition used more subjective inferences and
                                                                                                       participants in the last two conditions did better than the
interpretations about the key concept instead of using
                                                                                                       first where only textual prompts were presented. It also
normative phrases, which might leaded to construction of
                                                                                                       showed that the participants in the second condition did not
misunderstandings on the concepts. On the other hand,
                                                                                                       engage in the explanation activity as much as those in the
participants in the Positive condition used normative
                                                                                                       third. The first finding of Holmes (2007) is that the
expressions that were on track. It is assumed that the
                                                                                                       participants in the last two conditions, who worked with the
affective expressions generated by the agents facilitated the
                                                                                                       agent, performed better may be attributed to the fact that
participants’ motivation to keep their attention to the
                                                                                                       their task of explanation was being watched or monitored by
computer system which provided important information.
                                                                                                       the agent. Also, the second finding that the effect of the
 These results provide more reliable findings than those
                                                                                                       agent for the participants in a pair was not as high as for
compared with experiments conducted by the authors’
                                                                                                       those directly interacting with it alone may be because the
previous work (Hayashi, 2012). In those experiments, the
                                                                                                       level of attention of the participants in the second condition
influences of affective feedbacks were examined during
                                                                                                       was not as great as that in the third condition; it may be that
collaborative activities. Unfortunately, there was no neutral
                                                                                                       the participants in the second were less conscious of the
condition and dialogue analyses were not further conducted.
                                                                                                       presence of the monitoring agent than those in the third
The present study makes it clear that positive emotions
                                                                                                       group.
expressed by a pedagogical agent facilitated explanation
                                                                                                         These results of the present study suggest that participants
activities at the interaction level. This suggests that the
                                                                                                       would do better in the task of explanation if they are more
participants might have paid more attention during the
                                                                                                       conscious of the presence of the agents or if they are given
interaction process and worked harder when they received
                                                                                                       an explicit direction to pay attention to the agent. The
positive comments than they received neutral and negative
                                                                                                    1654

results of the present experiment provide new evidence that          7. Hayashi, Y., Miwa, K. (2009). Prior experience and
the positive feed backs made by the agents can facilitate               communication media in establishing common ground during
such "audience effect".                                                 collaboration. In Proceedings of the 31th annual conference of
                                                                        the cognitive science society, 528-531.
              Conclusion and future work                             8. Hayashi, Y. (2012), On pedagogical effects of learner-support
                                                                        agents in collaborative interaction. In S.A. Cerri and B. Clancey
The present study investigated the effectiveness of the use             (Eds.): Proceeding of the 11th International Conference on
of a conversational agent in a collaborative activity, where            Intelligent Tutoring Systems (ITS2011), Lecture Notes in
paired participants explained each other the meaning of                 Computer Science, Springer-Verlag, Vol 7315, pp. 22-32.
technical terms taught in a psychology class for a better            9. Holmes, J. (2007). Designing agents to support learning by
understanding. Conversational agents were used to                       explaining. Computers & Education, 48, 523-547.
encourage and facilitate the students' interaction through          10. Kim, Y., Baylor, A. L., & Shen, E. (2007). Pedagogical agents
both verbal and visual input. The experimental results                  as learning companions: The impact of agent emotion and
suggested that the presence of a conversational agent with              gender. Journal of Computer Assisted Learning, 23, 220-234.
positive expressions can trigger a deeper understanding of a        11. King, A. (1994). Guiding knowledge construction in the
concept during an explanation.                                          classroom: Effects of teaching children how to question and
  Pedagogical agent can play several different roles for                how to explain. American Educational Research Journal. 30,
collaborative learning activities and several studies have              338-368.
looked into the effectiveness of the use of a pedagogical           12. Mayer, D, K., Turner, J,C. (2002). Discovering emotion in
agent with different roles. For example, Baylor & Kim                   classroom motivation research, Educational Psychologist. 37,
(2007) investigated the effectiveness of the use of a                   107-114.
pedagogical agent which plays the roles of an expert teacher,       13. Miyake, N. (1986). Constructive interaction and the interactive
a motivator, and a mentor (both an expert and motivator).               process of understanding. Cognitive Science. 10, 151-177.
                                                                    14. Okada, T., & Simon, H. (1997). Collaborative discovery in a
However, not much is known yet about what roles it can
                                                                        scientific domain. Cognitive Science. 21, 109-146.
play effectively. Another issue to be further investigated is
                                                                    15. Reeves, B., Nass, C. (1996). The Media Equation: How People
the effect of the personality of the agent upon these roles.
                                                                        Treat Computers, Television, and New Media Like Real People
These and other related topics need to be further studied in            and Places. New York: Cambridge University Press
future.                                                             16. Salomon, G. (2001). Distributed cognition: Psychological and
                                                                        educational considerations. New York: Cambridge University
                     Acknowledgments                                    Press
I appreciate all students who participated in this experiment.      17. Shirouzu, H., Miyake, N., & Masukawa, H. (2002). Cognitively
I also want to thank my student advisee Shin Takii                      active externalization for situated reflection. Cognitive Science.
(Ritsumeikan University) and Rina Nakae (Ritsumeikan                    26, 469-501.
University), Yuichi Mizuno (Ritsumeikan University) for             18. Zajonc, R. B. (1965). Social facilitation. Science. 149, 271-
helping me to conduct the experiment.                                   274.
                          References
1. Baylor, A. L., & Kim, Y. (2005). Simulating instructional roles
   through pedagogical agents. International Journal of Artificial
   Intelligence in Education, 15, 95-115.
2. Bower, H, G., Forgas, P, J. (2001). Mood and social memory.
   In J. P. Forgas (Ed). Handbook of affect and social cognition,
   NJ, LEA, 95-120
3. Chi, M. T. H., Bassok, M., Lewis, M. W., Reimann, P., &
   Glaser, R. (1989). Self-explanations: How students study and
   use examples in learning to solve problems. Cognitive Science,
   13, 145-182.
4. Coleman, E. B.(1998). Using explanatory knowledge during
   collaborative problem solving in science. The Journal of
   Learning Sciences, 7, 387-427.
5. Graesser, A., McNamara, D. (2010). Self-regulated learning in
   learning environments with pedagogical agents that interact in
   natural language. Educational Psychologist, 45, 234-244.
6. Gulz, A., Haake, M. (2006). Design of animated pedagogical
   agents – A look at their look, International journal of Human-
   Computer Studies, 64, 322-339.
                                                                  1655

