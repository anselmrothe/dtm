UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Processes in Diagnostic Reasoning: Information Use in Causal Explanations
Permalink
https://escholarship.org/uc/item/28x8d1hd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Billman, Dorrit
Cummings, Kirstin
Shapiro, Daniel
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         Processes in Diagnostic Reasoning: Information Use in Causal Explanations
                                            Dorrit Billman*+ (billman@psych.stanford.edu)
                                                   Daniel Shapiro* (dgs@stanford.edu)
                                         Kirstin Cummings*+ (kirstinc@ccrma.stanford.edu)
     Center for Study of Language and Information, Stanford University;* Institute for the Study of Learning and Expertise+
                              Abstract
                                                                                                Domain and Tool
  This paper presents examples of the processes people use in
                                                                             The power system of the Space Station is one of many
  generating qualitative solutions to complex diagnostic
  problems. We developed a high fidelity model of the electrical
                                                                          complex systems that require ongoing monitoring and
  power system for the International Space Station, and presented         occasional troubleshooting. A high fidelity model of how the
  scenarios of off-nominal, or fault, situations. The model               system behaves under a wide range of input conditions is a
  interface provides rich information about functional                    powerful tool for supporting these activities. In addition to
  organization of the power system, including system topology             high fidelity, a good model should be easy for people to
  and graphs of variables changing over time. We presented two            understand and reason with. A transparent model (as opposed
  versions, with system information organized hierarchically or           to a black box model) reveals the structure and relations
  displayed in a single level. Novices, who were unfamiliar with          among underlying components, which should make it easier
  the system to be diagnosed but technically sophisticated, were
                                                                          to use. In particular, transparent models support diagnostic
  asked to study the scenarios and diagnose the fault situations.
  The particular scenario reported here was designed to be
                                                                          reasoning by less expert users. Experts often have internalized
  difficult, violate users’ expectations, and require ‘thinking           detailed models of a system, which let them reason from
  outside the box.’ Users chose to view quantitative information          massive, unstructured information sets such as fluctuating
  frequently as part of developing qualitative, causal                    arrays of variable values. In contrast, less experienced
  explanations. We found sophisticated reasoning processes and            diagnosticians lack a detailed and fluent knowledge of how
  frequently correct explanations despite the difficulty of the task.     variables interact and affect each other. As a result, they
  Design successes and weaknesses are discussed.                          cannot duplicate the expert’s feat; they need information
  Keywords[trouble-shooting, diagnostic reasoning, problem solving,
                                                                          about the system from a source other than their background
  human computer interaction]                                             knowledge. Further, we believe that a tool that reveals the
                           Introduction                                   structure and function of the system being modeled would
We explore the processes people use to generate qualitative               also aid experts. This has practical value as there is
solutions for complex diagnostic problem solving. More                    sometimes need for diagnoses to be done by less expert
precisely, we trace the activity of the human-plus-computer               personnel. Economic needs to ‘do more with less’ and
system. The computer presents a large amount of quantitative              technical needs of extended duration missions will eventually
(variables) and topological (network) information. It does so             require ground personnel or astronauts to monitor systems
in a way designed to display information selectively, and to              with which they are less familiar. Training technicians in
help the person manage the complexity of information                      structured troubleshooting methods, organized around
available. We ran a process-tracing study of problem solving              functional subsystems, improves performance (Schaafstal,
and summarize here the variety of component procedures                    Schraagen, & van Berlo, 2000); we expected that our
people used in the task.                                                  diagnostic system, which presents the structure and function
   This work fits in the tradition of complex problem solving             of the underlying system, would support sophisticated
research and the tradition of analyzing the affordances of                diagnostic reasoning even by novices. Our system also
human-computer systems. Our focus is on describing the                    provides information at multiple levels of scope and
procedures people used, how the procedures exploited the                  specificity, important in supporting troubleshooting for
information available in the interface (particularly                      process control (Lindegaard, 1995).
quantitative information), and the successes and pitfalls                    Our system consists of the Power Monitor and interface
encountered. This paper reports on one problem scenario                   tools for monitoring and diagnosit. The Power Monitor is a
designed to be particularly challenging. In this scenario, the            high fidelity, transparent model of the space station power
fault is outside of the system to be diagnosed. We expected               system,. It represents the behavior of dynamic systems in
that recognizing this might require breaking expectations                 terms of an interconnected network of processes and
about the form of the solutions. Troubleshooting a scenario               variables, called a causal process model [Langley et al.,
that violates expectations is difficult, as when multiple fault           2002]. Shapiro et al (2004) describes the Power Monitor in
scenarios require abandoning expectations about solution type             detail. Here we focus on its usability and the forms of
(Patrick, Grainger, Gregov, Halliday, Handley, Fames, and                 diagnostic reasoning it supports.
O’Reilly, 1999). Such a scenario might be particularly                       The interface to the system presents two representations of
revealing about how the system supports reasoning.                        system information: a dynamic network of connected
                                                                          variables and processes, and variable graphs plotting
                                                                      262

   Figure 1: Hierarchical condition layout, with time set to Day 3, when generation is higher than predicted to compensate for
under-generation on Day 2. User has 3 variables open and is comparing the timing and nature of the discrepancy between
predicted and observed plots.
values over time. This provides much richer information than         view the desired part of the network. In both, the network
available in the current SSP monitoring system and than              changes as different processes become active: only links to
typically provided in most monitoring systems. The network           and from active processes are displayed and only active
nodes are the processes (rectangles) and variables (ovals); the      processes are highlighted. Thus, temporal navigation while
links are arrows showing causal relations. Variables are             viewing the network shows changes over time in the active
linked to the processes for which they serve as input, and           processes.
processes in turn are linked to their output variables. Thus the        Clicking on the variable oval opens the variable graphs.
causal flow of the system is shown in a network of processes         The graph displays the value of the variable (y) over time (x)
and variables. Processes and variables are flagged with a            from the beginning of the scenario, up to the current time
yellow (or red) border to mark deviation from predicted (or          step. Many variables are given both a directly observed value
out of threshold) performance.                                       and a predicted value. The predicted value is what the
  Two versions of the interface were used in the study,              variable would be if every thing were operating as planned.
although comparison between versions is not the focus here.          When the variable is as expected, the plot lines for the
In one version, the network was organized hierarchically             predicted and observed fall on top of each other. If the
(Figure 1). A top-level window showed subprocesses for the           variable is not as expected, the observed values depart from
power generation, storage, and load subsystems. These could          those predicted. Using temporal navigation while viewing a
be clicked to show the process-variable network representing         variable graph will “draw” and “erase” the plot lines over
the subsystem, which in turn might have subsystems. In the           time.
flat version (Figure 2) the network was displayed without any           In addition to the video-like temporal navigation, the
hierarchical grouping. In both cases the Power Monitor               interface provides a method for “causal navigation”. Right-
displayed the network by showing the flow of causal links            clicking on a variable or process node allows the user to show
from left to right, to the extent possible. In both cases the        and then traverse either the set of forward links or backward
network required multiple screen-areas to show the entire            links connected to that object.
layout. In the hierarchical condition, the user navigated
through the display by clicking on subsystems and arranging                                Study Method &
the open windows. In the flat condition the user navigated           Task Domain. We used this testbed to look at complex,
through the display by scrolling across the whole layout to          diagnostic problem solving by a human-machine system.
                                                                 263

Problems are scenarios in which off-nominal events -- serious           Procedure. The whole experiment lasted three hours.
or slight -- occur. A solution is a qualitative explanation of       Participants worked on six problems, plus some auxiliary
what is wrong, including identifying the root cause and the          tasks. Users received training lasting roughly 40-60 minutes.
corresponding effects. Understanding effects is an important         We taught users about the general structure and function of
index of explanation quality, and also important because side        the Space Station power system components, we explained
effects can produce ancillary damage that needs to be                and provided practice with the interface, and we gave some
addressed; for example, excessive discharge of the battery to        practice problems under normal operation conditions, such as
compensate other faults can result in damage to the battery.         identifying a good time to schedule an additional load and
   Even with very good diagnostic tools, locating and                explaining why they chose that time. Users were asked to
understanding faults in this domain can be very difficult.           talk aloud during problem solving. Work times on the
Even though the discrepancy between predicted and observed           Shadowed Panels Scenario ranged from 7 to 32 minutes;
may be clearly flagged with a yellow border around a                 users were urged to finish up after 25 minutes.
variable, it is a long way from noticing a collection of flagged        Results Summary. We summarize problem solving
variables to understanding the causal structure of the event.        outcomes to provide context for discussing the processes used
There are many system components and effects propagate               in this activity. Prior to the experiment we had identified two
over many links effects can be nonlinear because of                  simple satisficing strategies which might produce
compensatory interaction; faults can appear simultaneously at        explanations that users would find adequate. Temporal
multiple components; and the time a fault is visible may be          Precedence is a strategy of looking for the earliest component
decoupled from the time the problem is flagged (because it           to be flagged as faulty, judging that component the cause, and
may take multiple time steps to create the degree of                 all other flagged components as effects. Causal Precedence is
discrepancy necessary to trigger flagging).                          a strategy of looking for the flagged component most
   It addition to these complexity issues, problem solving is        upstream in the causal network, judging that the cause and all
particularly difficult if it requires reasoning about situations     other flagged components as effects. Remarkably, no user
beyond the presumed boundaries of the problem. People                restricted themselves to either of our simple, hypothesized
recognize in principle that information may be incomplete:           strategies; all produced deeper and more elaborated accounts,
sensors may fail and models can have errors. Nevertheless, it        and used more information. In all but one case, the user of the
is very hard to simultaneously reason about an underlying            Power Monitor system produced a relevant diagnosis; 11/12
system and “meta-reason” about one’s reasoning tools.                correctly localized the problem to the power generation
   The fault scenario we focus on in this paper is the               functions of the system. Of greatest interest, in a third of the
Shadowed Panels Scenario. It was intended to require                 cases (4/12) the diagnosis was specific and correct: reduced
“thinking outside the box,” and was the first problem                sunlight. This required “thinking outside the box” in the
presented. The scenario simulated the situation in which the         sense that these explanations located the fault outside the
solar panels are partially shaded, as from an external object        focal system about which users were being taught and given
(or a piece of the Space Station) which begins to shadow the         data. The four users were able to compose the available
panels during the daylight (insolation) period, and stops            information-gathering processes to produce a relevant, exact,
during the night (eclipse). Thus the fault was actually outside      expectation-violating diagnosis. A second measure gave users
of the target system. We thought this explanation would be           a list of possible characterizations and asked them to check
hard to discover because the training that users had just            the descriptions that applied; 10 of 12 checked “shadowing
received and the characterization of the experiment treated          the panel.”
the Space Station power system as the target system to be               The data hints that the hierarchical interface supported
diagnosed. We hoped that novice users would be able to               diagnostic reasoning better than the flat interface. All the
negotiate the diagnostic path if they were supported by the          hierarchical condition users attributed the fault to the
Power Monitor.                                                       generation system; one to misalignment of the solar panels by
   Users. Twelve users participated; six tested the interface        the gimbal system (which rotates the solar panels to point at
with the hierarchical network layout and six tested the              the sun) and five to reduced power generation; two of these
interface with the flat network layout. Our intent was to have       five focused on possible problems with shunting (deliberately
users who were motivated, skilled in technical thinking, and         reducing power generation) while the remaining three
familiar with some relevant concepts for system                      correctly concluded the panels were not getting enough sun
troubleshooting, electrical systems, circuit diagrams, and/or        due to shadowing by some object. In the flat condition, five
control systems. Users were recruited in engineering classes         users attributed the fault to generation, and one erroneously
at Stanford and on bulletin boards in the engineering                attributed the fault to unpredicted excess load. Of the five
buildings. included undergraduate and graduate students              who identified the problem as generation, three focused on
(very roughly balanced between interfaces). We wanted                shunting, one on mechanical failure within the panels, and
people to diagnose a difficult, unfamiliar problem who were          one on reduced input.
technically proficient but lacked knowledge about the                   Explanations varied considerably in depth of
particular system to be diagnosed.                                   understanding. Careful study of the protocols revealed one
                                                                     subproblem that gave us a very sensitive index of the
                                                                 264

sophistication of the user’s model. This subproblem concerns        Monitor to guide diagnosis. Participants use the graphs of
the effect that appears on Day 3 as a result of reduced power       variable values over time in sophisticated ways and in
generation on Day 2. Because of low generation on Day 2,            combination with network information. Users differ in how
the batteries were drawn down more than predicted. As a             much they rely on variable information versus tracing status
result, the power generation on Day 3 also is not normal:           information through the network.
power is over-generated in order to recharge the batteries.            Basic operations. The system supports a set of operators
Recognizing this over-generation and why it occurred                for accessing visible information, network information,
requires a fairly elaborated and accurate model of the system       variable information, and the scenario as a whole.
dynamics in the scenario. The alternative user models of this          1) Indicate and select information (standard GUI).
subproblem included a) not noticing or analyzing this less             Actions: point with cursor to indicate any information and
critical departure from normal, or b) considering it a separate     click or drag windows into position. Typical use: point to
problem, e.g., caused by an independent episode in regulating       provide a visual anchor to any information being considered.
shunting. Because all users’ attention was focused on the           Open and align windows to organize sets of information
more serious Day 2 problems, this is a difficult aspect of the      being used together.
overall problem.                                                       2a) Navigate over the network: layout-based.
    Three of the six hierarchical users reached the correct and        Hierarchical Action: open or close network subsystem
complete analysis of this sub-problem (two noted the over-          window; arrange open windows. Flat Action: scroll network
generation but had different explanations; one did not note).       subsystem window to bring desired section of network into
In contrast, no user in the flat condition had the correct          view. Typical use: to locate components marked as faulty by
model, three never noted the discrepancy (either by cursor-         their color. Additional uses: to trace links in the network; to
pointing or by comment), two noted it but provided no               check what processes are active at a given time.
explanation, and one provided an incomplete explanation.               2b) Navigate over the network: causal links.
Developing the correct and complete model depended on a                Action: right click to choose forward (effects) or backward
complex comparison. All users who discovered the correct            (causes). Clicking on the tag for component X (variable or
solution compared the relation between predicted and                process) shows all components linked backward or forward;
observed values on one variable with the predicted-observed         clicking on a tag highlights and displays the component in the
relation for one or more additional variables. Further, the         network. Typical use: to find candidate effects or causes
solution required organizing the needed information:                linked to a fault-flagged node.
gathering operations and building an integrated model                  3) View variable values.
without becoming confused, disoriented, or overwhelmed.                Action: click on variable oval or move graph into view.
                                                                    Typical use: check the status of a variable. Often used in
    What Processes Generated the Explanations?                      comparisons.
   Solving these diagnostic problems requires several types of      4) Navigate through scenario time. Actions: click to play;
process. The user must detect a fault, determine the scope of       click to stop; click to move 1 time step; drag to target time-
the problem in terms of the elements and time span involved,        step. Typical use: play scenario through for initial viewing;
and understand the causal relations among these elements            play or drag over focal time of failure; step through critical
over this period. The user must navigate through an enormous        period.
amount of potential information in order to find the                   Composed Processes. The basic operations described
information that is relevant to the circumstance at hand. This      above were composed into more complex, goal directed
requires understanding the information, integrating it to form      procedures. We identified six of the processes that people
an explanation, and modifying the explanation until either it       used to gather and reason with information. These are
seems satisfactory or further improvement seems unlikely.           presented roughly in order of the complexity of information
We focus our attention on the information gathering                 being used in reasoning.
processes because these are the ones the interface was                 1) Assess Network Status: View Fault-flagged
designed to support, and hence are the most observable. Our         Components. For many components, the model generated
goal here is to sketch a taxonomy of the processes closely tied     enough information to flag a component (by changing its
to gathering information,                                           color) if it was off-nominal. People used this information to
   We summarize here the basic operations supported by the          detect the occurrence of a problem, to give an impression of
interface for accessing information. We then focus on the           severity and change of severity over time, to bound the
more complex processes (composed of basic operations) that          problem in terms of components involved, and to select
access and select information in the service of relational          variables for function-level viewing.
reasoning. Relational reasoning is a critical process because          2) View Variable Function: Use Value-over-Time
it is both closely linked to observable operations of               Representation of Variables. People used the displays of
information gathering, and is a key method by which                 variable values plotted over time to reason in more detail
information is organized to build a causal explanation.             about individual variables than supported by the network-
   From a complementary perspective, these processes show           level view.
that users are capitalizing on the affordances of the Power
                                                                265

   a) Select variables for monitoring. Users checked the              the possibility that excess demand was contributing to the
day/night variable to establish the overall pattern of activity       problem.
for the power system. Similarly, they used the battery-
charging graph to track the high-level power flow of the
system. In the hierarchical condition, participants used the
top-level window to select variables for monitoring, even
though these variables were never flagged red or yellow.
Interestingly, four of six hierarchical users opened unflagged,
high-level variables from this window, apparently with a
goal of monitoring or understanding the system rather than
reacting to a particular problem variable
   b) Diagnose from function shape. Users also studied the
shape of the function to make very specific inferences. For
example, one user used the step-function contour of the
SolarPowerOut graph, at the point that arriving sunlight is cut
and solar generation drops, to reason that the probable cause
of the change was something outside the system:
   “Here, at the beginning it goes as expected, and then               Figure 2. Reasoning about the discrepancy between predicted
suddenly, it drops. (pause) Things usually don't happen like          and observed on a single variable. This user rarely opened
this, like, it doesn't suddenly go into a right angle. It must be     multiple variables at once, but worked through a series of off-
some kind of external thing.”                                         nominal variables.
    3) Assess Discrepancy from Expected: Use Predicted
Value Plotted with Actual Value. The availability of the plots           4) Comparing Variables: Multiple Variables in View
of predicted values (and thresholds, when available), as well         Simultaneously. Users opened multiple variable graphs at
as actual values, supports a number of additional reasoning           once, and compared them. Comparison was indicated both
activities.                                                           by talking aloud and by pointing to corresponding parts of
   a) Scoping the problem. Users examined the paired plot             two graphs.
lines to identify the time when one variable diverged from               a) Reference Comparisons. Many users related a reference
predicted value. They identified the point when ‘things return        variable to a second variable in order to develop a more
to normal’, using this to bound the time scope of a problem.          integrated and coherent model of what was happening.
   b) Type of Discrepancy. Users also determined the nature           Several users viewed the day/night graph to interpret what
of the departure from a normal value, constraining the nature         was happening in other graphs, such as SolarPowerOut.
of the problem. At the end of Day 2, many users studied the           BatteryCharging was also used this way, as were the SOC
discrepancy in SolarPowerOut to reason about the nature of            (state of charge of the batteries) graphs.
the generation problem, with screens arranged as in Figure 1.            b) Parallel Parts Comparisons. Users also compared the
For example, immediately after the point where the solar              variables of analogous parts to see if a fault was local to one
power drops, one user opened IOBatAmps (input/output                  part or general to the system. For example, many users
Battery Amperes), and noted “here’s a spike here [plays               selected one variable, such as SOC (state of charge), for each
scenario] ... it’s lower than expected.” One particularly             of the three batteries. If the function looked the same for all
interesting case is the examination of SolarPowerOut when             three, users concluded that the problem was not specific to
the generation on the third day is higher than expected, in           one battery, but originated outside and upstream of the
order to compensate for the battery discharge on the second           individual batteries. Users then monitored variables from just
day. One user selected SolarPowerOut, looked at Day 3,                one battery to track all three. Several users also did this in an
started to say it was again too low, did a double take, and then      analogous situation with two variables in the generation
corrected himself to say the power generation was now too             system.
high.                                                                    5) Comparing Comparisons of Variables: Relating the
   c) Hypothesis Rejection. Comparison of actual to predicted         Predicted to Observed Pattern in One Variable to Other
values also serves the very important function of allowing            Variables. The variable representation supports a still more
users to cleanly test and reject hypotheses. For example, once        powerful type of reasoning, critical to understanding causal
they had determined that generation was lower than it should          structure of the system. Users compared how and when one
be, several users hypothesized that the gimbal system might           variable departs from predicted value with how a second
be responsible, and checked the gimbal variables. Finding             variable departs from its predicted value in order to make
that the actual values matched the predicted was a sufficient         complicated inferences about causal dynamics. To score
and compelling basis for rejecting the hypothesis that                behavior as “comparing comparisons” the user needed to
alignment of the panels by the gimbal was responsible for the         relate predicted-observed information in one graph to
problem. A few users also checked load variables to reject            predicted-observed information in the other, either by
                                                                      explicitly pointing between corresponding points on the two
                                                                  266

graphs, or relating the two variables verbally. An example                                       Conclusions
screen layout is shown in Figure 2.                                       An interface providing quantitative information about
   Six users clearly did this (five in hierarchical, one in flat);     variables and structural information about causal relations
two additional (flat) users made comparisons between some              allowed inexpert users to show sophisticated and successful
variable and the binary day/night variable; two users (flat)           diagnosis. Performance occurred in an area where human
never made multi-variable function comparisons and for two             deficiencies are often conspicuous, especially in the absence
users activity was ambiguous but did not clearly show                  of deep knowledge of the task. The study was conducted in
comparison. Users did these comparisons to determine which             the context of assessing one specific, important task. More
variable deviated from its predicted value first, and also to          broadly the findings demonstrate successful reasoning with
understand and reason about the compensatory relation                  multi-variate, quantitative function information to develop
between variables.                                                     causal explanations of problems in complex, unfamiliar
   This user had opened SOCBattery1, SOCBattery2, and                  systems. They illustrate the merits of designing tools for
SolarPowerOut through the completion of Day 3.                         complex diagnosis that provide both rich topological and rich
   “There was a deficit in solar power out [points to Day 2].          quantitative information. Further, our findings suggest that
But here we have surplus [Points Day 3; pause] that could              the hierarchical interface supported a deeper causal
cure [points SOC Day 3] the problem of battery, to go back to          understanding. Future analysis will identify more about the
its original predicted level.”                                         frequency and circumstances of using the various reasoning
   6) Inferences from Process Information. Information about           processes identified here.
processes seemed to be harder to use than information about                                 Acknowledgments
variables. Users did not always make the appropriate
                                                                       Funding by Grant NCC 2-1220 from NASA Ames Research
inferences about processes. Specifically, users might attribute
                                                                       Center. Thanks to Mei Marker for implementation & design
a fault to a process even when that process was not flagged.
                                                                       support; Tamar Shinar and Clayton Brown for system
For example, several users concluded that the fault lay in
                                                                       development; Rick Alena for NASA expertise, Pat Langley
shunting because the process ShuntSolarPower was upstream
                                                                       for the underlying process modeling concept.
of the problematic variable SolarPowerOut. This conclusion
is suspect because the process was not fault-flagged. It would
have been flagged if the expected input and output relations                                      References
were not being maintained.
   In contrast, noticing that this process was normal was the          Langley, P., Sanchez, J., Todorovski, L., & Dzeroski, S.
critical piece of evidence for one user to hypothesize that the            (2002). Inducing process models from continuous data.
problem must lie outside the system itself. This is one of the             Proceedings of the Nineteenth International Conference
most sophisticated pieces of reasoning we observed, and                    on Machine Learning (pp. 347–354). Morgan Kaufmann.
critically exploits the information available about processes.         Shapiro, D., Billman, D., Marker, M., & Langley, P. (2004).
[Here the screen layout was similar to that in Figure 1, but the           A Human-Centered Approach to Monitoring Complex
cursor and attention were focused on the lower left window.                Dynamic Systems. Final Report, NASA Grant NCC2-
The rectangular processes were all showing normal, but the                 1220. Institute for the Study of Learning and Expertise,
“downstream” variables were yellow. User had checked the                   Palo Alto, CA.
gimbal system, and concluded that it was fine.]                        Lindgaard & Gitte (1995). Human performance in fault
   “They [the processes] are not lighting up either, uh,                   diagnosis: Can expert systems help?‫ ت‬Interacting with
providing output for a given input. So, [sighs, pause] ad                  Computers Special Issue: Australasian special issue: II
input equals bad output. Right input. [very long pause] All I              United Kingdom Elsevier Science, 7(3), 254-272.
can say is they’re not getting enough sun. At this point.”             Patrick, J., Granger, L., Gregov, A., Halliday, Handley,
   Problems. Despite the successes reported here, the                      Fames, & O’Reilly (1999). Training to break the barriers
majority of users did not find and correctly integrate all the             of habit in reasoning about unusual faults. Journal of
relevant information the system had to offer. Some users                   Experimental Psychology, 5(3).
became lost or exhausted in the process. They might have               Schaafstal, A., Schraagen, J., & van Berlo, M. (2000).
known they did not understand everything but were uncertain                Cognitive task analysis and innovation of training: The
how to proceed. As well as showing that people can make                    case of structured troubleshooting. Human Factors, 42(1),
use of the resources offered in this interface, the study points           75-86.
to limitations of the design. The design provides an excellent
model of the system being diagnosed, but it does not directly
model or support the users’ activity in solving the problem.
For example, there is no support for keeping track of user-
generated information: variables that have been examined,
anomalies detected, hypotheses formed, or explanatory gaps
remaining.
                                                                   267

