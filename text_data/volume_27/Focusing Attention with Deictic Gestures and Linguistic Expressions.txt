UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Focusing Attention with Deictic Gestures and Linguistic Expressions
Permalink
https://escholarship.org/uc/item/201422tj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Bangerter, Adrian
Louwerse, Max M.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

               Focusing Attention with Deictic Gestures and Linguistic Expressions
                                            Max M. Louwerse (mlouwers@memphis.edu)
                                        Department of Psychology / Institute for Intelligent Systems
                                                            Memphis, TN 38152 USA
                                           Adrian Bangerter (adrian.bangerter@unine.ch)
                                                        Groupe de Psychologie Appliquée
                                                        CH - 2000 Neuchâtel, Switzerland
                              Abstract                                 communication. Gesture is thereby part of the language use.
                                                                       Evidence for this account comes for instance from Özyürek
   Comprehension and production of text and discourse do not           (2002) who showed that speakers change orientation of their
   solely depend on linguistic expressions, but also on the            gestures dependent on their hearers. However, these three
   physical context. The questions addressed in this study are 1)
                                                                       different accounts investigate the production of gestures. An
   whether deictic gestures are substitutable for deictic
   expressions, and 2) whether deictic gestures establish joint
                                                                       important question that remains is how addressees perceive
   attention. An eye tracking experiment investigated the effect       these gestures. According to the first two accounts the effect
   of referring expressions and gestures on various aspects of         gestures have on the addressee is irrelevant, according to the
   attention. Results indicated that deictic gestures substitute for   third account there is an immediate impact.
   location descriptions. Furthermore, the manipulation of the           There is strong evidence that gesture is intrinsically related to
   synchrony between gesture and speech showed that hearers            (symbolic) language processing (Butterworth and Morrisette,
   benefit from focusing of visual attention.                          1996). For instance, 90% of all gestures occur when we speak
                                                                       (McNeill, 1992). Furthermore, there are close ties between
                                                                       gesture and language development (Butcher & Goldin-Meadow,
                          Introduction                                 2000). Also, humans are the only species that gesture
   Understanding and production of naturally occurring                 (Butterworth, 2003; Povinelli, Bering, Giambrone, 2003). At
language does not solely rely on linguistic modalities like            the same time gestures are very different than linguistic cues.
content, prosody and text or dialog structure. It also very            For instance, despite the fact that interlocutors rely on cues from
much relies on non-linguistic modalities like eye gaze,                gestures, particularly when the speech is ambiguous (Thompson
facial expressions, body posture and gestures. It seems that           & Massaro, 1996) or when the environment is noisy (Rogers,
gestures fulfill an important supportive role in bringing              1978), they are often unable to remember what hand gestures
about the communicative project: everybody uses them,                  they have seen (Krauss, Morrell-Samuels, et al. 1991). Gestures
whether they are pointing out directions on the map,                   thus seem to fulfill an important but subtle function: They have
emphasizing a point they are trying to make, whether they              close ties to the linguistic system and seem to be intrinsically
are in a face-to-face argument or chatting on a cell phone.            integrated with it, at the same time there are differences in
  So why do we gesture? There are several explanations                 production and understanding. An important research question
that are not necessarily mutually exclusive. According to              is therefore what the relation is between gestures and linguistic
one account, we gesture to facilitate lexical access                   expressions.
(Butterworth & Beattie, 1978; Rime & Schiaratura, 1991).                 It is important to keep in mind that we have a large range of
The timing gap between a gesture and an unfamiliar word                gestures available. Kendon (1988) nicely places hand gestures
is larger than between a gesture and a familiar word                   along a continuum from 1) gesticulation, 2) language-like
(Morrel-Samuels & Krauss, 1992). Furthermore, gesture is               gestures and 3) emblems to 4) sign languages. Moving from left
associated with fluent speech: when the speech is disrupted,           to right along the continuum gestures are replacing the role of
like in stuttering, the gesture is halted (Mayberry & Jaques,          speech; hardly so in gesticulation, very much so in sign
2000). According to a second account, gestures facilitate              language. This paper uses gesture to solely refer to
thinking (Goldin-Meadow, 2003; McNeill, 1992). Gesture                 gesticulation. Within gestures different types can be identified
and speech are coexpressive manifestations of one                      (Ekman & Friesen, 1969; Goldin-Meadow, 2003; McNeill,
integrated system. They form complementary components                  1992). Generally, four categories are distinguished: 1) iconic
of one underlying process and thereby help organizing                  gestures that mimic the object being represented through the
thought. Indeed, children’s performance on counting tasks              gesture (making sawing movements when talking about sawing
improves when they gesture (Alibali & DiRusso, 1999).                  a tree), 2) concrete deictic gestures (pointing at a painting when
According to both of these accounts, gestures help speakers            talking about the Rembrandt’s Nightwatch), 3) abstract deictic
but not necessarily hearers. By a third account, gestures              gestures (gesturing from left to right saying “from the beginning
support communicative joint activities, that is, they are              to the end”); 4) beat movements (used in the rhythm of the
informative for hearers (Clark, 1996). The speaker and                 speech or to mark important intonational boundaries). In this
hearer are participating in the joint project of                       paper we will focus on concrete deictic gestures
                                                                     1331

                      Deictic Gestures                            reference resolutions. The effects of pointing and linguistic
We have earlier argued that gestures and language are             feature and location descriptions were investigated using eye-
intrinsically linked. In particular, concrete deictic gestures    tracking methodology.
nicely map onto deictic expressions like “this” and “that”,
“these” and “those”, “here” and “there”. Thus, they seem to                                 Experiment
substitute particularly well for certain linguistic               The current study investigates the effects of referring
expressions, especially spatial expressions. At the same          expressions and pointing gestures on the addressee’s attention.
time, deictic gestures form indices to individual things.         Participants viewed a video clip of a person describing and/or
Clark (2003) distinguishes two kinds of indicating:               pointing to an array of objects on a computer monitor while
directing-to and positioning-for. The first kind is what is       their eye movements were recorded.
generally considered as pointing and serves to move the
hearer’s attention from the speaker to the approximate                                         Method
region of the referent (Marlsen-Wilson, Levy, & Tyler,
1982). If speaker and hearer both know that their attention       Participants
is focused on a similar region, then this facilitates reference   The participants were 30 undergraduate students at a southern
resolution (Hanna & Tanenhaus, 2004).                             urban university. The participants received extra credit in an
  The purpose of the present study is two-fold. First, it aims    undergraduate course for participating in this experiment.
to answer the question whether pointing helps the hearer in
the communicative process. That is, gestures may be used          Materials
to organize thoughts or support lexical access for the            Participants saw 30 short movies (5 seconds each). Each movie
speaker, but may not facilitate the joint communicative           consisted of 12 smiley faces differing in props (e.g., hat,
activity. In contrast, the hypothesis investigated here is that   moustache, glasses) and emotion (happy, sad) and dependent on
deictic gestures help hearers identify the target indirectly,     the condition a human pointer, pointing out and/or describing
by guiding their gaze to its region. By this hypothesis,          the target. The position of the faces (three columns, four rows),
pointing helps establish a joint focus of attention between       the position of the pointer’s arm and hand and the movement of
speaker and hearer (joint-attention hypothesis). This in turn     the pointing, the feature description of the smiley faces using
facilitates processing on the part of the hearer. Second, the     two distinctive features at a time (emotion and additional
study aims at determining whether deictic gestures are            feature), and the location description (left and right versus top
substitutable for certain linguistic spatial expressions.         and bottom dimension) all remained constant. In a Latin Square-
Contrary to the prediction that gestures add information to       like design, each participant cycled through each condition 5
the communicative act, our hypothesis is that gestures can        times in a random order, totaling 30 trials. In addition, they
substitute for language functions (substitution hypothesis).      completed 10 filler trials (an unrelated text comprehension
  In other words, we suggest that the effect of pointing on       task).
the addressee is similar to that of a verbal description of an      Six conditions were used. The factorial combination of the
approximate region of space, e.g., “the upper right corner”       presence versus absence of a location description and the
(Bangerter, 2004). At least three different kinds of              presence versus absence of gestural pointing in combination to
strategies for referring to objects in shared visual space can    the feature description resulted in four conditions (Table 1).
be identified, one gestural and two linguistic:
1.   Pointing (e.g. hand pointing to target while saying          Table 1: Overview of pointing x description conditions
     “John is right there”)                                                    location description       no location description
                                                                  pointing Pointing +                     Pointing +
2.   Feature description (e.g. saying “John is the man with                    John is on the top left John has a hat and bow
     the hat”)                                                                 with a hat and bow tie     tie
3.   Location description (e.g. saying “John is the one on        no           John is on the top left John has a hat and bow
     the top right”).                                             pointing with a hat and bow tie         tie
  Unambiguous feature descriptions (i.e. that specify a
unique referent among possible competitors) have been             Two additional conditions were created by manipulating the
discussed as the way people typically identify referents          time and order of linguistic expressions and pointing: in a fifth
(Olson, 1970). But with a large set of potential referents,       condition, pointing preceded the linguistic expressions (feature
such a strategy may not be feasible, nor pragmatically            description only), but with an inserted pause of two seconds. In
appropriate. In real conversational situations, people            the final condition the feature description followed the pointing
typically try to create joint attention by circumscribing the     after a two-second pause.
domain of reference (Beun & Cremers, 1998). By the
substitution hypothesis, this can be done either by pointing      Apparatus
or by location descriptions. By the joint-attention               Participants’ eye movements were tracked using a Model 501
hypothesis, focusing attention in this way should facilitate      Applied Science Laboratory eye tracker. A magnetic head
                                                                1332

tracker with a head mounted apparatus was used so that
                                                                                               1
participants could move their head during data collection.
                                                                                                      0.93    0.93
Computer software recorded the eye movements.                                                                                          0.90
                                                                                                                            pointing
Participants were calibrated throughout the session to
insure reliable data. During calibration, participants viewed                                                        no
                                                                        Mean correct answers
nine points on a 1024 x 768 computer monitor and the eye                                                             pointing
tracker recorded corresponding x-y coordinates. The                                                                             0.63
temporal resolution of the Model 501 eye tracker was 60
Hz. The spatial resolution was a .50 degree angle
horizontally and a .40 degree angle vertically.
Procedure
Participants were asked to watch each clip with the 12
smiley faces and click the mouse button as soon as they had
identified the target face. During the process of the                                          0
participant identifying the target, their eye movements were
recorded. After they clicked the mouse button, they were                                           spatial description    no spatial description
presented with 12 circles that represented the positions of
the 12 faces and were asked to identify the target. Accuracy       Figure 1: Accuracy of answers for pointing x location
of the target identification was recorded.                         description.
                          Results
The results of the experiments consisted of two datasets,           However, it should be noted that the total time spent on task
one containing the participants’ answers and one the eye          could be a confounding variable in the accuracy results. For
tracking data. The accuracy of identifying the target             instance, the presence of spatial information (pointing or
showed an effect for pointing (F1(1, 29) = 34.66, p < .01,        location descriptions) necessarily allowed participants to
MSE = .02; F2 (1, 29) = 14.80, p < .01, MSE = .04),               consider the target longer than in the absence of this
location description (F1(1, 29) = 54.10, p < .01, MSE = .02;      information. The fact that participants had slightly more time on
F2 (1, 29) = 29.23, p < .01, MSE = .03) as well as their          making their choice in the location description condition could
interaction (F1(1, 29) = 44.62, p < .01, MSE = .01; F2 (1,        explain the accuracy findings. Eye tracking data can rule out
29) = 18.27, p < .01, MSE = .03). The number of correct           this explanation by considering the total time on task. The total
answers was higher when pointing or the location                  fixation time on all items in both correctly and incorrectly
description was present (Figure 1). The selection of the          answered items did not show significant differences between the
correct target was facilitated when the instructions helped       pointing, location description, or pointing and location
the hearer in identifying the target region, either by means      description conditions (p > .3), upholding the evidence for the
of a location description or gesture. This shows that both        substitution hypothesis. Whereas we did not find differences for
the use of pointing and the use of location description           the accuracy of answers between the asynchrony conditions, the
increase accuracy. Interestingly, when both pointing and          time on task did yield a significant difference. When pointing
location description were presented no additional                 preceded the location description, the total fixation time was
facilitation was found. Though this may be attributed to a        less (M = 1.22, SD = .21) than in the reverse situation (M =
ceiling effect, it may well suggest that pointing can             1.51, SD = .64), but not significantly different from the natural
substitute for the location description, providing support for    pointing condition (M = 1.14, SD = .31), (F1(2, 58) = 13.27, p <
the substitution hypothesis. It also supports the joint-          .01, MSE = .08; F2 (2, 58) = 13.5, p < .01, MSE = .09). In other
attention hypothesis.                                             words, when pointing preceded speech, regardless of the delay,
  The joint-attention hypothesis was also tested by               the accuracy of answers was not affected, but participants were
comparing the natural pointing condition with the                 able to get to the right answer faster. This provides evidence for
asynchronous pointing conditions where pointing either            the joint-attention hypothesis in that deictic gestures guide the
preceded or succeeded the feature description with an             hearers gaze to the target. When this guidance follows the target
inserted pause of two seconds. No evidence was found for          identification, it results in confusion.
this hypothesis: The accuracy of answers was the same               In the remainder of the eye tracking analyses, we removed
when pointing preceded the speech and when it followed            those items that were answered incorrectly. Accordingly, 14%
speech (p > .6).                                                  of the data was removed, but these cases were distributed over
                                                                  all stimuli and all participants. When the total fixation time was
                                                                  considered on all faces for which the target was identified
                                                                  correctly, no differences were found for the three pointing and
                                                                  location description conditions). The advantage we found for
                                                                  the accuracy of items with the presence of pointing or the
                                                                 1333

presence of a location description did not reflect the total                        falsification process, each non-target may have to be
amount of time spent on the task between conditions. On                             considered, but should be eliminated after being considered
the other hand, for the asynchrony conditions, we found the                         once. Therefore, if a non-target item was considered more than
same patterns as before. Not only does it take less time to                         once it indicated confusion in the listener.
answer an item, but it also takes less time to answer an item                         The presence of pointing indeed reduced the number of items
correctly (M= 1.20, SD = .15 vs. M = 1.51, SD = .65; (F1(1,                         considered (F1(1, 29) = 18.25, p < .01, MSE = 14.64; F2 (1, 29)
29) = 9.87, p < .01, MSE = .45; F2 (1, 29) = 17.36, p < .01,                        = 17.38, p < .01, MSE = 21.44). The presence of a location
MSE = .08). Not surprisingly, the number of regressive eye                          description had a similar effect, though marginally significant
movements is also significantly less when pointing                                  (F1(1, 29) = 3.68, p < .065, MSE = .15.99; F2 (1, 29) = 4.23, p <
precedes speech (M = 3.47, SD = .55 vs. M= 4.34, SD =                               .049, MSE = 13.87). Again, no interaction was found for
.91; F1(1, 29) = 21.55, p < .01, MSE = .62; F2 (1, 29) =                            pointing and location description, providing evidence for the
25.57, p < .01, MSE = .45). Interestingly, the number of                            substitution hypothesis (Table 2).
regressive eye movements is lower on the targets as well as
the non-targets in the condition where pointing precedes                                                                         Table 2: Number of non-targets considered
speech. In all cases the insertion of the delay had no effect
on fixation times and regressions, as long as pointing                                                                                             presence        absence
preceded the feature description.                                                                      location description                          5.49            5.76
  As Figure 2 shows, pointing resulted in more regressive                                                    pointing                                5.33            5.92
eye movements on the correct targets than did the no
pointing condition (F1(1, 29) = 4.59, p = .04, MSE = .26; F2
                                                                                      The asynchrony condition provided evidence for the joint-
(1, 29) = 3.26, p = .07, MSE = .49), and so did the presence
                                                                                    attention hypothesis, showing that pointing preceding speech
of the location description (F1(1, 29) = 3.92, p = .06, MSE
                                                                                    resulted in a significantly smaller number of items being
= 3.78; F2 (1, 29) = 14.73, p < .01, MSE = 2.02). as before,
                                                                                    considered (F1(1, 29) = 50.15, p < .01, MSE = 14.38 ; F2 (1, 29)
no interaction was found between pointing and the location
                                                                                    = 55.47, p < .01, MSE = 12.99) (Figure 3).
description.
                                                                                                                             7
                                        2                                                                                                                              6.66
   Number of regressive eye movements
                                                   1.85
                                                                                          Number of non-targets considered
                                            1.69          pointing
                                                         no
                                                   pointing
                                                                     0.70   0.68                                                       5.23            5.28
                                                                                                                             5
                                                                                                                                 pointing + loc    delay: point   delay: loc then
                                        0                                                                                          (no delay)       then loc          point
                                              target                 non-targets
                                                                                    Figure 3: Synchrony and asynchrony in location description and
Figure 2: Effects of pointing on regressions                                        pointing
  The problem with the results of regressive eye                                                                                               Discussion
movements in this task is that they can explain cognitive                            The findings of this study support the view that deictic gestures
processes in two directions. One could argue that more                               can substitute for language functions. That is, when a feature
regressions on targets are an indication that the task is                            description is accompanied by either a deictic gesture or a
easier: the hearer verifies the information by considering                           deictic expression, accuracy in target identification increases.
alternatives, each time moving back to the target                                    However, when both the deictic gesture and the deictic
strengthening the choice. An alternative explanation is that                         expression are present, no additional gains are found in
regressions on the target are an indication of confusion: the                        accuracy. This pattern was also found in the number of
hearer is not certain of the choice and needs to move back                           regressive eye movements. Participants spent more time on the
and forth. Because of this ambiguity, we performed a more                            correct target when pointing was present or when the location
subtle analysis. We counted the number of non-targets that                           description was present, but not when they were combined. This
were considered more than once. In either a verification or
                                                                                   1334

provides support for what we have called the substitution                              Acknowledgments
hypothesis for deictic gestures.                                 This research was supported by grant NSF-IIS-0416128 to the
  The results also provide evidence that gestures support        first author and by an Advanced Researchers Fellowship from
communicative joint activities, as stated by the joint-          the Swiss National Science Foundation (8210-061238) to the
attention hypothesis. Eye tracking data show that pointing       second. Any opinions, findings, and conclusions or
helps establish a joint focus of attention between speaker       recommendations expressed in this material are those of the
and hearer, as predicted by the joint-attention hypothesis. If   authors and do not necessarily reflect the views of the funding
the joint focus of attention is identified after the target      institutions. Correspondence concerning this article should be
identification, it results in confusion, as indicated by more    addressed to Max M. Louwerse, Institute for Intelligent Systems
regressive eye movements, higher fixation times to identify      / Department of Psychology, University of Memphis, 202
the target and more non-targets being considered before the      Psychology Building, Memphis, Tennessee 38152-3230.
correct target is identified. Whether the visual guidance
precedes with a two second delay or whether it naturally
co-occurs with the linguistic expression does not affect
                                                                                           References
fixations.
  This paper has focused on concrete deictic gestures            Alibali, M. W., & DiRusso, A. A. (1999). The function of
(pointing). Other gestures, including iconic, abstract deictic      gesture in learning to count: More than keeping track.
and beat gestures may not support the substitution and              Cognitive Development, 14, 37-56.
joint-attention hypotheses. Although there is some evidence      Bangerter, A. (2004). Using pointing and describing to achieve
                                                                    joint focus of attention in dialogue. Psychological Science,
that they do (see Goldin-Meadow, 2003; Özyürek, 2002),
                                                                    15, 415-419.
further research is needed. Concrete deictic gestures for
                                                                 Beun, R.J. & Cremers, A.H.M. (1998) Object Reference in a
instance have the special relationship with linguistic              Shared Domain of Conversation. Pragmatics and Cognition,
expressions that they can be substituted. That relationship         6, 111-142.
is less direct in the other gesture types.                       Butcher, C., & Goldin-Meadow, S. (2000). Gesture and the
  In addition to having limited ourselves to concrete deictic       transition from one to two-word speech: When hand and
gestures, we have only considered a limited set of linguistic       mouth come together. In D. McNeill (Ed.), Language and
expressions in English. The role of typical deictic                 gesture (pp. 235-257). New York: Cambridge University
expressions like “here”, “there”, “this” and “that” and             Press.
deictic gestures in the comprehension process have not           Butterworth, G. (2003). Pointing is the royal road to language
been tested here. Moreover, for practical reasons we have           for babies. In S. Kita (Ed.), Pointing: Where language,
only considered linguistic expressions in English. To               culture, and cognition meet (pp. 9-33). Mahwah, NJ:
generalize the relationship between gestures and linguistic         Erlbaum.
expressions, a cross-linguistic analysis taking into account     Butterworth B. L. & Beattie G. W. (1978). Gestures and silence
different morphological and syntactic constructions may             as indicator of planning in speech. In Campbell R. N., Smith
have to be considered in the future.                                P. T. (Eds.), Recent Advances in the Psychology of Language:
  The findings presented here have implications for a               Formal and Experimental Approaches (pp. 347-360). New
number of research areas. For instance, it suggests that in         York: Olenum Press.
building intelligent systems, gestures should not be             Butterworth, G., & Morissette, P. (1996). Onset of pointing and
ignored, since they support the joint visual attention with         the acquisition of language in infancy. Journal of
the user. Moreover, if the alignment of gesture to speech is        Reproductive and Infant Psychology, 14, 219-231.
not in synchrony, this could have an important impact on         Clark, H. H. (1996). Using Language. Cambridge: Cambridge
                                                                    University Press.
the user, for instance in intelligent tutoring systems
                                                                 Clark, H.H. (2003). Pointing and placing. In S. Kita (Ed.),
(Louwerse, et al., 2004).
                                                                    Pointing. Where language, culture, and cognition meet (pp.
  These findings also have implications for the answer why          243–268). Hillsdale NJ: Erlbaum.
we gesture. The alignment results support the notion that        Ekman, P. & Friesen, W. V. (1969). The repertoire of nonverbal
gesture and speech are indeed coexpressive manifestations           behavior: Categories, origins, usage, and coding. Semiotica,
of one integrated system. Disintegrating the two, for               1, 49- 98.
instance by changing their order, results in confusion. But      Goldin-Meadow, S. (2003). Hearing gesture: How our hands
regardless of whether we gesture to facilitate lexical access       help us think. Cambridge, MA: Harvard University Press
or to organize thoughts, our findings at least show that we      Hanna, J. E., & Tanenhaus, M. K. (2004). Pragmatic effects on
gesture to support communicative joint activities. That             reference resolution in a collaborative task: Evidence from
function can also be fulfilled by specific linguistic               eye movements. Cognitive Science, 28, 105-115.
expressions, as long as the description is as specific as the    Kendon, A. 1988. How gestures can become like words. In F.
gesture.                                                            Poyatos (ed.), Crosscultural perspectives in nonverbal
                                                                    communication (pp. 131-41). Toronto: Hogrefe.
                                                                 Krauss, R. M., Morrel-Samuels, P., Colasante, C. (1991). Do
                                                                    conversational hand gestures communicate? Journal of
                                                                    Personality and Social Psychology, 61, 743-754.
                                                               1335

Louwerse, M.M., Bard, E.G., Steedman, M., Hu, X.,             Olson, D. R. (1970). Language and thought: Aspects of a
  Graesser,      A.C.     (2004).    Tracking    multimodal      cognitive theory of semantics. Psychological Review, 77,
  communication in humans and agents. Technical report,          257-273.
  Institute for Intelligent Systems, University of Memphis,   Özyürek, A. (2002). Do speakers design their co-speech
  Memphis, TN.                                                   gestures for their addressees? The effects of addressee
Marslen-Wilson, W., Levy, E., & Tyler, L. K. (1982).             location on representational gestures. Journal of Memory and
  Producing interpretable discourse: The establishment and       Language, 46, 688-704.
  maintenance of reference. In R. J. Jarvella & W. Klein      Povinelli, D. J., Bering, J. M., & Giambrone, S. (2003).
  (Eds.), Speech, place and action. Studies in deixis and        Chimpanzee’ “pointing”: Another error of the argument by
  related topics. (pp. 339-378). Chichester: John Wiley.         analogy? In S. Kita (Ed.), Pointing: Where language, culture,
Mayberry, R.I. & Jaques, J. (2000). Gesture production           and cognition meet (pp. 35-68). Mahwah, NJ: Erlbaum.
  during stuttered speech: Insights into the nature of        Rime, B. and Schiaratura, L. (1991) Gesture and speech, In:
  gesture-speech integration. In D. McNeill (Ed.),               R.S. Feldman and B. Rime (Eds.) Fundamentals of
  Language and Gesture: Window into Thought and                  Nonverbal Behavior (pp. 239-284). Cambridge: Cambridge
  Action (pp. 199-213). Cambridge: Cambridge University          University Press.
  Press.                                                      Rogers, W. (1978). The contribution of kinesic illustrators
McNeill, D. (1992). Hand and Mind: What Gestures                 towards the comprehension of verbal behavior within
  Reveal about Thought. Chicago: University of Chicago           utterances. Human Communication Research, 5, 54-62.
  Press.                                                      Thompson, L. & D. Massaro (1986). Evaluation and integration
Morrel-Samuels, P. & Krauss, R.M. (1992). Word                   of speech and pointing gestures during referential
  familiarity predicts temporal asynchrony of hand               understanding. Journal of Experimental Child Psychology 42,
  gestures and speech. Journal of Experimental                   144- 168.
  Psychology: Learning, Memory and Cognition, 18, 615-
  623.
                                                            1336

