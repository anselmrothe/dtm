UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Perceiving and Describing Event Temporal Dynamics

Permalink
https://escholarship.org/uc/item/2tz5t44p

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Author
Luhman, Christian C.

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Perceiving and Describing Event Temporal Dynamics
Shulan Lu (Shulan_Lu@tamu-commerce.edu)
Devin Pierce (dpierce@cp.tamu-commerce.edu)
Department of Psychology and Special Education
Texas A & M University-Commerce
Commerce, TX 75429-3011, USA

Abstract
This paper investigates how people coordinate perceiving and
describing event temporal dynamics. Participants viewed
animations of fish swimming events and described how the
events are related in time. We examined the timing when
linguistic descriptions were launched, the linguistic
characteristics, and the eye movement properties of
participants viewing the fish swimming events. The results
showed that there are three modes of launching descriptions:
(a) some people always launch their descriptions while events
are unfolding, (b) some people always launch descriptions
after events unfold, and (c) some people switch between
launching during and after the events depending on the
context. When two events have a higher degree of
simultaneity in time, people tend to launch their spontaneous
descriptions after the events unfold. The linguistic
characteristics of the descriptions, for example, the number of
clauses and the number of verbs, reflect some of the
interactions between description modes and event temporal
properties. People tend to fixate on the end points of the
events when they are ready to utter the words “stop” and
“start”.

Introduction
We often need to describe events and their temporal
dynamics. For example, situations where we need to
represent temporal relations might include explaining to
someone how to make a particular dish by following a
recipe, remembering the temporal dynamics between events
of a traffic accident we witnessed, or talking to someone
over the phone about how to troubleshoot a computer
problem. When we think about event temporal dynamics,
we often need to know how long each event takes place
(i.e., event duration) and how each event is related to other
events (i.e., event temporal relations).
Events can unpack seamlessly, co-occur with one another
in time and space, and unfold simultaneously. The temporal
dynamics between events are abstract and subtle at times.
How do we encode the event temporal dynamics, and in
particular, event temporal relations when events are
unfolding? Hunt and Agnoli (1991) suggested that people
think more efficiently about a topic if their language
provides an efficient code. Gentner and Boroditsky (2001)
suggested that language plays a more important role in
representing abstract domains than concrete domains.
Boroditsky and her colleagues provide some evidence that
language plays a role in how people think about the
temporal aspects of an event (Boroditsky, 2001; Boroditsky,

Ham, & Ramscar, 2002). For example, Mandarin speakers
talk about time as if it flows vertically and think of time
vertically even when they were tested in English. Such
proposals suggest that there might be a close relationship
between describing and conceptualizing event temporal
dynamics.
In the current study, people viewed animations that
systematically varied the event temporal relations, and
described the temporal relations when they were ready. To
understand the relationship between perceiving and
describing the event temporal dynamics, we examined the
following four indicators: (a) do people tend to launch their
spontaneous descriptions when the events are unfolding or
afterwards? (b) what linguistic properties do online
descriptions have? (c) how well could the online
descriptions depict the event temporal dynamics? and (d)
where do people tend to look when they mark off the event
onsets and offsets? In the paragraphs below, we will discuss
each indicator and make some predictions accordingly.
Whether people describe events in a tight coupling with
their comprehension of events has long been a debate.
Wundt (1900/1970) suggested that describing events occurs
after people comprehend events, whereas Paul (1886/1970)
suggested that describing events and comprehending events
may interleave. There has been some evidence supporting
Wundt’s position. Griffin and Bock (2000) presented
participants events that were depicted in pictures and
participants described the events. Participants typically
initiated their corresponding linguistic descriptions after
they comprehended the events. Graesser, Lu, Olde, CooperPye, and Whitten (in press) presented participants an
illustrated text about an everyday device along with a
hypothetical breakdown scenario and participants generated
questions
that
could
troubleshoot
the
device.
Comprehenders performed causal analysis of the device
mechanism and fixated on the problem component of the
device before they launched their questions. The events used
in these studies were simple events depicted in static
pictures. There might be differences when events are
dynamically unfolding. Zacks, Tversky, and Iyre (2001)
asked participants to segment an ongoing everyday event at
both coarse grained level and fine grained level. Participants
tended to show a stronger alignment between coarse grained
and fine grained segmentation if they described events while
performing segmentation. Such evidence suggests that
people may launch their descriptions while the event
temporal dynamics are unfolding.

1349

of events (Graesser, 1978; Lichtenstein & Brewer, 1980;
Lu, 2004; Miller, Galanter, & Pribram, 1960; Rieger &
Zheng, 2003).
In this paper, we are trying to dissect the dynamic
couplings between perceiving and describing abstract event
temporal relations. We investigated the four indicators
discussed above and provided some preliminary answers. In
the sections below, we will report the details of the study
and the results.

What linguistic properties do online descriptions exhibit?
Slobin’s (1996) thinking-for-speaking hypothesis suggests
that people tend to constrain their descriptions based on the
temporal parameters available in language. Wierzbicka
(1994) proposed that BEFORE, AFTER, and WHEN are
three semantic primitives in temporal language. These three
primitives together with other temporal adjuncts can be used
to paraphrase complex temporal relational terms. Similarly,
Graesser, Wiemer-Hastings, and Wiemer-Hastings (2001)
proposed a common representational system for
representing text, episodic experiences, and world
knowledge, in which BEFORE, AFTER, and DURING are
primitives for encoding temporal descriptions. Lu and
Graesser (2004) asked participants to view, remember, and
subsequently judge the event temporal relations, and also
asked participants to sort temporal relational words into
semantic clusters. The results consistently showed support
for Wierzbicka and Graesser et al. proposals, in that, people
tend to think of temporal relations consisting of BEFORE,
AFTER, and some degree of co-occurrence that is
manifested by WHEN or DURING. Taken together, the
linguistic space of the online descriptions may be carved out
by these temporal primitives.
One may ask such a question as whether and how well the
online descriptions depict the temporal relations. For
example, some events start at the same time but end at
different times, whereas other events start at different times
but end at the same time. Do people tend to differentiate the
subtle distinctions by judiciously combining the temporal
primitives together with adjuncts? Or do people tend to blur
these distinctions? Studies showed that people frequently
simplify complex temporal relations between events, and
misconstrue them as simpler temporal relational primitives
(Lu, 2004; Lu & Graesser, 2004; Lu, Harter, & Graesser,
2005). For example, people often perceive events that
partially overlap in time as events that follow each other
immediately. Such evidence suggests that people are likely
to blur the distinctions when they are engaged in
spontaneous descriptions.
People typically fixate on an object in a picture while
they are thinking about it (Graesser et al., in press; Grant &
Spivey, 2003; Tanenhaus, Spivey-Knowlton, Eberhard, &
Sedivy, 1995). For example, Tanenhaus et al. (1995) asked
participants to manipulate objects in a toy environment
under audio command. Participants fixated on the objects in
pictures before they heard the end of the spoken word. One
question arises to where people fixate when they talk about
temporal concepts? To begin our understanding of this
question, we analyzed the eye movements before people
linguistically marked off the beginnings and ends of events.
Following the same reasoning that people look at an object
before they describe a concept, it is possible that people
may fixate on the relevant temporal markers of events
before they describe the markers. Research on events and
actions suggested that people pay closer attention to the
culmination of the plans and goals. This suggests an
alternative that people may tend to focus on the end points

Methods
Participants
There were 19 college students at the University of
Memphis who participated for course credit.

Materials
Animated Events A set of 42 animations depicting fish
swimming events were used in this experiment. Each
animation depicts one of Allen’s (1984; 1991) seven
temporal relations as described below (following Allen’s
naming system):
1. BEFORE: Event 1 occurs before Event 2 with
some temporal space in between.
2. MEET: Event 2 follows Event 1 immediately.
3. OVERLAP: Event 1 and Event 2 do not start and
end at the same times, but overlap over some time
in between.
4. START: Event 1 and Event 2 start at the same
time.
5. DURING: Event 2 occurs in between the beginning
and end of Event 1.
6. FINISH: Event 1 and Event 2 end at the same time.
7. EQUAL: Event 1 and Event 2 share the same time
course.
For each temporal relation, there were six different
animations. The animations varied the event spatial
trajectory, the spatial perspective, and the fish swimming
speed. The animations were created in 3d Studio Max
release 5. The animation quality is near photorealistic. Each
animation is about 25 seconds and runs at approximately 30
frames per second. The presentation order of the animations
was randomized. There were seven randomized orders for
the experiment. Each participant received one of the seven
orders.

1350

Temporal Word List A list of words and phrases that
encode the temporal relations were selected from Lu and
Graesser (2004) study, where participants sorted temporal
words into semantic groups. The purpose of the selection
was to expose participants to various ways in which
temporal relations are described in language. There were
verbs, adverbs, prepositions and conjunctions. The
following are some example words: (a) anticipate, precede,
follow after, succeed, go with, overlap, (b) before, earlier,
previously, in advance, after, later, next, subsequently, at the
same time, simultaneously, for now, and (c) prior to, soon

after, until, when, while, during, in the course of. The
complete word list was presented on a computer screen
during the exposure and training phase only.

Apparatus
An Applied Science Laboratory Model 501 eye tracker was
used in the study. Eye movements were recorded 60 times
per second (once every 17 ms). The experimental session
was videotaped and audio recorded through a VCR. The
VCR recorded a TV screen that displayed the ongoing
events in each animation and a superimposed image of what
the left eye was fixating on. The superimposed image was
generated by the eye tracking equipment. Each participant
wore a small microphone, which was connected to the VCR,
so their verbal descriptions were recorded.

Procedure
Participants were told that they will be viewing animations
of fish swimming events. Participants received the
following instructions, “While you view the animation, try
to describe the time relations between the fish swimming
events using one or two succinct sentences. For example,
the light fish swims before the dark fish, but stopped after
the dark fish. Or another example, the light fish and the dark
fish swim simultaneously. The words or phrases underlined
in these examples tell us the time relations between the two
fish swimming events. Of course, these are just arbitrary
examples. Describe the events and time relations in a way,
which is most natural to you and which is understandable to
others who do not see the animations. Before you speak,
please hit S on the keyboard”.
Participants were presented with the word list described
earlier on the computer screen. Participants were told that
these words are example words that describe the time
relations between events. Experimenter read each word to
participants and pointed to the word on the screen. Upon
completion, the word list screen was removed. Then
participants received trial animations and practiced to
perform the task by following the instructions. Participants
also positioned their finger next to the S key on the
keyboard.
When participants felt ready for the experiment task, they
went through an eye tracker calibration procedure. Upon
completing the calibration, participants viewed one
animation at a time and described event temporal dynamics
when they were ready. Calibration was checked periodically
throughout the experiment session.

Results
Modes of Launching Descriptions
There were three different modes of launching online
descriptions: (a) the after mode: participants always
launched their descriptions after the events unfolded
throughout the experiment; (b) the during mode:
participants always launched their descriptions while events
were unfolding; and (c) the mixed mode: participants some
times launched their descriptions after the events unfolded,

and sometimes while the events were unfolding. 37% of the
participants were after mode speakers, whereas 26% of the
participants were the during mode speakers. The rest 37% of
the participants were mixed mode speakers.
Interestingly, there was some trend that participants were
more likely to launch their descriptions after the events
completely unfolded with respect to some event temporal
relations. Figure 1 shows the proportions of descriptions
that were described during versus after events unfolded. For
START, DURING, FINISH, and EQUAL events, the
proportions of participants who launched their descriptions
after animated events finished were .61, .62, .62, and .67
respectively. However, there was not such a trend for other
event temporal relations. For BEFORE, MEET, and
OVERLAP events, the proportions of participants who
described after the animated events came to stop were .53,
.54, and .50 respectively. These two groups of event
temporal relations differed significantly on the proportions
of descriptions launched after events unfolded, t (18) = 2.02,
p < .05.

Linguistic Properties
Participants used a wide range of temporal words. There
were 11 different temporal verbs in all of the descriptions.
Start (M = 44.68) and stop (M = 48.21) were routinely used,
whereas other temporal verbs were used but not
consistently. Precede, lead, and continue are some
examples. Note that the mean value refers to the number of
times used per participant. There were 22 different temporal
adverbs in the descriptions, and 8 different temporal
conjunctions / prepositions. Before (M = 14.84) was the
most frequently used semantic primitive, whereas after (M
= 3.89) was infrequently used. During and when were rarely
used. At the same time (M = 14.89) and simultaneously (M
= 5.58) were accessed fairly frequently as well. In addition,
participants used and, then, first, and later on many
occasions.
We examined a number of linguistic properties, and
computed the index of each linguistic property as a function
of (a) 7 event temporal relations; and (b) 3 modes of
launching descriptions. With respect to the number of
temporal conjunctions in describing an animation (M =
1.40), there were significant main effects of temporal
relations, F (6, 96) = 14.56, MSE = .25, p < .05, there were
significant main effects of launching modes, F (2, 16) =
8.50, MSE = 2.03, p < .05, there were significant
interactions between temporal relations and launching
modes, F (12, 96) = 2.63, MSE = .25, p < .05. Participants in
the after mode tended to use more temporal conjunctions
(e.g., and, then) than those in the during mode (M = 2.10
versus 1.01). Participants, who waited till the animated
events finished, used 2 conjunctions, whereas those, who
did not wait, used 1 conjunction on average. With respect to
the number of temporal verbs in describing an animation (M
= 2.32), there were significant main effects of temporal
relations, F (6, 96) = 9.56, MSE = .25, p < .05, there were
significant main effects of launching modes, F (2, 16) =
8.50, MSE = 2.03, p < .05, there were significant
interactions between temporal relations and launching

1351

Figure 1: Proportions of trials launched description during versus after animated events.
modes, F (12, 96) = 2.63, MSE = .25, p < .05. Participants in
the during mode tended to use more temporal verbs (e.g.
start, stop) than those in the mixed mode (M = 2.71 versus
1.80). Participants, who launched descriptions while events
were unfolding, tended to mark the onset and offset of
events more precisely by using .9 verbs such as start and
finish. With respect to the number of temporal adverbs in
describing an animation (M = 1.10), there were significant
main effects of temporal relations, F (6, 96) = 11.28, MSE =
.24, p < .05, there were significant main effects of launching
modes, F (2, 16) = 3.81, MSE = .87, p < .05, there were no
significant interactions between temporal relations and
launching modes. Participants used at least 1 temporal
adverb such as simultaneously in each trial.
With respect to the number of clauses in describing an
animation (M = 3.00), there were significant main effects of
temporal relations, F (6, 96) = 23.39, MSE = .18, p < .05,
there were significant main effects of launching modes, F
(2, 16) = 4.69, MSE = 2.54, p < .05, there were significant
interactions between temporal relations and launching
modes, F (12, 96) = 1.85, MSE = .18, p < .05. Participants in
the during mode tended to have longer descriptions than
those in the mixed mode (M = 3.46 versus 2.42). On
average, the during mode participants used 1 more clause
than the mixed mode participants. Mainly present tense and
past tense were used in the descriptions, whereas other
tenses were rarely used. With respect to the number of past
tense in describing an animation (M = 1.37), there were
significant main effects of temporal relations, F (6, 96) =
6.00, MSE = .23, p < .05, there were marginally significant
main effects of launching modes, F (2, 16) = 3.31, MSE =
9.08, p = .06, there were significant interactions between
temporal relations and launching modes, F (12, 96) = 2.57,
MSE = .23, p < .005. Participants in the after mode tended to
use past tense than those in the mixed mode (M = 2.27

versus .79). With respect to the number of present tense in
describing an animation (M = 1.40), there were only
significant main effects of temporal relations, F (6, 96) =
2.63, MSE = .21, p < .05. Participants in the during mode
were most likely to use present tense (M = 1.88), whereas
participants in the after mode were least likely to use present
tense (M = .83).

Description and Communication
We also coded whether a reader can reconstruct the event
temporal relations from the verbal descriptions alone. A
description received a score of 1, if it was considered as
depicting the animation correctly. A description received a
score of 0, if it was considered as not depicting the
animation at all. A description received a score of .5, if was
considered as depicting the animation in general but not
making subtle distinctions among temporal relations (e.g.,
BEFORE versus MEET confusion). We added up scores for
all six descriptions of each temporal relation and then
divided the scores by 6. Thus we computed a
communication indexing score for descriptions of each
event temporal relation. The means of the communication
indexing score were the following: BEFORE (.58), MEET
(.54), OVERLAP (.82), START (.85), DURING (.77),
FINISH (.82), and EQUAL (.87). The results suggested that
the distinctions between BEFORE and MEET were
frequently not linguistically marked, whereas EQUAL
events were more frequently marked. There were not
significant differences between the during mode and the
mixed mode describers on the communication indexing
score. Below provides one sample description for each
temporal relation that received a score of 1. The pauses and
the hesitations in between were not coded, however, they
were not infrequent.

1352

•
•
•
•
•
•
•

BEFORE: The larger fish swims across and
finishes. And a few moments later, the smaller fish
swims across.
MEET: The light fish swam all the way across and
stopped. And then immediately, the dark fish swam
across and stopped.
OVERLAP: The red fish moves forward, and then
the pink fish moves forward shortly afterwards.
The red fish stops and then the pink fish stops.
START: The big red fish and the brown fish started
swimming simultaneously, and then the brown fish
stopped before the big red fish stopped.
DURING: The brown fish started swimming just
before the orange fish, but the orange fish stopped
swimming before the brown fish.
FINISH: The orange fish starts swimming before
the brown fish. And then the brown fish and the
orange fish stop simultaneously.
EQUAL: Both fish started swimming at the same
time and stopped at the same time.

Eye Movement Properties
The sample descriptions suggested that participants tend to
linguistically mark the beginning and ends of events. Did
participants fixate on the beginning points of an event when
they described the onset of an event? Did participants fixate
on the end points of an event when they described the offset
of an event? We performed some preliminary analysis of the
eye movements. The eye movements showed that
participants tend to switch back and forth between two fish
and keep track their motion trajectories. Almost all the time,
the end point of an event was fixated before participants
uttered the word such as “stop”. The end point of an event
was also frequently fixated before participants uttered the
word such as “start”. Interestingly, out of six animations
depicting each temporal relation, there were 1.48
occurrences of eye fixations tracing back to the starting
point of an event before participants delivered the word
“start”.

Discussion
The current study dissected a number of online cognitive
processes when people perceive and describe event temporal
dynamics. The results suggested that perceiving events and
describing events serve as online repository for each other,
exert constraints at times on each other, and scaffold each
other toward constructing abstract event structures.
The current study indicated that people do not always
wait to launch their descriptions until the events completely
unpack. For some event temporal relations (e.g., EQUAL),
people tend to wait till the end of events. One possibility is
that people have to wait till the end of animations to find out
temporal relations such as EQUAL. However, this
possibility is not entirely adequate in explaining why people
tend to wait till the end of START and DURING events.
Perceiving and comprehending events that have higher
degrees of simultaneity may be taxing working memory
capacity. Describing the events as the events unfold takes
away cognitive resources from comprehending events.

Subsequently, people prefer not to describe until they see
the full range of the events.
There appear to have been individual differences in
describing temporal relations. The during mode describers
tended to follow the event trajectory and take detailed notes
(story-teller type of describer), whereas the mixed mode
describers tended to use language as a strategy for capturing
the event relations and tried to economize their descriptions.
Compared with the mixed mode describers, the during mode
describers used longer descriptions, tended to use temporal
conjunctions linking clauses, usually marked off the onset
and offset of events, and used the present tense. The after
mode describers tended to be in between on some of the
linguistic measures.
People could choose different words while encoding the
temporal relations, but they show a proclivity toward some
words. Among the three semantic primitives, BEFORE was
accessed disproportionately more often the other two
primitives. One potential explanation is the iconicity
principle, where narrators tend to describe events in
alignment with the order in which the real world events
unfold (Ohtsuka & Brewer, 1992; Zwaan & Radvansky,
1998). The results suggested an interesting choice made by
describers when facing the linearity of language and the
simultaneity of events. Describers followed along the event
trajectory naturally, but varied the use of start and stop, and
constructed a sentential matrix of start and stop, indicating
the asynchrony between events. One potential challenge to
this conjecture is that people may not mark off the
beginnings and ends when the events are more complex and
embedded in a higher order event structure such as schema.
In the current study, not only event temporal relations
were varied, but also spatial perspectives where events
unpack were varied. To what extent did participants
describe the spatial properties of events? The occurrences of
spatial words and phrases are not frequent in the
descriptions. For example, the number of spatial
prepositions and prepositional phrases (e.g., in the middle)
were below 1 on average for each trial.
The descriptions did not always depict the temporal
relations accurately and appeared to be differential among
different relations. For example, participants frequently
failed to distinguish MEET from BEFORE. The
communication indexing scores are relatively high with
respect to START, DURING, FINISH, and EQUAL. The
verbal protocols suggested that participants efficiently used
the start and stop matrix in conjunction with temporal
adverbs. Interestingly, the during mode describers did not
score higher than the mixed mode describers.
The eye movements showed an interesting asymmetry.
Participants were equally likely to mark off the beginnings
and endings of events in descriptions; however, they
frequently fixated on the end points even when they were
describing the “start”. The eye movements hinted that
participants may regress to the beginning points of events
when two events overlap in some degree. There is also
some hint that participants in the after mode may be more
likely to performing the regression eye movements (M =
1.74), whereas participants in the mixed mode may be less
likely to perform the regression (M = 1.02). Participants

1353

may tend to regress more with some temporal relations
(OVERLAP, M = 1.81) than others (BEFORE, M = .81).
Further work is needed to examine the conditions under
which people perform regressive eye movements toward the
beginning of an event.
In closing, the current study investigated a few indicators
of the online cognitive processes when people are engaged
in perceiving, describing events, and constructing abstract
event temporal relations. The results showed the dynamic
coupling between the perceptions of ongoing events, the
nature of the event temporal relations, and the linguistic
properties that get activated online. Future research is
underway to systematically unpack the relationships.

Acknowledgments
We thank Art Graesser for encouraging and supporting this
work. We also thank James Wallace for his assistance in
data collection.

References
Allen, J. F. (1984). Towards a general theory of action and
time. Artificial Intelligence, 23, 123-154.
Allen, J. F. (1991). Time and time again: The many ways to
represent time. International Journal of Intelligent
Systems, 6, 341-355.
Boroditsky, L. (2001). Does language shape thought?
Mandarin and English speakers’ conceptions of time.
Cognitive Psychology, 43, 1-22.
Boroditsky, L., Ham, W., & Ramscar, M. (2002). What is
universal in event perception? Comparing English and
Indonesian speakers. In W. D. Gray, & C. D. Schunn
(Eds.), Proceedings of the 24th Annual Meeting of the
Cognitive Science Society. Mahwah, NJ: Erlbaum.
Gentner, D., & Boroditsky, L. (2001). Individuation,
relativity, and early word learning. In M. Bowerman, & S.
Levinson (Eds.), Language acquisition and conceptual
development. Cambridge, England: Cambridge University
Press.
Graesser, A. C. (1978). How to catch a fish: The memory
and representation of common procedures. Discourse
Processes, 1, 72-89.
Graesser, A. C., Lu, S., Olde, B., Cooper-Pye, E., &
Whitten, S. N. (in press). Question asking and eye
tracking during cognitive disequilibrium: Comprehending
illustrated texts when the devices breakdown. Memory
and Cognition.
Graesser, A. C., Wiemer-Hastings, P., & Wiemer-Hastings,
K. (2001). Constructing inferences and relations during
text comprehension. In T. Sanders, J. Schilperoord, & W.
Spooren (Eds.), Text representation: Linguistic and
psycholinguistic aspects. Amsterdam: Benjamins.
Grant, E. R., & Spivey, M. J. (2003). Eye movements and
problem solving: Guiding attention guides thought.
Psychological Science, 14, 462-466.
Griffin, Z. M., & Bock, K. (2000). What the eye says about
speaking. Psychological Science, 11, 273-279.

Hunt, E., & Agnoli, F. (1991). The Whorfian hypothesis: A
cognitive psychology perspective. Psychological Review,
98, 377-389.
Lichtenstein, E. D., & Brewer, W. F. (1980). Memory for
goal-directed events. Cognitive Psychology, 12, 412-445.
Lu, S. (2004). Perceiving, remembering, and describing
event temporal relations. Dissertation Abstracts
International, 65 (06), 3191. (UMI No. 3137799)
Lu, S., & Graesser, A. C. (2004). What is universal in
perceiving, remembering, and describing event temporal
relations? In K. D. Forbus, D. Gentner, & T. Regier
(Eds.), Proceedings of the 26th Annual Meeting of the
Cognitive Science Society. Mahwah, NJ: Erlbaum.
Lu, S., & Harter, D., & Graesser, A. C. (2005). Do events
have fuzzy psychological temporal frames? A
computational and empirical investigation of event
temporal relations. Manuscript submitted for publication.
Miller, G. A., Galanter, E., & Pribram, K. H. (1960). Plans
and the structure of behavior. New York: Holt, Rinehart
& Winston.
Ohtsuka, K., & Brewer, W. F. (1992). Discourse
organization in the comprehension of temporal order in
narrative texts. Discourse Processes, 15, 317-336.
Paul, H. (1970). The sentence as the expression of the
combination of several ideas. In A. L. Blumenthal (Ed.
And Trans.), Language and psychology: Historical
aspects of psycholinguistics. New York: Wiley. (Original
work published 1900).
Rieger, T., & Zheng, M. (2003). An attentional constraint
on spatial meaning. In R. Alterman & D. Kirsch (Eds.),
Proceedings of the 25th Annual Meeting of the Cognitive
Science Society. Mahwah, NJ: Erlbaum.
Slobin, D. (1996). From “thought and language” to
“thinking for speaking”. In J. Gumperz & S. Levinson
(Eds.), Rethinking linguistic relativity. Cambridge, UK:
Cambridge University Press.
Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K.
M., & Sedivy, J. C. (1995). Integration of visual and
linguistic information during spoken language
comprehension. Science, 268, 1632-1634.
Wierzbicka, A. (1994). Semantic primitives across
languages: A critical review. In C. Goddard, & A.
Wierzbicka (Eds.), Semantic and Lexical Universals:
Theory and Empirical Findings. Amsterdam: Benjamins.
Wundt, W. (1970). The psychology of the sentence. In A. L.
Blumenthal (Ed. and Trans.), Language and psychology:
Historical aspects of psycholinguistics. New York: Wiley.
(Original work published 1900).
Zacks, J. M., Tversky, B., & Iyer, G. (2001). Perceiving,
remembering, and communicating structure in events.
Journal of Experimental Psychology: General, 130, 2958.
Zwaan, R. A., & Radvansky, G. A. (1998). Situation model
in language comprehension and memory. Psychological
Bulletin, 123, 162-185.

1354

