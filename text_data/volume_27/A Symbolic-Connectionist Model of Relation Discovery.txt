UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Symbolic-Connectionist Model of Relation Discovery
Permalink
https://escholarship.org/uc/item/6b8624nv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Doumas, Leonidas A.A.
Hummel, John E.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    A Symbolic-Connectionist Model of Relation Discovery
                                Leonidas A. A. Doumas (adoumas@psych.ucla.edu)
                                    John E. Hummel (jhummel@psych.ucla.edu)
                             Department of Psychology, University of California, Los Angeles
                                                       405 Hilgard Ave.
                                                Los Angeles, CA 90095-1563
                             Abstract                                 Relations are Hard to Learn
                                                                         Learning relational concepts is difficult for two reasons.
   Relational reasoning is central in human cognition.
                                                                      The first begins with the very definition of a relation: A
   Numerous computational models address the component
   processes of relational reasoning, however these models            relation is a property that holds over a collection of
   require the modeler to hand-code the vocabulary of relations       arguments; it is never observable in a single object, so
   on which the model operates. The acquisition of relational         learning relations is vastly underconstrained by the
   concepts remains poorly understood. We present a theory of         examples from which we learn them. Take, for example,
   relation discovery instantiated in a symbolic-connectionist        the relation same-shape (x, y). When universally quantified
   model, which learns structured representations of attributes       it takes any shape as input, and therefore its truth-value (i.e.,
   and relations from unstructured distributed representations of     whether x and y are the same shape) is completely
   objects by a process of comparison, and subsequently refines       uncorrelated with the specific visual features of any shapes
   these representations through a process of mapping-based
                                                                      (or any pair of shapes for that matter). As a result, it cannot
   schema induction.
                                                                      be learned from the simple covariation of visual features.
Keywords:       relations, learning, neural network, symbolic            The second difficulty stems from the properties of
processing, structured representations                                relational representations. Relational representations are
                                                                      structure sensitive and semantically rich (Hummel &
                   Relational Reasoning                               Holyoak, 1997). In a relational expression the meaning of
                                                                      the individual relational roles and their fillers is invariant
   Virtually every conscious thought you have expresses a             with their arrangement in the expression (i.e., they are
relation. From the mundane, like “I’m late for work”, to the          independent), but the meaning of the expression as a whole
sublime, like Cantor’s proof that the cardinal number of the          is a function of both the elements that compose the
real numbers is greater than that of the integers, we are             expression and their arrangement (i.e., the bindings of fillers
constantly representing and reasoning with relations.                 to relational roles). Consider the statements chase (Bill, Joe)
Relational thinking is so commonplace it is easy to take for          and chase (Joe, Bill). We can appreciate that they mean
granted, but the ability to form and manipulate relational            different things (even though they are composed of the same
representations appears late in human development (Gentner            elements) because we can appreciate that the bindings of
& Rattermann, 1991; Smith, 1989), and is a late                       objects to relational roles is reversed in the two statements.
evolutionary development that appears to distinguish human            We can also appreciate that the individual elements chase,
cognition from that of other animals (Holyoak & Thagard,              Joe, and Bill, mean the same things in both statements
1995; Thompson & Oden, 2000).                                         (despite the fact that they are in different compositions).
   An important theme that has emerged from the study of              Additionally, we can cast these elements in novel
relational thinking – both empirical and theoretical – is that        configurations, for example generalizing the chase relation
the kinds of problems a person (or model) can solve depend            to novel arguments (e.g. chase (spoon, sprocket)). Thus, a
critically on what the person (or model) can and does                 relational concept must be represented independently of the
represent. However, little empirical work, and almost no              examples from which it is learned, must be able to take
theoretical work, has addressed the problem of how we                 arguments from both within and outside the set on which it
acquire relational concepts. Models based on relational               was learned (i.e., we must be able to extrapolate the relation
representations (e.g., Falkenhainer, Forbus, & Gentner,               to novel values), and must specify the bindings of its
1989; Hummel & Holyoak, 1997, 2003) have made                         arguments to its relational roles explicitly.
important strides elucidating the nature of relational thought.          Relational representations also explicitly specify the
However, these models are all granted a vocabulary of                 semantic content of objects and relational roles (e.g., the
relational representations by the modeler; they do not learn          lover and beloved roles of love (x, y) or the liker and liked
the relations they need for themselves. Although they                 roles of like (x, y)): We know what it means to be a lover,
address our capacity to manipulate relational representations,        and that knowledge is part of our representation of the
they do not address the question of where these                       relation itself. Consequently, it is easy to appreciate that the
representations come from in the first place.                         patient (i.e., killed) role of murder (x, y) is like the patient
                                                                      manslaughter (x, y), even though the agent roles differ (i.e.,
                                                                  606

the act is intentional in the former case but not the latter);        sets of shared properties together to form whole relational
and the agent role of murder (x, y) is similar to the agent           structures.
role of attempted-murder (x, y), even though the patient                 For example, consider what happens when a child learns
roles differ.                                                         the property “red” by comparing an apple to a toy fire
   A solution to the problem of learning representations of           engine. Assume that when the apple and fire engine are
relations that have all these properties has proven elusive.          compared, any features they share will be highlighted (i.e.,
Gasser and Colunga (2001) have made important strides                 get more input than unshared features). As apples and fire-
toward modeling the learning of relational concepts.                  engines are both red, perhaps the feature “red” gets most
However the representations this model forms do not                   active. If the child can predicate the highlighted feature (i.e.,
maintain independence of relations and arguments while                attach a predicate to the feature “red”), she will have formed
explicitly specify the bindings of specific roles to specific         an explicit representation the property “red”. If she can then
fillers. Bindings are carried by connections between units,           bind that property to the apple (or fire engine) she will have
and connections only implicitly represent bindings (von der           explicitly predicated the property of “red” about the apple
Malsburg, 1981/1994).          Moreover, the model learns             (or fire engine). Consistent with this idea, several previous
relations by learning correlations of specific feature values         studies have demonstrated that structure mapping bootstraps
with relational labels.       As noted above, one of the              the induction of abstract relational schemas (e.g., Gick &
difficulties of learning truly relational representations is that     Holyoak, 1983; Ratterman & Gentner, 1998), and that
they can be extrapolated to novel arguments and are,                  comparison helps people appreciate what lower-order
therefore, not learnable as covariations among features.              relations might be relevant to a specific task (Kotovsky &
                                                                      Gentner, 1996; Namy & Gentner, 2002; Sandhofer & Smith,
Constraints on Discovering Relations                                  2001; Yamauchi & Markman, 1998).
   Given these considerations, what kinds of cognitive                   In order for a system to perform comparison-based
operations can lead to the discovery of new relational                predication, its representation of roles and fillers must share
concepts? One step toward constraining this otherwise                 a common basis (i.e., role and filler representations should
deeply underconstrained problem is to choose an                       share the same pool of features). To illustrate, consider our
appropriate form of knowledge representation. One such                example from above. Initially “red” is an implicit feature of
representation is a role-filler binding scheme, in which              both the apple and the fire engine. When they are compared,
relational roles and their arguments are represented                  the feature “red” is abstracted to a new representation (i.e., a
explicitly and bound together to form role-filler sets (much          new unit learns a connection to this feature), but the same
like collections of single-place predicates). Collections of          feature codes “red” in both cases. If the representation of a
role-filler sets are linked together to form whole relational         property in an explicit form (i.e., as a predicate that takes an
structures. For example, the representation of loves (John,           object as an argument) was coded by a different set of
Mary) consists of the representation of the lover role bound          features than the representation of that property in a holistic
to John (lover(John)) and the beloved role bound to Mary              form (i.e., as a feature of an object), then the system could
(beloved(Mary)) linked together to form the structure                 not learn explicit representations by abstracting features out
(lover(John)+beloved(Mary)) (see e.g., Doumas & Hummel,               of holistic representations: The representation of a property
in press).                                                            as an implicit feature of an object would have nothing in
   Role-filler binding systems provide a natural constraint on        common with the explicit representation of that property.
the problem of relation discovery by reducing relational                 We now present a theory of relation discovery based on
roles to single place predicates. As a result, the problem of         these constraining assumptions embodied in a computer
learning relations reduces, at least in principle, to the             simulation called DORA (Discovery Of Relations by
problem of learning single-place predicates (i.e., object             Analogy).
properties) and then linking those predicates to form
complete relational structures.                                                           The DORA Model
   Given this, how might we learn single-place predicates             Representational Structure
(i.e., object properties)? An important theme that has
                                                                         Representations in DORA are an extension of those in
emerged in the literature on relational reasoning is that
                                                                      Hummel and Holyoak’s (1997, 2003) LISA. Like LISA,
comparison plays a central role in all forms of relational
                                                                      DORA represents propositions in a hierarchy of distributed
reasoning (see Gentner, 1983, 2003; Holyoak & Thagard,
                                                                      and localist codes (see Figure 1). At the bottom of the
1995). A primary hypothesis motivating the present
                                                                      hierarchy, semantic units code for the features of relational
research is that comparison may also play a central role in
                                                                      roles and their fillers in a distributed fashion. At the next
the discovery and predication of new relations. The reason
                                                                      level are localist token units that code for specific relational
is that comparison, by putting objects into direct contrast,
                                                                      roles and objects. For example, the proposition “Bill chases
might serve to highlight shared properties. By revealing
                                                                      Larry”, would be represented (in part) by units for the
shared attributes of otherwise different-seeming systems,
                                                                      relational roles chaser and chased and the objects Bill and
comparison may bootstrap the discovery and explicit
                                                                      Larry (see Figure 1). Bill would be connected to a set of
representation of object properties and subsequently link
                                                                      semantic units denoting his features (e.g., “adult”, “male”,
                                                                  607

“police-officer”) and Larry to a set of semantic units
denoting his features (e.g., “adult”, “male”, “criminal”).
Similarly, the chaser and chased roles would be connected
to the semantic units denoting their features. Semantically
related objects and relational roles (e.g., chaser and pursuer)
share many semantic units, making their semantic similarity
explicit. Above the role and object units role-binding (RB)
units encode the bindings of specific roles to specific fillers.
Continuing our example, one RB unit would code for the
binding of Bill to the chaser role and another would code
for the binding of Larry to the chased role. At the top of the
                                                                     Figure 1. Illustration of a proposition in DORA. Triangles
hierarchy proposition (P) units bind sets of role-filler
                                                                     are used to denote roles and circles to denote objects for
bindings into complete relational structures.
                                                                     clarity. In DORA, the same types of units code both roles
                                                                     and fillers.
Role-Filler Binding
   The hierarchy in Figure 1 represents a proposition in
DORA’s long-term-memory (LTM). When a proposition
becomes active (i.e., enters working memory; WM) DORA
uses a form of asynchronous binding (see Love, 1999) to
bind roles to their fillers: Bound role-filler pairs fire in
direct sequence, which serves to dynamically bind roles to
fillers in WM, and also keeps the representations of roles
and fillers distinct for the purposed of processing. To
illustrate, in order to bind Bill to the chaser role and Larry
to the chased role (and so represent chase (Bill, Larry)), the
units corresponding to the chaser role fire directly followed
by the units corresponding to Bill (see Figure 2a and b),
then the units for the chased role fire directly followed by
the units for Larry (Figure 2c and d). A system that is
sensitive to couplets (or pairs) of activation can use this
information to represent the bindings of Bill to the chaser          Figure 2. Role-filler binding by asynchrony of firing in
role and Larry to the chased role.                                   DORA. The chaser role fires (a), followed by Bill, the
                                                                     object bound to that role (b). Then, the chased role fires (c),
Comparison Based Predication                                         followed by Larry, the object bound to that role (d).
   Because DORA uses a common pool of semantic units to
code the features of both roles and objects, it can learn
predicates by comparing objects. Propositions in DORA are
divided into two sets, a driver and a recipient set (see
Hummel & Holyoak, 1997). Token units in the driver
become active and pass activation to their semantics.
Through the shared semantic pool, units in the recipient
propositions become active and respond to these patterns of
activation. Using a mapping algorithm adapted from LISA,
token units of the same kind (e.g., role/filler, RB) that are
active at the same time in both the driver and recipient
develop excitatory mapping connections to one-another.
These connections represent existing mappings and
constrain the discovery of future mappings.
   In DORA comparison is accomplished via this mapping
process. When propositions are compared corresponding                Figure 3. Comparison based predication. (a) An apple and a
units develop excitatory mapping connections. Consider the           fire-engine are compared. (b) Semantics shared by both
example of our child learning the property “red”. Because            objects become more active than unshared semantics. (c) A
the apple and the fire engine were compared they are                 new unit is recruited and learns connections to the active
mapped. Thus, an excitatory connection develops between              semantics in proportion to their activation. (d) The new unit
them and one tends to activate the other (Figure 3a). Both           is bound to the apple and to the fire-engine via RB units.
units also activate their semantic features. Shared semantics        Solid lines = stronger connections, dashed lines = weaker
receive twice as much input and therefore become twice as            connections. Gray = more active units.
                                                                 608

active as unshared semantics (Figure 3b). When a pair of            experienced. For example, if DORA had previously
mapped roles or fillers fires, DORA recruits a unit to learn        experienced that a car was big, and a matchbook small, and
connections to the active semantics, where the learned              then it noticed a train was big and a mouse was small, it
weights are proportional to the semantic units’ activations         could map big(train) to big(car) and small(mouse) to
(Figure 3c). The new unit can then be bound to the                  small(matchbook). This processes leads to a distinct pattern
role/filler units that were compared to create it via an RB         of firing over the units composing each set of propositions
unit (Figure 3d). Thus the shared properties of the apple           (namely, the RB units of big(train) fire out of synchrony
and the fire-engine (here the properties “red” and “shiny”)         with those of small(mouse) while the RB units of big(car)
are explicitly predicated about these objects.                      fire out of synchrony with those of small(matchbook)). This
   We use the example of learning the predicate red only            pulsing activation over sets of units acts as a signal to link
because it is easy to explain. Applied to more complex              oscillating RB units with a P unit. This process results in a
arrangements of objects, the very same operations permit            rudimentary (and context dependent) representation of a
DORA to learn more complex relational roles (e.g., has-size         relation (here bigger-than (train, mouse)). Subsequently,
(x), more-high-than-something (x), beside-something (x))            the same schema induction routine that serves to refine
that can be used to construct complex relational                    predicate representations serves to refine whole relation
representations (e.g., higher (x, y), beside (x, y); see From       representations,       producing       context      independent
Predicated Object Attributes to Whole Relations and                 representations of whole relations.
Simulations sections, and Doumas et al., in prep.).
Representation Refinement via Schema Induction
   Consistent with numerous findings in the developmental
literature (for a review see Smith, 1989), new predicates are
initially very context dependent. Most compared objects
share a number of extraneous features (e.g., the apple and
the fire engine were both “shiny” and “red”). To refine
predicate representations DORA uses its systematic
asynchronous binding routine coupled with an adaptation of
LISA’s schema induction routine.
   When propositions are compared corresponding elements
are mapped. If, for example, our child compares two
representations of explicitly red objects the red predicates
will map, as will their fillers (Figure 4a). Because roles fire
in direct sequence with their fillers, the mapped predicate
representations fire out of synchrony with their fillers.           Figure 4. Asynchronous schema based refinement. (a) The
Semantics shared by the two red predicates will become              red+apple role-filler binding maps to the red+book role-
twice as active as unshared semantics. Using a simple self-         filler binding (semi-dashed lines indicate mapping
supervised learning algorithm (Hummel & Holyoak, 2003)              connections).       (b) The red predicates activate their
token units are recruited to match active mapped pairs in the       semantics (darker gray indicates more activity). New units
driver and recipient propositions. So, a role/filler unit will      are recruited to respond to the active predicates and the
be recruited to learn connections to the active semantics           active RB (full lines indicate stronger connections, dashed
(encoding the overlap of the two red predicates; Figure 4b).        lines weaker connections). (c) The apple and book objects
When the mapped objects fire, a second role/filler unit will        become active, activating their semantics. A new object
be recruited to learn connections their shared semantics. In        unit is recruited to respond to the newly active objects.
addition, an RB unit will be recruited to encode the binding
of the two new role/filler units (Figure 4c). Thus, a refined                                Simulations
and schematized representation of the property red is                  Smith (1984) tested children’s ability to match items
formed.                                                             based on identicality, shared properties, and shared relations.
                                                                    The experimenters each selected two object based on
From Predicated Object Attributes to Whole                          identicality (e.g., both selected two identical items), a shared
Relations                                                           property (e.g., both selected two red items of different
   DORA provides a number of ways to learn whole                    types), or a shared relation (e.g., experimenter 1 chose two
relational representations (Doumas et al., in prep.). One of        red items of different size and shape, and experimenter 2
the most fundamental involves learning relations by                 chose two blue items of different size and shape). The child
mapping sets of co-occurring role-filler sets. If multiple          then had to select two items based on the same rule as that
role-filler sets enter DORA’s WM together, it can map them,         used by the experimenters. They found that two, three, and
as a set, onto other co-occuring role-filler sets it has            four-year olds could select items based on identicality, but
                                                                609

only three and four-year olds could consistently select items         representations (e.g., higher with semantics of “high” and
based on shared properties, and only four-year olds could             lower with semantics of “low”) and 10 value-independent
consistently select items based on shared relations.                  representations of height (e.g., representations of height
   DORA predicts this exact trajectory. Beginning with                without “high” or “low” semantics). We simulated five-
holistic object representations, DORA abstracts out and               year olds with 30 value-dependent and 30 value-
predicates representations of object properties (i.e., single         independent representations of height. At both “ages” we
place predicates). It then concatenates sets of single-place          also included 30 random propositions about butterflies.
predicates to form whole relations. When DORA only                       This distribution of propositions in LTM was chosen as it
represents objects, it can match based on over-all featural           mirrors DORA’s learning trajectory.            Starting with
similarity (e.g., it can match two red balls because they             representations of objects with semantics like as “high” and
share many semantic features), like the 2 year-olds in                “low” and “has-height” it learns single place explicit
Smith’s study.          Once DORA has predicated object               representations of high and low. Applying the more relation
properties, it can match objects based on their shared                to pairs of high and low items produces loaded
properties (e.g., it can match the propositions red (x) to red        representations of higher and lower (i.e., higher things that
(y) based on the similar predicates), like the 3 year-olds in         are “high” and lower things that are “low”). As DORA
Smith’s study.           When DORA learns relations by                compares high items to low items it begins to extract less
concatenating single-place predicates it can match objects            value-laden representations of the abstract property of
based on relational similarity (e.g., it can match the                height (i.e., has-height (x)). Applying the more relation to
propositions same-color (x, y) with same-color (a, b) based           pairs of items with the value-independent representation of
on the similar relations), like the 4 year-olds in Smith’s            height predicated about them produces value free
study. Importantly, DORA must follow this trajectory.                 representations of higher and lower (i.e., more-height (x, y)).
DORA learns structured representations of object properties           What is important here is that DORA must learn the value-
from unstructured representations of objects, and uses them           dependent representations first because it learns value-
to form representations of relations.                                 independent representations from them.
   We also used DORA to simulate the findings of Smith,                  We had DORA retrieve propositions from LTM using a
Rattermann, & Sera (1988). In this study children ages 4-5            retrieval algorithm based on the LISA model (Hummel &
were presented with pairs of toy butterflies at three different       Holyoak, 1997) and then map retrieved propositions onto
sets of heights: (1) One butterfly at one foot the other at           the propositions in the driver. The proposition that mapped
two feet; (2) one at three the other at four feet; (3) one at         most strongly to a driver proposition was selected as the
five and the other at six feet. The child was asked whether           winner and DORA answered the question which butterfly is
one of the two butterflies was higher (or lower) and if so            higher/lower using this proposition (e.g., if it mapped a
which one. On consistent trials both butterflies were high            representation of higher onto a predicate that took butterfly1
(or low) and the child was asked whether one was higher (or           as an argument it answered butterfly1 in response to the
lower). On neutral trials both butterflies were in the middle         question “which is higher” and guessed in response to the
(at three and four feet) and the child was asked whether one          question “which is lower”). Our results very closely
was higher or one was lower. On the inconsistent trials both          matched the empirical data (see Table 1). Because DORA
butterflies were high (or low) and the child was asked                is a process model, our interest is with qualitative fits of
whether one was lower (or higher). The 4 year-olds                    data. Importantly, the qualitative patterns we report are very
performed well on the consistent trials, but progressively            robust with respect parameter values.
worse on neutral and inconsistent trials. The 5 year-olds
performed well on all trial types (see Table 1).                                                  Table 1.
   DORA can learn to appreciate variations in the magnitude
of quantifiable properties (i.e., it learns the relation more (x,                        Consistent    Neutral    Inconsistent
y); Doumas et al., in prep.), so in this simulation if DORA           Children age 4       75.1          73.8          57.5
predicated a quantifiable property (e.g., height) about two           DORA age 4           67.3          61.4          53.5
objects it was allowed to apply the more (x, y) relation to the       Children age 5       87.6          86.5          81.5
role-filler sets (i.e., to represent that one of the two objects      DORA age 5           88.1          88.9          82.4
had more of that property than the other). We held the
representation of the problem constant across “age” in the               We have also used DORA to simulate a number of other
driver. For all trial types a proposition expressed that one          empirical findings (Doumas et al., in prep.).
butterfly had more height than the other (more-
height(butterfly1, butterfly2), see below). For the consistent                                 Discussion
and inconsistent trial types two additional propositions
                                                                         We have presented a theory of predication and relation
expressing that butterfly1 and butterfly2 were high or low
                                                                      discovery embodied in DORA, a computational model.
(e.g., high(butterfly1) and high(butterfly2)) were included.
                                                                      DORA provides a systematic account of how object
We varied the proportion of knowledge in LTM by “age”.
                                                                      properties and relational concepts can be learned from
We simulated four year-olds with 30 value-dependent
                                                                      examples. The primary hypothesis motivating DORA is
                                                                  610

that the same cognitive operations that exploit relational           in the study of language and thought (pp.195-235).
representations (namely, analogical mapping and schema               Cambridge, MA: MIT Press.
induction) are fundamental to their discovery. Our account         Gentner, D., & Rattermann, M. J. (1991). Language and
rests on a set of core theoretical claims. First, representing       the career of similarity. In S. A. Gelman & J. P. Byrnes
knowledge in a role-filler binding scheme reduces the                (Eds.), Perspectives on thought and language:
problem of relational discovery to the problem of                    Interrelations in development (pp. 225 – 277). New York:
predicating object properties and linking them to form full          Cambridge University Press.
relational structures. This makes the problem of relation          Gick, M. L., & Holyoak, K. J. (1983). Schema induction
discovery tractable. Second, comparison coupled with                 and analogical transfer. Cognitive Psychology, 15, 1-38.
intersection discovery can bootstrap the predication of            Hummel, J. E., & Holyoak, K. J. (1997). Distributed
object properties. Comparison-based predication requires             representations of structure: A theory of analogical
that roles and objects share a common representational basis,        access and mapping. Psychological Review, 104, 427-466.
and that the mechanism for binding roles to fillers not only       Hummel, J. E., & Holyoak, K. J. (2003). A symbolic-
explicitly represents role-filler bindings, but keeps bound          connectionist theory of relational inference and
roles and fillers distinct for the purposes of processing.           generalization. Psychological Review.
   Starting with holistic representations of objects, DORA         Kotovsky, L., & Gentner, D. (1996). Comparison and
learns structured representations of object properties (i.e.,        categorization in the development of relational similarity.
single-place predicates) and relations (i.e., multi-place            Child Development, 67, 2797-2822.
predicates). In so doing it provides a natural account of          Love, B. C. (1999). Utilizing time: Asynchronous binding.
children’s progression from holistic to more structured                Advances in Neural Information Processing Systems, 11,
knowledge representations. One limitation of DORA is that              38-44.
currently it does not speak to the question of where the           Namy, L. L., & Gentner, D. (2002). Making a silk purse out
semantic features of objects come from in the first place. (It       of two sow’s ears: Children’s use of comparison in
is worth noting that DORA is not alone in this respect. All          category learning. Journal of Experimental Psychology:
computational models are forced to assume some population            General, 131, 5-15.
of primitives.) A complete account of relation discovery           Ratterman, M. J., & Gentner, D. (1998). More evidence for
should address both how structured representations arise             a relational shift in the development of analogy:
from holistically represented collections of primitive               Children’s performance on a causal-mapping task.
features, as well as the origins of those primitive features.        Cognitive Development, 13, 453-478.
DORA provides a solution to the first of these problems,           Sandhofer, C. M, Smith, L. B. (2001). Why children learn
and we are currently working to generalize the same                  color and size words so differently: Evidence from adults'
routines to account for the second.                                  learning of artificial terms. Journal of Experimental
                                                                     Psychology: General, 130, 600-617.
                     Acknowledgements                              Smith, L. B. (1984). Young children’s understanding of
                                                                     attributes and dimensions. Child Development, 55, 363-
   The authors thank Steve Engel, Keith Holyoak, and Cathy
                                                                     380.
Sandhofer for helpful discussions.
                                                                   Smith, L. B. (1989). From global similarities to kinds of
                                                                     similarities: The construction of dimensions in
                          References                                 development. In S. Vosniadou and A. Ortoney (Eds.),
Doumas, L. A. A., & Hummel, J. E. (in press). Approaches             Similarity and analogical reasoning (pp. 147-177).
   to modeling human mental representations: What works,             Cambridge: Cambridge University Press.
   what doesn’t, and why. In K. J. Holyoak & R. Morrison           Smith, L. B., Rattermann, M. J., & Sera, M. (1988).
   (Eds.), The Cambridge Handbook of Thinking and                    “Higher” and “lower”: Comaprative interpretations by
   Reasoning. Cambridge: Cambridge University Press.                 children. Cognitive Development, 3, 341-357.
Doumas, L. A. A., Hummel, J. E., & Sandhofer, C. M. (in            Thompson, R. K. R., & Oden, D. L. (2000). Categorical
   prep.). A symobolic-connectionist model of predication            perception and conceptual judgments by nonhuman
   and relation discovery.                                           primates: The paleological monkey and the analogical ape.
Falkenhainer, B., Forbus, K. D., & Gentner, D. (1989). The           Cognitive Science, 24, 363-396.
   structure-mapping engine: Algorithm and examples.               von der Malsburg, C. (1981/1994). The correlation theory
   Artificial Intelligence, 41, 1-63.                                of brain function. In E. Domany, J. L. van Hemmen, & K.
Gasser, M. & Colunga, E. (2001). Learning relational                 Schulten (Eds.), Models of neural networks II (pp. 95-
   correlations. International Conference on Cognitive               119). Berlin: Springer.
   Modeling, 4, 91-96.                                             Yamauchi, T., & Markman, A. B. (1998). Category
Gentner, D. (1983). Structure-mapping: A theoretical                 learning by inference and classification. Journal of
   framework for analogy. Cognitive Science, 7, 155-170.             Memory & Language, 39,124-148.
Gentner, D. (2003). Why we’re so smart. In D. Gentner and
   S. Goldin-Meadow (Eds.), Language in mind: Advances
                                                               611

