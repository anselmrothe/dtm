UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Diagnosis of Ambiguous Faults in Simple Networks
Permalink
https://escholarship.org/uc/item/02n5k1c4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Goodwin, Geoffrey P.
Johnson-Laird, P.N.
Publication Date
2005-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                              Diagnosis of Ambiguous Faults in Simple Networks
                                         Geoffrey P. Goodwin (ggoodwin@princeton.edu)
                                       Department of Psychology, Green Hall, Princeton University
                                                          Princeton, NJ 08544 USA
                                             P. N. Johnson-Laird (phil@princeton.edu)
                                       Department of Psychology, Green Hall, Princeton University
                                                          Princeton, NJ 08544 USA
                              Abstract                                   i.e., in order for it to transmit a signal, it had to receive
                                                                         activation from every one of its input nodes. Faults were
   We propose a theory of how individuals diagnose faults, and           failures in one or more output nodes to yield a signal. The
   we report two experiments that tested its application to the          participants’ task was to locate the cause of a fault by
   diagnosis of faults in simple Boolean systems. Participants
                                                                         performing tests on single connections between pairs of
   were presented with simple network diagrams in which a signal
   was transmitted from a set of input nodes to an output node, via
                                                                         nodes. They needed to find the single faulty node that
   a set of connecting nodes. Their task was to detect and diagnose      accounted for all and only the observed output failures.
   faults. Experiment 1 showed that individuals tend to diagnose            These studies showed that several factors increased the
   events closest to an observed inconsistency as the cause of the       difficulty of the task, but they did not reveal much about the
   fault. Experiment 2 replicated this proximal effect, but also         initial generation of hypotheses to explain the faults. In order
   demonstrated that participants tend to target the proximal node       to investigate this process, we adopted a modified version of
   most often when it fails to transmit a signal. This phenomenon        the network task. Our networks were much simpler than those
   may occur because individuals construct models of those               previously investigated: they had only six nodes (Experiment
   situations in which a node works, but leave implicit those
                                                                         1) or seven nodes (Experiment 2), and only a single output
   situations in which it does not work. The present results
   extend the mental model theory to diagnostic reasoning.
                                                                         node. We allowed that the connecting nodes could be one of
                                                                         three sorts of Boolean operator – AND, OR, and OR ELSE.
How do individuals diagnose faults in simple systems? If                 And the participants were not required to determine the cause
something goes wrong, what guides their initial hypotheses               of the fault definitively, but only to formulate a preliminary
about the cause of the fault? In this paper we propose a theory          hypothesis about what to investigate first in the network in
that explains the diagnosis of faults in simple Boolean                  order to find the fault.
networks, and we report experimental tests of the theory. The
theory assumes that individuals diagnose faults by mentally                                       Experiment 1
simulating the network in a dynamic mental model (see                    The purpose of the study was to examine the ability of naïve
Johnson-Laird, 1983). It postulates three main principles for            individuals to detect inconsistencies in the behavior of a
diagnosis. First, individuals assume that causes of faults occur         simple network and the nature of their diagnoses. All the
prior to the fault and as close to it as possible. Hence, they           problems used the network shown in Figure 1.
should locate faults as close as possible to the output of a                 Input nodes      Connecting Nodes           Output
network. We refer to this sort of diagnosis as a “proximal”                                                              Node
bias, i.e., the proximal cause is the event that occurs nearest to
the effect. Second, individuals should be more likely to                    1                               B
diagnose faults in the proximal node when it ought to transmit
a signal than when it ought not to. Third, individuals assume               2
by default that complex components are more likely to go                                     A
wrong than simple components. One index of complexity is
the ease of understanding how a component works.                            3
   Prior research has investigated fault finding in network
tasks (see e.g., Morrison & Duncan, 1988; Rouse, 1978;                                Direction of signal
Rouse & Rouse, 1979). Participants were presented with a
matrix of nodes, connected in a variety of different ways. A                       Figure 1: The network used in Experiment 1.
set of input nodes was connected by intermediary nodes to a
set of output nodes. Typically, the networks consisted of a              The participants were told that inputs are fed into the three
matrix of about 49 nodes (7 by 7). The input nodes each                  input units, and a signal is transmitted from left-to-right to the
transmitted a signal through the system, and in the basic form           output node. It may or may not produce an output depending
of the task, each connecting node acted as an AND operator,              on the particular inputs and on the particular logical
                                                                         connectives (AND, OR, or OR ELSE) in the two nodes (A
                                                                     791

and B). On a given trial, the participants were presented with          the eight possible input patterns (there are eight possible
the inputs, the logical connectives in each node, and the               patterns, given three inputs with two settings each). Each
output, and they first judged whether the input-output                  input pattern was presented twice – once when the network
configuration was correct or incorrect. If they judged it as            produced a correct output, and once when it produced an
incorrect, they next indicated which of the two nodes, A or B,          incorrect output. The full set of the 29 problems that had
they would prefer to investigate first in an attempt to diagnose        incorrect outputs is presented in Table 1. The six sorts of
the cause or causes of the fault. This question was designed to         problem were presented in six separate blocks in a random
elucidate the principles underlying their diagnostic intuitions.        order for each participant, as was the order of the problems in
   The theory predicts that they should focus on the node               each block. There were six practice problems using the same
closest to the output. It further predicts that this bias should be     connective in both nodes.
strongest when that node ought to transmit a signal but in fact
does not. This prediction stems from a known bias to                            Table 1: The full set of inconsistent problems used in
represent only what is true in reasoning: individuals construct         Experiment 1, with the percentages of node choices alongside
mental models of propositions in which each model                                                   each node.
represents a true possibility, and within each of these true
possibilities, only those clauses that are true within that                No.     Inputs: 1    Output     Node A         Node B
possibility are represented (see principle of truth, Johnson-                      2 3
Laird & Savary, 1999). Extending the first component of this               1       0 0 0*          1       OR (16)        AND (79)
principle to the present domain, we predicted that individuals             2       1 0 0           1       OR (45)        AND (53)
should be more likely to construct explicit models of the                  3       1 1 0           0       OR (29)        AND (63)
                                                                           4       1 1 1           0       OR (26)        AND (66)
conditions under which each node transmits a signal rather                 5       0 0 0           1       AND (24)       OR (76)
than the conditions under which it does not transmit a signal.             6       0 1 0           1       AND (82)       OR (16)
As participants try to diagnose a fault in a network, their                7       0 1 1           0       AND (26)       OR 71)
attention should focus on nodes that ought to transmit a                   8       1 1 1*          0       AND (0)        OR (87)
signal, but which in fact do not. There is a mismatch between              9       0 0 0*          1       XOR (21)       AND (79)
the participants’ models of the node, which explicitly                     10      1 0 0           1       XOR (47)       AND (53)
represent only the transmitting possibilities, and their models            11      1 1 0           0       XOR (32)       AND (58)
of the node’s actual functioning, which is not to transmit a               12      0 1 1*          1       XOR (34)       AND (66)
signal (see the mismatch principle, Johnson-Laird, Girotto, &              13      1 1 1           1       XOR (89)       AND (8)
                                                                           14      0 0 0           1       AND (16)       XOR (84)
Legrenzi, 2004). Of course, there is also a mismatch in the                15      1 0 0           0       AND (11)       XOR (89)
case where a node ought not to transmit a signal, but in fact              16      0 1 0           1       AND (66)       XOR (24)
does transmit one, but the theory predicts an asymmetry in                 17      1 1 0           0       AND (21)       XOR (55)
diagnoses because of the tendency to represent explicitly only             18      0 1 1           0       AND (24)       XOR (68)
the transmitting possibilities. Finally, the theory predicts that          19      1 1 1           1       AND (24)       XOR (76)
nodes that are the most difficult to process should be                     20      0 0 0           1       XOR (42)       OR (55)
diagnosed as faulty most often.                                            21      0 1 0           0       XOR (45)       OR (50)
                                                                           22      1 1 0*          0       XOR (16)       OR (82)
Method                                                                     23      0 1 1           1       XOR (89)       OR (8)
                                                                           24      0 0 0           1       OR (29)        XOR (61)
                                                                           25      1 0 0           0       OR (13)        XOR (79)
Participants. Thirty-nine participants (13 male, 26 female)
                                                                           26      0 1 0           0       OR (37)        XOR (61)
from Princeton University were paid $10 or received course                 27      1 1 0           1       OR (34)        XOR (63)
credit for their participation.                                            28      0 1 1           0       OR (21)        XOR (71)
                                                                           29      1 1 1           1       OR (26)        XOR (74)
Design and Materials. Participants acted as their own                   Note. Consistent with standard logical notation, OR ELSE in
controls, and each performed 58 test problems. All problems             Table 1 is represented by XOR. Problems marked with an
used the network shown in Figure 1. The problems were                   asterisk are ones where the error could be explained only by
divided into six different categories according to the logical          an error in Node B. Problems in bold produced aberrant
connectives (AND, OR, or OR ELSE) in the two main nodes                 results (see results and discussion).
in the network. An AND node is one that transmits a signal if
and if only if it receives a signal from all of its inputs. An OR       Procedure. The participants were tested individually with a
node is one that transmits a signal if and only if it receives a        computer running the Eprime program. Each problem
signal from at least one of its inputs, or both. An OR ELSE             appeared on the screen as a static diagram of the network
node is one that transmits a signal if and only if it receives a        (showing the inputs, the logical operator within each
signal from at least one, but not both, of its inputs. Given the        connecting node, and the output), with yellow input and
three connectives and the two nodes, there are six sorts of             output nodes indicating that they were “on”, and white nodes
problem given that we examined only those problems in                   indicating that they were “off”. The participants judged
which the connectives in the two nodes were different. Within           whether the network was correct or incorrect by pressing “c”
each sort of problem, we selected a representative subset from
                                                                    792

or “i”, on the keyboard. After each practice problem                 there are two potential confounds. First, the proximal node, B,
participants received feedback about whether they had or had         was always at the top of network. Second, it was connected to
not made a correct evaluation of the network. In order to            both an input node and the output node, whereas the other
proceed to the main stage of the experiment, participants were       node, A, was not directly connected to the output node.
required to perform five out of six practice problems                   We examined factors that may modify the proximal bias.
correctly. For these problems, participants judged whether the       As the theory predicted, the proximal node was chosen more
network was behaving correctly or incorrectly, but did not go        frequently when it ought to have transmitted a signal but
on to make a diagnosis for the incorrect networks. They              failed to do so, than when it ought not to have transmitted a
repeatedly cycled through the same set of practice problems          signal, and yet did so (68% vs. 57%, Wilcoxon test, z = 3.13,
(in a new random order each time) until this criterion was           p < .01). In other words, the proximal node was more liable to
achieved. Participants required a mean of 1.79 cycles, and the       be diagnosed as faulty when it produced a “miss” rather than
modal number of cycles was 1.                                        a “false positive”. This difference may arise from
   In the experiment proper, the participants judged whether         participants’ explicitly constructing a model of the conditions
or not a network was correct. But, when they judged that it          under which the node should transmit a signal rather than
was incorrect, they then made a preliminary diagnosis. They          when it should not.
typed “a” or “b” to select node, A or B, as the one that they           As the theory also predicts, the participants were more
would test first in a preliminary investigation into what was        likely to locate the fault in the proximal node when it was an
wrong with the network. This judgment was hypothetical, i.e.,        OR ELSE node (67%), than when it was an AND node (59%,
participants did not go on to conduct the test, nor were they        Wilcoxon test, z = 2.53, p < .02) or an OR node (55%,
presented feedback about which node was in fact responsible          Wilcoxon test, z = 3.2, p < .01). But, there was no difference
for the error. The network remained on the screen while the          between AND and OR nodes (Wilcoxon test, z = .41, p =
diagnosis was made.                                                  .684). As the latency results above show, OR ELSE appears
                                                                     to be harder to understand than the other two connectives.
Results and discussion                                               Hence, it is a more complex connective for our participants,
The data from one participant were removed as a result of a          and so the participants should infer that a fault is more likely
computing error. The participants were accurate in their             to occur in its nodes. It may be that mere fluency of
judgments about whether or not the network was correct               processing exerts a direct effect on diagnosis (see Schwarz,
(95% correct). They were faster to make accurate judgments           2004). There were four problems in which node A was
about correct circuits than about incorrect circuits (6.60s vs.      chosen more frequently than node B (nos. 6, 13, 16, 23, in
7.43s, Wilcoxon test, z = 2.82, p < .01). Problems that              bold). But, for each of these four networks, the proximal node
included an OR ELSE node appeared to pose an extra                   transmitted output when it should not have. As we have
difficulty. The participants took longer to make judgments of        already seen, the proximal bias was attenuated for such
correctness for these circuits (7.25s) than for problems             problems. In addition, node A was an OR ELSE node for
without an OR ELSE node (6.25s; Wilcoxon test, z = 2.4, p <          problems 13 and 23, which made it more liable to be
.02). This effect occurred for judgments of both correct and         diagnosed as being in error.
incorrect networks (Wilcoxon tests, z = 2.76, p < .01; z = 2.08         Experiment 1 established that individuals are proficient at
p < .05, respectively). Networks that included OR ELSE               judging the correctness of simple networks. They are faster to
nodes therefore appeared somewhat more difficult to                  make accurate judgments about consistent networks than
simulate.                                                            about inconsistent networks. Their preliminary diagnoses
   The percentage of node choices for each problem is                corroborated the theory in three ways. First, they tended to
displayed in Table 1 (the percentages do not always sum to           locate faults in proximal nodes, i.e., those that were closest to
100 owing to some participants’ failure to identify the              the output revealing that a fault had occurred. Second, they
network as inconsistent, or to their pressing the wrong              were more likely to do so when the proximal node failed to
button). There was a consensus about which node to                   produce output when it should have than when it produced
investigate first for the circuits that were incorrect. As the       output when it should not have. Third, they also tended to be
theory predicts, the participants tended to select the node          biased towards locating the fault in the proximal node when it
closest to the output. This proximal bias was greater than 20%       was an OR ELSE node. These nodes are harder to
for 21 out of the 29 incorrect circuits. For problems where          understand, and so that difficulty may indicate that the node is
either A or B may have been in error (there were 24 such             complicated, and hence more likely to go wrong.
problems; and the five remaining problems were ones where
only B could account for the error, see table 1), the difference                             Experiment 2
between the percentages of A and B choices was 20% across            In order to eliminate the confounds in the previous
all subjects (Wilcoxon test, z = 3.3, p < .01), and across all       experiment, we carried out a second experiment using a more
problems (Wilcoxon test, z = 2.06, p < .05). This proximal           complicated network of seven nodes (see Figure 2). The
bias may occur because nodes earlier in the network are              theory yields three predictions. First, individuals should show
considered more reliable, or because individuals prefer to           the proximal bias, i.e., they should be biased to select node,
locate causes as close as possible to their effects. However,        D, as the cause of the fault.
                                                                 793

                                                                    with the constraint that the four possible types of input
                                                                    pattern (0 0; 0 1; 1 0; 1 1) were nearly equally represented
   Input Nodes       Connecting                Output               across the whole experiment.
                     Nodes                     Node
                                                                    Procedure. The procedure was the same as in Experiment 1.
 1                        B                                         The mean number of required cycles through the practice
                                                                    segment was 1.33, and the modal number was 1. When the
                                                                    participants made their diagnoses in the main part of the
                A                   D
                                                                    experiment, they indicated which node from A, B, C, or D,
                                                                    they would test first (by typing “a”, “b”, “c”, or “d”).
                          C
 2
                                                                    Results and Discussion
                                                                    Overall accuracy in detecting inconsistencies was high, as in
        Direction of signal                                         the first experiment. All problems were performed at greater
          Figure 2: The network used in Experiment 2.               than or equal to 75% accuracy. Participants correctly judged
                                                                    90% of the networks: 89% of the consistent networks and
   Second, the network again allowed us to investigate how          90% of the inconsistent networks (there was no reliable
the tendency to diagnose the proximal node is affected by           difference between these percentages).
mental models of its functioning. As before, we predicted              Table 2 illustrates the diagnoses made for the main classes
that the proximal node should be diagnosed as the faulty            of problems in the experiment (percentages do not sum to 100
component more often when it ought to transmit a signal but         owing to participants’ errors). The proximal bias was again
does not do so, than when it ought not to transmit a signal but     reliable. Across all problems, the percentages of selections of
does so. This tendency should arise from a bias to represent        each node were as follows:
only the transmitting possibilities of the proximal node.                 A: 22%
Third, networks that include OR ELSE nodes should take                    B: 11%
longer to evaluate than those that do not, and hence an                   C: 13%
account based on processing fluency predicts that the                     D: 43%
proximal node will be identified as the cause of the fault more     The last node, D, was chosen more often than each of the
often when it is an OR ELSE node.                                   other three nodes (all three pairwise Wilcoxon comparisons
                                                                    were significant, p < 0.01).
Method
                                                                      Table 2: The percentages of node choices depending on the
Participants. Twenty-four participants (15 male, 9 female)               functioning of the proximal node, D, in Experiment 2.
from Princeton University participated for course credit.
                                                                              Type of problem          Node     Node    Node  Node
Design and Materials. Participants acted as their own                                                  A        B       C     D
controls, and each performed 27 test problems that all used         Networks in which the proximal     13       10      9     54
the network in Figure 2 and the same three connectives as in        node should transmit output but
Experiment 1. Of the 27 problems, 23 were incorrect                 fails to do so.
                                                                    Networks in which the proximal     27       13      15    38
networks and four were correct networks.
                                                                    node should not transmit output
   We suspected that the first and last nodes, A and D, would       but does so in error.
be most salient, and would be diagnosed as faulty more                                                 15       8       12
                                                                    Networks in which the proximal                            53
frequently than either B or C. B and C are likely to be less        node was OR ELSE.
salient since they occupy symmetrical positions in the overall      Networks in which the proximal     29       13      13    39
network structure, and it should therefore be harder to             node was not OR ELSE.
motivate a choice of one over the other as the cause of the         Note. The horizontal line separates the two main sets of
fault. Hence, in order to test the proximal bias, the               comparisons. Numbers in bold indicate the key comparisons
connectives in the first and last nodes were always identical,      within each set.
whereas the connectives in the middle nodes were always
selected to be different from those in the end nodes. The              The predictions based on the mismatch principle were
problems were further divided into three main categories            confirmed. The participants were more likely to diagnose the
according to whether the first and last connectives were: OR,       proximal node, D, when it should have transmitted a signal
AND, or OR ELSE. Within each of those three categories,             but in fact did not, than when it should not have transmitted
there were three further sub-types, depending on the                but in fact did so (54% vs. 38%, Wilcoxon test, z = 2.3, p <
connectives in the middle nodes. Problems were sampled              .05). This again supports our theory that a mismatch between
from each of these nine categories. Different input patterns        an explicit model of the situations in which a node will
are also possible, and we selected these roughly at random,         transmit a signal, and a model of the node’s actual non-
                                                                794

transmission, leaves the node particularly liable to be               probably relies less on the temporal order of a mental
diagnosed as the cause of fault.                                      simulation, and more on the greater cognitive effort required
   As in Experiment 1, for inconsistent networks in which at          to change an earlier (as opposed to a later) component of a
least one input was on, those that included at least one OR           network. An earlier change may call for a later change,
ELSE node took longer to correctly evaluate than those that           whereas a later change need have no effect on what happened
had no such nodes (17.4s vs. 14.4s., Wilcoxon test, z = 2.43,         earlier in the network. There may thus be a rational element
p < .01, one-tailed). The theory predicts that participants           to this tendency.
should choose OR ELSE nodes with a greater frequency than                 There is less room for a rational interpretation of the
they choose either AND or OR nodes. And participants were             tendency to diagnose faults in the proximal node when it
more likely to diagnose the proximal node as faulty when it           produced a “miss” rather than a “false positive”. A failure to
was an OR ELSE node (53%) than when it was an AND node                transmit a signal is just as much an error than as the mistaken
(39%, Wilcoxon test, z = 2.59, p < .01), or an OR node (38%,          transmission of an signal, and there is no logical reason why
Wilcoxon test, z = 3.18, p < .01). Participants again seemed to       the proximal node is implicated to a greater extent in the first
prefer diagnosing more complex nodes as the cause of error.           sort of error. The bias, however, was predicted from an
                                                                      extension of the model theory’s principle of truth and its
                    General Discussion                                mismatch principle. According to this extension, participants
   The model theory of diagnosis proposes that individuals            are influenced by the match between their model of how the
base their intuitions on a mental simulation of a network. It         proximal node ought to be operating, and their model of its
postulates three main principles. First, individuals focus on         actual operation. The model of how the proximal node ought
proximal causes when forming diagnoses. Second, they tend             to be operating represents explicitly only the possibilities in
to diagnose the fault in the proximal node more often when it         which the node transmits a signal, leaving implicit the
ought to transmit a signal. And, third, they tend to diagnose         possibilities in which it does not transmit a signal. Hence,
faults in more complex nodes. We tested these principles in           while both misses and false positives produce mismatches,
two experiments which investigated how individuals form               only misses give rise to a mismatch with an explicit model of
intuitive diagnostic preferences when diagnosing a faulty             the node’s functioning, and thus lead to an increased
network.                                                              proclivity to attribute error. The tendency occurred only for
   Experiment 1 showed that individuals tended to diagnose            the proximal node, and not for the other nodes. However, this
the fault in the node that was as close as possible to its            difference makes sense, because the participant knows for
occurrence. This result could have been explained by other            certain only the output of the proximal node. Mismatches for
factors, but it held up in Experiment 2, in which such                the other nodes are a matter of inference. If, as we claim, the
alternative explanations were not available. This                     mismatch bias is responsible for the phenomenon, its
demonstration of a proximal effect parallels work showing             operation must be largely unconscious, because in post-
that more recent events are more likely to be “undone” in             experimental questioning, no participant ever put it into
counterfactual thinking (see Byrne, Segura, Culhane, Tasso,           words.
& Berrocal, 2000; Miller & Gunesegarm, 1990; Teigen,                      We found support for the theory’s third principle: complex
Evensen, & Samoilow, 1999; Walsh & Byrne, 2004, for the               nodes should tend to be diagnosed as the cause of faults. Both
temporal order effect). And it also parallels work on belief          experiments showed that OR ELSE gates were most liable to
revision, which has shown that information that is presented          be diagnosed as the source of error, and that they also took
earlier in a sequence tends to be regarded as less corrigible         the longest time to process. To our knowledge, this
(although the opposite effect has also been demonstrated in           demonstration is the first to show an effect of processing
some studies; see Hogarth & Einhorn, 1992, for a review).             fluency in diagnostic reasoning (see Schwarz, 2004).
Our findings extend this previous work by demonstrating a                A skeptic might argue that the diagnostic choices we
proximal effect in a Boolean domain, where information is             observed, and particularly the effects of mismatch, result
presented simultaneously rather than sequentially, but a              from posing a question to the participants that did not have a
mental model must reconstruct the temporal sequence of                correct answer. Such effects are arguably likely to be fleeting
events.                                                               and unimportant. We agree that the effects may not have a
   One interpretation of the proximal effect is that the parts of     persistent impact when individuals have to discover a single
the network that are mentally simulated first tend to be              and unambiguous cause of a fault (as in Rouse and his
regarded as the least revisable. This account attributes the          collaborators’ experiments). But, such tasks are unlikely to
result to memory processes – initial information may be the           match the diagnosis of faults in the real world. Evidence for
most salient (see e.g., Anderson, 1981; Hogarth & Einhorn,            them is rarely clear and unambiguous (see e.g., Dörner, 1996,
1992; Schlottmann & Anderson, 1995). We have offered an               on the Chernobyl incident). Ambiguous evidence is liable to
alternative interpretation: individuals tend to mentally undo         be assimilated to match prior hypotheses and to be processed
the event closest in causal proximity to an observed                  in a distorted way (e.g., Darley & Gross, 1983; Lord, Ross, &
inconsistency. These two interpretations are different, but our       Lepper, 1979). In such situations, the phenomena that we
present data are not able to distinguish between them. Yet, the       observed may prevent people from using new evidence to
second interpretation seems more plausible. The effect                reach a correct diagnosis.
                                                                  795

                    Acknowledgements                               Johnson-Laird, P. N., Girotto, V., & Legrenzi, P. (2004).
                                                                     Reasoning        from     inconsistency    to    consistency.
This research was supported by a grant from the National
                                                                     Psychological Review, 111, 640-661.
Science Foundation to the second author to study strategies in
                                                                   Lord, C. G., Ross, L., & Lepper, M. R. (1979). Biased
reasoning (BCS-0076287), and by a fellowship awarded to
                                                                     assimilation and attitude polarization: The effects of prior
the first author from the Woodrow Wilson School, Princeton
                                                                     theories on subsequently considered evidence. Journal of
University. We thank Louis Lee and three anonymous
                                                                     Personality and Social Psychology, 37, 2098-2109.
reviewers for their advice.
                                                                   Miller, D. T., & Gunasegaram, S. (1990). Temporal order and
                                                                     the perceived mutability of events: Implications for blame
                         References                                  assignment. Journal of Personality & Social Psychology,
Anderson, N. H. (1981). Foundations of information                   59, 111-1118.
  integration theory. New York: Academic Press.                    Morrison, D. L. & Duncan, K. D. (1988). Strategies and
Byrne, R. M. J., Segura, S., Culhane, R., Tasso, A., &               tactics in fault diagnosis. Ergonomics, 31, 761-784.
  Berrocal, P. (2000). The temporality effect in                   Rouse, W. B. (1978). Human problem solving performance in
  counterfactual thinking about what might have been.                a fault diagnosis task. IEEE Transactions on Systems, Man,
  Memory & Cognition, 28, 264-281.                                   and Cybernetics, 8, 258-271.
Darley, J. M., & Gross, P. H. (1983). A hypothesis-                Rouse, W. B., & Rouse, S. H. (1979). Measures of
  confirming bias in labeling effects. Journal of Personality        complexity of fault diagnosis tasks. IEEE Transactions on
  and Social Psychology, 44, 20-33.                                  Systems, Man, and Cybernetics, 9, 20-727.
Dörner, D. (1996). The logic of failure: Why things go wrong       Schlottmann, A., & Anderson, N. H. (1995). Belief revision
  and what we can do to make them right (R. Kimber & R.             in children: Serial judgment in social cognition and decision-
  Kimber, Trans.). New York: Metropolitan Books.                    making domains. Journal of Experimental Psychology:
Hogarth, R. M., & Einhorn, H. J. (1992). Order effects in           Learning, Memory,            and Cognition, 21, 1349-1364.
  belief updating: The belief-adjustment model. Cognitive          Schwarz, N. (2004). Metacognitive experiences in consumer
  Psychology, 24, 1-55.                                              judgment and decision making. Journal of Consumer
Johnson-Laird, P. N. (1983). Mental models. Cambridge:               Psychology, 14, 332-348.
  Cambridge University Press.                                      Teigen, K. H., Evensen, P. C., & Samoilow, D. (1999). Good
Johnson-Laird, P. N., & Savary, F. (1999). Illusory                  luck and bad luck: How to tell the difference. European
  inferences: A novel class of erroneous deductions.                 Journal of Social Psychology, 29, 981-1010.
  Cognition, 71, 191-229.                                          Walsh, C. R., & Byrne, R. M. J. (2004). Counterfactual
                                                                     thinking: The temporal order effect. Memory & Cognition,
                                                                     32, 369-378.
                                                               796

