UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Simulating Optional Infinitive Errors in Child Speech through the Omission of Sentence-
Internal Elements
Permalink
https://escholarship.org/uc/item/65c4s3fn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Freudenthal, Daniel
Gobert, Fernand
Pine, Julian
Publication Date
2005-01-01
Peer reviewed
  eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

                   Simulating Optional Infinitive Errors in Child Speech through
                                  the Omission of Sentence-Internal Elements
                                   Daniel Freudenthal (D.Freudenthal@Liverpool.Ac.Uk)
                                           Julian Pine (Julian.Pine@Liverpool.Ac.Uk)
                                             School of Psychology, University of Liverpool
                                                          L69 7ZA Liverpool, UK
                                        Fernand Gobet (Fernand.Gobet@Brunel.Ac.Uk)
                                         School of Social Sciences and Law, Brunel University
                                                   Uxbridge, Middlesex, UB8 3PH, UK
                              Abstract                                  form1. Wexler’s hypothesis explains the data from a variety
                                                                        of languages. However, there are two main weaknesses
  A new version of the MOSAIC model of syntax acquisition is            associated with the account. First, it fails to provide any
  presented. The modifications to the model aim to address two          quantitative predictions regarding the rate at which children
  weaknesses in its earlier simulations of the Optional Infinitive
                                                                        will use nonfinite forms in finite contexts, and, second, it
  phenomenon: an over-reliance on questions in the input as the
  source for Optional Infinitive errors, and the use of an
                                                                        ignores the possibility that children’s early language use
  utterance-final bias in learning (recency effect), without a          may reflect the operation of an input-driven learning
  corresponding utterance-initial bias (primacy effect). Where          mechanism as opposed to rich innate linguistic knowledge.
  the old version only produced utterance-final phrases, the new
  version of MOSAIC learns from both the left and right edge                   Simulating Child Language in MOSAIC
  of the utterance, and associates utterance-initial and utterance-
                                                                        MOSAIC is an attempt to investigate the extent to which
  final phrases. The new model produces both utterance-final
  phrases and concatenations of utterance-final and utterance-          children’s early language use can be explained by an input-
  initial phrases. MOSAIC now also differentiates between               driven learning mechanism. MOSAIC learns from Child-
  phrases learned from declarative and interrogative input. It          Directed speech and produces output that can be directly
  will be shown that the new version is capable of simulating           compared to children’s speech. MOSAIC has already been
  the Optional Infinitive phenomenon in English and Dutch               used to simulate the basic Optional Infinitive phenomenon
  without relying on interrogative input. Unlike the previous           in English and Dutch (Freudenthal, Pine & Gobet, 2002a,
  version of MOSAIC, the new version is also capable of                 submitted), as well as phenomena related to Subject
  simulating cross-linguistic variation in the occurrence of            Omission (Freudenthal, Pine & Gobet, 2002b) and the
  Optional Infinitive errors in Wh-questions.
                                                                        Modal Reference effect (Freudenthal, Pine & Gobet, 2004).
                                                                        MOSAIC is a simple discrimination network that
    The Characteristics of Early Child Speech                           incrementally learns and stores utterances that are presented
Early child speech is often telegraphic, and (in many                   to it. An important restriction on MOSAIC’s learning
languages) lacks inflections that are required in the adult             mechanism is that it builds up its representation of an
grammar. For example, English-speaking children produce                 utterance by starting at the end of the utterance and slowly
utterances such as Play car and He go and Dutch-speaking                working its way to the beginning. MOSAIC is therefore
children produce utterances such as Pappa eten (Daddy eat)              capable of producing an utterance such as He go by
and Trein spelen (Train play). As children grow older, the              producing the final phrase of Does he go? Similarly, it can
length of their utterances increases, their speech becomes              produce the Dutch utterance Trein spelen by producing the
less telegraphic, and they provide the appropriate inflections          ending of the phrase Ik wil met de trein spelen (I want with
more frequently. However, there is a period in which                    the train play). As MOSAIC sees more and more input, it
children use verbs in both their correct (inflected) and                learns to produce progressively longer utterances. As
incorrect (uninflected) forms in contexts in which inflected            utterances become longer, they are more likely to contain
forms are required. The apparent lack of inflection in child            finite verb forms. (Both in Dutch and English finite verb
speech has been the subject of considerable linguistic and              forms tend to occur near the beginning of the utterance. A
Nativist theorizing. Wexler (1994) proposes the Optional                model that produces utterance-final phrases will therefore
Infinitive hypothesis, which states that young children know
the full grammar of their language but optionally use
nonfinite forms where the adult grammar requires a finite
                                                                        1
                                                                          Data from languages like Dutch, which has an infinitival
                                                                        morpheme, suggest that, rather than dropping inflections, children
                                                                        are using non-finite verb forms in finite contexts.
                                                                    708

produce more utterances containing finite verb forms as the        version of MOSAIC that aims to accomplish this by
length of these utterances increases.)                             learning from both edges of the utterance and associating
   While MOSAIC successfully simulates the quantitative            sentence-initial and sentence-final fragments.
patterning of the Optional Infinitive phenomenon in English           The remainder of this paper is organized as follows: First,
and Dutch, its reliance on learning from the end of the            the new version of MOSAIC and its mechanism for
utterance also gives rise to certain weaknesses. First, the        associating utterance-initial and utterance-final phrases is
model is overly reliant on questions in the input as the           described. Next, two new simulations on a Dutch and an
source of Optional Infinitive errors with (third singular)         English child are compared to simulations with the earlier
subjects. While some Optional Infinitive errors with third         version of MOSAIC in terms of the fit to the Optional
singular subjects (e.g. Daddy eat or Pappa eten) can be            Infinitive phenomenon. It will be shown that the new
learned as sequences from (relatively infrequent) declarative      version still simulates the basic Optional Infinitive
double verb constructions (e.g. I see Daddy eat/Ik zie Pappa       phenomenon. Importantly, however, the new analyses are
eten), others (e.g. He eat a n d Hij eten) never occur as          performed on output learned from declarative phrases. Next,
sequences in declarative utterances. MOSAIC simulates              a more detailed analysis is performed on MOSAIC’s ability
such errors by learning them from questions such as Does           to simulate Optional Infinitive errors in Wh-questions.
he eat? or Gaat hij eten? (Goes he eat?). However, given
the obvious differences in the intonation contours of                                         MOSAIC
declaratives and questions, learning declaratives from             MOSAIC consists of a simple network of nodes that encode
questions might be regarded as somewhat implausible,               words and phrases that have been presented to the model.
especially if MOSAIC is seen as implementing a                     As the model sees more input it will incrementally encode
constructivist model of language development in which              more and longer phrases and will consequently be able to
children’s early knowledge consists of a repertoire of             generate more and longer output. Figure 1 shows a sample
unanalyzed wholes and lexically specific constructions             MOSAIC network. Learning in MOSAIC is anchored at the
learned directly from the input (e.g. Pine, Lieven &               sentence-initial and sentence-final positions: MOSAIC will
Rowland, 1998; Tomasello, 2000, 2003). Developing a way            only encode a new word or phrase when all the material that
of learning Optional Infinitives from declarative contexts         either follows or precedes it in the utterance has already
would therefore not only increase the plausibility of the          been encoded in the network. When presented with the
model, but also bring it more in line with general                 utterance He wants to go to the shops for instance, the
constructivist theorizing.                                         model may in the first instance encode the words He and
   One way in which MOSAIC could learn Optional                    shops. At a later stage it may encode the phrases He wants
Infinitives from declaratives is through the omission of           and the shops, until the point where it has encoded the entire
sentence-internal elements. An utterance such as He go, for        phrase He wants to go to the shops. When the model
example, could be produced by omitting the modal can from          processes an utterance, and a sentence-final and sentence-
He can go, or omitting wants to, from He wants to go. In           initial phrase for that utterance have already been encoded
Dutch, Hij eten (He eat) could be learned from Hij wil eten        in the network, MOSAIC associates the two nodes encoding
(He wants (to) eat). The omission of sentence-internal             these phrases, to indicate the two phrases have co-occurred
elements may also enable MOSAIC to simulate children’s             in one (longer) utterance. In Figure 1, the model has
Optional Infinitive errors in Wh-questions. English-               associated the phrases He wants and Go home.
speaking children often produce utterances such as What he
do? or Where he going? At present, MOSAIC is unable to
produce such utterances as it is not capable of omitting the
sentence-internal is or does. Developing a way of simulating
such errors would therefore also be a step forward.
Moreover, the occurrence of Optional Infinitive errors in
Wh-questions is an interesting domain for simulation in
itself, as English and Dutch speaking children appear to
produce such errors at rather different rates.
   At a more general level, the strict utterance-final bias in
MOSAIC is not very plausible in terms of general learning
theory. There is a wealth of evidence that human subjects             Figure 1: A partial MOSAIC model. The sentence-initial
display a primacy as well as a recency effect. The addition            phrase he wants, and the sentence-final phrase go home
of an utterance-initial bias (a requirement for implementing          have been associated, allowing the model to produce the
sentence-internal omission) to MOSAIC may therefore                                 utterance He wants go home.
resolve the weaknesses associated with the reliance on
questions and the omission of sentence-initial phrases, as         Learning in MOSAIC takes place by adding nodes that
well as bring the model more in line with general                  encode new words and phrases to the model. Learning is
psychological theorizing. This paper describes a new               relatively slow. The formula governing the probability of
                                                                   creating of a node in MOSAIC is as follows:
                                                               709

                                                                        branches that encode sentence-final phrases. (Sentence-
                                             d                          initial fragments are not generated as these may end in the
                              1                                       middle of the sentence, and often do not resemble child
 NCP =                                                                speech).
                1+ e 0.5((m*c )−u)                                       The second mechanism which is new to this version of
                                                                        MOSAIC is the concatenation of sentence-initial and
                                                                        sentence-final phrases. When MOSAIC builds up the
where: ncp = node creation probability
                                                                        network, it associates the sentence-initial and sentence-final
          m = a constant, set to 20 for these simulations.
                                                                        fragments from each utterance (cf He wants go home in
          c = corpus size (number of utterances)                        Figure 1). Since the concatenation of phrases could result in
          u = (total number of) utterances seen                         many implausible utterances, not all possible concatenations
          d = distance to the edge of the utterance                     are produced. A source utterance like Give the man a hand,
                                                                        for example, could potentially give rise to the concatenated
The formula results in a basic sigmoid function, with the               phrase Give the a hand. This utterance is awkward (and not
probability of creating a node increasing as a function of the          typical of child speech) because it breaks up the unit the
number of times the input has been presented. The input                 man. MOSAIC prevents such concatenations by only
corpus (which consists of realistic child-directed speech) is           concatenating phrases that are anchored: a sentence-initial
fed through the model iteratively, and output can be                    phrase can only be used for concatenation if the last word in
generated after every presentation of the input corpus.                 that phrase has occurred in a sentence-final position.
Making the node creation probability dependent on the                   Likewise, a sentence-final phrase can only be concatenated
number of times the corpus has been seen allows for                     if the first word in that phrase has occurred in sentence-
comparison across corpora of differing sizes. The distance              initial position. Since the word the will not occur in
to the edge (or length of the utterance being encoded)                  sentence-final position, the phrase Give the a hand will not
features in the exponent in the formula, and lowers the                 be generated. The rationale behind this restriction is that, to
likelihood of encoding long utterances. As a result,                    the extent that children concatenate phrases/omit sentence-
MOSAIC will initially only learn sentence-initial and                   internal elements, they will rarely break up syntactic units.
sentence–final words. Only when the base probability in the             Restricting concatenation to phrases where the internal
formula starts to increase (as a result of seeing more input),          edges are anchored effectively achieves this, as an anchored
                                                                        word is unlikely to be a partial unit.
will longer phrases start being encoded. Due to node-
                                                                           The rote output of MOSAIC thus consists of a mixture of
creation being probabilistic, a word or phrase must normally
                                                                        sentence-final phrases and concatenations of sentence-initial
be seen several times before it will be encoded. Frequent
                                                                        and sentence-final phrases. Both types of utterances are
words or phrases therefore have a higher probability of                 apparent in child language. An example of a phenomenon
being encoded than infrequent words or phrases.                         that might be explained through omission of sentence-initial
   MOSAIC maintains an utterance-final bias in that                     elements is the omission of subjects from the sentence-
learning from the right edge of the utterance is faster than            initial position (Bloom, 1990). Due to MOSAIC’s learning
learning from the left edge. This is accomplished by adding             mechanism and faster right-edge learning, MOSAIC’s
2 to the length of a left edge phrase2 (the parameter d) that is        output will initially contain a large proportion of sentence-
considered for encoding (The parameter d designates                     final fragments. As the Mean Length of Utterance (MLU) of
distance from the left edge of the utterance for left edge              the model increases, concatenations will become more
learning, and distance to the right edge of the utterance for           frequent. The concatenations themselves will be slowly
right edge learning). This learning mechanism results in a              replaced by complete utterances.
model that is biased towards learning sentence-initial words               The two mechanisms described so far produce output that
and a few (high-frequency) sentence initial phrases coupled             directly reflects the utterances present in the input (with the
with comparatively long utterance-final phrases. As a result,           potential omission of sentence-initial or sentence-internal
the sentence-internal elements that MOSAIC omits will tend              material). These two mechanisms are complemented by a
to be located near the left edge of the utterance.                      third mechanism which is responsible for the generation of
                                                                        novel utterances through the substitution of distributionally
Generating output from MOSAIC                                           similar words. When two words tend to be followed and
MOSAIC has two mechanisms for producing (rote) output.                  preceded by the same words in the input, they are
The first mechanism is (almost3) identical to that in earlier           considered equivalent, and can be substituted for each other.
                                                                        Thus, the model is capable (in principle) of producing the
versions of MOSAIC. In generation, the model traverses the
                                                                        utterance She run by omitting will from He will go, and
branches of the network, and generates the contents of
                                                                        substituting She for He, and run for go. A more in-depth
2
                                                                        discussion of MOSAIC’s mechanism for substituting
  The utterance-final bias applies to phrases, but not words.           distributionally similar items is given in Freudenthal, Pine
Sentence-initial and sentence-final words are equally likely to be      and Gobet (2005a), though the chunking mechanism
encoded.
3                                                                       described in that paper has not yet been implemented in the
  In line with the restriction discussed under concatenation, only
                                                                        present version of the model.
utterance-final phrases that start with a word that has occurred in
utterance-initial position are produced.
                                                                    710

                            The Simulations                              (2005b). As detailed in Freudenthal, Pine & Gobet
                                                                         (submitted), Dutch children show considerable
The main aim of the simulations was to replicate the
                                                                         developmental variation in their use of Optional Infinitives.
simulations of the Optional Infinitive phenomenon as
                                                                         Early in development, nearly all their utterances with verbs
reported in Freudenthal, Pine, and Gobet (submitted). In
                                                                         contain non-finite verb forms. By the time they approach an
these simulations, a good fit to the data was achieved, but
                                                                         MLU of 4, this has decreased to roughly 20% (see Fig. 2a).
these simulations relied too strongly on interrogative input.
                                                                         For English, the data are less clear. Since English uses an
For the present simulations, questions and declaratives were
                                                                         impoverished inflectional system, it is necessary to restrict
marked separately in the input (using the punctuation
                                                                         the analysis to utterances with a third singular subject.
present in the raw input files). Every word in the
                                                                         Doing so suggests a rate of Optional Infinitive errors around
interrogative input utterances was marked for being part of a
                                                                         50% at MLU 2, which rapidly declines as the MLU
question (creating a separate entry in the model for the
                                                                         increases (see Fig. 2b).
occurrence of a word in a declarative and an interrogative
                                                                           For all analyses the following classification of utterances
context). This made it possible to filter out utterances
                                                                         was used. Utterances that only contained non-finite verb
learned from interrogative input and only generate output
                                                                         forms were classed as non-finite. Utterances that only
that was learned from declarative input.
                                                                         contained finite verb forms were classed as simple finites.
                                                                         Utterances containing both finite and non-finite verb forms
                          Figure 2a: Data for Matthijs.
                                                                         were classed as compound finites. Utterances with the
                                                                         copula as the main verb were excluded from the analysis.
                                                                         The same classification scheme was used for English and
                      1
                                                                         Dutch, with the exception that the analysis on English was
                    0.8                                                  restricted to utterances containing a third singular subject,
       Proportion
                                                   Non-finite            and that English verb forms which could either be finite or
                    0.6
                                                   Simple Finite         non-finite (e.g. bought), were classed as ambiguous.
                    0.4                            Comp. Finite
                    0.2                                                                      Figure 3a: Old simulations for Matthijs.
                      0
                          1.5 2.1       2.8 3.5                                               1
                                MLU                                                          0.8
                                                                                Proportion
                                                                                             0.6                               Non-finite
                                                                                                                               Simple Finite
                          Figure 2b: Data for Anne                                           0.4                               Comp. Finite
                                                                                             0.2
                     1
                                                                                              0
                    0.8                                                                            1.4    2.3     3.1    3.8
                                                   Non-finite
       Proportion
                    0.6                            Simple Finite                                           MLU
                    0.4                            Comp. Finite
                                                   Ambiguous                                  Figure 3b: Old simulations for Anne
                    0.2
                     0
                          2.2       3      3.4                                                1
                                MLU                                                          0.8
                                                                                                                               Non-finite
                                                                                Proportion
                                                                                             0.6                               Simple Finite
  Figure 2: Development of finiteness marking for a Dutch                                    0.4                               Comp. Finite
                    and English child.                                                       0.2
                                                                                                                               Ambiguous
  The simulations were run using the child-directed speech                                    0
for one Dutch, and one English child, both taken from the                                           2.1     2.6         3.4
CHILDES database (MacWhinney, 2000). The Dutch Child                                                       MLU
(Matthijs) was part of the Groningen Corpus (Bol, 1995),
the English child (Anne) was taken from the Manchester                     Results for the old simulations are shown in Figures 3a
corpus (Theakston, Lieven, Rowland & Pine 2001). The size                and 3b. The main reason why the model simulates the
of the input was approximately 14,000 utterances for                     developmental pattern apparent in the children is because
Matthijs, and 35,000 utterances for Anne. Additional                     the model generates utterance-final phrases of increasing
simulations for one Dutch and English child, as well as a                length. As was mentioned, inflected verb forms tend to
German and Spanish child can be found in Freudenthal et al.
                                                                   711

occur near the beginning of the utterance, while uninflected                weakness that we hope to address through further
verb forms tend to occur nearer the end of the utterance                    refinement of the concatenation mechanism.
(especially for Dutch where non-finite verb forms are placed
in utterance-final position). A model that produces utterance               Optional Infinitives in Wh-questions
final phrases of increasing length will therefore show a                    Having established that MOSAIC is capable of simulating
decreasing proportion of utterances containing only non-                    the basic Optional Infinitive phenomenon in declaratives,
finite verbs with increasing MLU.                                           we can now turn to Optional Infinitives in Wh-questions.
   Figures 4a and b show the results for the new simulations.               English-speaking children sometimes omit inflection in Wh-
In these simulations, MOSAIC could only produce                             questions, resulting in utterances such as Why he go? In
utterances from nodes learned from declarative contexts.                    Dutch, and other V2 languages, Optional Infinitives appear
Output was made up of concatenations as well as utterance-                  to be quite rare in Wh-questions (Wexler, 1998). In order to
final phrases. The main thing to note about Figure 4 is that                establish the rates of Optional Infinitive errors in the two
the concatenation mechanism which results in the omission                   children, the corpora of Anne and Matthijs were searched
of sentence-internal elements is capable of producing                       for the occurrence of Wh-words in interrogative contexts. In
Optional Infinitive errors at rates that are sufficiently high to           order to unambiguously identify root infinitives in these
match the child, even when Optional Infinitive errors are                   utterances, only utterances with a subject and main verb
restricted to third singular contexts (for English). As such,               were included. Anne’s corpus contained 111 such questions,
sentence-internal omission appears to be a successful                       of which 41 (37%) were non-finite. The corpus of Matthijs
mechanism for the production of Optional Infinitive errors.                 contained relatively few Wh-questions (11), but none of
                                                                            these were non-finite, confirming Wexler’s (1998)
                      Fig 4a: New simulations for Matthijs                  observation. In order to establish whether MOSAIC
                                                                            simulates this pattern of results, a sample of Wh-questions
                       1                                                    was generated from the model (at MLU 3.0). Analysing
                     0.8                                                    these utterances in the same way as the children’s utterances
        Proportion
                                                      Non-finite            yielded 20% non-finite Wh-questions for Anne’s model
                     0.6                                                    compared to 8% non-finite Wh-questions for Matthijs’s
                                                      Simple Finite
                     0.4                              Comp. Finite          model (see Table 1). While not as pronounced as the
                     0.2                                                    difference between the children, this difference was
                                                                            statistically significant Χ2 = 8.88, p < .01
                       0
                           1.4   2.1       3    3.6                          Table 1: Finite and Non-finite Wh-questions for Anne and
                                  MLU                                                          Matthijs’s simulations
                      Figure 4b: New simulations for Anne.                                           Non-Finite               Finite
                      1                                                           Anne                    30                   123
                     0.8
                                                      Non-finite
       Proportion
                                                                                 Matthijs                 15                   164
                     0.6                              Simple Finite
                     0.4                              Comp. Finite          MOSAIC simulates this distinction between English and
                                                      Ambiguous             Dutch because, despite omitting sentence-internal elements,
                     0.2
                                                                            MOSAIC’s output still adheres to the basic word order for
                      0
                                                                            the language it is learning. In English, Wh-questions include
                            2          3       3.6
                                                                            a non-finite main verb preceded by a finite auxiliary (e.g.
                                  MLU                                       Where does he go?). English Wh-questions will therefore
                                                          .                 always contain a non-finite verb form and omission of the
For Dutch, the results are comparable to those for the earlier              auxiliary will result in an Optional Infinitive error. Dutch on
simulations, though a slightly better fit is achieved for the               the other hand, allows for finite Wh-questions, such as Wat
final stage. For English, the proportion of non-finites early               eet hij? (What eats he?). While modal plus non-finite
on is increased relative to the earlier simulations, resulting              constructions are possible in Dutch Wh-questions (Wat wil
in a slightly better fit. One thing that stands out in the                  hij eten?/What wants he (to) eat?), Wh-questions in Dutch
English simulations is that, while the model produces                       are less likely to contain a non-finite verb. Thus, Optional
Optional Infinitives at rates that match the child reasonably               Infinitives are less likely to occur in the Dutch simulations
well, the model produces more simple finites than                           since frames that can give rise to Optional Infinitives
compound finites at the first two data points. This is a                    through omission of sentence-internal elements make up a
                                                                            smaller proportion of the Wh-questions in the input.
                                                                      712

                         Conclusions                               Bol, G.W. (1995). Implicational scaling in child language
                                                                     acquisition: the order of production of Dutch verb
This paper set out to address some weaknesses in earlier
                                                                     constructions. In M. Verrips & F. Wijnen, (Eds.), Papers
versions of MOSAIC: an over-reliance on questions as the
                                                                     from the Dutch-German Colloquium on Language
source for Optional Infinitives, and the lack of an utterance-
                                                                     Acquisition, Amsterdam Series in Child Language
initial bias in learning. A new mechanism was proposed
                                                                     Development, 3, Amsterdam: Institute for General
which allows MOSAIC to concatenate the beginnings and
                                                                     Linguistics.
ends of sentences, resulting in the omission of sentence-
                                                                   Freudenthal, D., Pine, J.M. & Gobet, F. (submitted).
internal elements. The simulations presented in this paper
                                                                     Modelling the development of Children’s use of Optional
show that the model is still capable of simulating the
                                                                     Infinitive in Dutch and English using MOSAIC.
Optional Infinitive phenomenon without relying on
                                                                     Submitted to Cognitive Science.
questions as the source for Optional Infinitive errors. In the
                                                                   Freudenthal, D., Pine, J.M. & Gobet, F. (2005a). On the
present version, declaratives are the source of Optional
                                                                     resolution of ambiguities in the extraction of syntactic
Infinitive errors. Declaratives in the input therefore appear
                                                                     categories through chunking. Cognitive Systems
to include a sufficiently high number of frames that can give
                                                                     Research, 6, 17-25.
rise to Optional Infinitive errors to offset the loss of
                                                                   Freudenthal, D., Pine, J.M. & Gobet, F. (2005b). Simulating
Optional Infinitives learned from questions.
                                                                     the cross-linguistic development of Optional Infinitive
   The omission of sentence-internal elements, coupled with
                                                                     Errors in MOSAIC. This Volume.
a distinction between questions and declaratives, has also
                                                                   Freudenthal, D., Pine, J. M., & Gobet, F. (2004). Simulating
made it possible to simulate Optional Infinitive errors in
                                                                     the temporal reference of Dutch and English Root
Wh-questions. Thus, MOSAIC now not only produces
                                                                     Infinitives. In K. Forbus, D. Gentner, & T. Regier (Eds.),
Optional Infinitive errors in Wh-questions, but also
                                                                     Proceedings of the 26th Annual Meeting of the Cognitive
simulates the difference in the rate of Optional Infinitive
                                                                     Science Society (pp. 410-415). Mahwah, NJ: Erlbaum.
errors in Wh-questions in English and Dutch. This suggests
                                                                   Freudenthal, D., Pine, J.M. & Gobet, F. (2002a). Modelling
that differences in the way that questions are formed in
                                                                     the development of Dutch Optional Infinitives in
English and Dutch may be the cause of the differential rates
                                                                     MOSAIC. In: W. Gray & C. Schunn (Eds.), Proceedings
of Optional Infinitives in Wh-questions in the two
                                                                     of the 24th Annual Meeting of the Cognitive Science
languages. Contrary to Wexler’s (1998) claims, the present
                                                                     Society (pp. 322-327). Mahwah, NJ: LEA.
simulations show that differential rates of Optional
                                                                   Freudenthal, D., Pine, J.M. & Gobet, F. (2002b). Subject
Infinitive errors may arise from a simple distributional
                                                                     omission in children’s language; The case for
analysis of the input, and therefore do not provide evidence
                                                                     performance limitations in learning. In: W. Gray & C.
for rich innate linguistic knowledge on the part of the child.
                                                                     Schunn (Eds.), Proceedings of the 24th Annual Meeting of
   One possible weakness of the present model is that some
                                                                     the Cognitive Science Society, (pp. 328-333). Mahwah,
of the fine detail of the simulations (the ratio of simple to
                                                                     NJ: LEA.
compound finites in the English declarative simulations)
                                                                   MacWhinney, B. (2000). The CHILDES project: Tools for
does not match the child as well as it might. Further
                                                                     analyzing talk. Third Edition. Mahwah, NJ: Lawrence
experimentation with the implementation of the
                                                                     Erlbaum Associates.
concatenation mechanism may improve this more detailed
                                                                   Pine, J. M., Lieven, E. V. M. & Rowland, C. F. (1998).
fit. However, the finding that the omission of sentence-
                                                                     Comparing different models of the development of the
internal elements from declaratives can still result in high
                                                                     English verb category. Linguistics, 36, 807-830.
rates of Optional Infinitives is encouraging as it brings
                                                                   Theakston, A.L., Lieven, E.V.M., Pine, J.M. & Rowland,
MOSAIC’s mechanism for the production of Optional
                                                                     C.F. (2001). The role of performance limitations in the
Infinitive errors more in line with general constructivist
                                                                     acquisition of Verb-Argument structure: an alternative
theorizing. Likewise, the primacy effect that is implemented
                                                                     account. Journal of Child Language, 28, 127-152.
with the left-edge learning resolves an inconsistency with a
                                                                   Tomasello, M. (2000). The item-based nature of children’s
large body of general learning research, thus making
                                                                     early syntactic development. Trends in Cognitive
MOSAIC more credible as a general learning mechanism.
                                                                     Sciences, 4, 156-163.
                                                                   Tomasello, M. (2003). Constructing a language: A usage-
                                                                     based theory of language acquisition. Cambridge, Mass.:
                    Acknowledgements                                 Harvard University Press.
 This research was funded by the ESRC under grant number           Wexler, K. (1994). Optional infinitives, head movement and
                         RES000230211                                the economy of derivation in child grammar. In N.
                                                                     Hornstein & D. Lightfoot (Eds.), Verb Movement.
                          References                                 Cambridge: Cambridge University Press.
                                                                   Wexler, K. (1998). Very early parameter setting and the
Bloom, P. (1990). Subjectless sentences in child language.           unique checking constraint: a new explanation of the
   Linguistic Inquiry, 21, 491-504.                                  optional infinitive stage. Lingua, 106, 23-79.
                                                               713

