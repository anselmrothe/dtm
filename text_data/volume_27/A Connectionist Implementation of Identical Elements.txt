UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Connectionist Implementation of Identical Elements
Permalink
https://escholarship.org/uc/item/0xt0g9vd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Bao, Jianghua
Munro, Paul
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                           A Connectionist Implementation of Identical Elements
                                             Paul Munro (pmunro@mail.sis.pitt.edu)
                                                    Jianghua Bao (jib2@pitt.edu)
                                      Department of Information Science and Telecommunications
                                                      School of Information Sciences
                                                         Pittsburgh, PA 15260 USA
                               Abstract                                  trained simultaneously on multiple tasks can learn faster and
                                                                         converge to a state of lower error than if it is trained on one
   In training two networks on tasks that are different on the sur-      of the tasks in isolation. This reinforcement among the
   face, but similar, or even isomorphic, at a higher level of de-       tasks depends on whether the individual tasks can benefit
   scription, similarities between the network solutions are plau-
                                                                         from common intermediate features.
   sible if not expected. Such similarities tend to become evi-
   dent when two networks with shared weights are trained on
   similar tasks. After training, the shared weights were used as                    Identical Elements in a Network
   part of a third network that was trained on a third task similar       The central idea introduced in this paper is that a network
   to the first two. This “head start” results in significantly           can learn high-level features common to different tasks, and
   shorter training times than a network that starts with random          use them in learning a novel task, assuming it has similar
   weights. Shared hidden unit response profiles were analyzed
                                                                          high-level attributes. This Identical Elements Neural Net-
   across networks trained on structurally analogous tasks to re-
   veal parallel, but nonidentical features.                              work (IENN) approach uses simultaneous training of multi-
                                                                          ple tasks, but differs from MTL in that the tasks do not
                           Background                                     share a common input. In principle, the tasks can have in-
                                                                          puts that have very different coding, dimensionality, etc.
Experimental evidence for transfer was described early in                 Some of the weights learned from simultaneous training are
the last century by Thorndike & Woodworth (1901), who                     then used to initialize a network that is trained on a novel
proposed the identical elements theory of transfer. The the-              task. These transferred weights remain fixed.
ory proposes that two different “mental functions” may
share cognitive structures in their processing.                           The IENN approach requires more than one hidden layer.
                                                                          Only the weights between hidden layers are shared by mul-
Two events may seem similar or identical at an abstract                   tiple tasks, thus allowing different numbers of input and
level of description or representation, yet very different on             output units for the individual tasks. This also enables a
the surface. Analogical reasoning depends upon feature ab-                novel task to use the shared weights without interfering with
straction at a level that is sufficient to subsume concrete               performance on the original tasks.1
features of multiple situations. Using this higher-level rep-
resentation, a mapping can be established between features
                                                                                  Network Architecture and Training
in the concrete instances (Gentner, 1983). Such an analogi-
cal mapping is a mechanism, probably not unique, for trans-               Feedforward networks were trained using backprop (cross-
fer of knowledge from one domain to another.                              entropy error). The networks were strictly layered with two
                                                                          hidden layers. Two inputs activated all units in the first
To the extent that the structures underlying analogy can be               hidden layer (H1), which subsequently activated all units in
                                                                         the second hidden layer (H2), which activated the sole out-
represented as patterns, the connectionist framework is a
                                                                         put unit. Each hidden layer had 16 units. Training was
natural approach (e.g., Holyoak & Thagard, 1988; Halford
                                                                         conducted in one of three modes: single network with ran-
et al, 1993). A distributed approach to structural mapping               dom initial weights, single network with prespecified
was put forward by Hummel & Holyoak (1994). Several                      weights between the two hidden layers, and two networks
symbolic-connectionist models have addressed the process-                with yoked (shared) weights between the hidden layers.
ing of structural mapping in the context of language proc-
essing (e.g., Mitchell, 1993).                                           Mode 1: Single Network with random initial weights.
                                                                         This was the control condition for each study. Network
Some other connectionist models have addressed transfer
                                                                         weights and biases were initialized to random values, and
phenomena without explicitly addressing analogy; that is,
                                                                         trained to a time/error criterion.
these models do not focus on the development of a struc-
tural mapping. Pratt et al. (1991) demonstrated that using
weights from a network trained on one task to initialize a
network to be trained on a similar task could improve learn-
ing performance. The Multi-task Learning (MTL) approach                   1
                                                                            An earlier version of this system appeared as a one page mem-
of Caruana (1997) demonstrated that a single network                     ber’s abstract at Cogsci ’96 (Munro, 1996).
                                                                     1559

Mode 2: Single Network with fixed H1-H2 weights.                   Control Condition (CC): Network weights and biases are
Here, weights between the two hidden layers and bias val-         randomly initialized (Mode 1), and trained on a task for
ues of both hidden layers were initialized to values that were    comparison with the two experimental conditions below
results of training on a different task. These weights and        (Figure 1a).
biases were not modified during training. Note that these
weights were used to backpropagate errors to H1 for modifi-       Experimental Condition I (EC I): Pretraining with a single
cation of the input-H1 weights.                                    task. A network is trained with random initial weights
                                                                   (Mode 1) on a preparatory task (P). The H1 - H2 weights
Mode 3: Two networks with shared weights.                          and biases are then used as initial parameters for a network
In this mode, two networks are trained on different tasks          trained on T in Mode 2 (Figure 1b).
using the same values for the weights between the hidden
units and the same bias values for units in both H1 and H2.        Experimental Condition II (EC II): Pretraining with two
The weight parameters for the two networks from the input          simultaneous tasks. Two networks are trained with shared
to H1 are independent, as are the weight and bias parameters      H1 - H2 weights and biases on two different tasks (Mode 3),
for the output units. Patterns are not presented simultane-       which are then used to initialize a network to be trained on T
ously to the two networks; i.e. the shared layer processes        in Mode 2 (Figure 1c).
patterns from either task during a given training step, not
from both simultaneously.
                                                                                           The Tasks
For each experiment, a network was trained on a target task
(T) in three conditions:                                           The tasks were all classification of regions in a two dimen-
                                                                   sional space. The two inputs were x-y coordinate values in
                                                                   the unit square. The output unit was trained using the cross-
   a                         r
                                                                   entropy error function to classify a region; the target value
                                                                   was 1 for inputs inside the region and 0 for inputs outside.
                                                                   Based on the intuition that topological similarity is more
                                                                   abstract than geometrical similarity, the tasks were chosen
                                                                   to be topologically equivalent but geometrically different.
                          x      y                                 Study 1. Closed Regions.
                          Task T                                   All tasks here were simple convex closed regions (Figure 2).
   b             r                          r
               x     y                   x     y                        Task P               Task Q                Task T
              Task P                    Task T                                               Figure 2.
                                                                   Study 2. Annular Regions.
   c        r                  r                  r
                                                                   All tasks in this study were annular, having two similarly
                                                                   shaped regions, one completely inside the other. The target
                                                                   region was defined as points between the two boundaries
                                                                   (Figure 3).
         x     y           x      y             x     y
         Task P            Task Q               Task T
Figure 1. a: Control Condition (Mode 1). b: Pretraining
with a single task (Modes 1,2) c: Pretraining with two tasks
(Modes 3,2).                                                            Task P               Task Q                Task T
                                                                                             Figure 3.
                                                              1560

                               Results                              Response profiles of hidden units at both H1 and H2 were
                                                             2      also examined. Sample response profiles from networks
The test set for the tasks was the entire input space ([0,1] )
                                                                    trained on tasks P and Q with shared weights are shown in
sampled with a resolution of 0.01. Errors were averaged
                                                                    Figures 6 and 7. Note that the left and middle profiles in the
over all 10000 points. In order to analyze the details of
                                                                    two figures are from the same H1 and H2 units in the shared
network computation, response profiles were plotted for the
                                                                    weight matrix. The response profiles are different because
output unit on each task as well as the units at both H1 and
                                                                    the input-H1 weights are trained independently. But for
H2. These correspond to receptive field plots from studies
                                                                    both tasks, the boundary in the H1 profile approximately
of neurons in visual cortex.
                                                                    corresponds to a significant portion of the H2 boundary.
Study 1. Closed Regions.                                            Also, note that the shading is reversed; the 1 (white side) is
                                                                    opposite in the H1 and H2 profiles. This reversal occurs for
Error curves were generated for the duration of the simula-         both figures since they share the same negative weight value
tion. Figure 4 shows error curves for Task T in the 3 condi-        between the hidden layers.
tions: control (a), using H1 and H2 weights from a network
trained on task P alone (b) and using H1 and H2 weights
from shared training on Tasks P and Q together (c). Note
that all three curves converge to approximately the same
low error value, but that transfer accelerates the error reduc-
tion.
                                                                    Figure 6. Response profiles from a network trained on the
                                                                    square task (P). Left: an H1 unit. Middle: an H2 unit.
       Average error
                                                                    Right: the output unit.
                               a
                           b
                       c
                                                                    Figure 7. Response profiles from a network trained on the
                               Time (iterations)                    triangle task (Q). Left: an H1 unit. Middle: an H2 unit.
                                                                    Right: the output unit. The H1 unit and H2 unit are in the
Figure 4. Error curves for the closed region. Each curve is         same position as those in Figure 6 with respect to the shared
an average over 5 trials. a. Task T alone (control) b. Task T       weights.
using weights transferred from Task P network (EC I). c.
Task T using weights transferred from Task P/Q network
(EC II).                                                            Study 2. Annular Regions.
                                                                    The three error traces in Figure 8 correspond to those in
Response profiles generated for the output unit at 10000            Figure 4. Note that these traces to not seem to converge to a
iterations and 300000 iterations illustrate the correspon-          common value. In the control condition the curve seems to
dence between average error and the shape of the boundary           keep decreasing (a), while the curves for the experimental
predicted by the network (Figure 5).                                conditions appear to converge to distinct values.
                                                                    Response profiles of the output unit for tasks P, Q, and T
                                                                    show a progression in task complexity during the course for
                                                                    learning that resembles that seen as one progresses through
                                                                    layers of the network (Figure 9). The shapes of the response
                                                                    profiles in the early/intermediate stages (left column) do not
                                                                    all show the same degree of complexity. The square annu-
                                                                    lus seems to be at a more advanced stage than the triangle
                                                                    and the circle. Of course, this can be attributed to the dif-
                                                                    ferences in the tasks, but the differences are also due to the
Figure 5. Output unit response profiles at 10000 iterations         random weight initialization.
(left) and 300000 iterations (right).
                                                                 1561

                                                                                          Discussion
                                                               The weights in feed-forward networks can encode task in-
                                                               formation that can be utilized by related tasks. The results
   Average error
                                                               demonstrate that weights shared between networks trained
                                                               on similar tasks encode the common aspects of the tasks.
                       a                                       Thus, the shared weights come to encode the common ab-
                                                               stract features when simultaneously trained on task pairs
                                                               that are similar at a high level of description and dissimilar
                   b                                           on the surface.
                   c                                           Examination of the response profiles from certain units in
                                                               both hidden layers shows a progression in complexity simi-
                                                               lar to the receptive fields of simple and complex cells in
                                                               visual cortex, first described by Hubel & Wiesel (1962).
                           Time (iterations)                   Units in the H1 layer can only form linear boundaries.
Figure 8. Error curves for the annulus. Each curve is an       Complexity at the output layer is determined by the task and
average over 5 trials. a. Task T alone (control) b. Task T     constrained by the network structure. Examination of H2
using weights transferred from Task P network (EC I). c.       response profiles seems to indicate that they compute func-
Task T using weights transferred from Task P/Q network         tions of complexity that is intermediate between H1 and H2.
(EC II).
                                                               Unlike observations in visual cortex, however, the response
                                                               properties here are task dependent, since the input-hidden
                                                               weights are independently trained for the different tasks.
                                                               Response profiles from a given H2 unit can be composed
                                                               from H1 response profiles for a given task (as in Figures 6
                                                               and 7). Since the same H1 - H2 weights and biases are used
                                                               to compute a different task, the response profile for the same
                                                               H2 unit should be composed from the same H1 units, even
                                                               though the response profiles are very different.
                                                                  The error traces from Study 2 (Figure 4) for the three ex-
                                                                  perimental conditions shows that transfer from a single task
                                                                  speeds learning, but that the control condition eventually
                                                                  catches up. Transfer from a set of weights that were shared
                                                                  by tasks learning two tasks that were not identical but had
                                                                  features in common with each other as well as the target
                                                                  task, clearly increased learning speed even more. This sup-
                                                                  ports our hypothesis that shared weights between networks
                                                                  trained on multiple tasks tend to encode features shared by
                                                                  the tasks. Thus, this may be a mechanism for abstraction of
                                                                  high level features and transfer to other tasks.
                                                                  The error traces for Study 2 (Figure 8) also show a progres-
                                                                  sive speedup from the control condition to the single task
                                                                  pretraining to the double task pretraining. However, there
                                                                  are also some important differences. Rather than converg-
                                                                  ing to the same error, these curves converge to different
                                                                  values. This difference is explained by the increase in com-
                                                                  plexity relative to Study 1. When all network parameters
                                                                  are adjustable, the network can find a state of minimum
                                                                  error. However for this more complex task, the adjustable
                                                                  parameters are not sufficient to reduce the error as much as
                                                                  in the control case. So while pretraining with a single task
                                                                  (Figure 8, trace b) gives faster learning, the final state has a
Figure 9. Intermediate response profiles for the three annu-      higher average error. With a larger number of hidden units,
lar patterns (left) and final response profiles (right). The      the system would be expected to reach an error state as low
sharp curves indicate the boundaries used to generate the         as the control condition. Presumably for that system, there
training data.                                                    would exist another task of even higher complexity that
                                                           1562

would “break” the system for fixed weights between the two                                    Conclusions
hidden layers.
                                                                     Consider the following framework for neural implementa-
Pretraining on simultaneous tasks (EC II) shows even faster          tion of analogical reasoning:
learning than does pretraining on a single task (Figure 8,
                                                                     •     Different tasks are learned in cortical circuits or path-
traces b and c). It also gives a lower error in the final state,
                                                                           ways that may partially overlap. Some of the neurons
however not as low as the control condition. This can be
                                                                           in overlapping circuits come to compute features that
explained as follows. As in EC I, the information in the
                                                                           support both tasks (high-level abstraction of concepts).
pretrained weights is initially beneficial, but eventually they
limit learning since they are not modifiable. The better as-         •     These same features may have general utility as compu-
ymptotic performance of EC II is consistent with the notion                tational elements in a larger class of tasks (transfer to
that the shared weights encode more abstract features that                 novel tasks).
are more relevant to the target task.
                                                                     •     Thus, the influences that determine a neuron’s compu-
Of course, one should tread very lightly when making infer-                tational properties can be described as not only “bot-
ences about neural function based on a connectionist model.                tom-up” and “top-down”, but also “cross-task”.
With this caveat in mind, let us consider what insights can
be extracted from IENN with respect to how the brain im-             Like the MTL work of Caruana (1997), the IENN model
plements analogical reasoning. Examination of the simula-            demonstrates that units serving multiple tasks can develop
tions suggests that an individual neuron may play a role in          response properties that serve both tasks from simultaneous
different computations, and that its response properties may         top-down influences. In the brain, it is expected that the
change drastically from one computation to another. How-             overwhelming majority of units (if not all) are involved in
ever, if the computations have similarities at some level of         multiple tasks.
description, they can take advantage of the same neural cir-         The ability to recognize and apply high-level analogical
cuits.                                                               correspondences across situations seems much more highly
Furthermore, we make the following conjecture. If two                developed in humans than in other species. If the IENN
neural circuits are learning different tasks, overlapping            account is a model of the neurobiological underpinnings of
components of those circuits will tend to encode common              analogical reasoning, then we should look to the prefrontal
features of the tasks.                                               cortex as a candidate brain structure, as others have sug-
                                                                     gested (e.g. Damasio, 1989).
This idea does not explain how one of the input streams to
the shared weights and synapses does not generate a re-              The IENN approach bears extension in several directions.
sponse in the wrong output stream. For example if this               Anticipated work includes working with transfer in simple
model is taken literally, an input to the channel trained on         recurrent networks (Elman, 1990), models of transfer in
Task T could elicit a response from the output units trained         motor learning and spatial cognition, and implementation in
on Task Q. On the one hand, this can probably be handled             a more biologically realistic system. We intend to go well
by a mechanism (neural, of course) for maintaining the con-          beyond the work of Dienes and Altman (1999), exploring
text of the input. Perhaps some direct connections from the          the interaction of tasks that are structurally similar but non-
input to the output would be sufficient. On the other hand,          identical.
some crossover is potentially a very powerful mechanism
for establishing corresponding elements of analogical struc-                             Acknowledgments
tures. Ideally, there is some crossover that will enable rea-        The authors wish to thank colleagues at the University of
soning about one situation to inform reasoning about an-             Pittsburgh School of Information Sciences for valuable
other situation, but the crossover is controlled somehow so          feedback. The input of the anonymous reviewers is also
that context is preserved.                                           acknowledged, especially for directing us to some relevant
                                                                     papers in the literature.
A very similar network architecture was constructed by Di-
enes et al. (1999) using a modification of Elman’s (1990)
simple recurrent network, or SRN. Here, an SRN with two
                                                                                               References
hidden layers was trained to learn an artificial grammar (as         Caruana, R. (1997) Multitask learning. Machine Learning,
in Cleeremans et al., 1989). This research demonstrated the             28:41-75.
usefulness of weights from a previous task. In their experi-         Cleeremans, A., D. Servan-Schreiber, and J.L. McClelland.
ments, the two tasks were structurally itentical. They dem-             (1989) Finite state automata and simple recurrent net-
onstrate an increase in performance by the second network               works. Neural Computation, 1:372--381.
                                                                     Damasio, A. (1989) Time-locked multiregional retroactiva-
over the first. Interestingly, comparison of the modifiable
                                                                        tion: A systems level proposal for the neural substrates of
layers from the two networks shows correlated but non-
                                                                        recall and recognition. Cognition 33:25-62.
identical weight matrices.                                           Dienes, Z., Altman G. T. M., and Gao, S.-J. (1999) Mapping
                                                                        across domains without feedback: A neural network
                                                                1563

  model of transfer of implicit knowledge, Cognitive Sci-            Hummel, J. & Holyoak, K. (1997) Distributed representa-
  ence 12:53-82.                                                       tions of structure: A theory of analogical access and map-
Elman, J. L. (1990). Finding structure in time. Cognitive              ping. Psychological Review, 104, 427- 466.
  Science, 14:179--211.                                              Mitchell, M. (1993) Analogy-making as Perception: A com-
Gentner, D., (1983) Structure-mapping: A theoretical                   puter model. Cambridge, MA: MIT Press.
  framework for analogy, Cognitive Science 7:155-170.                Munro, P. (1996) Shared network resources and shared task
Halford, G., Wilson, W., Guo, J., Gayler, R., Wiles, J.,               properties. In: Proceedings of the Eighteenth Annual
  Stewart, J. (1994). Connectionist implications for process-          Conference of the Cognitive Science Society. Mahwah NJ:
  ing capacity limitations in analogies. In: K. Holyoak & J.           Erlbaum
  Barnden (eds.) Advances in connectionist and neural                Pratt, L. Y., Mostow, J., and Kamm, C. A. (1991) Direct
  computation theory, vol. 2, Analogical Connections, pp.              transfer of learned information among neural networks.
  363--415. Norwood, NJ: Ablex.                                        In: Proceedings of the Ninth National Conference on Arti-
Holyoak, K. & Thagard, P. (1989) Analogical mapping by                 ficial Intelligence (AAAI-91) Anaheim CA
  constrant satisfaction. Cognitive Science 13, 295-355.             Thorndike, E. L.., & Woodworth, R. S. (1901). The influ-
Hubel, D. H., & Wiesel, T. (1962). Receptive fields, binocu-           ence of improvement in one mental function upon the ef-
  lar interaction, and functional architecture in the cat's vis-       ficiency of other functions. Psychological
                                                                                                             a     Review, 8, 247-
  ual cortex. J. Physiol. 160, 106-154.                                261.
                                                                1564

