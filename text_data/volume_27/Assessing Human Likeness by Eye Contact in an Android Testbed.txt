UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Assessing Human Likeness by Eye Contact in an Android Testbed
Permalink
https://escholarship.org/uc/item/19h3c74d
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Cowley, Stephen
Ishiguro, Hiroshi
Itakura, Shoji
et al.
Publication Date
2005-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

    Assessing Human Likeness by Eye Contact in an Android Testbed
                    Karl F. MacDorman,1,2 Takashi Minato,1 Michihiro Shimada,1
                      Shoji Itakura,3 Stephen Cowley,4 and Hiroshi Ishiguro1,5
                      1
                          Department of Adaptive Machine Systems and 2 Frontier Research Center
                                        Osaka University, Suita, Osaka 565-0871 Japan
                                         3
                                           Department of Psychology, Kyoto University
                                    Yoshida Honmachi, Sakyo-ku, Kyoto 606-8501 Japan
                                     4
                                       School of Psychology, University of Hertfordshire,
                                  College Lane, Hertfordshire AL10 9AB United Kingdom
                               5
                                 Intelligent Robotics and Communication Laboratories, ATR
                             2-2-2 Hikaridai, Keihanna Science City, Kyoto, 619-0288, Japan
                           Abstract                                        +
                                                                                                                   uncanny valley
                                                                                                                                    healthy
  The development of robots that closely resemble human                                                humanoid robot
                                                                                                                        {           person
  beings enables us to investigate many phenomena re-
  lated to human interactions that could not otherwise be
  investigated with mechanical-looking robots. This is be-                                            toy
                                                                           familiarity
  cause more humanlike devices are in a better position to                               industrial
  elicit the kinds of responses people direct at each other.                               robot
  In particular, we cannot ignore the role of appearance
  in giving us a subjective impression of social presence or
  intelligence. However, this impression is inﬂuenced by                                 human likeness      50%                100%
  behavior and the complex relationship between it and
  appearance. As Masahiro Mori observed, a humanlike                                                                            prosthetic
  appearance does not necessarily give a positive impres-                                                   moving corpse         hand
  sion. We propose a hypothesis as to how appearance
  and behavior are related and map out a plan for an-
  droid research to investigate this hypothesis. We then          Figure 1: Mori’s uncanny valley for animated objects
  examine a study that evaluates the behavior of androids         [Mori, 1970].
  according to the patterns of gaze ﬁxations they elicit in
  human subjects. Studies such as these, which integrate
  the development of androids with the investigation of
  human behavior, constitute a new research area fusing           specialized brain centers to interpret them, including
  engineering and science.                                        those implicated in identifying faces [Farah et al., 2000],
                                                                  detecting faces [Kanwisher et al., 1997] and hands
                                                                  [Downing et al., 2001], and recognizing emotion.
                     Introduction                                    Honed by evolution and experience, our most highly
Progress is underway to develop humanoid robots                   developed model of a social other is our model of other
that can support rich, multimodal interaction                     people. If we cannot accept humanoid robots as a so-
[Kanda et al., 2004], and we may expect to see ad-                cial presence—even socially “competent” ones—because
equate competencies within the next decade for brief              they do not look human, this is something robotics engi-
exchanges in stereotyped situations. However, these               neers need to know and plan for accordingly. This need
robots will be of substantially less value if because of          has strongly motivated robotics engineers to learn some-
their appearance, ordinary people are unable to accept            thing about us as people and how the human form—and
them as a social presence. Studies of person-to-person            deviations from it—aﬀect our perceptions and reactions.
interaction in psychology and other ﬁelds generally               Simply put, what makes something a social presence? Is
take our human form for granted. This leaves us to                it mainly its behavior, or is there instead some complex
assume that our everyday impressions of sociality are             interplay between appearance and behavior?
a subjective phenomenon arising from our interactions                Running counter to the view that we should build
with other people.                                                robots that look like people—what we call androids—
   However, the importance of a humanlike appearance              is Masahiro Mori’s hunch that our goal should instead
has yet to be discounted, and there are a number of               be stylishly designed robots, because robots that look
reasons why it might be signiﬁcant. We have a range               too human might be disturbing [Mori, 1970]. Mori pro-
of biomechanical structures that have evolved or been             posed that our sense of familiarity increases as robots
adapted to express volition, intention, and emotion:              appear more human until an uncanny valley is reached
Our eyes indicate the direction of gaze, which supports           at which subtle defects in human likeness appear repul-
joint attention and other interactive responses; our faces        sive (Fig. 1). The impression would not be unlike that
and vocal tract are populated by scores of muscles in-            of a moving corpse.
volved in controlling facial expressions and the voice;              Only recently is Mori’s hunch materializing into a re-
and our bodies are animated by gestures and other                 search program for understanding the uncanny valley
meaningful acts. In addition, we are highly sensitized            [Minato et al., 2004]. The eﬀect of similarity can be
to these biomechanical structures and have developed              separated into the eﬀects of appearance and behavior,
                                                               1373

since both interdependently inﬂuence human-robot in-                                                                      Investigation of the
                                                                 Design of methods to                                 appearance-behavior problem
teraction. Goetz et al. [Goetz et al., 2003] observed a                                           synergy ridge
                                                                 make natural motion
synergistic eﬀect in our evaluation of an interaction when                                                                   uncanny valley
                                                                                             Overall evaluation
appearance and behavior are well-matched. Figure 2 av-
erages graphs derived from Mori’s uncanny valley hy-
                                                                             human
                                                                           Sim
                                                                              ila
                                                                                                                  ?
                                                                                             of the interaction
pothesis [Mori, 1970] and the hypothesis that appear-                            rity
                                                                                    of
ance and behavior should be well-matched.                                              be                                      ance human
                                                                                         ha
                                                                                           vio                           appear
   While one may argue that a robot’s degree of human                                                            rity of
                                                                 Design of methods to         r            Simila                Development of
likeness should be adjusted to ensure that people nei-           evaluate interactions                                         human-looking robots
ther place too few expectations on it (perhaps treating                                     Synthesized from
it like a piece of furniture) nor too many, it is unlikely
that either appearance or behavior can be reduced to a
single dimension. The temporal dimension is also miss-
ing from the ﬁgure. People tend to habituate to even an          Evaluation in terms                                       Evaluation in terms
uncanny appearance, and behavior results in the devel-           of behavior                                               of appearance
opment of relationships over time. In addition, a person
in a spacesuit may not look so diﬀerent from the sort of      Figure 2: The extended uncanny valley and a map for
humanoid robots that we might expect to lie near the          investigating it.
ﬁrst peak (e.g., Honda’s Asimo or Sony’s Qrio); how-
ever, we would expect people to evaluate the movement
of the astronaut more positively. Nevertheless, Minato
et al. [Minato et al., 2004] may be right to hypothesize
that a robot’s uncanniness can be mitigated by its be-
havior, if the behavior closely resembles that of a person.
   However, the uncanny valley can also be seen in a posi-
tive light. It indicates we are unconsciously applying our
model of other human beings to the android—a model
more demanding than the one we apply to mechanical-
looking humanoid robots. It is an artifact of a mismatch
between the more stringent demands of the human model
that has been elicited and, in our progress toward human
likeness, some vestigial sensory or sensorimotor data that
does not match it.
   Mori gave the example of shaking a prosthetic hand
                                                                            Figure 3: The android Repliee Q1.
on a dark night [Mori, 1970]: We may feel uneasy if, af-
ter seeing it, we expect a human hand but then discover
from its movement, feel, and temperature that it is in-
stead a mechanical prosthesis. In this example, there is      line,” increasing our sense of familiarity, while fewer of
a mismatch both in terms of time and modality: The            them would be violated. Thus, we may posit at least two
largely nonconscious expectations that at ﬁrst ﬁt the vi-     diﬀerent models: one that rewards anthropomorphism in
sual data cannot be reconciled with the tactile data. If,     general with feelings of familiarity, and a second model
owing to the humanlike appearance of an android, hu-          that punishes deviations from human norms in ﬁgures
man subjects are applying their model of other people, it     that seem very human.
becomes easier in an experimental setting to determine
when the robot’s behavior conforms to or deviates from
the norms that people apply to each other.                                     Android Research Map
   This kind of knowledge is clearly of value to robot en-    It may seem the ﬁnal goal of android development should
gineers in generating more natural movements. But it          be to realize a device whose appearance and behavior
is also relevant to researchers in the cognitive and social   cannot be distinguished from those of a human being
sciences because it concerns human behavior. The impli-       (in other words, a device that could pass the Total Tur-
cation is that an android may be able to go beyond the        ing Test at T3 [Harnad, 1989]). However, since there
limits of mechanical-looking robots to serve as a testbed     will always be subcognitive tests that could be used to
for theories about human behavior and for understand-         detect subtle diﬀerences between the internal architec-
ing the relationship between control mechanisms and so-       ture of a human being and an android [French, 1990]
cial interaction.                                             [French, 2000], an alternative goal would be to realize a
   However, the shape of the uncanny valley cannot be         device that is nearly indistinguishable from human be-
explained merely in terms of the elicitation of expec-        ings in everyday situations. In the process of pursu-
tations about other people and the violation of those         ing this goal, our research aims to investigate principles
expectations because, as we near 100% human like-             underlying interpersonal cognition and communication.
ness, more human-directed expectations would come “on         Three main research issues deﬁne the axes of Fig. 2.
                                                          1374

A method to evaluate human-robot interaction.                                                     Subject
Human-robot interaction can be evaluated by its hu-
man likeness. Therefore, it is necessary to compare
human-human and human-robot interactions. Quali-
tative measures include the semantic diﬀerential (SD)
method. Quantitative measures include statistical de-
scriptions of a person’s largely nonconscious behavior in-
cluding gaze behavior, interpersonal distance, and vocal                      Questioner
pitch. These observable responses reﬂect cognitive pro-                   (Human or android)
cesses we might not be able to infer from answers to a
questionnaire. We are studying how a human subject’s
responses reﬂect the humanlike quality of an interaction
and how they relate to the subject’s mental state.
Implementing natural motion in androids. To                                        (a) The experimental setup
understand the kinds of motion that give a natural im-
pression, the android precisely mimics a person’s move-
ment. We then monitor how a human subject’s inter-                                          Up
action with the android degrades as we remove some
aspect of the android’s motion. A straightforward way                                              Up and left
                                                                           Up and right
to animate the android is to design a sequence of con-
trol commands. However, this is diﬃcult because the                                                     Left
                                                                               Right
android has many degrees of freedom. Another method
is to copy the motion of a human model as measured by                      Down and right           Down and left
a motion capture system. Most methods that use a mo-
tion capture system assume a human body has the same                                         Down
kinematics as a robot in calculating the robot’s joint                        (b) The eight eye directions as coded
angles [Nakaoka et al., 2003]. However, because human
and robot kinematics diﬀer, there is no guarantee the
                                                               Figure 4: In the experimental setup, a human or android
robot’s motion as generated from the angles will resem-
ble human motion. Therefore, we need a method to en-           questioner interrogated Japanese college-aged students
sure that the motions we see at the surface of the robot       (a). Eight averted gaze directions were coded as shown
resemble those of a human being.                               in (b) as was eye contact.
   In particular, a human motion may be decomposed
into dominant motions and ﬁne motions that are contin-             A study of appearance and behavior
gent on the dominant motions. While a dominant mo-
tion may often be consciously initiated, it will result in     Breaking eye contact during thinking
ﬁne motions that are largely nonconscious. For example,        In the evaluation of a human-robot interaction, methods
when raising a hand, a person’s shoulder and waist may         of evaluating a human subject’s (largely nonconscious)
also move to keep balance. Breathing may become more           responses provide a complementary source of informa-
rapid during physical exertion. These motions are con-         tion to insights gleaned from a questionnaire or focus
sidered important if an android is to closely resemble a       group. This paper examines the subjects’ gaze behav-
person. We are studying methods to decompose human             ior. Gaze behavior in human-robot interaction can be
motion into dominant, contingent, and autonomic mo-            compared to the gaze behavior in human-human interac-
tions in addition to methods to map human motions to           tion, which has been studied in psychology and cognitive
the android by means of an appropriate decomposition.          science.
                                                                  In terms of gaze behavior, people generally make eye
The development of humanlike robots. We have                   contact by looking with their right eye at the interlocu-
developed several androids we are currently using for ex-      tor’s right eye. While thinking, people often break eye
perimentation. The android used in the experiments de-         contact (avert their eyes from the interlocutor.) Three
scribed in this paper is Repliee Q1, shown in Fig. 3, which    main theories explain this behavior:
was developed to realize humanlike motion. Repliee Q1
has 31 degrees of freedom in the upper body. The an-           • Arousal reduction theory
droid can generate various kinds of micromotions such             This theory claims that people break eye contact while
as the shoulder movements typically caused by human               thinking to reduce arousal and to focus on the problem
breathing. Silicone skin covers the head, neck, hands,            [Gale et al., 1978] by eliminating distractions.
and forearms. The compliance of the air actuators makes
for a safer interaction. Highly sensitive tactile sensors      • The diﬀerential cortical activation hypothesis
mounted just under the android’s skin enable contact              This hypothesis states that brain activation in-
interaction.                                                      duced by thinking tasks leads individuals to shift
                                                           1375

   their gaze away from the central visual ﬁeld                       Results. As in the Canadian study, the Japanese subjects
   [Previc and Murphy, 1997].                                      tended to make less eye contact for think questions (27% of
                                                                   the time on average, SD=19%) than know questions (40%,
• Social signal theory                                             SD=14%). Student’s t-Test (two tails, two-sample unequal
   This theory claims that people break eye contact to             variance) is 0.1354. However, in contrast to the Canadian
   inform others that they are thinking.                           study, Japanese tended to avert their eyes downward for
                                                                   both know and think questions. Table 1 lists the duration
   If breaking eye contact were a social signal, we would          of gaze in the eight directions shown in Fig. 4(b) (also see
expect it to be inﬂuenced by the interlocutor. Psycholog-          Figure 5(a)). From the ﬁgure, the duration of averting eyes
ical researchers have reported experimental evidence to            is longer for think questions; however, there is almost no di-
support the social signal theory [McCarthy et al., 2001,           rectional bias. Therefore, unless the signal is not present in
McCarthy and Muir, 2003]. We report an experiment                  Japanese culture, the social signal theory is not supported by
that compares subjects’ breaking of eye contact with a             the comparison between the know and think questions.
human versus android interlocutor.                                 Human-android conversation We hypothesized
Experiments                                                        that if the way in which eye contact is broken while
                                                                   thinking acts as a social signal, subjects will produce dif-
Human-human conversation It has been reported                      ferent eye movements if the interlocutor is not humanlike
that Canadian subjects break eye contact longer for                or if the subjects do not consider the interlocutor to be a
questions that require thinking with a preference for              responsive agent. Conversely, if eye movement does not
the upper-right direction; however, there was no di-               change, this supports the contention that subjects are
rectional bias for questions that do not require think-            treating the android as if it were a person, or at least a
ing [McCarthy et al., 2001, McCarthy and Muir, 2003].              social agent.
The preference for the upper-right direction is considered            Procedure. We then conducted an experiment with eight
to be the eﬀect of a social signal. Although diﬀerential           subjects that was almost identical to the one described in
cortical activation is considered to cause a downward-             the previous section except we substituted Repliee Q1 for the
                                                                   human questioner and told subjects the android was control-
averting gaze, people look up and to the right during in-          ling its own behavior. Repliee Q1 resembles a young woman
teraction with others to avoid looking downward, which             (Fig. 3). A speaker embedded in the android’s chest produced
is considered to be negative behavior in Canada.                   a prerecorded voice. Micromotions such as eye and shoulder
   Subjects. The subjects in all experiments were Japanese         movements were implemented in the android to make it seem
college students within the 18–25 age range.                       more humanlike.
   Procedure. Subjects sit opposite a human questioner                At ﬁrst the experimenter sitting beside the android ex-
(Fig. 4(a)). The questioner was a female Japanese college          plained the experiment to the subject to habituate the sub-
student. The subjects’ eye movements are measured while            ject to the android. The android behaved as an autonomous
they are considering the answers to questions posed by the         agent during the explanation (e.g., it continuously made
questioner. There are two types of questions: know questions       slight movements of the eyes, head, and shoulders while oc-
and think questions. Subjects already know the answer to           casionally yawning). It seemed the subject believed the an-
know questions (e.g., “How old are you?”) but not to think         droid to be asking questions autonomously, although ques-
questions as these questions force the subject to derive the       tions were manually triggered by an experimenter seated be-
answer (e.g., “Please tell me a word that consists of eight        hind a partition.
letters.”). The subjects were asked 10 know questions and             Results. The subjects tended to make much less eye con-
10 think questions in random order. Their faces were video-        tact for think questions (25%, SD=21%) than know questions
taped and the gaze direction was coded beginning from the          (57%, SD=28%). Student’s t-Test is 0.02326, which is very
end of the question to the beginning of the answer. Figure         signiﬁcant. Table 2 and Fig. 5(b) show the results.
4(b) shows the coding scheme for the eight averted directions,        If we assume the downward directional preference in
the ninth direction being eye contact.                             human-human interaction is a social signal, the weaker
               Table 1: Human Questioner                                Table 2: Android: “Autonomous” or “Operated”
              Gaze direction     think know                             Gaze direction       think know think know
              Eye Contact         27%       40%                         Eye Contact           25%      57%      16%      54%
              Up                    3%       3%                         Up                     4%       2%        4%      0%
              Up and left           5%       6%                         Up and left            3%       2%        5%      3%
              Left                16%       13%                         Left                  16%       7%      10%       7%
              Down and left         9%       2%                         Down and left          7%       8%      18%       7%
              Down                20%       20%                         Down                  14%       8%      27%      15%
              Down and right        5%       5%                         Down and right        14%       7%      10%       5%
              Right               11%        9%                         Right                  7%       5%        5%      5%
              Up and right          3%       2%                         Up and right           9%       4%        4%      3%
                                                               1376

                        Human Questioner                               “Autonomous” Android Questioner                 “Operated” Android Questioner
   think: 17 subjects                                                   think: 8 subjects                              think: 7 subjects
   know: 12 subjects     Up                                             know: 8 subjects                               know: 7 subjects
                         20%                                                    20%                                            20%
   Up and right                      Up and left
                         15%                                                    15%                                            15%
                         10%                                                    10%                     57%                    10%                     54%
                          5%                               40%                   5%                                            5%
    Right                                 Left       27%                                          25%
                                                                                                                                                 16%
Down and right                       Down and left      think   know                                think   know                                   think   know
                        Down                                                                                              27%
                  No eye contact                     Eye contact          No eye contact          Eye contact            No eye contact          Eye contact
                               (a)                                                          (b)                                            (c)
Figure 5: (a) For the 17 subjects in the “think” question experiment with the human interlocutor, the average amount
of time spent making eye contact was 27%, and the average amount of time spent averting the eyes downward was
20%. For the 12 subjects in the “know” question experiment, the average amount of time spent making eye contact
was 40% and the average amount of time averting the eyes downward was 20%. (b) The think question and know
question experiments were repeated with an android with the subjects being told the android was “autonomous”
and (c) with the subjects being shown how the android was operated by an experimenter.
preference in human-android interactions may suggest                                                               Discussion
the subjects were not treating the android as an inter-
active agent. To check this reasoning, we conducted an-                          Gaze may have a function not unlike how Cowley de-
other experiment with seven subjects in which the sub-                           scribes the interpersonal role of prosody in conversations
jects were told that the android is not autonomous and                           [Cowley, 1994]. In other words, it may operate as a (pre-
that an experimenter triggers the android to ask ques-                           dominantly subconscious) social response resulting from
tions. We predicted the downward directional preference                          the experience of living in a culture. On this view, gaze
would decrease because the subject no longer considers                           is constrained not only neurally and socially but is it-
the android to be a social agent.                                                self primitive behavior that falls under the dual control
                                                                                 of two brains. As a speaker acts to change her cogni-
   Results. The subjects tended to make much less eye con-                       tive state, the interlocutor’s gaze automatically serves
tact for think questions (16%, SD=15%) than know ques-                           as a cognitive resource. In this sense, gaze is intrinsic
tions (54%, SD=21%). Student’s t-Test is 0.002406, which is                      to epistemic action [Kirsh and Maglio, 1994]. When we
highly signiﬁcant. Table 2 and Figure 5(c) shows the results.                    talk, we aﬀect each other’s gaze just as we aﬀect real-
   Contrary to our expectation, the downward preference                          time patterns in each other’s speech. Thus, gaze is not
increased. This may be because the subjects were send-                           so much a “signal” or outer reaction to an environmental
ing a social signal to the experimenter. However the                             stimulus (e.g., a think question) as a way of contextual-
downward preference is much less pronounced for the                              izing by drawing on experience in ways that are likely to
android believed to be autonomous. The diﬀerence in                              be beneﬁcial to the gazer.
the gaze bias with respect to the diﬀerent questioners                              On this view, Canadians and Japanese behave dif-
suggests that breaking eye contact depends on the in-                            ferently1 because they have come to orient to diﬀerent
terlocutor. It also suggests that the sociality of the au-                       norms or, in population terms, have adopted diﬀerent
tonomous android is lower than the human questioner                              gaze practices. This joint activity is not standardized
for the subjects. Conversely, breaking eye contact can                           to anything like the extent that would be needed for it
be an evaluation of the android’s appearance and be-                             to be meaningfully described by a grammar. Except in
havior. We must, therefore, investigate which aspects of                         such extreme cases as staring, gaze is not normative in
appearance and behavior inﬂuence human gaze behavior.                            the sense that we can formalize its function, say, in terms
   Under the condition that the subject believes the an-                         of social codes. Gaze is, however, norm-based. This is
droid to be human-operated, we consider the subjects                             because deviations from common practice will take on
interacted with the experimenter through the android                             meaning in relation to both circumstances and an indi-
and the relation between the experimenter and subject                            vidual’s current perspective. Thus, any social group will
is diﬀerent from that between the human questioner and                           be sensitive to distinctions between marked (preferred)
subject. The diﬀerence may indicate that breaking eye                            and unmarked (disfavored) gaze responses.
contact has meaning as a social signal. However, the
sample size is too small and the variance in response too                           1
                                                                                      To put it more precisely, their behavior may be charac-
great to make a detailed interpretation.                                         terized by diﬀerent probability distributions.
                                                                           1377

   To test the merit of this line of speculation, it is nec-    [French, 2000] French, R. (2000). The Turing Test: The
essary to consider not only the focus of gazes but also            ﬁrst ﬁfty years. Trends in Cognitive Sciences, 4:115–
their duration and time sequence: The main question is             121.
whether eye movements function as signals that provide
information about whether the subject is, for example,          [Gale et al., 1978] Gale, A., Kingsley, E., Brookes, S.,
thinking or whether they function as prompts, probes,              and Smith, D. (1978). Cortical arousal and social in-
and teasers whose timing and other qualities are them-             timacy in the human female under diﬀerent conditions
selves the information shared among parties in closely-            of eye contact. Behavioral Processes, 3:271–275.
coordinated interaction. They may in fact function as           [Goetz et al., 2003] Goetz, J., Kiesler, S., and Powers,
both at once.                                                      A. (2003). Matching robot appearance and behavior
   If gaze functions epistemically, a person (or android)          to tasks to improve human-robot cooperation. In The
can use invariants that develop over a life history to             Twelveth IEEE International Workshop on Robot and
model what action aﬀords. If Canadian the person knows             Human Interactive Communication, Lisbon, Portugal.
(or acts as if she knows) that looking often (but not
continuously) at the right eye is likely to give a sense        [Harnad, 1989] Harnad, S. (1989). Minds, machines and
of whether the interaction is proceeding normally and              Searle. Journal of Experimental and Theoretical Arti-
that looking up and to the right will not invite social            ﬁcial Intelligence, 1:5–25.
sanction. In enacting this behavior, one person can
use another as a cognitive resource that emits hetero-          [Kanda et al., 2004] Kanda, T., Hirano, T., Eaton, D.,
geneous bundles of cues (e.g., as exhibited by the tim-            and Ishiguro, H. (2004). Interactive robots as social
ing of mutual gaze). These cues prompt real-time ad-               partners and peer tutors for children: A ﬁeld trial.
justments as both individuals engage each other inter-             Human-Computer Interaction, 19(1-2):61–84.
personally while orienting what they do around norm-            [Kanwisher et al., 1997] Kanwisher, N., McDermott, J.,
based behavior that has stabilized for some time period            and Chun, M. (1997). The fusiform face area: A mod-
(but will typically disappear). Some of these will be              ule in human extrastriate cortex specialized for face
pragmatic actions; others will be future epistemic ac-             perception. Journal of Neuroscience, 17:4302–4311.
tions [Kirsh and Maglio, 1994]. This can lead, among
other things, to the development of largely nonconscious        [Kirsh and Maglio, 1994] Kirsh, D. and Maglio, P.
forms of activity that are likely to achieve aﬀective re-          (1994). On distinguish epistemic from pragmatic ac-
ward. What may be crucial though is that epistemic ac-             tion. Cognitive Science, 18:513–549.
tion can use variable bundles of external features whose
value depends on culturally-stabilized patterns.                [McCarthy et al., 2001] McCarthy, A., Lee, K., and
                                                                   Muir, D. (2001). Eye gaze displays that index know-
                      Conclusion                                   ing, thinking and guessing (poster). In The Annual
This paper proposed a hypothesis on how appearance                 Conference of the American Psychological Society.
and behavior are related and mapped out a plan for an-          [McCarthy and Muir, 2003] McCarthy, A. and Muir, D.
droid research to investigate it. The study on break-              (2003). Eye movements as social signals during think-
ing eye contact during thinking was considered from the            ing: Age diﬀerences. In Biennial Meeting of the Soci-
standpoint of the appearance-behavior problem. In the              ety for Research in Child Development.
study, we used the android to investigate the social sig-
nal theory and obtained evidence diﬀering from previous         [Minato et al., 2004] Minato, T., Shimada, M., Ishiguro,
psychological experiments in human studies. Further-               H., and Itakura, S. (2004). Development of an an-
more, it was found that the breaking of eye contact can            droid robot for studying human-robot interaction. In
be an evaluation of an android’s human likeness.                   Orchard, R., Yang, C., and Ali, M., editors, Innova-
                                                                   tions in Applied Artiﬁcial Intelligence, pages 424–434,
                       References                                  Berlin.
[Cowley, 1994] Cowley, S. (1994). The role of rhythm in
                                                                [Mori, 1970] Mori, M. (1970). Bukimi no tani [the un-
   conversations: A behavioural perspective. Language
                                                                   canny valley]. Energy, 7:33–35.
   & Communication, 14:353–376.
[Downing et al., 2001] Downing, P., Jiang, Y., Shuman,          [Nakaoka et al., 2003] Nakaoka, S., Nakazawa, A.,
   M., and Kanwisher, N. (2001). A cortical area selec-            Yokoi, K., Hirukawa, H., and Ikeuchi, K. (2003). Gen-
   tive for visual processing of the human body. Science,          erating whole body motions for a biped humanoid
   293:2470–2473.                                                  robot from captured human dances. In Proceedings of
                                                                   the IEEE International Conference on Robotics and
[Farah et al., 2000] Farah, M., Rabinowitz, C., Quinn,             Automation, volume 3, pages 3905–3910.
   G., and Liu, G. (2000). Early commitment of neural
   substrates for face recognition. Cognitive Neuropsy-         [Previc and Murphy, 1997] Previc, F. H. and Murphy,
   chology, 17:117–123.                                            S. J. (1997). Vertical eye movements during mental
                                                                   tasks: A reexamination and hypothesis. Perceptual
[French, 1990] French, R. (1990). Subcognition and the             and Motor Skills, 84(3):835–847.
   limits of the Turing Test. Mind, 99:53–65.
                                                            1378

