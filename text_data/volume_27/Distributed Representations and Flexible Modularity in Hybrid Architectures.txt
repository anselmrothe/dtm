UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Distributed Representations and "Flexible" Modularity in Hybrid Architectures
Permalink
https://escholarship.org/uc/item/74v050n5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Calvi, Gianguglielmo
Pezzulo, Giovanni
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

    Distributed Representations and “Flexible” Modularity in Hybrid Architectures
     Giovanni Pezzulo (giovanni.pezzulo@istc.cnr.it), Gianguglielmo Calvi (gianguglielmo.calvi@noze.it)
                    Istituto di Scienze e Tecnologie della Cognizione - CNR, via S. Martino della Battaglia, 44
                                                           00185 Roma, Italy
                             Abstract                                respect to this objective, there are two strategies: the first
                                                                     one is well represented by some of the most known
   Here we discuss the role of modules and representations into      cognitive architectures, ACT-R (Anderson et al., 1998) and
   cognitive architectures by comparing the “unified” approach       SOAR (Rosenbloom et al., 1992), implementing the
   of SOAR and ACT-R with the “decentralized” one of the
                                                                     “Unified Theory of Cognition” where a small set of
   Society of Mind. We introduce AKIRA, an open-source
   hybrid architecture and show how to exploit its features,
                                                                     mechanisms (e.g. production rules) are exploited as the
   namely distributed representations and parallel, concurrent       substrate of all the cognitive functionalities.
   processing for agent based cognitive modeling.                        The second possible strategy is more liberal: the
                                                                     architecture only provides a functional, high level
   Keywords: hybrid architectures; distributed representations.      “blueprint” of the relations and interdependencies of its
                                                                     parts; each one can be developed independently, providing
                          Introduction                               that it matches the architectural constraints, and can exploit
Cognitive architectures are claimed to be central for                different, specialized mechanisms instead of a single,
cognitive science: Newell (1990) introduces the “Unified”            general-purpose one. However, there exist some underlying
approach to cognition, that consists in integrating many             principles (e.g. concurrence between the components) that
cognitive capabilities instead of building models of limited         are shared by all the processes and are supposed to
aspects of cognition; in a similar way, Sloman (1999) argues         constraint all high-level cognition. This approach is
for the opportunity of designing systems at the architectural        exemplified by the Society of Mind model, where a number
level instead of assembling single, specialized components.          of narrow-minded, specialized agents interact and compete
The most notable examples are the generic, unified                   into the same environment. Cooperation and coordination
architectures SOAR (Rosenbloom et al., 1992) and ACT-R               are an emergent property of the system: each agent learns
(Anderson et al., 1998); some other ones, such as the                how to exploit other’s capabilities and activity for its
DUAL/AMBR (Kokinov, 1994) and Copycat (Hofstadter et                 purposes. The challenge is thus having many processes and
al., 1994) models of analogy, do not address the generality          functions working together without having a common
of the cognitive processes, but try to capture the general           ontology or a single computational mechanism.
underlying principles of high-level cognition.
   In the following Sections we discuss the role of modules                                Modularization
and representations in cognitive architectures. We introduce          The second kind of architecture is more flexible even in
the architectural scheme of the Society of Mind (Minsky,              terms of modules and hierarchies. Fodor (1981) asserts the
1986), that exploits “vertical” modules and distributed               relevance of modules into cognitive architectures; both
representations, showing how it realizes dynamic, context             contents and processes in a module are “opaque” to the
dependent computation, and why it is relevant for cognitive           other components. Each module influences the others only
modeling. We also introduce AKIRA, an hybrid architecture             through its output (e.g. for an hypothetical “vision module”,
mixing up Multi-Agent and Pandemonium (Jackson, 1987)                 it could be a symbolic representation): it is impossible to
features; agents (called Daemons) are managed by a server             interact with the “private” processes of each module.
process (called Pandemonium). Differently from standard                  Sometimes (e.g. in ACT-R) modules also introduce a
Multi-Agent architectures, Daemons are related to a central           “serial bottleneck” into the processing: while many
resource, the Energy Pool, and spread activation via an               operations can be performed in parallel into a module, a
Energetic Network. These structures afford connectionist              single process is selected to be active for each moment. This
dynamics at the agent level; they permit to realize parallel,         introduces another rigidity element and makes it even more
dynamic and emergent computation by distributing the                  crucial the choice of which modules to implement and
operations between many simple, interacting processes,                which is the format of the representations.
giving high versatility to modularization. Moreover,                     Of course, given the complexity of a cognitive system, a
representations can be distributed among many partially               certain amount of modularization is mandatory; however,
active and partially available units.                                 how to modularize is a complex design choice that strongly
                                                                      influences the kind of capabilities that can be obtained (for a
        Designing at the Architectural Level                          review of modularization in AI systems see Bryson, 2004).
Sloman (1999) furnishes strong arguments for thinking and             Fodor argues in favor of “horizontal modularity”, i.e.
designing models at the architecture level, rather than               implementing as modules the main cognitive processes such
building single, independent cognitive functionalities. With          as perception, attention and memory. In this spirit, some
                                                                      architectures such as ACT-R exploit impenetrable
                                                                 1738

perceptual-motor and memory modules. While inside each             information in the environment (such as “Daemon x is
module there can be interaction and competition between            active now”). The same information can be of course
the representations and the operations, there is less              interpreted in different ways by different Daemons.
possibility for interactions between modules. Blendings,              There is another aspect of “modulating the modules”:
multi-modal interactions and other contextual and                  having processes interfering with the computational
interference effects between modules are of course possible,       resources of other modules, e.g. assigning them more or less
but only at a coarse-grained time rate and only exploiting a       priority, activation or communication bandwidth. This
certain format of the representations (for example, symbolic       allows developers to control the computational dynamics at
input and output). Moreover, each module has its private           the low level: e.g. representing alarms (Sloman, 1999) as
memory space and its computational resources; the                 urgent danger signals that stop all the computation; or the
processes in the different modules are independent and no         attention focus (see Baars, 1988). Resource management is
module assumes as contextual parameters the current               strongly related to another kind of modularity exploitable by
activity of the other ones. It remains an open issue if this      cognitive architectures: modularity by time sharing: the
modularization results to be too rigid: in fact, it could be      same resources are available to different processes, that can
claimed that in a cognitive architecture each process should      exploit them with different timings. For example, two
have place thanks to, and in the context of, each other, at       concurrent modules can exploit information encoded in the
least to a certain extent.                                        same cortical area (there is evidence in neurobiological
   On the contrary, more flexible and distributed cognitive       literature, see Bryson, 2004). The representations have thus
architectures can take advantage of modulating the modules,       different semantics in different times and contexts,
i.e. having modules interfering with the content and the          depending from the function that exploits them: even if the
processing of other ones. This feature can be exploited e.g.      representation is the same, it means and is used for different
for meta-reasoning, where some processes are supposed to          things. This has a more important consequence from the
have (at least a certain) access to the content and the           design point of view: some processes are mutually
processes of other modules. It can be also considered a           exclusive, because they exploit the same representation
general architectural principle; Cassimatis (2002) argues         space; this is in contrast with the general assumption that all
that to an extent impossible to modular systems, inference        the modules should be always active. Instead of being
schemes must share progress, exploit unforeseen                   interpreted only as a limitation to expressive power, this
opportunities, interrupt each other without hazard and be         feature should be exploited for cognitive modeling. For
responsive to world knowledge.                                    example, SOAR and ACT-R have introduced problem
   Knowledge in a module can be also used as the context of       spaces: each function can access only a part of the resources
another one in order e.g. to reduce the problem or search         and representations of the system. Problem spaces actually
space. In other cases a module or process has knowledge           serve as “framing” of situations in order to capture its
that is useful for another one; for example, in order to trace    context and to reduce computational load. Minsky (in
an object moving behind an obstacle, the attentional module       preparation) argues that special agents called selectors are
should exploit knowledge produced by an hypothetical              responsible for activating (only) a set of resources in
“ingenuous physics simulation” process.                           response to a given context; this is even the ultimate role of
   One of the central requirements for adding versatility to      emotions. Task specific agents (i.e. “vertical modules” in
the modules is synchronizing some of their representation         Fodor terms) can thus be recruited and made available to
(share progress); in a sense it means having a “deictic”          different extents in a context dependent way.
representation of the context. This can be done by using              Last, the most crippling limitation of rigid (and
shared variables, but this strongly constrains the content of     horizontal) modular systems is that it is often necessary to
all the modules, since a common ontology is needed; or by         explicitly pre-plan all their interactions and behaviors, thus
using an external element as a medium. A major claim of           it is difficult to design them. On the contrary, it is becoming
distributed cognition (Clark, 1997) is that the environment       popular (e.g. in behavior-based robotics, Brooks, 1991;
itself is such a medium: instead of using internal                Maes, 1990) to run a number of semi-independent,
representations the processes can attune themselves to the        concurrent behavioral components and let them dynamically
environment, using it as an external memory.                      interact without a fixed control cycle or a central interpreter:
   A similar method is exploited by the Pandemonium, that         a central theme of the Society of Mind model.
can have a “common memory and work space” (e.g. a                     It remains to be explored how much the modules have to
Blackboard): when they perform their operations (e.g.             be “flexible” and “penetrable” by other process; total
matching a pattern), the Daemons notify to the Blackboard         penetrability is the opposite of the concept of module, but
(by “shrieking”) that they are active. This notification can      here we have individuated a number of reasons for
be accessed by other Daemons that can synchronize their           designing some interactions (e.g. influencing the priority of
representations (e.g. be aware that such a pattern is matched     their processes, letting them compete for resources, or
in the context). The Daemons have neither to share a              synchronizing some inner states). Here we introduce a
common ontology, nor exchange explicit messages or share          different approach to modularization that is well suited for
variables, but only learn to be sensible to the same              this kind of fine-grained interactions.
                                                              1739

             The Society of Mind (SOM)                                  There is not a single, general purpose method for
                                                                    resolving problems, but on the contrary many inferences
The SOM is composed of many agencies that contain many
                                                                    and problem solving systems (e.g. the differences engine)
processes called agents. Agencies are different from Fodor-
                                                                    that interoperate and to a certain extent “emerge” as the
like modules: first of all, they are specialized processes for
                                                                    pattern of response of the whole SOM to a situation. The
specific tasks (e.g. to build a bridge, to sum up, etc.) rather
                                                                    SOM activity is thus dynamic, emergent, adaptive and
than large cognitive capabilities such as perception and
                                                                    highly context dependent. This versatility depends mainly
reasoning. This is a different way of segmenting the
                                                                    from the fact that knowledge is distributed and, depending
cognitive functionalities: in Fodor terms they are “vertical”
                                                                    from the context (e.g. the active K-lines), only a part of it is
rather than “horizontal” modules. Moreover, they couple
                                                                    available in a given moment. This is intended to address the
perceptual and motor elements; they are more flexible,
                                                                    frame problem: how to consider only salient information.
tightly interconnected and less impenetrable; they do not
communicate via an explicit inter-lingua (such as the
“mentalese”), they do not share a common ontology: on the                  Distributed, Emerging Representations
contrary, many of their interactions are simple activation           Perhaps the first problem to address in the tentative of
exchange, or they can synchronize their representations by           building a cognitive architecture is about the representations
observing and reacting to the same event. They thus                  it exploits. The first and more traditional kind of
massively exploit implicit communication (Castelfranchi,             representations, the symbolic ones, have been criticized in
2004), an important feature even in Pandemonium (Jackson,            the recent years for many reasons: the most crucial and
1987). Another crucial point in the SOM is that the                  basic problem is their “groundedness” (e.g. Chalmers,
organization and the control management is fully                     1992). Here we address only a limited point of the
distributed: there is no central interpreter, and arbitrations       discussion, i.e. the fact that they are rigid and often they are
within the same agency and between agencies are resolved             pre-fixed by the developer: they are empty labels and not
on-line. Agents and agencies compete for activation, exploit         active symbols in the sense of Hofstadter et al. (1994).
the activity of each other for their own purposes (e.g. the             Distributed, emergent representations are implemented
agency going home exploits the activity of sleep for                 and exploited in different ways in many kinds of models.
defeating go running), without centralized decision systems.         The connectionist, PDP approach (Rumelhart, 1986)
   In the SOM agents and agencies embed perceptual and               replaces symbolic and discrete representations with patterns
motor processes but no memory, that is instead represented           of fully distributed representations, e.g. embedded in neural
by specialized agents called K-lines: they are neural-like,          networks. Connectionist networks embody knowledge
distributed structures, that involve many links between              structures organized around prototype-style representations,
agents representing parts and patterns of experienced               i.e. multidimensional semantic space dotted with attractors
situations. Remembering is thus rebuilding what was active:         (Churchland, 1989). In a similar way, Hofstadter claims that
K-lines are (partially or totally) reactivated when a new           active      symbols      only     emerge      from    distributed
situation is encountered that resembles an old one; they in         representations; even if he proposes more coarse-grained
turn reactivate al the related agents by spreading activation       representations, the points is that a token only assumes a
through the links. Minsky (in preparation) extends the              semantic where interacting in a network of related ones.
concepts of K-lines: they not only activate other “memory           Another interesting possibility in a similar direction is the
management” agents, but become “selector” of whichever              model of Gärdenfors (2000) that bridges the symbolic and
kind of resource (or agency), including patterns of                 subsymbolic levels by a middle-level, geometric
emotional states. K-lines provide a good substrate for many         representation that treats concepts as vectors in a n-
dynamics of context-sensitive cognitive phenomena such as           dimensional (features) space. Another family of models
graded or partial recollection, blendings and analogy.              (including LISA: Hummel, 1996) exploits timing of
   There are many more agent kinds in SOM, (e.g. nomes              activation of distributed patterns for dynamic binding of
and nemes), and they are mainly organized through frames            representations: elements oscillating in synchrony are bound
and frame systems (a versatile formalism). Much of the              together and form more complex representations.
SOM structure is compositional and hierarchical: there exist            As Chalmers (1992) points out, the advantage of
links and patterns of activations between the agents that           distributed representations is that they are not carried on by
implement in a distributed way a planned activity: for              atomic tokens (that can only be empty, ungrounded labels:
example, the agency for building learns to activate in              this is the criticism to old-fashioned AI), but they have
sequence the agents for picking, releasing and so on.               meaningful structures, distributed e.g. in patterns of
Special emphasis is given to a general learning principle:          activation of a network of tokens. We assume (even if this
adapting and reusing some capabilities for other purposes,          point is controversial) that this property is shared by all the
and organizing knowledge in a way that affords abstractions         previously cited examples, even if they use different levels
and analogy. Minsky (1986) calls it the Papert’s Principle:         of granularity: in all the cases the level of the tokens
some of the most crucial steps in mental growth are based           (syntactic) lies below the level of the representations
not simply on acquiring new skills, but on acquiring new            (semantic). In the symbolic case, syntactic operations over
administrative ways to use what one already knows.                  the tokens are not assumed to have a direct semantic (e.g.
                                                                1740

adding the symbol “A” to the symbol “CAT”), but each               these systems use agents, each having an activation level
operation needs an external semantic interpretation. On the        representing the availability of the (localist) representation
contrary, in the case of distributed representations, their        they carry on. For example, in one of the main applications
structures can be directly manipulated and exploited by            of the architecture DUAL, a model of analogical reasoning
using operations that are directly meaningful; for example         called AMBR (Kokinov, 1997), the granularity of the
by performing arithmetic (the case of neural networks) or          representations is one single object per agent: each agent
geometrical operations (the case of concepts in Gärdenfors,        includes a frame representing e.g. a cup, or a plate.
2000); these operations modify the semantic of the                 Situations are fully distributed representations: e.g. “the cup
representations (activating more a node or a concept means         is on the plate” is represented by a number of (partially)
more relevance; crossing two concepts in a concept space           activated agents having links and exchanging activation;
produces a new concept) and not only their syntactic form.         moreover, the patterns of activation change dynamically
   The central capability provided by distributed                  because of system evolution (e.g. decay) or because of the
representations is that the description of a situation (or an      intervention of new elements or events (e.g. the cup is
object or a problem) emerges from patterns of activity of          broken). By exploiting distributed and dynamic
tokens at a lower level, representing e.g. their parts or          representation AMBR is able to perform analogical
features. Systems exploiting distributed representations can       reasoning in a context dependent way: the result of the
build up their models of the current problem or situation          computation dynamically emerge from the parallel and
instead of receiving as input pre-structured representations.      concurrent activity of many (partially) active agents,
These models are more versatile: the interaction between           carrying on (portions) of semantic information both in their
contingent phenomena and pre-existent knowledge (e.g. in a         symbolic and connectionist parts.
semantic network) leads to the emergence of new                       In a similar way, Copycat performs analogical reasoning
representations in a dynamic and context-sensitive way.            on the basis of a problem space that is not pre-fixed, but
   Here we introduce hybrid architectures, coupling the            changes dynamically during the analogical processing.
expressive power of symbolic modeling with the dynamics            Representation-building and mapping (e.g. of two
of distributed representations.                                    situations) run in parallel and influence each other.
                                                                      In AKIRA we have implemented (Pezzulo, 2005) a
                  Hybrid Architectures                             parallel BDI (Rao et al., 1995) where Goals and Plans are
In hybrid representations both symbolic and connectionist          implemented using Daemons; their usual relations (e.g. a
elements are present; the claim of hybrid cognitive                Plan can satisfy a Goal) are represented by using energetic
modeling is that many interesting cognitive phenomena              links that are the carriers of activation e.g. from Goals to
emerge from the interplay of simple and narrow-minded              Plans. The control cycle is thus parallel and distributed
processing units (in the sense of the SOM). The case of            among the concurrent processes without central interpreters.
representations is similar: a meaningful representation only          All these systems exploit hybrid representations (hybrid
emerges from the activity of tokens that lie at a lower level      agents for AKIRA and DUAL; a semantic network and a
of description. The point is how to couple connectionist           procedural memory for Copycat). Of course, the symbolic
dynamics and emergent representations with symbol/token            part can be set at whichever level of granularity (e.g. at the
manipulating systems.                                              level of objects, or features); normally these representations
   There exist many kinds of hybrid architectures, depending       are referred as “localist” and contrasted to “fully
on which feature is hybridized. For example, ACT-R is              distributed” ones. Their advantages and disadvantages are a
hybrid in the sense that it exploits two kinds of                  matter of discussion; localist ones are usually preferred in
representations, declarative and procedural. Some other            hybrid architectures, because they are more manageable and
architectures (such as CLARION: Sun, 1997) are hybrid in           understandable, apparently without losing expressive power.
the sense of layered: in the bottom layer (more reactive)          In fact, even if all the systems here described could in
connectionist dynamics make available symbolic, localist           principle exploit fully distributed representations (such as
representations in the upper layer (more deliberative).            neural networks), there are many problems with them: for
   AKIRA (as well as DUAL) is hybrid at the micro-level            example, they make it difficult to design at an high level,
(Kokinov, 1997): this means that each agent/daemon is              mainly because is not possible to interpret them (e.g. in
hybrid, carrying on both symbolic content (e.g. in the form        symbolic terms) once they are modified, since the structural
of a frame) and connectionist elements (activation level,          operations they exploit make the resulting structures
energetic links); and the two aspects interact. Some               opaque. The point here is having at least two levels of
connectionist features are used in the symbolic phase: for         description, one for the tokens and one for the
example, activation becomes the priority of the agent, and         representations: thus, representations of situations emerge
the semantic relations between the daemons are reflected by        from patterns of activation over simpler structures (such as
the topology of the links (e.g. an IS-A link spreads energy).      objects and events, the tokens), and the emergence is
   These systems thus exploit distributed representations and      dynamic and context aware. New, more complex
connectionist dynamics; instead of using simple and                representations can thus be formed on-line by the system
meaningless units such as nodes in the neural networks,            either by procedural operations running concurrently and
                                                              1741

modifying the problem space (e.g. the codelets in Copycat),         flexible way. According to SOM, Daemons should be
or by dynamic binding (such as in LISA), or by operations           specialized for simple tasks; complex ones should be
whose availability is directly coupled to the most active           managed by high-level Daemons exploiting the results of
representations (the case of AKIRA and DUAL).                       low-level ones, or by more complex structures (as in the
                                                                    case of the complex “agency for building”) or by the whole
          AKIRA and its Main Components                             Pandemonium. The behavior of the whole system emerges
AKIRA is a C++ platform fully developed in open-source. It          thus from energetic dynamics (the AKIRA Energetic Model)
is not a cognitive architecture, but a framework for building       without centralized control. All the Daemons can participate
cognitive models at different levels of complexity and              (totally or partially) to a given computation, and in principle
integration. AKIRA does not commit to a single model, but           each function, module or activity can influence each other,
many design choices are inspired by the Society of Mind             even without a common language or ontology.
(Minsky, 1986), the Pandemonium (Jackson, 1987), DUAL
(Kokinov, 1994) and Copycat (Hofstadter et al., 1994).
   Here we briefly introduce AKIRA’s components: the
kernel (called Pandemonium); the Agents (called Daemons);
the Blackboard, the pool of resources (Energy Pool). For
full reference, see Pezzulo (2005) or www.akira-project.org.
   The kernel is called Pandemonium; it is the management
structure of a set of Daemons, performing a number of
routine actions such as Blackboard management, garbage
collection, monitoring the system, etc.
   The Daemons are the basic kind of agents in AKIRA.
Each Daemon has a thread of execution; a functional body
where its behavior is specified; and a concurrent access to a
central resource called the Energy Pool, that is the core of
the AKIRA Energetic Model. The Pool is limited and gives                       Figure 1. Daemons as nodes and as agents.
an upper bound to the available resources: differently from
multi-agent systems, the priority of Daemons’ threads are              Thus, AKIRA realizes dynamic computation by exploiting
directly linked to their current energy. This feature (the          distributed representations and processes. This scheme
Energetic Metaphor: Kokinov, 1994) forces the Daemons to            allows developers to design any kind of cognitive
compete: only a limited amount of processes can run, and            architecture, by defining any kind (and degree) of
only a limited amount of representations are available in a         modularization and any granularity of the representations.
given moment, because only some Daemons are active in a                AKIRA does not define any specific agent architecture
certain moment. This models dynamic context-sensitive               but provides a set of prototypes that can be extended for
activation of salient resources, in the spirit of the SOM.          realizing and customizing agents having different design
   Daemons can: tap energy from the Energy Pool; spread             (e.g. reactive, deliberative, layered) and capabilities. The
activation to the other ones via an Energetic Network; form         AKIRA Macro Language provides a rich toolkit of
on-the-fly assemblies (called Coalitions) for resolving             resources, including, BDI (Rao et al., 1995); Behavior
complex tasks; exchange explicit messages via the                   Networks (Maes, 1990); Neural Networks, Fuzzy Logic and
Blackboard; exploit implicit communication, consisting in           Fuzzy Cognitive Maps (Kosko, 1997), etc. Our aim is to
monitoring the activity of another Daemon (“hearing its             allow cognitive modelers to compare different solutions for
shriek”), that is routinely notified to the Blackboard; and         the same problem and to integrate different models. The
execute their symbolic operation, but only if they have             Macro Language permits to abstract from implementation
enough energy (because operations have a cost).                     details, designing at the level of the cognitive functions.
   Fig. 1 provides an intuitive picture of the concurrency
model. The activation of each Daemon is calculated by an                       Conclusions and Current Work
energetic network affording energetic exchanges. Activation         We have discussed the role of distributed representations
becomes priority of the Daemons’ threads, driving their             and “flexible” modules in cognitive architectures. We have
sequences of activation: more active Daemons can act more.          introduced hybrid architectures, where connectionist and
Thus, Daemons are represented both as nodes (circles in the         symbolic elements are merged and influence each other.
grid on the bottom), that exchange activation (via the links),      Hybridization permits to model accessibility and saliency of
and as agents (circles in the cloud on the top). The priority      processes and representations: for example, in AKIRA each
of the agents (their height in the cloud) depends on the           agent has an associated priority depending on its contextual
activation of the correspondent nodes. Daemons also share a        relevance. As in the Global Workspace Theory (Baars,
limited amount of energy (summing up to the Energy Pool).          1998) this “attentional focus” influences not only
   A Daemon can be used for modeling a specific function,          representations but even processes (and possibly modules):
or a module, or embed a piece of semantic information, in a        focused processes communicate more, perform more
                                                               1742

operations and influence more the other ones. The main                Connectionist Paradigms: Closing the Gap, Hillsdale, NJ:
features of AKIRA are inspired by SOM and Pandemonium:                Lawrence Erlbaum
implicit communication, concurrency and cooperation                 Churchland, P. M. The Neurocomputational Perspective.
between the agents (i.e. even without explicit messaging);            Cambridge: MIT/Bradford Books, 1989
hierarchies and coalitions of agents; lack of centralization;       Clark, A. (1997) Being There: putting brain, body, and
the Blackboard as a shared workspace1.                                world together again MIT Press.
  Cognitive modelers can take advantage of these features,          Fodor J. Representations. Cambridge, MA: MIT Press 1981
that can be used as common functionalities for developing a         Gärdenfors, P. Conceptual Spaces - The Geometry of
broad range of models. For example, we used AKIRA for                 Thought, Cambridge: MIT Press, 2000
modeling decision under uncertainty (Pezzulo et al., 2004)          Hofstadter, D. R., and M. Mitchell. 1994. The Copycat
                                                                      Project. In Advances in connectionist and neural
and goal-oriented processing (Pezzulo, 2005). In both cases,
                                                                      computation theory, Vol. 2: logical connections, ed. K. J.
the knowledge and control structures are distributed: the
                                                                      Holyoak, and J. A. Barnden. Norwood N.J.: Ablex.
most salient beliefs, goals and actions are more active,            Hummel, J. E., & Holyoak, K. J. (1996). LISA: A
influencing more the overall state of the computation.                computational model of analogical inference and schema
  (Pezzulo, 2005b) describes a Pandemonium-like model                 induction. Proceedings of the Eighteenth Annual
where many specialized Daemons (mainly color and shape                Conference of the Cognitive Science Society (pp. 352-
detectors) realize a visual search task in a collaborative way,       357). Hillsdale, NJ: Erlbaum.
by jointly influencing the “focus controller” Daemon in a           Jackson J. V., Idea for a Mind. Siggart Newsettler, 181 1987
measure that is proportional to their current activation and        Kokinov B. N., The context-sensitive cognitive architecture
saliency. Thus, while in the original Pandemonium model a             DUAL, in Proceedings of the Sixteenth Annual
central decision process was used, we used a distributed              Conference of the Cognitive Science Society, Lawrence
schema. Some Daemons also monitor the progresses of the               Erlbaum Associates, (1994).
others: for example, line detectors are sensitive to the            Kokinov, B. N. (1997). Micro-level hybridization in the
activity of point detectors and exploit their activity. As a          cognitive architecture DUAL. In R. Sun & F. Alexander
design rule, we preferred monitoring activity to explicit             (Eds.), Connectionist-symbolic integration: From unified
message passing. The model also includes top-down                     to hybrid approaches (pp. 197-208). Hilsdale, NJ:
influences, with goal processes (e.g. “Find the Red T”) pre-          Lawrence Erlbaum Associates.
activating some feature recognizers (e.g. red recognizers)          Kosko B. Fuzzy Engineering Prentice-Hall, 1997.
and inhibiting others (e.g. green recognizers); we are now          Maes P., Situated Agents Can Have Goals. Robotics and
improving the model by adding Daemons that learn                      Autonomous Systems, 6 (1990).
regularities and anticipate interesting locations to search.        Minsky M. The Society of Mind. Simon and Schuster, N. Y.
                                                                      1986
                                                                    Minsky, M. The Emotion Machine. (In preparation)
                    Acknowledgments                                 Newell, A. (1990). Unified Theories of Cognition.
Work funded by the EU project MindRACES, FP6-511931.                  Cambridge, MA: Harvard University Press.
                                                                    Pezzulo G., Calvi G. Designing and Implementing MABS
                         References                                   in AKIRA P. Davidsson et al. (Eds.) MABS 2004, LNAI
Anderson, J. R. & Lebiere, C. (1998). The atomic                      3415, pp. 49–64, 2005
  components of thought. Mahwah, NJ: Erlbaum.                       Pezzulo G., Calvi G. (2005b) Dynamic Computation and
Baars, Bernard J. (1988). A Cognitive Theory of                       Context Effects in the Hybrid Architecture AKIRA
  Consciousness. New York: Cambridge University Press                 Proceedings of CONTEXT 2005
Brooks, R.A.. Intelligence without Representation. Artificial       Pezzulo G., Lorini E., Calvi G. (2004). How do I Know how
  Intelligence, Vol.47, 1991, pp.139-159                              much I don’t Know? Proceedings of COGSCI 2004.
Bryson, J. J. Modular Representations of Cognitive                  Rao A., Georgeff M., BDI Agents from Theory to Practice,
  Phenomena in AI, Psychology and Neuroscience. Visions               Tech. Note 56, AAII, 1995.
  of Mind. Darryl Davis ed. Final, 2004.                            Rosenbloom, P. S., Laird, J. E. & Newell, A. (1992) The
Cassimatis N. L. (2002). Polyscheme: A Cognitive                      Soar Papers: Research on Integrated Intelligence.
  Architecture for Integrating Multiple Representation and            Volumes 1 and 2. Cambridge, MA: MIT Press.
  Inference Schemes. Doctoral Dissertation, Media                   Rumelhart D. E., Mc Clelland J. L. and the PDP Research
  Laboratory, MIT, Cambridge, MA.                                     Group, Parallel distributed processing: explorations in
Castelfranchi C., Silent Agents: From Observation to Tacit            the microstructure of cognition. Vol. I, 1986.
  Communication, In: Proceedings of MOO 2004                        Sloman, A. 1999. What Sort of Architecture is Required for
Chalmers, D., 1992, Subsymbolic Computation and the                   a Human-like Agent? In Foundations of Rational Agency,
  Chinese Room, in J. Dinsmore (ed.), The Symbolic and                ed. M. Wooldridge, and A. Rao. Dordrecht, Netherlands:
                                                                      Kluwer Academic Publishers.
1
                                                                    Sun R., Learning, action, and consciousness: a hybrid
  Not all the elements of SOM are followed to the letter. For         approach towards modeling consciousness. Neural
example, SOM K-lines are quite separated from other agencies.         Networks, 10 (7), pp.1317-1331. 1997.
However, it is possible to represent K-lines in AKIRA by using
Daemons having semantic content and no functional body.
                                                                1743

