UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
What vs. Where: Which Direction Is Faster?
Permalink
https://escholarship.org/uc/item/3f23r6tf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Bao, Ruijun
Johnson, Todd R.
Wang, Hongbin
Publication Date
2005-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                    What vs Where: Which Direction Is Faster?
                                          Hongbin Wang (Hongbin.Wang@uth.tmc.edu)
                                        Todd R. Johnson (Todd.R.Johnson@uth.tmc.edu)
                                                Ruijun Bao (Ruijun.Bao@uth.tmc.edu)
                                  School of Health Information Sciences, University of Texas at Houston
                                              7000 Fannin Suite 600, Houston, TX 77030 USA
                               Abstract                                  blue triangle, red circle, black square, and green diamond)
                                                                         were briefly presented, each at a unique position relative to a
   It has been well documented that where a visual stimulus is           center fixation (e.g., top, right, bottom, left, respectively).
   located and what it is are represented and processed through          Subjects were then asked to perform a partial report task in
   different neural pathways. This paper reports on an experiment
                                                                         two conditions. In the location-cue condition, subjects were
   that investigated how the where pathway and the what pathway
   interact by evaluating and comparing the relative efficiency of
                                                                         presented a location word (e.g., “top”) and asked to report the
   retrieval in two directions: from what to where and from where        color and shape of the object that appeared at that location
   to what. Our results show that retrieving from what to where is       (i.e., “blue” & “triangle”). In the color-cue condition, subjects
   faster than retrieving from where to what, quite contradictory to     were presented a color word (e.g., “red”) and asked to report
   previous results. The implications of our findings are discussed.     the location and shape of the object with that color (i.e., “red”
                                                                         & “circle”). Nissen found that when the cue was a location,
                            Introduction                                 correct recall of color and shape were statistically
A large body of evidence in visual perception and attention              independent; however, when the cue was a color, correct
has shown that different dimensions of a visual stimulus are             recall of shape depended on correct recall of location.
processed in parallel by different specialized neural systems,              Based on these results, Nissen suggested that spatial
especially in early vision (see Farah, 2000). The well                   locations played a unique and special role in visual selective
documented distinction between the what and where                        attention – it is location that mediates visual feature
pathways reflects this general principle of modularity in the            integration and retrieval but not the other way around. In
brain’s information processing. Specifically, Ungerleider &              particular, she suggested that there existed multiple maps,
Mishkin (1982) suggested that there were two cortical visual             each representing a different visual feature. A color map
systems in the brain, with a ventral pathway through inferior            registered the spatial layout of presented colors, and a shape
temporal cortex processing information about features that are           map registered the spatial layout of presented shapes. Since
critical for object recognition, such as shape and color, and a          these maps were co-registered relative to spatial locations,
dorsal pathway through posterior parietal cortex processing              locations became special in that they allowed cross-reference
information about object location and spatial relations among            between maps. Therefore, retrieving the shape (or color) of an
objects. This distinction has later been summarized as “what”            object given its location as a cue could be done using the
versus “where”, respectively.                                            single shape map (or color map), resulting in a statistical
   Despite the enormous evidence supporting the segregation              independence in accuracy. On the contrary, retrieving the
of what and where processing, the implications of such                   shape of an object given its color as a cue required access to
segregation on perception, attention, and working memory                 two maps – one had to first use the color map to retrieve the
have been actively debated (see Farah, 2000). One essential              location containing an object with that color, followed by
issue is how the two pathways interact. For example, while it            using the shape map to retrieve the shape at that location. The
has been suggested that what and where information is                    crucial mediation role of location in cross-referencing maps
integrated in prefrontal cortex (e.g., Rao, Rainer, & Miller,            led to the statistical dependence in performance.
1997), Ungerleider, Courtney, & Haxby (1998) show that the                  Though Nissen’s analysis has been questioned (e.g.,
segregation of ventral what and dorsal where processing                  Monheit & Johnston, 1994; van der Velde & van der Heijden,
extends from visual cortex to prefrontal cortex, forming a               1997), her claim that spatial location plays a particularly
distributed neural system for visual working memory. In the              important role in visual perception and selective attention has
attention literature, although the role of location (where               generally been supported (Isenberg, Nissen, & Marchak,
information) in shifting attention and binding other visual              1990; Tsal & Lavie, 1993; Tsal & Lamy, 2000). Based on
features (what information) for object identification has been           Nissen’s results, a representational scheme that emphasizes
generally emphasized (e.g., Treisman & Gelade, 1980;                     spatial location’s function in bridging and binding other
Posner, 1980; Lamy & Tsal, 2001), various forms of object-               visual features was proposed (see Figure 1) and a
based attention have also been advocated (e.g., Pylyshyn,                computational model was developed using the ACT-R
2001; Scholl, 2001).                                                     cognitive architecture (Johnson, Wang, Zhang, & Wang,
   Nissen (1985) reported a study investigating how spatial              2002). The modeling results matched Nissen’s experimental
information processing interacts with visual feature                     results remarkably well.
processing. In her Experiment 2, four colored shapes (e.g.,
                                                                     2337

   This type of location-indexed multi-map theory of visual        link is included to allow a quite direct mutual influence
perception has interesting implications on the nature of           between the spatial where pathway and the object what
interaction between what and where pathways. On the one            pathway (see Figure 2). However, the model maintains that
hand, it suggests that while each visual feature of a              the link strengths are not equal for the two directions. In
multidimensional visual stimulus is processed and                  particular, the influence of spatial processing on the object
represented separately, each feature representation (what          pathway is stronger than the opposite direction, indicated by
information) is fundamentally intermingled with the                the thicker arrow in Figure 2. The bi-directional but
corresponding spatial location (where information) in a form       asymmetric link permits a more flexible balance of multiple
of map that directly links visual features and their locations     factors such as location-based versus object-based attention
(see Figure 1). This is inconsistent with the general principle    and top-down versus bottom-up control. It also leads to the
                                                                   prediction that from-where-to-what retrieval should be easier
of what and where segregation. On the other hand, if one
                                                                   than from-what-to-where retrieval.
indeed possesses these types of maps and can use them for
retrieval, we would expect that in a single map situation
retrieving a visual feature (what) from a location (where) is
no different from retrieving a location (where) from a visual
feature (what). This is just what Nissen suspected. She
predicted that when “subjects were cued with a color and
reported the location of the cued color, or they were cued
with a location and reported the color at the cued location …
selection by location would hold no special advantage” (p.
208).
                                                                     Figure 2: O’Reilly & Munakata (2000)’s model of spatial
                                                                                              attention.
                                                                       The experiment adopted a study-then-test paradigm. In the
                                                                    study phase, an array of objects (drawings), each with a
                                                                    unique location, was presented on a computer screen and the
                                                                    subject was asked to study the array. In the test phase, one of
                                                                    the two retrieval conditions was used. In the from-where-to-
                                                                    what condition, a location was marked and the subject was
    Figure 1: Johnson et al. (2002)’s location-indexed multi-       asked to report the object that had appeared at that location in
              map representations of visual stimuli.                the study phase. In the from-what-to-where location, a studied
                                                                    object was presented and the subject was asked to report the
   Is from-what-to-where retrieval truly as efficient as from-      location where the object had been studied. In either
where-to-what retrieval? Though Nissen’s experimental               condition, the subject was required to respond as quickly and
results supported this claim, only accuracy data were               accurately as possible and the RT was recorded.
provided. Due to possible speed-accuracy tradeoffs, accuracy           One key difficulty in the above design was how to mark or
data alone may not tell the whole story. Yet another way to         record object locations. To minimize various undesired
test the claim is to collect and analyze the reaction time (RT)     influences on the RT measures, we adopted a labeling
data as well. If retrievals in the two directions were closely      technique. In the from-where-to-what condition, all relevant
coupled and equally efficient, as suggested by the location-        locations were clearly marked with black squares, except that
indexed multi-map theory, one would expect similar RTs in           there was also a question mark appearing in the square of the
either direction. On the contrary, if two directions are not        target location. In the from-what-to-where condition, all
equally efficient, different RTs would be expected.                 relevant locations were again marked with black squares.
                                                                    However, each square was now labeled by a random unique
                         Experiment                                 number. The subject had only to report the number that
                                                                    identified the to-be-reported location.
The purpose of the experiment was to explore the interaction
of what and where processing by comparing the relative
                                                                    Method
efficiency of retrieval in two directions: from what to where
and from where to what. Though Nissen (1985)’s                      Subjects Twelve graduate students at the University of Texas
experimental results and Johnson et al. (2002)’s                    Health Science Center at Houston were paid to participate in
computational model both suggest that the two directions            the experiment.
would be similar (see Figure 1), different views exist.
O’Reilly and Munakata (2000) reported a connectionist               Apparatus and Materials Forty black line drawings of
model of spatial attention that involves specific claims of         common objects were selected from the database developed
what and where interaction. In that model, a bi-directional         by Snodgrass and Vanderwart (1980) and randomly assigned
                                                               2338

to five groups. There was no significant difference among            possible. Once a response was made (or 5s has passed with
different groups in several major semantic characteristics           no response), the next testing trial began until all 24 trials
such as name agreement, image agreement, familiarity, and            were finished. No feedback of the response correctness was
frequency. Each drawing is 100x100 pixels in size. A                 provided for each testing trial.
windows PC with a 17’’ VGA monitor (640x480 resolution)
                                                                                   a
was used to present the stimuli. E-prime was adopted to
control the experiment and collect the subject’s RT data via a
voice key. The subject’s verbal response (either a location
number or an object name) was recorded by an experimenter
sitting next to the subject.
Design Each subject performed both from-where-to-what and
from-what-to-where conditions. The order was counter-
balanced among subjects. The study phase was the same for
both conditions: eight object drawings were presented at eight
locations in the center region of the screen (see Figure 3a) and
                                                                                   b
the subject was required to study them. In each trial of the test
phase, the subject either had to report the object
corresponding to the location indicated by the question mark
(from-where-to-what condition, see figure 3b) or report the
number (1-8) that appeared at a location corresponding to a
centrally presented object (from-what-to-where condition, see
figure 3c).
   Each subject performed five blocks of each condition, with
each block using a unique group of object drawings for
studying and testing. In each block, after studying the object                     c
array, the subject proceeded to the test phase, in which each
just studied object drawing was tested three times, resulting in
24 testing trials in each block (and 24x5=120 testing trials in
each condition).
   An extra baseline block was performed in the very
beginning of each condition. For the from-where-to-what
condition, the baseline block consisted of 40 trials in each of
which a single object drawing was presented in the center of
the screen and the subject just had to report the name of the
object as quickly as possible. For the from-what-to-where                  Figure 3: Experimental design. a) study phase; b) from-
condition, the baseline condition consists of 24 trials in each           where-to-what retrieval; c) from-what-to-where retrieval
of which eight numbers (1-8) were presented at eight
locations with only one appearing in red background and the           Results
subject had to report that special number as quickly as
possible. The RTs in these trials were recorded as baseline for       Accuracy Data The average accuracy was 95.2% for the
later data analysis.                                                  from-where-to-what condition and 96.3% for the from-where-
                                                                      to-what condition, indicating that subjects could achieve
Procedure The subject was first provided a piece of paper             relatively high retrieval accuracy in both conditions.
with the forty object drawings and their corresponding names
on it and was asked to read them 3 times to get familiar with         RT Data Only those RTs from correct trials were used for
them. The subject was then led to the testing room where he           further analyses. The main results are shown in Table 1.
or she performed the two experimental conditions in a pre-               Several paired t-tests were carried out to compare the RTs
assigned order. There was a 2-minute break between                    in the two conditions. We found a significant difference for
conditions.                                                           the baseline RTs (Diff=-205.6ms, t(11)=-4.38, p<0.001), a
   In the study phase of each block, the subject was                  significant difference for the retrieval RTs (Diff=-463.9ms,
instructed to study and memorize the eight presented object           t(11)=-5.39, p<0.001), and a significant difference for the
drawings and their locations, at his/her own pace. In each            RTs of retrieval minus baseline (Diff=-258.3ms, t(11)=-2.56,
trial of the test phase, a fixation mark “+” was first                p<0.02). While the baseline RT difference is expected due to
presented in the center of the screen for 1.5s, accompanied           the well practiced nature of number reading than object
by a brief beep, at which point the condition-specific                naming, the latter two differences were quite surprising. They
retrieval cues were presented and the subject was required to         suggest that retrieval from what to where is faster than
make a corresponding response as quickly and accurately as
                                                                 2339

retrieval from where to what, contradictory to both                   term memory than the perceptual memory Nissen examined.
predictions described previously.                                     It is likely that the representations underlying perceptual
                                                                      visuospatial memory is quite different from the
Table 1: Average RTs in each condition (in ms). The numbers           representations      underlying     well-studied     longer-term
                in parentheses are standard errors.                   visuospatial memory. In addition, our use of object drawings
                                                                      might play a role. While the number of relevant screen
                                                      Retrieval-      locations was quite limited and well defined in our design, the
  Condition          Baseline         Retrieval                       number of potential objects might be numerous and not well
                                                      Baseline
                                                                      defined, resulting in a type of fan effect (e.g., Anderson &
 From-what-                            1333.0
                   676.1 (40.9)                     656.9 (89.0)      Reder, 1999). A general conclusion should not be drawn until
   to-where                            (101.0)
                                                                      these factors are carefully examined.
From-where-                            1796.9
                   881.7 (46.4)                     915.2 (90.3)
    to-what                             (75.0)                                             Acknowledgments
                                        -463.9          -258.3         This work is supported by grants from the Office of Naval
  Difference       -205.6 (46.9)
                                        (86.0)         (101.0)         Research (Grant Nos. N00014-01-1-0074 & N00014-04-1-
                                                                       0132). We thank Dr. Yanlong Sun for his help in
                                                                       experimental design.
                           Discussion
Segregation of processing is a general principle of how the                                     References
brain carries out cognitive functions. It has been well                Anderson, J. R., & Lebiere, C. (1998). The atomic
documented that different dimensions of a visual stimulus,               components of thought. Hillsdale, NJ: Lawrence Erlbaum
including it spatial location and various visual features (e.g.,         Press.
color, shape, and texture) are represented and processed              Anderson, J. R., & Reder, L. M. (1999). The fan effect: New
through different neural pathways. One critical question is              results and new theories. Journal of Experimental
how different pathways interact with each other to give rise to          Psychology: General, 128, 186-197.
unified human cognition.                                              Farah, M. J. (2000). The cognitive neuroscience of vision.
   This paper reported an experiment that intended to                    Malden, MA: Blackwell Publishers.
                                                                      Isenberg, L., Nissen, M. J., & Marchak, L. C. (1990).
investigate how the where pathway and the what pathway
                                                                         Attentional Processing and the Independence of Color and
interact by evaluating and comparing the relative efficiency
                                                                         Orientation. Journal of Experimental Psychology: Human
of retrieval in two directions: from what to where and from              Perception & Performance, 16(4), 843-856.
where to what. Previous results predicted that the two                Hunt, E., & Waller, D. (1999). Orientation and wayfinding: A
directions were either equally efficient (e.g., Nissen, 1985;            review (Technical Report to ONR). Arlington, VA.
Johnson et al., 2002) or that from-where-to-what retrieval is         Johnson, T. R., Wang, H., Zhang, J., & Wang, Y. (2002). A
faster than from-what-to-where retrieval (e.g., O’Reilly &               Model of Spatio-Temporal Coding of Memory for
Munakata, 2000). Quite surprisingly, our results contradicted            Multidimensional Stimuli. In The Twenty-Fourth Annual
either prediction. Showing that retrieving from what to where            Conference of Cognitive Science Society. Hillsdale, NJ:
is faster than retrieving from where to what, our results imply          Lawrence Erlbaum.
some quite different underlying representations. Specifically,        Lamy, D., & Tsal, Y. (2001). On the status of location in
our results suggest that the link strength from object identity          visual attention. European Journal of Cognitive
(or other visual features) to its location is stronger than the          Psychology, 13(3), 305-342.
link strength from object location to its identity. It seems that     Monheit, M., & Johnston, J. C. (1994). Spatial attention to
object location, as an important feature of object, is readily           arrays of multidimensional objects. Journal of
represented and strongly bound with the object                           Experimental Psychology: Human Perception &
representation. Therefore, given an object, its location can be          Performance, 20(4), 691-708.
quite quickly retrieved. On the other hand, there may not exist       Nissen, M. J. (1985). Accessing features and objects: Is
readily retrievable location representations that link to the            location special? In M. I. Posner & O. S. M. Marin (Eds.),
objects that have occupied that location. Such information               Attention and performance XI (pp. 205-219). Hillsdale, NJ:
may have to be computed online when needed, therefore                    Erlbaum.
taking longer time (e.g., Hunt & Waller, 1999).                       O’Reilly, R. C., & Munakata, Y. (2000). Computational
                                                                         explorations in cognitive neuroscience. Cambridge, MA:
   It is important to note that there are multiple factors that
                                                                         MIT Press.
may contribute to the pattern of results in our experiment. For
                                                                      Posner, M. I. (1980). Orienting of attention. Quarterly
example, we allowed subjects to study the object array at their          Journal of Experimental Psychology, 32, 3-25.
own pace. On average, our subjects used about 2.5 minutes             Posner, M. I., Walker, J. A., Friedrich, F. J., & Rafal, R. D.
(range = 1.2 to 3.5 minutes) to study the array, which was               (1984). Effects of parietal lobe injury on covert orienting of
very different from Nissen’s experiments where the stimuli               visual attention. Journal of Neuroscience, 4, 1863-1874.
were presented very briefly (~120ms). As a result, we are             Pylyshyn, Z. W. (2001). Visual indexes, preconceptual
actually examining the representations underlying a longer-              objects, and situated vision. Cognition, 80, 127-158.
                                                                  2340

Rao, S. C., Rainer, G., & Miller, E. K. (1997). Integration of        Tsal, Y., & Lavie, N. (1993). Location Dominance in
  What and Where in the Primate Prefrontal Cortex. Science,             Attending to Color and Shape. Journal of Experimental
  276, 821-824.                                                         Psychology: Human Perception and Performance, 19(1),
Scholl, B. J. (2001). Objects and attention: The state of the           131-139.
  art. Cognition, 80, 1-46.                                           Ungerleider, L. G., Courtney, S. M., & Haxby, J. V. (1998).
Snodgrass, J. G., & Vanderwart, M. (1980). A standardized               A neural system for human visual working memory. Proc
  set of 260 pictures: Norms for name agreement, image                  Natl Acad Sci U S A, 95, 883-890.
  agreement, familiarity, and visual complexity. Journal of           Ungerleider, L. G., & Mishkin, M. (1982). Two cortical
  Experimental Psychology: Human Learning & Memory, 6,                  visual systems. In D. J. Ingle, M. A. Goodale & R. J. W.
  174-215.                                                              Mansfield (Eds.), Analysis of visual behavior. Cambridge,
Treisman, A., & Gelade, G. (1980). A feature-integration                MA: MIT Press.
  theory of attention. Cognitive Psychology, 12, 97-136.              van der Velde, F., & van der Heijden, A. H. C. (1997). On the
Tsal, Y., & Lamy, D. (2000). Attending to an object’s color             Statistical Independence of Color and Shape in Object
  entails attending to its location: Support for location-special       Identification. Journal of Experimental Psychology:
  views of visual attention. Perception & Psychophysics,                Human Perception and Performance, 23(6), 1798-1812.
  62(5), 960-968.
                                                                 2341

