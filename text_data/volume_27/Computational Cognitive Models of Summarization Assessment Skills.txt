UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Computational Cognitive Models of Summarization Assessment Skills
Permalink
https://escholarship.org/uc/item/0bn3s934
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Denhiere, Guy
Dessus, Philippe
Lamaire, Benoit
et al.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

             Computational Cognitive Models of Summarization Assessment Skills
                                          Benoît Lemaire (Benoit.Lemaire@imag.fr)
                                            Laboratoire Leibniz-IMAG (CNRS UMR 5522)
                                                   38031 Grenoble Cedex 1 FRANCE
                                     Sonia Mandin (Sonia.Mandin@upmf-grenoble.fr)
                                                L.S.E., University of Grenoble & IUFM
                                                   38040 Grenoble Cedex 9 FRANCE
                                    Philippe Dessus (Philippe.Dessus@upmf-grenoble.fr)
                                                L.S.E., University of Grenoble & IUFM
                                                   38040 Grenoble Cedex 9 FRANCE
                                           Guy Denhière (denhiere@up.univ-mrs.fr)
                                              L.P.C., University of Aix-Marseille & CNRS
                                                   13331 Marseille Cedex 1 FRANCE
                            Abstract                                   assess the importance of sentences in texts. Then, we will
                                                                       describe a method for automatically inferring the macrorules
  This paper presents a general computational cognitive model of       that humans could have used in producing a summary. Both
  the way a summary is assessed by teachers. It is based on            models will be applied to a system that helps students to
  models of two subprocesses: determining the importance of            summarize texts.
  sentences and guessing the cognitive rules that the student may
  have used. All models are based on Latent Semantic Analysis, a
                                                                          Our process models are based on an underlying
  computational model of the representation of the meaning of          representation model, namely Latent Semantic Analysis
  words and sentences. Models' performances are compared with          (Landauer & Dumais, 1997), that can provide semantic
  data from an experiment conducted with 278 middle school             relations between sentences or propositions.
  students. The general model was implemented in a learning               The remainder of this paper is as follows. First, we will
  environment designed for helping students to write summaries.        briefly present LSA, then four models of the sentence
  Keywords: Summarization; Macrorules; Cognitive modeling;             selection task, then a model of the way the use of macrorules
  Computer environment; Latent Semantic Analysis.                      could be detected in a summary, then a computer system that
                                                                       implements both text selection and macrorules detection.
                         Introduction
                                                                        A Representation of Sentences based on Latent
Summarizing information after reading a text is a very
important and complex task. This ability can be both viewed                                 Semantic Analysis
as the cause of text comprehension (Thiede & Anderson,                 Modeling the activities involved in the summarization
2003) and its consequence (Brown & Day, 1983). This ability            process should be done at the semantic level, especially for
can be more precisely described by two distinct sub-models: –          the purpose of cognitive modeling. We thus rely on LSA
assessing the importance of the text read for selection                (Landauer, 2002), a powerful model for the representation of
purposes (Garner, 1987); – applying a set of macrorules like           the meaning of words and sentences. LSA takes a huge
generalizing or deleting information (Brown & Day, 1983;               corpus as input and yields a high-dimensional vector repre-
Kintsch & van Dijk, 1978) that builds elements of the text             sentation for each word. It is based on a singular value
macrostructure.                                                        decomposition of a word x paragraph occurrence matrix,
  This paper is not concerned with the summarization                   which implements the idea that words are given similar rep-
process per se, whose result is a summary, but with the                resentations if they occur in similar contexts (not identical
summarization assessment process, whose result is a                    contexts, as LSA is often reduced to!). Such a vector repre-
diagnosis on a summary and possibly a global score.                    sentation is very convenient to give a representation to sen-
Actually, both processes probably share similar subprocesses.          tences that were not in the corpus: the meaning of a sentence
The teacher who is assessing a summary should have                     is represented as a linear combination of its word vectors.
previously mentally assessed the importance of the text                Therefore, we can virtually take any sentence and give it a
sentences. The difference probably lies in the fact that the           representation. The second advantage of the vector represen-
teacher does not actually have to apply macrorules to                  tation is that it is straightforward to compute the similarity
construct the summary, but rather detects the use of these             between vectors, usually by means of the cosine function. Our
macrorules by the student.                                             models largely rely on this LSA measure of semantic
  The purpose of this paper is to design and test                      similarity.
computational cognitive models of these two subprocesses.                 The corpus from which the semantic space is built plays a
First, we will present various models of the way humans                large role, especially for the purpose of cognitive modeling. If
                                                                  1266

the semantic similarity between words or pieces of text is            by the four following models. Any sentence partially
meant to model human associations in semantic memory,                 underlined by participants was categorized as entirely
then the corpus should correspond as closely as possible to           underlined. Our tables will indicate results by grade because
the kind and amount of text humans are exposed to.                    we were looking for possible differences. Since we do not
   The LSA semantic space which was used in all four models           know whether the differences found are due to a school or
was built from a 13 million word corpus composed of three             class effect, they are hardly interpretable. We therefore
sub-corpora:                                                          discuss only on the overall results.
– a 3.3 million word corpus representing the kind of texts
     participants were exposed to during their childhood                  Table 1: Participants' distribution between grades and text
     (Denhière & Lemaire, 2004);                                                                       read.
– a 5 million word corpus composed of novels;
– a 5 million word corpus composed of newspaper articles.                Text/Grade     8th        9th       10th     11th      Total
   This huge corpus was processed by LSA and all words                   Narrative      25         39        55       19        138
were represented as vectors in a 300-dimensional space. We               Expository     25         39        54       22        140
will now successively present the two subprocesses that are
part of the summary assessment skills.                                 Model 1: Important Sentences have a High Semantic
                                                                       Similarity with Text
            Subprocess 1: Sentence Selection                           In our first model, we postulate that important sentences have
This first set of models seeks to describe the way humans as-          a high semantic similarity with the whole text. The two texts
sess the importance of sentences in a text. These models are           and all their sentences were represented as vectors in the
not specific to the summarization assessment process, they             semantic space mentioned earlier. All sentences were
are probably the same as the summarization process itself.             assigned a measure of importance which was their cosine
   Our four models manage differently the cognitive processes          with the text. Correlations with human data are presented in
which may be involved in identifying the most important                Table 2. Results show a good adequacy for the expository
sentences in a text. The first one postulates that, in so doing,       text, much better than for the narrative text. It is worth noting
we compare each sentence to the entire text (E. Kintsch et al.,        that such a simple model of importance assessment could so
2000). The second model considers that the reader would                well mimic human judgments.
consider as being important those sentences that are highly
connected to the others. We borrowed this idea from                        Table 2: Within-grade correlations between model 1 and
Kintsch's (2002) notion of sentence typicality, which is the                                       human data.
semantic relation between a sentence and all other sentences
in its text section. The third model postulates that the reader is       Text/Grade 8th           9th        10th   11th      Overall
rather aware of coherence gaps between two blocks of                     Narrative       .37      .18        .34    .28       .31
sentences (Foltz, Kintsch & Landauer, 1998). The last model              (N = 24)
views the main idea selection as the result of the sentence by           Expository      .52*     .70**      .59**  .58*      .64**
sentence comprehension of the text, by the way of the                    (N = 18)
Construction-Integration model (Kintsch, 1998).                          *p < .05; **p < .01
   These four computational models will be successively pre-
sented and all simulations will be compared to human data.                One reason why the narrative text does not yield good
We first present the experiment which provided these data.             results could be due to the LSA rule of compositionality: the
                                                                       meaning of the whole text is a linear combination of the
Human Experiment                                                       meaning of its sentences. A text is therefore an aggregate
We carried out a human experiment to collect empirical data            structure which tends to flatten the individual meanings of its
to which each of our computational models of sentence                  sentences. It is not a problem with expository texts for which
selection was to be compared. We chose participants above              all sentences are related to the general theme. For instance, all
grade 7 for their adult-like capability to rate important              sentences of our expository text have to do with elephants.
passages (Hidi & Anderson, 1986). A total of 278 middle                Narrative texts are quite different. They usually have a “plot”
school students (grades 8 to 11, see Table 1 for the                   (Pinto Molina, 1995). Sentences must be linked to that plot,
distribution) were given a single-page text among two: an              but not necessarily to an “average meaning” of the story.
expository text, entitled “Elephants’ drugstore” or a narrative        Therefore, this model might not be adequate for narrative
text, entitled “Miguel”. These texts respectively contained            texts.
523 and 382 words (18 and 24 sentences). The average
number of words per sentence was 29.06 (SD = 14.66) in the             Model 2: Important Sentences are Highly Connected
first text, and 15.92 (SD = 8.22) in the second one. The               to Other Sentences
expository text was selected because of the lack of                    The second model is more fine-grained. Instead of
participants' prior knowledge in this domain. The task was to          considering the text as a whole, it breaks it into sentences. It
read the text and to “underline three to five sentences on the         is based on the idea that important sentences are highly
sheet, that seemed to be the most important”. The underlined           connected to others. The degree of connectivity between two
sentences were then compared to the set of sentences selected          sentences is defined as the cosine of their vectors. Therefore,
                                                                  1267

we define the importance of a sentence as the number of other           For example, given the sentences 12, 13, 14 with inter-
sentences whose cosine with the current one is above a given        sentence similarities respectively of .1 (between 12 and 13),
threshold (.12 in this study). Table 3 displays the correlations    .5 (between 13 and 14) and .1 (between 14 and 15), sentences
with human data. The expository text was still better than the      13 and 14 are considered part of a coherent block. In order to
narrative one and overall results are better than for model 1.      match results from the model with human ones, selected
                                                                    sentences were coded 1, others were coded 0.
    Table 3: Within-grade correlations between model 2 and              Table 4 shows that the comparison between human
                           human data.                              selection and data from this model yields significant values
                                                                    for the expository text, but rather poor ones for the narrative
  Text/Grade 8th          9th      10th      11th      Overall      text, comparable to the data from the first model.
  Narrative       .34     .10      .48*      .37       .37
  (N = 24)                                                              Table 4: Within-grade correlations between model 3 and
  Expository      .53*    .68**    .62**     .65**     .66**                                     human data.
  (N = 18)
  *p < .05; **p < .01                                                  Text/Grade     8th       9th      10th     11th      Overall
                                                                       Narrative      .22       .23      .35      .27       .30
                                                                       (N = 24)
Model 3: Important Sentences Belong to Coherent                        Expository     .48*      .57*     .41      .54*      .51*
Blocks                                                                 (N = 18)
Another dimension of the structure of a text to be summarized          *p < .05
is its coherence. This notion expresses the amount of
relatedness between text units (e.g., sentences, paragraphs),           Comparing the three previous models, we could say that
provided that the more coherent are parts of a text, the more        model 2 is the best: it is the most fine-grained and it takes into
they could be selected as the most important ideas from this         account all text sentences instead of just adjacent ones. It
text (i.e., the macrostructure of the text). This dimension is       could be a reason why this kind of model is widely used in
related to the capability to recognize connections between           the field of automatic summarization.
adjacent elements of the text.
   The third model we tested used coherence between                  Model 4: Important Sentences have High Activation
sentences to predict their importance. This model postulates         Values in a Simulation of their Comprehension
that, given a block of sentences, important ones are merely          The fourth model attempts to integrate information among
placed at the beginning and at the end of the block                  sentences. Instead of considering each sentence in isolation
(Baxendale, 1958; Williams et al., 1984). We defined a               and compare it to the whole text (model 1), other sentences
coherent block as a consecutive chain of sentences separated         (model 2), or the preceding and following sentences (model
from others by a coherence gap.                                      3), it takes into account the time course of sentence
   Barzilay and Elhadad (1997) used such a procedure for             comprehension. The importance of sentences is given by their
automatically extracting the most important segments of a            activation value at the end of the whole text processing. This
text. First, they constructed a net of semantically connected        model is based on the Construction-Integration model of text
words, and then they carried out three heuristics. The third is      comprehension (Kintsch, 1998). It relies on three different
especially important for our purpose: “[the central topic is] a      memory structures:
cluster of successive segments with high density of chain            – a working memory which is a set of concepts (words) or
members”. This procedure resembles ours because we                        propositions as well as their activation values. Items
designed a model able to capture successive segments of texts             come from the text itself, the semantic memory or the
that also are highly coherent.                                            episodic memory.
   The procedure used in the model 3 is as follows. This             – a semantic memory, simulated by LSA, which can
model is a generalization of the result presented above: the              provide associates to concepts or propositions.
first and last sentences of a paragraph are often considered         – an episodic memory, which keeps track of all concepts or
important. The notion of paragraph can be extended to any                 propositions that occur in working memory, as well as
block of sentences (e.g., text) and our model becomes: first              their activation value which tend to decay over time.
and last sentences of a coherent block of text are considered        Figure 1 describes the architecture. The text is processed
important. The two source texts were thus processed in order         proposition by proposition (sentence by sentence in this study
to find out coherent blocks of sentences, that is, any sequence      for the sake of homogeneity). Each proposition activates
of inter-sentence similarities above an arbitrary threshold (.11     semantic neighbors from semantic memory (for instance, the
in this study). We used LSA to compute these inter-sentence          bee is sucking nectar from a flower activates honey and hive).
similarities following Foltz et al. (1998) method: similarity        They are all added to working memory. Concepts or
between two adjoining sentences is the cosine of their               propositions from episodic memory can also be added to
vectors. The first and last sentences of each text were              working memory if they are close enough (and activated
obviously also selected.                                             enough) to one of the current elements.
                                                                1268

                                                                    connections between sentences are less obvious than in
                                                                    expository texts. All the sentences of our expository text deal
                                                                    with the same topic, whereas the domain of the narrative text
                                                                    is much broader. This could explain why model 4 produced
                                                                    better results with the narrative text. For the purpose of
                                                                    assessment, we compared our models to a simpler model,
                                                                    namely the Microsoft Word summary generator. Its overall
                                                                    correlations with human data appear to be lower than
                                                                    previous ones (r = .45 for the narrative text; and r = –.30 for
                                                                    the expository one).
                                                                      Subprocess 2: Detecting the Use of Macrorules
                                                                     We are now concerned with the second subprocess of the
                                                                     summarization assessment process. Besides identifying
               Figure 1: Architecture of model 4.                    important sentences in the text, the teacher is engaged in the
                                                                     detection of the student's strategy, which is viewed as the
   The integration algorithm defined by Kintsch (1998) is then       application of adequate macrorules.
applied to provide activation values to elements and to rule           Macrorules are the core of the cognitive processes involved
out irrelevant ones. It is based on a matrix of semantic             in the summarization activity (Kintsch & van Dijk,
similarities also provided by LSA. For instance, a concept           1978).These authors described three macrorules:
like florist that could have been activated from semantic            – deletion, where each proposition (in our case, sentence)
memory would be given a low activation value and removed                 that either contains minor, redundant or unrelated details
from working memory in the previous context of the bees.                 may be deleted;
However, a proposition that could have occurred previously           – generalization, where “each sequence of propositions may
in the text, like How the honey is made would be retrieved               be substituted by the general proposition denoting an
from episodic memory, given a high activation value and kept             immediate superset” (id., p. 366);
in working memory.                                                   – construction, where “each sequence of propositions may
   This model was implemented in Perl and hooked up to                   be substituted by a proposition denoting a global fact of
LSA. It is available on demand for academic purpose.                     which the facts denoted by the microstructure
   Our two texts were processed with this model and the final            propositions are normal conditions, components, or
activation values of all text sentences were collected. These            consequences”. (ibid.)
values were then compared with the participants' judgments             We did not implement these macrorules, which is quite a
of importance (see Table 5). It turns out that correlations are     hard task (Kintsch, 2002), but rather modeled the detection of
more homogeneous. They are even better than previously for          their usage by the student. Given a text and its summary, a
the narrative text and worse for the expositive one.                teacher is able to infer that this particular sentence in the text
                                                                    has been deleted, that this summary sentence is a
   Table 5: Within-grade correlations between model 4 and           generalization, and so on. Our goal is to account for that task.
                           human data.                                 We also designed three additional macrorules which more
                                                                    extensively describe the operations on the source text (after
  Text/Grade     8th     9th       10th     11th      Overall       Brown & Day, 1983):
  Narrative      .42*    .42*      .39      .41*      .43*          – paraphrase, which consists in writing down a
  (N = 24)                                                                semantically similar sentence;
  Expository     .30     .31       .39      .37       .37            – copy, for which the resulting sentence is copied almost
  (N = 18)                                                                exactly;
  *p < .05                                                           – off-the-subject, when a sentence is added without being
                                                                          related to the subject.
   Our four models follow a progression in the way the                 As for the selection subprocess, that subprocess was
sentences are assessed. In model 1, sentences are compared to       operationalized through the use of LSA: each sentence of the
the whole text. Model 2 is intended to be more fine-grained         summary is semantically compared with each sentence of the
since sentences are compared to other sentences, no matter          source text (ST). For instance, a sentence of the ST would be
their location in the text. Model 3 operates at the same level,     considered as deleted if no sentence of the summary is
but considers only adjacent sentences (the previous one and         sufficiently close to it. In the same way, a generalized
the next one). Model 4 is another refinement since it is            sentence is a sentence of the summary that is sufficiently
entirely dependent on the sentence order by automatically           close to more than one sentence of the ST.
extracting the text macrostructure. This last model is quite           It is then necessary to operationalize this very notion of
different from the three others. It is based on a representation    closeness: how close to another is a “rather close” sentence?
of different memory structures and could even retrieve              Three similarity thresholds have been used corresponding to
concepts that were not in the text. These features are              the following similarities: not enough similarity (cosine < .2),
especially necessary for processing narrative texts since the       low similarity (.2 < cosine < .5), good similarity (.5 < cosine
                                                                1269

< .8), too high similarity (cosine > .8). The comparison of           original text. Prompts are then given to the child according to
each sentence from the summary with all N text sentences              the quality of the matching.
results in a distribution of N similarities among these four              Macrorules are more or less mentally elaborated and
categories. It is that distribution that permits the detection of     difficult to perform depending on the age and the competence
the student strategy.                                                 of the student; their application also has an effect on the
    Figure 2 shows an example of a distribution of similarities       production of the summary (Brown & Day, 1983).
with a given summary sentence. Five text sentences are                Furthermore, research showed that training students to
semantically too far from the summary sentence (# 13, 12, 6,          identify main ideas as well as to apply higher-order
7 and 4), eight share some relation with it (# 10, 3, 5, 8, 14,       macrorules (e.g., generalization, construction) led them to
16, 1 and 15), three have good similarity with it (# 11, 9 and        increase the quality of written summaries (Casazza, 1993).
2) and none is almost identical. This distribution indicates that     Once the macrorules have been detected, it is useful to
the summary sentence is probably a generalization, since              prompt the student to use the most elaborated ones. An
there are three sentences of the text that are highly similar to      overall score can also be delivered taking into account this
it.                                                                   application. For instance, if a student was generalizing a ST
                                                                      sentence using too many words, the student would be warned:
13    12 6 7    4   10 3 5 8 14 16 1 15        11    9   2            “This generalized sentence might be longer than the
                                                                      corresponding ST sentences”. It is worth noting that the
                                                                      diagnosis also takes into account the importance of the
0                 .2                       .5                .8       ranking of the sentences. For instance, if the student has
 Figure 2: Representation of the comparisons between a given          paraphrased an unimportant sentence, she or he would be
 summary sentence and each source text sentence (represented          warned.
                           by numbers).                                   Our environment implements the two subprocesses
                                                                      described previously. Assessing the importance of sentences
    More precisely, the categorization is the following. Let Qi =     in the source text is performed by an implementation of
(x1, x2, x3, x4) be the distribution of similarities over the four    model 1. Detecting the use of macrorules and providing a
categories. In the previous example, Qi = (5,8,3,0). The              diagnosis was implemented from the theoretical model we
number of sentences of the text is x1+x2+x3+x4. If we                 presented previously. The interaction with the student is as
consider that '?' indicates an unspecified value, we will say         follows. First, the student is provided with a source text. After
that a sentence Ri of the summary is:                                 reading it, the student writes out a summary of the text in
– a copy if Qi = (?, ?, ?, N), N ≥ 1 (there is at least one           another window. Secondly, at any time the student can get an
      sentence of ST which is very close to Ri);                      assessment of the summary. This feedback may either
– a generalization if Qi = (?, ?, N, 0), N ≥ 2 (there are             highlight sentences depending on whether they are adequate
      several sentences of the ST that are close to Ri);              or not, or deliver diagnostic messages about the macrorules
– a paraphrase if Qi = (?, ?, 1, 0) (there is only one                the student applied. It is worth noting that our environment
      sentence of the TS that is close to Ri);                        does not generate any “expert” summary to be compared to
– a construction if Qi = (?, N, 0, 0), N ≥ 1 (no sentences of         the students' summary. It rather diagnoses whether the student
      TS are close to Ri, but at least one of them is somehow         actually applied the macrorules to the different sentences of
      related to Ri);                                                 the summary.
– off-the-subject if Qi = (?, 0, 0, 0) (all sentences of TS are
      unrelated to Ri).                                                                         Conclusion
    Obviously, the length of the summary sentence also plays           The main asset of the learning environment we have just been
an important role in the diagnosis: each summarized sentence           presenting is its cognitive foundations. The summarizing
has to be shorter than the reference sentence. This model is           process engages numerous complex cognitive skills that have
currently a theoretical model. It has been implemented in a            to be assessed in order to assess a summary. We considered a
computer program but has not been tested yet. The reason is            two-step process: assessing the importance of sentences and
that its validation is much more difficult than for the previous       detecting the student use of macrorules. Although the first
model. One way to do that would be to compare the results of           subprocess has been subject to empirical validation, the
the model to teachers' categorizations of summary sentences.           second remains to be confronted to human data. We thus plan
                                                                       to ask teachers to detect and diagnose macrorule application
  Application: a Learning Environment to Help                          after reading student's summaries. This comparison against
              Students to Summarize Texts                              human data could help tackle a major issue: LSA-based
Since our models are computational models, they have been              models often rely on similarity thresholds to decide between
integrated into a learning environment. The goal is to rely on         two alternatives (sentences are coherent or not, words are
the information we identified (importance of sentences,                semantically related or not, etc.). However, it is quite hard to
cognitive macrorules inferred) to provide students with                set the value of those thresholds. They are often arbitrarily
several prompts that can help them to produce their                    determined and we plan instead to perform a fine tuning by a
summaries. Our system resembles other tutoring systems                 comparison to human data.
(Halpin et al., 2004; Wade-Stein & Kintsch, 2004) in which                The cognitive skills involved in the summarization process
texts rewritten by students are automatically compared to the          probably depends on the nature of the text read. Our follow-
                                                                  1270

up investigations will take into account this major difference     Hidi, S., & Anderson, V. (1986). Producing written
between narrative and expository texts.                              summaries: Tasks demands, cognitive operations, and
                                                                     implications for instruction. Rev. Educ. Res., 56, 473-493.
                    Acknowledgements                               Kintsch, W. (1998). Comprehension, a Paradigm for
This research was supported by a grant from the French               Cognition. Cambridge: Cambridge University Press.
Research Ministry under a Cognitique project leaded by Guy         Kintsch, W. (2002). On the notions of theme and topic in
Denhière. We would like to thank Beulah Henry and                    psychological process models of text comprehension. In M.
Françoise Raby for their thoughtful comments on an earlier           Louwerse & W. van Peer (Eds.), Thematics:
version of this paper; and Céline Marchais for her help during       Interdisciplinary Studies (pp. 157-170). Amsterdam:
the experiments. We also thank teachers who kindly accepted          Benjamins.
to pass the text selection experiment in their classes.            Kintsch, E., Steinhart, D., Stahl, G., LSA Research Group,
                                                                     Matthews, C., & Lamb, R. (2000). Developing
                                                                     summarization skills through the use of LSA-based
                          References                                 feedback. Interactive Learn. Env., 8, 87-109.
Barzilay, R., & Elhadad, M. (1997). Using lexical chains for       Kintsch, W., & van Dijk, T. A. (1978). Toward a model of
   text summarization. Proc. ISTS'97, Madrid.                        text comprehension and production. Psychol. Rev., 85, 363-
Baxendale, P. B. (1958). Machine-made index for technical            394.
   literature – An experiment. IBM J. Res. Dev., 2, 354-365.       Landauer, T. K. (2002). On the computational basis of
Brown, A. L., & Day, J. D. (1983). Macrorules for                    learning and cognition: Arguments from LSA. Psychol.
   summarizing texts: The development of expertise. J. Verb.         Learn. Motivation, 41, 43-84.
   Learn. Verb. Behav., 22, 1-14.                                  Landauer, T. K., & Dumais, S. T. (1997). A solution to
Casazza, M. E. (1993). Using a model of direct instruction to        Plato's problem: the Latent Semantic Analysis theory of
   teach summary writing in a college reading class. Journal         acquisition, induction and representation of knowledge.
   of Reading, 37, 202-208.                                          Psychol. Rev., 104, 211-240.
Denhière, G., & Lemaire, B. (2004). A Computational Model          Pinto Molina, M. (1995). Documentary abstracting : toward a
   of Children's Semantic Memory, in Proc. 26th Annual               methodological model. J. Am. Soc. Inform. Sci., 46, 225-
   Meeting of the Cognitive Science Society (CogSci'2004),           234.
   297-302.                                                        Thiede, K. W., & Anderson, M. C. M. (2003). Summarizing
Foltz, P. W., Kintsch, W., & Landauer, T. K. (1998). The             can improve metacomprehension accuracy. Contemp.
   measurement of textual coherence with Latent Semantic             Educ. Psychol., 28, 129-160.
   Analysis. Discourse Processes, 25, 285-307.                     Wade-Stein, D., & Kintsch, E. (2004). Summary Street:
Garner, R. (1987). Metacognition and Reading                         Interactive computer support for writing. Cognition and
   Comprehension. Norwood: Ablex.                                    Instruction, 22, 333-362.
Halpin, H., Moore, J. D., & Robertson, J. (2004). Automatic        Williams, J. P., Taylor, M. B., & de Cani, J. S. (1984).
   analysis of plot for story rewriting. Proc. EMNLP 2004.           Constructing macrostructure for expository text. J. Educ.
   Barcelona, Spain.                                                 Psychol., 76, 1065-1075.
                                                              1271

