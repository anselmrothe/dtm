UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Opponent Models and Heuristic Strategies for Simple Games
Permalink
https://escholarship.org/uc/item/3w68782k
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Author
Vickery, Timothy J.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                     Opponent Models and Heuristic Strategies for Simple Games
                                        Timothy J. Vickery (vickery@wjh.harvard.edu)
                                               Department of Psychology, 33 Kirkland St.
                                                         Cambridge, MA 02138
                            Abstract                                   joint decisions. Nash (1950) determined that any such
                                                                       scenario has at least one solution strategy from which no
   This study introduces a model that describes the reasoning          player can benefit by deviating. This solution, called Nash
   strategies of a population of players in simultaneous-move,         equilibrium, is an optimal solution to a game when all
   one-shot games. In the past, models of such behavior have           agents behave “rationally,” in terms of decision theory.
   explicitly employed the concept of Nash equilibrium in              The games typically submitted to game theoretic analyses
   players’ models of other players. In this model, behavior is        are analytically tractable: far simpler than games like
   accounted for in terms of simple heuristic strategies and           chess, but useful for probing the capabilities of agents.
   opponent modeling, rather than by recourse to the concept
                                                                          Two games employed by Stahl and Wilson (1995) to
   of Nash equilibrium. The model represents six types of
   boundedly rational players: three types who employ no
                                                                       study human behavior are shown in table 1. The model
   model of their opponents, two types who model their                 presented in this paper will later be applied to the data
   opponents as employing simple heuristics, and one type              they collected as humans played these games, which are
   who models the population as a mixture of different types           fairly prototypical of situations studied in game theory. In
   of players. Results show promise for eliminating the                these games, each subject is asked to examine each
   concept of Nash equilibrium from players’ models of other           matrix, in turn, and choose T, M or B as a response. The
   players. In pursuit of this goal, a new type of graphical           player’s reward is determined by values in the chosen
   model based on Influence Diagrams is developed.                     row. Each cell represents the value of an individual’s
   Uncertain Decision Diagrams are suitable for modeling               choice given the choices of her opponent, which
   human decision-making with respect to explicit mental               correspond to the columns. Thus, if a player chose T and
   models that include noisy estimates of utility, and can be          her opponent chose “M,” she would receive the payoff in
   extended to model players’ models of other players.                 cell (T,“M”). The games used here are symmetric,
                                                                       meaning that the opponent’s payoff table is the same.
                        Introduction                                      The prescriptive qualities of game theoretic models are
Agents often confront situations in which not only their               fascinating and useful as benchmarks to the success of
personal choices, but also the choices of others, affect the           algorithms in approximating solutions, but behavioral
subjective value of an outcome. Some examples of these                 economists and psychologists have found that the
situations are the negotiation of hunting rights between               traditional forms are unfortunately dysfunctional as
two tribes, the barter of goods at a market, and a game of             descriptive models in many situations (cf. Camerer, 2003,
rock, paper, or scissors. Such problems are of great                   who reviews many behavioral observations that
interest to cognitive science, because humans evolved and              disconfirm predictions relying on the concept of Nash
exist in an environment replete with demands to compete                equilibrium). The most successful models of human
and opportunities for cooperation. An understanding of                 behavior in repeated games depict humans as employing
how humans reason about competitive scenarios would                    algorithms that depend on reward history to approximate
improve our understanding of human behavior in                         an optimal solution (for example, reinforcement
numerous ways, allowing us to probe questions about the                algorithms). In general, humans do not seem to employ
representation of utility, other agents, and the world, and            strategies that correspond to Nash equilibrium strategies
enabling the construction of artificial agents that exploit            either initially or over repeated interactions, but rather
or enhance the strengths and weaknesses of human                       they often approximate the Nash equilibrium strategy in a
decision making.                                                       manner consistent with reinforcement learning or similar
   The model sketched here describes how humans make                   algorithms that depend on historical factors.
decisions in games, or formalized incentive structures                    Behavior matching the Nash equilibrium in one-shot
involving multiple agents. We model reasoning strategies               (non-repeated) games would imply either infinitely
employed when a person has no reward history with a                    recursive reasoning or explicit knowledge of how to
game (i.e., the games are one-shot, not repeated). The                 calculate Nash equilibrium. Thus, there is little reason to
model describes a population of players as a mixture of                believe that humans bring to a game any mechanism
player types, some of whom employ simple heuristic                     tuned to extracting an optimal strategy like the Nash
strategies, and others of whom employ simple models of                 equilibrium solution without any experience at all with a
opponents who play by these heuristic strategies.                      particular incentive structure. The behavioral data
                                                                       reported by Stahl and Wilson (1995) are testament to this:
Game Theory Background                                                 the Nash equilibrium strategy alone is entirely inadequate
                                                                       for explaining behavior. However, the authors presented a
   Traditional game theory formalizes the basic problem
                                                                       successful model of behavior in one-shot games, in which
of determining the optimal solution for all agents in a
                                                                       some players were modeled as having a concept of others
setting in which outcomes for agents are determined by
                                                                 2313

                                                                  Greatest Minimum (GM) heuristic. This strategy is
  Table 1:Games (2/12) used by Stahl and Wilson (1995)            consistent with the notion that most humans are highly
                                                                  risk-averse, and is sensible if you want to maximize the
                                                                  least reward you could possibly receive. These two
 Game         “T”   “M”   “B”   Game         “T”   “M”   “B”      strategies together predicted >90% of the choices made in
                                                                  the twelve games used here. A third type of “level-zero”
          T    25    30   100            T    75    40    45      thinking will be included, the uniform random strategy
                                                                  (U), in which choices are made with equal likelihood. A
     1   M     40    45     65      2   M     70    15   100      player employing U might misunderstand the situation or
                                                                  lack motivation altogether.
         B     31     0     40           B    70    60     0
that included the Nash equilibrium strategy. This paper           Depth of Strategic Reasoning
addresses whether or not a model of this sort can be              The second core concept is the modeling of opponent
successful without resorting to the Nash equilibrium              strategies. If an opponent’s strategy is known, then
concept in agents’ models of others.                              solving for one’s best strategy is a decision theoretic
   The discovery of consistent initial strategies in game         problem. In most situations the opponent’s strategy is
solving has important consequences. For one, it makes             unknown. One way of approaching a situation in which
choice behavior predictable in novel situations. It also has      you have no expectations is to view it from the
consequences for the course of learning. As repeated              perspective of the opponent, and then respond with the
iterations of the same or similar situation occurs, the time      best response to her expected choice. The problem with
course of learning is more predictable with such                  this is that it can be carried to an arbitrary depth. A player
knowledge than by an algorithm based upon reward                  might model an opponent as behaving on the basis of a
history alone. Knowing the initial states of learners makes       heuristic strategy, or she might regard her opponent as
prediction of the eventual stable state reliable in models        behaving on the basis of a best response to a heuristic
of behavior in games that have multiple equilibria.               strategy, and so on. Due to practical restrictions it is
   Following Stahl and Wilson (1995), the model                   unlikely that an infinitely recursive strategy could be
developed here assumes that humans are making optimal             employed by humans in such situations. However, it is
choices with respect to a noisy internal representation of        possible that people make assumptions about other
the world, including representations of other agents. The         opponents that allow them to reduce the complexity of the
model relies on an extension to Bayesian networks (Pearl,         problem to a manageable form. Empirical studies support
1988) that allows the incorporation of beliefs about others       a shallow depth of initial reasoning (e.g., Hedden and
into an explicit model.                                           Zhang, 2002).
                                                                     Stahl and Wilson (1995) constructed a model that is
            Core Concepts of the Model                            closely resembled by the model presented in this paper,
                                                                  and which will serve as a point of comparison. They
Two core concepts underlie the model presented here.              modeled a population of players using a mixture of player
The first core concept is that of a heuristic strategy. The       models, and found support for the idea that the population
second is depth of strategic reasoning. These concepts            consisted of players who randomly selected responses
motivate the structure of the model.                              (U), players who chose the best response to U, or BR(U)1,
                                                                  players who chose the best response to the best response
Heuristic Strategies                                              to U, or BR(BR(U)), players who behaved as if their
A heuristic is a simple rule of thumb or “ad hoc” strategy.       opponents played the Nash equilibrium strategy (Naïve
A person who is knowledgeable of an incentive structure           Nash, or NN), and “worldly” types who behaved as if the
but carries no preconceived notions of her opponents’             world were a mixture of the above types. They used their
states of mind might choose randomly, or they might use           model to estimate the posterior likelihood of each player’s
a simple rule. In fact, an informal test of these hypotheses      type, and found very strong support that most players
gives support to the concept of a heuristic strategy. The         were acting consistently with the behavior of one of the
twelve games used by Stahl and Wilson (1995) were                 predefined types.
presented to ten subjects. The subjects were shown only              Two aspects of their study led to this model. For one,
the payoffs to themselves. Subjects were asked to make            their model was rather arbitrary and it is difficult to
no assumptions about what the opponents would receive             imagine a generalization to more complex scenarios. The
as payoffs. Almost all of the subjects responded in a             model presented here adopts a graphical modeling
manner that was consistent with one of two heuristic              approach, making it more extensible by allowing the
strategies.                                                       addition of arbitrary variables and levels of reasoning.
   The first tendency was to choose the row in which the          Secondly, this model eliminates the concept of the Nash
summed payoff was greatest. We will call this heuristic           equilibrium from players’ models, and replaces it with
strategy the Maximum Sum (MS) heuristic. This strategy            heuristic types described above.
is rational if the opponent is assumed to choose at
random. A second tendency was to choose the row with              1
                                                                    If estimates of utility are noiseless, BR(U) is equivalent to MS,
the highest minimum payoff. I will call this strategy the         since it prescribes the choice of row with highest average utility.
                                                             2314

             The Structure of the Model                           variety of possible models of their opponents, with
                                                                  uncertainty about which one their opponent will actually
This model assumes, like Stahl and Wilson (1995), that
                                                                  employ (Gal and Pfeffer, 2003). The models employed by
the population is composed of players who approach each
                                                                  this study borrow concepts from the NIDs framework, but
individual game with a consistent initial strategy. Each
                                                                  the full arsenal provided by this modeling language is not
player type is modeled individually using a graphical
                                                                  necessary to build the basic models that we will use, and
model from which the probability of any particular
                                                                  some additions are necessary.
strategy can be derived. These models are the components
                                                                     NIDs are rooted, acyclic directed graphs in which the
of a mixture model which is used to obtain estimates of
                                                                  nodes (called blocks to avoid confusion with nodes
the probability of the data given the full model.
                                                                  internal to blocks) are self-contained IDs and MAIDs.
Graphical Models and Extensions                                   Root blocks represent the “top-level” model. Blocks are
                                                                  assigned to individual agents. The decisions of agents
Bayesian networks are a class of graphical models in              may be modeled by child blocks. Edges from one block to
which the causal structure of the world is codified into          another block indicate that a decision node in the parent is
nodes, representing variables, and edges, representing            modeled by the child.
dependencies amongst variables. Nodes can have various               If a decision in a parent block is modeled by multiple
states, which are either known or unknown. For example,           child blocks, then a chance variable (labeled Mod[D],
a node might represent rain on the 25th. Before the 25th,         where D is the modeled decision node) is introduced to
the state of the node is unknown, but various other factors       the parent. Mod[D] is a parent node D, and it takes on
influence the probability of each state (e.g., the recent         values corresponding to each of the child blocks that
weather history). Given knowledge about the states of             model the decision. Its conditional probability table (CPT)
known variables, and the probabilistic dependencies               contains the probability allotted by the parent block to
amongst the nodes, the probability of an unknown                  each of the different child models. In other words, it
variable’s taking on some state can be determined.                represents the degree of belief that each of the child
Bayesian networks have been explored extensively in               blocks is being used by opponents. To solve a NID, one
computer science (Pearl, 1988), and recently applied to           simply works from the leaf blocks to the root, solving for
modeling human cognition. Influence diagrams (IDs)                each decision variable the optimal response. Leaves are
extend Bayesian Networks with decision and utility nodes          MAIDs or simple IDs, which may be solved according to
(Howard and Matheson, 1984). They allow the modeler to            known methods. The decision rules thus computed are
calculate the best possible choice for an agent given             available to the parent nodes, and are incorporated into
specific knowledge about the world, the choices available         parents as follows: each decision node in a parent that is
to the agent, and the payoffs that depend upon the choices        modeled by a child requires the addition of a chance node
of the agent and the state of the world. Decision nodes in        to the parent. For each edge leaving a block, a chance
IDs represent choices of agents (represented as rectangles        node is added to the parent. This node has a conditional
in diagrams), and simply denote the (discrete) choices            probability distribution over its component choices that is
available to the agent. Utility nodes represent the value to      determined by the solution to the child. The original
agents of states of the world. Decision and utility nodes         decision node becomes a chance node with each node that
possess many of the same properties of chance nodes in a          has been added as its parents. The new node takes on
Bayesian network. Many details are omitted here due to            values of its parent nodes according to the probabilities
limited space.                                                    allotted to the CPT of Mod[D]. Once the tree has been
   Extensions of IDs called multiple agent influence              solved up to the root node, the root node becomes a
diagrams (MAIDs) have been used recently to simplify              MAID in the same fashion. Solving the root gives a
the process of calculating the Nash equilibrium solution          Bayesian network that is open for interesting queries. This
for players in competitive games (Koller and Milch,               description is dense, high-level and misses many nuances.
2001). MAIDs allow modeling of multiple agents, each              For a full description of NIDs, see Gal and Pfeffer (2003).
with their own decision and utility nodes. Solving a                 Traditionally, IDs have been used to model situations
MAID involves calculating the optimal decisions of                for the purposes of making a decision. However, since
players with respect to their knowledge of the world, but         human decision making is inherently noisy, in order to
MAIDs assume rational agents with infinitely recursive            model human behavior we will have to replace the
models of opponents. Given that the goal of this work is          traditional decision nodes with a noisy version. To
to eliminate the need for the Nash equlibrium concept in          accomplish this, each decision node is converted to a
explaining human behavior, We will not spend any more             chance variable where each choice, or state, is chosen
time discussing the specifics of MAIDs.                           with some probability that is determined on the basis of a
   An additional extension to MAIDs and IDs, known as             noisy estimate of expected utility. If the noise has the
networks of influence diagrams (NIDs), can be used to             properties that it is additive, independent and identically
model agents who have any particular model of their               distributed according to a Weibull distribution, then the
opponents, agents who make decisions based on
extraneous variables, and agents who conceive of a
                                                             2315

                     D      P(D)
                                                                   D      U(D)                                                     D[A]              D[B(MS)]
         D[A]        T       1/3                 D[A]                                               A[BR(MS)]
                                                                   T    (sum the
                    M        1/3
                                                                   M       row
                     B       1/3
                                                                   B    payoffs)                              After solving children...
       a. "U" Player w/ CPT                                                                                                                  U[MS]
                                                U[MS]                                               A[BR(MS)]
                                                              b. "MS" player and utility table
                                                                                                                     c. BR)MS) player (left: NUDD; Right: UDD)
                                                                 D[B(GM)]         D[B(MS)]
     A[Mix]
                                                                                                   D[B(U)]
                                    After solving children...
                                                                   D[B]                        Mod[D[B]]       Squares respresent decision nodes, diamonds
                                                                                                               utility nodes, and ovals chance nodes.
      B[GM]              B[U]            B[MS]
                                                                                                               Notation: A is the modeled player, B is the opponent.
                                                                     D[A]                   U[A]
  d. BR(Mix) Player (Left: NUDD; Right: UDD)
                                        Figure 1: Four models of players in one-shot, three-choice matrix games
probability of the decision takes the                           convenient                 opponent’s prior over responses is the same as the Nash
conditional logit form,                                                                    equilibrium solution to the game). Revisiting this model,
                                  exp(γ * EU j )                                           we will define 6 types of our own, without appeal to the
                    P j (γ ) ≡                                            (1)              Nash equilibrium concept. Descriptions of these 6 types
                                 ∑ k
                                     exp(γ * EU k )                                        follow, along with the parameters that were allowed to
                                                                                           vary for each model. For modeling simplicity, the values
where Pj is the probability of making choice j, EUj is the
                                                                                           of these parameters were assumed to be constant for every
expected utility of the choice, and γ is a noise parameter
                                                                                           player within a class.
(this choice was also inspired by Stahl and Wilson, 1995).                                  1. The level-0 type of Stahl and Wilson (1995) becomes
Expected utility is calculated using basic algorithms for                                      the “Uniform” player (U). A model of this player is
IDs, on the basis of the values in utility and chance nodes.                                   pictured in figure 1a. Her choices are simply
IDs with the addition of this new type of decision node                                        represented as a chance node with equal probabilities
will be referred to as Uncertain Decision Diagrams                                             for each of the three decisions. This model has no free
(UDDs).                                                                                        parameters.
   Another modification to NIDs for modeling humans is                                      2. The level-1 type (best response to level-0) becomes
the elimination of decision nodes for decisions that are                                       the “Maximum Sum” heuristic player (MS). This
modeled by child blocks. The reason for this is that                                           player’s model is shown in figure 1b. The model is an
leaving these decision nodes in for the opponent would                                         UDD with a decision node and a utility node, where
require the use of MAIDs. Algorithms for solving MAIDs                                         the utilities have been determined by summing the
introduce the Nash equilibrium concept, which we                                               payoffs for each row. The noise parameter γ1 was
attempt to eliminate as an explanation for behavior in this                                    allowed to vary.
game. Graphical models with the above modifications                                         3. The level-2 type (best response to level-1), becomes
will be referred to as NUDDs (Networks of UDDs).                                               the “Best response to maximum sum heuristic” player,
                                                                                               BR(MS). The model for this player type is shown in
A model of behavior in one-shot matrix games                                                   figure 1c (in NUDD form and solved form). This is a
Using NUDDs, behavior in any simultaneous matrix                                               simple NUDD in which the child block is the UDD
game can be modeled given assumptions about the                                                described in 1. The noise parameter γ2 was varied.
contents of utility nodes and the form of each player’s                                     4. A second type of heuristic player, who chooses on
model. Following Stahl and Wilson (1995), this model                                           the basis of the row with the maximum minimum
assumes that players fall into several categories. The                                         payoff. This player is referred to as the “Greatest
primary goal was to replicate Stahl and Wilson (1995),                                         Minimum” heuristic player, or GM. Her model is just
but to do so without appealing to the Nash Equilibrium in                                      like the MS player, but the values of the utility node
opponent models. Their notation is reproduced where                                            correspond to the least minimum payoff for each of
possible, and many of the same procedures are followed                                         the choices. Noise parameter, γ3, was allowed to vary.
to maximize the comparability of this model to theirs.                                      5. The fifth type is the “Best Response to Greatest
 Of the five player types posited by Stahl and Wilson, two                                     Minimum Heuristic” player, or BR(GM). This model
include the concept of Nash equilibrium (i.e., some                                            is similar to BR(MS) with the child block replaced
component of these two models specifies that the
                                                                                 2316

      with the GM player’s UDD. Decisional precision γ4                deviate [0,1] and choose a class based on this value and
      was allowed to vary.                                             the α̂ l ’s (i.e., choose class l with probability α̂ l ). Then,
 6. The sixth type is the “Mixture of strategies” player, or           obtain the probability of each decision given the
      BR(Mix). This is a player who believes that others are           corresponding model and its parameter estimates. Finally,
      a mixture of the above strategies. We include a player           choose a decision by drawing a second uniform random
      who chooses the best response to a mixture of                    deviate and comparing it to this value. Once the samples
      strategies 1, 2, and 4. In other words, she models her           s* were generated, we determined maximum-likelihood
      opponents as playing some mixture of the uniform and             parameters β ' * for each s* using the same technique as
      heuristic strategies. This player has 3 parameters that          before, and determined 95% confidence intervals for each
      are allowed to vary: γ5 (noise), m1 (the proportion of           β. The maximum-likelihood estimates and confidence
      her opponents that she believes are uniform players),            intervals are given in Table 2. On first glance, we see that
      and m2 (the proportion believed to be MS players).               most parameters take on reasonable values. Approximate
      This player believes that opponents are GM players               proportions of each player type were 14% (U), 17% (MS),
      with probability m3 =1-m1-m2. This player’s model is             2% (BR(MS)), 35% (GM), 17% (BR(GM)), and 16%
      shown in figure 1c. The CPT for Mod[D] is                        (BR(Mix)). Their confidence intervals do not include 0,
      determined by the mixing parameters described above.             suggesting that sufficient evidence exists to include all of
   Each of the models above produces predictions of the                these types in this model, although two of the intervals do
probability of each choice in each game. Choice                        come close. The only immediate cause of concern is the
probabilities for each strategy j ∈ {1, 2, 3} within each              confidence interval of γ2, which includes 0. When γ2 is 0,
game i ∈ {1, 2, ..., 12} for each model l (l=1, 2, 3, 4, 5, or         noise is so great that the strategy becomes the same as U.
6) were determined by equation 1, where expected utility               The likely reason for this is that only one player (as will
of each response is calculated using a common algorithm                be shown) is employing this strategy, and thus in many
for solving influence diagrams based on the structure of               fits, γ2 was allowed to vary greatly with little consequence
the graphical model. Subject h’s strategy in game i will be            to the likelihood values. The BR(Mix) strategist seems to
referred to as s ( h, i ) ∈ {1, 2, 3} . The probability of choice      be employing a model with 40% GM players, 20% MS
i given model type l and model parameters βl is denoted                players, and 40% U players. The maximum log-likelihood
Pij(βl). Following Stahl and Wilson’s (1995) conventions,              was -448.75, which is slightly less than the value of -
the probability of subject h’s choices in game i                       442.73 obtained by Stahl and Wilson (1995). However,
conditioned on that player belonging to class l is Pis(h,i)(           we believe that it still compares favorably, especially
βl) and the joint probability of all of participant h’s                given the following considerations: (1) although this
choices conditional on being a class l player is                       model’s parameters have 12 degrees of freedom relative
                    P h (β ) =
                      l     l   ∏ i
                                        Pis ( h ,i ) (β )
                                                       l
                                                              (2)      to their 11 degrees of freedom, our model is somewhat
                                                                       more restricted due to the replacement of the Nash
                                                                       equilibrium prior. The Nash equilibrium prior is more
The full mixture model includes 6 parameters αl defining               flexible than either of our heuristic priors, predicting in
the proportion of subjects in the population who employ
                                                                       some cases equal probabilities for all three choices. (2)
model l (the sum of all αl is 1). The likelihood of                    Goodness-of-fit is lower for our (conceptually simpler)
participant h making her particular choices is given by                model. This statistic was obtained using the following
                                      6                       (3)
                  L( s h | β ) ≡ ∑ α l Pl h ( β l )
                                                                       equation,
                                                                                                         (nij − Nπ ij ) 2
                                                                                         λ = ∑∑
                                    l =1
                                                                                                                                    (5)
Log-likelihood of the entire sample is
                                                                                                              Nπ ij
                         ∑ log[L(s
                                                                                                i   j
                   3≡
                                           h
                                                | β )]        (4)
                                                                       where nij is the number of people who chose j in game i,
                          h
                                                                       N is the number of subjects, and πij is the proportion of
                                                                       such choices predicted by our model. The πij are
                    A Test of the Model                                calculated as follows,
   Parameter estimates β ' were determined by                                                          6
maximizing (4) for the data collected by Stahl and Wilson
(1995). They tested 48 subjects on 12 games (2 of which
                                                                                             π ij = ∑ αˆ P (β )
                                                                                                     l =1
                                                                                                            l ij l                  (6)
are shown in Table 1). Estimates of the maximum-                       We obtained λ=49.48 (distributed chi-square with df=24)
likelihood parameters were obtained using the constrained              for the full 12 games and 48 subjects, which exceeds
line-search procedure provided with the Matlab                         acceptable values (p<.01). The null hypothesis that this
Optimization Toolbox and several randomly chosen
                                                                       model underlies the production of the data must be
starting points. Imitating the procedures of Stahl and
                                                                       rejected on the basis of this statistic. However, this
Wilson (1995), we constructed 95% confidence intervals
using a bootstrap technique. From the parameter estimates              difficulty was also encountered by Stahl and Wilson
 β ' , M=400 sample decisions s* (of the same sample size,             (1995), who obtained an even higher value, λ=57.57.
48 subjects and 12 games) were generated using the                     They point out that games 10 and 11 produced
following technique. First, draw a uniform random                      particularly troublesome results for their model, and the
                                                                       same applies here. Excluding these games from analysis, I
                                                                  2317

obtained λ=25.79 (df=20), compared with their λ=26.09.                                   Conclusions
The model cannot be rejected (at α=.05) as an explanation         It is important to understand how real agents form their
of this data on the basis of this statistic. A direct             initial models, not only to predict agent behavior in novel
comparison of these models is not possible, since they            situations, but also to predict the course of learning. This
differ structurally. However, the above comparisons are           study shows that a successful model need only assume
not unfavorable to this model.                                    simple heuristics and low level opponent modeling to
                                                                  predict behavior. This model shows promise as an
 Table 2: Results of model fit to data from S. & W. (1995)        explanation for human behavior in simple games played
                                                                  without repetition. The model fit comparably to the model
   Parameter         Estimate 95% Confidence Interval             of Stahl and Wilson (1995), and most importantly it
       γ1[MS]         0.2718       0.1815        0.4583           eliminated the Nash equilibrium concept from players’
    γ2 [BR(MS)]       0.5549          0          3.9587           models. The heuristics proposed in this article require
      γ3 [GM]         0.0710       0.0504        0.0917           only very simple cognitive abilities.
     γ4[BR(GM)]       0.2903       0.1678        0.4174              A new type of node was introduced to Influence
     γ5[BR(Mix)]      0.5525       0.3630        1.0630           Diagrams to make them suitable for modeling human
µ2 [% MS in BR(Mix)]  0.1989       0.0992        0.2619           decision making. UDDs should be extended to model
 µ3 [% U in BR(Mix)]  0.4016       0.3077        0.5517           sequential decisions. Any domain that involves decision-
      α0 [U]          0.1691       0.0478        0.2918           making that employs internal models of other agents
     α1 [MS]          0.0208       0.0003        0.1490           might benefit from the application of such models. In
                                                                  future work, the methods here will be extended to
  α2 [BR(MS)]         0.3450       0.2010        0.5552
                                                                  determine which models are most appropriate to include
     α3 [GM]          0.1658       0.0992        0.2619
                                                                  in a full mixture model. These models should be extended
  α4 [BR(GM)]         0.1591       0.3077        0.5517           to model different types of games with more choices,
         3               -448.75 (compared to -442.73)            more agents, and sequential decisions.
         λ           49.48/25.79 (compared to 57.57/26.09)
                                                                                     Acknowledgments
   Posterior estimates of player types were obtained using        I thank Josh Tenenbaum, Kobi Gal, Yuhong Jiang, and
a bootstrap method described by Stahl and Wilson (1995).          Christian Luhmann for useful discussions. This work was
Only a sketch of the results is reported here. Results show       partially supported by an ONR award to Yuhong Jiang.
that subject classifications were not as well-defined as in
the Stahl and Wilson (1995) model. 31 out of 48 were
classified with a probability greater than 90%, compared                                  References
with 38 in their model. However, many fewer bootstrap             Camerer, C.F. (2003). Behavioral Game Theory:
parameter estimates were obtained, and each of these was             Experiments in Strategic Interaction, Princeton:
from a small number of attempts to search the parameter              Princeton University Press.
space. We also did not constrain parameter values as              Gal, K. and Pfeffer, A. (2003). A Language for Modeling
much as my predecessors. Even so, it is clear that the new           Agents' Decision Making Processes in Games. Second
heuristic (GM) and the model that responds to GM,                    International Joint Conference on Autonomous Agents
BR(GM), are most appropriate for 18 and 10 players,                  and Multi-Agent Systems, Melbourne Australia.
respectively, and most of these with extremely high               Hedden, T. and Zhang, J. (2002). What do you think I
probability. At the very least, there is evidence for the            think you think? Theory of mind and strategic
employ of these strategies in lieu of NN. MS picks up 8              reasoning in matrix games. Cognition, 85: 1-36.
players (the same as their roughly equivalent BR(U).              Howard, R.A., and Matheson, J.H. (1984). Influence
BR(MS), which in our model finds very little support, is             Diagrams. In Readings on the Principles and
still only likely for one subject. Given that one player’s           Applications of Decision Analysis, 721-762.
decisions match the noiseless BR(MS) predictions                  Koller, D. and Milch, B. (2003), Multi-Agent Influence
exactly, it is probable that this player used that strategy,         Diagrams for Representing and Solving Games, Games
but there is little support for that strategy, otherwise.            and Economic Behavior, 45: 181-221.
Br(Mix) is most probable for only 4 players. The uniform          Nash, J.F. (1950). Equilibrium points in n-person games.
strategy is the most likely candidate for only 7 players.            PNAS, 36:48-49.
The GM strategy is highly successful, with extremely              Pearl, J. (1988). Probabilistic Reasoning in Intelligent
high probability of being the model for many players                 Systems, San Francisco: Morgan Kaufmann Publishers.
formerly classified as level-0 (U) and NN players, as well        Stahl, D.O., and Wilson, P.W. (1995). On Players’
as several mixture players. BR(GM) is also successful in             Models of Other Players: Theory and Experimental
explaining the activities of players formerly thought to be          Evidence. Games and Economic Behavior, 10, 218-254.
playing a best response to a mix of NN, U, and BR(U)
strategies.
                                                             2318

