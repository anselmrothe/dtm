UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An Empirical Evaluation of Models of Text Document Similarity
Permalink
https://escholarship.org/uc/item/48g155nq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Lee, Michael D.
Pincombe, Brandon
Welsh, Matthew
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                       University of California

    An Empirical Evaluation of Models of Text Document Similarity
                                Michael D. Lee (michael.lee@adelaide.edu.au)
                                    Department of Psychology, University of Adelaide
                                          South Australia, 5005, AUSTRALIA
                     Brandon Pincombe (brandon.pincombe@dsto.defence.gov.au)
       Intelligence Surveillance and Reconnaissance Division, Defence Science and Technology Organisation
                                     PO Box 1500, Edinburgh SA 5111 AUSTRALIA
                            Matthew Welsh (matthew.welsh@adelaide.edu.au)
                         Australian School of Petroleum Engineering, University of Adelaide
                                          South Australia, 5005, AUSTRALIA
                         Abstract                              achieved some level of practical success, they have gen-
                                                               erally not been assessed in terms of their ability to
   Modeling the semantic similarity between text docu-         model human judgments of text document similarity.
   ments presents a significant theoretical challenge for      The most likely reason for this failure is that no suit-
   cognitive science, with ready-made applications in in-
   formation handling and decision support systems deal-       able empirical data exist, and considerable effort is in-
   ing with text. While a number of candidate models           volved in collecting pairwise ratings of text document
   exist, they have generally not been assessed in terms       similarity for even a moderate number of documents.
   of their ability to emulate human judgments of simi-        This paper reports the collection of data that give ten
   larity. To address this problem, we conducted an ex-        independent ratings of the similarity of every pair of 50
   periment that collected repeated similarity measures
   for each pair of documents in a small corpus of short       short text documents, and so represents an attempt to
   news documents. An analysis of human performance            establish a ‘psychological ground truth’ for evaluating
   showed inter-rater correlations of about 0.6. We then       models. Using the new data, we report a first eval-
   considered the ability of existing models—using word-       uation of the ability of word-based, n-gram and LSA
   based, n-gram and Latent Semantic Analysis (LSA)
   approaches—to model these human judgments. The              approaches to model human judgments.
   best performed LSA model produced correlations of
   about 0.6, consistent with human performance, while                              Experiment
   the best performed word-based and n-gram models
   achieved correlations closer to 0.5. Many of the re-
   maining models showed almost no correlation with hu-        Materials
   man performance. Based on our results, we provide
   some discussion of the key strengths and weaknesses         The text corpus evaluated by human judges contained
   of the models we examined.                                  50 documents selected from the Australian Broadcast-
                                                               ing Corporation’s news mail service, which provides
                                                               text e-mails of headline stories. The documents varied
                      Introduction                             in length from 51 to 126 words, and covered a number
Modeling the semantic similarity between text docu-            of broad topics. A further 314 documents from the
ments is an interesting problem for cognitive science,         same were collected to act as a larger ‘backgrounding’
for both theoretical and practical reasons. Theoret-           corpus for LSA.
ically, it involves the study of a basic cognitive pro-           Both document sets were assessed against a stan-
cess with richly structured natural stimuli. Practically,      dard corpus of five English texts using four models of
search engines, text corpus visualizations, and a vari-        language. These were the log-normal, generalized in-
ety of other applications for filtering, sorting, retriev-     verse Gauss-Poisson (with γ = −0.5), Yule-Simon and
ing, and generally handling text rely fundamentally on         Zipfian models (Baayen, 2001). Both document sets
similarity measures. For this reason, the ability to as-       were within the normal range of English text for word
sess semantic similarity in an accurate, automated, and        frequency spectrum and vocabulary growth and were
scalable way is a key determinant of the effectiveness of      therefore regarded as representative of normal English
most information handling and decision support soft-           texts.
ware that deals with text.
   A variety of different approaches have been devel-          Subjects
oped for modeling text document similarity. These in-
clude simple word-based, keyword-based and n-gram              The subjects were 83 University of Adelaide students
measures (e.g., Salton, 1989; Damashek, 1995), and             (29 males and 54 females), with a mean age of 19.7
more complicated approaches such as Latent Seman-              years. They were each paid with a ten (Australian)
tic Analysis (LSA: Deerwester et al., 1990; Landauer           dollar gift voucher for every 100 document pair ratings
and Dumais, 1997). While all of these approaches have          made.
                                                           1254

Procedure                                                                       0.5
Subjects were asked to read and judge the similarity
of documents presented in pairs displayed side by side.
The full text of each document was always displayed.                            0.4
For each pair, a subject indicated how similar they
felt the documents were on a five-point scale (with
                                                                    Frequency
                                                                                0.3
one indicating “highly unrelated” and five indicating
“highly related”). Once a judgement had been made,
another pair of documents was presented and the pro-                            0.2
cess repeated. Each possible pair of documents (ex-
cluding self-comparisons) was presented between eight
and twelve times1 . The pairings were presented in a                            0.1
random order, and which documents were shown on
the left and right was also randomly determined.                                 0
                                                                                      −5   −4   −3   −2      −1    0     1    2   3   4   5
                                                                                                          Similarity Difference
Basic Results
The distribution of ratings over all trials revealed a
heavy skew towards low similarity values, with fre-             Figure 1: Distribution of differences between individ-
quencies of about 0.64, 0.18, 0.10, 0.06 and 0.02 for           ual subjects ratings, and the overall mean for each doc-
the similarity responses ‘one’, ‘two’, ‘three’, ‘four’ and      ument pair.
‘five’ respectively.
   To test for individual differences in similarity rat-
ings, the difference between every rating made by a
                                                                the complete set of words, and using that subset of
subject and the overall mean for that document pair
                                                                the words not included in a standard set of common
was calculated. The distribution of these difference
                                                                words (a stoplist) were both generated. In addition,
scores is shown in Figure 1. The mean absolute dif-
                                                                n-gram representations (Damashek, 1995), based on
ference is about 0.46 on the five-point scale and about
                                                                sequences of n successive characters occuring in the
90% of the differences are less than one. We also pro-
                                                                text, were generated for n = 3, 4, . . ., 10. Formally,
duced a measure of ‘inter-rater’ correlation, by choos-
                                                                each approach represents the corpus as a u × v matrix
ing one rating for each document pair at random, and
                                                                of counts X = [xik] where xik counts the number of
measuring its correlation with the average of the re-
                                                                times the i-th word or n-gram occurs in the k-th doc-
maining human judgments. The average of 1,000 such
                                                                ument. The value u is the number of words, number
correlations was 0.605.
                                                                of words not in the stop list, or number of n-grams in
   To test whether the left-right positioning of docu-
                                                                the corpus, and v is the number of documents.
ments affected similarity judgment, the difference be-
tween the average similarity for both positionings was          Binary Similarity Models
calculated. The average difference was 0.37 on the five-
point scale, and more than 95% of all the pairs were            Measures In cognitive science, considerable atten-
within one point on that scale.                                 tion has been given to the problem of modeling hu-
   These results suggest that similarity judgments do           man similarity judgments for featural stimuli, where
not vary significantly across subjects or because of left-      only the presence or absence of features is used to rep-
right positioning, and so similarity values for all pre-        resent objects (e.g., Navarro and Lee, ress; Tversky,
sentations of each document pair were averaged. The             1977; Tenenbaum and Griffiths, 2001). In the current
resultant five-point similarity scores were then normal-        context, this corresponds to a representation that does
ized to lie on a 0-1 scale for ease of comparison with          not count the number of times words occur in docu-
the various models of similarity.                               ments, but simply denotes whether they occur at all.
                                                                Defining tik = 1 if xik > 0 and tik = 0 if xik = 0
   Evaluation of Automated Measures                             allows different similarity models for binary represen-
                                                                tations to be defined in terms of four counts.PFor the
Document Representation                                         i-th and j-th documents, the count aij =          k tik tjk
After removing all punctuation and capitalization from          is the number of words or n-grams in the corpus rep-
the text, words were defined as unique strings sep-             resentation that
                                                                              P are common to both P       documents, the
arated by spaces. The corpus representations using              counts bij = k tik (1 − tjk ) and cij = k (1 − tik ) tjk
   1                                                            are the distinctive words or n-grams that one doc-
     The intention was to present each pair exactly ten
times, but an error in running the program resulted in          ument P has but the other does not, and the count
about 10% of the pairings being presented eight, nine,          dij =     k (1 − tik ) (1 − tjk ) is the number contained
eleven or twelve times                                          within neither document.
                                                             1255

   Previous similarity modeling suggests three theoret-                         0.7
ically important alternatives based on these counts.
                                                                                0.6
The most widely used (e.g., Lee and Navarro, 2002;
Shepard and Arabie, 1979) is the Common Features
                                                                                0.5
Model, which is a special case of Tversky’s (1977)
Contrast Model, and assumes simply that similarity                              0.4
                                                                 Correlation
is measured by the proportion of common features, so
                                                                                                                                        Ratio
that:                                                                           0.3                                                     Common
                               aij
              scom
               ij  =                        .                                                                                           Distinctive
                      aij + bij + cij + dij                                     0.2
An alternative is Tversky’s (1977) Ratio Model:
                                                                                0.1
                               aij
                srat
                 ij    =                 ,                                       0
                         aij + bij + cij
which measures similarity as the ratio of common to                            −0.1
                                                                                       CW     SW     N3    N4     N5   N6   N7    N8   N9   N10
common and distinctive features. Finally, the Distinc-                                                    Binary Representation
tive Features special case of the Contrast Model, which
is equivalent to the similarity model used in discrete       Figure 2: Correlations between the human similarity
multidimensional scaling (e.g., Rohde, 2002), assumes        measures and all binary representations using three
that two stimuli become more dissimilar to the extent        similarity models. CW=complete word, SW=stopped
that one stimulus has a feature that the other does
                                                             word, N3=3-gram, and so on. The dashed line shows
not, so that:
                                                             the inter-rater correlation.
                             aij + dij
             sdis
              ij =                           .
                       aij + bij + cij + dij
                                                             considered by Rorvig (1999). Using his terminology,
   Beyond these psychologically motivated measures,          these are the Correlation model:
Cox and Cox (1994, p. 11) list another nine similarity                                P
                                                                                         k xikP
                                                                                              xjk
measures based on the a, b, c, and d counts. We also                        scor
                                                                             ij  = P                 ,
                                                                                     y cik +   k xjk
evaluated these measures, but found that none outper-
formed the best of the three psychologically motivated       the Jaccard model:
measures.                                                                                              P
                                                                                                         x x
                                                                                      sjac
                                                                                       ij    = P       Pk ik jkP          ,
Results Figure 2 shows the correlations between the                                              x
                                                                                                k ik +   x
                                                                                                        k jk −  k xik xjk
human similarity measures, and those predicted by the        the Cosine model:
Ratio, Common Features and Distinctive Features sim-                                                            P
ilarity models. These correlations are shown for com-                                                                xik xjk
                                                                                              scos   =           k
                                                                                                                              ,
plete binary and stopped binary word-based represen-                                           ij
                                                                                                         P         2
                                                                                                                     P 2  12
tations, and binary 3-gram through to 10-gram repre-                                                             x
                                                                                                                k ik      x
                                                                                                                        k jk
sentations.
   Figure 2 shows at least four clear results. First,        and the Overlap model:
the Ratio Model outperforms the Common Features                                                            P
                                                                                                              x xjk
Model for most representations, and both are signif-                                         sove
                                                                                              ij =        P k ik P      .
                                                                                                                2      2
icantly better than the Distinctive Features Model.                                                   min     x
                                                                                                            k ik  ,  x
                                                                                                                    k jk
Secondly, for the Ratio and Common Features Models,
the stopped representation leads to better performance       Results Figure 3 shows the correlations between the
than using the complete word representation. Thirdly,        human similarity measures, and those predicted by the
the Ratio and Common Features Models achieve their           Jaccard, Cosine, Correlation and Overlap similarity
best correlation using 7-, 8-, or 9-grams, with worse        models. Once again, these correlations are shown for
performance for smaller and larger lengths. In the best      complete and stopped word-based representations, and
case, the models have a correlation of about 0.5 with        3-gram through to 10-gram representations. Figure 3
human judgments.                                             shows that the differences between the four similarity
                                                             models are very small, but that there are important
Count Similarity Models                                      differences in the performance supported by the un-
Measures For the corpus representations using                derlying document representations. Stopped represen-
counts, we tested the four symmetric similarity models       tation leads to better performance than the complete
                                                          1256

               0.7                                                               smaller additional emphasis to larger frequencies, while
                                                                                 the third measure is sensitive only to whether the word
               0.6
                                                                                 is in the document. The first global weighting function
                                                                                 we considered normalized each word using the local
               0.5
                                                                                 weighting function, the second was an inverse docu-
               0.4
                                                                                 ment frequency measure, and the third global was an
Correlation
                                                                                 entropy measure. More details are provided by Pin-
               0.3                                                               combe (2004).
                                                                                   Local and global weighting functions are used to gen-
               0.2
                                                                                 erate a weighted corpus representation W = [wik]. In
                                                                                 LSA, this weighted representation is subjected to sin-
               0.1
                                                                Cosine
                                                                                 gular value decomposition. This involves choosing a
                0                                               Overlap          dimensionality d ≤ m for the subspace representation,
                                                                Correlation      and finding the n × d orthonormal matrix U, the d × d
                                                                Jaccard
              −0.1                                                               diagonal matrix D and the m × d orthonormal matrix
                     CW   SW   N3    N4   N5   N6   N7
                                    Count Representation
                                                           N8   N9   N10         V that minimize the squared difference kW−UDVTk.
                                                                                    The resulting n × d matrix N = [nik] is a least
Figure 3: Correlations between the human similar-                                squares best fit to W produced by zeroing all but the
ity measures and all count representations using four                            largest d coefficients of D. The document similarities
                                                                                 are arrived at using a similarity measure similar to the
similarity models. CW=complete word, SW=stopped
                                                                                 earlier Cosine model, the exact form of which is
word, N3=3-gram, and so on. The dashed line shows
the inter-rater correlation.                                                                                 P
                                                                                                               i nik nij
                                                                                               scos
                                                                                                kj    = P        P       1/2
                                                                                                                             .
                                                                                                        ( i nik i n2ik )
                                                                                                             2
word representation, as with the binary representation
analysis. n-grams with length six or above are better
performed than smaller lengths. None of the correla-                                For the original corpus, in both its complete and
tions reach the 0.5 level and, perhaps surprisingly, the                         stopped forms, and using all nine possible pairings of
count representations generally led to worse correla-                            local and global weighting functions, we considered di-
tions with human performance than the binary repre-                              mensionalities of 10, 20, 30, 40, and 50. For the ex-
sentations.                                                                      tended corpus, again in both complete and stopped
                                                                                 forms, and using all weighting combinations, we con-
LSA Similarity Models                                                            sidered dimensionalities of 10, 20, 30, 40, 50, 100, 150,
Measures LSA begins with a n × v matrix C = [cik]                                200, 250, and 300.
where n is the number of words, v is the number of doc-                          Results The results of these analyses are shown in
uments in the corpus, and cik is the frequency of the                            Figure 4. It is clear that altering the local weight-
i-th word in the k-th document. There are three con-                             ing function makes relatively little difference but that
ceptually different components to the way LSA uses                               changing the global weighting function does make a
this document representations to measure similarity.                             difference. Entropy global weighting is generally su-
These are the local weighting function, which mea-                               perior to normalized weighting, and both are better
sures the importance of a word within a document, the                            than the inverse document frequency function. For
global weighting function, which measures the impor-                             the 50 document corpus, performance is best when
tance of a word across the entire corpus of documents,                           there is no dimensionality reduction in the represen-
and the number of dimensions retained during the sin-                            tation (i.e., when all 50 factors are used thus reducing
gular value decomposition, which makes assumptions                               LSA to a weighted vector space model). Peak perfor-
about the complexity of the underlying semantic reg-                             mance for the extended 364 document corpus is bet-
ularities expressed by the corpus.                                               ter and is achieved when between 100 and 200 fac-
   The three local weighting functions we considered                             tors are used. Applying the stop word list leads to a
are based on the frequency of the i-th word in the k-th                          significant improvement when using the (poorly per-
document. The first local weighting function was just                            forming) inverse document frequency global weighting
this term frequency, the second was logarithmic in the                           function, and there is also a small improvement in most
frequency, and the third was binary, taking the value                            other cases. The best performed LSA models, corre-
one if the frequency was non-zero. Intuitively, the first                        late about 0.6 with human judgments, which is better
two local weights give increasing importance to more                             than the keyword and n-gram vector space methods,
frequent words, but the logarithmic gives progressively                          and at the base level of inter-rater correlation.
                                                                              1257

                                        0.7                                        0.7
                                              a                                          b                            bin−ent
                                        0.6                                        0.6
                                        0.5                                        0.5                                log−ent
                                        0.4                                        0.4                                tf−ent
                                        0.3                                        0.3                                bin−nml
                                        0.2                                        0.2                                log−nml
                                        0.1                                        0.1                                tf−nml
                                         0                                          0
                                                                                                                      bin−idf
                                       −0.1                                       −0.1
                         Correlation
                                                    10   20   30   40   50                   10   20   30   40   50   log−idf
                                                                                                                      tf−idf
                                        0.7                                        0.7
                                              c                                          d
                                        0.6                                        0.6
                                        0.5                                        0.5
                                        0.4                                        0.4
                                        0.3                                        0.3
                                        0.2                                        0.2
                                        0.1                                        0.1
                                         0                                          0
                                       −0.1                                       −0.1
                                                  10 20 30 40 50100 200 300              10 20 30 40 50100 200 300
                                                                             LSA Factors
Figure 4: Correlations between the human similarity measures and nine LSA similarity models, for each of four
situations corresponding to (a) the 50 document corpus; (b) the 50 document without stopwords; (c) the 364
document corpus; (b) the 364 document without stopwords. The nine similarity models consider every pairing of
the binary (‘bin’), logarithmic (‘log’) and term frequency (‘tf”) local weighting functions with the entropy (‘ent’),
normalized (‘nml’) and inverse document frequency (‘idf’) global weighting functions. The dashed lines shows
the inter-rater correlation.
                    Conclusion                                                               relationship between modeled and human values for
                                                                                             all documents pairs, using the common and distinctive
We have argued that the automated measurement of
                                                                                             similarity models, with 8-gram binary representations.
the similarity between text documents is fundamen-
                                                                                             The performance of the distinctive model is typical of
tally a psychological modeling problem. This means
                                                                                             those with near-zero correlations, showing no system-
that various existing methods, widely used in infor-
                                                                                             atic relationship between modeled and human values.
mation science applications, ought to be assessed (at
                                                                                             The deficiencies evident for the common model, how-
least in part) in terms of their ability to model human
                                                                                             ever, are more interesting. It is clear that when the
performance. This paper presents an assessment of
                                                                                             model judges two documents to be highly similar, it
keyword, n-gram and LSA approaches against human
                                                                                             is correct. Its weakness is that it fails to detect other
data for a small corpus of short news documents. We
                                                                                             high-similarity pairings, giving them relatively low val-
considered a variety of existing cognitive models, us-
                                                                                             ues. In information science terms, if the task is to
ing different representational assumptions—including
                                                                                             identify highly similar documents, the model has very
whether or not a stopword list was applied, whether
                                                                                             good precision, but poor recall. It seems that the best
word frequency was considered, what n-gram length
                                                                                             performed models we examined are able to detect only
was used, and how many LSA factors were used—and
                                                                                             a subset of the highly semantically similar document
a variety of different similarity modeling assumptions.
                                                                                             pairs.
   Using an extended corpus to retain about 100 fac-
tors, LSA under the entropy global weighting function                                           These findings suggest alternative models of text
produced correlations of about 0.6, at the base level of                                     document similarity. Alternatives could arise from new
inter-rater correlation.. The best performed keyword                                         representations of text documents, specifying new sim-
and n-gram models achieved correlations closer to                                            ilarity models, or both. The performance of the com-
about 0.5. Many of the methods we considered showed                                          mon features model in Figure 5 suggests that it works
almost no correlation with human performance.                                                well when the underlying representations of two doc-
   An examination of the relationship between mod-                                           uments share features. More sophisticated representa-
eled and human similarity values shows two clear reg-                                        tions might be able to identify the common features
ularities that highlight weaknesses in the models we                                         between the highly similar document pairs currently
examined. These regularities are well characterized by                                       being missed. Obvious candidates for improved repre-
the scatterplots shown in Figure 5, which show the                                           sentation include those used by the topics model (e.g.,
                                                                                    1258

             Distinctive                       Common               n-grams: Language-independent categorization of
    max                               max                           text. Science, 267:843–848.
                                                                  Deerwester, S. C., Dumais, S. T., Landauer, T. K.,
                                                                    Furnas, G. W., and Harshman, R. A. (1990).
 Human                             Human
                                                                    Indexing by latent semantic analysis.         Journal
                                                                    of the American Society of Information Science,
                                                                    41(6):391–407.
                                                                  Dennis, S. J. (2004). An unsupervised method for the
     min                               min                          extraction of propositional information from text.
       min                   max         min             max
              Modeled                          Modeled              Proceedings of the National Academy of Sciences,
                                                                    101:5206–5213.
Figure 5: The relationship between model and human                Griffiths, T. L. and Steyvers, M. (2004). Finding sci-
judgments of similarity for all document pairs, using               entific topics. Proceedings of the National Academy
                                                                    of Sciences, 101:5228–5235.
the distinctive features (left panel) and the common
features models (right panel), using the binary features          Landauer, T. K. and Dumais, S. T. (1997). A solution
                                                                    to Plato’s problem: The latent semantic analysis
representation based on 8-grams.
                                                                    theory of acquisition, induction, and representation
                                                                    of knowledge. Psychological Review, 104(2):211–240.
                                                                  Lee, M. D. and Navarro, D. J. (2002). Extending
Griffiths and Steyvers, 2004) and the SP model (e.g.,               the ALCOVE model of category learning to featural
Dennis, 2004).                                                      stimulus domains. Psychonomic Bulletin & Review,
   Alternatively, more complicated representations                  9(1):43–58.
might not be required if a more sophisticated similarity          Navarro, D. J. and Lee, M. D. (in press). Common and
model was used. We have in mind a similarity model                  distinctive features in stimulus similarity: A mod-
that judges documents in terms of their similarity rela-            ified version of the contrast model. Psychonomic
tionships to other documents in the corpus. Intuitively,            Bulletin & Review.
there may be short paths between highly-similar docu-
                                                                  Pincombe, B. M. (2004). Comparison of human and la-
ments as they are currently represented and measured,
                                                                    tent semantic analysis (LSA) judgments of pairwise
even if that similarity is not evident from examining
                                                                    document similarities for a news corpus. Defence
the two documents being assessed in isolation. Recent
                                                                    Science and Technology Organisation Research Re-
psychologically-motivated data-analysis methods that
                                                                    port DSTO–RR–0278.
focus on establishing global relationships using local
properties, such as ISOMAP (e.g., Tenenbaum et al.,               Rohde, D. L. T. (2002). Methods for binary multidi-
2000) provide a possibile starting point for examining              mensional scaling. Neural Computation, 14(5):1195–
this idea.                                                          1232.
   Of course, to what extent these sorts of theoretical           Rorvig, M. E. (1999). Images of similarity: A visual
improvements manifest themselves in applied benefits,               exploration of optimal similarity metrics and scal-
improving the performance of search engines, decision               ing properties of TREC topic-document sets. Jour-
support systems, or other text based systems, remains               nal of the American Society for Information Science,
an open question. We believe, however, they are av-                 50(8):639–651.
enues worth exploring.                                            Salton, G. (1989). Automatic Text Processing: The
                                                                    Transformation, Analysis, and Retrieval of Informa-
                 Acknowledgments                                    tion by Computer. Addison-Wesley, Boston, MA.
This research was supported by Australian Research                Shepard, R. N. and Arabie, P. (1979). Additive clus-
Council Grant DP0211406, and the Defence Science                    tering representations of similarities as combinations
and Technology Organisation. We thank Simon Den-                    of discrete overlapping properties. Psychological Re-
nis, Dan Navarro, Ben Grindlay and Lama Chan-                       view, 86(2):87–123.
drasena.                                                          Tenenbaum, J. B., de Silva, V., and Langford, J. C.
                                                                    (2000). A global geometric framework for nonlinear
                           References                               dimensionality reduction. Science, 290:2319–2323.
Baayen, R. H. (2001). Word Frequency Distributions.               Tenenbaum, J. B. and Griffiths, T. L. (2001). Gener-
  Kluwer, London.                                                   alization, similarity, and Bayesian inference. Behav-
                                                                    ioral and Brain Sciences, 24(4):629–640.
Cox, T. F. and Cox, M. A. A. (1994). Multidimensional
  Scaling. Chapman and Hall, London.                              Tversky, A. (1977). Features of similarity. Psycholog-
                                                                    ical Review, 84(4):327–352.
Damashek, M. (1995).        Gauging similarity with
                                                               1259

