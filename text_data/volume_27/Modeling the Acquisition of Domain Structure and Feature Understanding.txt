already have an appropriate basic-level term in their vo-        functionality is an important feature for artifacts but not
cabulary [14]. There is also a clear developmental trend         biological kinds [6] and that color is more important for
in the ability to use superordinate or subordinate cat-          nonliving natural kinds [11] and food [13].
egories, either in induction [8], classification [23], or as        Just as knowing about structure can help children
the possible target in a word-learning task [15]. In sum,        learn and classify new objects in a domain, learning
though the data are unclear about whether very young             which features are important can help them general-
children have taxonomic categories, there is strong evi-         ize that knowledge to new items as well. Recent work
dence that at least they have a difficult time using tax-        by Samuelson & Smith suggests that the acquisition of
onomic information until they are older.                         feature biases can facilitate the learning of new object
   At that point, children can apply their knowledge             names [20]. Their explanation is that children are able
about taxonomic structure to new learning situations             to use the words they learn to infer that categories are
such as word learning and object classification. 4-year-         organized by similarity in shape. When presented with
old children given multiple examples of a novel word are         a novel word-object label, they are therefore more apt
capable of generalizing its meaning based on its loca-           to generalize the word based on its shape rather than on
tion in a taxonomic structure [22]. Also, learning su-           other properties.
perordinate labels appears to enable children to improve            In sum, there is evidence that children learn domain-
their performance on classification tasks in taxonomic           specific knowledge of feature biases during the first few
domains [23].                                                    years of life. They are then capable of using this fea-
   Structural knowledge can also be helpful in prop-             ture knowledge to learn novel words and thus classify
erty induction, since explicit understanding of taxonomic        novel objects in that domain. Our model illustrates the
structure can guide the ability to correctly reason about        emergence of the shape bias in a domain where it applies
novel features [12]. For instance, knowing that whales           (animals) as well as its lack of emergence in a domain
are more closely related to elephants than they are to           where other features such as color may be equally or
fish in a taxonomic structure can help one realize that          more important (foods). Additionally, when objects co-
whales might be warm-blooded like elephants rather               vary coherently according to some features, our model
than cold-blooded like fish. Children readily make in-           is capable of recognizing that covariance and using it to
ductions about the internal features of novel objects in         correctly classify new objects.
taxonomic domains based on knowledge of domain struc-
ture, and older children make inferences at the superor-                        The Bayesian model
dinate level more often than younger children [8].
                                                                 There are two aspects to our model: learning domain
   In sum, there is evidence that children learn to repre-       structure and learning feature weights.
sent or use the correct underlying structure in taxonomic
                                                                    The structure-learning component, described more
domains over the first five years of life. They are capa-
                                                                 fully in Kemp, Perfors, & Tenenbaum [12], defines a
ble of using this structure knowledge to correctly classify
                                                                 structure as a graph over objects, such that objects with
novel words and objects as well as to correctly general-
                                                                 many common features are closer together in the graph.
ize about hidden properties of objects. Our model gives
                                                                 For instance, a one-dimensional chain is a good struc-
one account for how children’s developmental shift to-
                                                                 ture for the American political domain because objects
wards the robust use of structural information can arise,
                                                                 (politicians) on one extreme of the chain tend to share
both in a strongly taxonomic domain (animals) as well as
                                                                 many features with politicians at their end rather than
one with a less clear hierarchical structure (foods). The
                                                                 politicians on the other extreme. We assume that learn-
model also demonstrates how more accurate generaliza-
                                                                 ers come to a new domain equipped with the capacity to
tion of hidden features in older children may be a result
                                                                 represent a range of qualitatively distinct kinds of struc-
of their more accurate underlying structural knowledge
                                                                 tures that could describe that domain, including tax-
about that domain.
                                                                 onomies (trees), dimensions (chains), and clusters. (A
Learning about features Children often learn                     cluster is a grouping of objects such that all the ob-
domain-specific feature biases even before realizing what        jects within it are expected to share many features, but
the correct structure for that domain is. By the age             there is no higher-order relationship between or within
of two, they correctly generalize novel count nouns on           clusters). Though people can surely conceptualize more
the basis of whether the original referent is a solid or a       complex structure classes, we restrict ourselves to these
non-solid [21]. If the referent is a solid, children show        three here, as a representative set of simple hypotheses
a distinct shape bias: a tendency to generalize the new          that small children could reasonably learn about in early
word on the basis of shape rather than size, color, or tex-      development.
ture [10, 21]. When the original referent is a non-solid,           Our model assumes that learners are presented with
children have a “material bias” in which they generalize         data in the form of binary-valued object-feature matri-
the novel name to objects sharing the same material but          ces. We can use Bayesian model selection to evaluate
having a different shape [21]; however, this bias does not       which structure class was most likely to have generated
appear strongly until after 30 months [20].                      this data. More formally, if D is an object-feature ma-
   Though the shape bias emerges earliest and applies to         trix, the posterior probability of any structure class C
many domains, children are capable of learning different         is proportional to its likelihood under the data p(D|C)
biases for different domains. They eventually realize that       times its prior probability p(C). Since we assign equal
                                                            1721

prior probability to all classes, the best class is the one                           The Datasets
that makes the data most likely.                                 We used datasets in two domains, animals and foods. We
   Likelihood for trees and chains is calculated based on        chose these domains because they are of great interest to
the intuition that objects that are “close to” each other        very young children and contain words that are among
on a structure will be more likely to share features than        the first few learned [7]. Moreover, the domains may
objects further away. This is captured formally by as-           differ in terms of which structure best describes them
suming that features are generated over structures using         [18] as well as which features are highly weighted [13].
a symmetric mutation process, under which the proba-                Each dataset is a binary-valued object-feature matrix.
bility of a feature switching values between the beginning       The choice of features and objects was inspired by the
and end of any branch b is a function of the length of b         features and objects in the data collected by Cree &
and the mutation rate, λ. We assume that features are            McRae [5]. A subject blind to the hypothesis of the
conditionally independent given the structure, and can           experiment classified the features as shape, surface (col-
then compute the likelihood p(D|S, C), the probability           ors and textures), behavior (for animals), smell & taste
of the data given structure S and structure class C, for         (for foods), is-a features corresponding to superordinate
each feature vector taken individually. The likelihood of        words (e.g. “is a reptile”, “is a vegetable”), and internal
any specific structure can be calculated by multiplying          features corresponding to internal properties (e.g., “has
probabilities for each feature taken individually on that        lungs”, “has red blood”). In both domains, all is-a words
structure; the likelihood of a structure class by integrat-      were structurally appropriate for a hierarchy. None of
ing1 over the space of all structures, as below:                 the internal features applied to insects or cephalopods,
                         Z
                                                                 but all other animals had at least two.2
              p(D|C) = p(D|S, C)p(S|C)dS                 (1)        The animal dataset contained 60 animals with 112 fea-
                                                                 tures, and the foods dataset contained 56 foods with 64
   Intuitively, this means that a structure class C pro-         features. Animals consisted of mammals, reptiles, birds,
vides a good account of object-feature data D if the             amphibians, and insects; foods consisted primarily of
data are highly probable under a range of structures S           fruits and vegetables (49 objects), but included desserts
in class C, and if these structures themselves have high         and other staples (bread, rice, etc) as well (7 objects).
prior probability within C. For trees and chains, prior          Not all objects had the same number of features, but the
probability p(S|C) is spread uniformly over the space of         variance between objects was small and no objects had
all possible trees or chains. For clusters, we use a prior       fewer than eight (animal mean: 27 features, sd: 6.86;
over possible cluster partitions that is derived from the        food mean: 17.1 features, sd: 4.06).
Chinese Restaurant Process [3]. This prior admits any               One way to model development is to alter the nature
number of clusters but favors fewer clusters, while the          and number of features the model works with. Early
likelihood favors more clusters in order to fit the data         in development, children may have access to perceptual,
better. The likelihood p(D|S, C) is defined by a weighted        obvious features, but not to conceptual or hidden ones.
coin flipping process, with distinct weights for each clus-      A subject blind to the hypothesis of the experiment clas-
ter and for each feature in the data. The balance between        sified each of the features on a scale measuring its degree
priors and likelihoods instantiates a Bayesian version of        of perceptual obviousness (where “is red” is very obvi-
Occam’s razor that finds a cluster model with an ap-             ous, but “has Vitamin C” is very nonobvious). When
propriate number of clusters. This clustering model is           we wished to model differing numbers of perceptual fea-
related to Anderson’s rational model of categorization           tures, we presented the model input composed of the
[1], and a more mathematical treatment can be found in           most perceptually obvious features.3
[16].                                                               Another way to model development is to alter the
   For all structure classes, we can intuitively understand      number of objects the model works with. This was done
the “most important” features as the individual features         by ranking each object in the order of the age of the
with the highest likelihood. Feature likelihood captures         first production of the word corresponding to the object,
the intuition that the highly weighted features are those        according to the 50% norms found in Fenson et al. [7].4
that best fit a given structure. For instance, “warm             Adding objects in the order of word acquisition might
blooded”, an important feature, is tightly clumped on            be seen as a way to model word learning or as a reflec-
an animal taxonomy (only mammals and birds are warm              tion of the amount of exposure each child has had to the
blooded). The feature “is black”, on the other hand, is          different objects in the world. Either of these interpreta-
not important and does not fit well (animals of all types
                                                                     2
may be black, regardless of where they are in the tax-                 A copy of the dataset may be found at www.mit.edu/
                                                                 ∼perfors/cogsci05.html.
onomy). In our model these features would have lower                 3
weights because they have low likelihood given that par-               There were enough animal features to make two percep-
                                                                 tual datasets. One had the 48 most perceptually obvious
ticular taxonomy. This intuition applies equally well            features, the other had the 61 most obvious.
to all structure classes: for instance, an important fea-            4
                                                                       A few objects were included if children spoke a similar
ture for a given cluster would be one that obeys cluster         word early and that word did not correspond to an object in
boundaries and thus has a higher likelihood.                     the dataset: e.g. rat for mouse. Additionally, children learn
                                                                 the words bird and fish quite early: these were approximated
    1
      In practice, we approximate the integral using Markov      by including the most prototypical examples of each category
Chain Monte Carlo (MCMC) techniques                              in the dataset, robin for bird and trout for fish.
                                                            1722

                  Objects   # Feat   Percept.    Ltree   Lchain   Lclust
                    20        48       48        -460     -418     -470
                    20        67       48        -607     -530     -614
                    40        48       48        -859     -849     -903
        Animals
                    40        67       48       -1092     -967    -1098
                    40        61       61       -1108    -1076    -1166
                    60        61       61       -1510    -1522    -1639
                    60        80       61       -1842    -1929    -2013
                    60        80       61       -2106    -2157    -2255
                    60       112       61       -2854    -2994    -3051
                    20        37       37        -417     -405     -415
        Foods
                    20        44       37        -477     -443     -482
                    56        64       37       -2087    -1607    -1680
Table 1: Log likelihoods on each structure class as a function
of type of input. Higher likelihoods are indicated in bold.
tions is consistent with our results, in which we compare                         Figure 1: Partial consensus trees from two datasets, each
datasets composed of 20, 40, and 60 objects. Datasets                             with 60 objects and 61 features. Tree A is built from a dataset
with fewer objects tend to have a higher proportion of                            containing internal and is-a as well as perceptual features,
                                                                                  and is more structurally accurate; Tree B is built using only
mammals than later datasets do.                                                   perceptual features.
                                     Results
We now explore how our model accounts for the phe-                                   The food domain is an interesting contrast to animals.
nomena described in the introduction.                                             For all food datasets, no matter how many objects or
                                                                                  features the algorithm was working with, the chain class
Learning about structure                                                          fit the data better than either the tree or cluster model
                                                                                  class. This may be because our foods dataset was com-
Our model gives one account of how children’s develop-
                                                                                  prised primarily of fruits and vegetables. This is in line
mental shift towards the robust use of structural infor-
                                                                                  with a recent study that found that subcategories are
mation can arise, both in a strongly taxonomic domain
                                                                                  much less well-differentiated in the domain of fruits than
(animals) as well as one with a less clear hierarchical
                                                                                  in the animal domain [18]. Indeed, the best chains fol-
structure (foods). Table 1 shows the log likelihood val-
                                                                                  low a sensible path from green leafy vegetables on one
ues for each structure class considered by our model,
                                                                                  end, through melons, citruses, and berries, then finally
as a function of its input. Because log likelihoods are
                                                                                  going through legumes and roots before arriving at all
negative, higher likelihood model classes (highlighted in
                                                                                  the non-plant foods at the other end.
bold) have a smaller absolute value. Because they are
log probabilities, differences of the magnitude shown in                             One area in which the interdependence of features and
the table are substantial. Trends in both the foods and                           structure becomes most apparent is in comparing struc-
the animals domain can be identified.                                             tures made using datasets with different features. Is-a
   The trend in the animal domain demonstrates an                                 features like “is a mammal” and internal features like
interesting progression from simplicity to complexity.                            “has warm blood” are often learned by children around
When there are fewer objects and fewer features, the                              the same time they begin to realize that the animal do-
simpler chain structure class has a higher likelihood than                        main is organized taxonomically. Similarly, we find that
the more complicated tree structure class (though both                            the taxonomies found by the model appear more accu-
had a higher likelihood for than clusters). The change                            rate when made using datasets that incorporate these
from chain to tree is primarily driven by the increased                           features compared to datasets incorporating purely per-
number of objects in the dataset: all of the datasets with                        ceptual features. Figure 1 compares portions of two 60-
40 objects are best fit by a chain, while all of the datasets                     object trees found by our model, each made with 61 fea-
with 60 objects are best fit by a tree.                                           tures. Tree A contains 42 perceptual, nine is-a, and ten
   What are the developmental implications of this                                internal features. By contrast, Tree B contained no is-a
change in structure? Because a chain is one-dimensional,                          or internal features, just the 61 basic perceptual features.
it cannot represent superordinate structure. This par-                               Though both trees are adequate, Tree B has some
allels evidence suggesting that younger children do not                           structural flaws that are not apparent in Tree A. For
seem to use the superordinate level in tasks like induc-                          instance, Tree B incorrectly locates the aquatic mam-
tion, classification, or word learning. They do so only                           mals with the sea creatures and places the panther far
when they reach the age of 4 or 5 years, suggesting                               from the other felines. Tree A, which incorporates the
that before then they might not believe that a tree-                              information that aquatic mammals are mammals and
structure representation is appropriate. [8, 15, 23]. Why                         that panthers are felines, does not have these errors.
did our model find that chains were more appropriate                              This supports the intuition that structures incorporat-
than clusters? This is probably because clusters collapse                         ing “more important” features will appear to be more
all within-cluster information. Since reasonable animal                           accurate than structures that do not.
clusters are highly heterogeneous (e.g., mammals vary                                If structures and features are interdependent, improve-
widely in size, shape, and behavior), a cluster structure                         ment in one should lead to improvement in the other. In
would lose too much information compared to a chain.                              this case, does the more accurate structural knowledge
                                                                           1723

in Tree A lead to improved generalization of hidden or                              −0.3
                                                                                                    Animals                        Foods
                                                                                                                       −0.3
unknown features? We can test this by observing the                                                                                               Shape
performance of Tree A and Tree B on a property in-                                                                                                Surface
                                                                     Feature bias
duction task. We compare the inductive predictions us-                              −0.4                               −0.4                       Behavior
                                                                                                                                                  Smell/Taste
ing Tree A and Tree B to the human argument ratings
collected by Osherson et al [17]. Osherson used a ten-                              −0.5                               −0.5
animal domain consisting only of mammals: horse, cow,
chimp, gorilla, mouse, squirrel, dolphin, seal, elephant,                           −0.6                               −0.6
                                                                                                                               20         56
and rhino.5 The specific set contains 36 two-example ar-                                   20         40
                                                                                                Number of objects
                                                                                                                  60
                                                                                                                              Number of objects
guments, and the conclusion species is always “horse.”
The general set contains 45 three-example arguments,                 Figure 2: Relative (normalized) log likelihood of each type
and the conclusion category is “all mammals.” Unfamil-               of feature as the number of objects in the dataset increases.
iar (blank) predicates were used for all these arguments.            In the food domain, there is no bias towards one type of
                                                                     feature no matter how many objects were in the dataset: all
The tree-based Bayesian model rates the strength of gen-             likelihoods are similar. In the animal domain, a shape bias
eral arguments by computing the probability that all ten             emerges for larger datasets.
animals in the domain have the property.
   The predictions of the model using Tree B were no-
                                                                     significantly higher likelihoods than surface features for
ticeably more poorly correlated with ratings of human
                                                                     animals but not foods suggests that a shape bias will
argument strength than were the predictions using Tree
                                                                     not just emerge automatically given enough features.7
A (specific: r = 0.833 (Tree A), r = 0.739 (Tree B);
                                                                     Rather, shape features for animals simply covary more
general: r = 0.832 (Tree A), r = 0.566 (Tree B)). This
                                                                     coherently with the correct structure, and thus the model
poor performance is probably a result of Tree B’s less
                                                                     tends to give them a higher likelihood than features that
accurate structure. In a similar way, older children’s
                                                                     are less coherent.
more accurate taxonomic knowledge may underlie their
increasingly accurate generalization of hidden features.                Recent work by Samuelson and Smith [20] suggests
                                                                     that acquiring a shape bias can facilitate the learning of
Learning about features                                              more object names. Is this evident in our model? When
                                                                     objects covary coherently according to some features, is
We have shown that our model is capable of learning                  our model capable of recognizing that coherence and us-
appropriate structural information and applying that in-             ing it to correctly classify new objects?
formation to make inferences about features. But can
                                                                        We can answer this by adapting a test done by Rogers
it learn about features directly by giving more weight
                                                                     & McClelland [19]. They trained a connectionist net-
to more important features in a domain? As Figure 2
                                                                     work on 21 biological objects (birds, fish, mammals, and
shows, our model correctly realizes that shape features
                                                                     plants) and 57 features. They then presented it with four
should be given more weight in the animal but not the
                                                                     new test items and four new features. The four new fea-
food domain, and that this realization is a function of
                                                                     tures included two features they called “size” (large and
how many objects the model has “seen.” For all animal
                                                                     small) and two dubbed “brightness” (dull and bright).
datasets with only 20 objects, there was little difference
                                                                     Size but not brightness mattered for discriminating be-
in the feature likelihoods6 of shape, surface, or behavior
                                                                     tween trees and flowers, while brightness but not size
features. For all animal datasets with 60 objects, shape
                                                                     mattered for discriminating fish and birds (e.g., all birds
features are consistently significantly different than sur-
                                                                     were bright and all fish dull, but brightness features var-
face (color & texture) features.
                                                                     ied randomly for the plants). Test objects were given
   Unlike in the animal domain, for the foods there is no            values on these features such that items O1 & O3 and
significant difference in the likelihoods of any of the fea-         O2 & O4 were of the same brightness, but O1 & O2 and
tures at any stage. Thus we do not see the emergence of a            O3 & O4 were of the same size. In one run, the test items
bias towards the shape features; however, there is also no           were also given a feature belonging to plants (“roots”);
bias toward other types of features, including the surface           in another, they were instead given one belonging to an-
features like color. This contrasts with the finding that            imals (“skin”). If the model is able to infer domain-
young children consider color features important in the              specific feature biases – size for plants and brightness for
food domain [13]; however, since our dataset included                animals – then it should classify the test items according
primarily fruits and vegetables rather than a represen-              to their size when they have plant features, but by their
tative sampling of the foods 2-year-olds were likely to              brightness when they have animal features.
be exposed to, it may not be strictly comparable. In-
                                                                        We presented our model with the same dataset and
deed, the finding that shape features were likely to have
                                                                     found that test items were classified appropriately. Fig-
   5
     We replaced cow with bison and mouse with rat since             ure 3 shows the output tree when test items had the
these two words were not in our dataset; this is conservative        “skin” feature. Items 3 and 4, which are the same bright-
because if anything, this would make performance on the
model decrease more for the more “correct” trees, rather than           7
                                                                          It was not that case that shape features have an average
the reverse.                                                         higher likelihood simply because there are more of them; for
   6
     All feature likelihoods are calculated with respect to the      instance, in the dataset showing a significant difference be-
best structure for that dataset, but the results are qualita-        tween shape and both surface and behavior features, there
tively the same no matter which structure is used.                   were 23 shape, 15 surface, and 43 behavior features
                                                              1724

                                                                                          References
                                                                 [1] Anderson, J. (1991). The adaptive nature of human cat-
                                                                    egorization. Psych.Review, 98(3):409–429.
                                                                 [2] Atran, S. (1998). Folkbiology and the anthropology of sci-
                                                                    ence: Cognitive universals and cultural particulars. BBS,
                                                                    21:547–609.
                                                                 [3] Blei, D., Griffiths, T., Jordan, M., and Tenenbaum, J. B.
                                                                    (2003). Hierarchical topic models and the nested chinese
                                                                    restaurant process. In NIPS 16.
Figure 3: Performance on the object classification task mod-     [4] Colunga, E. and Smith, L. (2004). Dumb mechanisms
eled by that in Rogers and McClelland [19]. Test items O3           make smart concepts. In Proceedings of the 26th annual
& O4 and O1 & O2 should be classified together, since they          conference of the Cognitive Science Society.
share the feature that is important for animals.                 [5] Cree, G. and McRae, K. (2003). Analyzing the factors
                                                                    underlying the structure and computation of the meaning
                                                                    of chipmunk, cherry, chisel, cheese, and cello (and many
                                                                    other such concrete nouns). JExP: General, 132:163–201.
ness (an important feature for animals) are classified to-       [6] Diesendruck, G. (2003). Mapping the sim. space of chil-
gether; items 1 and 3, which share size, are not. The run           dren & adults’ artifact categories. Cog.Dev., 18:217–231.
using the “root” feature shows similar results; for space        [7] Fenson, L., Dale, P., Reznick, J., Bates, E., Thal, D., and
reasons, we did not include it.                                     Pethick, S. (1994). Variability in Early Communicative
                                                                    Devleopment, volume 49. Monographs of the Society for
   This suggests that learning a bias for coherently vary-          Research in Child Development.
ing features can actually assist with the generalization         [8] Gelman, S. and O’Reilly, A. (1988). Children’s induc-
of novel items. A learning algorithm that can correctly             tive inferences within superordinate categories: the role of
place novel items in the existing domain structure will be          language and category structure. Ch.Dev., 59:876–887.
able to learn more of these items than one that cannot.          [9] Horton, M. and Markman, E. (1980). Developmental dif-
In our model, learning a bias towards certain features –            ferences in the acquisition of basic and superordinate cat-
                                                                    egories. Ch.Dev., 51:708–719.
that is, learning that some features have a higher likeli-
                                                                 [10] Imai, M., Gentner, D., and Uchida, N. (1994). Children’s
hood on the correct structure in that domain – can result           theories of word meaning: the role of shape similarity in
in this improved generalization.                                    early acquisition. Cog.Dev., 9:45–75.
                                                                 [11] Keil, F. (2003). Explanation, association, and the ac-
                                                                    quisition of word meaning. Lingua, 92:169–196.
                      Conclusions                                [12] Kemp, C., Perfors, A., and Tenenbaum, J. B. (2003).
                                                                    Learning domain structures. In Proceedings of the 26th
                                                                    annual conference of the Cognitive Science Society.
The Bayesian model presented here provides an explicit           [13] Macario, J. F. (1991). Young children’s use of color
and tractable paradigm in which to explore the interac-             in classification: Foods as canonically colored objects.
                                                                    Cog.Dev., 6:17–46.
tion of word learning and concept acquisition. We ex-
                                                                 [14] Macnamara, J. (1982). Names for Things. MIT Press.
plored developmental phenomena in both feature and
                                                                 [15] Markman, E. and Hutchinson, J. (1984). Children’s sen-
structure learning and showed that our model could                  sitivity to constraints on word meaning: taxonomic vs.
qualitatively capture the stages of learning of both. Our           thematic relations. Cog.Psych., 16:1–27.
model can also demonstrate how this learned knowledge            [16] Neal, R. (1992). Bayesian mixture modeling by monte
might be useful for accurate word/object classification             carlo simulation. Technical report, University of Toronto.
and property induction. Our intent was not to demon-             [17] Osherson, D., Smith, E. E., Wilkie, O., Lopez, A., and
strate that it fully captures all aspects of these phe-             Shafir, E. (1990). Category-based induction. Psych.Rev.,
nomena, but rather to give a “proof of concept” – a                 97:185–200.
demonstration that our model can be a useful tool for            [18] Rogers, T., Garrard, P., McClelland, J., Ralph, M.,
                                                                    Bozeat, S., Hodges, J., and Patterson, K. (2004). Struc-
cognitive scientists seeking to understand the interac-             ture and deterioration of semantic memory: a neuropsy-
tion between features and structure in conceptual devel-            chological and computational investigation. Psych.Rev.,
opment, and the role that different types of input may              111:205–235.
play. The model can qualitatively and quantitatively ex-         [19] Rogers, T. and McClelland, J. (2004). Semantic cog-
plain a range of interesting phenomena: the emergence               nition: A parallel distributed processing approach. MIT
                                                                    Press, Cambridge, MA.
of domain-specific feature biases, the ability to use these
                                                                 [20] Samuelson, L. and Smith, L. (1999). Early noun vocab-
biases to correctly classify new objects, the realization           ularies: Do ontology, category organization, and syntax
that some domains are hierarchically organized, and the             correspond? Cognition, 73:1–33.
ability to use this structure knowledge to improve in-           [21] Soja, N., Carey, S., and Spelke, E. (1991). Ontologi-
duction of novel properties. We are optimistic that this            cal categories guide young children’s inductions of word
modeling approach has the flexibility and transparency              meaning: object terms and substance terms. Cognition,
to be an important tool for developmental psychologists             38:179–211.
                                                                 [22] Tenenbaum, J. and Xu, F. (2000). Word learning as
and cognitive scientists alike.                                     bayesian inference. Proceedings of the 22nd Annual Con-
                                                                    ference of the Cognitive Science Society.
   Acknowledgements AFP was supported by the ND-                 [23] Waxman, S. and Gelman, R. (1986). Preschoolers’ use
SEG graduate fellowship, and JBT by the Paul E. New-                of superordinate relations in classification and language.
ton Career Development Chair.                                       Cog.Dev., 1:139–156.
                                                            1725

