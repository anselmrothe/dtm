UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Sentence Understanding Engages Motor Processes
Permalink
https://escholarship.org/uc/item/4zw9s7m4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Bergen, Benjamin K.
Wheeler, Kathryn B.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                             Sentence Understanding Engages Motor Processes
                                          Benjamin K. Bergen (Bergen@Hawaii.Edu)
                                        Kathryn B. Wheeler (Kwheeler@Hawaii.Edu)
                                  Department of Linguistics, 569 Moore Hall, 1890 East West Road,
                                                        Honolulu, HI 96822 USA
                             Abstract                                 running a mental simulation of a described scene, wherein
                                                                      an understander activates motor representations
   Processing sentences describing actions performed by the           corresponding to what participants in the scene might do
   hearer (e.g. You gave Andy a pizza) primes actually                and perceptual representations of images they might
   performing a motor action compatible with the one described        perceive. The reasoning behind this is straightforward.
   (Glenberg & Kaschak 2002), This result has been interpreted
                                                                      Perceptual and motor imagery are known to play critical
   as indicating that processing meaning involves the activation
   of motor control circuitry to prepare the language                 roles in higher cognitive functions like memory (Wheeler et
   understander for situated action. A complementary view             al. 2000, Nyberg et al. 2001). By extension, they may well
   (Bergen & Chang 2005) argues that motor control structures         be integral to language understanding as well. On this view,
   are automatically and unconsciously engaged during motion          viable communication involves the successful evocation of
   language processing irrespective of whether that language          an aligned set of perceptual and motor images in the mind of
   pertains to the understander, because the meaning of action        a hearer (Glenberg & Robertson 1999, Bergen & Chang
   language is inherently grounded in motor control circuitry. To     2005). Recent evidence from neuroscience suggests a
   distinguish between these views, we must determine whether         mechanism by which the internal imagination of a scene
   motor activity results from processing language about actions      described by language may be effected.
   performed by and on third persons (e.g. Andy gave Sara a
                                                                         Two studies provide evidence that processing motion
   pizza.) Two experiments tested the scope of compatible action
   facilitation during sentence understanding, where sentences        language associated with particular body parts also results in
   either encoded motion in a particular direction (e.g. John         the activation of areas of motor and pre-motor cortex
   opened the drawer) or using a particular handshape (e.g.           involved in producing motor actions associated with those
   Mary grabbed the marble.) Both studies yielded significant         same effectors. Using both behavioral and
   Action-sentence Compatibility Effects, demonstrating that          neurophysiological evidence, Pulvermüller et al. (2001)
   whether language is about the understander or not, it engages      found that verbs associated with different effectors (mouth,
   their motor system.                                                hand, leg) were processed at different rates and in different
                                                                      regions of motor cortex. More recently, Tettamanti et al.
   Keywords: sentence processing, mental simulation, motor
                                                                      (m.s.) have shown through an imaging study that passive
   control, Action-sentence Compatibility Effect
                                                                      listening to sentences describing mouth versus leg versus
                                                                      hand motions activate different parts of pre-motor cortex (as
                          Introduction                                well as other areas, specifically BA 6, BA 40, and BA 44).
Language use integrally involves perceptual and motor                    From a broader perspective, to the extent that evidence is
processes, since the production of language requires the              found indicating that imagery plays a role in language
control of facial, manual, and other effectors, and language          understanding, this bolsters an embodied view of meaning,
processing begins with the detection of visual, auditory, and         in which the particular experiences a language user has had
other perceptual cues. However, language appears to engage            in their life, in their body, create the substantive basis for
perceptual and motor systems and the neural structures                language production and understanding, as suggested by a
dedicated to them in another, less obvious way. Just as               number of authors, like Barsalou (1999), Zwaan (1999),
performing imagery about action (Porro et al. 1996, Lotze et          Glenberg and Robertson (2000), Bergen, et al. (2003),
al. 1999) and perception (Kosslyn et al. 2001) makes use of           Feldman and Narayanan (2004), Bergen and Chang (2005),
action and perception systems, so it now appears that                 and Matlock (To Appear), and MacWhinney (In Press).
processing language about perceptual or motor content                    While important and productive lines of research are
results in the activation of neural structures overlapping            beginning to gain momentum in the area of mental
with those that would be used to actually perceive or                 simulation and language understanding, there has been
perform the described content. The mental (re)creation of             insufficient focus thus far on the exact linguistic
perceptual and motor experiences (among others) in order to           mechanisms that trigger mental simulation.              More
deeply understand language goes under the rubric of mental            specifically, there are two questions that have yet to be
simulation (Barsalou 1999).                                           addressed in previous studies. The first concerns the types
   The notion that language understanding makes significant           of language that trigger simulation and the second concerns
use of perception and action imagery has been proposed in a           the degree of detail involved in simulation.
variety of contexts (Barsalou 1999, Zwaan 1999, Glenberg                 It is of critical theoretical importance to determine how
& Robertson 2000, Feldman & Narayanan 2004, Gallese &                 prevalent language-triggered motor simulation is – whether
Lakoff 2005, Bergen & Chang 2005). What these various                 it occurs only when people process language about
views share is the idea that language understanding entails
                                                                  238

themselves, or whether it is used to process sentences              Materials
describing motor actions regardless of who the described            A total of 160 sentences were created, 60 meaningful
actor is. Motor simulation has been argued to serve as the          critical stimuli, 20 meaningful filler stimuli, and 80 non-
basis for understanding language about actions in general           meaningful filler stimuli. The 60 critical stimuli were
(e.g. by MacWhinney In Press, Feldman & Narayanan 2004,             composed of 30 pairs of sentences, with one sentence
Gallese and Lakoff 2005, and Bergen and Chang 2005).                denoting motion forwards, away from the body and the
This perspective views the internal (re)creation of motor           other denoting motion backwards, towards the body. These
control events as critical to processing language about             stimuli were of three types. One set of 20 consisted of 10
actions. This claim cannot be evaluated solely on the basis         pairs of transitive sentences that differed only in terms of
of language involving the interlocutor as a participant             their object noun phrase (1a). The second set consisted of 10
because this language is precisely the type of language most        pairs of transitive sentences that differed only in their main
likely to induce motor imagery. Rather, the case must be            verb (1b). The final set was composed of 10 pairs of abstract
made by demonstrating that language not about the                   caused-motion sentences that varied in their main verb and
interlocutor nevertheless results in activation of the specific     preposition in a final prepositional phrase (1c). All
motor control systems that would perform the described              sentences were in the present tense with progressive aspect,
actions.                                                            and all referents were third-person. It was predicted that an
   While both motor and perceptual imagery have been                Action-sentence Compatibility Effect would be observed in
shown in various experiments to be automatically and                response to sentences denoting literal motion (1a,b), and
unconsciously activated by language, the level of detail of         possibly also to abstract sentences, like (1c).
that imagery remains in question. While motor imagery
appears to include the direction of motion of a particular          (1) a. Jane is wringing {her hands, Mary's neck.}
action (Glenberg & Kaschak 2002), it is not known whether                b. John is {opening, closing} the drawer.
finer details like hand-shape are also (re)created. A fine               c. Vincent is {donating, accepting} a kidney {to,
level of detail in mental simulations is critical to an account              from} the biology department.
of language understanding based on imagery if imagery is to
account for inference and disambiguation.                              Sentence pairs were drawn (with some modifications)
   In order to flesh out these remaining questions, the             from the stimuli used by Glenberg and Kaschak (2002), in
research reported here first modified a study by Glenberg           addition to newly generated ones conforming to the above
and Kaschak (2002) that demonstrated simulation effects in          described criteria. These were then submitted to a norming
language by replacing first-person with third-person                study in order to choose pairs whose members encoded the
referents in the stimuli. If understanders are in fact              appropriate direction of motion. In the norming study, 12
activating the specified neural structures while processing         subjects were instructed to decide if the described action
the language, they should display the same effects with             required movement of the hand toward or away from the
language that does not directly involve them, from which            body. To respond, they pressed buttons labeled toward and
we can infer that they are indeed activating a mental               away or, neither. Only verb pairs each of whose members
simulation in order to understand the language input.               received a majority of scores in the appropriate direction
   The second experiment addressed the level of detail              and had no more than one half as many in the opposite
involved in simulation. Subjects were asked to perform a            direction were included in the critical stimuli.
slightly modified version of the same forced-choice task,
which this time required the execution of a pre-assigned            Design and Procedure
hand-shape, that was either compatible or incompatible with
the hand-shape implied in the critical sentences. Based on          Each subject saw all 160 sentences. Each critical pair was
the idea that simulation involves fine-motor details (e.g.          split into two blocks, as were each of the three types of
Bergen & Chang 2005, Gallese & Lakoff 2005), we                     stimuli. The design fully crossed the two blocks (1 and 2)
hypothesized that subjects would be faster at responding            with the two sentence directions (toward the body and away
when the hand-shapes implied by the verb and required to            from the body) and the two response directions (yes is away
respond were compatible.                                            or yes is toward). Response direction ordering was fixed
                                                                    with yes-is-away and no-is-toward in the first half and was
                       Experiment 1                                 reversed halfway through the experiment. Thus, half of the
                                                                    subjects answered each sentence in the yes-is-away
This study tested whether sentences that describe actions           condition and half in the yes-is-toward condition.
performed only by third persons yield a significant Action-            Small colored labels were created and attached to the keys
Sentence Compatibility Effect - facilitatory priming of             on a computer keyboard such that the green “Yes” and red
manual actions by sentences denoting similar actions.               “No” were equidistant from a blank yellow middle button.
                                                                    The keyboard was also rotated such that it was
Subjects                                                            perpendicular to the subject allowing these three buttons to
54 students at the University of Hawai’i Manoa participated         be in a straight line with four keys separating each.
for either course credit or five dollars. All subjects were            When presented with a fixation cross, subjects pressed
right-handed native English speakers.                               and held the yellow button (the “h” key) to reveal the
                                                                    stimulus until they had decided if (yes) the sentence made
                                                                239

sense or (no) it did not, whereupon they released the yellow        Discussion
button and pressed either the “yes” or the “no.” Subjects           As expected, sentences denoting motion away from the
were instructed to use only their right hand during the             body were responded to faster when the subject’s physical
experiment. A training session preceded each half of the            response involved actually moving the hand away from the
experiment.                                                         body, and similarly for towards sentences and toward
                                                                    motions. However, unexpectedly, this effect was observed
Results                                                             not on the length of time it took subjects to read the
Three subjects were eliminated: two because they responded          sentence and release the button keeping the sentence on the
to the critical stimuli with less than 80% accuracy, and one        screen, but rather on the time between release of this button
because their mean reaction time surpassed 2.5 s.d. greater         and pressing of the response button – that is, in the time it
than the grand mean. One sentence item was removed from             took to actually execute a response. We discuss this
analysis for the same reason. All responses greater than 2.5        difference in the General Discussion, below. Interestingly,
s.d. from the mean per subject were replaced with the value         the away responses show a smaller effect than the toward
2.5 s.d. from the mean for that subject. This resulted in           responses, which may be due in part to the relatively shorter
modification of less than 1% of the data.                           response times in this condition.
   The two sets of literal sentences - those in pairs that             A second notable finding from this experiment is that
differed in terms of the just object noun (1a) or just the verb     sentences denoting abstract motion did not yield a
(1b), were pooled together for analysis, since the prediction       significant compatibility effect in the way that the literal
that they would yield a motor compatibility effect applies to       motion sentences did. This stands in potential contrast with
both of them. Glenberg and Kaschak (2002) found that                the results of Glenberg & Kaschak (2002) who found a
subjects were faster to remove their finger from the button         significant compatibility effect with a set of stimuli that
keeping the displayed sentence on the screen when the               included abstract sentences like these. One explanation that
sentence and the action they had to perform to identify it as       immediately presents itself is the possibility that when
meaningful were in the same direction. In the current study,        processing language not about oneself, an understander
release times on the same button did not show the predicted         performs less detailed motor imagery in general. As a
effects. In contrast with the results reported by Glenberg          consequence, the motor imagery in response to language not
and Kaschak (2002), there was no significant interaction            literally describing motion, which by all accounts would
effect between sentence direction (away, toward) and                tend to be less intense than motor imagery evoked by literal
response direction (away, toward), p=0.27.                          language, would decrease below the level of detection by
   However, the time subjects took to press the response            this particular instrument.
button indicating that the sentence was meaningful did show            Regardless of these differences, the fact remains that
the predicted effects (Figure 1). A significant interaction         reading literal sentences denoting motion towards or away
effect was observed, in which subjects took longer to               from the body yielded a significant compatibility effect on
respond to sentences when the direction of their response           the time it took subjects to press a button indicating
was incompatible with the direction of described motion: in         meaningfulness of the sentence. We can conclude from this
a subject repeated-measures ANOVA, F(1,51)=4.31;                    that not only sentences describing the interlocutor as a
p<0.05. The two main effects (response direction and                participant but also sentences describing only third persons
sentence direction) were not significant.                           can result in the activation of motor control functions.
    370                                                                                     Experiment 2
    360                                        Sent.                In order to establish the stability of this Action-sentence
    350                                        Away                 Compatibility Effect with third person participants, we
    340                                        Sent.                designed another ACE experiment in which subjects once
    330                                        Toward               again read sentences denoting motion of one of two types.
    320                                                             As in the previous study, the response action could be
               Away        Toward                                   compatible or incompatible with the described action. Since
                                                                    sentences only involved third-person participants, the results
               Response Direction
                                                                    would help assess first, whether motor activation in
Figure 1: Response times as a product of toward and away            response to sentences not involving the understander is
sentences, when manual responses were toward or away                indeed a replicable effect, and second, whether finding the
from the body.                                                      expected interaction effect on the button press, rather than
                                                                    release time was a reliable product of sentences like this.
   Like the sentences denoting literal motion of the hand           Moreover, we were interested in investigating the depth of
towards or away from the body, abstract sentences yielded           motor detail contained within the motor imagery that
no significant interference effect in the button release            subjects appeared to be performing, so the particular design
measure, but unlike literal sentences they also displayed no        we adopted manipulated not the direction of motion, but
interaction effect in the response measure: in a subject            rather the handshape used to perform described actions.
repeated-measures ANOVA, F1(1,51)=0.08; p=0.78. Neither                The design of this experiment was quite similar to that of
of the main effects was significant.                                Experiment 1, described above. Subjects were asked to push
                                                                240

down a button to display a sentence they had to read, and          Design and Procedure
decide as quickly as possible whether the sentence made            Each trial began with a fixation cross in the center of the
sense or not. The critical sentences described an action           computer screen that remained until the subject pressed the
performed either with an open palm handshape or a closed           “Enter” key in order to initiate the visual presentation of the
fist handshape, depending on the condition. Subjects then          stimulus sentence. The sentence remained until the subject
responded by pushing a large flat foot pedal with their hand,      released the “Enter” key in order to press the response
using either an open palm or closed fist. Response actions         button with either of the pre-assigned hand shapes (closed
could thus be compatible or incompatible with the                  fist or open palm). Once the subject had responded by
handshape of the action described in the sentence. We              pressing the button, the fixation cross would appear in
predicted that subjects would take longer to press the button      preparation for the next trial. Subjects were instructed to
when they had to do so with an incompatible handshape –            use only their right hand during the experiment. Subjects
that is, that we would observe an ACE for handshape.               had a training session before each half of the experiment (16
                                                                   and 20 trials, respectively) in order to familiarize them with
Subjects                                                           the task.
88 students at the University of Hawaii participated for              Subjects read sentences that were either meaningful or
either course credit or five dollars. All subjects were right-     not, and were asked to make a sensibility judgment – 'yes, it
handed native English speakers. The data from four                 makes sense, or 'no, it does not make sense'. They indicated
subjects were excluded for having lower than 80% accuracy,         their judgment by pressing a button, using a pre-assigned
one due to experimenter error, and eighteen subjects for           hand-shape, either a flat, open palm or a clenched fist. (This
performing the task incorrectly. The task in this experiment       methodology is similar to Ellis and Tucker 2000 and Tucker
proved to be difficult for subjects and incorrect performance      and Ellis 2001, which required responses using different
included pressing the wrong “Enter” key on the keyboard            types of grip.) The response pattern (fist means ‘yes’ and
not switching the response hand-shapes in the second half,         palm means 'no; or fist means ‘no’ and palm means 'yes')
answering with the opposite hand-shape than that assigned,         was randomly assigned to each participant and was reversed
or using different hands to press the “Enter” key and the          midway through the experiment.
response button.                                                      In order to check accuracy of response, subjects were
                                                                   video-recorded and answers (palm or fist) were coded by a
Materials                                                          naïve assistant with no knowledge of which condition was
16 critical sentences were created, half with verbs encoding       assigned to each half for a given subject. If a subject failed
a palm hand-shape (2a) and half with a fist hand-shape (2b).       to respond to a trial, or didn’t hold down the Enter key such
Another 16 critical sentences were created using 8 verbs that      that the sentence stimulus flashed on the screen and the
variably encoded actions performed with either a fist (3a) or      subject chose to guess the answer, the response was noted
palm hand-shape (3b), depending on the direct object. In           and eliminated from analysis.
order to mask any possible relation between the physical
responses subjects had to perform and the semantics of the         Results
critical verbs, a large number of fillers were also created to     As discussed earlier, previous work with sentences
make the total number of sentences 160. All critical trials        describing actions involving the understander (Glenberg and
were sensible and transitive (since they encoded hand              Kaschak 2002) has shown that subjects are faster to read a
actions on objects) but fillers were divided such that half of     sentence when it is compatible with the action they have to
all stimuli were non-sensible, and orthogonally, half of all       perform. In the current study, just as in Experiment 1,
stimuli were intransitive.                                         release times on the same button indicating reading time did
   As mentioned above, we used critical stimuli of two             not show the predicted interaction effect. A three-way
types. The first (fixed) type had a verb strongly implying the     (sentence type [fixed, variable] by handshape [fist, palm] by
use of a fixed hand-shape (e.g. The nanny patted the               sentence shape [fist, palm]) repeated-measured subjects
cushion; The singer gripped the microphone) – see also the         ANOVA showed a main effect of sentence type (fixed or
examples in (2). The second (variable) type contained a            variable): F1(1,65)=7.473; p<.01, and a strong two-way
verb whose action could be performed with one hand-shape           interaction between sentence type and sentence hand-shape
or the other depending on the sentential context (e.g. The         (fist or palm): F1(1,65)=27.698, p<.001. However, the
busboy lifted the plate; The bartender lifted the bottle ), as     critical interaction between the response hand-shape and the
seen as well in (3). The use of these two types of stimuli         sentence hand-shape was not significant: F1(1,65)=.011,
was meant to evaluate whether any action compatibility             p=.916.
effects resulted just from the lexical semantics of the verbs,        Instead, as in Experiment 1, the time subjects took to
or whether they resulted from the generation of a mental           press the response button indicating that the sentence was
simulation of the event described by the entire sentence.          meaningful did show the predicted effect. With response
                                                                   button press times, there was a main effect of sentence
(2) a.    The waiter smoothed the tablecloth.                      hand-shape (fist or palm), F1(1,65)=9.189; p<.01, which is
     b.   The tourist punched the wall.                            not unexpected since the palm and fist sentences were
(3) a.    The waitress carried the platter.                        different and not intended to be matched for response
     b.   The lawyer carried the briefcase.                        latency. There was also a two-way effect between sentence
                                                               241

type (fixed or variable) and sentence hand-shape,                    demonstrate that motor action is facilitated even when
F1(1,65)=5.903; p<.05, which we did not predict.                     language describes actions involving only third-person
   Critically, the interaction effect between response hand-         participants, in which case they are less likely to be
shape (fist or palm) and sentence hand-shape (the ACE) is            preparing to perform the described actions. This finding
significant, and in the predicted direction: F1(1,65)=6.294;         demonstrates that motor imagery is much more pervasive
p<.05 (Fig. 2). A repeated-measures item analysis also               than previously known. An interpretation of this effect is
confirmed the significance of the ACE for these sentences:           that language comprehension in general engages cognitive
F2(1,30)=6.35, p<0.05. As expected, subjects were much               mechanisms responsible for motor performance in order to
quicker to press the response button when the hand-shape             perform a mental simulation of language content (Feldman
required to respond was compatible with the hand-shape               & Narayanan 2004, Bergen & Chang 2005, Lakoff &
implied by the sentence. This can be interpreted as evidence         Gallese 2005).
that action language comprehension has an effect on action              Not only have we seen that language not about an
performance to the level of fine motor detail, despite the fact      understander will nevertheless lead them to perform mental
that the effect was much stronger for fist than palm                 motor imagery, but in addition, Experiment 2 showed that
sentences.                                                           this simulation includes detail as to the handshapes that
                                                                     would be required to perform the described action. By
                                                                     demonstrating that subjects found it easier to respond when
         590                                                         sentential semantics and an executed handshape were
         580
         570                                         Sent.
                                                                     compatible, Experiment 2 provides behavioral evidence that
         560                                         Fist            this kind of mental simulation of action performance in
         550
         540                                         Sent.           language understanding includes detailed motor
         530                                         Palm            information.
         520
         510                                                            Both of these findings serve to strengthen an embodied
                   Fist         Palm                                 theory of meaning wherein experiences of action and
                    Response Shape                                   perception provide the basis for the subsequent mental
                                                                     recreation of these experiences such that they can be
  Figure 2: Response Hand-shape by Sentence Hand-shape               recruited for the purposes of interpreting and acting on the
                                                                     basis of upon linguistic input.
   If there was a significantly different effect for fixed hand-        One interesting sidenote relates to the measurement on
shape verbs versus variable hand-shape verbs, we should              which the Action-sentence Compatibility Effect was
expect a three-way interaction between sentence type,                observed. As noted above, in their original work, Glenberg
response hand-shape, and sentence hand-shape. However,               & Kaschak (2002) found a significant compatibility effect
there was no such significant effect, which fails to                 on the time it took subjects to read the sentence and release
disconfirm the null hypothesis that these two sentence types         the button keeping it on the screen. By contrast, in each of
yield the same effect: F1(1,65)=.346, p=.559.                        the studies described above (like in Tseng & Bergen 2005),
                                                                     the effect was observed instead on the time it took subjects
Discussion                                                           to perform the compatible or incompatible action that
These results demonstrate that sentences denoting actions            indicated their meaningfulness judgment.
performed using a particular handshape prime the                        Here is a possible explanation. The main difference
performance of a physical response using the same                    between the two experiments was in whether the sentence
handshape. This effect is produced by processing sentences           stimuli described actions involving the experimental subject
denoting actions performed by third persons, confirming the          or not. It could thus be the case that when language is about
finding reported in Experiment 1 that a sentence need not            an understander (compared with when it only pertains to
involve the understander for it to yield motor activity. This        third persons), they more immediately engage motor
level of motor detail has not been previously demonstrated           imagery, as they are preparing for situated action. This
in sentence processing research on language not involving            would explain why in Glenberg & Kaschak's (2002) study,
the understander. Finally, the observed effect here                  which used second-person participants in sentences, the
measured the time it took subjects to respond by pressing a          motor compatibility effect was observed as early as the
button using the target response handshape, further                  release time - when subjects are still planning their motor
reinforcing the finding in Experiment 1 that response time,          response. By contrast, in the current studies, where
and not reading time, is the critical measure of motor               sentences did not involve the experimental subject, motor
activity in third-person-participant sentence comprehension.         activation occurred later, and therefore showed up on the
                                                                     motor response times, rather than the reading button release
                    General Discussion                               times. If this explanation is correct, such a difference in
Previous studies have shown that language about a hearer             timecourse of simulation would constitute a dramatic
leads them to perform motor imagery about the described              demonstration of the intricate nature of mental access to
actions. It has been argued that this motor activation arises        semantic content during language processing, and would
due to the need on the part of the language understander to          highlight the importance of attending to the details of
prepare for situated action (Glenberg & Kaschak 2002).               linguistic stimuli in language processing.
While this may be correct, results from the current studies
                                                                 242

                        Conclusion                                  Kosslyn, S. M., G. Ganis, and W. L. Thompson. 2001.
                                                                      Neural foundations of imagery. Nature Reviews
The body, and our experiences in it, matter to language in a
                                                                      Neuroscience, 2, 635 -642.
trivial and a non-trivial way. Trivially, without a body, we
                                                                    Lotze, M., P. Montoya, M. Erb, E. Hülsmann, H. Flor, U.
could obviously not produce or perceive language, nor for
                                                                      Klose, N. Birbaumer, and W. Grodd. 1999. Activation of
that matter would we have much of interest to talk about.
                                                                      cortical and cerebellar motor areas during executed and
But less trivially, it seems that the act of communicating
                                                                      imagined hand movements: An fMRI study, Journal of
through language about action uses the ability to call up
                                                                      Cognitive Neuroscience, 11(5): 491-501
mental representations of how one moves one's body. The
                                                                    MacWhinney, B. (in press) The emergence of grammar
integration of language processing with the mental
                                                                      from perspective taking. In Pecher, D and Zwaan, R.
simulation of motor action is yet another in an increasingly
                                                                      (Eds.) . The grounding of cognition.
long list of important ways in which the embodiment of
                                                                    Matlock, T. To appear. Fictive motion as cognitive
human beings critically structures the higher-order cognitive
                                                                      simulation. Memory and Cognition.
behaviors they engage in.
                                                                    Porro, C. A., M. P. Francescato, V. Cettolo, M. E. Diamond,
                                                                      P. Baraldi, C. Zuian, M. Bazzocchi, and P. E. di
                    Acknowledgments                                   Prampero. 1996. Primary motor and sensory cortex
Our thanks to Art Glenberg for invaluable consultation                activation during motor performance and motor imagery:
throughout, to Kristin Ciano for her help coding the data             a functional magnetic resonance imaging study. Journal
and running subjects, as well as to Meylysa Tseng and other           of Neuroscience 16:7688–7698.
members of the Cognitive Linguistics Research Group at the          Nyberg, L., K. M. Petersson, L. G. Nilsson, J. Sandblom, C.
University of Hawai`i for feedback on the design. All errors          Åberg, and M. Ingvar. 2001. Reactivation of motor brain
and omissions are of course our own.                                  areas during explicit memory for actions. NeuroImage,
                                                                      14, 521-528.
                         References                                 Pulvermueller, F., Haerle, M., & Hummel, F. 2001.
Barsalou, L.W. (1999). Perceptual symbol systems.                     Walking or Talking?: Behavioral and Neurophysiological
   Behavioral and Brain Sciences, 22, 577-609.                        Correlates of Action Verb Processing. Brain and
Bergen, B. & N. Chang. (2005). Embodied Construction                  Language 78, 143–168.
   Grammar in Simulation-Based Language Understanding.              Rizzolatti, G., F. Luciano, G. Vittorio, L. Fogassi. 1996.
                                                                      Premotor cortex and the recognition of motor actions.
   In J.-O. Östman & M. Fried (Eds.), Construction
   Grammars: Cognitive grounding and theoretical                      Cognitive Brain Research, 3:131-141.
   extensions. John Benjamins.                                      Stanfield, R. A. and R. A. Zwaan. 2001. The effect of
Bergen, B., S. Narayan, and J. Feldman. 2003. Embodied                implied orientation derived from verbal context on picture
   verbal semantics: evidence from an image-verb matching             recognition. Psych Science, 12, 153-156.
   task.    In Proceedings of the Twenty-Fifth Annual               Tettamanti, M., Buccino, G., Saccuman, M.C., Gallese, V.,
                                                                      Danna, M., Perani, D., Cappa, S.F., Fazio, F., &
   Conference of the Cognitive Science Society.
Buccino, G., F. Binkofski, G. R. Fink, L. Fadiga, L. Fogassi,         Rizzolatti, G. Unpublished Ms. Sentences describing
   V. Gallese, R. J. Seitz, K. Zilles, G. Rozzolatti, and H. J.       actions activate visuomotor execution and observation
   Freund. 2001. Action observation activates premotor and            systems.
   parietal areas in a somatotopic manner: an fMRI study.           Tseng, Meylysa and Benjamin Bergen. 2005. Lexical
   European Journal of Neuroscience, 13 (2): 400-404.                 Processing Drives Motor Simulation. This volume.
                                                                    Tucker, M. and R. Ellis. 2001. The potentiation of grasp
Ellis, R., and M. Tucker. 2000. Micro-affordance: The
   potentiation of components of action by seen objects.              types during visual object categorization. V i s u a l
   British Journal of Psychology, 91, 451-471.                        Cognition, 8 (6), 769-800.
Feldman, J. & S. Narayanan. 2004. Embodied Meaning in a             Wheeler, M. E., S. E. Petersen, and R. L. Buckner. 2000.
   Neural Theory of Language. Brain and Language 89,                  Memory’s echo: Vivid remembering reactivates sensory
   385-392, 2004.                                                     specific cortex. Proceedings of the National Academy of
                                                                      Science, USA 97: 11125–11129.
Gallese, V., L. Fadiga, L. Fogassi, and G. Rizzolatti. 1996.
   Action recognition in the premotor cortex. Brain 119:            Zwaan, R.A. (1999). Embodied cognition, perceptual
   593-609.                                                           symbols, and situation models. Discourse Processes, 28,
Gallese, V. & G. Lakoff. 2005. The Brain’s Concepts: The              81-88
   Role of the Sensory-Motor System in Reason and                   Zwaan, R. A., R. A. Stanfield and R. H. Yaxley. 2002. Do
   Language. Cognitive Neuropsychology.                               language comprehenders routinely represent the shapes of
                                                                      objects? Psychological Science, 13, 168-171.
Glenberg, A. and M. Kaschak. 2002. Grounding Language
   in Action. Psychonomic Bulletin & Review, 9 (3), 558-
   565.
Glenberg, A. & D. Robertson (2000). Symbol Grounding
   and Meaning: A Comparison of High-Dimensional and
   Embodied Theories of Meaning. Journal of Memory and
   Language, 43, 379-401.
                                                                243

