UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Biologically Inspired Visuo-Motor Control Model based on a Deflationary Interpretation of
Mirror Neurons

Permalink
https://escholarship.org/uc/item/4g67070n

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Author
Martin, Bridgette A.

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Biologically Inspired Visuo-Motor Control Model based on a Deflationary
Interpretation of Mirror Neurons
Roberto Prevete (prevete@na.infn.it) - Matteo Santoro (santoro@na.infn.it)
Department of Physical Sciences, Compl.Univ. Monte Sant’Angelo
Naples, NA 80126 Italy

Francesco Mariotti (f.mariotti@fls.unipi.it)
Department of Philosophy
Pisa, PI 56100 Italy

and the activity of the F5 neurons is selective for both
“action goal” (grasping, holding, tearing etc.) and “action
modality” (precision grip, whole hand grip, etc) (Rizzolatti
G. et al. 1988; Fogassi L. et al. 2001; Gallese et al. 1996 ).
Moreover, in area F5 a population of neurons was
discovered which are “active” (high spike rate) during both
the execution of a Goal Oriented action (executed-GO
action) and the observation of the same action executed by
another individual (observed-GO action). Because of their
characteristic activation, these neurons have been called
mirror neurons (Fadiga et al. 2000; Gallese et al. 1996;
Rizzolatti et al. 1996; Rizzolatti et al. 2001). Hence, the
AIP, PF ⇔ F5 circuit is often called Mirror System (MSys).
The expression “goal-oriented action” is used to denote a
series of prehension movements that relate body parts
(effectors like hand or foot) of the subject to a threedimensional object - e.g. to grasp a food piece by a precision
grip is a goal-oriented action.
Canonical neurons form another distinctive family of F5
neurons (Gallese et al. 1996; Rizzolatti et al. 2001). These
are active both when the monkey performs a goal-oriented
action and when the monkey observes a “graspable object”.
No data are reported in literature about activation state of
canonical neurons when an action is observed. Thus, mirror
neurons are indistinguishable from canonical neurons
insofar as their spike rates during executed-GO action are
concerned, but their behaviours seem to differ insofar as
their visual properties are concerned.

Abstract
We propose a new deflationary interpretation for the
functional role of mirror neurons discovered by Rizzolatti and
colleagues into the macaque’s F5 motor area. Several
functional interpretations of the mirror activity have been
proposed, emphasizing their role in action understanding and
representing, language evolution, or mind-reading abilities.
However, according to the interpretation presented here, full
understanding of agent goals and intentional action are related
to mirror neuron activity only insofar as the process of
understanding an intentional action necessarily involves the
capability of assigning a “structural description” to the action.
In particular, we argue that mirror activity is involved in both
recognizing action structural features and associating these
features to motor commands. Our functional interpretation
includes an anticipatory mechanism, enabling one to verify
whether the actual, suitably coded visual input, matches an
expected visual input computed on the basis of a motor
command sequence. This mechanism is involved in both
action recognition and action execution control. We believe
that this mirror neuron model could fit biological data better
than the Oztop and Arbib model. Starting from this
interpretation, we propose a biologically inspired visuo-motor
control model merging basic elements of the Oztop and Arbib
model with an expected perception mechanism. This model
has been formalized within an algorithmic stance however
actual implementation is in progress.
Keywords: mirror neurons, visuo-motor control, anticipatory
mechanism, expected perception.

Mirror System: basic elements

Mirror System Interpretations

Let us recall basic facts and notions concerning mirror
neurons that will be needed to introduce our functional
model of mirror neurons and compare it with other
interpretations and models. Some macaque’s cortical
circuits have been found to be strongly involved in
controlling arm and hand movements in order to reach and
manipulate objects (Luppino G., Rizzolatti G., 2000; Matelli
M., Luppino G, 2001; Rizzolatti G., Luppino G, 2001). In
particular, these findings concern: a) the VIP ⇔ F4 circuit,
transforming object location in appropriate arm movements
towards the same object; b) the AIP,PF ⇔ F5 circuit,
transforming object features in hand configurations suitable
to object manipulation. Area F5 in pre-motor area is
functionally interpreted as a “vocabulary of movements”,

Several functional interpretations of the MSys activity have
been proposed (Arbib M.A. et al. 2000; Arbib M.A. 2003;
Fadiga L. et al. 2000; Rizzolatti G. et al. 2001; Makino T.
and Aihara K. 2003) which variously emphasize their role in
(a) action understanding and representing (Gallese V. 2003;
Gallese V. et al. 1996), (b) language evolution (Arbib M.
2004), and (c) evolution of mind-reading abilities (Umiltà
M.A. et al. 2001).
In particular, these interpretations of MSys activity often
involve a distinction between goal-oriented actions and
simple motor events. Gallese (2003), tries to provide a
physiological underpinning for goal-oriented action in
general, and for the concept of “goal possession” in
particular. But the distinction between goal-oriented actions

1779

and simple motor events is mostly assumed on the
behavioural grounds that - unlike goal-oriented actions movements “without goal” do not involve any interaction
with objects and do not appear to be deployed for doing
anything in particular, except to carry out the movement
itself.
In our view, however, it is correct to speak of “goaloriented action” if the agent performing the action actually
possesses a goal (Jonas, H. 1953). If we assume this view,
behavioural evidence (i.e., the series of movements
composing an action) does not suffice to discriminate
between goal-oriented actions and actions without a goal.
Moreover, we concord with Stamenov (2002) about MSys’
agency blindness: from the analysis of MSys’ activity,
during action observation and execution, there is no
evidence that this system is able to distinguish agent and
observer and then to identify the self with one of them. So,
if we still want to talk about “goal-oriented actions”, in
relation with MSys activity, we have to do it referring only
to the function of the action, eluding the agent’s goal (his
intention). In this context the term “function” is strictly
linked with the structure of the action, with “how it works”,
with “how it functions”: the accomplishing of the goal is
only the final stage of the functional process of the action.
Action understanding is another notion often involved in
MSys’ activity functional interpretations. It is difficult to
provide a thoroughly satisfactory account of what it is to
understand (recognize, classify, etc.) an intentional action
(see for example Giese MA & Poggio T 2003). Nonetheless,
at least this much seems to be clear: action understanding
necessarily involves the capability of assigning both a
structural description to the observed behaviour and more
subsequent additional interpretive steps. However, we are
not concerned with this additional step here, insofar as an
empirically adequate functional model of mirror neurons
does not require any reference to an interpretive stage.
In the next Section we will give a more precise definition
of the meaning of structural description and we will show
how to identify a goal-oriented action (only in the sense
clarified above) from its structure.

Structural Description and Mirror Neurons
As we are interested in both executed and observed actions,
a definition of structural description must be adequate for
both executed actions and observed actions.
Let us begin introducing the following two definitions:
– structural description of executed actions. Given an
agent A (monkey or human experimenter), let us call CA
the internal representation of the finite set of the agent’s
own motor commands. We define structural description
of an A’s executed action as the correspondent motor
command sequence cs ∈ CA* (CA* is the set of all strings
from CA, including the empty string).
– structural description of observed actions. When the
agent A observes an agent B (including the particular case
A=B), A receives sensory inputs (in the visual modality,
1780

for instance). Let us call VA,B the finite set of all A’s
internal representations of A’s visual inputs when A
observes an action executed by B. We define structural
description of a B’s action observed by A as the
correspondent A’s visual input sequence, vs ∈ VA,B* (VA,B*
is the set of all strings from VA, including the empty
string).
On the basis of the above definitions we suppose that it
possible to identify a GO-action in the following way:
– structural description of executed-GO actions. We
assume that there is a specific subset of motor command
sequences LCA ⊂CA* with the following property: if G is
an achievable goal of the agent A then there is a sequence
csG ∈ LCA such that the movements corresponding to csG
make the achievement of goal G possible. We identify
csG∈ LCA with the structural description of the executed
GO- action.
– structural description of observed-GO actions. We
assume that there is a specific subset of visual input
sequences LVA,B ⊂VA,B* with the following property:

assuming that vsG ∈ VA,B* is the visual input sequence of
agent A observing agent B while achieving its own goal
G, if vsG ∈ LVA,B then there is csG ∈ LCA such that if csG is
executed by A then this execution causes the same
sequence, vsG, of A’s internal representations by visual
input. We identify vsG∈LVA,B with the structural
description of the observed GO-action.

An account of the capability of providing a structural
description of an action does not require one to provide an
account of how one understands or performs truly
intentional actions. Accordingly, the ensuing interpretation
of MSys activity, centred around the idea that mirror
neurons recognize and compute structural descriptions of
actions, is a deflationary, intentionality-free interpretation
Especially congenial to our proposed interpretation is
Gallese’s hypothesis on the possible evolution of MSys
from an ancient mechanism devoted to the improvement of
action control (Gallese V., Goldman A. 1998). We conceive
of the MSys of some agent A as a mechanism devoted to
verifying whether a particular sequence of effector’s
movements is appropriate, that is,
− verifying whether vs belongs to LVA,B

− identifying the corresponding cs∈ LCA if vs∈ LVA,B
Mirror System Models

Many computational models inspired by mirror neuron
findings have been proposed (Marom Y. et al. 2002; Billard
A. & Matari´c M.J. 2001; Oztop E. & Arbib M.A. 2002;
Tetsunari Inamura, Yoshihiko Nakamura and Moriaki
Shimozaki 2002; Miall RC. 2003; Demiris Y & Johnson M
2003). Some such models, for example those of Marom Y.

et al. (2002) and Billard A. & Matari´c M.J. (2001), suppose
that mirror activity is directly linked to motor activity, i.e.
mirror activity causes the correct activity in motor area.
However, these models are unable to account for the fact
that an inactivation of mirror neurons is known to cause
only a slowdown of motor activity, since the correct action
is eventually performed when mirror neurons are inactivated
(Fogassi L. et al. 2001). Hence, in contrast with the account
provided by these models, it seems reasonable to
hypothesize that mirror activity facilitates motor activity
without being strictly necessary to it. This view also differs
from a hypothesis embodied into one of the more interesting
and detailed mirror neuron models, that is, the Oztop and
Arbib model (OA model) (Oztop E. & Arbib M.A. 2002),
for the OA model assumes that mirror neuron activity does
not influence motor activity.
The OA model is represented as a system of interacting
schemas (functional units). Distinguishing features of the
OA model include:
– On the basis of object features (affordances) oriented to
perform an action, it is computed a hand-program
controlling hand movements. This computation step
models the activity of canonical neurons.
– Hand state hypothesis. Visual input is coded into a vector
of observer-independent features. Under this hypothesis,
the moving hand can be another agent’s or the observer’s
own hand.
– The functional role of mirror neuron activity is modelled
by means of a recognition module classifying the correct
action on the basis of object affordances – hand state
associations. This module is implemented using a multilayered feed-forward neural network which is trained on
the basis of affordances – hand state association
sequences and the corresponding hand-program. In this
connection, the authors remark: “… output is a signal
expressing confidence that the observed trajectory will
extrapolate to match the observed target object using the
grasp encoded by that mirror neuron” (Oztop E. & Arbib
M.A. 2002).
According to the OA model, a visual input sequence is
transformed into a sequence of hand states, vs, and is
classified by the action recognition module. This process is
similar to the process of verifying whether vs belongs to
some specific subset of “visual input sequences”. Thus, in
the OA model mirror neurons are basically assigned the role
of classifying arm+hand movements with respect to
“structural features” of the movement concerning object
features and hand shapes during the action. Evidently, the
OA model is an intentionality-free model too, and its focus
is the ability to classify actions on the basis of structural
features. One has to notice, however, that this model does
not account for some crucial biological data, notably the fact
that mirror neuron inactivation causes motor slowing
(Fogassi L. et al. 2001).

1781

MEP Model
We propose now an alternative visual–motor control model
for goal-oriented actions, which is centred on the following
interpretation of mirror neurons:
– Mirror neurons code an expected perception;
– Mirror neurons compare the expected perception
representation with the actual perception.
As we will argue below, this interpretation enables one to
account for the following biological data:
– mirror neuron are active in the same way during both
executed-GO actions and observed-GO actions. (This is
accounted for by the OA model too.)
– an inactivation of mirror neurons causes a motor slowing,
but the correct action is still performed. This means that
mirror activity facilitates without being a necessary
condition for the correct activity of the motor area. (This
is unaccounted for by the OA model.)
Some novel qualitative predictions can also be made on
the basis of this interpretation. Notably, one should observe
a decrement in neural activity if an unexpected event occurs
during a GO action, for instance, if the graspable object is
taken away. At the moment, no data relevant to assess this
conjecture are reported in the literature.
Our model and the OA model share the following
similarities:
– Visual input is coded in a vector of observer-independent
features.
– An initial sequence of subtasks or commands, the plan,
is computed from both task and/or object features
oriented to perform an action.
A distinctive feature of our model is its anticipatory
mechanism, significantly related to the expected perception
model proposed in Datteri E. et al. (2003).
Accordingly, let us call this model Mirror Expected
Perception model (MEP, see Figure 1), and let us proceed
to a description of its interacting functional parts.
If an agent A performs a GO-action:
1. Object location (relative to A’s hand), object features
(relative to A’s hand intrinsic features), arm coding (A’s
arm shape and A’s arm motion relative to the object) and
hand coding (A’s hand shape and A’s hand motion
relative to the object) are computed, in an observerindependent internal representation, from somatosensory
and visual information (actual perception): v1. This step
captures the functional interpretation of AIP and VIP
neurons.
2. Both an arm plan and a hand plan are computed from task
assignment and v1. One can represent these plans as a
sequence of subtasks or commands coded as an internal
representation cs≡ c1 c2… ck. This step captures the
functional interpretation of F4 neurons and F5 canonical
neurons.

3. Starting from i=1, we have the following loop (Mirror
loop: steps 3.2 and 3.3 capture our interpretation of F5
mirror neurons):
3.1. ci is sent to a controller which transforms ci in an
arm motor program and a hand motor program
which control the motor apparatus.
3.2. At the same time, from ci an expected perception evi
is computed.
3.3. evi is compared with the new actual perception vi+1.
If evi = vi+1 then the step 3.1 is carried out on the
next subtask ci+1 else the process returns to step 1 to
compute a new plan.

Somatosensory
features

Visual
features

object
location

arm
coding

object
features

Environment

hand
coding

AIP

VIP

IPL
Actual
perception

Match
T

F4

F5C

Arm
plan

hand
plan

Notice that the same sequence of expected perceptions
occurs when the same GO-action is observed or executed by
agent A, i.e if cs’ = cs and v’1= v1 then ev’1 v’2… ev’k = ev1
ev2… evk. This is what happens also for the mirror neuron’s
activity in the biological case.
Notice, moreover, that a fundamental hypothesis is the
observer independence in the coding of hand-arm
information..
On the basis of the formalism introduced in Section
Structural Description and Mirror Neurons we state that if
the mirror loop is executed without interruptions then the
visual sequence vs’≡ v’1 v’2… v’k+1 belongs to LVA,B and the

Knowledge
base

motor
apparatus

Arm subtask
extraction

Arm
program

hand subtask
extraction

hand
program

If an agent A observes an agent B carrying out a GOaction, the same process is carried out by A, except for the
motor program sending step:
1. object location (relative to B’s arm), object features
(relative to A’s hand intrinsic features), arm coding (B’s
arm shape and B’s arm motion relative to the object) and
hand coding (B’s hand shape and B’s hand motion
relative to the object) are computed, in an observerindependent internal representation, from visual
information (actual perception): v’1.
2. From v’1 a potential arm and hand plan cs’≡ c’1 c’2… c’k
is computed (but it is not sent to the motor apparatus).
3. Starting from i=1 we have the following loop (Mirror
loop: the following steps capture our interpretation of F5
mirror neurons):
3.1. an expected perception ev’i is computed from c’i
3.2. ev’i is compared with the new actual perception
v’i+1. If ev’i = v’i+1 then the process continues from
step 3.1 with the next subtask c’i+1 otherwise the
process returns to step 1 for computing a new plan.

Expected Mirror System
perception
(MSys)

Figure 1: Architecture of the MEP model. For more
details see the text.

Notice that steps 3.2 and 3.3 express salient aspects of
our new interpretation of F5 mirror neurons, i.e. an expected
perception is computed and the expected perception is
compared with actual perception. We observe that
inactivation of mirror neurons corresponds to “expected
perception does not match actual perception” in our model.
Therefore, in this case, the plan is continuously rebuilt, but
the first step of the plan is always carried out. This means
that the action is correctly executed, even though in a
slowed down fashion. And this slowing down is exactly
what happens in the biological case, i.e., when mirror
neurons are inactivated.

1782

corresponding command sequence belonging to LCA is cs’≡
c’1 c’2… c’k+1.
Observe that, in our interpretation, the understanding of
an action is the capability to associate to the visual sequence
v’1 v’2… v’k+1 the potential plan cs’=c’1 c’2… c’k such that if
cs’ is carried out by A then A should be able to perform the
same task of B. Thus, according to MEP, the role of F5
Mirror neurons is to control whether some plan is correct on
the basis of visual and/or somatosensory information.
During a executed GO-action this ability enables one to
continue on in plan execution or else to restart a new plan in
such a way that an agent is able to control unexpected
events. During the observation of an action this ability
enables one to associate sequences of visual information to
potential plans.
From an algorithmic point of view, the main blocks of
this overall process can be schematized as the algorithm in
the table 1.

Concluding remarks and future work
We have introduced the biologically inspired, visuo-motor
control mode, MEP, based on a new deflationary,

intentionality-free interpretation of mirror neurons, and
differing in significant ways from the Oztop and Arbib
functional model. We have argued that mirror activity is
involved in both recognizing action structural features and
associating these features to motor abilities. To achieve this
functionality, mirror neurons take part into an anticipatory
mechanism which verifies whether the actual visual input,
matches a predicted visual input computed on the basis of a
motor command sequence. We have emphasized that our
mirror neuron interpretation could fit biological data better
than one of the more interesting and detailed mirror models,
that is, the Oztop and Arbib model. Notably, it was pointed
out that the MEP model accounts for experimental data
collected during inactivation of mirror neurons, i.e., for the
fact that action is slowed down and yet correctly executed in
these situations. Moreover, on the basis of MEP one predicts
a decrement of mirror neuron activity if an unexpected event
takes place during some goal oriented action .
One should carefully note, however, that the MEP model
does not fit all available experimental data on mirror
neurons. For instance, it was showed in Umiltà M.A. et al.
(2001) that a subset of mirror neurons becomes active
during action presentation, and also when the final part of

the action, which is crucial for triggering the response in full
vision, is hidden. In this case, our interpretation fails
because expected perception does not match actual
perception. In order to fit these experimental data we might
introduce a “weaker” definition of match between expected
perception and actual perception; for example, one may
suppose that an expected perception matches an actual
perception when the actual perception does not contradict
the expected perception.
Note, finally, that we have not addressed here various
central questions: How is the right plan computed? How is
the actual perception computed in an observer-independent
representation? We have merely supposed that it is possible
to perform these subtasks because we were chiefly
concerned here with the problem of including a mirror
neuron functional model into a visuo-motor control model.
All implementation details have been ignored so far, but the
next step of our research program is to implement this
model in a simulated environment. subsequently, we intend
to probe MEP by embodying the proposed visuo-motor
control model into a real robotic platform interacting with
another robot in a real environment.

Table 1: The MEP algorithm.
A l g o r i t h m :

M E P

Input: task: Agent Task, executeGoAction: Boolean
Global variables: environment
visualInputÅ read(environment)
handObjectFeaturesÅ AIPComputation(visualInput, task)
objectLoacationÅ where(visualInput)
vÅcoding(handObjectFeatures, objectLoacation)
planÅ canonicalComputation(v, task)
cÅ pop(plan)
IF (executedGoAction is TRUE) THEN
WHILE c is not NIL DO
environment Å perform(c)
evÅ EPGenerator(v,c)
visualInputÅ read(environment)
handObjectFeaturesÅ AIPComputation(visualInput, task)
objectLoacationÅ where(visualInput)
vÅcoding(handObjectFeatures, objectLoacation)
matchÅ mirrorComputation(v,ev)
IF (match is FALSE) THEN planÅ canonicalComputation(v, task)
cÅ pop(plan)
ENDWHILE

ELSE
WHILE c is not NIL DO
evÅ EPGenerator(v,c)
visualInputÅ read(environment)
handObjectFeaturesÅ AIPComputation(visualInput, task)
objectLoacationÅ where(visualInput)
vÅcoding(handObjectFeatures, objectLoacation)
matchÅ mirrorComputation(v,ev)
IF (match is FALSE) THEN planÅ canonicalComputation(v, task)
cÅ pop(plan)
ENDWHILE
ENDIF

1783

Acknowledgments
We wish to thank the Cognitive Science group of the Dept.
of Physical Sciences of the University of Naples Federico II
for useful and interesting discussion. R. Prevete thanks Prof.
G. Rizzolatti and his colleagues for the invaluable inputs
received during his stay at the Dept. of Neurosciences of the
University of Parma.

References
Arbib, M.A., Billard, A., Iacoboni, M., & Oztop, E., (2000).
Synthetic brain imaging: grasping, mirror neurons and
imitation, Neural Networks Special Issue 13, 975–997.
Arbib, M.A. (2004). From Monkey-like Action Recognition
to Human Language: An Evolutionary Framework for
Neurolinguistics, Behavioral and Brain Sciences.
Arbib, M.A. (2003). Towards a neurally-inspired computer
architecture, Natural Computing, 2, 1–46.
Asada, M., MacDorman, K.F., Ishiguro, H., Kuniyoshi, Y.
(2001). Cognitive developmental robotics as a new
paradigm for the design of humanoid robots, Robotics and
Autonomous Systems, 37, 185–193.
Billard, A., & Matari´c, M.J. (2001). Learning human arm
movements by imitation: Evaluation of a biologically
inspired connectionist architecture, Robotics and
Autonomous Systems, 37, 145–160.
Datteri, E., Teti, G., Laschi, C., Tamburrini, G., Dario, P.,
Guglielmelli, E. (2003). Expected perception in robots: a
biologically driven perception-action scheme", in
Proceedings of ICAR 2003, 11th International Conference
on Advanced Robotics, Coimbra, Portugal, June 30 - July
3, 1405-1410.
Datteri, E., Teti, G., Laschi, C., Tamburrini, G., Dario, P.,
Guglielmelli, E. (2003). Expected perception: an
anticipation-based perception-action scheme in robots, in
Proceedings of IROS 2003, 2003 IEEE/RSJ International
Conference on Intelligent Robots and Systems, Las Vegas,
Nevada.
Demiris Y., Johnson M. (2003). Distributed, predictive
perception of actions: a biologically inspired robotics
architecture for imitation and learning, Connection
Science, 15, 231-243.
Fadiga, L., Fogassi, L., Gallese, V., Rizzolatti, G., (2000).
Visuomotor neurons: ambiguity of the discharge or
‘motor’
perception?.
International
Journal
of
Psychophysiology, 35, 165-177.
Fogassi L., Gallese V., Buccino G., Craighero L., Fadiga L.,
Rizzolatti G. (2001). Cortical Mechanism for visual
guidance of hand grasping movements in the monkey, a
reversible inactivation study. Brain, 124, 571-586.
Gallese,V. (2003). A neuroscientific grasp of concepts: from
control to representation, Phil. Trans. Royal Soc. London.
Gallese, V., Fadiga, L., Fogassi, L., Rizzolatti, G. (1996).
Action recognition in the premotor cortex, Brain, 119,
593-609.

1784

Gallese V., Goldman A (1998). Mirror neurons and the
simulation theory of mind-reading. Trends in Cognitive
Sciences, 12, 493-501.
Jonas H. (1953). A Critique of Cybernetics. Social Research
20, 2, 172-192
Giese M A, Poggio T (2003). Neural mechanisms for the
recognition of biological movements and action. Nature
Reviews Neuroscience, 4, 179-192
Luppino G., Rizzolatti G., (2000). The organization of the
frontal motor cortex, News Physiol. Sci. 15:219-224, 2000
Makino T. and Aihara K., (2003). Self-observation Principle
for Estimating the Other’s Internal State – New
Computational Theory on Communication (Mathematical
Engineering Technical Reports METR 2003-36),
University of Tokyo, October.
Marom, Y., Malstros, G., Hayes, G. (2002), Toward a
Mirror System for the development of socially-mediated
skills, Proceedings Second International Workshop on
Epigenetic Robotics: Modeling Cognitive Development in
Robotic Systems, 94, Edinburgh, Scotland.
Matelli M., Luppino G, (2001). Parietofrontal circuits for
action and space perception in the macaque monkey,
Neuroimage, 14, S27-S32.
Miall RC. (2003), Connecting mirror neurons and forward
models, Neuroreport., 2;14(17):2135-7.
Oztop, E., Arbib, M.A. (2002). Schema design and
implementation of the grasp-related mirror neuron system,
Biol. Cybern., 87, 116–140.
Rizzolatti G., Camarda R., Fogassi L., Gentilucci M.,
Luppino G., & Matelli M. (1988). Functional organization
of inferior area 6 in the macaque monkey II. Area F5 and
the control of distal movements. Experimental Brain
Research, 71, 491–507.
Rizzolatti G, Fadiga L, Gallese V, Fogassi L (1996)
Premotor cortex andthe recognition of motor actions.
Cogn Brain Res, 3, 131–141
Rizzolatti G., Luppino G, (2001), The cortical motor
system, Neuron, 31, 889-901.
Rizzolatti, G., Fogassi, L., Gallese, V. (2001).
Neuropsychological
mechanisms
underlying
the
understanding and imitation of action, Nature Reviews
Neuroscience , 2.
Stamenov, M. L. (2002). Some features that make mirror
neurons and human language faculty unique. In M. L.
Stamenov and V. Gallese (Eds.), Mirror Neurons and the
Evolution of Brain and Language. Amsterdam: John
Benjamins.
Tetsunari Inamura, Yoshihiko Nakamura and Moriaki
Shimozaki (2002). Associative Computational Model of
Mirror Neurons that connects Missing Link between
Behaviors and Symbols, Proceedings of the 2002
IEEE/RSJ Intl. Conference on Intelligent Robots and
Systems EPFL, Lausanne, Switzerland.
Umiltà, M.A., Kohler, E., Gallese,V., Fogassi, L., Fadiga,
L., Keysers,C., Rizzolatti, G. (2001). I Know What You
Are Doing: A Neurophysiological Study, Neuron, 31,
155–165.

