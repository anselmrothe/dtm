UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Processing and Integrating Multimodal Material — The Influence of Color-Coding
Permalink
https://escholarship.org/uc/item/5ch098t2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Folker, Sonja
Ritter, Helge
Sichelschmidt, Lorenz
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

   Processing and Integrating Multimodal Material – The Influence of Color-Coding
                               Sonja Folker (sonja.folker@uni-bielefeld.de) and Helge Ritter
                                Neuroinformatics Group, Faculty of Technology, Bielefeld University
                                               P.O.-Box 100131, 33501 Bielefeld, Germany
                                                          Lorenz Sichelschmidt
                                       Faculty of Linguistics and Literature, Bielefeld University
                                               P.O.-Box 100131, 33501 Bielefeld, Germany
                              Abstract                                  can switch between the sources of information at will, he
                                                                        even can ignore one of the sources entirely or (re)consider
   Constructing effective learning material has always been a           parts of the text and the picture in a self-determined
   central issue in education, and is even more so in the time of       sequence and at his own pace. The aspect of control
   international student assessment. In our experiment we               becomes even more crucial with an increase in complexity:
   concentrated on the processing of typical multimodal                 our brain clearly evolved to process spoken language,
   textbook material (i.e. a written text with accompanying             however, the advantage of using written language to convey
   illustrations) and on how the processing and integration of          complex information is undeniable. And it has often been
   these different representational modalities can be improved by
                                                                        documented that the combination of a text with illustrations
   color-coding. Color-codes reduce search effort and thus
   produce similar effect to an increase in spatial or temporal
                                                                        has a positive effect: illustrations are known to draw the
   contiguity (Kalyuga, Chandler & Sweller, 1999). In this              reader’s attention and to ameliorate motivation,
   context, contiguity is defined as the adjacency of distinct          comprehension, and retention (see Carney & Levin, 2002).
   elements in general. By using eye-tracking methodology we               While the demonstrated benefit of multimodal material is
   chose a means that could provide detailed insights into the          highly relevant for instructional issues, the question of how
   actual process of information intake. Our results affirm the         the processing of these materials is cognitively achieved
   differences in processing verbal and linguistic material and         remains open. The first basic assumption concerning the
   show the advantage of color-coded material on processing             processing of multimodal material was made by Paivio
   efficiency and integration. This leads us to the conclusion that     (1986), who postulated two interconnected but functionally
   the genuine difficulty of multimodal material lies in the            independent subsystems for human information processing,
   integration of the different sources of information and that         a verbal and a nonverbal (pictorial) one. The verbal and
   especially learners with low prior knowledge can profit from         visual representations (logogenes and imagines) are
   an increase in coherence and contiguity (see Mayer, 2001).           considered to be built up separately; nonetheless referential
   Keywords: color-coding; eye-tracking; multimodality; text            links between corresponding logogenes and imagines can be
   and picture processing; coherence formation.                         established. The dual coding assumption is preserved in
                                                                        current cognitive models of multimodal information
                          Introduction                                  processing: Mayer (1993) explicitly presents a dual coding
                                                                        theory of learning from visual and verbal materials and later
In oral communication and instruction it is natural to use              models of Mayer (1997) and Schnotz and Bannert (1999)
visual and linguistic sources of information simultaneously.            also assume two clearly differentiated though in parallel
In line with the goal to provide more naturalistic learning             working channels for building up mental representations of
environments in educational contexts, multimedia                        texts and pictures.
approaches therefore often favor a combination of spoken                   However, the goal of learning with multimodal material
text with moving or static pictures to avoid split-attention            does not consist in building up separate representations of
effects (Mayer, 2001).                                                  different sources of information but rather to build up
   However, the research of Guan (2003) shows that the use              referential links and to integrate the information processed
of different representational modes addressing only the                 in both channels. There are different views as to the
visual modality (e.g. written text and static pictures) can             cognitive demands of this integration process: Rayner,
prove just as efficient as a dual modality presentation where           Rotello, Stewart, Keir and Duffy (2001: 219) affirm that
spoken text and static pictures are presented. At first glance,         “[p]resumably, most skilled readers are adept at alternating
this might be a surprising result: in understanding an                  between text and pictures to produce a mental model of the
illustrated text, text and pictures can only be considered              complete message”. Nevertheless it has to be kept in mind
sequentially, which should complicate the integration                   that reading (as information processing in general) depends
process, while in hearing a description of a picture while              on physiological processes and cognitive resources that are
looking at it, linguistic and pictorial information is accessed         necessarily restrained. Visual information intake is limited
simultaneously. At a second glance, good reasons can be                 to the area foveally and (depending on the type of stimulus
found for the use of "written-only" material: it gives the              material) parafoveally perceived during the fixations, i.e. the
reader more control over his intake of information, i.e. he             phases where the eye is kept relatively stable. Further
                                                                    690

processing is limited by attentional mechanisms (Liversedge              Previous studies on multimodal material have indeed
& Findlay, 2000) and the capacity of our working memory.              documented the positive influence of an increase in
   These restrictions implicate that the use of written               contiguity on different levels. As Mayer and Anderson
multimodal material runs the risk of asking too much of the           (1992) have shown, high tempo-spatial contiguity
reader, depending on the quality of the material on the one           constitutes the basis for a successful integration: pictures
hand and on the reader’s prior knowledge, his general                 have to be shown in the same time and spatially close to the
reading capacities and his interest and motivation on the             passages of the text they illustrate. Moreover, a high degree
other hand. In the latter case, even “good pictures” can              of contiguity should exist on the semantic level, i.e. text and
“fail”, i.e. they might not lead to the frequently                    pictures should be closely related to each other in regard to
demonstrated advantage over a text without illustrations              the content (Carney & Levin, 2002) and superfluous
(Weidenmann, 1989, but cf. Mayer, 2001). Two possible                 information should be suppressed to facilitate the integration
reasons for this failure can be identified: the reader might          process (Mayer, Heiser, & Lonn, 2001).
concentrate entirely on the text, fail to process the pictures           Up until now, studies on the contiguity of multimodal
sufficiently and therefore not profit from the additional             material mainly assessed the retention performance
information they provide. Or else the reader might be able to         depending on significant changes in the degree of contiguity
process the text as well as the pictures but not have                 (i.e. showing text and pictures simultaneously vs.
sufficient cognitive capacities to integrate the different            sequentially or suppressing superfluous information). There
representations.                                                      are few studies using eye-tracking in combination with
   The research by Weidenmann (1989) focuses on                       multimodal material; they reveal reciprocal influences of
processing difficulties. In his view, pictures are conceived          picture and text processing. If the text is longer and the
as easily accessible, as the eye quickly identifies the most          illustrations closely related to the text, switches of attention
informative details of the picture and adjusts the following          to the illustrations necessarily interrupt the text processing
eye movements accordingly. Thus picture processing often              sequence. These switches generally occur at major syntactic
stops at a superficial level giving the learner the illusion of a     and semantic boundaries (Hegarty & Just, 1989). The
full understanding that is in fact not being achieved.                picture viewing process is highly text-directed, i.e. the
Following Weidenmann, this risk of underestimating                    pictures are only considered after having read the text and
pictures is even higher if the picture is combined with a text,       according to the information the text provides (Hegarty &
as the text often is perceived as the better medium to                Just, 1993; Carroll, Young & Guertin, 1992).
provide the content to be learned. Drawing attention to the              As color-codes strengthen the referential connections
pictures by the means of instructions can therefore foster the        between separate information sources, the can create the
learning process (Peeck, 1993) - provided that the pictures           same effects as an increase in contiguity. Parting from the
actually risk being underestimated. As Weidenmann points              idea that color can produce strong bottom-up effects on the
out, this might not be the case if the task is perceived as           attraction of gaze and assist higher cognitive processes such
demanding, thus inducing a sufficient level of processing of          as structuring and coherence formation (Marcus, 1992),
the text and its illustrations.                                       structures in the illustration corresponding to words or
   But even if the two distinct sources of information are            phrases in the text were colored identically (see Fig. 2). For
sufficiently processed, the difficulty of integrating the             example: if the word “chromosome” was colored in blue,
information remains: to build up an integrated                        the fibrous structures in the schematic cell representing the
representation, the reader has to recognize the referential           chromosomes as well as the corresponding labels were
connections between the two sources; he has to align the              colored identically. The introduction of these color codes
sources in order to match corresponding parts, to detect              should have the same effect as an increase in contiguity,
inconsistencies and to add complementary information.                 facilitate the alignment and matching processes, and thus
Even without having detailed theoretical assumptions on               lead to an enhanced integration process (see Kalyuga,
how the integration process is actually accomplished, the             Chandler and Sweller, 1999).
alignment can be assumed to be facilitated if the material
itself underlines the existing referential connections between                                 Experiment
text and pictures. Following this view, good multimodal               The experiment we conducted was designed both to gain
material therefore is characterized by a high degree of               insight into the processing of multimodal material in general
contiguity and coherence.                                             as well as to test whether the use of color-codes can foster
                                           Verbal                     the processing and integration of this type of material.
             Text                      representation                 Standard material and color-coded material was tested on
                                                                      two separate groups of participants (control group and color
                                                                      group). The data of the control group serves to discuss
 + Contiguity                                   + Integration         general processing issues while a comparison between
                                                                      groups should yield information about the influence of
                                          Pictorial                   color-coding.
            Picture                    representation                    The changes in our material were rather subtle: content
                                                                      and configuration of the material remained unchanged.
                                                                      Moreover, the learning outcome mainly served as a control
     Figure 1: The influence of contiguity on integration.            as our main interest lay on the actual processing. Therefore
                                                                  691

we decided to use eye-tracking methodology to gain a finely            the understanding and as highly related to the text (median
grained and on-line access to multimodal information                   of 4.0 and 4.5 on a five-point scale resp.). Moreover, the
processing. As eye movements are closely correlated to the             topic had the advantage of being in principle known to the
reader’s allocation of attention and the accompanying intake           subjects (the mitosis is an obligatory matter in biological
of information (Just & Carpenter, 1987), their analysis                education in German High school) – and at the same time
allows for conclusions to cognitive processes.                         not too familiar. The choice of topic and a preliminary
                                                                       questionnaire assessing the subject’s expertise allowed for
Method                                                                 the control of prior knowledge, holding it at a consistently
Participants A total of 20 subjects with normal or                     low level. This is especially important as prior knowledge
corrected-to-normal vision were tested individually. The               can be considered as one of the most decisive factors for
color-blind or color-impaired subjects were allocated to the           effective processing (Mayer, 2001).
normal stimulus group. All subjects were students, 14                     The pictures were identically colored in both conditions.
females and 6 males, aged 20 to 34 years with a mean age of            In the color condition, passages of the text corresponding to
24.3 years with a standard deviation of ± 4.0 years. They              structures or labels in the picture were colored additionally
were paid for their participation in the experiment.                   (see Fig. 2). As the subjects were informed about the fact
                                                                       that the material was color-coded and even received an
Material We designed effective multimodal material, i.e.               example of color-coded stimulus material before starting the
material already displaying a high degree of contiguity. To            trial, they could consciously use the color to direct their
guarantee tempo-spatial contiguity, a standardized design              attention.
was chosen. A text with an average of 118.1 words was
presented on the left hand side of the screen whereas the              Recording and analysis of eye movements Eye
right side was divided in two equal parts, showing two                 movements were registered using the SMI EyeLink I eye-
pictures related to the text in chronological order (i.e. the          tracker. Only fixations exceeding a threshold of 100 ms
upper picture referring to the upper part of the text and the          were included in the analysis. In cognitive-oriented eye
lower picture to the lower part of the text, see Fig. 2). The          tracking research, a fixation threshold is usually introduced
pictures were schematized, suppressing superfluous                     for the following reasons: due to saccadic suppression,
information like details of cell structure (semantic                   information intake is considered to be possible only during
contiguity).                                                           longer fixations (Matin, 1974). In addition to this, the
   The material described the function and the different               threshold also serves to eliminate the noise due to unsteady
phases of mitotic cell division. The choice of the topic was           fixations (i.e. one long fixation is recorded as a suite of short
motivated by the following two aspects: the description of             fixations in one region).
the spatial configuration of cell bodies in the different stages          Both eyes were tracked. It is typically assumed that left
of mitosis necessitates the use of pictures (semantic                  and right eye movements are conjugated (Rayner, 1998) and
contiguity). An evaluation of the material showed that the             therefore could be expected to lead to the same experimental
subjects indeed perceived the pictures as being important for          results. We also tested the ocular dominance of the subjects:
                                                                       as expected most of them showed a right eye-dominance. As
             Interphase                                           cell membrane
             In the interphase, the genetic material can be found
             in the nucleus in the form of chromatin fibres. In         centrioles
             this “unwound” form, reduplication of the genetic
             material is possible. The duplicated fibres remain
             attached to each other at one specific point of the         nucleus
             fibres, the centromeres. At the end of the
             interphase, the nucleus contains two sets of genetic            chromatin fibers
             information that have to be separated and
             distributed in the following five phases of the                    Fig. 1: Cell in the interphase
             mitosis.
                                                                    reduplicated                            mitotic spindle
             Mitosis - Prophase
                                                                    centrioles
             In the first phase of the mitosis, the prophase, the
             chromatin fibre pairs start condensing into
             chromosomes. The centrioles reduplicate, and           dissolving
             the pairs move to the opposite poles. Between          nucleus
             them, the mitotic spindle develops. The                membrane
             membrane of the nucleus begins to dissolve.
                                                                                Fig. 2: Cell in the prophase
                                     Fig. 2: Example of color-coded stimulus material (translated).
                                                                  692

the issue of whether to use only the dominant eye for                 Discussion In line with existing studies our data show
analysis is an issue under current debate (Goldberg &                 significant differences in the attention allocation between
Wichansky, 2003), we decided to use the right eye for                 text and pictures (see Rayner, 1998): significantly more time
analysis.                                                             is spent and more fixations are made on the text region than
                                                                      while studying the illustrations. The results seem to support
Procedure First the subjects were asked to fill in a                  the hypothesis of Weidenmann (1989) that pictures in
questionnaire assessing their prior knowledge on the topic.           multimodal material are processed insufficiently and that the
All subjects then performed a visual acuity test with Landolt         text is considered as the main source of information.
rings as well as the Ishihara test for color-blindness.               Furthermore, this view is buttressed by the introspective
   All experiment-relevant instructions were presented in             data collected in the knowledge test: if the question related
written form on the computer screen in the course of the              to information that could be found in the text as well as in
experiment. The subjects were instructed to read the                  the picture, the subjects mostly named the text as their most
presented material thoroughly in view of a test that would            relevant source of information.
be given afterwards. To familiarize the subjects with the                However, one can argue as well that few fixations are
design, they first saw a stimulus example showing the same            sufficient to understand the gist of a scene, given that,
configuration as the test material; the example was unrelated         compared to reading, an increased extra-foveal intake of
in regards to the content, offering a short account of blood          information is possible in scene perception (Pollatsek,
transfusion. Subsequently, two example questions were                 Rayner, & Collins, 1984) and that the pictures only illustrate
presented (one text related multiple choice and one picture           part of the information given in the text. Following this
related recall question) to give the subjects an idea of what         assumption, the small number of fixations would only
would be asked of them in the knowledge test. During the              underline the processing differences between text and
reading of the stimulus items eye movements were recorded.            pictures. The control group data alone therefore does not
Between each item a drift correction was conducted.                   seem to provide grounds to argue for one of these
   The reading task was followed by the test for ocular               assumptions.
dominance, i.a. to prevent recency effects in the knowledge              In fact, some of our results confirm the typical differences
test. Then the subjects performed a computer-based                    in the processing of texts and pictures stated in literature:
knowledge test consisting of 24 questions referring either to         texts are processed with many short fixations, pictures with
the text or to the pictures or to both sources of information.        few and longer fixations. Interestingly, the difference in
The test comprised multiple-choice questions (i.e.                    fixation duration is not as pronounced as in processing text
recognition) as well as fill-in-the-blank tasks (i.e. recall) and     or pictures alone: in his review, Rayner (1998) gives values
two sorting questions.                                                of an average fixation duration of 330 ms during scene
   For each answer they gave, the students had to decide              perception and 225 ms during reading. While our reading
whether they considered the text, the picture or their own            data approximates this value, fixation durations on pictures
prior knowledge as their main source of information for               in a multimodal context seem to be clearly reduced
answering the question. The subjects always had the                   compared to scene perception. The text seems to provide
possibility to answer “I’m not sure” to the knowledge as              constraints for the picture perception process, rendering the
well as to the information source questions to prevent them           picture viewing process more effective. The analysis of the
from just answering by chance.                                        first ten fixations underlines the directive function of the
                                                                      text: in spite of the property of pictures to attract attention, it
                  Results and Discussion                              is mainly the text that is considered first (Hegarty & Just,
                                                                      1989).
Differences in text and picture processing                               As the discussion shows, an analysis of the control group
                                                                      data alone necessarily remains descriptive; it cannot yield
Results Statistical analysis of the control group data with           results on the quality of the processing or the degree of
pair wise t-tests yields the following results: There are             integration achieved. Differences in processing times
significant differences in the cumulated fixation duration.           between text and pictures might simply be due to
On average, subjects spent 56.5 seconds on reading the text           differences in information content (i.e. the text might simply
and only 20.8 seconds on the equally sized picture region             be more complex than the picture); differences in processing
(t(9)=8.496, p<.001). The pictures are processed with                 of pictures between conditions, however, should be due to
significantly less fixations (text average of 261.7 vs. picture       color-coding as the content of the material itself remained
85.5, t(9)=8.961, p<.001) of a significantly longer mean              unchanged.
duration (text 216.9 ms, picture 243.6 ms, t(9)=5.139,                   Therefore, a comparison to the data of the color group is
p<.01). If subjects received a question in the knowledge test         necessary to determine if color-coding actually leads to an
that related to information occurring in the picture as well as       enhanced processing and integration of the material. As
in the text region, the subjects perceived the text as the main       presentation in a multimodal context has a stronger
source of information, (t(9)=2.493, p<.05). Analyzing the             influence on picture processing than on the highly
scan path, we found that of the first 10 fixations, 7.8 are on        constrained text processing, we also expect changes to be
the text, only 2.2 on the picture region (t(9)=5.979, p<.001).        more pronounced in picture processing. Therefore, a
                                                                      comparison might provide evidence on the question of
                                                                      (in)sufficient picture processing as well.
                                                                  693

Effects of color-coding
   Results The subjects of the color group were significantly       Discussion The shorter processing times on the reading task
faster in processing the multimodal material: on average, it        show that the material in the color condition is easier to
took them 76.6 sec to process one page of the test material         process than the standard material. Color-codes seem to
while the subjects of the control group needed 97.1 sec             provide orientation and reduce search processes, thus
(t(18)=2.223, p<.05). However, an analysis of variance              freeing cognitive capacities (Kalyuga, Chandler & Sweller,
(ANOVA) reveals that the differences in the number of               1999). The differences in processing the knowledge test are
fixations and the cumulated fixation duration are only              approaching significance, the color group being faster in
approaching significance, lower values were found in the            answering the questions. The time advantage is not due to a
color group (284.0 vs. 347.2 fixations, F(1,18)=3.677, p<.1         less intensive reading or superficial completion of the
and 63.5 vs. 77.3 sec. fixation duration, F(1,18)=3.371,            knowledge test, as the scores on the test do not differ
p<.1). The ANOVA confirms the known differences in                  between the groups. Color-coding therefore seems to
attention allocation between text and picture as to the             facilitate the processing of multimodal instruction material
number of fixations (F(1,18)=241.658, p<.001) and the               and might even lead to more efficiently accessible
cumulated fixation duration (F(1,18)=207.629, p<.001) but           representations.
yields no significant interaction effect. Although there is a          As the text is accompanied by two different pictures, a
slight increase in the number of switches between the               minimum of four switches (from text to picture 1 and back
control condition and the color condition, this difference is       and from text to picture 2 and back) should occur. Given the
not significant (9.47 control vs. 12.12 color, t(18)=1.518,         complexity of the text, an average of 9.47 or 12.12 switches
p>.1). But the number of switches/second is significantly           does neither appear excessive nor represent a more or less
higher in the color condition than in the control condition         isolated processing as found by Carroll, Young and Guertin
(0.157 vs. 0.097, t(18)=4.344, p<.001).                             (1992). Due to the significant differences in processing time
   The significant differences in picture and text processing       between the two groups, the relative number of switches
together with our expectation that an increase in contiguity        over time seems more appropriate to reflect differences in
influences picture processing in particular motivate a more         the efficiency of the integration process. As the number of
detailed between-groups analysis. In fact, the cumulated            switches per second is significantly higher in the color
fixation duration as well as the number of fixations on the         condition, a more integrated processing can be postulated.
picture region are significantly reduced the color condition           Therefore our results indicate that the use of color-codes
(15.04 sec. vs. 20.80 sec., t(18)=2.120, p<.05, 62.56 vs.           in multimodal material has similar effects as an increase in
85.50 fixations, t(18)=2.182, p<.05). The comparison of the         contiguity and fosters its processing and integration. The
fixation duration on the text region between the two                detailed analysis of the eye-tracking data documents that
conditions, however, yields no significant results.                 this amelioration is not achieved by paying more attention to
   The two groups do not differ significantly in prior              the pictures. In contrast to Weidenmann’s (1989) hypothesis
knowledge or in performance on the knowledge test (mean             the data shows that the number of fixations on the picture
score prior knowledge: 23.4 (control) vs. 26.1 (color),             section as well as their duration is still reduced, this
t(18)=.489, p>.1; mean score knowledge test: 33.1 (control)         reduction being significant in contrast to the reductions on
vs. 34.1 (color), t(18)=.310, p>.1). However, the difference        the text regions. Even fewer and shorter fixations than in the
in the overall time for answering the questions is                  control condition seem to be sufficient for processing the
approaching significance, the color-group being faster than         picture.
the standard group (337.8 vs. 434.7 seconds, t(18)=2.023,              The fact that the pictures are sufficiently processed even
p<.1).                                                              in the color condition is corroborated by the data from the
   Aside from the attention allocation, the capability to           knowledge test. Questions concerning pictures are answered
answer the picture-related questions in the knowledge test          as well as text questions although the amount of free recall
correctly is an important indicator for sufficient picture          tasks is higher than for text related questions (90.91% vs.
processing. An ANOVA reveals that no significant                    57.14% recall questions) and therefore should have been
differences can be found between the two conditions in              more difficult to answer. The higher difficulty might have
answering the knowledge questions correctly (F(1,18)=.027,          been balanced out by the fact that pictorial material in
p>.1) and no interactions exists between the condition and          general proves to be more efficiently remembered (picture-
the question type (i.e. questions relating to text, pictures or     superiority effect (Paivio, 1986)) and by the fact that
text and pictures in combination). However, a significant           pictorial presentation of test items leads to better results in
effect as to the type of question can be found                      the knowledge test, especially if the subjects received the
(F(2,36)=16.505,       p<.001).     Subsequent       pair-wise      learning material in a pictorial form as well (Brünken,
comparisons of the mean values show that no significant             Steinbacher, Schnotz & Leutner, 2001).
differences exist in the amount of correct answers to picture          The reduced fixation times are worth further discussions.
and text questions (57.14% text and 63.64% picture                  The reduction can be interpreted as an increase in
questions, t(19) =1.684, p>.1). Only the performance on             processing efficiency; parts of the picture are more easily
questions relating to information represented in the text as        identified (i.e. aligned with their verbal description). The
well as in the pictures significantly surpasses the                 results of Carroll, Young and Guertin (1992), however,
performance on text and picture questions (t(19)=5.605,             seem to contradict this interpretation: if the caption of a
p<0.001 and t(19)=4.383, p<.001).                                   cartoon is shown before the picture longer fixations can be
                                                                694

found on the cartoon than if the material is presented in             Department of Linguistics and Literature, University of
reverse order. Carroll and colleagues attributed this to a less       Bielefeld.
explorative viewing pattern, indicating a more careful              Goldberg, J. H., & Wichansky, A. M. (2003). Eye tracking
processing of the picture with the objective of integrating           in usability evaluation: A practitioner's guide. In J.
linguistic and pictorial information. In contrast to the              Hyönä, R. Radach & H. Deubel (Eds.), The mind's eye.
experimental design by Carroll and colleagues, a less                 Amsterdam et al.: Elsevier.
explorative viewing pattern can be expected in both our             Hegarty, M., & Just, M. A. (1989). Understanding machines
conditions as the subjects always tend to consider the text           from text and diagrams. In H. Mandl & J. R. Levin (Eds.),
first. If the fixation duration indeed reflects the duration of       Knowledge acquisition from text and pictures.
the integration process, introducing color codes seems to             Amsterdam et al.: Elsevier.
accelerate it. As the performance on the knowledge test does        Hegarty, M., & Just, M. A. (1993). Constructing mental
not differ between groups, it is improbable that the                  models of machines from text and diagrams. Journal of
shortening of the fixation duration reflects an inferior degree       memory and language, 32, 717-742.
of integration or intensity of processing.                          Just, M. A., & Carpenter, P. A. (1987). The psychology of
                                                                      reading and language comprehension. Boston: Allyn &
                         Conclusion                                   Bacon.
   Our results underline the fact that texts and pictures are       Kalyuga, S., Chandler, P. & Sweller, J. (1999). Managing
indeed processed differently. No indications of insufficient          split-attention and redundancy in multimedia instruction.
picture processing can be found, as the time allocated to the         Applied Cognitive Psychology, 13, 351-371.
pictures can even be reduced in the color condition without         Liversedge, S. P., & Findlay, J. M. (2000). Saccadic eye
deterioration of performance on the knowledge test. It is             movements and cognition. Trends in Cognitive Sciences,
possible that the readers perceive the task as too complex            4, 6-14.
and the pictures as too important not to sufficiently process       Marcus, A. (1992). Graphic design for electronic documents
them.                                                                 and user interfaces. New York: ACM Press.
   The data also shows that the text is perceived as the main       Matin, E. (1974). Saccadic suppression: A review and an
medium for the acquisition of information. In trying to               analysis. Psychological Bulletin, 81, 889-917.
guide the reader’s attention one should therefore start from        Mayer, R. E. (1993). Comprehension of graphics in texts:
the text (as color-codes do). In our opinion the importance           An overview. Learning and Instruction, 3, 239-245.
and guiding function of the text justify the use of traditional     Mayer, R. E. (1997). Multimedia learning: Are we asking
textbook material even with a variety of other media at               the right questions? Educational Psychologist, 32, 1-19.
hand. This holds especially if the presented information is         Mayer, R. E. (2001). Multimedia learning. Cambridge:
extensive and complex and an audio presentation risks to              Cambridge University Press.
exceed working memory capacity (Kalyuga, Chandler &                 Mayer, R. E., & Anderson, R. B. (1992). The instructive
Sweller, 1999). The use of color-codes as a means of                  animation. Journal of Educational Psychology, 84, 444-
achieving contiguity effects and reducing search processes            452.
can also be recommended; color-codes increase the                   Mayer, R. E., Heiser, J., & Lonn, S. (2001). Cognitive
efficiency of processing for subjects with low prior                  constraints on multimedia learning. Journal of
knowledge and can easily be used in standard textbook                 Educational Psychology, 93, 187-198.
material. Most importantly, they seem to lead to a more             Paivio, A. (1986). Mental representations: A dual coding
integrated processing, thus maximizing the benefit of                 approach. Oxford, England: Oxford University Press.
multimodal material.                                                Peeck, J. (1993). Increasing picture effects in learning from
                                                                      illustrated text. Learning and Instruction, 3, 227-238.
                                                                    Pollatsek, A., Rayner, K., & Collins, W. E. (1984).
                     Acknowledgments                                  Integrating pictorial information across eye movements.
This research was funded by the German Research Council               Journal of Experimental Psychology: General, 113, 426-
(Graduate Program 256, Task Oriented Communication).                  442.
                                                                    Rayner, K. (1998). Eye movements in reading and
                         References                                   information processing: 20 Years of research.
Brünken, R., Steinbacher, S., Schnotz, W., Leutner, D.                Psychological Bulletin, 124, 372-422.
   (2001). Mentale Modelle und Effekte der Präsentations-           Rayner, K., Rotello, C. M., Stewart, A. J., Keir, J., & Duffy,
   und Abrufkodalität beim Lernen mit Multimedia.                     S. A. (2001). Integrating text and pictorial information.
   Zeitschrift für Pädagogische Psychologie, 15, 16-27.               Journal of Experimental Psychology, 7, 219-226.
Carney, R. N., & Levin, J. R. (2002). Pictorial illustrations       Schnotz, W., & Bannert, M. (1999). Einflüsse der
   still improve students' learning from text. Educational            Visualisierungsform auf die Konstruktion mentaler
   Psychology Review, 14, 5-26.                                       Modelle beim Text- und Bildverstehen. Zeitschrift für
Carroll, P. J., Young, J. R., & Guertin, M. S. (1992). Visual         Experimentelle Psychologie, 46, 217-236.
   analysis of cartoons. In K. Rayner (Ed.), Eye movements          Weidenmann, B. (1989). When good pictures fail. In H.
   and visual cognition. New York et al.: Springer.                   Mandl & J. R. Levin (Eds.), Knowledge acquisition from
Guan, Y.-H. (2003). The effects of multimedia presentations           text and pictures. Amsterdam et al.: Elsevier.
   on information processing. Doctoral dissertation,
                                                                695

