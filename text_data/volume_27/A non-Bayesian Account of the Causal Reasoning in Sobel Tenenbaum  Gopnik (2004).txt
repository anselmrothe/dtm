UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A non-Bayesian Account of the "Causal Reasoning" in Sobel, Tenenbaum &amp; Gopnik
(2004)
Permalink
https://escholarship.org/uc/item/4j60b10w
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Nakagawa, Masanori
Sakamoto, Kayo
Terai, Asuka
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              A non-Bayesian Account of the “Causal Reasoning”
                                         in Sobel, Tenenbaum & Gopnik (2004)
                                           Serban C. Musca (smusca@upmf-grenoble.fr)
             Psychology and NeuroCognition Lab - CNRS UMR 5105, University Pierre Mendes France (Grenoble 2)
                                      1251 Avenue Centrale, BP 47, 38040 Grenoble cedex 9, France
                                            Gautam Vallabha (vallabha@cnbc.cmu.edu)
                    Center for the Neural Basis of Cognition, Carnegie Mellon University, 4400 Forbes Avenue
                                                       Pittsburgh, PA 15213, USA
                                Abstract                               object A is placed on it by itself. Sobel et al. found that
                                                                       4½-year old children, and to a lesser extent, 3½-year old
   Sobel, Tenenbaum & Gopnik (2004) investigated the                   children, were both able to make the expected inferences,
   development of causal inferences in preschoolers in three           that is that object B is a blicket in the indirect screening-off
   experiments with tasks adapted from conditioning literature
                                                                       task, but not in the backwards-blocking task. Sobel et al.
   (backwards blocking and screening-off) and concluded from
   this indirect evidence that children develop a mechanism for        (2004) used these results to argue that children’s responses
   Bayesian structure learning. It is proposed that (a) the            are based on Bayesian structure learning rather than on
   differential performances in the two tasks are more likely due      learning of cause-consequence associations.
   to differential memory demands, and (b) the observed                    Though attractive and nicely formalized, the Bayesian
   developmental differences between 3½ and 4½-year old                account has two problematic limitations. First, there is a
   children may be due to maturation of the memory system,             conceptual problem. A Bayesian inference structure cannot
   with higher retroactive interference in younger children and        operate without an initial core of knowledge. If the theory
   lower retroactive interference in older children. This account      aims to explain the origins of this core of knowledge, one is
   is supported by simulations with Ans & Rousset's (1997,
                                                                       faced with a chicken and egg problem: children are
   2000) memory self-refreshing neural networks architecture.
   The implications of the account proposed here on a theory of        supposed to apply their statistical knowledge in order to
   causal relation learning are discussed.                             enhance some pre-existing knowledge "database", but this
                                                                       cannot explain where the initial core of knowledge comes
   Keywords: causal inference; retroactive interference;               from. Second, the tasks used by Sobel et al. (2004) are
   backwards blocking; screening-off; memory limitations;
                                                                       adapted from conditioning literature, and are designed to tap
   preschoolers;      developmental        maturation;   memory
   self-refreshing; artificial neural networks.
                                                                       into the memory system. To use these tasks as measures of
                                                                       causal reasoning, one has to assume that memory demands
                                                                       are the same for both groups of children. This assumption is
                           Introduction
                                                                       erroneous: Both the indirect screening-off and backwards-
Early knowledge of the causal structure of the world is                blocking results may be shown to be memory artifacts rather
thought to result from innate abilities or from interactions           than instances of causal reasoning. Further, the performance
with the environment during early childhood. In the latter             difference between the 4½ and 3½-year-olds can be
framework, a learning mechanism must be specified in order             explained as a maturation of the memory system rather than
to delineate a theory of causal relation learning. Sobel,              the development of a Bayesian mechanism. Our critique is
Tenenbaum & Gopnik (2004) have recently proposed such a                based on the simulation of memory as a “self-refreshing
theory, suggesting that children construct "a ‘causal graph’           neural network”.
– an abstract representation of the causal structure of a set of
variables – based on evidence about the conditional                       Memory as a self-refreshing neural network
probability of those variables" (Sobel et al., 2004, p. 306).
In particular, they proposed that children use Bayesian                 A common problem with neural network models of memory
reasoning to construct the causal graph, and tested these               is that of catastrophic forgetting. The memory of a neural
claims in two experiments. In both, children were told that             network resides in connection weights that are adjusted to
only certain objects (called blickets) cause a device (a                improve the network’s performance on the current training
blicket-detector) to be activated. In the “indirect screening-          set. Consequently, training on a new set S2 tends to
off” task, the children were shown that the detector is                overwrite the effects of prior training on set S1 (McCloskey
activated when two objects (A and B) are placed on it, and             & Cohen, 1989; Ratcliff, 1990). The problem can be
that it does not activate when object A is placed on it by             avoided if sequential learning (i.e. first S1 then S2) is
itself. Then, they were asked if each object was a blicket. In         transformed into concurrent learning (S1 and S2 trained
the “backwards blocking” task, the detector is activated                together). As concurrency is implausible for sequential
when two objects (A and B) are placed on it, and also when              learning (e.g. Blackmon et al., in press), it can be
                                                                   1582

approximated by having the network “internally” generate                 Sobel et al. (2004). In the experiment, the following
“pseudo-exemplars” representative of its previous training               protocol was used:
exemplars and intersperse these with exemplars from S2.                     (1) The children were familiarized with the task of using
This approach, introduced by Robins (1995), can be                       novel names for objects; they were shown a knob (or a tee-
implemented in a model with two complementary networks,                  joint) and told that it was a “dax” (or a “wug”).
NET1 and NET2 (Ans & Rousset, 1997, 2000; Ans,
                                                                            (2) The blicket-detector was demonstrated to the children
Rousset, French & Musca, 2002, 2004; French, 1997). Each
                                                                         using two blocks. Each was placed on the detector, and the
network consists of an input layer connected both to an
                                                                         child’s attention was drawn to the fact that one block (a
auto-associative target and to a hetero-associative target.
                                                                         “blicket”) activated the detector, while the other (a non-
   Ans & Rousset's (1997, 2000) dual-reverberated self-
                                                                         blicket) did not.
refreshing network (DRSR) is used here. This model works
as follows. (1) NET1 is trained on S1 exemplars to criterion.               (3) Two training trials ensured that the children
The auto-associative part learns the structure of the inputs,            understood the function of the detector; each block was
while the hetero-associative part learns the mapping to the              placed on the detector and the child was asked whether it
outputs. Training ends when the criterion has been reached               was a blicket or not.
on both parts. (2) A random input is presented to NET1’s                    (4) The experimental phase consisted of two trials using
input layer, cycled R times through the auto-associative part,           two new objects, A and B. This consisted of either the
then propagated through the network and mapped to a                      indirect screening-off or the backwards-blocking condition.
hetero-associative output. This input-output pair is called a               The stimuli for the simulations were created to match the
“reverberated pseudo-pattern” (PP). Many such PPs are                    above experimental conditions. Sixteen 10-bit binary
generated and used to train NET2; thus NET2 learns a                     vectors were generated, each of which was made up of five
generalization of the auto- and hetero-associative map learnt            zeros and five ones (randomly placed within the 10
by NET1. (3) When NET1 has to learn S2, its training                     dimensions of the vector). From these, 10 input stimuli – 4
involves exemplars from S2 interspersed with PPs generated               demonstration items, 4 training items, and 2 experimental
by NET2. In effect, NET1 learns new items from the                       items – were selected at random. A single stimulus (e.g. A)
environment and the old items from NET2. As a result,                    always consisted of the concatenation of a 10-bit nil vector
NET1 learns a combination of S1 and S2. A memory                         and of the 10-bit vector for stimulus A. A compound
consolidation parameter, C, determines the relative                      stimulus (e.g. AB) consisted of the concatenation of the
frequency of PPs to new exemplars in the NET1 training. If               10-bit vector for stimulus A and the 10-bit vector for
C is low, learning is biased toward the new material                     stimulus B (note that the leftmost 10 bits of the input layer
(causing more retroactive interference, RI); if C is high,               are nonzero only when there is a compound stimulus).
learning is biased toward the old material (causing more                 Finally, four 10-bit vectors (two with four ones and two
proactive interference).                                                 with three ones) were generated; these corresponded to the
                                                                         knobs and tee-joints in the familiarization phase of the
                         Simulations                                     experiment.
In the DRSR model used in our simulations, NET1 and                         The training of the network proceeded in four phases. At
NET2 were feedforward backpropagation networks trained                   the end of each phase, PPs were generated using NET1, and
with a gradient descent algorithm that minimizes the cross-              NET2 was trained on these PPs. Except for the first phase,
entropy error function (Hinton, 1989). Both NET1 and                     NET1 was trained on the current inputs and the PPs
NET2 had 20 input nodes, 8 hidden nodes, and 21 output                   generated by NET2 (one may think of NET2 as providing a
nodes (20 auto-associative nodes and 1 hetero-associative                summary of the training history for the ongoing learning by
node)1 and were trained with a learning rate of 0.01 and a               NET1).
momentum of 0.7. After each phase of training (described                    Phase 1: The “knob” and “tee-joint” inputs were
below), 104 PPs were generated by NET1 and used to train                 presented to NET1 and the auto-associative part of the
NET2. In all the simulations presented below R = 5, and C                network was trained on them. This “familiarized” the
was manipulated. C was set to 0.25 (low parameter value,                 network with the input space (however, this phase is not
high RI) to simulate the performance of 3½-year-olds, and                essential for the overall results).
to 10 (high parameter value, low RI) to simulate the
                                                                            Phase 2: The “demonstration” and “training” items were
performance of 4½-year-olds.
                                                                         presented to the network (in the experiment, the “training”
                                                                         trials were interactive, consisting of responses and feedback.
Simulation 1 and Simulation 2
                                                                         In the simulation, these were treated as additional
These simulations correspond to the "indirect screening-off"             demonstration trials). There were 8 items in all (4 blickets
and the "backwards blocking" conditions of Experiment 1 in               and 4 non-blickets); each was individually presented to the
                                                                         network with the hetero-associative target set to 1 for a
1
  Unless otherwise stated, training ends when the criterion has been     blicket and 0 for a non-blicket.
reached on both the auto-associative and the hetero-associative
parts of a DRSR network.
                                                                    1583

   Phase 3: This was the first “experimental” trial. The              After the completion of Phase 4, the network was
network was simultaneously presented with A and B and a            separately presented with the A and B inputs, and the
target output of 1. This input-output pairing is henceforth        activation of the output unit was taken to index a “blicket”
denoted as AB → 1.                                                 response (possibly based on a task-specific decision
   Phase 4: This was the second “experimental” trial. In the       threshold). Finally, the results for each simulation were
“indirect screening-off” condition (Simulation 1), the             averaged over 16 replications (on each replication, the 10
network was presented with only A and a target of 1                input stimuli were drawn at random from the pool of 16
(A → 1); in the “backwards blocking” condition                     10-bit vectors).
(Simulation 2), the network was presented with A → 0.                 Figure 1 shows the results for Simulation 1, and Figure 2
Other than this difference in Phase 4, Simulations 1 and 2         the results for Simulation 2 (note that the vertical scale in
were the identical in all other respects.                          Figure 2b goes from 0.7 to 1.0). Both simulations
                                                                   qualitatively match the behavioral results. Simulation 1
   Training proceeded until the RMS error for the (new)
                                                                   results are free from the ceiling effect that is observed on
training exemplars fell under 0.1 or for a maximum of 104
                                                                   stimulus B, and of the floor effect observed on stimulus A at
epochs. The training exemplars were presented in random
                                                                   age 4½.
order. Each PP from NET2 was generated “on the fly” and
used only once.
  Figure 1: Indirect screening-off condition: a) behavioral results (from Table 1 in Sobel et al., 2004, p. 312); b) simulations
                            with DRSR, with the memory consolidation parameter (C) manipulated.
   Figure 2: Backwards blocking condition: a) behavioral results (from Table 1 in Sobel et al., 2004, p. 312); b) simulations
                             with DRSR, with the memory consolidation parameter (C) manipulated.
                                                              1584

Simulation 3                                                           to transform sequential learning into concurrent learning.
The simulation corresponds to Experiment 3 in Sobel et al.             With this simplification, two-network self-refreshing
(2004)2. Children were given a close variant of the                    memory may be understood by analogy to a three unit
backwards blocking task in Experiment 1, but preceded by a             network with two input units (X and Y) connected to an
phase where the frequency of the blickets was manipulated.             output unit (O), with a linear activation function and weight
In this phase, a child was presented with 10 different blocks          update governed by the delta rule (Widrow & Hoff, 1960),
of which (a) 9 were identified as blickets and 1 as a non-             dwij = ε · acti · (target – actual). Note that the delta rule
blicket (the “common” condition), or (b) 1 was identified as          imposes a fixed point – if the net input is less than the
a blicket and 9 as non-blickets (the “rare” condition).               target, then weights from the active input units are
Children in the “common” condition were more likely to                increased; if the net input is greater, the weights are
say that B was also a blicket.                                        decreased. The “A” and “B” inputs are presented by
   The stimuli were those from Simulation 2, except for two           clamping input units X and Y (respectively) to 1.0.
additional vectors made up of five zeros and five ones. Out              For the indirect screening-off condition, imagine that the
of these 18 10-bit vectors, 16 input stimuli (2 demonstration         3-unit network is trained on {AB → 1} until the weights
items, 2 training items, 10 frequency-training items, 2               stabilize at 0.5 each. The second, new trial, is {A → 0}. In
experimental items) were selected at random. The same                 accordance with idea of a self-refreshing memory, the 3-unit
Phase 1 procedure as in Simulation 2 was used. Phase 2                network would be trained on both {AB → 1} and {A → 0}.
consisted of the presentation of “demonstration” items A′             Each time the network is presented {A → 0}, the weight
and B′ (the network was presented {A′B′ → 1}, then                    from X is decremented slightly; when {AB → 1} is
{A′ → 1} and then {B′ → 0}) and of “training” items A′′               presented, both weights increase. Over several training
and B′′ (the network was presented {A′′B′′ → 1}, then                 epochs, the weight from X slowly goes to 0 and that from Y
{A′′ → 1} and then {B′′ → 0}). This was followed by                   goes to 1.0. With C < 1, {A → 0} is presented more often,
additional training that manipulated the blicket frequency.           so the X-weight decreases faster and the Y-weight increases
The network was presented with 10 new input stimuli with 9            to compensate. Hence, in Figure 1b there is a slight
identified as blickets and 1 as a non-blicket (the “common”           advantage for the B responses with C = 0.25 over C = 10.
condition), or with 1 identified as a blicket and 9 as non-              For the backwards-blocking condition, again imagine that
blickets (the “rare” condition). After this training, Phases 3        the 3-unit network is trained on {AB → 1} until the weights
and 4 proceeded as before. Finally, the results for each              stabilize at 0.5. Then the network would be trained on both
simulation (the activation of the output unit in response to a        {AB → 1} and {A → 1}. When {A → 1} is presented, the
B input) were averaged over 25 replications (on each                  weight from X increases slightly. As a result, when
replication, the 16 input stimuli were drawn at random from           {AB → 1} is presented, the net input is greater than the
the pool of 18 10-bit vectors).                                       target output of 1.0. Because of the delta rule, weights from
   The results presented in Figure 3 concern the response to          both X and Y are slightly decremented. If {AB → 1} is
stimulus B only. The simulation results match very well the           presented less often (C < 1), the weight from Y decreases
behavioral results, except for the “rare” conditions in               slowly. If {AB → 1} is presented more often (C > 1), the
3½-year-olds (note that the vertical scale in Figure 3b goes          weight from Y decreases much more quickly. Hence, in
from 0.3 to 1.0). However, it is surprising that when blickets        Figure 2b, there is a substantial advantage for the B
are rare stimulus B is called more often a blicket than when          responses with C = 0.25 over C = 10.
blickets are neither common nor rare (81% blicket response               The results of Simulation 3 may be understood by
for stimulus B in the “rare” condition in 3½-year-olds in             assuming that the 3-unit network has a “bias” unit that is
Experiment 3 as compared to 50% blicket response for                  connected to the output unit and whose activity is fixed at
stimulus B in 3½-year-olds in Experiment 2). We thus                  1.0. If there are a variety of inputs and the target output is
propose that the discrepancy arises from a bias for                   1.0 most of the time (as in the training for the “common”
responding blicket in the “rare” condition of Experiment 3            condition) the bias weight will be positive and relatively
in 3½-year-olds.                                                      large. When the network is subsequently trained with
                                                                      {AB → 1} and {A → 1}, it is already predisposed to
                          Discussion                                  respond “1”, so the error will be small and the weights from
                                                                      X and Y would not change much. The “common”
Considering that only one parameter was manipulated and               conditions in Figure 3c (for both C = 0.25 and C = 10)
the networks were initialized with random weights, the                reflect this predisposition of the network to respond “1”. In
behavioral results of Sobel et al. (2004) were simulated              the “rare” condition, the target output during the frequency-
surprisingly well. The reasons for the model’s success are            training is usually 0.0, so the weight from the bias unit
quite straightforward – the self-refreshing mechanism tends           would either be negative or close to zero. Consequently, the
                                                                       changes in the weights from X and Y would be very similar
2
  Experiment 2 does not investigate the difference in performance      to those in the Simulation 2, viz. there would be a
between 3½-year-olds and 4½-year-olds, but replicates the results      substantial advantage for the B responses with C = 0.25
found in Experiment 1 with 4½-year-olds. For this reason, no           over C = 10.
additional simulation has been conducted for Experiment 2.
                                                                  1585

     Figure 3: Backwards blocking preceded by a manipulation of blickets' frequency: a) behavioral results (from Table 5 in
       Sobel et al., 2004, p. 325); b) simulations with DRSR, with the memory consolidation parameter (C) manipulated.
   The main import of the above discussion is that the                    Finally, we must note one point of concern regarding rate
network’s ability to match the data is not due to a complex            of learning. In the simulation, the model received extensive,
associative architecture. It stems from a straightforward              repeated training on the same two patterns, while in the
combination of a Rescorla-Wagner-type learning rule with               experiment the children are able to perform the task after
interleaved exposure. The DRSR architecture is a                       seeing the patterns only once. However, there may have
sophisticated and general way of managing the interleaving             been “internal” training or repetition as part of a cognitive
in the absence of the old training exemplars, but it is not            rehearsal process. Such a rehearsal is needed even in a
essential for the current purposes. Critically, children's             symbolic process (e.g. Bayesian inference over a causal
developmentally different performances were simulated by               graph), since the cognitive system needs some way of
manipulating the memory consolidation parameter that                   sustaining the symbols in memory as the symbolic processes
affects the level of retroactive interference. This suggests           unfold. Therefore we feel that the learning rate issue does
that the results presented by Sobel et al. (2004) in support of        not by itself disqualify the model as an account of the
the idea of a Bayesian structure learning mechanism may be             children’s cognitive performance.
explained by a memory limitation in young children that
fade away as they grow older. The network model also
allows us to make more fine-grained predictions regarding                                        Conclusion
the children’s performance. One consequence of a                        The main conclusion from our simulation is not a critique of
distributed representation for the inputs is that learning              Bayesian causal reasoning per se, but whether such
cannot be separated from generalization. If all the items               reasoning is necessary to account for the children’s
shown to the network as “blickets” in Phase 1 and 2 share               performance in Sobel et al. (2004). Our simulations have
certain properties (e.g. color, gross shape), then the network          shown that pure “memory operations” are sufficient to
would be more susceptible to classifying similar objects                account for indirect screening-off, backwards blocking, and
(and more resistant to classifying dissimilar objects) as               the effect of prior frequency. This suggests that for young
blickets in future trials. This can be tested in the experiment:        children (and maybe in general) the memory and reasoning
say all the objects classified as blickets in the demonstration         systems are intertwined in highly complex ways. In
and training trials are bright red, and in the trials for indirect      particular, the “nodes” in the causal graph, which Sobel et
screening-off (where {A → 0}) the “A” object is also bright             al. take as a starting point for reasoning, may actually be the
red. This might bias the child to respond that “A” is a                 end result of highly sophisticated cognitive processing to
blicket, even though the causal reasoning may suggest                   isolate and abstract certain parts of the world (analogous to
otherwise. In general, it is not clear whether children                 how our concepts of “circle” and “equilateral triangle”,
classify “blickets” as an abstract category (determined                 while starting points for geometric reasoning, are actually
purely by the detector) because this would go against the               the result of sophisticated cognitive abstraction). Possibly,
everyday experience in which objects belonging to a                     as children get older, they get socialized into a similarly
category usually have common features or at least have                  sophisticated cause and effect view. In other words, we
“family resemblances”. Thus there may be exposure-                      suggest that a child’s developmental interaction with the
dependent or similarity-based learning occurring in this                environment gradually coalesces as a core of knowledge.
experiment which a purely “causal reasoning” account may                The Bayesian structure learning proposed by Sobel et al.
not capture.                                                            (2004) may be appropriate for describing the operation and
                                                                   1586

development of rational processes that operate on this core         24th Annual Meeting of the Cognitive Science Society.
knowledge, but it does not appear to explain how that               Mahwah, NJ: Lawrence Erlbaum Associates.
knowledge arises to begin with.                                  Ans, B., Rousset, S., French, R. M., & Musca, S. C. (2004).
   Though we did not specifically address this question here,       Self-refreshing memory in artificial neural networks:
we would like to speculate on a possible explanation of the         learning temporal sequences without catastrophic
origins of causal reasoning. It is our sentiment that               forgetting. Connection Science, 16: 71-99.
associative learning of cause-consequence patterns is at the     Blackmon, J., Byrd, D., Cummins, R., Poirier, P., & Roth,
root of this ability. However, contrary to a model of               M. (in press). Atomistic learning in non-modular systems.
associative learning of the kind proposed by Rescorla &             Philosophical Psychology.
Wagner (1972), we suggest that the learning of cause-            French, R. M. (1997). Pseudo-recurrent connectionist
                                                                    networks: an approach to the ‘sensitivity-stability’
consequence patterns is achieved very gradually in a
                                                                    dilemma. Connection Science, 9, 353–379.
memory system where a memory self-refreshing mechanism
                                                                 Hinton, G. E. (1989) Connectionist learning procedures.
becomes efficient through a developmental maturation                Artificial Intelligence, 40, 185–234.
process during early childhood.                                  McCloskey, M., and Cohen, N. J., (1989). Catastrophic
                                                                    interference in connectionist networks: the sequential
                     Acknowledgments                                learning problem. In H. G. Bower (Ed.), The Psychology
SCM was supported in part by the European Commission                of Learning and Motivation, Vol. 24 (pp. 109–165). New
(research grant HPRN-CT-1999-00065) and by the French               York: Academic Press.
government (CNRS UMR 5105). GV was supported by the              Ratcliff, R. (1990). Connectionist models of recognition and
National Institutes of Health, USA (Grant MH64445). The             memory: constraints imposed by learning and forgetting
authors thank James McClelland for helpful discussions.             functions. Psychological Review, 97, 285–308.
                                                                  Rescorla, R. A., & Wagner, A. R. (1972). A theory of
                         References                                 Pavlovian conditioning: Variations in the effectiveness of
                                                                    reinforcement and nonreinforcement. In A. H. Black &
Ans, B., & Rousset, S. (1997). Avoiding catastrophic                W. F. Prokasy (Eds.), Classical conditioning II: Current
     forgetting by coupling two reverberating neural                theory and research (pp. 64–99). New York: Appleton-
     networks. Comptes Rendus de l'Académie des Sciences            Century-Crofts.
     Paris, Life Sciences, 320, 989-997.                          Robins, A. (1995). Catastrophic forgetting, rehearsal and
Ans, B., & Rousset, S. (2000). Neural networks with a self-         pseudorehearsal. Connection Science, 7(2), 123-146.
   refreshing memory: Knowledge transfer in sequential
                                                                  Sobel, D. M., Tenenbaum, J. B., & Gopnik, A. (2004).
   learning tasks without catastrophic forgetting. Connection
                                                                    Children’s causal inferences from indirect evidence:
   Science, 12, 1-19.
                                                                    Backwards blocking and Bayesian reasoning in
Ans, B., Rousset, S., French, R. M., & Musca, S. C. (2002).
                                                                    preschoolers. Cognitive Science, 28, 303-333.
   Preventing catastrophic interference in multiple-sequence
   learning using coupled reverberating Elman networks. In        Widrow, G., & Hoff, M. E. (1960). Adaptative switching
   W. D. Gray & C. D. Schunn (Eds.), Proceedings of the             circuits. Paper presented at the, Western Electronic Show
                                                                    and Convention, Institute of Radio Engeneers (IRE), New
                                                                    York.
                                                             1587

