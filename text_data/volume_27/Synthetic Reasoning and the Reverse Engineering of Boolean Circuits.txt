UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Synthetic Reasoning and the Reverse Engineering of Boolean Circuits
Permalink
https://escholarship.org/uc/item/8rh683md
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Johnson-Laird, P.N.
Lee, N.Y. Louis
Publication Date
2005-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

               Synthetic Reasoning and the Reverse Engineering of Boolean Circuits
                                              N. Y. Louis Lee (ngarlee@princeton.edu)
                                              Department of Psychology, Princeton University
                                                       Princeton, NJ 08544-1010 USA
                                              P. N. Johnson-Laird (phil@princeton.edu)
                                              Department of Psychology, Princeton University
                                                       Princeton, NJ 08544-1010 USA
                                Abstract                                  model that represents competing hypotheses, e.g., Thagard
                                                                          (2000).
   In synthetic reasoning, individuals assemble elementary                    Hence, despite a sizable literature in explanatory reasoning
   components into effective systems, such as the working                 and abduction, the underlying mental processes of synthetic
   mechanism of an unknown device. This paper proposes a new
                                                                          reasoning remain largely unknown. We therefore formulated
   theory of this ability, and reports two experiments investigating
   how individuals reverse engineer Boolean circuits with two
                                                                          a theory of synthetic reasoning, and carried out two
   inputs and an output. Experiment 1 supported the theory’s              experiments to test it. The next section describes our theory
   prediction that the complexity, and hence difficulty, of synthetic     and illustrates our test-bed of Boolean systems. A Boolean
   reasoning problems should depend on the number of                      system, such as an electrical circuit of switches, has a “logic”
   possibilities in which the assembled system works, the number          equivalent to negation, conjunction, and disjunction. This
   of components in that system, and the relations between the            logic also applies to concepts (e.g., Shepard, Hovland, &
   component parts. Experiment 2 generalized this finding, and            Jenkins, 1961), to sentential connectives (e.g., Johnson-Laird,
   showed that individuals develop two distinct strategies.               Byrne, & Schaeken, 1992), and to learning algorithms in
                                                                          artificial intelligence (e.g., Kearns & Vazirani, 1994). No-one
                            Introduction                                  knows for certain what makes Boolean problems difficult.
Synthetic reasoning is a sequence of mental steps that                    Our theory, however, makes clear predictions about their
individuals follow in assembling elementary components into               difficulty.
an effective system. When you explain an everyday event,
you synthesize your existing causal knowledge with new                                  A Theory of Synthetic Reasoning
information in order to explain the event. When you figure                 In order to construct a working model of a system, you need
out how a device works, you infer from the functions of each               to understand what the system does and how its components
of the device’s components the overall mechanism. Synthetic                work. Our theory postulates that individuals construct mental
reasoning calls for both deduction and induction, especially               models of systems, i.e., representations in which the structure
the form of induction that generates explanations, i.e.,                   of the model corresponds to the structure of the system
“abduction”. It occurs both in daily life and science. But, how            (Gentner & Stevens, 1983; Johnson-Laird, 2001). But, how
do people do it?                                                           do individuals construct such a model? Like any sort of
   Cognitive scientists have investigated a variety of aspects             thinking – with the possible exception of mental arithmetic –
of synthetic reasoning in both psychology and artificial                   the process of synthetic reasoning has to be treated as non-
intelligence (e.g., Johnson & Krems, 2001). Klahr and                      deterministic (Hopcroft & Ullman, 1979). As in deductive
colleagues have studied how individuals discover the function              reasoning (van der Henst, Yang, & Johnson-Laird, 2002) and
of a control on a toy robot (see, e.g., Klahr & Dunbar, 1988;              problem solving (Lee & Johnson-Laird, 2004), reasoners
Klahr, 2000). The participants write programs that control the             should develop different strategies as they learn to synthesize
robot, to try to discover the function of the control. The main            systems of the same sort. There are two main sorts of
finding was that individuals differ in whether they focus on               strategies that they are likely to develop: they may focus one
hypotheses about the control or on possible experiments. AI                at a time on the possibilities in which the system either does
researchers have proposed accounts of ‘abductive’ reasoning                or does not produce an output, or they may focus on each of
in which individuals generate explanations (for a review, see              the input components one at a time and try to account for its
Paul, 1993). These accounts, however, presuppose a pre-                    effects on the output. To grasp the difference between the two
existing set of putative explanations, i.e., they have finessed            strategies, consider the following problem in which
the problem of how individuals use knowledge to synthesize                 individuals have to assemble an electrical circuit containing
explanations. For example, the ‘set-cover’ approach selects                two binary switches, a battery, a light bulb, and some wires.
subsets of existing hypotheses, e.g., Allemang, Tanner,                    In this circuit, the light comes on when one or both of the
Bylander, & Josephson (1987). Similarly, the ‘explanatory-                 switches are up. Thus, the circuit has four different
coherence’ account relies on a handcrafted connectionist                   possibilities:
                                                                      1260

                Switch A      Switch B       Light                    Hence, the problem should be easier than one in which none
                Up            Up             On                       of the switches has this privileged effect.
                Up            Down           On                           Granted that individuals tend to focus on the system’s
                Down          Up             On                       possibilities or on its input components, independent systems
                Down          Down           Off                      should be easier to reverse engineer than dependent ones. In
                                                                      sum, three factors should determine the difficulty of
In the first sort of strategy, individuals try to account for each    synthesizing a system, at least a Boolean system: the number
possible outcome one at a time. In deductive reasoning,               of variable input components, the number of positive
individuals typically focus on what is true, but not what is          possibilities, and the relative independence of the input
false (see, e.g., Johnson-Laird & Savary, 1999). Hence, they          components. To test the theory, we carried out two
should be more likely to consider first the positive                  experiments calling for the reverse engineering of Boolean
possibilities in which the light comes on, rather than the            systems.
possibilities in which it does not come on. They accordingly
construct a circuit that accounts for the first positive                                       Experiment 1
possibility (e.g., when both switches are up, and the light            Experiment 1 examined the reverse engineering of three sorts
comes on), and then modify the circuit to account for the              of Boolean electrical circuit. On each trial, the participants
remaining possibilities. In the second strategy, they consider         saw a “black box” with two switches and a bulb. The
the effects on the light of each switch separately. For                computer displayed the four possible switch settings and
example, they notice that when one switch is up, the light             whether or not the bulb came on. Figure 1 presents such a
always comes on, and so they construct a circuit with only             problem. The participants’ task was to design the circuit
one switch that connects the ciruit. Then, they work out how           connecting the switches that yielded these contingencies. In
to insert another switch into the circuit so as to account for all     the and problem, the bulb came on only when both switches
the possibilities. Both strategies ultimately require individuals     were up (as in Figure 1). In the or problem, the bulb came on
to make sure that all the components yield the correct                when one or other switch was up or both of them were. In the
outcomes.                                                             or-else problem, the bulb came on only when one or other of
   This theory of strategies predicts that three factors should       the switches was up, but not both. Figure 2 shows the
affect the difficulty of synthetic problems. The first factor is      minimal solutions of the three problems in the experiment.
the number of variable components that the system contains.
A variable component is a component that has more than one
state, e.g., a switch. This factor is similar to Halford’s concept
of relational complexity, which he regards as sufficient to
account for complexity (see, e.g., Halford, Wilson, & Philips,
1998). The prediction, say, that a system with two
components should be easier to synthesize than one with two            Figure 1: The presentation of the and problem in Experiment
hundred components hardly warrants an experimental test.               1. This picture shows the four different combinations of the
   A second factor is the number of positive possibilities, i.e.,      switch positions and their effects on the bulb. It comes on
the possibilities in which the light comes on. Many studies of         only when both switches are up.
reasoning have demonstrated such effects (see, e.g., Johnson-
Laird, 2001). Hence, we can predict that the or problem in the         The theory predicts that the two independent problems (and
table above should be harder to synthesize than an and                 and or) should be easier than the dependent problem (or-
problem with only one positive possibility.                            else), because dependence plays havoc with the two strategies
   The third factor is more subtle. It is the dependence of the        that we described earlier. You cannot focus on one input
input components on one another in yielding the output. In             component at a time. The theory also predicts that the and
the case of the or problem above, each switch acts                     problem (one positive possibility) should be easier than the or
independently of the other to switch the light on. In the case         problem (three positive possibilities). The ease of each
of an and problem (see below), each switch acts                        problem should be reflected in the accuracy of the circuits,
independently of the other to switch the light off. In contrast,       fewer separate drawings to produce a correct solution, and a
an or-else problem (see below) is a dependent one. In this             faster time to produce it.
problem, the light comes on only when one or-else the other,
but not both of the switches, is up. Hence, the effect of one
switch depends on the other switch’s position. This notion of
dependence is similar to Vapnik’s (1998) notion of a non-
linear system. But, unlike linearity versus non-linearity,
dependence is a gradeable notion. Imagine a system
                                                                       Figure 2: The minimal Boolean electrical circuits for and, or,
controlled by three switches. If one particular switch makes
                                                                      and or-else problems. The circles represent bulbs, the
the light come on in, say, three out of the four positive
                                                                      rectangles represent batteries, and the switches are binary.
possibilities, the switch is relatively independent of the others.
                                                                  1261

Method and Procedure                                                                          Experiment 2
We tested 18 Princeton University students individually. The          The aim of Experiment 2 was to examine the strategies that
experimenter explained that their task was to design a circuit        individuals developed as they reverse engineered Boolean
for a “black box” that contained the following components: a          problems. It also aimed to generalize the results to a new
battery, a bulb, two binary switches, and as many wires as            domain of water flow systems. The task in this domain was to
necessary. Each switch had one input terminal and either one          assemble a water flow system from the following
or two output terminals, so that the switch could make or             components: a pump that supplied the water, two faucets, a
break one or two circuits. The experimenter explained: a              turbine, and pipes that were either straight or L-shaped.
switch can function in two ways. A “simple” switch uses one           Figure 4 shows the presentation of the and problem. The task
output terminal and closes or breaks a single circuit; whereas        was to design a system that ensured that the turbine ran only
a “complex” switch has two output terminals so that in one            with the appropriate positions of the faucets. The three
position it closes one circuit whilst breaking the other circuit,     problems in this domain were isomorphic to those in
and in the other position it has the opposite effect. The             Experiment 1; Figure 5 presents correct minimal solutions.
experimenter illustrated with examples how both sorts of              The theory predicts that the participants should employ the
switches worked. The aim of a circuit was to produce the              two principal strategies that we described earlier, either
effects of the switches’ positions on the light. The participants     focusing on one input component (i.e., binary switch) at a
carried out a practice trial for a black box with one switch and      time, or one outcome possibility at a time. It also predicts the
one bulb. The experimenter answered the participants’                 same trend of difficulty for both the electrical and water flow
questions, and then proceeded to the experiment proper. The           problems. Even though the participants receive no feedback,
participants drew diagrams of the circuits and they were              the second block of problems should be easier than the first
encouraged to draw as many as they needed on the answer               block.
sheet. The experimenter told them that they had seven
minutes to solve each problem, and that they would be timed.
The instructions and the problems were presented using the
PowerPoint program, and each participant received the three
problems in one of the six possible orders.
Results and Discussion
                                                                      Figure 4: The presentation of the and problem in a water
Figure 3 presents the number of correct responses and the            flow system in Experiment 2. This picture shows the four
overall mean latencies. The figure shows the predicted trend:        different combinations of the faucets’ positions and their
the and problem yielded more correct solutions than the or           effects on the turbine. It comes on, as shown in red, only
problem, which in turn yielded more correct solutions than           when both faucets are up.
the or-else problem (Page’s L = 237.0, z = 3.50, p <.01).
Likewise, the predicted trend occurred in the times to solve
the problems (Page’s L = 234.5, z = 3.08, p <.005). The mean
numbers of diagrams that the participants drew to reach a
solution or to exceed the time limit were 1.1, 2.4, and 3.8
diagrams for the and, or, and or-else problems respectively,
and this trend was also reliable (Page’s L = 194.0, z = 3.67, p
<.0005). The results accordingly corroborated the theory.             Figure 5: The minimal Boolean water flow solutions for the
                                                                      and, or, and or-else problems. The ellipses represent turbines,
                                                                     the rectangles represent water pumps, and the faucets are
                                                                     binary.
                                                                      Method and Procedure
                                                                      We tested 20 Princeton University students with two blocks
                                                                      of three problems. One block contained the three electrical
                                                                      circuit problems; and the other block contained the three
                                                                      water flow problems. The order of the two blocks, and the
                                                                      order of the problems within each block, were counter-
                                                                      balanced over the participants. The procedure was the same
                                                                      as in Experiment 1, with a training trial before each block of
                                                                      problems. However, in this experiment, the participants had
Figure 3: Mean latencies (of both accurate and inaccurate
                                                                      to think aloud as they solved the problems, they had 11
responses) and numbers of accurate responses in the three
                                                                      minutes to solve each problem, and they had to describe the
problems of Experiment 1.
                                                                      strategies that they had used in a post-experiment interview.
                                                                 1262

We recorded their protocols with a portable cassette tape            to the other end of faucet B so that the system would still be
recorder.                                                            closed when switch B was not up (2). She repeated this step
                                                                     to account for the third possibility in which faucet A was not
Results and Discussion                                               up and faucet B was up, and the turbine was running. This
The numbers of correct solutions corroborated the predicted          solution, however, was incorrect, because the turbine would
trend in both domains: the and problem yielded more correct          still come on when both switches were not up.
solutions (20 in both domains) than the or problem (9 in both
domains), which in turn yielded more correct solutions than
the or-else problem (5 in both domains, Page’s L = 269.0, z =
4.59, p <<.001; it was also highly reliable for each domain
separately). Figure 6 presents the mean times that the
participants spent on the problems, whether the solution was
correct or incorrect. These trends were highly reliable (Page’s
L = 272.5, z = 5.14, p <<.001). The trend was also reliable in       Figure 7: An example of the strategy of building a model to
the number of diagrams that the participants drew (means,            account for one possibility first, and then modifying to
excluding the final diagram, were 0.88, 4.28, and 4.88 for the       account for the other possibilities (see text).
and, or, and or-else problems respectively, Page’s L = 270.0,
z = 4.74, p<<.001). No reliable differences occurred in either          The second strategy was to focus on the effects of a single
accuracies or latencies between the two domains, or even             switch or faucet. Figure 8 shows how a participant (No.16)
between the two blocks of trials.                                    used this strategy to solve the electrical or problem. She first
                                                                     focused on the fact that the bulb always came on when switch
                                                                     A was up. She drew a complete circuit with only switch A
                                                                     (2). She then considered the possibilities in which switch A
                                                                     was down (3), and added switch B to the model (4). Then, she
                                                                     worked out which output terminals in the circuit
                                                                     corresponded with which switch positions, changing her mind
                                                                     about what the “up” position of switch A (5-6) and the “up”
                                                                     position of switch B (6-8) should be. Finally, she drew out the
                                                                     resulting model in full as a correct solution (9).
Figure 6: Mean latencies (of both accurate and inaccurate
responses) for the three problems in each domain in
Experiment 2.
   An analysis of the participants’ protocols showed that they
indeed developed two main strategies for synthesizing the
systems. These strategies were also borne out by their post-
experimental interviews. They did not necessarily use the
same strategy for all problems, and some participants even
switched from one strategy to another whilst they were
solving a problem.                                                    Figure 8: An example of the second strategy in which the
   As predicted, the first strategy was to consider each input-       participant focuses on the effects of a single switch on the
output possibility separately. The participants first                 bulb, and then extends the model to account for the second
synthesized a solution for one possibility, and then tried to         switch (see text).
modify this solution to capture the other possibilities. Figure 7
illustrates how one participant (No.3) used this strategy to                              General Discussion
solve the water flow or problem. She started with the                 When individuals try to reverse engineer a system, they need
possibility in which both switches were up and the turbine            to understand what the system does and how its components
was running, and constructed a working model for this                 work. They then have to assemble the components in a
possibility (1). She modified this model to capture the               synthesis that delivers the required performance of the
possibility in which faucet A was up and faucet B was not,            system. As the theory predicts, individuals tend to synthesize
and the turbine was running. She accordingly added a                  a circuit by accounting either for one switch or else one
branching pipe between the two faucets, which she connected           possibility at a time. The difficulty of the task follows from
                                                                 1263

this account: it depends on the number of variable                     because the participants were explicitly taught this use of the
components, the number of settings of them that yield                  switches, and because some participants used this switch in
positive outputs from the system, and the dependence of the            solving the inclusive or problems. But, we cannot as yet rule
system’s input components. Experiment 1 showed that both               out this putative explanation. The model-based theory of
the number of positive outputs and dependence affected                 synthetic reasoning has so far yielded reliable predictions.
performance. The participants found it easier to synthesize an         The theory extends to domains outside Boolean circuits, but
and circuit (one positive possibility) than an or circuit (three       we have yet to test its applications there.
positive possibilities). Even though an or-else circuit has only
two positive possibilities, it was hardest of all, because the                               Acknowledgments
two input components’ effects are dependent. Their positions           This research was supported by a grant from the National
interact. The difficulty in synthesizing an exclusive                  Science Foundation to the second author to study strategies in
disjunction is well known to “connectionists”: unlike                  reasoning (BCS-0076287). We thank Caren Frosch, Sonja
inclusive disjunction, it calls for “hidden units” if a network        Geiger, Sam Glucksberg, Geoff Goodwin, Cathy Haught, and
of units is to learn it (see McClelland & Rumelhart, 1986).            Ira Noveck for helpful comments.
   Experiment 2 corroborated these findings, showing that the
same trend occurred in synthesizing water flow systems.
                                                                                                  References
More importantly, the participants’ think-aloud protocols and
the post-experiment interviews showed that they did develop            Allemang, D., Tanner, M., Bylander, T., & Josephson, J.
two principal strategies. In one, the participants focus on a             (1987). Computational complexity of hypothesis assembly.
single positive possibility, and construct a circuit for it. They         Proceedings of the 10th International Joint conference on
then try to extend the circuit to cope with the other                     Artificial Intelligence, pp.1112-1117.
possibilities. In the other, they focus on a single switch, and        Feldman, J. (2000). Minimization of Boolean complexity in
construct a circuit that controls the output appropriately. They          human concept learning. Nature, 407, 630-634.
then try to extend the circuit to cope with the effects of the         Gentner, D., & Stevens, A.L. (Eds.) (1983). Mental models.
other switch.                                                             NJ: LEA.
   Are alternative theories likely to account for our results?        Halford, G.S., Wilson, W.H., & Phillips, S. (1998).
The most influential psychological theory views the search                Processing capacity defined by relational complexity:
for a solution to a problem as governed by a means-ends                   Implications for comparative, developmental, and cognitive
analysis (see, e.g., Newell & Simon, 1972; Newell, 1990).                 psychology. Behavioral and Brain Sciences, 21, 803-831.
But, as in many other synthetic tasks, our circuit problems are        Hopcroft, J.E., & Ullman, J.D. (1979). Formal languages and
not amenable to this heuristic. The goal of our problems was              their relation to automata. Reading, MA: Addison-
clear, but it was not one that allowed our participants to                Wesley.
envisage a position that was just a move away from the                Johnson, T.R., & Krems, J.F. (2001). Use of current
solution. Hence, they cannot work backwards from the goal.                explanations in multicausal abductive reasoning. Cognitive
Likewise, because both the number of positive possibilities               Science, 25, 903-939.
and the dependence of the input components affected the               Johnson-Laird, P.N. (2001). Mental models and deduction.
difficulty of the problems, it seems unlikely that relational             Trends in Cognitive Sciences, 5, 434-442.
complexity alone can account for performance (pace Halford             Johnson-Laird, P.N., Byrne, R.M.J., & Schaeken, W. (1992).
et al., 1998). In addition, some theories argue that the                  Propositional reasoning by model. Psychological Review,
complexity of Boolean concepts depends on the concept’s                   99, 418-439.
minimal description, i.e., the length of the concept’s shortest        Johnson-Laird, P.N., & Savary, F. (1999). Illusory inferences:
equivalent logical formula (see e.g., Feldman, 2000).                     A novel class of erroneous deductions. Cognition, 71, 191-
However, such accounts treat both conjunction and inclusive               229.
disjunction, but not exclusive disjunction, as the primitives of       Kearns, M.J., & Vazirani, U.V. (1994) An Introduction to
a logical formula. Hence, although these accounts can predict             Computational Learning Theory. Cambridge, MA: MIT
why an or-else problem should be harder than an or or an and              Press.
problem, they do so merely by stipulating that or-else is not          Klahr, D. (2000). Exploring science: The cognition and
allowed in their descriptive language. They also fail to                  development of discovery processes. Cambridge, MA: MIT
explain why an or problem should be harder than an and                    Press.
problem.                                                              Klahr, D., & Dunbar, K. (1988). Dual space search during
   Readers may argue that the or-else problems call for an                scientific reasoning. Cognitive Science, 12, 1-48.
insight (see, e.g., Knoblich, Ohlsson, Haider, & Rhenius,             Knoblich, G., Ohlsson, S., Haider, H., & Rhenius, D. (1999).
1999; Ormerod, MacGregor, & Chronicle, 2002), namely, the                 Constraint relaxation and chunk decomposition in insight
realization that instead of breaking or closing a single circuit,         problem solving. Journal of Experimental Psychology:
a switch can also direct the current into two different circuits          Learning, Memory, and Cognition, 25, 1534-1555.
in its two different positions. In our view, this possibility does     Lee, N.Y.L., & Johnson-Laird, P.N. (2004). Creative
not explain the difficulty of the or-else problems, if only               strategies in problem solving. In K. Forbus, D. Gentner &
                                                                          T. Regier (Eds.). Proceedings of the Twenty-Sixth Annual
                                                                  1264

  Conference of the Cognitive Science Society, Chicago, IL       Paul, G. (1993). Approaches to abductive reasoning: an
  (pp.813-818). Mahwah, NJ: LEA.                                   overview. Artificial Intelligence Review, 7, 109-152.
Rumelhart, D. E., & McClelland, J. L. (1986). Parallel           Shepard, R. N., Hovland, C. I., & Jenkins, H. M. (1961).
  distributed processing: Explorations in the microstructure       Learning     and      memorization      of    classifications.
  of cognition, (Vol. 1 & 2). Cambridge, MA: MIT Press.            Psychological Monographs: General and Applied, 75, 1-
Newell, A., & Simon, H.A. (1972). Human problem solving.           42.
  Englewood Cliffs, NJ: Prentice Hall.                           Thagard, P. (2000). Coherence in Thought and Action.
Newell, A. (1990). Unified theories of cognition. Cambridge,       Cambridge, MA: MIT Press.
  MA: Harvard University Press.                                  Van der Henst, J.-B., Yang, Y., & Johnson-Laird, P.N.
Ormerod, T.C., MacGregor, J.N., & Chronicle, E.P. (2002).          (2002). Strategies in sentential reasoning. Cognitive
  Dynamics and constraints in insight problem solving.             Science, 26, 425-468.
  Journal of Experimental Psychology: Learning, Memory,          Vapnik, V.N. (1998). Statistical learning theory. New York:
  and Cognition, 28, 791-799.                                      John Wiley & Sons.
                                                             1265

