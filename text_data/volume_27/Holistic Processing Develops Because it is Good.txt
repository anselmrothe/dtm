UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Holistic Processing Develops Because it is Good
Permalink
https://escholarship.org/uc/item/1cj064kz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Cottrell, Garrison W.
Zhang, Lingyun
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                       Holistic Processing Develops Because it is Good
                                      Lingyun Zhang and Garrison W. Cottrell
                                               {lingyun,gary}@cs.ucsd.edu
                                           UCSD Computer Science and Engineering
                                        9500 Gilman Dr., La Jolla, CA 92093-0114 USA
                            Abstract                               to be found in both targets and non-targets (high false
                                                                   alarms) and large, specific features are unlikely to gen-
   In this paper, we investigate the question, “what are           eralize to more than the image they are found in (high
   the best features for face identification?” Ullman et al.
   used mutual information as measurement of how good              misses). Intermediate complexity gives a good balance
   a feature is for a class [Ullman et al., 2002]. Their ex-       between the trade-offs of misses and false alarms. They
   periments suggested that features of intermediate com-          suggested that these features are represented after the
   plexity are best in tasks of face vs. non-face and cars         encoding of simple features in V1 but before the encod-
   vs. non-cars. We are interested in the tasks of face            ing of complex object views in anterior IT cortex, and
   identification and expression classification. We applied
   Ullman’s technique of finding features with high mu-            that the features of intermediate complexity are the nat-
   tual information with category labels to the tasks. We          ural result of being selected for visual classification.
   found that features of large sizes convey the most in-
   formation about face identity. Local features such as
   eyes and mouth are informative for identity in the con-
   text of large face areas. Yet they are not very infor-
   mative by themselves, especially for an image set with
   high variability of facial expressions. On the other hand,
   small sized features around the eyes and mouth contain
   relatively high information for expression classification.
   This suggests that the appropriate feature sizes are task
   dependent. We suggest that holistic processing of faces
   has developed because these features are optimal for face
   identification.                                                 Figure 1: The set of fragments extracted by maximizing the
                                                                   amount of information delivered. (a) The features found for
                                                                   faces. (b) Examples of images in the training set. (c) The
                        Introduction                               features found for cars. (adapted from [Ullman et al., 2002]
                                                                   with author’s permission).
In this paper, we investigated what the best features
are for face identification. Face identification is a sub-
ordinate level task [Diamond and Carey, 1986] and is                  Will features that are good for telling faces from ob-
known to be holistic or configural. Holistic process-              jects be good for identification? We expect more specific
ing is typically taken to mean that the context of the             features would be needed for face identification. Our re-
whole face has an important contribution to process-               sults show that features of large size are best for face
ing the parts, and suggests that subjects use some                 identity classification. Local features are not as infor-
kind of whole-face representation when processing faces:           mative as global ones because the variances of local fea-
they have difficulty recognizing parts of the face in              tures such as eyes and mouth across different images
isolation, and they have difficulty ignoring parts of              of the same person due to expressions and other fac-
the face when making judgments about another part                  tors are comparable to those across individuals. We also
[Carey and Diamond, 1977, Carey and Diamond, 1994,                 show that the features optimal for expression classifica-
Farah et al., 1995, Tanaka and Farah, 1993]. Configural            tion are of small sizes. The result suggests that holistic
processing means that subjects are sensitive to the re-            processing for faces has been developed simply because
lationships between the parts, e.g., the spacing between           it is good or even necessary for accurate identification.
the eyes.
   Ullman et al. proposed using a measure of the mu-                                       Methods
tual information between features and categories to find
the features that provide the most information relevant            Data Set
to classification problems [Ullman et al., 2002]. Their
experiments showed that features of intermediate com-              36 frontal images of 6 individuals (6 images each) from
plexity in size and resolution were best for classification        the FERET database were used [Phillips et al., 1998].
(faces vs. non-faces, cars vs. non-cars). Figure 1 shows           The images were aligned by rotating, scaling and crop-
the combination of features they found for faces and cars.         ping [Zhang and Cottrell, 2004]. Figure 2 shows the nor-
The intuition is that small, simple features are likely            malized face images, where each row is an individual.
                                                              2428

                                                               Figure 3: A Gabor function is constructed by multiplying
                                                               a Gaussian function by sinusoidal function [Daugman, 1985].
                                                               We used five scales with eight orientations.
                                                               (Figure 4). Gabor filter responses of a certain frequency
                                                               with all orientations on these grid points are collected.
                                                               Hence, one “patch” is a concatenated vector of 8 Gabor
                                                               filter responses at each grid point. Patches were of differ-
                                                               ent locations, sizes and frequencies. We collect patches
                                                               of size (2n − 1) ∗ (2m − 1) of all possible locations and
                                                               frequencies, i.e. size 1 ∗ 1, 1 ∗ 3, 1 ∗ 5, ..., 3 ∗ 1, 3 ∗ 3, ...
                                                               at all possible locations and frequencies.
                                                               Figure 4: Patches of different centers, sizes and Gabor filter
                                                               frequencies were taken from the images.
                                                                  Because we have normalized our images, we can de-
Figure 2: The 6 individual by 6 images from FERET. Each        fine corresponding patches in image coordinates. We de-
row is an individual.
                                                               fine corresponding patches to be the patches of the same
                                                               position, size and Gabor filter frequency across images.
Preprocessing                                                  (Figure 5). A patch is said to be present in an image if
                                                               the corresponding patch in the images has a correlation
Ullman et al. used raw pixel patterns of varying
                                                               bigger than the threshold (a parameter) with the patch.
size and resolution in their study, which is an unre-
                                                               Here we did not search across location for patch matches
alistic cortical representation of an image. Research
                                                               because the images were all normalized to approximately
suggests that the receptive fields of the striate neu-
                                                               the same layout.
rons are restricted to small regions of space, respond-
ing to narrow ranges of stimulus orientation and spa-
tial frequency [Jones and Palmer, 1987]. DeValois et
al. [DeValois and DeValois, 1988] mapped the recep-
tive fields of V1 cells and found evidence for multiple
loci of excitation and inhibition. Two-D Gabor filters
[Daugman, 1985](Figure 3) have been found to fit the
2D spatial response profile of simple cells quite well
[Jones and Palmer, 1987]. The complex cells are found                 Figure 5: Corresponding patches across images.
to approximately compute the magnitudes of the re-
sponses [Pollen and Ronner, 1983]. In the preprocess-          Measurements by Mutual Information
ing, the images were filtered with a set of overlapping
2-D Gabor filters in quadrature pairs at five scales and       Following Ullman et al.([Ullman et al., 2002]), the use-
eight orientations. Gabor filter responses are sampled at      fulness of the patches for face identification was mea-
every grid point on a rigid 23 by 15 grid (Figure 4).          sured by mutual information:
[Dailey et al., 2002]. The magnitudes of the filter re-                        I(C; F ) = H(C) − H(C|F )                     (1)
sponses were then z-scored across images (subtract mean
and divide by standard deviation so as to be zero mean         In the equation, H denotes entropy which measures the
and one standard deviation, so that every response is          uncertainty of the variable. Thus I(C; F ) measures how
treated equally).                                              much the uncertainty of variable C is reduced by know-
                                                               ing variable F . In other words, it measures how much
Patches                                                        information F conveys about C.
Patches of Gabor filter responses were taken from the             In our implementation, C and F are both binary vari-
images. A patch is a rectangle sample of grid points           ables. C denotes the binary variable of “the image is the
                                                          2429

face of the individual or not” for a certain individual. F
denotes the binary variable of “presence of the patch in
the image or not” for a certain patch.
   For patch i in image j, C = 1 for the 6 images belong-
ing to the same individual of image j, C = 0 for the rest
30 images; F = 1 for images in which patch i is present,
F = 0 otherwise. The mutual information can thus be
calculated as follows:                                               Figure 7: The mutual information of all the patches centered
                                                                     at the image center. The x axis is the width of the patch,
         I(C; F ) = −p(C) log p(C) − p(C̄) log p(C̄)                 and the y axis is the height of the patch. The big patches are
                                                                     on the top right while small patches are on the bottom left.
   +p(F )(p(C|F ) log p(C|F ) + p(C̄|F ) log p(C̄|F ))               The good patches are of large sizes.
   +p(F̄ )(p(C|F̄ ) log p(C|F̄ ) + p(C̄|F̄ ) log p(C̄|F̄ ))
   Mutual information is calculated between every in-                Winner Take All In this experiment, the classifica-
dividual and the patches from the images of the indi-                tion was carried out by voting of the patches. The best
vidual. This measures how much the presence of the                   100 (this number was arbitrarily used in the experiments
patch predicts identity. The best threshold for “pres-               reported in this paper) patches and their thresholds were
ence of a patch” was found for each patch by brute force             calculated from the training set. For the test set, 1 im-
search, from −0.9 to 0.9 by steps of 0.1. The threshold              age of each individual was taken as a “known” image.
with the highest mutual information was used for that                The other 30 were “novel.” For each novel image, the
patch. This is after the fashion of Ullman et al. Averages           identity was decided by calculating how many of the best
across corresponding patches from images belonging to                100 patches from a “known” image were present in this
the same individual were taken to measure how much a                 image and taking the identity of the image to be the
patch predicts this individual. Averages across individu-            identity of the individual with the most patches present.
als were taken to measure how much this patch predicts                  The 36 images of the test set were divided to 6 sets
identity.                                                            of “known” images (the columns of Figure 8), and with
                                                                     each as the “known” image set, the error rate was calcu-
                 Face Identification                                 lated. Table 1 shows the results. One issue that arises
The results showed that patches of large sizes had the               is how the Gabor filter responses on the test set are nor-
most information about identity. The best patches are                malized by z-scoring. We consider the z-score to be an
not whole face patches, but they do encode at least two              adaptation on an individual neuron level, that is, each
“traditional” features (eyes, nose, mouth). That is, they            complex cell is adjusting its response to be 0-mean and
encode the eye in the context of the nose and vice versa.            unit standard deviation. If this is slow, then the training
Figure 6 shows several patches with highest mutual in-               set z-scoring should be used. But if this is fast (the sub-
formation. Figure 7 displays the mutual information of               ject adapts to the test set), then the test set should be
all patches centered on the image. Large patches are                 used. We report both for completeness. That the test
usually preferred given same frequency scale and posi-               set is z-scored by the test set means that the test set’s
tion.                                                                mean and standard deviation are used, while that the
                                                                     test set is z-scored by the training set means that the
                                                                     training set’s are used. Note that there is a decrease in
                                                                     performance when the test set is z-scored by the training
                                                                     set’s mean and standard deviation.
                                                                              Table  1: Error rate in “winner takes all”
Figure 6: The best 6 patches. Frequency of 1 to 5 denotes                Training        Test         Test set      Error rate
from the highest Gabor filter frequency to the lowest. These                set          set        z-scored by (out of 180)
are the patches with the highest mutual information. Note
that some are similar to others because we do not eliminate             FERET1        FERET2          Test set       3.3% (6)
redundancy in the results reported in this paper, i.e., the best        FERET1        FERET2 Training set           8.3% (15)
combination was not considered at this stage as in Ullman et
al.’s work.                                                             FERET2        FERET1          Test set       6.1%(11)
                                                                        FERET2        FERET1 Training set           11.1%(20)
                     Generalization
To find out how well the patches we found generalize to             Thresholding In this experiment, we set a threshold
other face images, we extracted another set of 36 images            for “accepting the identity”, if the count of the patches
(6 individual by 6 images each) from FERET (Figure 8).              (from a “known image”) presented (in a novel one) is
In the following text, the earlier set will be referred as          above the threshold, then accept the identity of the
“FERET1” and this new set as “FERET2”.                              known image as the novel image’s identity. In this formu-
   We tested generalization in 2 ways.                              lation, none or more than one identity can be accepted
                                                                2430

                                                                            Figure 9: F-measure of FERET1.
                                                                Table 2: Threshold = 29, Training set = FERET1, Test
                                                                set = FERET2
                                                                         Test set          Miss        False alarm
                                                                       z-scored by (out of 180) (out of 900)
                                                                         Test set        2.2% (4)       2.2% (20)
                                                                       Training set      1.1%(2)       49.6% (446)
                                                               for the training set is maximized (0.993) when threshold
                                                               is in range [34,42]. The results are calculated by using
                                                               threshold of 38 (the midpoint of [34,42]) in the test set.
Figure 8: The new set 6 individual by 6 images from
FERET. Each row is an individual.
                                                               Table 3: Threshold = 38, Training set = FERET2, Test
                                                               set = FERET1
for one image. Note the threshold is the number of the
present patches and is different from the threshold for                  Test set          Miss        False alarm
deciding whether a patch is present or not.                            z-scored by (out of 180) (out of 900)
   For the training set, the 100 best patches were                       Test set       11.1% (20)      1.3% (12)
again calculated. Then the evaluation matrix of true                   Training set      3.3%(6)       24.2% (218)
positive, false positive etc. is calculated by thresh-
olding the number of presented patches.           The F-
measure[Salton and McGill, 1983] can thus be calcu-               The results generally got worse when z-scored with the
lated:                                                         training set’s mean and standard deviation. The effect is
                                                               larger in the thresholding method than the voting one.
                           2 ∗ recall ∗ precision
          F − measure =                                (2)     This may because the training set’s mean is off-center
                            recall + precision                 from the test set to some degree. The patches are thus
where                                                          distorted and more correlated. In the voting method,
                                                               the number of the present patches for the correct iden-
                           true positive                       tity goes up with the wrong ones so the maxima are
        recall =                                       (3)
                 true positive + f alse negative               not affected too much(Table 1), while in the threshold
                                                               method, misses decreased but many more false alarms
                           true positive                       occurred (Table 2,3) because the counts goes up. We
     precision =                                       (4)
                  true positive + f alse positive              would expect a larger training set should help because
   Figure 9 plots how the F-measure of FERET1 changes          the center (the mean) would be more general.
with the threshold. The F-measure is maximized (0.990)            The results were far from perfect. Yet it was encourag-
when the threshold is from range [28,30]. We then ap-          ing because in the tests, classification (or identity accep-
plied the threshold of 29 (the midpoint of [28,30]) to the     tance/rejection) was based on only one image per person,
test set of FERET. Table 2 shows the results. The first        and generalized to five.
row shows the results when the test set is z-scored with
its own mean and standard deviation and the second row                     Expression Classification
with the training set’s.                                       The results from last section showed that local features
   Table 3 shows the results when using FERET2 as              such as eyes and mouth are informative for identity in
training set and FERET1 as test set. The F-measure             the context of large face areas but not by themselves.
                                                           2431

Why are the main features on the face such as the eyes
and the mouth not good enough? Why features need to
include configural information?
   Our hypothesis is that local features vary a lot in dif-
ferent images of the same individual due to expression
and other possible factors. This variability could be com-
parable to that across different individuals, which makes        Figure 11: The best patches for each expression. The num-
local features bad predictors for identities. For example,       bers in the parentheses are the Gabor filter frequencies, 1 the
“happy eyes” from different individuals could be more            highest and 5 the lowest. Note that because the frequency
similar to each other than “sad eyes” and “happy eyes”           for the sad one is of low frequency, which means the patch
                                                                 covers more spatial extent than would be suggested by the
from one individual. Thus, depending on the similarities         patch size.
of local features, a happy face would be more likely to be
matched to another happy face rather than those of the
same identity. Following this reasoning, we would expect         we examined how smaller patches are doing for identi-
local features to be good predictors of expressions.             ties. Figure 12 shows mutual information between 3 by
   To test our hypothesis, we did similar experiments on         3 grid sized patches and identity of the POFA set. Note
36 images from POFA [Ekman and Friesen, 1976] (6 in-             that patches centered on the eyes or mouth are very bad
dividual by 6 expressions, Figure 10). Figure 11 shows           for classifying identities although they can be good indi-
the best patch found for each expression. (We do not             cator of expressions. Patches around hairlines are better
show the best ones for identification here for comparison        because the individuals’ hairstyles do not change in this
because the hairlines are always being chosen. This is           image set. Figure 13 shows that of the image set from
due to the fact that hairstyle of each individual dose not       FERET1. In this image set, the expressions of individu-
change in POFA, so it is the most reliable identification        als do not change as dramatically as those in the POFA,
feature.)                                                        so the patches around local features such as mouth and
                                                                 eyes do not show a drop in mutual information, but they
                                                                 are not as informative as the large ones we showed earlier
                                                                 (Figure 7).
                                                                 Figure 12: The mutual information of all 3*3 grid size
                                                                 patches for identity with the 36 images from POFA. The
                                                                 patches centered on the eyes and the nose are bad indica-
                                                                 tors of identity because the variability within an individual
                                                                 is largely due to different expressions.
                                                                 Figure 13: The mutual information of all 3*3 grid size
                                                                 patches for identity with the 36 images from FERET.
                                                                                          Discussion
                                                                 We applied Ullman et al.’s technique of finding features
                                                                 with high mutual information with category labels to the
Figure 10: The 6 individual by 6 expression face images          tasks of face identification and expression classification.
from POFA. Each row is an individual. Each column is an          Our results showed that large areas of faces are informa-
expression.                                                      tive for the identity, or rather, individual features need
                                                                 to be processed in context of larger areas of the face to
   As expected, local features are good predictors for ex-       be informative. On the other hand, local features are in-
pressions, which make them unlikely to be good predic-           formative for expression classification. This result may
tors for identities at the same time. To take a closer look,     suggest why holistic processing of faces has developed -
                                                            2432

simply because it is good or even necessary for identifi-           [DeValois and DeValois, 1988] DeValois, R. L. and DeValois,
cation, given individual features are not very useful by               K. K. (1988). Spatial Vision. Oxford University Press.
themselves.                                                         [Diamond and Carey, 1986] Diamond, R. and Carey, S.
                                                                       (1986). Why faces are and are not special: an effect of
                      Future Work                                      expertise. Journal of Experimantal Psychology: General,
A virtue of what we have done is its simplicity, but we                115(2):107–117.
also want to explore other issues. First, we do not search          [Ekman and Friesen, 1976] Ekman, P. and Friesen, W.
across images for patch matches, i.e. we assume a loca-                (1976). Pictures of Facial Affect. Consulting Psycholo-
tion as well. We would like to further investigate match-              gists Press.
ing patches at multiple locations. Then the training can            [Farah et al., 1995] Farah, M., Levinson, K., and Klein, K.
possibly be done without aligning the images. Second, in               (1995). Face perception and within-category discrimina-
the current work, mutual information of patches is calcu-              tion in prosopagnosia. Neuropsychologia, 33:661–674.
lated separately. We would like to further looking into
                                                                    [Jones and Palmer, 1987] Jones, J. P. and Palmer, L. A.
what combinations of features are optimal. Third, as                   (1987). An evaluation of the two-dimensional gabor fil-
Ullman et al. did, weights can be associated to patches                ter model of simple receptive fields in cat striate cortex.
depending how much information they provide for the                    Journal of Neurophysiology, 58(6):1233–1258.
classification task. Last but not least, the generalization
                                                                    [Phillips et al., 1998] Phillips, J., Wechsler, H., Huang, J.,
tests we did are limited. We would like to further test                and Rauss, P. J. (1998). The feret database and evalua-
our method and hypothesis with larger and more varied                  tion procedure for face-recognition algorithms. Image and
data sets.                                                             Vision Computing, 16(5):295–306.
                                                                    [Pollen and Ronner, 1983] Pollen, D. A. and Ronner, S.
                  Acknowledgement                                      (1983). Visual cortical neurons as localized spatial fre-
We thank PEN (Perceptual Expertise Network) for valu-                  quency filters. ieee transactions on systems. IEEE Trans-
able discussions, GURU (Gary’s Unbelievable Research                   actions on Systems, Man, and Cybernetics, 13(5):907–916.
Unit) for suggestions. This research project was sup-               [Salton and McGill, 1983] Salton, G. and McGill, M. (1983).
ported by NIMH grant MH57075 to GWC.                                   Introduction to Modern Information Retrieval. McGraw-
                                                                       Hill.
                        References
                                                                    [Tanaka and Farah, 1993] Tanaka, J. and Farah, M. (1993).
[Carey and Diamond, 1977] Carey, S. and Diamond, R.                    Parts and wholes in face recognition. The Quarterly
   (1977). From piecemeal to configurational representation            Journal of Experimental Psychology: Human Experimental
   of faces. Science, 195:213–313.                                     Psychology, 46A(2):225–245.
[Carey and Diamond, 1994] Carey, S. and Diamond, R.                 [Ullman et al., 2002] Ullman, S., Vidal-Naquet, M., and Sali,
   (1994). Are faces perceived as configuration more by adults         E. (2002). Visual features of intermediate complexity and
   than by children? Visual Cognition, 1:253–274.                      their use in classification. Nature Neuroscience, 5(7):682–
                                                                       687.
[Dailey et al., 2002] Dailey, M. N., Cottrell, G. W., Padgett,
   C., and Adolphs, R. (2002). Empath: A neural network             [Zhang and Cottrell, 2004] Zhang, L. and Cottrell, G. W.
   that categorizes facial expressions. Journal of Cognitive           (2004). When holistic processing is not enough: Local
   Neuroscience, 14(8):1158–1173.                                      features save the day. In Proceedings of the 26th Annual
                                                                       Cognitive Science Conference, Chicago, Illinois. Cognitive
[Daugman, 1985] Daugman, J. G. (1985). Uncertainty rela-               Science Society.
   tion for resolution in space, spacial frequency, and orien-
   tation optimized by two-dimensional visual cortical filters.
   Journal of the Optical Society of American A, 2:1160–1169.
                                                               2433

