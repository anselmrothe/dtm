UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Hierarchical Preferences in a Broad-Coverage Lexical Taxonomy
Permalink
https://escholarship.org/uc/item/9j8221x8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Ciaramita, Massimiliano
Johnson, Mark
Sloman, Steven
et al.
Publication Date
2005-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

       Hierarchical Preferences in a Broad-Coverage Lexical Taxonomy
                            Massimiliano Ciaramita (M.Ciaramita@ISTC.CNR.IT)
                                        Institute for Cognitive Science and Technology
                              National Research Council, Via Nomentana 56, Roma, 00161 Italy
                                   Steven Sloman (Steven Sloman@Brown.Edu)
                                 Department of Cognitive and Linguistic Sciences; Box 1978
                                   Mark Johnson (Mark Johnson@Brown.Edu)
                                 Department of Cognitive and Linguistic Sciences; Box 1978
                                           Eli Upfal (Eli Upfal@Brown.Edu)
                                          Department of Computer Science; Box 1910
                                                         Brown University
                                                   Providence, RI 02912 USA
                            Abstract                                                           ENTITY
   We investigate the problem of finding informative su-                LOCATION
                                                                                                               SUBSTANCE
   perordinates in a broad-coverage taxonomy of nominal                          ARTIFACT       ORGANISM
   concepts. We present results from a study which shows
   that speakers often exhibit strong preferences on what            CLOTHING         FACILITY                FOOD
   superordinate is more informative, together with a solid                    VEHICLE       ANIMAL                  CHEMICAL
                                                                                                         PLANT
   bias for specific classes. We then define the task of iden-
   tifying the properties that characterize such concepts in                INVERTEBRATE   VERTEBRATE
   the taxonomy as a ranking problem. We identify sev-                                                          FLOWER
                                                                          MAMMAL
   eral such properties which are related to properties of                                REPTILE         TREE
                                                                                                     FISH
   basic concepts. While these properties provide accurate                        BIRD
                                                                                          SNAKE
   sources of information for identifying the most useful                                           TURTLE
   superordinate, their interaction remains obscure.
                                                                                  ASP     VIPER
                        Introduction                                                     RATTLER
Lexical meaning is often summarized as category mem-               Figure 1. A simplified portion of the Wordnet taxonomy of
bership: a “convertible” is a “car”, a “trombonist” is             nominal concepts above the noun “rattler”.
a “musician”, “irritation” is a “feeling”, etc. Within
taxonomic organizations a nominal concept belongs to
all its superordinates; e.g., “rattler” belongs to “viper”,        taxonomy, and several hundred nouns found in a corpus.
“snake”, “reptile”, “vertebrate”, “animal”, “organism”.            We found that for a large fraction of nouns, more than
However, certain superordinates such as “snake” tend               84%, there is a superordinate which is significantly more
to be more important than others. Arguably the rele-               informative than the others; participants were mostly
vance is context-dependent; if a “rattler” was found on            unsure about nouns referring to abstract concepts such
an asteroid one would probably wonder how an “ani-                 as relations and states. In the second part of the paper
mal” managed to get there, more than how a “snake”                 we use the outcome of our study as a gold standard and
did. Nonetheless, in hierarchical categorization schemes           we investigate the properties that characterize informa-
people tend to prefer useful and efficient classes, in terms       tive superordinates. We frame the problem of choosing
of information content, i.e., concepts where the trade-off         the “best” superordinate for a noun as a ranking task.
between size of the category and similarity of its mem-            We investigate word-specific properties – those that can
bers is optimal (Gluck & Corter, 1985). Such concepts              be extracted from a word’s orthography, from corpus
are called basic (Brown, 1958; Rosch et al. 1976) and              data, and from hierarchical knowledge relating words –
are well-studied in humans (Murphy, 2002).                         to try to characterize informative superordinates.
   In this paper we address two aspects relevant to ba-               We found that word length provides the weakest pre-
sic categories. In the first part we investigate for what          dictor, while entropy and frequency, and especially func-
fraction of nouns in naturally occurring language there            tions that measure the association between the noun and
is a corresponding “favorite” superordinate. The goal is           the superordinate such as mutual information, are more
to estimate, at least as a first crude approximation, the          accurate. Finally, most surprisingly, we found that the
extent of this phenomenon. We examine this issue with              best predictor is the concept specificity; i.e., people have
a naming task in which we collected data from English              a strong preference for specific concepts. This finding
speakers concerning their preferences about different su-          suggests a simple hypothesis: that the data might be ex-
perordinate levels. We used a broad-coverage nominal               plained by a model that combines specificity and other
                                                               459

properties of basic categories. However, we show that the          artifact           34   substance     9  event           4
interaction of the different information sources is com-           person             32   attribute     9  possession      4
                                                                   plant              24   cognition     9  time            3
plex and the choice of the superordinate might depend              animal             23   food          8  process         3
on subtle semantic and cultural factors.                           act                20   group         8  phenomenon      2
                                                                   communication      17   body          6  feeling         2
                                                                   state              11   object        5  relation        2
      Basic Categories and Information                             location           10   quantity      4  shape/motive    1
The superordinates of a noun such as ”rattler” (viper,               Table 1. Number of test words per supersense category.
snake, reptile, vertebrate, animal, and organism) are
not equally useful. The choice of one extreme or the
other has both advantages and shortcomings. Broad                quences. Other applications in principle include all those
classes such as “organism” are easy to discriminate, e.g.,       that involve semantic classification tasks such as lexical
from “artifacts”, but are not very informative because           disambiguation or named-entity recognition, which cur-
they have very dissimilar subordinates like “animal” and         rently focus on repertories of, respectively, excessively
“plant” (cf. Figure 1). In contrast, specific classes such       narrow and excessively broad classes.
as “viper” contain very similar subordinates but are hard
to discriminate; e.g., it is harder to distinguish a “viper”            Speakers’ Hierarchical Preferences
from an “asp” than an “animal” from an “artifact”. It
seems intuitive that there should be an intermediate level       We ran a study in which we collected data about people’s
where an optimal balance between discriminative power            preferences within hierarchical classification schemes.
and similarity of the subordinates is achieved.                  The goal was to estimate the fraction of nouns with a
                                                                 consistently preferred superordinate and provide data
   A level with such properties is called a basic level in
                                                                 to determine which nouns showed such consistency and
human categorization (Brown, 1958; Rosch et al., 1976).
                                                                 what the properties are of preferred superordinates.
Basic categories are intermediate-level classes typically
expressed by phonologically simple (short) and frequent          Description of the Data
words; e.g., “chair” “tree” and “snake”. The basic-
                                                                 We found all nouns in the Brown corpus (Francis &
level is of great importance to human tasks like nam-
                                                                 Kučera, 1982), a balanced corpus of about a million
ing (Rosch et al. 1976), forming mental images (Tversky
                                                                 words, that have an entry in Wordnet (Fellbaum, 1998),
& Hemenway, 1984), and reasoning about objects’ func-
                                                                 a large ontology which contains 115,000 nouns which be-
tions and other attributes (Sloman & Ahn, 1999). Basic
                                                                 long to about 80,000 concepts called synsets hierarchi-
categories are most useful because they are accurate at
                                                                 cally organized according to the “is a kind of” relation
predicting distinctive attributes of their members and,
                                                                 (e.g., “pen” is-a “writing implement”). We searched for
at the same time, possess high category resemblance.
                                                                 single words and compounds such as “real estate” or
The basic level provides the most natural contrast be-
                                                                 “psychological warfare”1 . We found 12,218 such nouns,
tween categories and is the most useful for induction.
                                                                 roughly 80% are common nouns. We associated each
These properties can be expressed with information the-
                                                                 noun with its most common synset according to Word-
oretical, i.e., entropy-based, measures (Gluck & Corter,
                                                                 net; e.g., the first synset of rattler is “snake” while the
1985; Corter & Gluck, 1992) which quantify a category’s
                                                                 second is “freight-train”.2 Each synset in Wordnet is
power to reduce uncertainty about the features of its
                                                                 also tagged with a label corresponding to the categories
members – or the category utility. Gluck and Corter
                                                                 used by lexicographers to organize the development of
(1985; Corter & Gluck, 1992) show that this model is
                                                                 the database. There are 26 such categories which we
consistent with people’s performances in category learn-
                                                                 call supersenses (cf. (Ciaramita et al., 2003)); e.g., “per-
ing experiments. Informativeness does seem to be a par-
                                                                 son”, “animal”, “plant”, “artifact”, “location”, “feeling”
tial explanation for the basic-level. The basic-level refers
                                                                 etc. To select a set of words representative of the overall
to a hierarchical level that is picked out by a variety of
                                                                 composition of the Wordnet lexicon we binned the word-
different language-related tasks, in this sense it repre-
                                                                 synset pairs according to their supersense label. For each
sents an empirical phenomenon. Informativeness serves
                                                                 supersense ssi we randomly selected a number of word
as an explanation of the basic-level, almost all theories of
the basic-level appeal to informativeness which provides         senses equal to dN P|ss|ssi|
                                                                                              j|
                                                                                                 e, where N is the total num-
                                                                                         j
a natural and useful explanatory notion.                         ber of test words and |ssi | is the number of synsets with
   The information-theoretical interpretation of the ba-         supersense label ssi . For example, 14% of the synsets
sic level can be formalized precisely and implemented in         are “artifacts” while 0.05% are “motives”, respectively
computational models (cf. (Fisher, 1988) for an imple-           the larger and smaller supersense.3
mentation of the category utility model). Among other               We decided to test 250 common nouns, the number
applications, this is relevant to natural language pro-          of words that we estimated could be tagged in an hour.
cessing systems; e.g., in language generation. Basic-level           1
terms are crucial for generating utterances that, not only             For this purpose we used the functions “getindex()” and
                                                                 “morphstr()” from the Wordnet library “wn.h”.
sound natural, but also obey Gricean maxims of dis-                  2
                                                                       This information was compiled by the Wordnet lexicog-
course (cf. (Dale & Reiter, 1995)); e.g., the choice of          raphers based mainly on estimations from the Brown corpus.
“look at the Canis familiaris” vs. “look at the dog”                 3
                                                                       We only chose synsets that have no hyponyms, i.e., leaf-
or “look at the pitbull” has different pragmatic conse-          nodes, 62870 of the synsets in Wordnet (79%).
                                                             460

                         2000                                                                         Results
 Number of pairs
                         1500
                                                                                                      We tested 12 Brown graduate and undergraduate stu-
                                                                                                      dents on all 301 nouns and computed the relative fre-
                         1000
                                                                                                      quency of the preferences obtained by each superor-
                          500                                                                         dinate; e.g., for “turmoil”, “state” was chosen twice,
                                                                                                      P(state)=0.16, “disorder” 4 times, P(disorder)=0.33,
                            0
                             0            0.2          0.4         0.6          0.8         1         and “disturbance” 6 times P(disturbance)=0.5. The
                                  Relative frequencies of word−superordinate pairs                    upper portion of Figure 2 plots an histogram of the
                          100
                                                                                                      distribution of relative frequencies for all test word-
       Number of pairs
                                                                                                      superordinate pairs; a large fraction of superordinates
                           50
                                                                                                      have a relative frequency of 0, i.e., were never selected.
                                                                                                      In particular, very general candidates such as “entity”,
                                                                                                      “abstraction” or “psychological feature” are by and large
                            0                                                                         ignored. The lower portion plots the distribution of rela-
                            0.2     0.3         0.4   0.5    0.6    0.7   0.8         0.9   1
                                                                                                      tive frequencies of the 301 candidates that obtained most
                                    Relative frequencies of highest scoring pairs
                                                                                                      votes. A large fraction of the favorite superordinates ob-
Figure 2. Histograms of relative frequencies from the speakers                                        tained more than half of the votes, about 70% of these
data for all 2,228 test word-superordinate pairs (above) and for
the 301 superordinates that participants chose the most (below).                                      have a relative frequency of 0.6 or higher.
                                                                                                      Statistical Analysis
                                                                                                      To estimate the fraction of nouns for which there was
Table 1 summarizes the number of words per each super-                                                one clear favorite superordinate, and evaluate the con-
sense category generated for this value of N . In addition                                            sistency of the experimental data, we performed a sta-
to the common nouns we selected a set of 51 proper                                                    tistical analysis. First we used the K statistic (c.f. Di
nouns, which are also in Wordnet, for the supersense
categories “person” “group” and “location”. These three                                               Eugenio & Glass, 2004). K = P (A)−P       (E)
                                                                                                                                          1−P (E) , where P (A)
categories alone cover more than 80% of all proper nouns.                                             is the agreement between participants and P (E) is the
These 301 common and proper nouns represented our                                                     expected agreement at chance. Unfortunately K proved
sample of nouns appearing in naturally occurring lan-                                                 inadequate to our case. The data consists of a single
guage. In a pilot study we tested 10 participants on                                                  row of values for each noun, often characterized by very
a different set of 213 nouns. We learned that some of                                                 skewed distributions of votes. These cases yield odd val-
the participants didn’t know several of the words. Dur-                                               ues for K; e.g., if a category has 11 votes P (A) = 0.83,
ing the development of the final data set we excluded                                                 P (E) = 0.84 and K = −0.0625. For values of K close
obscure nouns and nouns for which the first sense ac-                                                 to 0 agreement is assessed as close to chance, while a
cording to Wordnet was clearly not the most frequent                                                  generally accepted cutoff for “moderate” agreement is
sense in current use; e.g., “hot dog” as “exhibitionist”                                              0.67 (Agresti, 1992); although, determining significance
instead of “sandwich”.                                                                                levels for K is problematic in itself (Fleiss (1981) for ex-
                                                                                                      ample indicates the interval 0.40-0.75 as an indicator of
Description of the Test                                                                               “fair to good agreement, beyond chance”). In our case
                                                                                                      the K statistic fails to provide a meaningful assessment
                                                                                                      of the agreement rate because the expected agreement
Participants were presented one test word at a time
                                                                                                      at chance tend to be unreasonably large especially when
on a computer monitor in randomized order. Together
                                                                                                      the distribution of votes is more skewed; i.e., when there
they saw a numbered list of candidates, also random-
                                                                                                      is more agreement. Di Eugenio and Glass (2004) call
ized, the superordinates of the test word. Each super-
                                                                                                      this the “prevalence” problem with K.6
ordinate was expressed by one noun, the first in the list
                                                                                                         Based on these considerations, we developed an alter-
for that synset;4 e.g., one test noun is “turmoil” and
                                                                                                      native analysis of the data. The aggregated data for each
the list of candidates is: “state”, “disorder” and “distur-
                                                                                                      word defines a multinomial random variable which is the
bance”. Participants were asked to choose which term
                                                                                                      result of an experiment consisting of n = 12 trials, the
they would use to answer the question “What kind of
                                                                                                      number of participants, with k possible outcomes, the
thing is this?”.5 The total number of candidates, i.e.,
                                                                                                      number of superordinates. We indicate with k1 the cat-
test word-superordinate pairs was 2228, or 7.4 candi-
                                                                                                      egory that obtained more votes from the data. If there
dates per word on average. Participants were explicitly
                                                                                                      is no agreement among participants one would expect
told that there were no wrong answers – all candidates
provided a correct explanation – and they could imag-                                                    6
                                                                                                           Computing P(E) as 1/k, where k is the number of cat-
ine a situation in which somebody, who didn’t know the                                                egories, thus the theoretical expected agreement at chance,
meaning of the word, asked the question to which they                                                 does not solve the problem. The outcomes of K are more
had to answer using only one of the words in the list.                                                meaningful but still suspicious; e.g., in the case of “tabloid”
                                                                                                      9 participants chose “print media” (75%), 2 chose “journal-
                                                                                                      ism” and 1 “medium”; this yields a value of K of 0.51 which
            4
                                                                                                      is still below the commonly accepted threshold for moderate
                     This ordering was also compiled by the lexicographers.                           agreement. For completeness we report the average K value
            5
                     Or “Who is this?” if the test word was a person’s name.                          on all nouns which was equal to 0.47.
                                                                                                461

  w               k     k1 /P (k1 )           P (H0 )    Sig         more than a “police”, “organization”, “administrative
  altruism        8     unselfishness/0.42    0.095      NO          unit” etc.). On average P (H0 ) was equal to 0.0317, 0.038
  forum           4     meeting/0.75          0.002      YES         for common nouns alone. This results prove that for a
  sidewinder      13    snake/0.917           0          YES         large fraction of nouns, which are instances of very dif-
                                                                     ferent semantic categories from “artifacts” and “plants”
Table 2. Three examples of the results of the significance test:     to “substances” and “groups”, there is one superordinate
w is the test word, k is the number of candidates, P (k1 ) is
the probability of the highest-scoring category from the data.       which is clearly more informative than the others for a
P (H0 ) is the probability of H0 estimated with the simulation.      significant number of participants. This means that the
                                                                     capacity for recognizing the most informative taxonomic
                                                                     level has quite broad conceptual coverage. Furthermore,
the distribution of votes to be “approximately” uniform.             while different people might have different preferred su-
Within this model one can define a null hypothesis ac-               perordinates, participants showed a solid agreement on
cording to which the probability of each outcome is the              which superordinate might be the most informative for
same; i.e., H0 : p1 = p2 = ... = pk . A multinomial exper-           somebody else, i.e., in a shared context.
iment under H0 can be performed by generating one of
the k possible categories at random n times. From the                              Ranking Superordinates
outcome of this experiment the probability of the most               We now investigate the properties that characterize the
likely category is computed. If this value is greater or             most informative superordinates of nouns.
equal to P (k1 ) then it is possible, under H0 , to gener-
ate a distribution that is consistent with the data. After           Preliminaries
repeating this experiment, the fraction of times H0 is               One way of formalizing the task of recognizing the most
consistent yields the significance level at which H0 can             informative categories in a taxonomy is as a ranking
be rejected. We ran this experiment 10,000 times.                    problem. We adapt here a notation used for the prob-
   Notice that in this model a simulated distribution is             lem of re-ranking parse trees (Collins, 2000). In our case
consistent with H0 not just when the distribution is                 there are n = 301 test words, for each word wi there
close to uniform, but, more conservatively, when sam-                are ki possible superordinates of concept ci , the leaf-
pling under H0 it is possible to generate a distribution             concepts wi belongs to. We define as cij the jth su-
with one “spike” that is consistent with the experimen-              perordinate of ci and ci1 the highest scoring candidate
tal data. For example, the following is the data for                 according to the results of the experiment; i.e., the most
the noun “apostle”: “entity/0”, “living thing/0”, “or-               informative superordinate. The goal in a ranking prob-
ganism/0”, “causal agent/0”, “object/0”, “advocate/1”,               lem is to find good scoring functions F (cij ); i.e., func-
“person/3”, “believer/3”, “supporter/5”. This is hardly              tions that assign a score to ci1 that is higher than the
a uniform distribution of votes, 5 categories out of 9               score for the other candidates cij . More precisely we are
have no votes and there is one with more than 40% of                 interested in functions that minimize a ranking loss func-
the votes. However, this is a non-significant case with              tion, which counts the number of the time a candidate
P (H0 ) = 0.062, because more than 5% of the times it                cij 6= ci1 is scored by F (.) higher than ci1 :
is possible to generate a distribution where the proba-
bility of the category with more votes, whichever it is,                                    Xn X ki
is greater or equal to P (supporter). Table 2 illustrates                    RankLoss =             JF (ci1 ) < F (cij )K    (1)
three more cases with different significance levels.                                         i  j≥2
Discussion                                                           where J.K is the indicator function.
For 84.4% of the words H0 is rejected with p < 0.05;
i.e., 84.4% of the time there was a superordinate which              Basic scoring functions
was chosen as more informative by a large enough num-                We define a set of scoring functions based on known
ber of participants. We found 249 different most infor-              properties of basic categories. In particular we are in-
mative superordinates, the most frequent are “person”                terested in properties that can be extracted from cor-
(11), “plant part” (8), “plant” (7), “animal” (4). The               pus data or from the taxonomy. Basic categories are
words on which there is less agreement all refer to ab-              typically expressed by short frequent words (Rosch et
stract concepts: “act”, “cognition”, “communication”,                al., 1976). They dominate many subordinate categories
“quantity”, “relation”, “state”, and “time”, with aver-              very similar to each other (Gluck & Corter, 1985), hence
age P (H0 ) = 0.11. It is possible that the organization             if we consider a concept as a random variable whose pos-
of such classes within a taxonomic structure does not re-            sible outcomes are its children concepts then this vari-
flect how people tend to categorize them. The opposite is            able should be characterized by high entropy. For ex-
true of proper nouns. Participants were, in general, abso-           ample, a concept like “tree”, which dominates several
lutely positive of what kind of thing (or who) each proper           kinds of trees, many of which have similar frequencies
noun was; e.g., Baltimore is a “city” (much more than                (oak, pine, elm, redwood, etc.), has a higher entropy
an “urban area”, “municipality”, “location”, “district”              than “entity” which dominates very dissimilar things.
etc.), Elvis Presley is a “rock-star” (much more than a              The information-theoretical interpretation of the basic
“musician”, “singer”, “performer”, “entertainer”, etc.),             level leads also to a characterization of good superordi-
and Scotland Yard is a “law enforcement agency” (much                nates as those which provide the greatest reduction in
                                                                 462

                             Ranking     function                     Since each word can have a different number of cate-
       Score   L       H        FR        LR       PMI    SD          gories and there are a few cases in which there are two
       RA      44.4    59.1     61.6      70.4 79.0       87.0        correct answers, i.e., two highest scoring classes, we com-
       EM      12.0    24.9     26.2      35.9 46.5       56.1        puted the ranking error rate with the following variant
                                                                      of Equation 1 which is used for multi-label ranking prob-
           Table 3. Results of all the ranking functions.             lems (Schapire & Singer, 2000):
                                                                                            k i
                                                                                         1X     1
 uncertainty about the target noun, or that are strongly                        ER =               JF (ci1 ) ≤ F (cij )K       (2)
                                                                                         n      Zi
 correlated with the noun. Thus, we also introduce two                                     j≥2
 functions that implement this intuition. Finally we no-
 ticed from the participants’ data that preferred superor-            where |ci1 | is the number of correct answers for word
 dinates are often low-level classes and we define a feature          wi and Zi = |ci1 |(ki − |ci1 |). For word length (2), and
 also for this notion. We denote with wi a test word, with            distance (6), we used the negative of these values because
 ci its word sense, with cij one of the superordinates of             we prefer short words and low classes. In Table 3 we
 ci and with wij the first noun in the synset cij . The               report ranking accuracy, RA = (1 − ER )*100, and also
 following are the basic features we used to build scoring            the fraction of times the correct answer is the top scoring
 functions:                                                           superordinate, or exact match (EM).
                                                                         Length (L) provides the worst ranking function. Par-
1. FR(cij ): frequency of wij                                         ticipants don’t always prefer short nouns as their an-
                                                                      swers. Entropy (H) and frequency (FR) are consider-
2. L(cij ): number of characters of wij                               ably more accurate, 59.1% and 61.6% ranking accuracy,
                                                                      24.9% 26.2% exact match accuracy. Likelihood ratio
3. H(c Pij ):       entropy        of      cij     calculated  as
                                                                      (LR), RA=70.4%, EM=35.9%, and particularly mutual
    − k P (cijk ) log P (cijk ); cijk is a child of cij ,
                      counts(cijk )                                   information (PMI), RA=79%, EM=46.5%, capture even
    and P (cijk ) = P counts(c     ijk )                              more robust regularities in the data. A good super-
                       k
                                                                      ordinate is likely to be characterized by a strong dis-
4. PMI(cij ): point-wise mutual information between wi                tributional correlation with the noun and, even more,
    and wij                                                           by the reduction in uncertainty which provides with re-
                                            L(H1 )                    spect to the target noun. Finally, the evaluation shows
5. LR(cij ): likelihood ratio −2 log        L(H2 )                    that distance (SD) is the most reliable ranking function:
                                                                      RA=87%, EM=56.1%. People often find the most in-
6. SD(cij ): length of the shortest path from ci to cij               formative levels to be among the most specific superor-
                                                                      dinates, 82% of the times the preferred superordinates
    Frequencies in (1) are collected using “Yahoo!”. For
                                                                      is within two categories above the noun. This is even
 (3) we used frequencies from the Brown corpus for all
                                                                      more surprising considering that participants saw a list
 words in Wordnet (plus a smoothing count of 1) and
                                                                      of superordinate terms in randomized order.
 added the counts of each word to all its superordinates.
 Functions (4) and (5) are designed to capture how much               Discussion
 the frequencies of two words are correlated. Point-wise
                                                                      The most informative superordinates are characterized
 mutual information measures how much information one
                                                                      by well-known properties of basic levels; 83.3% of the
 word contains about another word, it is computed as
                      P (wi ,wij )                                    time the output of at least one of the ranking functions
 I(wij , wi ) = log P (wi )P (wij ) . Function (5) formulates         is the same as the correct answer. There might be a
 a log-likelihood chi-squared statistic comparing the hy-             model which combines the individual sources of informa-
 pothesis that the distributions of wi and wij are in-                tion and fits the experimental data more accurately. A
 dependent (H1 ) against the hypothesis that they are                 simple way of combining different ranking functions is by
 dependent (H2 ). The frequencies for (4) and (5) were                defining a new function which combines the predictions
 also computed from “Yahoo!”. For (6) we measured the                 of the individual functions as a weighted sum yielding the
 distance in edges of the shortest path between ci and                posterior probability of a superordinate cij given a set
 cij .7 Each of these functions implicitly defines a rank-            of scoring functions F={F R, L, H, P M I, LR, SD} (Flo-
 ing by assigning a score to each concept. For example,               rian & Yarowsky, 2002):
 PMI(garbage,waste) = 2.9, while PMI(garbage,material)                                             P
 = 1.4. Using PMI “waste” is ranked higher than “mate-                                                F ∈F λF rankF (cij )
                                                                                 P (cij |F) =    P P                           (3)
                                                                                                        F ∈F λF rankF (cij )
 rial” with respect to the noun “garbage”.                                                          j
 Evaluation                                                           where λ is a vector of parameters adjusted to weigh
                                                                      each function individually in order to maximize accuracy.
 The accuracy of each ranking function is evaluated by                We adjusted λ with a line search using as development
 computing its ranking error on the experimental data.                data the results for the 213 words of the pilot study.
     7
       Wordnet’s nominal taxonomy is not a tree since there           Unfortunately this method doesn’t work, RA=86.8%,
 exists many concepts with more than one parent, to find the          EM=58.6%, which is comparable to the distance mea-
 shortest path we used Dijkstra’s algorithm.                          sure but not better. The problem is that the different
                                                                  463

functions are all strongly correlated. This fact can be                                 References
verified by comparing the individual functions outcomes;          Agresti, A. (1992). Modeling Patterns of Agreement
i.e., success or failure in predicting the true superordi-          and Disagreement. Statistical Methods in Medical Re-
nate of a noun. The pairs of functions with highest co-             search, 1.
efficient of correlation are SD and PMI (ρ = 0.538), FR
and LR (ρ = 0.527), L and FR (ρ = 0.4227) etc. Because            Brown, R. (1958). How Shall a Thing be Called?. Psy-
of this high degree of correlation, and because there is a          chological Review, 65, 14-21;
strong bias for specificity, the simple combination model         Ciaramita, M. & Johnson, M. (2003). Supersense Tag-
is forced to put so much weight on the distance feature             ging of Unknown Nouns in WordNet. In Proceedings
that the others rarely make a difference.8                          of the 2003 Conference on Empirical Methods in Nat-
   Given the specificity bias, an interesting question is           ural Language Processing.
when do people decide to use a more general class? In-            Collins, M. (2000). Discriminative Reranking for Nat-
terestingly a measure that is correlated with the partic-           ural Language Parsing. In Proceedings of the 17th
ipants’ use of a more general superordinate is when the             ICML.
different functions predict conflicting categories. This
uncertainty can be measured using entropy; e.g., for the          Corter, J. & Gluck, M. (1992). Explaining Basic Cate-
noun “remembrance” the six functions predict 5 times                gories: Feature Predictability and Information. Psy-
“memory” (the correct class) and once “ability”, thus the           chological Bulletin. 111(2).
entropy is low (0.65), in this case participants chose the        Dale, R. & Reiter, E. (1995). Computational Interpre-
most specific superordinate. Entropy of the predictions             tation of the Gricean Maxims in the Generation of
and presence of a generalization are positively correlated          Referring Expressions, Cognitive Science, 19.
(ρ = 0.18). Uncertainty in this case indicates that there         Di Eugenio, B. & Glass, M. (2004). The Kappa Statis-
is no obvious most informative candidate. In such cases,            tics: A Second Look. Computational Linguistics,
often the preferred superordinate can be associated with            30(1).
at least one of the identified properties. However, the
specific choice seems to involve complex semantic and             Fellbaum, C. (1998). WordNet: An Electronic Lexical
cultural inferences triggered by the superordinate term.            Database. Cambridge, MA: MIT Press.
For example, “person” is used for nouns such as “abo-             Fisher, D.H. (1988). A Computational Account of Basic
rigine” and “alcoholic”, it is possible that participants           Level and Typicality Effects. In Proceedings of AAAI
in these cases avoid the use of terms with strong cul-              1988.
tural connotations such as “primitive” or “drunkard”
                                                                  Fleiss, J.L (1981). Statistical Methods for Rates and Pro-
(but “trouble shooter” is a “repairman”). General terms
                                                                    portions, (2nd ed.). New York, NY: Wiley.
are also used when the alternatives presuppose some
technical knowledge; e.g., “plant” instead of “rhododen-          Florian, R. & Yarowsky, D. (2002). Modeling Consen-
dron” for “azalea” (but “flower” for “chrysanthemum”)               sus: Classifiers Combination for Word Sense Disam-
and “animal” instead of “placental” for “anteater” (but             biguation. In Proceedings of the 2002 Conference on
“bear” for “grizzly”). Further research will be necessary           Empirical Methods in Natural Language Processing
to gain a better understanding of these issues.                   Francis, W & Kučera, H (1982). Frequency Analysis of
                                                                    English Usage: Lexicon and Grammar. Boston, MA:
                       Conclusion                                   Houghton Mifflin.
We investigated the coverage and properties of informa-           Gluck, M. & Corter, J. (1985). Information, Uncertainty
tive superordinates using statistics from a corpus of word          and the Utility of Categories. In Proceedings of the 7th
frequencies and associations. We found that for a vast              Annual Conference of the Cognitive Science Society.
fraction of nouns humans have converging preferences
about which superordinate is more informative. In little          Murphy, G.L. (2002). The Big Book of Concepts. Cam-
more than half of the cases the most informative class              bridge, MA: MIT Press..
is the most specific one. Informative superordinates are          Rosch, E. & Mervis, C.B & Gray, W.D. & Johnson, D.M.
characterized by properties of basic concepts such as fre-          & Boyes-Braem, P. (1976). Basic Objects in Natural
quency and association measures, however a complete                 Categories, Cognitive Psychology 8.
understanding of the determinants of the basic-level will
                                                                  Schapire, R.E. & Singer, Y. (2000). BoosTexter: A
require appealing to principles beyond orthography, fre-
                                                                    Boosting-Based System for Text Categorization. Ma-
quency, and hierarchical structure. For example, causal
                                                                    chine Learning, 39.
knowledge and pragmatic principles are also relevant.
                                                                  Sloman, S. & Ahn, W. (1999). Feature Centrality: Nam-
                  Acknowledgments                                   ing versus Imagining. Journal of Memory and Cogni-
We would like to thank Elie Bienenstock and Fulvio Do-              tion, 27(3), 526-37.
mini for helpful discussions and comments.                        Tversky, B. & and Hemenway, K. (1984). Objects, Parts,
    8
                                                                    and Categories. Journal of Experimental Psychology:
      Experiments with a more sophisticated ranking function        General, 113(2), 169-97.
based on Boosting (Collins, 2000) improved only slightly over
the distance model.
                                                              464

