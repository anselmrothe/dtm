UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Attention Driven Memory
Permalink
https://escholarship.org/uc/item/0mb6k5dw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Grunewalder, Steffen
Obermayer, Klaus
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                          Attention Driven Memory
                                 Steffen Grünewälder (gruenew@cs.tu-berlin.de)
                           Department of Computer Science, Technical University Berlin,
                                                   10587 Berlin, Germany
                                       Klaus Obermayer (oby@cs.tu-berlin.de)
                            Department of Computer Science, Technical University Berlin
                                                    10587 Berlin,Germany
                          Abstract                                            Output
   Categorization is a skill which is used extensively in
   everyday life and as therefore an important aspect of hu-
   man cognition. Consequently a variety of studies exist
   which address the topic and revealed that diverse factors
   affect human categorization performance. A critical but
   not extensively studied factor is time. Imagine watch-                                                             Recall
   ing a basketball game for 30 minutes. In this period
   of time plenty of actions will take place resulting in di-
   verse impressions which make you afterwards categorize
   the game as interesting or boring. Such a categorization
   task is very similar to a time series classification task        Memory
   in the context of machine learning. In the field of ma-
   chine learning a phenomen called “vanishing gradient”
   is known which makes it generally hard to solve such
   a categorization task. A prominent method that over-                                                               Encode
   comes this phenomen is the long short term memory
   which basicly consists of a memory that is controlled by
   two gate units which can be interpreted as adaptive en-
   coding and recall units. Critical points which make the
   processing of the structure differ from human processing
   concern the encoding and the storage: (1) The structure
   is built to massively store information instead of care-
   fully selecting few impressions for storage in memory.
   (2) Reweighting of stored information due to changing
   constellations is not possible. Coming back to the exam-
   ple this would mean that a nice action at the beginning                     Input
   of the game has a strong impact on your categorization
   independent of what kind of actions - might they be
   impressive or not - followed afterwards. In this work          Figure 1. Interpretation of the LSTM. The central element
   we tackle these points through introducing an attention        is the memory which is controlled by adaptive encoding and
   mechanism which drives the encoding and the storage            recall units. Encoding/recall activation scales the memory in-
   of the structure. We analyse the model behavior in cat-        put/output through a multiplicative relation to the ordinary
   egory learning tasks.                                          pathway (dashed line). The hidden layer (memory, encode,
                                                                  recall) is fully connected (not drawn due to readability).
Keywords: LSTM, Memory, Attention, Catego-
rization, Modelling.
                                                                     In the machine learning field similar classification
                       Introduction                               problems are studied, whereas the machine learn-
Diverse factors like category dimensionality (Shep-               ing methods here face a similar problem like a hu-
ard, Hovland, & Jenkins, 1961), covariance com-                   man. The information they need for classification is
plexity (Alfonso-Reese, Ashby, & Brainard, 2002)                  spread over time so not all of the relevant informa-
or, for rule-based task, if a rule is conjunctive or              tion is available at one moment. Just like a human
disjunctive (Bourne, 1970) are responsible for hu-                these methods have to memorize relevant informa-
man categorization performance. Another impor-                    tion to yield good performance in the task.
tant but not extensively studied factor is time. Cat-                Interestingly, studies in the machine learning field
egorization tasks which involve the temporal do-                  revealed that such classification tasks are generally
main come up all the time in every day life, think                hard to solve. This mainly relies on the so called
for example of the different ways you can take to                 vanishing gradient problem (S. Hochreiter (1991),
your work place. You will surely have categorized                 Bengio, Simard, and Frasconi (1994) and S. Hochre-
them according to the time you need to arrive at                  iter (1998)). This “problem” comes up when stored
work.                                                             information decays with time. This results in the
                                                              845

effect that information that might be strongly re-         units got a sigmoidal activation function in [0, 1].
lated to a later signal being downscaled with time         Thus when the activation of these control units
and finally when the later signal comes the origi-         tends to zero the information flow is stopped.
nal information can no longer be distinguished from           An important aspect about the encoding and re-
noise. This way the relation between the singals can       call units is that they are adaptive and through
not be revealed, respectively learned. This has dra-       training learn when to store information and when
matic effects on the performance of methods which          to use stored information.
have the problem. Due to this effect traditional
recurrent networks1 are hardly able to relate two                Attentional Driven Encoding and
signals which are 15 time steps or more apart from                                Storage
each other.
   A prominent machine learning method that over-          Encoding in human memory is driven by atten-
comes this problem is the Long Short Term Memory           tion. This has the advantage that the memory
(LSTM, J. Hochreiter and Schmidhuber (1997)).              can be used according to current needs or objec-
The LSTM is a recurrent neural network struc-              tives. Furthermore, storing information selectively
ture which basicly consists of a memory unit that          reduces the needed memory and this way it is eas-
is controlled by adaptive encoding and recall units        ier to detect a relation between past attended and
(see figure 1 and next section). Similarities of the       present events. A disadvantage is, that when a re-
LSTM structure to recent neuropsychological mod-           lation exists between past and present events, but
els of working memory exist as stated in (O’Reilly,        attention is not drawn to the relevant past events
Braver, & Cohen, 1999).                                    then the relation will hardly be detected. Encod-
   Despite these similarities some obvious differ-         ing in the LSTM varies in these points from human
ences still exist between the processing through the       encoding. The LSTM massively stores information.
LSTM structure and human processing of informa-            Therefore problems arise with the memory capac-
tion. Two points are especially critical: (1) The          ity. Addionally, through this massive storage the
LSTM tends to massively store information in its           LSTM is on the one hand able to detect a wide
memory in contrast to the very selective storage in        variety of relations, however, on the other hand it
humans. (2) Information that is once stored can            takes a long time to extract relations. Thus, a well
not be reweighted due to changed conditions.               working attention mechanism should be able to im-
   We address these two points through introducing         prove the LSTM performance, make its encoding
an attention mechanism which drives the encoding           behavior more human like and thus make it a mem-
unit and rescales the memory content when needed.          ory structure whose processing is more similar to
   Furthermore, we analyse the behavior of this            human information processing.
process model in category learning tasks.                     We start from a basic and general assumption of
                                                           how the memory content should be computed out
     Long Short Term Memory (LSTM)                         of input and attention values at different time steps.
                                                           It shows up that critical elements of the attention
Figure 1 shows the LSTM structure (J. Hochre-              process are predetermined from this first assump-
iter & Schmidhuber, 1997). The key element is the          tion and thus at the core of the attention structure
memory unit in the center of the LSTM. The unit            no variations are possible when the defined equation
uses the identity as an activation function and is         (1) should hold.
self-connected with a recurrent connection. This              Basicly we want the memory content to “concen-
recurrent connection has a weight of one which             trate” on few strongly attended information and to
garanties that no information is lost, respectively        downscale the impact of information which has a
information is conserved and so the vanishing gra-         low attention value relative to the strongly attended
dient problem does not apply.                              signals. Due to the vastly reduced amount of stored
   A problem that occurs directly from the conser-         information that must be processed, detecting re-
vation of all information which is encoded in the          lations between attended signals should be much
unit, is that the capacity of the memory unit will         easier. Further, we don’t want the storage of in-
be quickly exceeded. This problem is overcome              formation to rely on the special timestep when the
through introducing an encoding unit which con-            information arrives. So basicly the memory content
trolls the inflow of information into the memory.          at time T should look like this.
Besidea that a recall unit is used to control the flow
of information out of the memory cell back into the                        X T
network.                                                       memi (T ) =      ini (t) · φ(Amax (T ) − A(t))  (1)
   The control of the inflow and outflow is achieved
                                                                            t=1
through scaling the input to the memory respec-
tively the output from the memory, with the acti-          φ denotes a function which operates on the relative
vation of the encoding/recall unit. Whereas both           value between the strongest and the actual atten-
   1
     For an introduction to neural network models see      tion value at step t. If the relative value is high the
(Haykin, 1999)                                             input should be strongly downgraded.
                                                       846

          1) Full Model                                                                2) Attention
                    Output                                                                                Rescale
                                                                                        Encode
                                                               Rescale
          Memory
                                                    Encode
                                                                                                             max
                                                        Attention                                Features
                     Input                                                                Input
Figure 2. 1) Full Model: Modified LSTM structure. Like in the LSTM the central element is the memory cell and the input
to the memory is controlled by an encoding unit. In difference to the LSTM the encode and rescale units are driven by an
attention process which weights the input according to its relevance and reweights the memory when new constellations come
up (e.g. a new signal attracts most attention). Encode and rescale units have exponential activation functions which are used
to emphasize strong attented input and downscale input of low attention value. 2) A detailed view on the attention box of
the left part. The input activates a set of features which lead to an attention value. This attention value is compared with
the stored maximal attention value and replaces this when it is higher. It further drives together with the maximal attention
value the encode unit. The rescale unit on the other hand is driven by the difference between the new and the old maximal
attention value.
   When storage is limited and thus not every A(T )               introducing an additional minus and a scaling factor
and ini (t) can or should be stored it is not sim-                σ we get
ply possible to rescale the stored information when
Amax changes. What we need is a function φ that                                  X T
makes it possible to rescale the stored information                memi (T ) =        ini (t) · exp(−σ(Amax (T ) − A(t)))
in the way that                                                                  t=1
                            rescale
                    z          }|         {                       The rescaling factor K computes now to
      memi (T ) = K · memi (T − 1) +
                                                                         K = exp(σ(Amax (T − 1) − Amax (T )))
                    ini (T ) · φ(Amax (T ) − A(T ))
                    |                 {z              }
                                    encode                        To guarantee that the equation holds in every step
                                                                  we only need to store the memory value mem i (T )
To do so it must be possible to transform the ’-’ into            and the highest activation value Amax (T ) that has
a multiplicative factor, in other words φ(A max (T )−             come up till the time step T.
A(t)) = φ(Amax (T )) · φ(−A(t)). This only holds                    In the next section we present a model which is
for the exponential function thus φ = exp. After                  based on these equations.
                                                              847

      Input
                                                                           *
      Memory
       Time
Figure 3. We presented a sequence of 15 steps to a network. In the first 10 steps cards were drawn randomly with equal
probability from a pool of 20 cards, whereas each card could appear only once. In the final 5 steps no card was presented.
At step 15 the network got an error signal for it’s classification response. In the upper part one such sequence is shown.
The sequence is presented from left to right with one card per time step. The relation of the sequence and the class was
deterministic. If the black square card (* in the figure) was presented the class of the sequence was 1 otherwise the class was
0. The variables Fi (t) where chosen to be reactive to only one of the cards, so we got 20 variables (one for each card). This
way the calculation of A(t) was trivial and the emphasis layed on the weighting over the different time steps. The according
weights of Fi (t) were initialized with a value of 0.2 whereas the weights between the memory and the output layer were chosen
randomly in [−0.1, 0.1]. The bias values where negatively initialized (-2) to initially hold attention values low. The lower part
shows the memory of a trained network (20 000 training steps, mean squared error < 0.1). At the position of the correct card
the memory is rescaled and the stored values are strongly downgraded. At the same moment the input is stored with a high
attention value and overshadows the other input signals.
Model Description                                                    step t calculates in our method as follows:
Figure 2 shows the model structure. The input is
passed to the attention process and to the memory.                                A(t) = f (max(ŵi Fi (t) + bi ))
The attention process computes an attention value
for the momentary time step due to the input. Ac-                    Here max is the maximum function and f is a logistic
cording to this attention value it drives the encode                 sigmoidal function. Variable Fi (t) is dependent on
and rescale units which will control if the new input                the input and as stated above simulates a feature
is stored, respectively how “strong” it is stored, and               detector that signals if a feature i is present at time
how the memory content must be reweighted due to                     step t (in simulations the range of F i (t) was chosen
changed conditions.                                                  to be in [0, 1]). A short remark: the function to
   Diverse factors exist which drive our attention in                calculate A(t) must not have the upper form, one
one special moment. An example is our physical                       might for example also use a weighted sum of the
condition. When we are hungry or thirsty totally                     different feature activations. Finally, in the above
different objects attract our attention than when                    equation ŵi is the weight of feature i and bi a bias.
we are tired. Also totally different conditions like a               Both are adaptive and modulated through learning.
task we are working on at the moment or personal                       Contrary to the choise of A(t) the following vari-
preferences effect what attracts our attention. The                  ables are predefined through our initial assumption
study of the influence of these points is beyond the                 (equation 1).
scope of this work. Instead of realizing an attention                  As stated above the maximal attention value
mechanism which is driven by all these factors we                    which appears until step t is needed to encode and
used some abstract variables Fi (t) which might be                   rescale:
used to represent a variety of features which are rel-
evant to control attention. The only condition the                            Amax (t) = max(A(t), Amax (t − 1))
variables must fulfill is that the values the variables
can take lie in a bounded interval.                                    Building up on the value A(t), Amax (t) and
   Due to these features the attention value at time                 Amax (t − 1) the encode and the rescale value can
                                                                 848

be calculated:                                            it hard to process temporal information. Like in
                                                          the original LSTM in our model this problem does
    encode(t) = exp(−σ(Amax (t) − A(t)))                  not apply. The reason for this is that the rescal-
                                                          ing for stored information is bounded, as long as
    rescale(t) = exp(σ(Amax (t − 1) − Amax (t)))          the range of A(t) lies in a bounded interval (for our
                                                          case [0, 1]), information, respectively the gradient,
                                                          can not vanish. The upper bound for rescaling is 1,
Finally the activation of the memory at time step t       which is trivial and the lower bound can be infered
calculates as follows:                                    in the following way.
                                                             Because Amax (j) − Amax (i) ≥ −1 for i > j due
memi (t+1) = ini (t)·encode(t)+memi (t)·rescale(t)        to the choise of the function f and thus
                                                             k=j
And the output of the network:                               Y
                                                                  rescale(t) =exp(σ(Amax (i + 1) − Amax (i)))·
                           X                               k=i+1
          out(t + 1) = f (    wi memi (t) + b)
                           i                                               ·...· exp(σ(Amax (j) − Amax (j − 1)))
                                                                               =exp(σ(Amax (j) − Amax (i)))
   In this simple setup adaptive parameters that
must be learned are the wi values which weight the                             ≥exp(−σ)
impact of the memory content to the output of the
network and the ŵi values which weight the impact        the overall rescale value summed over all time steps
of the different features to the attention value at       is lower bounded by e−σ . Thus stored information
one time step. The latter ones are the interesting        can not be rescaled arbitrary low and thus will in all
ones, because they define how the network uses its        situations still have a noticeable effect. This leads to
memory. Another remark: in the LSTM input is              the statement that the vanishing gradient problem
bundled through a weighted sum and thus concen-           does not apply.
trated in one memory unit. This can also be done
here through introducing another weight layer be-                                Simulation
tween the input and the memory. The attention at          We evaluate our model in category learning tasks.
one special moment will in this case have a large         The tasks we consider here are rule-based category
impact on the learning of the input weights. Input        learning tasks (Ashby & Shawn, 2001). In the simu-
units that are active when attention is high and thus     lations we presented the network a set of cards (see
the encode unit stores information will be strongly       figure 3) whereas at each point in time only one card
effected by a learning process.                           was presented. Thus the networks had to learn to
   Training the network can be done with any gradi-       memorize information about the seen cards to solve
ent descent algorithm which does not rely on higher       the categorization task. The relation between the
derivatives (s. below). We used back-propagation          presented cards and the category was deterministic,
through time (Haykin, 1999) for training. The             if a special card was present in the sequence then the
derivations are basicly straight forward we only          according category was one, otherwise zero. Each
want to single out two of them. First, the deriva-        card was represented through a 5x5 matrix of input
         max (t)
tion ∂A∂A(t)     because the maximum function is in-      activation. To each input unit directly one memory
volved. The maximum function is derivable, how-           unit corresponded, thus we also had a matrix of 5x5
ever its derivation is not continuous:                    memory units. Input to the memory, respectively
                                                          the rescale of the memory, was however controlled
                      (                                   by just one unit. So a single attention mechanism
        ∂Amax (t)       1, A(t) ≥ Amax (t − 1)            was responsible for the inflow of information to the
                    =
          ∂A(t)         0, otherwise                      5x5 memory units.
                                                             In the first simulation we were interested in how
This makes no problem for calculating the gradient        the memory is used from a network which had
and thus to train with a gradient descent method          learned to solve the categorization task (see figure
which does not rely on the second or higher deriva-       3). It shows up that the network has learned to ex-
tions.                                                    tract the relevant feature and store it in the memory
   The other derivation which we want to single out       whereas the other input elements are downscaled
is                                                        when the relevant feature is seen.
               ∂memi (t + 1)                                 We made a second experiment to study how the
                             = rescale(t)                 performance of the network changes when atten-
                 ∂memi (t)
                                                          tion is directly drawn towards the correct feature
This one is important because of the vanishing gra-       against the case when attention is high for irrele-
dient problem ((S. Hochreiter, 1991), (S. Hochre-         vant features and low for the correct one. Figure 4
iter, 1998) and (Bengio et al., 1994)) which makes        shows the results. An interesting side effect became
                                                      849

                                4
                       2.4
                             x 10                                                        models of the working memory. However different
                                                                                         points make its processing behavior vary from hu-
                       2.2                                                               man processing. Especially as it tends to massively
                        2                                                                memorize information and is not able to reweight
                                                                                         memorized information due to changing constella-
                                                                                         tions. We showed that these points can be tackled
Needed Trainingsteps
                       1.8     Standard LSTM
                       1.6                                                               through introducing an attention mechanism which
                                                                                         drives the encoding and the storage process. Es-
                       1.4                                                               pecially, when the attention mechanism is working
                       1.2 Crosstalk Reduction
                                                                                         well, the performance of the network increases and
                                                                                         learning becomes faster than with standard LSTM.
                        1                                                                However, the network performance strongly relies
                       0.8
                                                                                         on the quality of the attention process (in our sim-
                                                                                         ulations an exponential relation shows up), thus
                       0.6                                                               when attention is attracted by irrelevant signals and
                                                                                         the relevant signals are omitted then performance
                       0.4
                          0           5           10            15       20   25         dramatically decreases. Beside this point the sim-
                                               Rank of Correct Feature                   ulations revealed that the network is very sensitive
                                                                                         to the effects of interference between input signals.
Figure 4. We measured how the initial weighting of the cor-
rect feature and its relative weighting to other features effects                                              References
the performance of the model. The signals and features were                              Alfonso-Reese, L. A., Ashby, F. G., & Brainard, D. H. (2002).
chosen like in simulation described in figure 3. We used the                                  What makes a categorization task difficult? Perception
number of trainingsteps which are needed to bring the mean                                    & Psychophysics, 64 (4), 570-583.
squared error below 0.1 as a measurement for the perfor-
mance of the network. We initialized the feature weights in                              Ashby, F. G., & Shawn, W. E. (2001). The neurobiology of
the following way: ŵi = 0.1·i and changed the position of the                               human category learning. TRENDS in Cognitive Sci-
correct feature. So in the worst case the initial weight was 0.1                             ences, 5 (5), 204-210.
and in the best 2.1 for the correct feature. For each setup we
made 100 runs. Notice that beside the effect of the rank also                            Bengio, Y., Simard, P., & Frasconi, P. (1994). Learning
interference effects came up because the different cards we                                   long-term dependencies with gradient descent is diffi-
presented had similarities. Especially the cards which were                                   cult. IEEE Transactions on Neural Networks, 5, 157-
similar to the black square card (this was the relevant fea-                                  166.
ture) had an impact on the performance. This becomes most
obvious in the plot at position 3. Here the feature responsible                          Bourne, L. E. (1970). Knowing and using concepts. Psycho-
to detect the black square card with a dot in center (in figure                              logical Review (77), 546-556.
3 the card in the upper left) was initialized with a low weight
which resulted in a low attention value when the card came                               Haykin, S. (1999). Neural networks: A comprehensive foun-
up. Because this card is very similar to the relevant feature                                dation (2 ed.). Prentice Hall.
the reduced attention to this card boosted the performance
of the network. We also made a run with the standard LSTM                                Hochreiter, J., & Schmidhuber, J. (1997). Long short-term
to compare the perfomance. We have chosen the same learn-                                    memory. Neural Computation, 9 (8), 1735-1780.
ing rate as in our model and initialized the other parameters
similar to (J. Hochreiter & Schmidhuber, 1997). The mean                                 Hochreiter, S. (1991). Untersuchung zu dynamischen neu-
number of training steps was 17640 and standard deviation                                    ronalen netzen. Unpublished master’s thesis, Techni-
was 781.28 (dashed line in the figure).                                                      sche Universität München, Germany.
                                                                                         Hochreiter, S. (1998). The vanishing gradient problem dur-
                                                                                             ing learning recurrent neural nets and problem solu-
apparant in this simulation. The cards we have cho-                                          tions. International Journal of Uncertainty, Fuzziness
                                                                                             and Knowledge-Based Systems, 6 (2), 107-116.
sen are in parts similar. During the simulation it
became clear that this has a considerable impact                                         O’Reilly, R. C., Braver, T. S., & Cohen, J. D. (1999). A bi-
on the performance of the network. Especially as                                             ologically based computational model of working mem-
the performance was strongly boosted when a card                                             ory. In A. Miyake & P. Shah (Eds.), Models of work-
which was nearly the same as the relevant card at-                                           ing memory: Mechanisms of active maintenance and
                                                                                             executive control (p. 375-411). New York: Cambridge
tracted no attention (the arrow in the figure).                                              University Press.
                                               Conclusion                                Shepard, R. N., Hovland, C. L., & Jenkins, H. M. (1961).
                                                                                              Learning and memorization of classifications. Psycho-
An important factor in categorization is time. Cat-                                           logical Monographs, 75 (13).
egorizing events which are spread over time puts hu-
mans in a similar position as machine learning mod-
els which have to classify time series. A prominent
machine learning method, the Long Short Term
Memory, which successfully processes time series
has some similarities to recent neuropsychological
                                                                                   850

