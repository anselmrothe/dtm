ence to be performed in a specific context has merely been
learned in a similar context (regardless of its status as deontic       Context (x)
                                                                                               T                      A
or not). As well, it is assumed that the necessary inference            (VMPFC)
                                                                                       Assoc        Determine
                                                                                                                                     Motor areas
need not be spelled out as a complex, multi-step schema, but                          Memory        Response
is rather a direct mapping between the presented rule and ap-                                                                        Correct Answer (A*)
propriate responses in that context.                                                                                    Response
                                                                        Rule (R)                                        Goodness
   Notably, Cosmides (1989) challenges any theory based                 (Wernicke)                                                    Valence (V)
on induction, like that underlying BioSLIE, to lay out the
mechanistically defined domain-general procedures that can
take modern human experience as statistically encountered
as input, and produce the observed domain specific perfor-                                                    Right Inferior Frontal
mance in the selection task as output. This is a challenge that
BioSLIE meets.
                                                                        Figure 1: Functional decomposition and anatomical mapping
                      Model description                                 of the model. The letters in bold indicate the vector signals in
BioSLIE integrates advances in structured vector representa-            the model associated with the area.
tions, relevant physiological and anatomical data from frontal
cortices (Wharton & Grafman, 1998), and the NEF, to explain
                                                                        operations are defined as:
human performance on the Wason task.
   Since the early 1990s, there have been a series of sug-                  C =         A⊗B                and        B      ≈     A⊕C
gestions as to how to incorporate structure-sensitive process-                          Pn−1                                       Pn−1
                                                                            cj =           k=0 ak bj−k                bj     =       k=0 ak cj+k
ing in models employing distributed representations (includ-
ing Spatter Codes (Kanerva 1994); Holographic Reduced                   where subscripts are modulo n. Conveniently, correlation can
Representations (HRRs; Plate 1991); and Tensor Products                 be defined in terms of convolution: A ⊕ C = A0 ⊗ C, where
(Smolensky 1990)). Few of these approaches have been used               0
                                                                          indicates an approximate inverse.
to build models of cognitive phenomena (although see Elia-                 To implement convolution in a spiking network using the
smith & Thagard 2001). However, none of these methods                   NEF, we must first define the encoding and decoding for a
have been employed in a biologically plausible computational            vector x in a population a of neurons ai . The encoding de-
setting. As described in the next section, I extend the NEF to          scribes the biophysical processes that result in a series of
incorporate HRRs, in order to integrate the structure sensitiv-         rapid neural voltage changes (i.e., neural spikes). The de-
ity of the latter with the biologically plausibility of the former.     coding determines how much information those spikes carry
   Of course, to use this characterization of structure-sensitive       about the original signal x, by determining an estimate of that
processing in an explanatorily useful model, it is essential to         signal, x̂:
suggest which anatomical structures may be performing the
relevant functions. Only then is it possible to bring to bear                    Encoding                                  h D                E        i
                                                                                           PN
the additional constraints of (and make predictions relating                     ai (t) = n=1 δ(t − tin ) = Gi αi x · φ̃i m + Jibias
to) single cell physiology and functional imaging data. Fig-
                                                                                 Decoding
ure 1 shows how BioSLIE is mapped to functional anatomy.                               PNt ,N
Specifically, the network consists of: a) input from ventrome-                   x̂ = i=1,n=1      hi (t − tn )φxi
dial prefrontal cortex (VMPFC) which provides familiarity,
                                                                        where δi (·) are the Nt spikes at times tn for neuron ai , gen-
or context, information that is used to select the appropriate
                                                                        erated by the spiking nonlinearity Gi in the population with
transformation (Adolphs et al. 1995); b) left language ar-
eas which provide representations of the rule to be examined            N neurons. The neuron parameters αi , φ̃i , and Jibias are the
(Parsons, Osherson, & Martinez 1999); and c) anterior cin-              gain, preferred direction vector in stimulus space, and bias
gulate cortex (ACC) which gives an error signal consisting of           current respectively, which are chosen to reflect the hetero-
either the correct answer, or an indication that the response           geneity of neuron responses observed in cortex (Eliasmith
was correct or not (Holroyd & Coles 2002). The neural pop-              and Anderson, 2003). For the decoding, hi (t) are the linear
ulations that make up BioSLIE itself model right inferior               decoding filters, which for reasons of biological plausibility,
frontal cortex, where VMPFC and linguistic information is               are taken to be the post-synaptic currents (PSCs) generated in
combined to select and apply the appropriate transformation             the subsequent neuron’s dendrites, and the decoding vectors,
to solve the Wason task (Parsons & Osherson 2001). It is dur-           φxi , determine the importance of that neuron’s response to the
ing the application of the transformation that learning is also         estimate of x. Notably, the neural nonlinearity Gi can be as
presumed to occur.                                                      complex (i.e. biologically realistic) as desired. In BioSLIE
                                                                        we use a standard leaky integrate-and-fire (LIF) model.
                      Model derivation                                     Assuming this kind of vector representation in four pop-
                                                                        ulations, a, b, c, and d, it is possible to implement circular
HHRs in spiking networks                                                convolution. Using the convolution theorem, we know that
Following Plate (1991) BioSLIE encodes structure in a dis-              any convolution in a domain x is equivalent to multiplication
tributed vector representation using circular convolution (⊗),          in its Fourier domain. Thus, the two vectors to be convolved
which implements a kind of vector binding. In order to de-              are projected through the Fourier matrix into a middle layer
code the structure, circular correlation (⊕) is used. These             (using the encoding defined earlier):
                                                                    625

       a)
                                                                                     b)
      0.5
                                                                                                                                                               x                 T
A       0
      -0.5
                                                                                                                                                   x                y
             0   0.1   0.2    0.3    0.4     0.5       0.6    0.7   0.8   0.9    1
                                                                                                                                                                                     A
      0.5
B       0
      -0.5
                                                                                                                                                                    z
      0.5
             0   0.1   0.2    0.3    0.4     0.5       0.6    0.7   0.8   0.9    1
                                                                                                                                                                                     B
A⊗B
        0
      -0.5
             0   0.1   0.2    0.3    0.4     0.5
                                       time (s)
                                                       0.6    0.7   0.8   0.9    1
                                                                                                                                 Figure 3: The network structure for associative learning.
                                                                                                                                 Here, the transformation T in a context x is learned by chang-
                                                                                                                                 ing the weights between neurons in populations x and y based
Figure 2: The convolution over time of two sets of vectors.
                                                                                                                                 on information in population z.
The input vectors change after 0.5 seconds. a) The solid lines
indicate the decoded estimates of the signal value from the
neural spikes. The dashed lines indicate the ideal values. b)                                                                    its constituents. Essentially, the HRR constituents are blurred
The neural spikes generated during the same run.                                                                                 upon being used to encode this structure. This is not the case
                                                                                                                                 for a classical representation.
                                                                                                                                    A transformation vector that provides the typical human
                                                                                                                                 response to this rule is T1 = ante0 +impl0 ⊗rel0 +cons0 ,
                                                                                                                                 which results in T1 ⊗ R ≈ vowel + even. However, we
                                    ck ([AF F T , BF F T ])                                                                      cannot build this kind of transformation into the model if we
                                          h                                   i
                                    = Gk αk φ̃k ([AF F T , BF F T ]) + Jkbias                                                    want it to learn to behave differently given varying context
                                                                                                                               signals from VMPFC.
                                            X               X                                                                       To model learning of different transformations in different
                                    = Gk         ωik ai +    ωjk bj + Jkbias                                                   contexts, we need to derive a biologically plausible learning
                                                              i                           j                                      rule that can infer these transformations. Neumann (2001)
                                                                                                                                 noted that to find some unknown transformation T between
where ωik = αk φk1˜...kN WF F T φA                                                                                               two vectors A and B, we can solve
                                      i . This equation deter-
mines the connection weights from a and b to c that result                                                                                         Ã                     !−1 Ã                 !
                                                                                                                                                       m
                                                                                                                                                       X                         m
                                                                                                                                                                                 X
in spikes in the middle layer (c) that encode the Fourier trans-
form of vectors A and B. Once in this space, the the element-                                                                           T = circ               Bi ⊕ Bi               Bi ⊕ Ai
wise product can be extracted and the inverse Fourier matrix                                                                                               i                     i
applied, giving
                                                                                                                                 where circ(·) is the circulant matrix and m is the number of
                             dl (A ⊗ B)                                                                                             Pm Noting Bi ⊕ Bi ≈ 1 this can be simplified to T =
                                                                                                                                 examples.
                                                                                                                                  1
                                   " Ã                                                                  !              #         m     i Bi ⊕Ai . The resulting rule can be implemented using
                                                                                      X                                          a standard delta rule Ti+1 = wi (Ti − Bi ⊕ Ai ), where wi
                             = Gl αl                         φ̃l WIF F T                      ck φA.B
                                                                                                  k         + Jkbias
                                                                                                                                 is an adaptive learning rate inversely proportional to i.
                                                                                          k
                                           "                                              #                                         Of course, this rule is not useful for BioSLIE as it stands
                                               X                                                                                 because it does not determine how connection weights of the
                             = Gl                            ωlk ck +           Jlbias
                                                                                                                                 individual neurons representing these vectors are to be up-
                                                   k
                                                                                                                                 dated. So, I have derived (derivation not shown) the follow-
                                                                                                                                 ing neuron-level rule in terms of the network shown in figure
where ωlk = αl φ̃l WIF F T φA.Bk   . Thus, this four layer net-                                                                  3:
work will result in the circular convolution of Aand B being
represented in the output layer d. Generally speaking, this                                                                                           δE
derivation demonstrates how spiking networks can compute                                                                                    ∆ωjl = κ
                                                                                                                                                     δωjl
complex, nonlinear functions like convolution. The result of                                                                                                             
convolving two 6-dimensional vectors is shown in figure 2.                                                                                       X            X
                                                                                                                                            = κ     ωjk zk −   ωj 0 j yj  (yj > 0)xl
Learning HRR transformations                                                                                                                           k                 j0
In order to explain the results of the Wason task, it is es-
sential to transform HRRs encoding the rule being exam-                                                                          where κ is the learning rate, neurons yj carry the current pre-
ined into the appropriate response given a context. For ex-                                                                      diction for the transformation T, zk neurons carry the corre-
ample, to encode the rule “If there’s a vowel then there’s an                                                                    lation of the encoded A and B vectors, and xl carries the
even number,” we can construct the following HRR vector:                                                                         context signal. This is a form of Hebbian learning, a class of
R = ante ⊗ vowel + rel ⊗ impl + cons ⊗ even. This is                                                                             learning rules known to be biologically plausible.
similar to the structure Implies(vowel, even), in a classical                                                                       As demonstrated in figure 4, this rule leads to successful
cognitive system. However, the HRR representation is sim-                                                                        learning, and allows for the switching of learned transforma-
ply a vector R which is of the same dimensionality as each of                                                                    tions based on the context signal.
                                                                                                                           626

 1.5
                                                                             x                     T                   A=T⊗R
          Context Signal        Learning      Recall                              a    b                        f
   1
                                                                                                                                       A*
                                                                                                 R’⊗A*                  h          i
 0.5                                                                                         c              m
   0
                                                                             R
-0.5
                                                                                  e                                       A·A*
                                                                                                     <V,A·A*>                          V
       Transformation
                                                                 1
                                                                                                                        l            j
       Signal                                                    2
  -1                                                             3
                                                                 4
                                                                 5
                                                                 6
-1.5                                                                      Figure 5: The complete network at the population level. The
                                                                          lower case letters indicate populations of approximately 2000
                                                                          neurons each. Upper case letters indicate the signals being
Figure 4: Learning and retrieval of a 6-dimensional vector in
                                                                          sent along the relevant projections. The dotted boxes indicate
a spiking network. During the first two-thirds of the simula-
                                                                          how this diagram relates to figure 3, and hence the anatomical
tion, the context signal is changed while the input from z is
                                                                          mapping discussed earlier.
changed to associate the context with the vector represented
by z. In the last third, learning is turned off, and successful
retrieval of the vectors is displayed given a context signal.             the network’s answer is a and not-b. BioSLIE has learned to
                                                                          perform different inferences in different contexts, resulting in
                                                                          similar performance to human subjects on the Wason task.
                Results on the Wason task
Performance in different contexts                                         Generalization within a context
BioSLIE combines these subnetworks as shown in figure 5,                  To demonstrate that the network is truly learning a language-
resulting in a model that consists of ten interconnected neural           like transformation in a context, figure 7 shows that it gener-
populations, for a total of approximately twenty thousand                 alizes learned, structure-sensitive transformations to new rep-
neurons. The representations in this network have been scaled             resentations. This demonstrates that the system has learned a
up to 100 dimensions, in order to encoded the vectors needed              systematic regularity. That is, it can transform the structured
to perform the task.                                                      representation based solely on the syntax of that representa-
     The model is able to reproduce the typical results from the          tion.
Wason task under both the abstract and permissive contexts,                  This simulation is similar to that presented previously, ex-
as shown in figure 6. In order to classify the results pro-               cept the context signal is kept constant and there are three sep-
duced by the model, the resulting vectors must be ‘cleaned-               arate rules that are presented to BioSLIE. During the learn-
up’. That is, they are compared to all possible labeled an-               ing ’on’ phase, the rules Implies(a,b) and Implies(c,d) along
swers by taking a similarity measure (dot product) between                with their expected answers are presented to the network.
the resulting vector and items in the ‘clean-up’ memory (i.e.,            The learning is then turned off, and it is presented with Im-
all labeled vectors used in any simulation presented; 19 vec-             plies(e,f). As expected, since the context is the same as the
tors). The labels on the graph indicate the similarity mea-               previous examples, the same transformation is applied, and
sures (maximum of 1). The top three responses are displayed               BioSLIE infers that e and f are the expected answer. In the
to demonstrate the large difference in similarity between the             last quarter of the simulation, no rule is presented and thus
provided answers and the next most similar vector. Simple                 no answer is produced (i.e., all similarity measures are very
thresholding can thus be used to determine what counts as an              low). The similarity measures of the top three most similar
answer and what does not.                                                 vectors in the clean-up memory are displayed to demonstrate
     When the run in figure 6 begins, learning is initiated, the          that the top two responses are the appropriate answers in this
context is set to ‘abstract’ (i.e. 1), and the correct result in that     context.
context is present to the network. The network then learns to
infer (in this context) the expected (incorrect) result (i.e., a                                   Conclusion
and b). Both the context and expected result is then changed              I have successfully built and simulated BioSLIE, a low-level,
for the second phase, and the network learns a different trans-           spiking neuron model of a high-level cognitive behavior, the
formation in the new ‘permissive’ context (i.e., -1; resulting            Wason task. Compared to past models of the Wason task,
in a and not-b). Learning is then turned off, and the expected            this model has a number of advantages. In contrast to Cos-
result is no longer presented to the network. Only the context            mides’ explanation, I have presented a detailed computational
signal is changed. As expected, in the abstract context the               model that demonstrates that a domain general mechanism
network’s answer is a and b, and in the permissive context                can indeed account for the observed phenomena. As well, this
                                                                      627

                                                                                                                         0.2
                                                                                                                                   d,   0.40
                                                                                                                                                                      cons, 0.018
                                                                                                                                   c,   0.33
                                                                                                                        0.15       b,   0.16
                                                                                                                                                                      ~a, 0.014
                                                                                                                                                                      ~b, 0.013
                                                                                                                         0.1
                                                                                              Smoothed Spike Activity
                                                                                                                        0.05
  a)
            0.3
                                                                                                                           0
                            1            2             1                2
                                          b, 0.62
            0.2
                                          a, 0.55                                                                       -0.05
                                          not, 0.050
            0.1
                                                                                                                         -0.1
                                                                                                                                 b, 0.56
                                                                                                                                 a, 0.28
                                                                                                                                                                        f, 0.42
                       0                                                                                                         impl, 0.16
                                                                                                                        -0.15                                           e, 0.17
                                                                                                                                                                        ~a, 0.14
        -0.1                                                                                                                     Learning on           Learning off
                                                                                                                         -0.2
                                                                                                                             0           20    40    60        80      100          120
        -0.2               b, 0.56
                                         not-b, 0.36                                                                                                Time
                                          a, 0.29
                           a, 0.48        f, 0.089
                           not, 0.055                                   not-b, 0.37
        -0.3                                                             a, 0.36
                           Learning on                   Learning off
                                                                         f, 0.08
                                                                                              Figure 7: Generalization across different rules in the same
        -0.4                                                                                  context. See text for discussion.
            0                      20        40    60           80          100   120
                                                  Time
   b)
                                                                                              model offers an advantage over pragmatic reasoning schemas,
                                                                                              in that the transformations used to solve the problem are not
                                                                                              limited to a pre-specified, discrete group of “schemas” which
                                                                                              are identical for all subjects. Instead, each individual can
                                                                                              solve the problem using her own estimation of the correct
       Neuron Number
                                                                                              transformation in the given context, as determined by her
                                                                                              idiosyncratic learning history in that context. BioSLIE is thus
                                                                                              not restricted to the binary “deontic” and “non-deontic” dis-
                                                                                              tinctions made by Cheng and Holyoak.
                                                                                                 More generally, because BioSLIE spans what are often
                                                                                              considered disparate levels of description of cognitive phe-
                                                                                              nomena, it is also able to support predictions at those various
                                                                                              levels. I believe it is the first model to do so.
                                                                                                 At the single neuron level, BioSLIE helps clarify the kinds
                                                                                              of properties neurons involved in these computations need
                                                                                              to have. For instance, in order to implement the high-
                                                                                              dimensional nonlinear vector transformation necessary to
Figure 6: Results of the Wason task for the complete net-                                     capture structure-sensitive behavior, neurons in the simula-
work. a) This is the decoded neural output representing the                                   tion need to respond to at least two dimensions at the same
100-dimensional vector. Results have been smoothed for leg-                                   time (one from each vector being convolved). However, de-
ibility. The similarity measures for labeled vectors are written                              spite the size of the vectors being convolved, no more than
above the decoded neural output. These similarity measures                                    two dimensions need to be represented either (suggesting that
                                                                                              the model will scale very well). As well, the learning rule de-
indicate which answers are returned (and hence which infer-
                                                                                              rived to implement the network has implications for neuron
ences are performed) in those contexts. The numbers in boxes                                  connectivity. Specifically, it suggests that information car-
indicate the context (1 for abstract, 2 for permissive). This                                 ried by projections from one of the associative populations
diagram shows that in the first two contexts, two different                                   serves to direct the modification of synaptic weights between
transformations are learned. Then, these transformations are                                  the memory population, and the other associative population.
appropriately applied when those contexts are later encoun-                                   Thus the biophysical mechanisms (e.g. NO transport) that
tered. b) The neural spikes produced by every 100th neuron                                    can support this kind of learning should be prevalent in these
in the population representing these results.                                                 areas. Finally, examining the spike trains produced by the
                                                                                              model show that despite the model being deterministic, the
                                                                                              nonlinearities in the model serve to generate very random-
                                                                                              looking spike trains, like those observed in cortex. This sug-
                                                                                              gests that perhaps nonlinearities, not noise, are largely re-
                                                                                              sponsible for spike train variability in frontal areas.
                                                                                                 At the behavioral level, the model not only meets Cos-
                                                                                              mides’ challenge of specifying an inductive, domain general
                                                                                        628

inference mechanism, it also makes it possible to predict be-             [7] Holroyd, C., and Coles, M. 2002. “The neural basis
havioral variations on the task given a learning history. For                 of human error processing: Reinforcement learning,
instance, it should be possible to predict the effects of varying             dopamine, and the error-related negativity.” Psycholog-
the kind of feedback that a subject receives in similar and dis-              ical Review 109:679–709.
similar contexts. As well, I have not discussed the differing
effects of explicit (i.e., the answer) versus implicit (i.e. ‘right’      [8] Jackendoff, R. 2002. Foundations of Language: Brain,
or ‘wrong’) feedback on learning transformations. However,                    Meaning, Grammar, Evolution. Oxford University
the model includes a valence signal that can be used to ex-                   Press.
amine these differences. Finally, the ability of the model to             [9] Kanerva, P. 1994. “The spatter code for encoding con-
generalize helps explain why those trained in logic do bet-                   cepts at many levels.” Proceedings of International
ter on the content-independent tasks (Rinella, Bringsjord, &                  Conference on Artificial Neural Networks 46:226–229.
Yang 2001).
   More theoretically, the model is at the very least an ex-             [10] Neumann, J. 2001. Holistic Processing of Hierarchical
istence proof that understanding neural computation might                     Structures in Connectionist Networks. PhD dissertation,
have important implications for understanding cognitive be-                   University of Edinburgh, Department of Computer Sci-
havior, contra Fodor, Pylyshyn, and Jackendoff. This is be-                   ence.
cause HRRs, unlike classical symbols, are noisy representa-
tions. Thus, there are serious limitations on memory size,               [11] Oaksford and Chater, 1994, "A rational analysis of the
depth of structure, etc., that can be encoded by BioSLIE, just                selection task as optimal data selection," Psychological
as there are for people. Understanding how well such noisy                    Review, 101(4), 608–631.
representations can be processed by a realistic neural system
helps pave the way to better understanding these limitations.            [12] Oaksford and Chater, 1996. "Rational explanation of the
These same properties show how this model is also not a                       selection task" Psychological Review 103(2):381–391
‘mere’ implementation of a classical system. Classical sys-              [13] Parsons, L., and D. Osherson. 2001. “New evidence for
tems are perfectly compositional and systematic. However,                     distinct right and left brain systems for deductive versus
BioSLIE clearly is not, since encoding essentially blurs the                  probabilistic reasoning.” Cerebral Cortex 11:954–965.
represented constituents. Nevertheless, BioSLIE has enough
compositionality and systematicity to model human cogni-                 [14] Parsons, L., D. Osherson and M. Martinez. 1999. “Dis-
tive performance. Thus, neurocomputational models, like                       tinct neural mechanisms for propositional logic and
BioSLIE, can help us understand the degrees of systematicity                  probabilistic reasoning.” Proceedings of the Psycho-
and compositionality possessed by real cognitive systems in                   nomic Society Meeting 61–62.
ways that classical models cannot.
                                                                         [15] Plate, A. 1991. “Holographic reduced representations:
                            References                                        Convolution algebra for compositional distributed rep-
  [1] Adolphs, R., A. Bechara, D. Tranel, H. Damasio, and                     resentations.” In Mylopoulos, J., and Reiter, R., eds.,
      A. Damasio, 1995. “Neuropsychological approaches                        Proceedings of the 12th International Joint Confer-
      to reasoning and decision-making.” In A. Damasio,                       ence on Artificial Intelligence. San Mateo, CA: Morgan
      H. Damasio and Y. Christen., eds., Neurobiology of                      Kaufmann.
      Decision-Making. New York: Springer Verlag.                        [16] Rinella, K., S. Bringsjord, Y. and Yang. 2001. “Effi-
  [2] Cheng, P. W., and Holyoak, K. J. 1985. “Pragmatic rea-                  cacious logic instruction: People are not irremediably
      soning schemas.” Cognitive Psychology 17:391–416.                       poor deductive reasoners.” In Moore, J., and Stenning,
                                                                              K., eds., Proceedings of the 23rd Annual Conference of
  [3] Cosmides, 1989. "The logic of social exchange: Has                      the Cognitive Science Society, Mahwah, NJ: Lawrence
      natural selection shaped how humans reason? Studies                     Erlbaum Associates. 851–856.
      with the Wason selection task." Cognition, 31:187–276,
                                                                         [17] Smolensky, P. 1990. “Tensor product variable binding
  [4] Eliasmith, C., and Anderson, C. H. 2003. Neural engi-                   and the representation of symbolic structures in connec-
      neering: Computation, representation, and dynamics in                   tionist systems.” Artificial Intelligence 46:159–217.
      neurobiological systems. Cambridge, MA: MIT Press.
                                                                         [18] Sperber, Cara, and Girotto, 1995. "Relevence theory ex-
  [5] Eliasmith, C., and Thagard, P. 2001. “Integrating struc-                plains the selection task." Cognition 57: 31–95.
      ture and meaning: A distributed model of analogical
      mapping.” Cognitive Science 25:245–286.                            [19] Wason, P. C. 1966. “Reasoning.” In Foss, B. M., ed.,
                                                                              New horizons in psychology. Harmondsworth: Penguin.
  [6] Fodor, J., and Pylyshyn, Z. 1988. “Connectionism and
      cognitive science: A critical analysis.” Behavioral and            [20] Wharton, C., and Grafman, J. 1998. “Deductive reason-
      Brain Sciences 28:3–71.                                                 ing and the brain.” Trends in Cognitive Sciences 2:54–
                                                                              59.
                                                                     629

