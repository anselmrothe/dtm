UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Concept Learning and Categorization from the Web
Permalink
https://escholarship.org/uc/item/8gh9h462
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Almuhareb, Abdulrahman
Poesio, Massimo
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              Concept Learning and Categorization from the Web
                                          Abdulrahman Almuhareb (aalmuh@essex.ac.uk)
                                               Massimo Poesio (poesio@essex.ac.uk)
                                  Department of Computer Science / Language and Computation Group
                                                            University of Essex
                                                 Colchester, CO4 3SQ, United Kingdom
                                Abstract                                  about syntactic relations. A new clustering experiment is
                                                                          then discussed. The analysis of the results indicates that
   In previous work, we found that a great deal of information            using simple text patterns is an efficient method to collect
   about noun attributes can be extracted from the Web using              data from the Web. Also, the results indicate that class type
   simple text patterns, and that enriching vector-based models           and frequency significantly affect the quality of the
   of concepts with this information about attributes led to              clustering, while ambiguity has no such effect.
   drastic improvements in noun categorization. We extend this
   previous work in two ways: (i) by comparing concept
   descriptions extracted using patterns with descriptions
                                                                                                  Background
   extracted with a parser, and (ii) by developing an improved            Lexical Acquisition with Vectorial Representations
   dataset balanced with respect to ambiguity, frequency, and
   WordNet unique beginners.                                              Much of the original work in the acquisition of lexical
                                                                          resources and domain ontologies in NLP used vector-based
                            Introduction                                  word representations derived from work in information
                                                                          retrieval (Schuetze, 1992), in which only word associations
The goal of our research is to develop fully automatic                    are recorded. These kinds of representations are still in use,
methods to learn from text the associations between a                     particularly in work on concept acquisition in computational
concept and its attributes1–e.g., to learn that flights, unlike           psycholinguistics (Landauer, Foltz, and Laham, 1998; Lund
enzymes or trials, have departure times and destinations.                 and Burgess, 1996) but most current work in NLP exploits
Although this information is considered central for concept               information about grammatical relations extracted using a
definition both in knowledge representation work based on                 parser (Curran and Moens 2002; Grefenstette, 1993; Lin,
description logics (Baader et al, 2003) and in psychological              1998; Maedche and Staab, 2002; Pantel and Ravichandran,
research on concepts (Murphy, 2004), this information is                  2004). For example, Lin (1998) would represents the noun
not present in WordNet (Fellbaum, 1998) (except for                       dog as a vector of <syntactic relation, term> pairs such as
information about parts) and is not used in current natural               <adj-mod, brown>. Such vectors are used as the input to
language processing (NLP) work on learning concept                        clustering. Both hierarchical and non-hierarchical
hierarchies (Curran and Moens, 2002; Lin, 1998; Pantel and                algorithms have been tested, using soft-clustering as well as
Ravichandran, 2004). In previous work (Almuhareb and                      hard-clustering (e.g., EM), but non-hierarchical hard-
Poesio, 2004) we demonstrated (i) that a great deal of                    clustering is prevalent (for a good discussion, see (Maedche
information about noun attributes2 can be extracted from the              and Staab 2002; Manning and Schuetze, 1999)).3 The best
Web, and (ii) that enriching vector-based lexical                         of the clustering algorithms in (Pantel and Lin, 2002)
representations of nouns by including automatically                       achieves an F of about 60%.
extracted information about attributes leads to drastic                      While the vectorial representations used in this work do
improvements in noun clustering. However, our earlier                     capture relational information, the relations in question are
work was limited in two ways. First of all, we only used                  purely syntactic—subject, object, adjunct, noun modifier—
simple text patterns to identify noun modifiers and noun                  and even though terms such as brown specify values of
attributes, whereas parsers are used in most work of this                 attributes, no attempt is done to identify terms that specify
kind. Secondly, an analysis of the relatively few                         different values of the same attribute—i.e., to generalize the
misclassified nouns indicated that many such cases were                   representation of a concept to include the attribute color.
ambiguous or infrequent nouns, but our original dataset was
not designed to fully analyze these cases. The experiments                Mining the Web for Attributes
discussed in this paper were designed to remedy these
shortcomings. We briefly review the literature and our own                The starting point of this research is previous work
previous work. We then discuss a new dataset balanced with                attempting to identify particular semantic relations: e.g.,
respect to ambiguity and frequency, and the methodology                   part-of relations (Berland and Charniak, 1999; Poesio et al,
we used to build concept descriptions including information               2002) and is-a relations (Caraballo, 1999; Hearst, 1998;
                                                                          Pantel and Ravichandran, 2004). To our knowledge, no
                                                                          attempt had been made to learn about attributes, nor to use
1
  We’ll use the term ‘attribute’ to refer to the notion also referred
                                                                          3
to in the literature as ‘feature’ or ‘role’.                                Many researchers attempt to extract is-a links directly from text
2
   For the moment our system does not attempt word sense                  instead of using hierarchical clustering—e.g., Caraballo (1999),
discrimination, hence the talk of ‘nouns’ instead of ‘concepts’.          Pantel and Ravichandran (2004).
                                                                      103

these ‘semantic’ relations in the vector representation of                                  information –i.e., combining the ‘definitional’ information
concepts in replacement of, or addition to, grammatical                                     provided by attributes with the ‘concordance’-like
relations such as those discussed above. We did this in                                     information provided by modifiers: e.g., although both cars
previous work (Almuhareb and Poesio, 2004), building                                        and buildings have a color, red is a much more likely color
noun descriptions by extracting relational information from                                 for cars than for buildings. In fact, using both attributes and
the Web via simple patterns used to express queries for the                                 modifiers we obtained perfect clustering for the Lund /
Google API. In addition to a pattern to extract noun                                        Burgess dataset. Even with the larger dataset, we obtained
modifiers, we also used a pattern to extract (candidate)                                    very good results: Accuracy 85.51%, F=74.41%—but a
nominal attributes. This pattern for attributes was based on a                              total of 31 nouns were misclassified.
linguistic test for attributes first proposed by Woods (1975):                                 The first question raised by this early work is whether
                                                                                            classification errors could be further reduced by using a
 o    A is an attribute of C if we can say [V is a/the A of C],                             parser to extract information about a greater range of
for example: brown is a color of dogs. The pattern used to                                  syntactic relations. A second question is how many of these
identify noun modifiers is shown in (1), that for nominal                                   mistakes were due to ambiguity or to data sparsity. Our
attributes in (2):                                                                          analysis of the results of the previous experiment did reveal,
                                                                                            first of all, that many of the misclassified nouns were
   (1)    "[a|an|the] * C [is|was]"                                                         ambiguous: e.g., cancer has both a feeling and a disease
          (e.g., "… an inexpensive car is …")                                               sense in WordNet; lounge can be used to describe both a
                                                                                            building and a piece of furniture. Secondly, we found that
   (2)    "the * of the C [is|was]"                                                         many of these misclassified nouns were relatively rare:
          (e.g., "… the price of the car was ... ")                                         examples include abattoir and zebra. The experiments
                                                                                            discussed in this paper were designed to address these
   A variety of ways of using the information extracted from
                                                                                            issues.
the Web to build vectorial lexical representations were
tested. We tested both vectors using only modifiers and only
attributes, and vectors using both. Both Boolean vectors and                                                  The New Experiment
weighted vectors were tried; both raw frequencies and                                       For this new experiment, we designed a balanced dataset
normalized weights obtained using the t-test weighting                                      containing 402 nouns from 21 WordNet classes and used
function from Manning and Schuetze (1999) were used:                                        the RASP parser (Briscoe and Carroll, 2002) to extract
                                                                                            grammatical relations (GRs).
                   C (concepti , attribute j )     C (concepti ) × C (attribute j ) 
(3)                                            −                                   
                             N                                       N2              
                                                                                            A Balanced Dataset for Noun Clustering
          ti , j ≈
                                       C (concepti , attribute j )                          Our goal was to create a dataset balanced with respect to
                                                    N  2                                    three factors: class type, frequency, and ambiguity.
                                                                                               First of all, we aimed to include one class of nouns for
where N is the total number of relations, and C is a count                                  each of the 21 unique beginners of the WordNet noun
function. The modifiers formula is similar. We also tested                                  hierarchy4. We chose subclasses for each of these 21
a variety of clustering algorithms; the best results were                                   beginners that would represent a reasonably natural cluster:
obtained using CLUTO's hard-clustering algorithm                                            e.g., the hyponym social occasion for the unique beginner
(Karypis, 2002) and extended Jaccard as vector similarity                                   event. From each such class, we selected between 13 and 21
measure, consistently with what suggested, e.g., by Curran                                  nouns to be representative concepts for the class (e.g.,
and Moens (2002):                                                                           ceremony, feast, and graduation for the class social
                                                                                            occasion).
                                               ∑ (t      m ,i × t n ,i )                       Secondly, we aimed to include about 1/3 high frequency
(4) sim(concept , concept ) =                     i
                                                                                            nouns, 1/3 medium frequency, and 1/3 low frequency. Noun
                                               ∑ (t
                       m               n
                                                         m ,i + t n ,i )                    frequencies where estimated using the British National
                                                 i
                                                                                            Corpus. We considered as highly frequent those nouns with
                                                                                            frequency 1,000 or more; as medium frequent the nouns
where tm,i and tn,i are the weighted co-occurrence values                                   with between 1,000 and 100 occurrences; and those between
between concept m and concept n with attribute/modifier i,                                  100 and 5 as low frequent.
and computed as in equation (3).                                                               Thirdly, we wanted the dataset to be balanced as to
   Two evaluations were tried: with the dataset of 34                                       ambiguity, estimated on the basis of the number of senses in
concepts from 3 classes (animals, body parts, and                                           WordNet. Nouns with 4 or more senses were considered
geographical locations) used by Lund and Burgess (1996)                                     highly ambiguous; nouns with 2 or 3 senses medium
and with a larger set of 214 nouns from 13 different classes                                ambiguous; and nouns with a single sense as not ambiguous.
in WordNet (Fellbaum, 1998) (buildings, diseases, vehicles,                                    The final set contains 402 nouns, and each level of
feelings, body parts, fruits, creators, publications, animals,
furniture, cloth, family relation, time). The worse results
were obtained using vector representations containing only                                  4
                                                                                              WordNet has 25 unique beginners; four of them (body, food,
modifiers; better results were obtained using just attributes;                              communication, and process) are actually hyponyms of other
but the best results were obtained using both types of                                      unique beginners.
                                                                                        104

frequency and ambiguity is equally represented in the set.           identify actual attributes (Poesio and Almuhareb, 2005);5
The set contains 46 nouns that can be assigned to more than          however, some of these problematic cases can already be
one class belonging to the dataset itself, e.g., bull is both an     identified by means of morphological information and
animal and a legal document. The dataset is shown in                 weighting.
Appendix A.                                                             Examples like the one above can be identified simply by
                                                                     checking whether the candidate attribute is a noun. This
Vector Descriptions                                                  could be done using a POS tagger; we did it by checking if
In the previous experiment, we used three different lexical          the ‘attribute’ is in WordNet’s noun database. This method
representations for nouns. In each model, nouns were                 also helps in identifying misspelled words.
described using a vector of features; the three models differ           The t-test weighting function (3) was used to select the
in the type of features. The features in the attribute model         best features. We only consider positive values produced
are noun attributes extracted using the pattern in (2), such as      from the t-test weighting function as it shown to produce
color and size for the noun car. The features of the values          better results for similar tasks (Almuhareb and Poesio,
model are nominal modifiers extracted using pattern (1) (we          2004; Curran and Moens, 2002). We found that increasing
simply call them values as many of them are values of                the t-test threshold from 0 to a higher value does not
attributes, e.g., red for the attribute color). The third model,     improve the clustering accuracy. Curran and Moens (2002)
both, contains features of the first and the second models.          found that introducing cutoffs on frequencies improves the
   In this new experiment, we introduced a new model that            accuracy. We achieved the best results using a minimum
is based on parsed text. Features of this model are all types        cutoff at 2 and a maximum cutoff at 5,000 on the
of grammatical relations (GRs) produced by RASP. These               accumulated frequency of the attributes/values over all of
include nominal modifiers, verb subjects, and conjunctions.          the concepts. The cutoffs are used to remove very rare and
For example, the bear vector includes:                               general features.
   (Modifier, polar)          832                                    Clustering Algorithm and Evaluation Measures
   (Modifier, of, paw)        374                                    Noun clustering was done using the CLUTO clustering
   (Conjunction, lion)        517
                                                                     toolkit as in the previous study. We used CLUTO’s default
   (Subject, eat)             191
                                                                     clustering algorithm, Repeated Bisections, which produces
   The numbers above are the frequency of encountering               hard globular clusters. Nouns that have more than one
each relation with the noun bear in the text.                        possible class are judged to be correctly clustered if they
                                                                     were clustered with any of the possible classes. The
Web Data Collection                                                  pairwise similarities between nouns were computed using
For each noun, we aimed to collect up to 10,000 attributes           the extended Jaccard similarity function as in (4).
and values. Concept attributes and attribute values were
                                                                                   Table 1: Entropy and Purity in CLUTO
collected from the Web using the text patterns and the
Google search engine as discussed in the background
                                                                                            Entropy                          Purity
section (Almuhareb and Poesio, 2004). However, we
relaxed the text patterns used to collect attributes and values                                      q
                                                                                                         n ri     ni            1
                                                                      Single E ( S ) = − 1
(“the * of the C is” and “the * C is”) to collect more data
                                                                     Cluster          r              ∑
                                                                                             log q i =1 n r
                                                                                                              log r
                                                                                                                  nr
                                                                                                                     P(S r ) =
                                                                                                                               nr i
                                                                                                                                    max ( n ri )
for the low frequency concepts. A new pattern for attributes
based on the possessive construction was added, “the C’s *
is”. Also, the list of restriction words used to make sure                                         k
                                                                                                      nr                         k
                                                                                                                                     nr
that C is a noun (i.e., is and was) was expanded to include          Overall       Entropy = ∑            E (S r )   Purity = ∑         P( S r )
                                                                                                 r =1 n                         r =1 n
other words, for example: are, were, for, and will.
   The URLs of the collected pattern instances were used to
retrieve documents from the Web. A maximum of 10,000                 Sr is a cluster, nr is the size of the cluster, q is the number of
documents were retrieved for each noun; depending on the             classes, nir is the number of concepts from the ith class that were
number of the collected URLs. Only sentences that contain            assigned to the rth cluster, and n is the number of concepts and k
the targeted nouns were extracted from these documents and           is the number of clusters.
parsed to collect grammatical relations that are related these
nouns.                                                                  The clusters were evaluated using CLUTO’s purity and
                                                                     entropy functions. Cluster purity indicates the degree to
Filtering and Weighting Features                                     which a cluster contains concepts from one class only
                                                                     (perfect purity would be 1). Cluster entropy indicates
A moment’s thought will suggest that not all ‘attributes’            whether concepts of different classes are represented in the
found by means of our patterns correspond to actual
attributes: this is because the (quasi) possessive                   5
construction, just like any other syntactic constructions, can         Briefly, we have developed a classifier to automatically classify
be used to express a variety of semantic relations. So, for          candidate attributes into: parts (e.g., “the window of the car”),
                                                                     qualities (e.g., “the color of the car”), activities (e.g., “the selling
example, “The car’s gone” compared to “The car’s
                                                                     of the car”), related-agents (e.g., “the driver of the car”), related-
window”. We have recently developed a classifier to
                                                                     objects (e.g., “the track of the car”), and non-attributes.
                                                                 105

cluster (perfect entropy would be 0). Overall purity and                   0.664, respectively). The vector size of the attribute models
entropy are the weighted sum of all individual cluster purity              is about ¼ the size of the value model.
and entropy, respectively. The equations for entropy and
purity are shown in Table 1.                                                     Table 3: Clustering accuracy using filtered models
                                Results                                                               Filtered    Filtered
                                                                                    Description                               Both
                                                                                                    Attributes     Values
Comparing Text Patterns to Parsed Text                                              Purity              0.709        0.627    0.664
Table 2 shows the clustering accuracy of different sub-                             Entropy             0.283        0.338    0.302
datasets using unfiltered data for the four models. The                             Vector Size        12,345       51,345 63,690
results show that there is no advantage from using a model
that is based on a parsed text. In fact, using simple text                 Effect of Class, Frequency, and Ambiguity on
patterns to build a definition model from the Web produces                 Clustering Accuracy
better results. For example: the purity of the complete
dataset produced from the combined model of attributes and                 The effect of class, ambiguity and frequency on clustering
values built using text patterns is more accurate than the                 accuracy was measured using the purity of the cluster to
parsed model (0.677 compared to 0.614).                                    which a concept was assigned as evaluation measure. A one-
                                                                           way ANOVA with cluster purity as the dependent variable
   Table 2: Clustering accuracy for the four models using                  was computed for each factor. The calculation matrix used for
                     different number of classes                           these one-way ANOVAs is a 402 × 2 matrix, with one row
                                                                           for each concept: the first column specifies the value of the
                                                                           factor (e.g., ambiguity level, or class ID), and the second
Description       Attributes Values Both Parsed Text                       column is the purity of the cluster to which the noun is
                                3 Classes                                  assigned. We found that the class factor has a significant main
Purity                0.984          0.823        0.968         0.919      effect on the clustering accuracy (F(20,381) = 46.045, P <
Entropy               0.060          0.465        0.118         0.253      0.0005) as does frequency (F(2,399) = 3.554, P < 0.05), but
Vector Size           9,586         24,180 33,766              184,610     we found no significant main effect for ambiguity.
                                9 Classes
Purity                0.859          0.876        0.882         0.871      Uniqueness of Common Attributes Among Concepts
Entropy               0.211          0.201        0.180         0.188      of Different Classes
Vector Size          15,824         49,584 65,408              332,747     Different classes vary widely on the degree of uniqueness of
                21 Classes (the complete dataset)                          the common attributes among their concepts. Table 4 shows
Purity                0.657          0.567        0.677         0.614      the top 5 common attributes that are shared between concepts
Entropy               0.335          0.384        0.296         0.360      of each class in the dataset. Also, it shows the average of the
Vector Size          24,178         94,989 119,167 276,501*                degree of uniqueness of these common attributes. The degree
* Using a threshold of 2. The original vector size is 535,901.
                                                                           of uniqueness of attributej of classi is computed as the
                                                                           following:
   The superiority of the text patterns models is much clearer                                            C (classi , attribute j ) 2
when looking to the sizes of the vectors in these models.                           Uniquenessi , j =
The pattern models are much simpler than the model based                                                    ni × C (attribute j )
on parsed text. For example, in the complete dataset, the                  where ni is the number of concepts in classi. C is a count
vector size of the combined model is about 1/5 the vector                  function that counts concepts that are associated with the
size of the parsed model.                                                  given attribute. Uniqueness ranges from 0 to 1. Uniquenessi,j
   An additional advantage of the pattern models over the                  is equivalent to the conditional probability P(classi | attributej)
parsed model is has to do with the complexity of the data                  multiplied by the conditional probability P(attributej | classi).
collection procedure. Data collection for the pattern models                  Certain classes such as animal and vehicle have more
requires only sending the query to the Google search engine,               unique attributes than the other classes. This results in more
and extracting features from the return results. While the                 accurate clustering for their concepts. For example, the purity
parsed model requires: finding related Web documents,                      of the cluster with animal majority is 1.000, and the purity of
downloading and preprocessing them, parsing relative                       the vehicle majority cluster is 0.875. On the other hand, some
sentences, and extracting GRs. Elsewhere we have                           classes such as game and pain do not have such useful
experienced with selecting fewer GR types and achieved                     attributes which results in having less accurate clusters. For
better results.                                                            example, the purity of the game majority cluster is 0.636 and
                                                                           the purity of the cluster with pain majority is 0.524. This
Clustering the Whole Dataset using Filtered Data                           result is particularly intriguing at the light of Wittgenstein’s
Table 3 shows the clustering accuracy of the text pattern                  use of the concept ‘game’ as an example of concept whose
models using filtered data for the whole dataset. The attribute            instances share few or no attributes (Wittgenstein, 1953).
model produced the best results (e.g., purity=0.709)
compared to the value and the combined models (0.627 and
                                                                       106

 Table 4: Top common attributes of each class in the dataset                               Acknowledgments
                                                                        Abdulrahman Almuhareb is supported by King Abdulaziz
                Top 5 Common Attributes
Class                                                                   City for Science and Technology (KACST), Riyadh, Saudi
                (Average Uniqueness)
                                                                        Arabia.
animal          liver, intestines, stomach, skull, fur (0.81)
vehicle         tires, windshield, backseat, motor, brakes (0.75)
                                                                                                References
                ingenuity, initials, expertise, imagination, widow
creator         (0.64)                                                  Almuhareb, A. and Poesio, M. (2004). Attribute-Based and
edible fruit    pulp, ripeness, juice, peel, tartness (0.55)               Value-Based Clustering: An Evaluation. In Proc. of
monetary        devaluation, depreciation, pegging, overvaluation,         EMNLP. Barcelona, July.
unit            convertibility (0.52)                                   Baader, F., Calvanese, D., McGuinness, D., Nardi, D. and
social                                                                     Patel-Schneider, P. (Editors). (2003). The Description
                venue, eve, attendees, evening, occasion (0.43)            Logic Handbook. Cambridge University Press.
occasion
                citizens, geology, topography, landscape, mayor         Berland, M. and Charniak, E. (1999). Finding parts in very
district        (0.41)                                                     large corpora. In Proc. of the 37th ACL (pp. 57–64).
                founder, membership, leadership, chief, missions           University of Maryland.
social unit     (0.41)                                                  Briscoe, E. and Carroll, J. (2002). Robust accurate statistical
legal           signing, negotiation, issuance, amendment,                 annotation of general text. In Proceedings of the Third
documents       wording (0.39)                                             International Conference on Language Resources and
chemical        combustion, corrosion, bioavailability, solubility,        Evaluation (pp. 1499-1504). Las Palmas, Gran Canaria.
element         absorption (0.36)                                       Caraballo, S. A. (1999). Automatic construction of a
                vertices, symmetries, vertexes, surfaces, triangles        hypernym-labeled noun hierarchy from text. In Proc. of
solid           (0.28)                                                     the 37th ACL.
time            fashions, trends, weather, artists, dictator (0.28)     Curran, J. R. and Moens, M. (2002). Improvements in
assets
                quantum, payment, maximisation, allocation,                automatic thesaurus extraction. In Proc. of the ACL
                proceeds (0.27)                                            Workshop on Unsupervised Lexical Acquisition (pp. 59–
                pathogenesis, diagnosis, etiology, outbreak,               66).
illness         complications (0.27)                                    Fellbaum, C. (Editor). (1998). WordNet: An electronic
physical        derivative, measuring, scaling, logarithm,                 lexical database. The MIT Press.
property        reciprocal (0.26)                                       Grefenstette, G. (1993). SEXTANT: Extracting semantics
                ardour, reawakening, listener, incarnation, spent          from raw text implementation details. Heuristics: The
feeling         (0.25)
                                                                           Journal of Knowledge Engineering.
atmospheric                                                             Hearst, M. A. (1998). Automated discovery of WordNet
                winds, brunt, roar, rumbling, swath (0.23)
phenomenon                                                                 relations. In Fellbaum, C. (Editor). WordNet: An
tree            leaves, bark, foliage, trunk, wood (0.22)                  Electronic Lexical Database. MIT Press.
                embodiment, quickening, insanity, promptings,
motivation                                                              Karypis, G. (2002). CLUTO: A clustering toolkit. Technical
                reproach (0.13)
                                                                           Report 02-017. University of Minnesota. At http://www-
pain            pain, worst, pathophysiology, severity, cure (0.10)
                                                                           users.cs.umn.edu/~karypis/cluto/.
game            finals, final, winners, game, stands (0.09)
                                                                        Landauer, T. K., Foltz, P. and Laham, D. (1998).
                                                                           Introduction to Latent Semantic Analysis. Discourse
                          Conclusions                                      Processes, 25, (pp. 259-284).
The main expected advantage of using a parser over simple               Lin, D. (1998). Automatic retrieval and clustering of similar
text patterns is that working off the output of a syntactic                words. In Proc. of COLING-ACL (pp. 768-774).
parser allows to generalize across patterns instantiations:             Lund, K. and Burgess, C. (1996). Producing high-
e.g., the instances: ‘the color of C’, ‘the final color of C’,             dimensional semantic spaces from lexical co-occurrence.
and ‘the surprisingly rich color of C’ can all be used to                  Behavior Research Methods, Instrumentation, and
identify color as a possible attribute of C. Much recent                   Computers, 28, (pp. 203-208).
work on using the Web as a corpus suggests that this usage              Maedche, A. and Staab, S. (2002). Measuring Similarity
can alleviate data sparsity problems. The work discussed                   between Ontologies. In Proc. Of the European
here indicates that with enough data, there may be less need               Conference on Knowledge Acquisition and Management
to generalize across syntactic patterns; we can find enough
                                                                           - EKAW-2002. Madrid, Spain, October 1-4.
information using just the simplest patterns.
                                                                        Manning, C. D. and Schuetze, H. (1999). Foundations of
   We also hope the dataset proposed here can be a first step
towards developing common evaluation criteria for lexical                  Statistical NLP. MIT Press.
acquisition.                                                            Murphy, G. L. (2004). The Big Book of Concepts. MIT
                                                                           Press.
                                                                        Pantel, P. and Lin, D. (2002). Discovering Word Senses
                                                                           from Text. In Proceedings of KDD-02 (pp. 613-619).
                                                                           Edmonton, Canada.
                                                                    107

Pantel, P. and Ravichandran, D. (2004). Automatic Labeling                Schuetze, H. (1992). Dimensions of meaning. In
   of Semantic Classes. In Proc. of NAACL.                                   Proceedings of Supercomputing '92 (pp. 787-796).
Poesio, M. and Almuhareb, A. (2005). Identifying Concept                  Wittgenstein, L. (1953). Philosophical Investigations.
   Attributes Using a Classifier. In Proc. ACL Workshop on                   Blackwell.
   Deep Lexical Acquisition. Ann Arbor, USA, June.                        Woods, W. A. (1975). What’s in a link: Foundations for
Poesio, M., Ishikawa, T., Walde, S. and Vieira, R. (2002).                   semantic networks. In Bobrow, D. G. and Collins, A. M.
   Acquiring lexical knowledge for anaphora resolution. In                   (Editors). Representation and Understanding: Studies in
   Proc. of LREC. Las Palmas. June.                                          Cognitive Science (pp. 35-82). Academic Press, New
                                                                             York.
                                   Appendix A: A Balanced Dataset of 402 Nouns
WordNet Un.
                Class         Nouns
Beginner
                             bear, bull, camel, cat, cow, deer, dog, elephant, horse, kitten, lion, monkey, mouse, oyster, puppy, rat,
animal         animal
                             sheep, tiger, turtle, zebra
                             allocation, allotment, capital, credit, dispensation, fund, gain, gold, hoard, income, interest, investment,
possession     assets
                             margin, mortgage, payoff, profit, quota, taxation, trove, venture, wager
natural        atmospheric airstream, aurora, blast, clemency, cloud, cloudburst, crosswind, cyclone, drizzle, fog, hurricane, lightning,
phenomenon phenomenon rainstorm, sandstorm, shower, snowfall, thunderstorm, tornado, twister, typhoon, wind
               chemical      aluminium, bismuth, cadmium, calcium, carbon, charcoal, copper, germanium, helium, hydrogen, iron,
substance
               element       lithium, magnesium, neon, nitrogen, oxygen, platinum, potassium, silver, titanium, zinc
                             architect, artist, builder, constructor, craftsman, designer, developer, farmer, inventor, maker, manufacturer,
person         creator
                             musician, originator, painter, photographer, producer, tailor
                             anchorage, borderland, borough, caliphate, canton, city, country, county, kingdom, land, metropolis, parish,
location       district
                             prefecture, riverside, seafront, shire, state, suburb, sultanate, town, village
natural                      apple, banana, berry, cherry, grape, kiwi, lemon, mango, melon, olive, orange, peach, pear, pineapple,
               edible fruit
object                       strawberry, watermelon
feeling        feeling       anger, desire, fear, happiness, joy, love, pain, passion, pleasure, sadness, sensitivity, shame, wonder
                             baccarat, basketball, beano, bowling, chess, curling, faro, football, golf, handball, keno, lotto, nap, raffle,
act            game
                             rugby, soccer, softball, tennis, volleyball, whist
                             acne, anthrax, arthritis, asthma, cancer, cholera, cirrhosis, diabetes, eczema, flu, glaucoma, hepatitis,
state          illness
                             leukemia, malnutrition, meningitis, plague, rheumatism, smallpox
               legal         acceptance, assignment, bill, bond, check, cheque, constitution, convention, decree, draft, floater, law,
relation
               document      licence, obligation, opinion, rescript, sequestration, share, statute, straddle, treaty
               monetary      cent, cordoba, dinar, dirham, dollar, drachma, escudo, fen, franc, guilder, lira, mark, penny, peso, pound,
quantity
               unit          riel, rouble, rupee, shilling, yuan, zloty
                             compulsion, conscience, deterrence, disincentive, dynamic, ethics, impulse, incentive, incitement,
motivation     motivation
                             inducement, life, mania, morality, motivator, obsession, occasion, possession, superego, urge, wanderlust
                             ache, backache, bellyache, burn, earache, headache, lumbago, migraine, neuralgia, sciatica, soreness, sting,
cognition      pain
                             stinging, stitch, suffering, tenderness, throb, toothache, torment
               physical      chill, coolness, deflection, diameter, extension, glow, heaviness, length, mass, momentum, plasticity,
attribute
               property      poundage, radius, reflexion, shortness, snap, stretch, temperature, visibility, weight
               social        ball, celebration, ceremony, commemoration, commencement, coronation, dance, enthronement, feast, fete,
event
               occasion      fiesta, fundraiser, funeral, graduation, inaugural, pageantry, party, prom, rededication, wedding
                             agency, branch, brigade, bureau, club, committee, company, confederacy, department, divan, family, house,
group          social unit
                             household, league, legion, nation, office, platoon, team, tribe, troop
                             concavity, corner, crinkle, cube, cuboid, cylinder, dodecahedron, dome, droop, fluting, icosahedron,
shape          solid
                             indentation, jag, knob, octahedron, ovoid, ring, salient, taper, tetrahedron
                             aeon, date, day, epoch, future, gestation, hereafter, menopause, moment, nonce, period, quaternary, today,
time           time
                             tomorrow, tonight, yesterday, yesteryear
                             acacia, casuarina, chestnut, cinchona, coco, conifer, fig, hornbeam, jacaranda, lime, mandarin, mangrove,
plant          tree
                             oak, palm, pine, pistachio, rowan, samba, sapling, sycamore, walnut
                             aircraft, airplane, automobile, bicycle, boat, car, cruiser, helicopter, motorcycle, pickup, rocket, ship, truck,
artifact       vehicle
                             van
                                                                    108

