UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Toward Computational Recognition of Humorous Intent
Permalink
https://escholarship.org/uc/item/6dx3m4rb
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Author
McClelland, James l.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                        Toward Computational Recognition of Humorous Intent
                                              Julia M. Taylor (tayloj8@email.uc.edu)
                                     Applied Artificial Intelligence Laboratory, 811C Rhodes Hall
                                                       Cincinnati, Ohio 45221-0030
                                             Lawrence J. Mazlack (mazlack@uc.edu)
                                     Applied Artificial Intelligence Laboratory, 811C Rhodes Hall
                                                       Cincinnati, Ohio 45221-0030
                              Abstract                                 or words with alternative meanings, for example, “fly’ being
                                                                       a noun and a verb.
   Recognizing the intent of a written utterance is a difficult
   task. To understand the intended meanings, it may be neces-                             John likes (ham and eggs).
   sary to recognize all possible meanings of the utterance; and,                         John likes (ham) and (eggs).
   then choose the most appropriate one for the situation. The
   choice may be made using heuristics. A method for recogni-
                                                                                     Figure 1: Competing sentence structure
   tion of a humorous intent in a text is proposed. Computational
   recognition of a humorous intent can be broken down into                There are different theories of indirect or figurative lan-
   two parts: recognition of a humorous text, and recognition of        guage comprehension. “A figurative language is language
   the intent to be humorous. To narrow the focus, we propose to        that means one thing literally, but is taken to mean
   recognize the humorous intent of short dialogs. A dialog will        something else” (Carroll, 2004).        One of the figurative
   be considered humorous if the first part of the text can have        language theories is a pragmatic theory. The pragmatic
   two meanings; and, one of the meanings conflicts with the            theory (Searle, 1975; Carroll, 2004) states that figurative
   meaning of the punchline. The intent of the text is considered       language is being comprehended by first considering the
   humorous if the schema related to the non-conflicting mean-          literal meaning of the utterance and then rejecting it if the
   ing of the setup has not been activated in the preceding text.
                                                                        listener decides that the literal meaning was not intended.
   Keywords: computational humor; intent recognition; jokes;               This paper will concentrate on the task of recognizing if a
   wordplay.                                                            text is intended to be humorous. In other words, can a text
                                                                        be a joke? If it can, was it intended to be a joke?
                          Introduction                                     Many texts that appear on the Internet are semantically
Natural language processing is a difficult and increasingly             tagged. The tags are invisible to a human, but readable for a
important topic to study. With computers becoming more                  computer. Some tags provide information about the inten-
and more “knowledgeable” and assisting in some everyday                 tional topic of the document. For example, if a title of a
tasks, the need for an accurate natural language processing             web-page tagged with “jokes”, it is likely that this web-page
system becomes more apparent and desirable.                             contains humorous texts. Similarly, if the title of the web-
   Recognizing the intent of a written utterance is a difficult         page is tagged with “world news”, it is less likely that most
task. To understand the intended meaning without addi-                  of the text is humorous.
tional hints, it may be necessary to recognize many mean-                  For the purposes of humorous intent recognition, the
ings of the utterance and then choose the most appropriate              documents (or texts) could be divided into three categories:
one for the situation. The choice may be made using                          (1) Documents containing a semantic tag indicat-
heuristics.                                                                       ing that the text is intended to be humorous,
   It is not always an easy task for a human, let along the                       regardless of the actual funniness level of the
computer, to recognize the meaning of an utterance. One                           text.
difficulty is because the utterance can have both a literal and              (2) Documents containing a semantic tag indicat-
a non-literal meaning. For example, the literal meaning of                        ing that the text is intended to be non-
Text1 is “Are you capable of closing the door?” while the                         humorous.
indirect meaning is “Please close it.” Most people, through                  (3) Documents that do not contain any tag that
their experience, know that the intended meaning of Text1 is                      would provide clues to the intended humorous
indirect.                                                                         level of the text.
      Text1: Can you close the door?
                                                                           This paper will concentrate on recognizing the intent of
However, if one says: “It is cold here,” the intended mean-             sentences in categories (2) and (3). The intent of texts in the
ing may be “Please close the window.” Understanding this                category (1) can be recognized by reading the tag. The in-
intended meaning is not trivial.                                        tent of the text in category (2) could also be recognized by
   Disambiguation is not only a matter of choosing between              reading the tag. But, this category is still of interest as the
literal and non-literal meanings; there also problems with              texts may contain humorous sentences.
words having alternate meanings and alternate parsing                      A method similar to pragmatic theory will be used to rec-
caused by either competing sentence structure (see Figure 1)            ognize humorous intent of an utterance or a text. Parts of
                                                                   2166

the candidate text will be examined to find their most fre-
quently intended meaning (the literal meaning in pragmatic                                  Interpretation2
theory). If this meaning does not agree with the rest of the
candidate text, a different meaning that agrees with the rest
of the text will be explored. The candidate text will be con-
sidered humorous if both of the following conditions hold:             Interpretation1                        Meaning
                                                                                                    ?
   • The first, most common, meaning of the first part of
     the text does not agree with the rest of the text.
   • There is another meaning of the first part of the text                         Setup                    Punchline
     that does agree with entire text.
                                                                               Figure 2: Joke description (Ritchie, 2004)
   To computationally recognize a humorous text, several
things must be present. First, a computer should at least             In Joke1, the setup is: “Customer: Do you mind if I try on
partially understand natural language, and activate                that dress in the window?” The first, more obvious inter-
alternative possible meanings of a grammatically structured        pretation of the setup is that the customer wants to try on a
text. Secondly, a system should have access a database of          dress that is located in the window. The punchline,
world knowledge to determine if the text is meaningful. To         “Wouldn’t it be better to use the fitting room,” reveals the
determine if a humorous text was intended to be humorous,          second, conflicting, interpretation: customer wanting to
previous context has to be considered.                             change their clothes in the window. The first interpretation
   Not all humorous sentences are intended to be humorous.         conflicts with the punchline, while the second one makes
Consider Text2 as example:                                         sense, even though it is an odd thing to do. “The comic ef-
   Text2: “It was mentioned on CNN that the new prime              fect arises when an alternative, non-favored and therefore
             number discovered recently is four times              non-expected interpretation is revealed, at the punchline, as
             bigger than the previous record.”                     the correct one” (Dascal, 1985; Ritchie, 2004). Theories
                                               John Blasic         that favor incongruity and resolution “explanation” of jokes
                                                                   are called Incongruity-Resolution Theories.
   Text2 is funny if one knows that a prime number cannot             Raskin’s (1985) Semantic-Script Theory of Verbal Humor
be divisible by anything but one and itself. Therefore, a          (SSTH) can be considered an Incongruity-Resolution the-
number that is four times larger than a different number,          ory. Raskin argues that there are two necessary and suffi-
cannot be prime. However, it is unlikely that the CNN re-          cient conditions for a text to be humorous:
porter intended it to be funny.
                                                                         • A text has to be compatible, fully or in part, with
                             Jokes                                         two different scripts.
                                                                         • The two scripts with which the text is compatible
Humor is a part of natural language. Verbal humor is a sub-                are opposite, and must overlap fully or partially.
set of all types of humor. It results from incongruous texts
or dialogs, where the resolution to incongruity is provided in        Raskin defines a script as “a large chunk of semantic in-
the final sentence. Sometimes incongruity is caused by             formation surrounding the word or evoked by it. The script
ambiguity in the text. To understand the ambiguity, and            is a cognitive structure internalized by the native speaker
disambiguate the text, both natural language understanding         and it represents the native speaker’s knowledge of a small
and world knowledge is required.                                   part of the world.”
   A subset of verbal humor is the joke. A joke is a short            We can say that a text can have a humorous intent if the
humorous narrative where the funniness culminates in the           text compatible, fully or in part, with two scripts that over-
final section (Hetzron, 1991). Many humor theorists agree          lap and oppose.
that a joke typically consists of a setup and a punchline.            To find all the possible scripts used in different texts, a
The setup is the part of the joke that prepares a reader’s         complete natural language understanding is required. Com-
expectations.                                                      plete Natural Language Processing (NLP) is far from being
   The punchline breaks the expectation created by the setup       achieved.
(explicitly or implicitly stated). When the setup of a joke is
read, the reader comes up with an interpretation of the setup       Wordplay Jokes
(Interpretation1). When the punchline is read, the meaning          Recognition of all verbal humor is an overly broad topic.
of it conflicts with Interpretation1 of the setup, causing the      To narrow down the focus, a subclass of verbal humor is
reader to come up with a different interpretation                   considered.      Wordplay jokes are jokes that depend on
(Interpretation2), which does not conflict with the setup. (see     words that are similar (or the same) in sound, but have two
Figure 2)                                                           different meanings. The setup promotes one meaning. The
   Consider Joke1 as an example.                                    punchline unveils another meaning of a word in the setup,
   Joke1: Customer: Do you mind if I try on that dress in           or a meaning of a word that sounds similar to a word in the
          the window?                                               setup. The difference between the two meanings creates a
          Sales Assistant: Wouldn’t it be better to use             conflict by breaking expectations. And, by the previous
          the fitting room?                                         definition, is humorous.
                                                               2167

   Wordplay can be created between two words with the                  For a text to be coherent, all information does not have to
same pronunciation and spelling, with two words with dif-          be present in the text itself. Some can come from a mental
ferent spelling but the same pronunciation, and with two           model. For example (Carroll, 2004):
words with different spelling and similar pronunciation. For
example,                                                               Text3: John bought a cake at the bake shop. The
                                                                               birthday card was signed by all of the
   Joke2: Nurse: I need to get your weight today.                              employees. The party went on until after
          Impatient patient: Three hours and twelve                            midnight.
          minutes.
                                                                       The sentences are not syntactically connected, yet we
   The text is a joke due to the “confusion” between wait          seem to make sense out of them and make them into one
and weight. From the SSTH point, the joke has two scripts,         story.
“waiting time” and “person’s weight,” that overlap in pro-             Sometimes it is difficult to understand the text without an
nunciation of “wait/weight” and differ in meaning. From            appropriate activation of a schema of a mental model. “A
the intent recognition method, the most common meaning             schema is a structure in semantic memory that specifies the
for the first sentence is “I need to get your weight today” as     general or expected arrangement of a body of information”
it is common for a nurse in the doctor’s office to measure a       (Carroll, 2004).
patients’ weigh. The most common meaning of the first                  Schema activation can play an important role in jokes.
sentence does not agree with the second sentence. Another          Suppose we have a conversation about athletic
meaning of the first sentence is “I need to get your wait to-      organizations for kids. It is likely that the schema for
day”. The second meaning is unlikely, but, perhaps, the            athletic clubs has been activated. When we hear the
office is trying to improve patients’ waiting time. The sec-       question “Do you believe in clubs for young people?” we
ond meaning of the first sentence agrees with the second           think about clubs as organizations since this is the schema
sentence. Therefore, the text is a joke; and, could be in-         that is active. Suppose the conversation was not about
tended to be humorous.                                             athletic organizations, but about child abuse. Upon hearing
                                                                   the same sentence, it is likely that a different schema will be
            Communication and Discourse                            activated, if it hasn’t been already. And, it would have
Any computational intent recognition is, at the very least, as     something to do with hitting children with some objects.
difficult as intent recognition in conversations between two       Now, consider Joke3:
people. As stated in the introduction, it is not easy to recog-           Joke3: --Do you believe in clubs for young people?
nize the intent of all utterances in conversation between two                    --Only when kindness fails.
people. What makes the intent recognition difficult is our
inability to “read” somebody else’s mind. To put it in other           It could be argued that if the conversation was about child
words, we do not always understand the intended meaning            abuse, there is a chance that the “Athletic organization”
of a written or spoken text.                                       schema was not activated. If the schema of hitting children
   This paper focuses on recognizing the humorous intent of        is activated first, the first meaning of the first sentence will
dialogs. Dialogs can be in written form as well as oral. For       agree with the second sentence. Then, there would be no
example, online chat sessions such as AOL’s instant mes-           need to look for the second meaning of the first sentence.
senger can be looked at as real-time dialogs. For this dialog      Would Joke3 be considered a joke?
to be successful, people have to understand the intended
meaning of the phrase as opposed to its literal meaning.                          Syntactic Ambiguity in Jokes
Most of us have read a sentence in an email, or heard               There are jokes that depend on syntactic ambiguity.
something in a conversation, and wondered what was actu-            (Attardo et al., 1994) These jokes are based on the way we
ally meant by it.                                                   “group” words in a sentence. As an example, consider
   Discourse comprehension is more difficult than sentence          Joke4:
comprehension. Discourse comprehension “depends less on
the meaning of the individual sentences than on their ar-              Joke4: One morning I shot an elephant in my
rangement. Indeed, it is entirely possible for a group of                      pajamas. How he got into my pajamas I don’t
meaningful sentences to be thrown together in a way that                       know.1
makes no sense at all.” (Carroll, 2004)                                The joke works because “I shot an elephant in my
   For a person to understand a joke, the joke has to be co-        pajamas” can be interpreted as:
herent and relevant to their world knowledge. Coherence is
defined as “the range of possibilities that exist for linking             • I shot the elephant that was wearing my pajamas.
with what has gone before” (Hasan & Halliday, 1976). In                   • I shot the elephant and I was wearing my pajamas.
the context of this paper, world knowledge is a mental                 “Parsing is the process of assigning elements of surface
model. In other words, it is “a cognitive structure that            structure to linguistic categories” (Carroll, 2004). There are
represents some aspect of our environment” (Carroll, 2004).         different strategies to parsing. Depending on what type of
Therefore, we can say that jokes are funny if we find them          strategy is used, different trees will be constructed.
coherent and incongruous according to our mental model.
The resolution of the incongruity has to correspond to our
                                                                    1
mental model as well.                                                 Groucho Marx, Animal Crackers, 1930
                                                               2168

   Different strategies use different computational algo-               It is not clear how to achieve complete natural language
rithms to choose grammar rules to build a tree. A sentence          understanding. One approach could be to use ontologies.
can be considered syntactically unambiguous if all parsing              "An ontology defines the terms used to describe and rep-
algorithms produce the same tree. A sentence can be con-            resent an area of knowledge. Ontologies are used by people,
sidered grammatically correct if at least one tree could be         databases, and applications that need to share domain in-
built.                                                              formation (a domain is just a specific subject area or area of
   A syntactic ambiguity of one part of a text does not imply       knowledge, like medicine, tool manufacturing, real estate,
that the text is a joke. The candidate text with a syntactic        automobile repair, financial management, etc.). Ontologies
ambiguity in the setup will only be considered a joke if            include computer-usable definitions of basic concepts in the
syntactic ambiguity leads to semantic ambiguity, and the            domain and the relationships among them (note that here
semantic ambiguity is resolved in the second part of the            and throughout this document, definition is not used in the
text, the punchline. For example, Text5 (Carroll, 2004) is          technical sense understood by logicians). They encode
structurally ambiguous, but is not a joke:                          knowledge in a domain and also knowledge that spans do-
                                                                    mains. In this way, they make that knowledge reusable....
   Text5: The boy hit the girl with the boomerang.
                                                                    Ontologies are usually expressed in a logic-based language,
                                                                    so that detailed, accurate, consistent, sound, and meaningful
     Computational Understanding of Natural                         distinctions can be made among the classes, properties, and
                          Language                                  relations." (W3C Recommendation [10 February 2004]).
Natural language understanding is a complicated process.                It is speculated that ontologies can aid natural language
To fully understand a speaker, the listener has to compre-          processing. There are no ontological structures yet that can
hend the intended meaning of what the speaker has said.             fully handle natural language. However, there are some on-
The earlier section on Communication and Discourse dis-             tologies that may be close to it.
cussed how the context of the previous conversation or text             There are a large number of existing ontologies. One of
effects schemata activation for the text that is being proc-        the largest, and probably most complete, is Cyc (Lenat,
essed by humans. Can computers do it? Can computers                 1995). Cyc was intended to capture and represent
fully process natural language?                                     knowledge in a context addressable form.
   The following quotes are taken from Government Com-                     “The Cyc knowledge base (KB) is a formalized
puter News of June 23, 2004:                                               representation of a vast quantity of fundamental
   • Amtrak has installed speech recognition software to                   human knowledge: facts, rules of thumb, and heu-
      replace the button-pressing menus that drive many                    ristics for reasoning about the objects and events of
      people mad. Now you can talk to a virtual salesper-                  everyday life. The medium of representation is the
      son named Julie to get train schedules, make reser-                  formal language CycL. The KB consists of terms
      vations, pay for tickets, and discuss problems. Cus-                 — which constitute the vocabulary of CycL — and
      tomers are happier, and Amtrak is saving money.                      assertions which relate those terms. These asser-
   • IBM has a Super Human Speech Recognition Pro-                         tions include both simple ground assertions and
      gram to greatly improve accuracy, and in the next                    rules.”2
      decade Microsoft's program is expected to reduce the              Cyc can be used as a natural language processing system.
      error rate of speech recognition, matching human ca-          The background knowledge captured in its knowledge base
      pabilities.                                                   can be used to come up with the exact meaning or word in a
   • MIT is planning to demonstrate their Project Oxygen,           sentence, even if the word can otherwise have more than
      which features a voice-machine interface. Project di-         one meaning otherwise.
      rector Rodney Brooks says, "I wanted to bring the
      machine into our world, a machine that will [...] let              Computational Recognition of Humor and
      you ask questions in casual English, and answer them
      the same way."                                                                       Humorous Intent
   • General Motors OnStar driver assistance system re-              Computational recognition of a humorous intent can be bro-
      lies primarily on voice commands, with live staff for          ken down into two sub-problems:
      backup; the number of subscribers has grown from
      200,000 to 2 million and is expected to increase by 1                • Can the candidate text be humorous?
      million per year.                                                    • Is the humorous text intended to be humorous?
   • The Lexus DVD Navigation System responds to over                   To summarize previous sections, a candidate text is a joke
      100 commands and guides the driver with voice and              if it is compatible with two different scripts that oppose. In
      visual directions.                                             other words, if a part of the text can have two interpreta-
   • Reliable speech recognition should be common by                 tions, but only one interpretation works with the rest of the
      2010.                                                          text.
   It seems like the interest in speech (and, therefore, natural
language) processing is increasing. If reliable speech rec-
ognition can be achieved by 2010, recognizing humorous
statements would be desirable.                                       2
                                                                       http://www.cyc.com/cyc/technology/whatiscyc_dir/whatsincyc
                                                                2169

Intent Recognition                                                 the dialog contains an answer to the question. The question
Once it is determined that the candidate text is a joke, it has    line is the setup of the joke; the answer line is the punchline.
to be decided if the text was intended to be humorous. Ac-         Two meanings of the setup should be based on wordplay.
cording to Ritchie’s (2004) description of a joke, a joke has      The punchline should be based on one meaning of the setup.
an obvious and a hidden meaning. The obvious meaning               It will be assumed that the punchline is based on the hidden
conflicts with the punchline, and the hidden meaning does          meaning of the setup.
not. If the text was intended to be a joke, the first, most            Using these rules, Joke3 will be considered as a candidate
probable, meaning of the setup will conflict with the punch-       text for a joke; but, Joke2 will not be, as the first sentence is
line, while the less probable meaning will not. The key is         not in the form of a question. Joke2 could be rewritten as
to find which meaning is most probable.                            Joke2.a.
   For humans, the choice of interpretations depends on the            Joke2.a: Nurse: Can I get your weight today?
schemata activated by previous context. For a computer to                        Impatient patient: Three hours and twelve
simulate human behavior in humorous intent recognition,                          minutes.
previous context must be considered in recognizing
intended meaning of a candidate text as well.                          Joke2.a will be considered as a joke candidate because the
   As NLP is far from recognizing most common meanings,            first line is a question. The first line contains wordplay.
or overall meanings of text, this paper will assume that all       Both meanings of the first line are based on the wordplay.
texts of interest are semantically tagged. With the continu-       The second line is the answer to the question asked in the
ing development of Semantic Web, this assumption may not           first line. The second line is based on one of the meanings
be far from reality. For the purposes of this paper, it will be    of the first line.
assumed that each paragraph has a field that contains the              It is possible to restrict the problem even further. Only
key concepts that the paragraph talks about. These concepts        questions relating to certain subjects could be used. For
will activate schemata. It should be noted that Semantic           example, only math questions can be used in the first line.
Web does not automatically assign key concepts to                  If that is the case, Joke2.a will not be considered.
paragraphs.                                                            A restriction to a particular domain (in this case mathe-
   It will also be assumed that words in the sentences may be      matics) narrows down the number of concepts and concept
semantically tagged. This means that a computer could po-          relationship that the computer must understand in order to
tentially recognize the intended meaning of the sentence.          recognize jokes.
However, since the tags can be seen by a computer, but not
by a human that is reading the texts, these sentences would        Wordplay
still be checked for other possible meanings. In this case, if     It is easy for a human to see that the first line of Joke2.a
a joke was found in an intentionally non-humorous text (ac-        contains wordplay: wait/weight. Computational recognition
cording the meaning of the sentence received from the se-           of wordplay starts with comparing orthographic similarity
mantic tags), the sentence could be “flagged” to the author         of tags in the setup and punchline. The two tags that are
of the text to avoid potential misunderstanding and embar-          orthographically most similar will become wordplay
rassment.        This case will be ignored for the rest of the      candidates. Then, repeating substitution of letters, guided
discussion.                                                         by a heuristic approach, will be used to transform one word
   If the text can be a joke, and the previous context did not      into another. If such transformation can be made, the word
activate a schema relevant to the setup, it will be assumed         in the setup will be substituted with its wordplay. If the
that the speaker intended to tell a joke.                           setup containing wordplay is syntactically and semantically
   If the text can be a joke, but the last schema activated by      correct, the text will be considered a joke. Syntactic cor-
the previous context is needed for the hidden interpretation        rectness can be verified by a parser, semantic correctness
of the joke, it will be assumed that the text was not intended      can be verified by using the ontology and CycNL.
to be humorous. A better version of this approach is to use            Consider Joke2.a as an example. Each verb, noun and ad-
conditional probability to calculate which interpretation is       jective is semantically tagged. A noun phrase, verb phrase
activated first, given the schemata of the previous context.       or a prepositional phrase can be tagged as well. In Joke2.a
This means that Joke3 would not have a humorous intent if           “three hours and twelve minutes” is tagged as “wait”.
the last topic was about hitting children and its schema was           The orthographic similarity between concepts can be cal-
activated before “athletic organizations.”                          culated using the LCSR coefficient. LCSR is calculated by
   This also means that if a company finds a potential joke in      dividing the length of the longest common subsequence by
an email, it will not block the email if the hidden interpreta-     the length of the longest string. The similarity of “wait” and
tion of the joke closely relates to the previous discussion;        “weight” equals the length of “wit” divided by the length of
and, the previous discussion activates hidden interpretation        “weight,” which is 0.5. This similarity is the highest among
faster than the obvious interpretation.                             all possible setup/punchline pairs. Letters in “weight” will
                                                                    be substituted with similar-sounding letters, until the word
Joke Format                                                         “wait” is produced; or, all possible substitutions are made
The domain of wordplay jokes is large. To restrict the              and but we do not get “wait”.
problem, only two lines dialogs containing wordplay could              If “wait” is found, “I need to get you weight today” and “I
be considered. Each line contains only one sentence. The            need to get your wait today” will be syntactically and
first line of the dialog is a question, and the second line of
                                                               2170

semantically verified. If both are successful, the dialog is a     was not the last schema that was activated in the preceding
joke.                                                              text.
   If “wait” is not found, a setup/punchline concept pair with        The method could be initially tested on two-line question-
the second highest similarity will be considered.                  answer dialogs. The first line of the dialog should contain a
                                                                   sound-alike word with a word in the second line or with a
Parsing                                                            concept in the second line.
A syntactic structure of each sentence will be validated              The success of the joke recognition and intent recognition
through a parser. If a candidate text contains a sentence that     will depend on the success of recognizing the appropriate
does not follow the grammatical rules, the text will not be        wordplay.
considered humorous. A sentence does not follow the rules
of grammar if the parser cannot build at least one parse tree                             Bibliography
for the sentence. It is assumed that the parser uses algo-          S. Attardo, D. H. Attardo, P. Baltes, M. J. Petray (1994)
rithms based on several strategies, and builds more than one          “The linear organization of jokes: Analysis of two
parse tree for ambiguous sentences.                                   thousand texts,” Humor: International Journal of Humor
   If the setup sentence is syntactically ambiguous, each             Research, 7:1.
parse tree will be used to find semantic interpretations of the     D. Carroll (2004), Psychology of Language, Thompson
sentence. A sentence can be syntactically ambiguous and               Wadsworth, Belmont, California, 2004
contain a wordplay if the wordplay is based on words with           M. Dascal (1985) “Linguistic use in jokes and dreams:
the same spelling. The text will be considered a joke if the          Sociopragmatics vs. psychopragmatics,” Language and
punchline does not conflict with the meaning of at least one          Communication, 5(2)
parse tree.                                                         D. Dooling & R. Lachman (1971), “Effects of
                                                                      Comprehension on Retention of Prose,” Journal of
                         Summary                                      Experimental Psychology
Computational recognition of human subtexts such as hu-            R. Hasan & M. Halliday (1976), Cohesion in English,
mor is a difficult task. Humor often depends on a change in           Longman, London, 1986
context. The recognition of humorous intent depends on             R. Hetzron (1991) “On The Structure Of Punchlines,”
recognizing an intentional context change. Computational              HUMOR: International Journal of Humor Research, 4:1
context understanding has not been achieved. To make pre-          D. Jurafsky & J. Martin (2000), Speech and Language
vious context understanding easier, text can be semantically          Processing, Prentice-Hall, New Jersey, 2000
tagged.                                                            D. Lenat (1995) "Steps to Sharing Knowledge." In N. Mars
   Computational recognition of humorous intent can be di-            (Ed) Toward Very Large Knowledge Bases, IOS Press,
vided into two parts: recognition of a humorous text, and             1995.
recognition of the intent to be humorous.                          V. Raskin (1985), The Semantic Mechanisms Of Humour,
   A text is considered humorous if the first part of the text        Reidel, Dordrecht, 1985
can have two meanings, or is compatible with two scripts or        G. Ritchie (2004), “Incongruity Resolution,” Presentation at
concepts. The meaning of the punchline script has to be               Forth International Summer School and Symposium on
incompatible with the default setup script.                           Humour and Laughter, Wolverhampton, England, 2004
   The intent of the text is considered humorous if the            J. Searle (1975), “Indirect Speech Acts,” In P.Cole & J.
schema related to the non-conflicting meaning of the setup            Morgan (Eds) Syntax and Semantics: Vol. 3. Speech acts,
                                                                      New York, 1975
                                                               2171

