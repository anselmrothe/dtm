UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Colour and Stability in Embodied Representations
Permalink
https://escholarship.org/uc/item/1rf372kq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Author
Connell, Louise
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              Colour and Stability in Embodied Representations
                                     Louise Connell (louise.connell@northumbria.ac.uk)
                                           Division of Psychology, Northumbria University
                                                  Newcastle upon Tyne, NE1 8ST, UK
                              Abstract                                  shortcut offered by amodal symbols facilitates the modeling
                                                                        and testing of large-scale, complex, cognitive tasks.
   Traditional views of cognition have assumed that thought               However, criticism of amodal representations has become
   involves the representation and manipulation of discrete,            increasingly frequent of late (Barsalou, 1999; Glenberg &
   amodal symbols, while embodied theories of cognition hold            Kachak, 2002; Johnson-Laird, 1983; Pecher & Zwaan,
   that thought is grounded in the same neural systems that             2005). The main criticisms concern the interaction between
   govern sensation, perception and action. This paper examines         the external and internal world: how perception can map to
   whether implicit perceptual information on object colour is          arbitrary conceptual symbols (the transduction problem:
   represented during sentence comprehension even though
                                                                        Barsalou, 1999), and how conceptual symbols can map back
   doing so does not necessarily facilitate task performance.
   After reading a sentence that implied a particular colour for a
                                                                        to the real world (the grounding problem: Harnad, 1990).
   given object, participants were presented with a picture of that     Even if the bowl of savoury liquid in front of us can be
   object that either matched or mismatched the implied colour.         related to the arbitrary symbol SOUP, and if the symbol
   When asked if the pictured object was mentioned in the               SOUP can be related to other similar bowls of liquid, the
   preceding sentence, results showed that people’s responses           means by which this perceptual↔conceptual translation
   were faster (but less accurate) when the colours mismatched          takes place remains unknown. Without any reference to the
   than when they matched. A distinction between stable and             outside world, amodal symbols can have no meaning
   unstable embodied representations is proposed to allow               (Searle, 1980), and this has led some researchers to propose
   embodied theories to account for these findings, and                 more perceptually-grounded embodied theories of
   discussed with reference to future directions in cognitive           conceptual thought.
   modelling.
                                                                        Embodied Representations
                          Introduction                                  A growing body of empirical work has recently emerged in
Imagine a person sitting at a desk wondering whether to                 support of embodied representations of concepts.
have a sandwich or soup for lunch. This is an everyday                  Neuroimaging studies have shown how sensorimotor areas
cognitive feat, and yet is fraught with many unresolved                 in the brain are activated during language processing
issues. How do we represent a sandwich that is not actually             (Carpenter et al., 1999; Pulvermüller, 1999). In addition, it
in front of us at the time? How do we represent the notion              has been shown that “low-level” sensorimotor
of soup without a specific flavour or colour? The ability to            representations play a role in “high-level” cognitive
form and utilise conceptual knowledge is central to human               processes such as language comprehension and memory
cognitive life, and how we manage to do this is a key                   retrieval (Glenberg & Kaschak, 2002; Richardson et al.,
question in cognitive psychology and cognitive science.                 2003; Solomon & Barsalou, 2001; Stanfield & Zwaan,
                                                                        2001; Zwaan, Stanfield & Yaxley, 2002). Importantly,
Amodal Representations                                                  these studies employed implicit tasks such as recognition
Many traditional theories of conceptual thought have                    and naming, demonstrating that perceptual information is
assumed that concepts are discrete, amodal representations              activated even though doing so does not facilitate task
(e.g., Katz & Fodor, 1963; Kintsch & van Dijk, 1978;                    performance. For example, Stanfield and Zwaan (2001)
Fodor, 1975; Pylyshyn, 1984).              In such an amodal            presented people with sentences that mention objects with
representation, our hypothetical bowl of soup could be                  implied orientation (e.g., “Rick put the pencil in the cup” or
represented simply as SOUP, and we would not have to                    “Rick put the pencil in the drawer”), followed by a picture
concern ourselves with properties such as flavour or colour             of an object (e.g. a pencil). People were faster to verify that
unless we have that information available to represent (e.g.            a pencil had been mentioned in the sentence when it was
FLAVOUR:TOMATO or COLOUR:RED). Such amodal                              pictured in the orientation implied by the sentence (i.e.
theories of representation have been popular in cognitive               pictured vertically for the cup sentence, pictured
science for their computational convenience, and are a                  horizontally for the drawer sentence). This finding is
cornerstone of symbolic cognitive modelling in domains                  incompatible with amodal theories of conceptual
from language comprehension (Kintsch, 2001) and                         knowledge, which cannot account for why the orientation of
plausibility judgement (Connell & Keane, in sub.), to                   the pencil is represented when it is not specified in the
analogical reasoning (Falkenhainer, Forbus & Gentner,                   sentence. However, Stanfield and Zwaan’s findings can be
1989; Keane, Ledgeway & Duff, 1994) and more general                    explained if participants construct an embodied
cognitive architectures (Anderson, 1993; Newell, 1990).                 representation of the sentence (e.g. a sensorimotor
There are significant advantages in using an amodal                     simulation of placing a pencil in a cup/drawer), as this
approach in cognitive models, as the representational
                                                                    482

would include implied information about the pencil’s                The Current Study
orientation.                                                        In an amodal representation, the sentence “John looked at
   Although such evidence is often presented as                     the steak” could be represented by a proposition such as
underscoring the endemic problems of amodal theories of             LOOK(JOHN, STEAK). But what about the colour of the
representation, there is currently no single theory of              steak: is it red (raw) or brown (cooked)? This information is
embodied cognition that can integrate their findings.               not contained in the sentence and so we do not have a colour
Rather, theories of embodied representation share certain           attribute available for STEAK. An embodied representation
characteristics and assumptions (see Wilson, 2002) and              of this sentence would also lack this colour information, as
consider perception and action as central to higher                 simulating an individual steak does not require simulating
cognition. One of the most influential of these theories is         its colour. 1
Barsalou’s (1999) Perceptual Symbol Systems. According                 On the other hand, what if the sentence read “John looked
to this theory, concepts are essentially partial recordings of      at the steak on his plate.”? As before, an amodal
the neural activation that arises during perceptual and motor       representation does not encode any colour information as it
experiences. These recordings (or “perceptual symbols”)             only represents the explicit information in the sentence, such
can later be re-enacted as a perceptual simulation of that          as        LOOK(JOHN,STEAK[LOCATION:ON_PLATE]).
concept.                                                            However, although the sentence contains no explicit colour
   For example, to represent the concept of soup, neural            information, the placing of a steak on a plate implies that the
systems for vision, action, touch, taste, smell etc. partially      steak is cooked and therefore has a brown colour. An
reproduce our previous experiences of soup. The perceptual          embodied representation of a sentence would contain such
symbols activated for soup may include visual information           implied perceptual information by simulating an individual
of liquid in a bowl, sensorimotor information of eating hot         plate and steak and then specialising the colour of the steak
savoury liquid with a spoon, etc. Barsalou (1999) thus              to brown.
argues that Perceptual Symbol Systems theory avoids                    The study reported in this paper examines whether
transduction and grounding problems by assuming that                implicit perceptual information on object colour is
conceptual representations are based on the same systems            represented during sentence comprehension. Such a finding
that are used for perception and action.                            would be incompatible with traditional amodal theories of
                                                                    representation and cognition, and would lend support to the
          Representing Colour Information                           embodied view of mental representation. In this study,
Colour representation is a key aspect of perceptual                 participants are asked to perform an implicit recognition
information that has not received the same attention in the         task that tests whether perceptual information is activated
embodiment debate as other visual object attributes such as         even though doing so does not facilitate task performance.
shape, size and orientation. However, some studies have             Results are then related back to amodal and embodied
already indicated that colour may not be represented as a           theories of representation, and are discussed with a view to
context-free amodal attribute (such as COLOUR: X). For              the future of both theories within cognitive science.
example, when asked to compare the colour grey to black
and white, Medin and Shoben (1988) found that people                                          Experiment
considered grey to be more similar to white in the context of       This experiment presents participants with short sentences
hair, but more similar to black in the context of clouds.           followed by a picture, and asks them to indicate whether the
Similarly, Halff, Ortony, and Anderson (1976) found that            pictured object was mentioned in the sentence. For test
people represented the colour red differently for hair, wine,       items, the pictured object was always mentioned in the
flag, brick, and blood, considering the colour of a red flag to     preceding sentence but the object was shown in one of two
be more similar to a red light than a red wine. Rather than         picture conditions: matching the colour implied by the
using a single amodal symbol such as COLOUR:RED                     sentence or mismatching the colour implied in the sentence .
across concepts, people appeared to use different perceptual,       For example, the sentence “John looked at the steak on his
embodied representations.                                           plate.” was followed by a picture of a brown steak in the
   However, a colour such as red is not a constant                  match condition, but by a red steak in the mismatch
parameter: differing wavelengths of light give rise to shades       condition (note that each colour used in the match and
of red that vary in hue, saturation, and luminosity. In that        mismatch picture conditions was a valid colour
respect, it is perhaps not surprising that people consider red      representation of that particular object: raw steaks are red,
wine differently to red bricks. These findings are not              cooked steaks are brown). In addition, sentences had two
necessarily incompatible with amodal representations if one         different forms, each of which implied one of the object
argues that people are retrieving knowledge of context-             colours. Figure 1 shows a sample of the sentences versions
specific, subordinate shades of the colour category red (e.g.       and pictures used in each condition. Thus, the basic design
COLOR:WINE-RED, COLOR:BRICK-RED) rather than a                      crossed two sentence versions (version 1, version 2) with
generic superordinate COLOR:RED. Presenting people                  two picture conditions (match, mismatch).
with explicit colour terms is not a suitable paradigm for
distinguishing whether amodal or embodied symbols are
activated in representing colour information.                       1
                                                                       A default colour could be represented for steak in either an
                                                                    amodal or embodied representation, but this is not important for
                                                                    our present purposes as it does not distinguish the two theories.
                                                                483

Sentence                                                  Picture Condition
                                                          Match                                  Mismatch
John looked at the steak on his plate.
                                                                         (brown steak)                        (red steak)
John looked at the steak in the butcher’s window.
                                                                         (red steak)                          (brown steak)
            Figure 1: Sample sentences used in experiment, showing pictures used in match and mismatch conditions
   There are two important aspects of this design that differ      red steak predominantly contains shades of red). Each pair
from earlier studies such as Halff et al. (1976) that were not     of test pictures was identical except for the colours used.
concerned with the amodal/embodied distinction. First, as          All pictures were resized to a maximum of 250 pixel height
previously discussed, colour information is not explicitly         (approx. 6.9cm onscreen) and 350 pixel width (approx.
stated but rather is implied by the sentential context.            9.7cm onscreen).
Second, rather than keeping colour constant and varying the           It was important that picture recognition would not be
possible objects, the object has been kept constant and its        affected by the canonicality or view specificity of the
possible colours varied. This allows amodal and embodied           pictures (see Stanfield and Zwaan, 2001), and so each
representations to be teased apart because of their differing      picture was pretested to meet these requirements. Twenty-
predictions regarding participant response latencies               two participants were presented onscreen with an object
   In amodal representations, both sentence versions shown         name followed by a picture, and had to indicate whether the
in Figure 1 would be represented without any colour                picture matched the name. Each pair of test pictures (e.g.
information. Thus, the traditional amodal view would               red / brown steak) was separated to form two groups of
predict that people would respond equally quickly and              items and participants were randomly assigned to one of the
accurately in the match and mismatch conditions because            groups. Filler pictures were seen by both groups and were
they are simply confirming that the pictured object (e.g.          presented after semantically unrelated words, thus requiring
STEAK) was mentioned in the preceding sentence (e.g.               a “no” response. All test pictures were presented after their
LOOK(JOHN,STEAK[LOCATION:ON_PLATE]).                      The      object name and required a “yes” response. After indicating
embodied view, however, makes very different predictions.          their yes/no response, participants were asked to rate the
In embodied representations, both sentence versions would          general quality of the picture on a scale from 1 (poor
be represented with the implied colour encoded as part of          quality) to 7 (good quality). All pictures used as test items
the simulation for steak – i.e. simulating a steak on a plate      in this experiment met the following criteria: the median
would involve specializing the steak colour to the                 response time for each item was < 1250ms, there was no
appropriate brown, while simulating a steak in a butcher’s         significant difference in response times between the pictures
window would involve specializing the steak colour to the          in each test pair (all ps > 0.2), and each item received a
appropriate red. Thus, the embodied view would predict             median quality rating of at least 4 out of 7. The sole
that people will be faster and more accurate (confirming that      criterion for filler items was that each received a median
the pictured object was mentioned in the sentence) in the          quality rating of at least 4 out of 7.
match condition than in the mismatch condition.                       Forty-four sentences were constructed to accompany the
                                                                   pictures in this experiment. Of these, twenty-four were test
Method                                                             items (naming an object featured in a test picture) and
Materials. Forty-four pictures were created for use in this        twenty were fillers (naming objects not featured in either the
experiment. Of these, twenty-four were test items (forming         test or filler pictures). The test sentences thus formed pairs,
pairs of pictures) and twenty were fillers (unrelated              with each member of a pair implying a different colour for
standalone pictures). Many of the pictures came from               the same object. Filler sentences all contained at least one
popular clipart packages but some were created by the              concrete noun. In order to ensure that the test sentences
author. All pictures were coloured naturalistically by             actually implied the intended colour for the object, another
sampling shades from photographs of the relevant objects,          pretest (using 24 new participants) was conducted. Each
and contained only one predominant colour (e.g. Figure 1’s         pair of test sentences was separated to form two groups of
                                                                   items and participants were randomly assigned to one of the
                                                               484

groups. Each sentence was presented along with two                   Results & Discussion
pictures of an object mentioned in the sentence (i.e. both           Two participants that answered <50% of the comprehension
matching and mismatching pictures) and participants were             questions correctly were eliminated from the analysis. One
asked to choose, from four forced-choice alternatives,               further participant was also excluded for failing to respond
whether a) the first picture best matched the sentence, b) the       with valid keystrokes. All responses <300ms and >3000ms
second picture best matched the sentence, c) both pictures           were considered outliers and dropped from the analysis, as
equally match the sentence, or d) neither picture matches the        were any responses more than two standard deviations away
sentence. All test items used in this experiment met the             from a participant’s mean in the relevant condition.
criterion of having the picture from the matching condition          Altogether, 9% of the data was excluded in this way.
chosen at least 50% of the time.                                        Results were not wholly consistent with either the amodal
                                                                     or embodied views of representation, but were partially
Design. Test items were divided into four groups so that             consistent with the embodied view. Table 1 shows the
each group featured one of four sentence-picture                     mean correct response times and accuracy for the match and
combinations:          version1-match,       version1-mismatch,      mismatch picture conditions. Analyses of variance were run
version2-match, version2-mismatch. Each group contained              on the data by participants and by items, and interactions
equal numbers of match and mismatch test items, and the              involving the group variable are not reported due to their
various colours featured in test pictures were distributed           lack of theoretical importance. Against both amodal and
approximately evenly across groups. Participants were                embodied predictions, people responded more quickly when
assigned randomly to one of the groups. Thus, the                    the picture colour mismatched (M=1190ms, SD=542ms) the
experiment was a 2 (sentence version: version1, version2) ×          object colour implied by the sentence than when it matched
2 (picture condition: match, mismatch) × 4 (group) design,           (M=1328ms, SD=577ms), with analysis significant by
with sentence version and picture condition as within-               participants, F1(1, 41)=7.845, MSE=0.082, p<0.01; F2(1,
participants variables and group as a between-participants           31)=2.156, MSE=0.070, p=0.15.            The interaction of
variable.                                                            sentence version × picture condition was significant by
                                                                     participants, F1(1, 41)=6.212, MSE=0.103, p<0.05; F2<1.
Participants. Sixty native speakers of English from                  Accuracy (responding correctly that the pictured object was
Northumbria University (not used in pretests) were paid a            mentioned in the preceding sentence) was significantly
nominal sum for participation in this experiment.                    higher when the picture colour matched the implied colour
                                                                     (93.6%) than when it mismatched (70.2%), in line with
Procedure. Testing took place on portable computers                  embodied predictions, F1(1, 53)=56.056, p<0.0001; F2(1,
running Presentation software.                Participants read      32)=14.018, p<0.001]. The interaction of sentence version
instructions describing the experiment and instructing them          × picture condition was not significant (Fs<1).
to read each sentence and then to decide if the pictured                The profile of response times was much slower than other
object had been mentioned in the preceding sentence.                 experiments using a similar picture decision paradigm (e.g.
Participants were asked to respond as quickly as possible as         Stanfield & Zwaan, 2001; Zwaan et al., 2003), inviting the
their response time was being measured, and to read every            possibility that these slower response latencies reflect very
sentence carefully as their comprehension would be tested at         different processing and task strategies. However, even
various points during the experiment. Each trial began with          when the fastest quartile of response times per condition is
a left-aligned vertically-centred fixation cross presented for       taken2, the same pattern of response times emerges with the
1000ms, followed by presentation of a sentence. When                 mismatch picture condition (687ms) being faster than the
participants pressed the space bar to indicate comprehension         match condition (734ms). It should be noted that the other
another fixation cross was displayed centrally onscreen for          studies mentioned used black and white line drawings while
500ms, followed by a picture. Participants had to decide if          the present study uses coloured line drawings, and this extra
the pictured object had appeared in the preceding sentence           complexity may influence processing times.
and indicate their decision by pressing the key labeled “yes”           So what do these results mean for the contrasting
(the comma key) or the key labeled “no” (the full stop key).         positions of amodal and embodied representation? The
In half of all filler trials, a comprehension question (relating     predictions of the amodal view (that implied sentence colour
to the filler sentence) appeared after the picture decision.         would have no effect on people’s response speed and
Participants were required to answer an equal number of              accuracy) were not borne out by the data. The main
“yes” and “no” comprehension questions. A blank screen               prediction of the embodied view (that matching sentence
was displayed for 500ms as an inter-stimulus break between           and picture colours would facilitate faster responses) was
trials. The entire procedure took approximately 10 minutes.          not supported either. Indeed, the exact inverse was found
                                                                     with mismatching colours being faster than matching. Only
   Table 1: Mean response times with standard deviations             the accuracy prediction made by the embodied view (that
   (in ms) and accuracy rates (%) for match and mismatch             matching colours would make people more accurate in
                         picture conditions.                         confirming that the pictured object was mentioned in the
                                                                     sentence) found support in the results. The match condition
  Picture Condition       Mean RT (SD)            Accuracy
  Match                   1328 (577)              93.6%              2
                                                                       Above a minimum threshold of 300ms, response times at the 25th
  Mismatch                1190 (542)              70.2%
                                                                     percentile were 977ms (match) and 890ms (mismatch).
                                                                 485

was significantly more accurate than the mismatch                      presence, position, or shape) and hence that colour is
condition, as also found by Zwaan et al. (2002). However,              encoded with less stability in scene representations
it is interesting to note that the pattern of errors in this study     (Aginsky & Tarr, 2000; Vandenbeld & Rensink, 2003). If
does not conform to speed-acuracy tradeoff: accuracy                   an embodied sentence representation involves a perceptual
improves as responses become faster, reaching 97.6%                    simulation of visual information, then it is possible that the
(match) and 91.8% (mismatch) in the fastest quartile 2.                colour of an object (as a non-configurational property) is not
Together, these findings suggest that many of the criticisms           represented as a stable specialisation. The instability of
levelled at amodal theories are accurate: simple                       colour information in an embodied representation could be a
propositional representations of sentences cannot account              contributing factor to the overall slower response times and
for the results found in this study. However, it is also               increased error rates observed in this experiment compared
apparent that current theories of embodied representation,             to experiments concerned with more stable, configurational
such as Barsalou’s (1999) Perceptual Symbol Systems, are               shape and orientation information. More importantly, the
at present ill-equipped to explain these findings.                     instability of embodied colour information could also
   While it seems counterintuitive that people’s response              account for faster response times in the mismatch versus
times were facilitated by mismatching rather than matching             match condition. This notion will be explored further in the
colours, Naor-Raz, Tarr and Kersten (2003) reported a                  general discussion.
similar pattern of results in a modified Stroop task. They
showed participants names of concrete objects displayed in                                General Discussion
different colours (e.g. “banana” in yellow or purple text) and
                                                                       In this work, amodal and embodied theories of
measured naming times for the text colour. They found that
                                                                       representation are contrasted with a study examining the
people were faster when text colour mismatched the named
                                                                       representation of implied colour information. Results
object’s colour (e.g. “banana” in purple text) than when text
                                                                       showed that perceptual colour information is activated
and object colour matched (e.g. “banana” in yellow text).
                                                                       during sentence comprehension even though doing so does
Naor-Raz et al.’s results suggest that participants found it
                                                                       not facilitate task performance. People responded more
easier to ignore incongruent information about object colour
                                                                       accurately when the colour of a pictured object matched the
than to ignore congruent colour information. The same
                                                                       colour implied by the previous sentence. This finding is in
rationale can be applied to the results reported here. When
                                                                       line with embodied theories and is incompatible with
the colour of the pictured object is different to that implied
                                                                       amodal, propositional theories which hold that implied
by the sentence, people can compare the pictured object to
                                                                       perceptual information is not represented. In addition,
their mental representation and confirm rapidly that yes, the
                                                                       people were found to respond more slowly when the colour
object was indeed mentioned in the preceding sentence
                                                                       of a pictured object matched the colour implied by the
(ignoring differences in other properties). Conversely, when
                                                                       previous sentence. This finding is also incompatible with
the colour of the pictured object is the same as that implied
                                                                       amodal theories and is contrary to that predicted by current
by the sentence, people compare the pictured object to their
                                                                       embodied theories which hold that matching implied
mental representation and confirm that yes, the object was
                                                                       information should facilitate faster responses. So, this paper
indeed mentioned in the preceding sentence and yes, it even
                                                                       proposes a distinction between stable and unstable
matches in colour (ignoring differences in other properties).
                                                                       embodied representations as explanation for the results.
In other words, responses in the mismatching condition may
                                                                          According to Perceptual Symbol Systems theory
be faster than those in the matching condition because the
                                                                       (Barsalou, 1999), the neural systems that represent colour in
implied colour information in the sentence representation is
                                                                       perception also represent object colours (as perceptual
easier to ignore. There is some benefit to the extra
                                                                       simulations). For example, thinking about a red car
processing time consumed in the matching condition:
                                                                       involves activating the partial recordings of neural
attending to the implied colour information makes
                                                                       activation that arose during previous perceptual experiences
participants more likely to confirm accurately that the
                                                                       with cars (i.e. a perceptual simulation of car) and then
pictured object was mentioned in the preceding sentence.
                                                                       specialising the colour to red.         In short, perceptual
   But why should implied colour information produce such
                                                                       properties of objects – visual, aural, tactile, etc. – are
different behaviour to implied orientation (Stanfield &
                                                                       represented by specialising the perceptual simulation of the
Zwaan, 2001) or shape (Zwaan et al., 2002) information?
                                                                       relevant object. In this paper, the focus of the experiment
While Kaschak et al. (2005) also found mismatch
                                                                       was the representation of visual information.           When
facilitation when examining object motion, their explanation
                                                                       information that determines the configuration of a visual
– a visual stimulus “ties up” neural motion mechanisms and
                                                                       scene (shape, size, orientation, etc.) is implied by a
hinders ability to process a simultaneously-presented
                                                                       sentence, it is represented in a perceptual simulation as a
auditory sentence that describes motion in the same
                                                                       stable specialisation of the relevant object. This stability
direction – cannot explain results in this study’s sequential
                                                                       makes implied information difficult to ignore when a
presentation paradigm. One other possible explanation is
                                                                       mismatch occurs between a pictured object (e.g. a vertical
that colour, unlike other object attributes such as shape, size,
                                                                       pencil) and the preceding sentence (e.g. “Rick put the pencil
and orientation, does not have as stable a specialisation in an
                                                                       in the drawer”) (Stanfield & Zwaan, 2001). So, for stable
embodied representation. Studies of visual memory have
                                                                       embodied representations, people are slower to respond in a
suggested that colour is not as salient as other properties that
                                                                       mismatching condition than a matching condition.
determine the configuration of a scene (e.g., object
                                                                       Conversely, when information that is not salient to the
                                                                   486

configuration of a visual scene (such as colour) is implied        Glenberg, A. M., & Kaschak, M. P. (2002). Grounding
by a sentence, it is represented in a perceptual simulation as       language in action. Psychonomic Bulletin & Review, 9,
an unstable specialisation of the relevant object. This              558–565.
instability makes the implied information relatively easy to       Halff, H. M., Ortony, A. & Anderson, R. C. (1976) A
ignore when a mismatch occurs between a pictured object              context-sensitive representation of word meanings.
(e.g. a brown steak) and the preceding sentence (e.g. “John          Memory & Cognition 4, 378–83.
looked at the steak in the butcher’s window”). Thus, for           Harnad, S. (1990). The symbol grounding problem. Physica
unstable embodied representations, people are faster to              D, 42, 335-346.
respond in a mismatching condition than a matching                 Johnson-Laird, P. N. (1983). Mental models. Cambridge,
condition, as reported in the present study. Further research        MA: Harvard University Press.
on this topic (Connell, in prep.) examines whether this            Kaschak, M. P., Madden, C. J., Therriault, D. J., Yaxley, R.
stable / unstable distinction is specific to embodied                H., Aveyard, M., Blanchard, A. A., & Zwaan, R. A.
representations of familiar objects.                                 (2005). Perception of motion affects language processing.
   Nevertheless, amodal theories of representation are               Cognition, 94, B79–B89.
widely used in cognitive science and cognitive modelling,          Katz, J. J. & Fodor, J. A, (1963). The structure of a
often to valuable effect. For this reason, it is important to        Semantic Theory, Language, 39, 170-210.
observe that embodied theories of representation are not           Keane, M. T., Ledgeway, T., & Duff, S. (1994). Constraints
necessarily incompatible with the idea that cognitive tasks          on analogical mapping: A comparison of three models.
can be described in terms of computational processing.               Cognitive Science, 18, 387-438.
Many cognitive models are not functionally dependent on            Kintsch, W. (2001). Predication. Cognitive Science, 25, 173-
discrete symbols, and their views of cognitive processing            202.
would be valid irrespective of the form of the mental              Kintsch, W. & van Dijk, T. A. (1978). Toward a model of
representations actually being processed. As evidence                text comprehension and production. Psychological
grows for embodied mental representations, we gain a better          Review, 85, 363-394.
understanding of exactly what information people represent         Medin, D., & Shoben, E. (1988). Context and structure in
and how they use it across a variety of cognitive tasks.             conceptual combinations. Cognitive Psychology, 20, 158-
Future cognitive models that address such tasks should               190.
examine ways to integrate the embodied evidence and                Naor-Raz, G., Tarr, M. J., & Kersten, D. (2003). Is color an
obviate explicit commitment to ungrounded symbols. In                intrinsic property of object representation? Perception,
this way, cognitive modelling and embodied research could            32, 667-680.
mutually inform theories of cognitive processing.                  Newell, A. (1990). Unified theories of cognition.
                                                                     Cambridge, MA: Harvard University Press.
                      Acknowledgments                              Pecher, D., & Zwaan, R. A. (2005). Introduction to
                                                                     grounding cognition. In D. Pecher & R. A. Zwaan (Eds.),
This work was funded by the Division of Psychology in
                                                                     Grounding cognition: the role of perception and action in
Northumbria University. Many thanks to Dermot Lynott for
                                                                     memory, language, and thinking. Cambridge: Cambridge
helpful comments and discussion, and to Ben Singleton and
                                                                     University Press.
Darren Dunning for data collection.
                                                                   Pulvermüller, F. (1999). Words in the brain’s language.
                                                                     Behavioral & Brain Sciences, 22, 253–336.
                          References                               Pylyshyn, Z. W. (1984). Computation and cognition.
Aginsky, V., & Tarr, M. J. (2000). How are different                 Cambridge, MA: MIT Press.
   properties of a scene encoded in visual memory? Visual          Richardson, D. C., Spivey, M. J., Barsalou, L. W., &
   Cognition, 7, 147-162.                                            McRae, K. (2003). Spatial representations activated
Anderson, J. (1993). Rules of the Mind. Hillsdale, NJ:               during real-time comprehension of verbs. Cognitive
   Erlbaum.                                                          Science, 27, 767-780.
Barsalou, L. W. (1999). Perceptual symbol systems.                 Searle, J. R. (1980). Minds, brains, and programs.
   Behavioral & Brain Sciences 22, 577–660.                          Behavioral and Brain Sciences, 3, 417–24.
Carpenter, P. A., Just, M. A., Keller, T. A., Eddy, W. F.,         Solomon, K. O., & Barsalou, L. W. (2001). Representing
   Thulborn, K. R. (1999). Time course of fMRI-activation            properties locally. Cognitive Psychology 43, 129–169.
   in language and spatial networks during sentence                Stanfield, R. A., & Zwaan, R. A. (2001). The effect of
   comprehension. NeuroImage, 10, 216-224.                           implied orientation derived from verbal context on picture
Connell, L. (in prep.). Embodied representations of colour.          recognition. Psychological Science, 12, 153–156.
   Manuscript in preparation.                                      Vandenbeld, L. A., & Rensink, R. A. The decay
Connell, L., & Keane, M. T. (in sub.). A model of                    characteristics of size, color, and shape information in
   plausibility. Manuscript in submission.                           visual short-term memory. Journal of Vision, 3. 682.
Falkenhainer, B., Forbus, K., & Gentner, D. (1989). The            Wilson, M. (2002). Six views of embodied cognition.
   Structure-Mapping engine: algorithm and examples.                 Psychonomic Bulletin & Review, 9, 625–636.
   Artificial Intelligence, 41, 1-63.                              Zwaan, R.A., Stanfield, R.A., Yaxley, R.H. (2002).
Fodor, J. (1975). The language of thought. Cambridge:                Language comprehenders routinely represent the shapes
   Harvard University Press.                                         of objects? Psychological Science, 13, 168-171.
                                                               487

