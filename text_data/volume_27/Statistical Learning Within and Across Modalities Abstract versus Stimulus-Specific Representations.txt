UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Statistical Learning Within and Across Modalities: Abstract versus Stimulus-Specific
Representations
Permalink
https://escholarship.org/uc/item/8x84q3hr
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Christiansen, Morten H.
Conway, Christiopher T.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                      University of California

                             Statistical Learning Within and Across Modalities:
                              Abstract versus Stimulus-Specific Representations
       Christopher M. Conway (cmc82@cornell.edu)                          Morten H. Christiansen (mhc27@cornell.edu)
                                        Department of Psychology, Uris Hall, Cornell University
                                                          Ithaca, NY 14853 USA
                              Abstract                                 “abstractive” view posits that learning consists of extracting
                                                                       the abstract, amodal rules of the underlying input structure
   When learners encode sequential patterns and generalize their       (e.g., Marcus et al., 1999; Reber, 1993). Alternatively,
   knowledge to novel instances, are they relying on abstract or       instead of abstract knowledge, participants may be learning
   stimulus-specific representations? Artificial grammar learning
                                                                       the statistical structure of the input sequences in a modality-
   (AGL) experiments showing transfer of learning from one
   stimulus set to another has encouraged the view that learning
                                                                       or feature-specific manner (e.g., Chang & Knowlton, 2004;
   is mediated by abstract representations that are independent of     Conway & Christiansen, 2005).
   the sense modality or perceptual features of the stimuli. Using        Another unanswered question is: can people learn
   a novel modification of the standard AGL paradigm, we               different sets of statistical regularities simultaneously across
   present data to the contrary. These experiments pit abstract,       and within modalities? The answer to this question will help
   domain-general processing against stimulus-specific learning.       reveal the nature of the underlying cognitive/neural
   The results show that learning in an AGL task is mediated to a      mechanisms of statistical learning. If people can learn
   greater extent by stimulus-specific, rather than abstract,          multiple concurrent streams of statistical information
   representations. They furthermore show that learning can
                                                                       independently of one another, it may suggest the existence
   proceed separately and independently (i.e., in parallel) for
   multiple input streams that occur along separate perceptual
                                                                       of multiple, modality-specific mechanisms rather than a
   dimensions or modalities. We conclude that learning                 single amodal one.
   probabilistic structure and generalizing to novel stimuli
   inherently involves learning mechanisms that are closely tied       A Modified Artificial Grammar Design
   to perceptual features.                                             One way to explore these issues is by using the artificial
                                                                       grammar learning (AGL) task. In a standard AGL
   Keywords: statistical learning; artificial grammar learning;
                                                                       experiment (Reber, 1967), an artificial grammar is used to
   modality-specificity; crossmodal; intramodal
                                                                       generate stimuli that conform to certain rules governing the
                                                                       order that elements can occur within a sequence. After being
                           Introduction                                exposed to a subset of structured sequences under incidental
   The world is temporally bounded. The events that we                 learning conditions, it is participants’ task to classify novel
observe, as well as the behaviors we produce, occur                    stimuli in terms of whether they conform to the rules of the
sequentially over time. It is therefore important for                  grammar. Participants typically achieve a moderate degree
organisms to have the ability to process sequential                    of success despite being unable to verbally express the
information. One way of encoding sequential structure is by            nature of the rules, leading to the assumption that learning is
learning the statistical relationships between sequence                “implicit”. Furthermore, because the task presumably
elements occurring in an input stream. Statistical learning of         requires learners to extract the probabilistic structure of the
sequential structure is involved in many aspects of human              sequences, such as element co-occurrences, learning can be
and primate cognition, including skill learning, perceptual            regarded as one of computing and encoding statistically-
learning, and language processing (Conway & Christiansen,              based patterns.
2001).                                                                    We introduce a novel modification of the AGL paradigm
   Statistical learning has been demonstrated in many                  to examine the nature of statistical learning within and
domains, using auditory (Saffran, Johnson, Aslin, &                    across modalities. We used two different finite-state
Newport, 1999; Saffran, Newport, & Aslin, 1996), visual                grammars in a cross-over design such that the grammatical
(Baker, Olson, & Behrmann, 2004; Fiser & Aslin, 2002),                 test sequences of one grammar were used as the
tactile (Conway & Christiansen, 2005), and visuomotor                  ungrammatical test sequences for the other grammar. In the
stimuli (Cleeremans & McClelland, 1991; Nissen &                       training phase, each grammar was instantiated in a different
Bullemer, 1987). However, several questions remain                     sense modality (auditory tones versus color sequences,
unanswered. For instance, it is not entirely clear to what             Experiment 1) or within the same modality along different
extent learning is specific to the input modality in which it          perceptual “dimensions” (colors versus shapes, Experiment
is learned. This has been a hotly debated issue in cognitive           2A; tones versus nonwords, Experiment 2B) or within the
science (e.g., Christiansen & Curtin, 1999; Marcus, Vijayan,           same perceptual dimension (two different shape sets,
Rao, & Vishton, 1999; McClelland & Plaut, 1999;                        Experiment 3A; or two different nonword sets, Experiment
Seidenberg & Elman, 1999). Is statistical learning stimulus-           3B). At test, all sequences were instantiated in just one of
specific or is it abstract and amodal? The traditional
                                                                   488

the vocabularies they were trained on (e.g., colors or tones        intervals between them (see Conway & Christiansen, 2005).
for Experiment 1).                                                  As an example, for one participant, the Grammar A
   For example, in Experiment 1, participants were exposed          sequence “V-V-M” might be instantiated as two light green
to visual sequences of one grammar and auditory sequences           stimuli followed by a light blue stimulus, whereas for
from the other grammar. In the test phase, they observed            another participant, this same sequence might be
new grammatical sequences from both grammars, half                  instantiated as two 389 Hz tones followed by a 286 Hz tone.
generated from one grammar and half from the other.
However, for each participant, all test items were
instantiated only visually or only aurally.                                                    M
   This cross-over design allows us to make the following                                          X
prediction. If participants learn the abstract underlying rules
of both grammars, they ought to classify all sequences as                           X                             M
equally grammatical (scoring 50%). However, if they learn
statistical regularities specific to the sense modality in                                      R
                                                                                                             T
which they were instantiated, participants ought to classify a
sequence as grammatical only if the sense modality and                              V                            M
grammar are matched appropriately, in which case the
participants should score above chance levels. We also                                             V
incorporated single-grammar conditions to provide a                                            T
baseline level for comparison to dual-grammar learning.
                                                                                                 T
        Experiment 1: Crossmodal Learning                                                              X           M
Experiment 1 assesses crossmodal learning by presenting                              X            R
participants with auditory tone sequences generated from
one grammar and visual color sequences generated from a                                  M                     R
second grammar. We then test participants using novel
grammatical stimuli from each grammar that are instantiated                                        V
in one of the vocabularies only (tones or colors), cross-                             V
balanced across participants. If participants learn the                                                T
underlying statistical regularities of the grammars specific to                                  R
the sense modality in which they were presented, they ought
to classify the novel sequences appropriately. On the other
hand, if instead participants are learning the abstract,               Figure 1: Grammar A (top) and Grammar B (bottom)
amodal structure of the sequences, all test sequences will          used in all three experiments. The letters from each
appear equally grammatical, and this should be reflected in         grammar were instantiated as colors or tones (Experiment
their classification performance.                                   1), colors or shapes (Experiment 2A), tones or nonwords
                                                                    (Experiment 2B), two different shape sets (Experiment 3A),
Method                                                              or two different nonword sets (Experiment 3B).
Subjects For Experiment 1, 40 participants (10 in each                 All visual stimuli were presented in a sequential format in
condition) were recruited for extra credit from Cornell             the center of a computer screen. Auditory stimuli were
University undergraduate psychology classes.                        presented via headphones. Each element (color or tone) of a
Materials Two different finite-state grammars, Grammar A            particular sequence was presented for 500ms with 100ms
and Grammar B (shown in Figure 1), were used to generate            occurring between elements. Each sequence was separated
two sets of non-overlapping stimuli. Each grammar had 9             by 1700ms blank screen.
grammatical sequences used for the training phase and 10            Procedure Participants were randomly assigned to one of
grammatical sequences used for the test phase, all sequences        two experimental conditions or one of two baseline control
containing between three and nine elements. As Figure 1             conditions. Participants in the experimental conditions were
shows, the sequence elements were the letters X, T, M, R,           trained on color sequences from one grammar and tone
and V. For Experiment 1, each letter was in turn instantiated       sequences from the other grammar. Modality-grammar
either as one of five differently colored squares or one of         assignments were cross-balanced across participants.
five auditory tones. The five colored squares ranged along a        Additionally, the particular assignment of letters to visual or
continuum from light blue to green, chosen such that each           auditory elements was randomized for each participant.
was perceptually distinct yet similar enough to make a              Participants were told that they would hear and/or see
verbal coding strategy difficult. The five tones had                sequences of auditory and visual stimuli. Importantly, they
frequencies of 210, 245, 286, 333, and 389 Hz. These                were not explicitly told of the existence of the grammars,
frequencies were chosen because they neither conform to             underlying rules, or regularities of any kind. However, they
standard musical notes nor contain standard musical
                                                                489

were told that it was important to pay attention to the stimuli     instantiated in a different sense modality1. Perhaps
because they would be tested on what they observed. The 18          surprisingly, the levels of performance in the dual-grammar
training sequences (9 from each grammar) were presented             experimental conditions are no worse than those resulting
randomly, one at a time, in six blocks, for a total of 108          from exposure to stimuli from just one of the grammars
sequences. Note that because the order of presentation was          alone. This lack of a learning decrement suggests that
entirely random, the visual and auditory sequences were             learning of visual and auditory statistical structure occurs in
completely intermixed with one another.                             parallel and independently. Furthermore, these results stand
   In the test phase, participants were instructed that the         in contrast to previous reports showing transfer of learning
stimuli they had observed were generated according to a             in AGL between two different modalities (e.g., Altmann,
complex set of rules that determined the order of the               Dienes, & Goode, 1995). Our data essentially show a lack of
stimulus elements within each sequence. Participants were           transfer. If our participants had exhibited transfer between
told they would now be exposed to new color or tone                 the two sense modalities, then all test sequences would have
sequences that they had not yet observed. Some of these             appeared grammatical to them, driving their performance to
sequences would conform to the same set of rules as before,         chance levels. Thus, our data suggests that the knowledge of
while the others would be different. Their task was to judge        the statistical patterns, instead of being amodal or abstract,
which of the sequences followed the same rules as before            was stimulus-specific. We next ask whether learners can
and which did not. For the test phase, 20 sequences were            similarly learn from two different statistical input streams
used, 10 that were grammatical with respect to one grammar          that are within the same sense modality. In order to provide
and 10 that were grammatical with respect to the other. For         the most optimal conditions for learning, we chose the two
half of the participants, these test sequences were                 input streams so that they are as perceptually dissimilar as
instantiated using the color vocabulary (Visual-                    possible: colors versus shapes and tones versus nonwords.
Experimental condition), while for the other half, the test
sequences were instantiated using the tone vocabulary                  Experiment 2: Intramodal Learning Along
(Auditory-Experimental condition). A classification                            Different Perceptual Dimensions
judgment was scored as correct if the sequence was
correctly classified in relation to the sense modality in           The purpose of Experiment 2 is to test whether learners can
question.                                                           learn two sets of statistical regularities when they are
   Participants in the baseline control conditions followed a       presented within the same sense modality but instantiated
similar procedure except that they received training                along two different perceptual “dimensions”. Experiment
sequences from only one of the grammars, instantiated in            2A examines intramodal learning in the visual modality
just one of the sense modalities, cross-balanced across             while Experiment 2B examines auditory learning. For
participants. The nine training sequences were presented            Experiment 2A, one grammar is instantiated with colors and
randomly in blocks of six for a total of 54 presentations. The      the other with shapes. For Experiment 2B, one grammar is
baseline participants were tested using the same test set,          instantiated with tones and the other with nonwords.
instantiated with the same vocabulary with which they were
trained on. Thus, the baseline condition assesses visual and
                                                                    Method
auditory learning with one grammar alone (Visual-Baseline           Subjects For Experiment 2, 60 additional participants (10 in
and Auditory-Baseline conditions).                                  each condition) were recruited in the same manner as in
                                                                    Experiment 1.
Results and Discussion                                              Materials Experiment 2 incorporated the same two
We report mean correct classification scores (out of 20) and        grammars, training and test sequences that were used in
t-tests compared to chance levels for each group: 12.7              Experiment 1. The visual sequences were instantiated using
(63.5%), t(9)=2.76, p<.05 for the Visual-Experimental               two sets of vocabularies. The first visual vocabulary was the
condition; 14.1 (70.5%), t(9)=4.38, p<.01 for the Auditory-         same set of colors as Experiment 1. The second visual
Experimental condition; 12.4 (62.0%), t(9)=2.54, p<.05 for          vocabulary consisted of five abstract, geometric shapes.
the Visual-Baseline condition; and 13.1 (65.5%), t(9)=3.44,         These shapes were chosen as to be perceptually distinct yet
p<.01 for the Auditory-Baseline condition. Thus, each               not amenable to a verbal coding strategy. The auditory
group’s overall performance was better than what would be           sequences also were instantiated using two sets of
expected by chance. Furthermore, we compared each                   vocabularies. The first auditory vocabulary consisted of the
experimental group to its respective baseline group and             same set of tones as in Experiment 1. The second auditory
found no statistical differences: Visual-Experimental versus        vocabulary consisted of five different nonwords, recorded as
Visual-Baseline, t(9)=.22; p=.83; Auditory-Experimental             individual sound files spoken by a human speaker (taken
versus Auditory-Baseline, t(9)=1.1; p=.30.                          from Gomez, 2002): “vot”, “pel”, “dak”, “jic”, and “rud”.
   These results clearly show that participants can
                                                                    1
simultaneously learn statistical regularities from input              We regard the learning as “statistical” because encoding
generated by two separate artificial grammars, each                 something akin to “n-gram” chunks or transitional probabilities
                                                                    among sequence elements will result in above-chance test
                                                                    performance.
                                                                490

Procedure Participants were randomly assigned to one of              the same perceptual dimension (two different sets of shapes
six conditions, two for Experiment 2A, two for Experiment            and two different sets of nonwords).
2B, and two new baseline control conditions. The general
procedure was the same as in Experiment 1 with the                      Experiment 3: Intramodal Learning Within
following differences. In Experiment 2A, participants were                      the Same Perceptual Dimension
trained on both grammars, one instantiated with the color
vocabulary and the other as the shape vocabulary. As in              The purpose of Experiment 3 is to test whether learners can
Experiment 1, participants were tested on their ability to           learn two sets of statistical regularities when they are
classify novel sequences; for half of the participants, these        presented within the same sense modality but exist along the
test sequences were instantiated all as colors while for the         same perceptual “dimension”. Experiment 3A incorporates
other half they were instantiated all as shapes. Likewise, in        two different sets of visual shapes and Experiment 3B
Experiment 2B, participants were trained on both grammars,           incorporates two different sets of auditory nonwords.
one instantiated as the tone vocabulary and the other
instantiated as the nonword vocabulary. For half of these
                                                                     Method
participants, the test sequences were instantiated all as tones      Subjects For Experiment 3, 60 additional participants (10 in
and for the other half they were instantiated all as nonwords.       each condition) were recruited.
   The two new baseline conditions provided data for single-         Materials Experiment 3 incorporated the same two
grammar performance for the new shape and nonword                    grammars, training and test sequences that were used in
vocabularies (note that we used the color and tone                   Experiments 1 and 2. Like the previous experiments, the
vocabulary baseline data from Experiment 1). In all other            experimental conditions employed learning under dual-
respects, the procedure for Experiment 2 was the same as in          grammar conditions. Experiment 3A employed two visual
Experiment 1.                                                        vocabularies: shape sets 1 and 2. Shape set 1 was the same
                                                                     set of shapes used in Experiment 2A; shape set 2 was a new
Results and Discussion                                               set of shapes similar in overall appearance but perceptually
Mean scores and t-tests compared to chance levels are                distinct from set 1. Experiment 3B employed the nonword
provided for each condition: 11.9 (59.5%), t(9)=2.97, p<.05          vocabulary used in Experiment 2B as well as a new
for the Colors-Experimental condition; 11.9 (59.5%),                 nonword set consisting of “tood”, “jeen”, “gens”, “tam”,
t(9)=2.31, p<.05 for the Shapes-Experimental condition;              and “leb”.
13.7 (68.5%), t(9)=4.25, p<.01 for the Tones-Experimental            Procedure Participants were randomly assigned to one of
condition; 12.0 (60.0%), t(9)=2.58, p<.05 for the Nonwords-          six conditions, two for Experiment 3A, two for Experiment
Experimental condition; 13.2 (66.0%), t(9)=6.25, p<.001 for          3B, and two new baseline control conditions. The general
the Shapes-Baseline condition; and 12.2 (61.0%), t(9)=2.34,          procedure was identical to Experiment 2 except that
p<.05 for the Nonwords-Baseline condition. Thus, each                different vocabularies were used. In Experiment 3A, one
group’s overall performance was better than what would be            grammar was instantiated with shape set 1 and the other
expected by chance. Furthermore, there was no statistical            grammar was instantiated as shape set 2. At test, half of the
difference between the respective experimental and baseline          participants were given the test sequences instantiated as
groups: Colors-Experimental versus Colors-Baseline, t(9)=-           shape set 1 and for the other half they were instantiated as
.42, p=.68; Shapes-Experimental versus Shapes-Baseline,              shape set 2. Similarly, participants in Experiment 3B were
t(9)=-1.15, p =.28; Tones-Experimental versus Tones-                 also trained on both grammars, with one grammar being
Baseline, t(9)=.439, p=.67; Nonwords-Experimental versus             instantiated as nonword set 1 and the other instantiated as
Nonwords-Baseline, t(9)=-.178, p=.86.                                nonword set 2. Half of these participants were tested on the
   The results for Experiments 2A and 2B are similar to              first nonword set and the other half were tested on the
Experiment 1. Participants were adept at learning two                second nonword set.
different sets of statistical regularities simultaneously within        The two new baseline conditions provided data for single-
the same sense modality, for shape and color sequences               grammar performance for the new shape set 2 and nonword
(Experiment 2A) and tone and nonword sequences                       set 2 vocabularies (note that we used the shape set 1 and
(Experiment 2B). Performance levels in these dual-grammar            nonword set 1 baseline data from Experiment 2). In all other
conditions were no worse than learning levels with one               respects, the procedure for Experiment 3 was the same as in
grammar only. These results thus suggest that participants’          Experiment 2.
learning was not mediated by abstract information.
Additionally, learners can acquire statistical regularities          Results and Discussion
from two streams of information within the same sense                Mean scores and t-tests compared to chance levels are
modality, at least when the two streams differ along a major         provided for each condition: 12.0 (60.0%), t(9)=2.58, p<.05
perceptual dimension (colors versus shapes and tones versus          for the Shapes1-Experimental condition; 11.2 (56.0%),
nonwords). We next explore whether such learning abilities           t(9)=1.65, p=.13 for the Shapes2-Experimental condition;
continue even when the two streams of information lie along          10.9 (54.5%), t(9)=1.49, p =.17 for the Nonwords1-
                                                                     Experimental condition; 12.4 (62.0%), t(9)=6.47, p<.001 for
                                                                 491

the Nonwords2-Experimental condition; 11.6 (58.0%),                  test performance under such dual-grammar conditions was
t(9)=2.95, p<.05 for the Shapes2-Baseline condition; and             identical to baseline, single-grammar performance.
13.3 (66.5%), t(9)=3.79, p<.01 for the Nonwords2-Baseline            Experiments 2 and 3 extended these results, showing that
condition. We also compared each experimental group to its           learners can also learn regularities from two input streams
respective baseline performance: Shapes1-Experimental                simultaneously within the same sense modality–as long as
versus Shapes1-Baseline, t(9)=-1.68, p=.13; Shapes2-                 the respective vocabularies differ along a major perceptual
Experimental versus Shapes2-Baseline, t(9)=-.89, p=.40;              dimension. Learning suffered when the vocabularies for
Nonwords1-Experimental versus Nonwords1-Baseline,                    each grammar existed along the same perceptual dimension:
t(9)=-.99, p =.35; Nonwords2-Experimental versus                     participants could only extract statistical relationships from
Nonwords2-Baseline t(9)=-.96, p=.36.                                 just one of the two input streams, not both.
   Experiment 3 shows a decrement in performance of
statistical learning when the two grammars are composed of             15
vocabularies within the same perceptual dimension. When
exposed to two different statistically-governed streams of             14
visual input, each with a distinct vocabulary of shapes,
learners on average are only able to learn the structure for           13
one of the streams. This same result was also found when
                                                                       12
learners were exposed to two different nonword auditory
streams. This data thus suggests that learning of multiple             11
sources of statistical information is hindered when the input
elements of the two vocabularies are perceptually similar2.            10
Traditional, abstractive theories of AGL cannot account for                  Crossmodal     Intra-diff    Intra-same     Baseline
such low-level, perceptual effects.
Overal Analyses To better quantify the differences in                   Figure 2: Mean test performance (out of 20) for all three
learning across the three experiments, we submitted all data         experiments: Crossmodal (Experiment 1), Intramodal,
to a 4 X 2 X 2 ANOVA that constrasted condition                      different-dimension (Experiment 2), Intramodal, same-
(crossmodal, intramodal-different dimension, intramodal-             dimension (Experiment 3), and Baseline, single-grammar
same dimension, or baseline), modality (visual versus                conditions (Experiments 1, 2, 3).
auditory), and grammar (Grammar A versus Grammar B).
There was a main effect of condition, F(3,144)=2.66;                    These studies were motivated by two questions. First, is
p=.050. There was a marginally significant main effect of            statistical learning stimulus-specific or is it abstract and
modality, F(1,144)=2.97; p=.087. There was no main effect            amodal? The data showed that learning was tied to the
of grammar, F(1,144)=1.26; p=.264, nor were there any                specific sense modality and perceptual dimension of the
significant interactions (p’s >.05). The marginal effect of          input. This stands in contrast to other arguments that
modality is consistent with previous research showing that           learning may consist of modality-independent
auditory statistical learning of sequential input is generally       representations (Altmann et al., 1995) or abstract “rules”
superior to visual or tactile learning (Conway &                     (Marcus et al., 1999; Reber, 1993)3.
Christiansen, 2005).                                                    Second, can participants learn multiple, independent
   For ease of presentation, Figure 2 shows the overall data         statistical regularities simultaneously? Quite remarkably,
collapsed across grammar and modality. Post-hoc                      Experiments 1 and 2 showed that indeed they can, at least
comparisons reveal that the mean performance for the                 under crossmodal and intramodal (different-dimension)
intramodal, same-dimension condition is significantly less           conditions. This ability makes sense when one considers
than performance on both the crossmodal (p<.01) and                  that humans often process multiple, concurrent perceptual
baseline (p<.05) conditions. Thus, the ANOVA confirms                inputs at the same time, especially across different sensory
that there was a learning decrement in Experiment 3, for             modalities. For example, driving a car involves performing
intramodal, same-dimension learning.                                 certain motor sequences as well as attending to multiple
                                                                     visual, auditory, and haptic input patterns. It is likely that
                     General Discussion                              there is an adaptive advantage for organisms to be able to
Experiment 1 showed that learners can learn statistical              encode statistical regularities from multiple environmental
regularities from two artificial grammars presented via two          input streams simultaneously.
different input streams when they occur in different sense              It could be that the advantage that our learners displayed
modalities, one visually and the other aurally. Furthermore,         for crossmodal learning may be due to attentional
2                                                                    3
  Another interpretation of these results is that learning in          As two anonymous reviewers pointed out, an alternative
Experiment 3 was based on abstract information, leading to near-     possibility is that human cognition is an adaptive process relying
chance performance; however, it is unclear why learning would be     on stimulus-specific representations in some situations and abstract
abstract here but not so in Experiments 1 and 2.                     learning in others.
                                                                 492

constraints. It is known that people can better attend to                                          References
rapidly-presented sequential stimuli when one stream is            Alho, K., Huotilainen, M., Tiitinen, H., Ilmoniemi, R.J., Knuutila, J., &
auditory and the other is visual, compared to when both are           Naatanen, R. (1993). Memory-related processing of complex sound
in the same modality (Duncan, Martens, & Ward, 1997).                 patterns in human auditory cortex: a MEG study. Neuroreport, 4, 391-
Thus, although it is generally assumed that implicit                  394.
statistical learning does not require attention, our results       Altmann, G.T.M., Dienes, Z., & Goode, A. (1995). Modality independence
indicate that attention may play an important role (also see          of implicitly learned grammatical knowledge. Journal of Experimental
Baker et al., 2004).                                                  Psychology: Learning, Memory, & Cognition, 21, 899-912.
   Our results also may provide insight into the underlying        Baker, C.I., Olson, C.R., & Behrmann, M. (2004). Role of attention and
cognitive and neural mechanisms of statistical learning. One          perceptual grouping in visual statistical learning. Psychological Science,
possibility is that statistical learning is a single mechanism        15, 460-466.
that operates over all types of input (e.g., Kirkham,              Chang, G.Y. & Knowlton, B.J. (2004). Visual feature learning in artificial
Slemmer, & Johnson, 2002). However, such an account has               grammar classification. Journal of Experimental Psychology: Learning,
difficulty explaining the presence of learning-related                Memory, & Cognition, 30, 714-722.
modality differences (Conway & Christiansen, 2005).                Christiansen, M.H. & Curtin, S. (1999). Transfer of learning: Rule
Furthermore, it is not clear how a single mechanism can               acquisition or statistical learning? Trends in Cognitive Sciences, 3, 289-
afford simultaneous learning of multiple statistical                  290.
regularities and keep the stimulus-specific representations        Cleeremans, A. & McClelland, J. (1991). Learning the structure of event
independent of one another, as our current data show.                 sequences. Journal of Experimental Psychology: General, 120, 235-253.
                                                                   Conway, C.M. & Christiansen, M.H. (2005). Modality-constrained
   It may be more likely that statistical learning consists of
                                                                      statistical learning of tactile, visual, and auditory sequences. Journal of
multiple subsystems that are closely tied to specific
                                                                      Experimental Psychology: Learning, Memory, & Cognition, 31, 24-39.
modality-specific neural regions (Conway & Christiansen,
                                                                   Conway, C.M. & Christiansen, M.H. (2001). Sequential learning in non-
2005). For instance, the mismatch negativity brain response,
                                                                      human primates. Trends in Cognitive Sciences, 5, 539-546.
which is elicited when a deviant sound occurs in a complex         Fiser, J. & Aslin, R.N. (2002). Statistical learning of higher order temporal
sound sequence, is generated within auditory cortex (Alho,            structure from visual shape-sequences. Journal of Experimental
et al., 1993). Additionally, primary and secondary visual             Psychology: Learning, Memory, & Cognition, 28, 458-467.
association areas (BA 17-19) show decreased activity when          Gomez, R.L. (2002). Variability and detection of invariant structure.
participants learn complex visual patterns implicitly (Reber          Psychological Science, 13, 431-436.
et al., 1998), perhaps reflecting a kind of perceptual fluency     Goschke, T. (1998). Implicit learning of perceptual and motor sequences:
effect.                                                               Evidence for independent learning systems. In M. Stadler & Frensch
   Something akin to perceptual fluency may very likely               (Eds.), Handbook of implicit learning (pp. 401-444). Thousand Oaks,
underlie statistical learning, where items that are similar in        CA: Sage Publications.
structure are processed more efficiently by networks of            Keele, S.W., Ivry, R., Mayr, U., Hazeltine, E., & Heuer, H. (2003). The
neurons in modality-specific brain regions (see also Chang            cognitive and neural architecture of sequence representation.
& Knowlton, 2004). Such a view of statistical learning, and           Psychological Review, 110, 316-339.
implicit learning more generally, resonates with theories of       Marcus, G.F., Vijayan, S., Rao, S.B., & Vishton, P.M. (1999). Rule
implicit memory (Schacter, Chiu, & Ochsner, 1993) and                 learning by seven-month-old infants. Science, 283, 77-79.
procedural learning (Goschke, 1998; Keele, Ivry, Mayr,             McClelland, J.L. & Plaut, D.C. (1999). Does generalization in infant
Hazeltine, & Heuer, 2003), which also stress the                      learning implicate abstract algebra-like rules? Trends in Cognitive
involvement of multiple, modality-specific subsystems.                Sciences, 3, 166-168.
                                                                   Nissen, M.J. & Bullemer, P. (1987). Attentional requirements of learning:
                                                                      Evidence from performance measures. Cognitive Psychology, 19, 1-32.
                         Conclusion
                                                                   Reber, A.S. (1993). Implicit learning and tacit knowledge: An essay on the
These experiments suggest that statistical learning is                cognitive unconscious. Oxford University Press.
mediated by stimulus-specific representations. Furthermore,        Reber, P.J., Stark, C.E.L., & Squire, L.R. (1998). Cortical areas supporting
we’ve shown that learners can simultaneously encode                   category learning identified using functional MRI. Proceedings of the
statistical structure from two grammars originating from two          National Academy of Sciences, USA, 95, 747-750.
different input streams and keep the knowledge                     Saffran, J.R., Johnson, E.K., Aslin, R.N., & Newport, E.L. (1999).
representations independent of one another, as long as each           Statistical learning of tone sequences by human infants and adults.
is presented in a different sensory modality or along                 Cognition, 70, 27-52.
different perceptual dimensions. This suggests that the            Saffran, J.R., Newport, E.L., & Aslin, R.N. (1996). Word segmentation:
knowledge underlying statistical learning is closely tied to          The role of distributional cues. Journal of Memory and Language, 35,
the perceptual features of the material itself, perhaps               606-621.
indicating the involvement of multiple learning subsystems.        Schacter, D.L., Chiu, C.Y.P., Ochsner, K.N. (1993). Implicit memory: A
                                                                      selective review. Annual Review of Neuroscience, 16, 159-182.
                                                                   Seidenberg, M.S. & Elman, J.L. (1999). Networks are not ‘hidden rules’.
                     Acknowledgments
                                                                      Trends in Cognitive Sciences, 3, 288-289.
We thank Nick Chater for helpful comments during this
project.
                                                               493

