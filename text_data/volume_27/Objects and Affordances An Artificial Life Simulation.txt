UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Objects and Affordances: An Artificial Life Simulation
Permalink
https://escholarship.org/uc/item/949833nw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Borghi, Anna M.
Parisi, Domencio
Tsiotas, Giorgio
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

                            Objects and Affordances: An Artificial Life Simulation
                                                    Giorgio Tsiotas (tsiotas@libero.it)
                                         Department of Computer Science, 7 Mura Anteo Zamboni
                                                              Bologna, 40127 Italy
                                           Anna M. Borghi (annamaria.borghi@unibo.it)
                                               Department of Psychology, 5 Viale Berti Pichat
                                                              Bologna, 40127 Italy
                                            Domenico Parisi (domenico.parisi@istc.cnr.it)
                             Institute of Sciences and Technologies of Cognition (ISTC), 15 Viale C. Marx,
                                                                Rome, 00137 Italy
                               Abstract                                   property on an object that influences how the object can be
                                                                          used (Gibson, 1979). For example, the properties of the
   We simulated organisms with an arm terminating with a hand             handle of a door determine how one opens the door - by
   composed by two fingers, a thumb and an index, each                    pulling, or pushing, or twisting, and so on. Accordingly,
   composed by two segments, whose behavior was guided by a
                                                                          seeing an object such as a cup may re-activate the affordances
   nervous system simulated through an artificial network. The
   organisms, which evolved through a genetic algorithm, lived in
                                                                          linked to reaching and grasping the cup’s handle, even if the
   a bidimensional environment containing four objects, either            position of the handle is not relevant to the task at hand
   large or small, either grey or black. In a baseline simulation the     (Tucker & Ellis, 1998).
   organisms had to learn to grasp small objects with a precision            Most evidence regarding the strict interrelations between
   grip and large objects with a power grip. In Simulation 1 the          perception and action concerns simple interactions with
   organisms learned to perform two tasks: in Task 1 they                 objects, rather than complex actions probably mediated by the
   continued to grasp objects according to their size, in Task 2          actor's goals. So, for example, protruding object parts may
   they had to decide the objects' color by using a precision or a        activate reaching motor behaviors, whereas objects of a
   power grip. Learning occured earlier when the grip required to
                                                                          specific size may activate specific grasping behaviors. In
   respond to the object and to decide the color was the same than
   when it was not, even if object size was irrelevant to the task.
                                                                          order to refer to these “low-level” affordances, Ellis & Tucker
   The simulation replicates the result of an experiment by Tucker        (2000) created the expression of “micro-affordances”. Micro-
   & Ellis (2001) suggesting that seeing objects automatically            affordances facilitate simple and specific kinds of interactions
   activates motor information on how to grasp them.                      with objects but they do not pertain complex, goal-mediated
                                                                          actions. Most importantly, micro-affordances probably imply
                           Introduction                                   access to conceptual knowledge, as they are rather specific
In opposition to theories that posit perception and action as             and suitable for a given object. So, for example, seeing an
separate (Pylyshyn, 1999), it has recently been suggested that            object does not elicit simply a grasping behavior, but a
perception and action are strictly interwoven and that                    specific type of grasping behavior which is suitable for that
perception is guided and filtered by action (Berthoz, 1997;               particular object.
Ward, 2002). In a related way, recent theories emphasize the                 Ellis & Tucker (2000) and Tucker & Ellis (2001) have
interconnections between sensorimotor and cognitive                       demonstrated the role played by affordances in eliciting
processes. In particular, it has been proposed that cognition is          motor behavior by presenting participants with real objects of
embodied, i.e., that it depends on the experiences that result            different sizes. Participants had to categorize the objects as
from possessing a body with given physical characteristics                natural or artefact using either a power grip or a precision
and a particular sensorimotor system (Barsalou, 1999;                     grip. They found a compatibility effect between the kind of
Glenberg, 1997; Goldstone & Barsalou, 1998). This view of                 grasp and a task-irrelevant dimension, the object`s size. The
cognition is clearly in opposition to the classical cognitivist           effect was also observed when the object was located outside
view according to which mind is a device for manipulating                 the reaching space, which suggests that seeing the object
arbitrary symbols.                                                        activates the simulation of a specific type of grasping. A
   More specifically, some theories suggest that object                   similar compatibility effect was found between the direction
concepts re-enhance sensorimotor experiences with objects                 of the wrist’s rotation and the kind of grasp required by the
(Barsalou, 1999; Glenberg, 1997; Pecher & Zwaan, 2005).                   object. For example, objects such as bottles facilitated
Studies on the relationships between the visual system and the            responses with a clockwise wrist rotation, while objects such
motor system claim that seeing an object tends to evoke its               as toothbrushes facilitated a counter-clockwise wrist rotation.
affordances, re-activating previous experiences and
interactions with the object. An affordance refers to a
                                                                      2212

Aim of the paper                                                      positions. Consider that our organisms receives both
Aim of the present paper is to reproduce with an Artificial           proprioceptive and visual information, but are unable to see
Life connectionist simulation the situation explored by T&E.          their hand moving in space and to detect visually how they
A typical feature of Artificial Life connectionist simulations        are grasping the object.
is that the experimenter can control how organisms learn to
perform a given task but he or she doesn’t pre-define the
single learning steps and the organisms find their own way to
solve the problem. In our case, we first taught the organism to
grasp small and large objects using two different types of
grip, trying to reproduce in this way real life experiences in
interacting with objects. Then we reproduced Tucker &
Ellis’s (2001) experiment with some minor variations.
   Our aim was to assess whether previous grasping
experiences with objects of different size influenced the
organism’s performance when the object’s size was irrelevant
to the task at hand, i.e., in a task in which the organisms had           Figure 1: The arm and the hand of the organism and how
to perform a different kind of grip depending on the color of              sensory-motor information is encoded in the organism’s
the object they were seeing.                                                                   neural network.
   Connectionist simulations not only make it possible to
replicate behavioral tasks but they also allow us to analyze the          The behavior of the organisms is controlled by a nervous
activation patterns of the neural network’s hidden units, i.e.,        system, which is simulated with a neural network (see Figure
the neural organization that the network acquires to solve the         1 and Figure 2). The network architecture consists of 3 layers:
problem. This may seem odd, as the artificial networks used            one input layer with 3 different groups of units, one
in the simulations are enormously simplified compared to real          intermediate layer of 4 hidden units, and one output layer of 5
brains, and the analysis of hidden units’ activations may seem         units.
an impoverished replication of brain scanning techniques.
However, connectionist simulations allow us to analyze the
hidden units organization at different learning stages, which
brain scanning and other techniques can’t easily do.
                           The model
In our study we simulated artificial organisms endowed with
a visual system and a motor system. The visual system allows
the organisms to see different objects, one at a time. The
motor system consists of a single arm composed by two
segments; by moving the arm different points of space can be
reached with the arm’s endpoint (the hand) (see Figure 1).
The arm sends proprioceptive information to the organisms
that specifies the arm's current position. The arm terminates
with a hand composed by only two fingers, each in turn                            Figure 2: The neural network architecture.
composed by two segments. One of the finger, the thumb, is
shorter than the other one, the index finger. With their hand             In the input layer there are 3 groups of neurons. The first
the organisms can perform all kinds of grips. In our                  group, composed by 15 units, encodes the perceptual
simulation we were interested in two different kinds of grips.        properties of the objects that the organism “sees”. The input
The precision grip was defined by the opposition between the          value can vary within a range from 0 to 1. As shown in Figure
thumb and the index which are spatially close to each other.          1, a large object corresponds to 9 filled cells in a matrix of 15
The power grip was defined by the fact that it is a kind of grip      cells, whereas a small object corresponds to 1 filled cell in the
suitable for larger objects, i.e., the distance between the finger    same matrix of 15 cells. Grey objects are encoded with a 0.5
and the thumb is much larger than for the precision grip.             activation value; black objects with a 1.0 value. A second
Consider that the index finger can be conceived of as a               group of 2 input units encodes information specifying the task
“virtual finger”. Namely, when we grasp objects, we use all           the organism is required to perform, and a third group of 5
the fingers except the thumb as a single functional unit,             units encodes proprioceptive information. Two proprioceptive
applying force to the object (Arbib, 2002). Thus our index            input units encode the current angles between the shoulder
finger does not model only the index movements but the                and the arm and between the arm and the forearm, while the
movements of the whole hand (except the thumb). The                   remaining 3 units encode the 3 angles of the fingers (2 angles
fingers also send proprioceptive information to the organisms,        between the fingers' falangi and another one between the 2
which therefore are “aware” both of the arm and the finger            fingers).
                                                                  2213

   The 5 output units encode the movements of the organism’s                                   Simulation 1
hand and fingers, by specifying the variation of the previously      In Simulation 1 we reproduced the real-life experience of
described angles. As shown in Figure 2, the visual input units       grasping objects of different sizes in an appropriate way. In
and the task units are connected with the hidden units, while        this simulation the organisms had to learn to react
the proprioceptive input units are directly connected with the       appropriately to the object’s affordances: they had to learn
output units.                                                        that, when they saw an object, they had to reach the object
   On each trial the organism sees a single object. There are 4      and grasp it in the appropriate way, i.e., using a power grip
different objects: 2 of them are small and 2 are large. Both the     for large objects and a precision grip for small ones. This
small and the large objects can be of two different colors:          reflects exactly what we typically do in real life: we learn to
either grey or black.                                                react appropriately to objects’ affordances and to adapt our
   Each organism is a member of a population of 100                  grip to object size.
organisms. To find the connection weights which allow the               The fitness of the organisms depended on both their
organisms to perform correctly the task we used a genetic            capability to reach the visually perceived object, i.e., to bring
algorithm, the evolution strategy described by Rechenberg            the hand to the right region of space, and to grasp the object
(1973). We first assigned random connection weights to the           appropriately.
neural networks of an initial population of 100 organisms.              In order to obtain reliable results the simulation was
Each organism had a genotype encoding the organism's                 repeated 10 times, starting with different sets of initial
connection weights. We used a direct one-to-one mapping:             connection weights.
each gene encoded a different connection weight as a real
number. Then we tested each of these 100 organisms on 16             Results
randomly selected trials in Simulation 1 and on 32 randomly
selected trials in Simulation 2. In each trial each organism         All the results presented are the average of the 10
started with a randomly chosen position of the arm and               replications. We calculated the average fitness of the
fingers and saw one of the four objects. At the end of the           organisms based on the percentage of correct responses and
trials we assigned each organism a fitness value reflecting the      of errors (trials in which the organism did not reach or did not
organism's ability to perform the task.                              grasp appropriately the object) in performing the task. At the
   The fitness value was calculated when the fingers stopped         end of the simulation, i.e., after 2000 generations, the best
to move. A positive fitness value was given to the organisms         organisms were able to respond correctly to all patterns, as
if the fingers stopped while touching the borders of the object.     shown in Figure 3.
Also the distance of the fingers from the object and the
distance between the index finger and the thumb were
evaluated and influenced fitness. The 20 best organisms were
selected for (nonsexual) reproduction and each of them
generated 5 offspring inheriting their parent's genotype with
the addition of some random mutations. The 20x5=100
organisms thus obtained represented the new generation. The
process was repeated for 2000 generations.
                          Predictions
   In Simulation 1 the task consisted in reaching and grasping
appropriately the objects, i.e., the organisms had to learn to
reach the objects and to grasp small objects with a precision
grip and large objects with a power grip. Thus, Simulation 1
was simply aimed to replicate what we typically do in real
life, so we only expect that the organisms learn the task. In
Simulation 2 the organisms had two different tasks: either              Figure 3: Simulation 1. Fitness of the best organisms and
they had to grasp the object with the appropriate grip or they      average population fitness across 2000 generations.
had to respond to the object’s color by using either a precision
or a power grip. Our critical predictions concern Simulation                                   Simulation 2
2. We expect that responses are faster (in terms of number of        After being trained for 2000 generations in Simulation 1, in
generations necessary to learn the task) in case of                  Simulation 2 the organisms were trained for further 2000
compatibility between the object size and the kind of grip           generations with 2 different tasks. The 2 tasks were encoded
used to classify the object, thus suggesting that object’s size      in the 2 input task units as 01 and 10, respectively.
automatically evokes, or “affords”, a specific response. We             As in Simulation 1, the organisms saw four objects, one at
also predict that this advantage of the Compatible condition is      a time, which could be small or large, black or grey. In order
reflected in the hidden units organization.                          to make sure that the organisms didn’t “forget” what they had
                                                                     previously learned, with Task 1, encoded as 01, the organisms
                                                                2214

had to respond to the size of the object by grasping the object
with an appropriate grip, ignoring the object’s color. With           In order to control whether learning occurred earlier (in
Task 2, encoded as 10, they had to respond to the object’s         terms of number of generations) in the Compatible than in the
color, ignoring its size. They had to respond using a precision    Incompatible condition, we calculated the fitness for the best
grip when the object was grey and a power grip when the            organism of each generation in Task 1 and in Task 2, in both
object was black. Thus in Task 2 the object’s size became          the Compatible and in the Incompatible conditions; we also
irrelevant to the task.                                            calculated the population average.
   Task 2 reproduced the laboratory situation devised by              As shown in Figure 4, the fitness of the best organisms and
T&E, with some small variations. T&E asked participants to         of the population average was higher in Task 1 than in Task
classify the objects by pressing a device using either a power     2. However, the organisms learned both tasks. More
or a precision grip independent of whether natural objects         importantly, in Task 2 Compatible Condition the average
(i.e., an apple or a cherry) or artifacts (i.e., a bottle or a     fitness for all the generations tested was superior than the
needle) were small or large objects. In our simulation,            average fitness in the Incompatible Condition. The advantage
teaching the network to distinguish between natural objects        of the Compatible over the Incompatible condition was
and artifacts would have been rather implausible. For this         maintained also with respect to the performance of the best
reason we decided to train the network to respond to objects       organisms of the generations we tested (see Figure 4).
of different color. Notice that the crucial aspect of T&E’s           In order to compare the data obtained in the two conditions,
experiment was maintained: namely, the objects’ size was not       we performed four within subjects Anovas. We compared the
relevant to the task (Task 2), independent of the fact that the    average fitness of the best organisms of each of the 10
organisms had to decide what kind of object (natural/artefact)     replications in the Compatible and in the Incompatible
they were seeing, or what color (grey/black) they were seeing.     conditions at generations 500, 1000, 1500, and 2000. The
If the objects’ size affords a specific kind of action, then it    results were straightforward and confirmed our prediction. At
should influence the organisms performance not only in Task        generation 500 and 1000 the performance of the best
1, but also in Task 2.                                             organisms in the Compatible condition was significantly
   Accordingly, our crucial prediction is that in the              better than in the Incompatible condition, as indicated by the
Compatible Condition - i.e., when object size and the kind of      significant difference between the Fitness value in the
grip used to classify the object correspond - learning occurs      Compatible and in the Incompatible Condition [F (1,9) =
earlier (in terms of number of generations) than in                6.42, Mse = 2.6, p >.03;F (1,9) = 5.81, Mse = 2.87, p >.04].
Incompatible Condition. If this is true, it would suggest that     The advantage of the Compatible over the Incompatible
object’s size automatically evokes a specific kind of motor        condition dramatically decreased at generations 1500 and
response, even if object’s size is not relevant to the task at     2000, suggesting that the best organisms had learned to
hand.                                                              respond to all patterns. This clearly indicates that the
                                                                   Compatible patterns were learned earlier, in terms of number
Results                                                            of generations, than the Incompatible ones.
Simulation 2 was also repeated 10 times and the results
presented are the average of the 10 replications.
Figure 4: Simulation 2. Fitness of the Best Organisms in Task 1 and in Task 2, and comparison between the Compatible and the
                                                Incompatible Conditions in Task 2.
                                                               2215

                                                                     replications the network, in order to determine the object’s
Hidden units analysis                                                color (Task 2), does not use the same neuron used to
The results we found support our initial predictions: seeing         determine the object’s size (Task 1). The replication based on
objects automatically activates information on how to grasp          random seed 114 is a good example (see Figure 5): while the
them, also when this information is not relevant to the task.        network uses the fourth neuron for Task 1, it uses the second
The hidden units analysis we performed was aimed to detect           neuron for Task 2. This suggests that while doing Task 2 the
what kind of neural organization developed to perform the            network “keeps track” of what it has learned in Task 1, and in
tasks. More specifically, we were interested in the neural           order to determine color it does not use the same module
organization used in Task 2 in both the Compatible and               “dedicated” to size. In the remaining 4 cases, the network
Incompatible conditions. We selected the networks of the 10          distributes the information concerning color, i.e., the
best organisms of the last generation (generation 2000) and          information useful to perform the motor task, over two
analyzed their hidden units’ activation patterns. The                neurons, one of which was the one used in Task 1 to
hypotheses we wanted to test are the following. If the motor         determine the object’s size. An example is represented by the
information related to object size is automatically activated in     replication based on seed 250 (see Figure 5). This strategy has
Task 2, then: (1) the network should tend to change only the         the advantage to be quite economical, as it allows the network
activation pattern of the Incompatible condition; (2) in the         to change the values of only one of the neurons used for Task
activation pattern of the units used for Task 2, the network         1.
should keep some “trace” of what it learned in Task 1. To               Both the modular and the distributed strategies suggest that
find such a trace could help explain the advantage of the            the network did not “forget” information used for Task 1.
Compatible over the Incompatible condition.                          Consider, however, that the network could use a different
   Figure 5 shows the activation patterns of the hidden units        strategy: it could keep the neuron “dedicated” to size with the
for two replications of the simulation. In the first row of each     same values and use 2 other neurons to determine color. This
replication one can see the activation patterns of the 4 hidden      did not happen. The network worked in a very economical
units for each of the 4 patterns of Task 1, while the second         way, using only two neurons for both tasks. Thus in Task 2
row shows the activation patterns of the 4 units for each of the     the network “kept track” of Task 1, but only for the
4 patterns of Task 2.                                                Compatible condition. Otherwise it used primarily an action-
   The first and the last pattern in the second row represent the    based strategy, i.e. a strategy which was oriented to the
Compatible Condition: given a large, black object, the               output. Thus our second hypothesis is only partially
organisms have to respond with a power grip; given a small,          confirmed.
grey object, the organisms have to respond with a precision
grip. The two central patterns represent the Incompatible
Condition, i.e., the cases in which the organisms had to
respond with a power grip to a small, black object, and with a
precision grip to a large, grey object. In interpreting the
figures, our analysis will focus on the units whose value
varies, as they may be active or not active depending on the
pattern and the task.
    Figure 5 shows that in order to perform Task 1 the network
typically uses a single hidden unit, the value of which
switches from 0 to 1. For example, in Seed 250 (see Figure 5)
only the fourth neuron varies, and it has value 0 for large
objects and value 1 for small objects.
   The situation is more complex for Task 2. First of all,
consider that across all seeds the network changes the 2
values of both Incompatible patterns. In the Compatible
condition in 4 out of 10 replications the activation patterns do
not change at all, while in the remaining 6 cases, only one of
the two patterns changes. This confirms our first hypothesis,
at least for the majority of the replications: in the Compatible
condition the network maintains the same activation patterns
used in Task 1 and a new unit is simply added to encode the
new task. On the contrary, in the Incompatible condition the                Figure 5: Simulation 2. The activation pattern of the
network has to be re-organized, and different units are used to        hidden units in Task 1 (first row) and Task 2 (second row).
encode the 2 tasks.
   Consider now the strategies used by the network in Task 2.                                 Conclusion
It uses two different strategies, which we could call a               Our results confirm the findings obtained by T&E in their
“modular” strategy and a “distributed” strategy. In 6 out of 10       experiments: seeing objects automatically elicits motor
                                                                 2216

information concerning the way we interact with the objects.         Buxbaum, L. J., Schwartz, M. F., & Carew, T. G. (1997). The
Even if the object’s size is irrelevant to the task at hand,           role of semantic memory in object use. Cognitive
seeing the object activates the kind of prehension appropriate         Neuropsychology, 14, 219-254.
for its size. When the kind of grip and the object’s size are        Creem, S.H. & Proffitt, D.R. (2001). Grasping objects by
compatible, responding to the object’s color is quicker than           their handles: a necessary interaction between perception
when the kind of grip and the object’s size are not                    and action. Journal of Experimental Psychology: Human
compatible.                                                            Perception and Performance, 27,1, 218-228.
   Our simulations leave the question open of whether                Ellis, R. & Tucker, M. (2000). Micro-affordance: The
compatibility results as those that we have described imply            potentiation of components of action by seen objects.
access to conceptual knowledge. According to an influential            British Journal of Psychology, 91, 451-471.
account, two different routes to action exist: a direct vision-      Gentilucci, M. (2003). Object motor representation and
to-action route, mediated by on-line dorsal system processes,            language. Experimental Brain Research, 153, 260-265.
and a mediated vision-to-semantics-to-action ventral route           Gibson, J.J. (1979). The ecological approach to visual
(Rumiati & Humphreys, 1998). However, recent evidence                    perception. Boston: Houghton Mifflin.
suggests that the direct route to action may be limited to novel     Glenberg, A. M. (1997). What memory is for. Behavioral and
objects. With a dual task paradigm, Creem and Proffitt (2001)            Brain Sciences, 20, 1-55.
have shown that the ability to grasp common objects such as          Goldstone, R., Barsalou, L. W. (1998). Reuniting cognition
a hammer or a toothbrush appropriately by, for example,                  and perception. The perceptual bases of rules and
reaching for the object’s handle even if it is not oriented              similarity. Cognition, 65, 231-262.
towards us, decreased with a semantic interference task, but         Parisi, D., Borghi, A.M., Di Ferdinando, E. & Tsiotas, G. (in
not with a spatial interference task. This suggests that to              press). Meaning and motor actions: Artificial Life and
perform gestures appropriate to objects it is necessary to               behavioral evidence. Commentary to Arbib, M.A. (in
combine conceptual knowledge with affordances derived                    press). From monkey-like action recognition to human
from objects (Buxbaum, Schwartz & Carew, 1997). In                       language:         An        evolutionary       framework
addition, there is recent evidence of action-based                       for neurolinguistics. Behavioral and Brain Sciences.
compatibility effects, as those we obtained in the present           Pecher, D. & Zwaan, R. (2005). Grounding Cognition: The
simulation, with words rather than pictures (Borghi, Glenberg            Role of Perception and Action in Memory, Language, and
& Kaschak, 2004; Tucker & Ellis, 2004). The presence of                  Thinking. Cambridge: Cambridge University Press.
these effects also with words argues either for a                    Pylyshyn, Z. (1999). Is vision continuous with cognition? The
representation of the object encoded also in the dorsal stream           case for cognitive impenetrability of visual perception.
(Gentilucci, 2003) or for the involvement not only of the                Behavioral and Brain Sciences, 22, 341-423.
dorsal but also of the ventral system and of long-term               Rechenberg, I. (1973). Evolutionsstrategie: Optimierung
knowledge in generating affordances (Tucker & Ellis, 2004).              technischer systeme nach prinzipien der biologischen
These effects would be accounted for by long-term                        evolution. Stuttgart, Germany: Frommann-Holzboog
visuomotor associations between objects and actions executed             Verlag.
on them. Simulating compatibility effects also with words            Rumiati, R.I. & Humphreys, G.W. (1998). Recognition by
referring to objects is one of the possible extensions of our            action: Dissociating visual and semantic routes to action
work.                                                                    in normal observer. Journal of Experimental Psychology:
                                                                         Human Perception and Performance, 24, 631-647.
                     Acknowledgments                                 Tucker, M., & Ellis, R. (1998). On the relations between seen
                                                                         objects and components of potential actions. Journal of
Thanks to Andrea Di Ferdinando and Marco Mirolli for                     Experimental Psychology: Human perception and
discussion and useful suggestions.                                       performance, 24, 3, 830-846.
                                                                     Tucker, M., & Ellis, R. (2001). The potentiation of grasp
                          References                                     types during visual object categorization. Visual
Arbib, M.A. (2002). Grounding the mirror system hypothesis               Cognition, 8, 769-800.
   for the evolution of the language-ready brain. In A.              Tucker & Ellis (2004). Action priming by briefly presented
   Cangelosi, D. Parisi (eds.), Simulating the evolution of              objects. Acta Psychologica, 116, 185-203.
   language. London: Springer.                                       Vogt, S., Taylor, P., & Hopkins, B. (2003). Visuomotor
Barsalou, L.W. (1999). Perceptual Symbol Systems.                      priming by pictures of hand pictures: perspective matters.
   Behavioral and Brain Sciences, 22, 577-609.                         Neuropsychologia, 41, 941-951.
Berthoz, A. (1997). Le sens du movement. Paris: Odile Jacob.         Ward, R. (2002). Independence and integration of perception
Borghi, A.M. (2005). Object concepts and action. In D.                 and action: An introduction. Visual Cognition, 9,385-391.
   Pecher, R. Zwaan (Eds.), Grounding Cognition: The Role
   of Perception and Action in Memory, Language, and
   Thinking. Cambridge: Cambridge University Press.
Borghi, Glenberg, Kaschak (2004). Putting words in
   perspective. Memory and cognition,32, 863-873.
                                                                2217

