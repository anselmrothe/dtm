UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Interaction in Spoken Word Recognition Models: Feedback Helps
Permalink
https://escholarship.org/uc/item/24j8j91x
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Harris, Harlan D.
Magnuson, James S.
Strauss, Ted
Publication Date
2005-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                   Interaction in spoken word recognition models: Feedback helps
                                    James S. Magnuson* (james.magnuson@uconn.edu)
                                              Ted Strauss (ted.strauss@uconn.edu)
                                        Harlan D. Harris (harlan.harris@uconn.edu)
                                        Department of Psychology, University of Connecticut
                                                      Storrs, CT 06269-1020 USA
                            Abstract                                   continuously from its earliest moments. On this view, early
                                                                       and continuous access to prior knowledge will make
   A long-standing debate between autonomous and interactive           processing more efficient, essentially by tuning perceptual
   models of spoken word recognition was given new life with           systems to prior probabilities based on experience (Knill &
   the claim that not only are autonomous models more
                                                                       Richards, 1996).
   parsimonious, but feedback cannot aid recognition (Norris,
   McQueen, & Cutler, 2000). The claim was bolstered by
                                                                         While Fodor’s (1983) arguments for modularity were
   simulations with the preeminent interactive activation model,       meant to apply between rather than within input systems,
   TRACE (McClelland & Elman, 1986). When lexical feedback             similar arguments have been made for information flow
   is turned off, as many words are recognized more quickly as         within modalities. A notable example is the domain of
   are recognized less quickly (Frauenfelder & Peters, 1998),          speech perception and spoken word recognition, where this
   suggesting that feedback does not help recognition, even in         debate has recently taken center stage. The core phenomena
   the prototypical interactive model. However, these                  at issue are lexical effects on the perception of sublexical
   simulations used only a small subset of the lexicon, and did        units, e.g., phonemes (consonants and vowels), such as the
   not address a primary motivation for interaction: to make the
                                                                       word superiority effect (phonemes are detected more
   model robust in noise. We compared recognition of every
   item in a large TRACE lexicon with and without feedback
                                                                       quickly in words than nonwords; Rubin, Turvey, & Van
   under multiple levels of noise. With or without noise, most         Gelder, 1976), and phoneme restoration (context dependent
   words were recognized more quickly with feedback than               restoration of a phoneme replaced with noise or an
   without. Feedback also makes the model resistant to noise:          ambiguous sound as a function of lexical or sentential
   recognition is more accurate and faster with feedback than          context, e.g., Samuel, 1981).
   without when noise is added to the input. In short, feedback          Proponents of interactive models (e.g., McClelland &
   helps.                                                              Elman, 1986) hold that early and continuous interaction not
                                                                       only accounts for effects of top-down knowledge, but does
 Word recognition: Interactive or autonomous?                          so in a way that is efficient and leads to robust performance
The nature of information flow during perception and                   given noise (McClelland & Rumelhart, 1981). Indeed,
beyond is a central question in cognitive science. When                despite well-known deficiencies (McClelland & Elman,
should sensory data be integrated with prior knowledge?                1986; Norris, 1994), the TRACE interactive-activation
Does veridical perception require that sense data be                   model continues to hold its position as the model of speech
protected from top-down knowledge, or can direct top-down              perception and spoken word recognition that accounts for
interaction make bottom-up processing more efficient and               the broadest and deepest set of empirical phenomena.
robust in noise? Compelling arguments have been made for                 Proponents of autonomous models (e.g., Norris,
both positions. On the one hand, the case for early                    McQueen, & Cutler, 2000) argue that purely feedforward
encapsulation follows from concerns that it would be                   models can account for top-down effects via post-lexical
difficult if not impossible to balance top-down and bottom-            interaction, precluding sublexical hallucination from
up information sources so as to allow veridical perception             feedback, and avoiding the arguably more complex
(Fodor, 1983); an organism that hallucinates tigers                    machinery of feedback connections. Recently, the debate
whenever it sees a flash of orange will not be able to act             has been re-energized both empirically and theoretically.
efficiently in its environment. Instead, veridical perception          The empirical impetus came from evidence that apparently
requires an encapsulated first-pass analysis of the bottom-up          compelling evidence for interaction (that a lexically-restored
input that feeds its results forward to higher levels of               phoneme could drive compensatory coarticulatory effects at
representation where top-down knowledge can be integrated              the phoneme level, suggesting lexical feedback had truly
safely.                                                                modulated sublexical representations; Elman & McClelland,
   On the other hand, proponents of interaction argue that a           1988) could arise from a potentially sublexical locus
system can learn to balance top-down and bottom-up                     (diphone transitional probabilities) rather than from top-
interaction such that veridical perception is not sacrificed           down lexical feedback (Pitt & McQueen, 1998). Later
but top-down information is available to guide perception              studies (e.g., Magnuson, McMurray, Tanenhaus, & Aslin,
*
  Also at Haskins Labs, New Haven, CT.
                                                                  1379

2003; Samuel & Pitt, 2003) replicated the original results          the structure of lexical neighborhoods: the more words there
using lexical contexts that could not be attributed to              are with a particular sequence, the more feedback the
transitional probabilities, but not all parties are convinced       component phonemes of that sequence receive. In the case
(McQueen, 2003).                                                    of weak bottom up information (e.g., due to a low amplitude
   The theoretical impetus came from a paper by Norris et           input signal or the presence of noise), feedback will help.
al. (2000), who argued that feedback is not necessary, and          Given roughly equivalent evidence for two sublexical
furthermore, it could never help word recognition – and             alternatives, if one is contained in a word and the other is
might in fact hinder it. As Norris et al. put it:                   not, or one is contained in more words than the other,
    The best performance that could possibly be expected            feedback will push the system towards that alternative.
    from a word recognition system is to reliably identify          Given roughly equivalent bottom-up information for two
    the word whose lexical representation best matches              lexical alternatives, if one has a higher prior probability
    the input representation. This may sound trivially              (either in terms of lexical frequency [if it is implemented
    obvious, but it highlights the fact that a recognition          Dahan, Magnuson, & Tanenhaus, 2001] or sublexical
    system that simply matched the perceptual input                 frequencies implicit in the lexicon), this will be reflected in
    against each lexical entry, and then selected the entry         greater feedback and will push the system to favor the
    with the best fit, would provide an optimal means of            alternative more consistent with prior knowledge. Why,
    performing isolated word recognition (independent of            then, did FP98 fail to find a benefit of feedback? We argue
    any higher-level contextual constraints), limited only          that the apparent failure of feedback to help lexical
    by the accuracy of the representations. Adding                  recognition in TRACE stems from the failure to test the
    activation feedback from lexical nodes to the input             model in conditions where the bottom-up information does
    nodes (whether phonemic or featural) could not                  not perfectly identify a lexical alternative. We will also
    possibly improve recognition accuracy at the lexical            consider the possibility that the result may not generalize
    level (p. 301).                                                 beyond the 21-word subset FP98 tested.
Norris et al. bolstered this argument by pointing out that                     Simulations: Feedback and Noise
while feedback in TRACE does modify phonemic
                                                                    We reexamined the role of feedback in TRACE by
processing, Frauenfelder and Peeters (1998; FP98 from here
                                                                    comparing word recognition in TRACE with and without
on) showed that it does not have a “general beneficial effect
                                                                    feedback, and under levels of increasing noise. This allows
on word recognition.” FP98 compared the time it took a
                                                                    us to test the expectation that feedback in interactive-
target word to reach a threshold with feedback set to the
                                                                    activation models should make them robust to noise. We
default level or turned off (set to 0.0; their Simulation 5).
                                                                    also tested the generality of the FP98 failure to find a
They compared recognition times for a set of 21 words that
                                                                    feedback advantage without noise by testing every word in a
had been chosen for two other simulations. The expectation
                                                                    large, 901-word lexicon. FP98 only tested 21 words with
was that feedback would speed recognition, since the
                                                                    homogenous characteristics (seven-phoneme words with
bottom-up input should be amplified by recurrence via top-
                                                                    uniqueness point at phoneme position four). These were
down connections. However, FP98 found that about half
                                                                    chosen for specific reasons for their earlier simulations, but
their items were recognized more quickly without feedback
                                                                    it is possible that they are not representative of the entire
than with feedback. The implication would seem to be that
                                                                    lexicon with respect to the effects of feedback.
feedback in TRACE does not serve any useful purpose aside
from accounting for top-down effects.
                                                                    Methods
   However, the FP98 simulation does not address a crucial
motivation for feedback: it makes a model robust under                 Lexicon. We did not have access to FP98’s “biglex”
degraded conditions, such as the presence of external or            lexicon of 1024 words, so we generated our own
internal noise. This issue is addressed briefly in the original     (“biglex901”) by following the procedures FP98 describe
TRACE paper (McClelland & Elman, 1986), as it was                   for compiling biglex: we scanned a large electronic
                                                                    dictionary (20,000 words) for all items that could be
addressed in depth in the first major interactive-activation
                                                                    transcribed using only TRACE’s 14 phonemes (/p/, /b/, /t/,
paper (McClelland & Rumelhart, 1981). Noise is a crucial
                                                                    /d/, /k/, /g/, /s/, /S/, /r/, /l/, /a/, /i/, /u/, /^/). This yielded a set
ecological consideration, given considerable internal noise         of 462 words, so we substituted /^/ for schwa in the
in neural systems and the variable (and often literally noisy)      dictionary, which brought the total to 604. Collapsing across
conditions under which speech is experienced.                       vocalic and consonantal liquids (substituting /l/ and /r/ for
   One way to construe feedback in interactive-activation           both) brought the total to 901.
models is that they make the models implicit Bayesians (cf.            TRACE parameters. We used the standard (McClelland
Movellan & McClelland, 2001). The simple addition of                & Elman, 1986) settings for all but two parameters. We
feedback gives the model early and continuous access to             assumed our lexicon would work best if we modified lexical
dynamic, context-sensitive prior probabilities at multiple          inhibition and feedback as FP98 did to optimize
windows of analysis without explicit representations of the         performance with their biglex. We changed lexical
probabilities. For example, simple diphone and longer n-
phone transitional probabilities will emerge as a function of
                                                               1380

  inhibition from the standard 0.030 to 0.025, and of course,        graphical representation, scripting and batch processing, and
  we manipulated feedback.                                           is available at http://maglab.psy.uconn.edu/jtrace.html. For
     Feedback. We used three levels of feedback: none (0.00),        our current purposes, jTRACE’s ability to run large batches
  the FP98 value for lexical feedback in large lexicons (0.015)      of simulations was crucial.
  and twice that (0.030, also the value used in the standard            Procedure. Each word in the biglex901 lexicon was used
  parameter set).                                                    as the target 21 times: 3 (levels of feedback) X 7 (levels of
     Noise. Gaussian noise was sampled from a normal                 noise). We also repeated the simulations with smaller
  distribution function and added to the input stimulus values       lexicons (including the original, 212-word TRACE lexicon
  (which range from 0.0 to 1.0). The mean of the distribution        known as slex), for reasons we discuss below. In each case,
  was kept constant at 0.0, while a 7-step continuum was             the decision rule described above was applied and
  created on the standard deviation of the noise in steps            recognition time and accuracy were recorded. Simulations
  ranging from 0.0 to 1.5 in steps of 0.25.                          were run for 100 cycles. Without noise, most words in the
     Operationalizing recognition. TRACE solves the                  lexicon were recognized by cycle 95. Thus, 100 cycles
  segmentation problem by reduplicating each phoneme and             provided adequate time for recognition; accuracy would not
  word unit. For example, there are copies of the template           significantly increase at any feedback X noise level were we
  corresponding to the word “cat” aligned with the pseudo-           to run the simulations for more cycles. The items that were
  spectral trace every 3 time cycles. In this way, a “cat”           not correctly recognized typically fell short of the threshold,
  template will be closely aligned with any corresponding            and could never reach it. This issue is addressed further
  input over the entire input to the model. However, a modeler       below and by Magnuson et al. (in preparation).
  must decide how to interpret the bank of word units. FP98
  based their interpretation on the method McClelland and            Results
  Elman (1986) used for phoneme decisions: one simply                Feedback helps in the absence of noise. First, we
  chooses the unit known to be aligned with the input. FP98          examined whether we replicated the FP98 result that equal
  point out that the unit immediately to the right of the            numbers of items are recognized more quickly with and
  perfectly aligned unit sometimes attains a higher activation,      without feedback. The left panel of Figure 1 is a scatter plot
  and therefore they summed the activation of the target unit        comparing reaction times with and without feedback. Items
  perfectly aligned with the input and the unit immediately          below the equality line were recognized more quickly with
  following it. One must also decide how to treat potential          feedback than without. In fact, 73% of items in the lexicon
  competitors. FP98 considered any unit with any overlap             were recognized more quickly with feedback.
  with the target as competitors. Response probabilities were           How can we reconcile this with the FP98 report that
  then calculated at each TRACE processing step using the            feedback does not confer a general advantage? Recall that
  Luce (1959) choice rule:                                           FP98 used a set of 21 words chosen to have particular
                     e ka i                                          characteristics important for earlier simulations. The 21
            Ri =                                      (1)            words they selected consisted of all the seven-phoneme
                  ∑ e ka j                                           words in their lexicon with uniqueness point at the fourth
                                                                     phoneme. We examined whether those items might have
  where R i is the response probability for item i, a i is that
                                                                     particular combinations of neighborhood, length, etc., that
  item’s activation in TRACE, k is a constant (set to 20, as in
                                                                     could lead to the FP98 result. In our 901-word lexicon, we
  FP98 simulations) that controls target-competitor
                                                                     only had 8 items that matched the FP98 characteristics. The
  separation, and the summed activations in the denominator
                                                                     right panel of Figure 1 shows the results for those 8 items.
€ include all target and competitor units. As in the FP98
                                                                     Just as FP98 reported, there is not a general feedback
  simulations, an item was considered “recognized” when its
                                                                     advantage for items with these characteristics.
  response probability exceeded a threshold of 0.9.
                                                                        So on the one hand, the items FP98 had chosen for other
     While we have serious reservations about this decision
                                                                     simulations happened to have characteristics that seem to
  rule (in particular, the selective nature of the target and
                                                                     counteract a feedback advantage. On the other, there remain
  competitor sets), we used it to maintain consistency with
                                                                     a substantial proportion of items that are recognized more
  FP98. However, simulations with decisions rules that avoid
                                                                     quickly without feedback. Our analyses so far show that
  these problems yield quite similar results (Magnuson,
                                                                     items that are recognized more quickly without feedback fall
  Strauss, & Harris, in preparation).
                                                                     into at least one but more often two or all three of the
     Simulation software. The simulations were conducted
                                                                     following sets: (a) long words – the longer a word is, the
  using jTRACE, a recent Java reimplementation of the
                                                                     more items it overlaps with temporally, each of which can
  original TRACE C code (Strauss, Magnuson & Harris,
                                                                     inhibit it; (b) items with multiple shorter words embedded
  2005, this volume). We have successfully replicated all
                                                                     within them; (c) items that share onsets with items that get
  attempted previous TRACE simulations with jTRACE,
                                                                     early advantages from a “gang effect” – for example,
  despite minor implementational differences (e.g., the
                                                                     “colleague” (/kalig/) is recognized more quickly without
  original TRACE code depended heavily on pointer
                                                                     feedback, and its strongest competitor is “car” (/kar/), which
  arithmetic, which is not available in Java). jTRACE is also
                                                                     receives feedback from several words beginning with /ka/
  augmented with an easy to use interface, and facilities for
                                                                1381

  Figure 1: Response times in TRACE cycles with feedback (vertical axis) and without (horizontal). Items below the
  equality line are recognized more quickly with feedback. Left panel: all 901 items in the lexicon; size of a symbol
  indicates how many words lie at a point. Right panel: 8-item subset comparable to the FP98 set of 21 items.
and /kar/. In each of these cases, feedback boosts the               For each simulation, we measured accuracy and response
activation of competitor items early on such that inhibition         time (time for the response probability of a unit to exceed
from those competitors slows the target’s activation. We             the threshold).
discuss these issues in more detail in Magnuson et al. (in             Figure 2 shows accuracy and response time for each
preparation).                                                        feedback condition at each level of noise. Regarding
   Feedback makes recognition resistant to noise. Again,             accuracy, note that there is a consistent advantage with
the argument FP98 and Norris et al. (2000) make about the            feedback once the standard deviation of the noise reaches
FP98 results – that there is no general benefit to feedback –        0.5. The difference between the 0.015 and 0.030 levels of
neglects an important motivation for interactivity:                  feedback demonstrates that too much feedback has a
robustness in noise (leaving aside for the moment the fact           deleterious effect on accuracy, which suffers in the low-
that we have now found a general benefit of feedback).               noise conditions.
   This motivated us to repeat the simulations with different          Finally, we have the surprising result that accuracy
levels of noise added to the input. As described above,              without noise does not reach ceiling levels; it is a bit better
Gaussian noise with a mean of 0.0 and standard deviation             than 85% with the lower level of feedback or without
ranging from 0.0 (i.e., no noise) to 1.50 in steps of 0.25 was       feedback. The items that are not recognized were always the
added to each input unit. All words in a lexicon were tested         most active item, but could not reach the FP98 threshold.
at each noise level. We also used three levels of feedback:          These were typically short words or words in larger cohort
none (0.0), the standard level for large lexicons (0.015) and        groups.
the standard level for the original, 212-word lexicon (0.030).         To better understand why these words were problematic,
   Figure 2: Mean accuracy (left) and response time for every item in the 901-word lexicon at each level of feedback and
   noise. Error bars in the right panel represent standard error (standard error is not meaningful for accuracy, as it is based on
   a binary measure – correct or not – for each item from a single simulation). The response time curves end at different
   noise levels for different levels of feedback because accuracy falls to 0 more quickly at different levels.
                                                                1382

   Figure 3: Mean accuracy (left panel) and response time for every item in the original 212-word TRACE lexicon (slex) at
   each level of feedback and noise. Error bars in the right panel represent standard error.
we explored several possible explanations. First, we tested          a poorly-motivated mechanism that simply allows the model
whether the phoneme substitutions we used to get the                 to account for top-down effects like word superiority.
lexicon up to 901 words might be responsible, as those               Instead, the underlying motivation for feedback in
substitutions could generate unnatural neighborhoods. We             interactive activation models is to make performance robust
incrementally removed our substitutions, and repeated the            under difficult conditions, such as speech in noisy or
full set of simulations with different lexicons. First, if we do     otherwise degraded or suboptimal conditions. Our
not collapse across vocalic and consonantal liquids the              simulations show feedback substantially boosts efficiency
lexicon is reduced to 604 words, but there is not a                  under clear and difficult conditions, both in accuracy and
significant increase in accuracy. Second, if we do not               response time. This validates the original motivation for
                                                                     feedback, and demonstrates that the ability of a model like
substitute /^/ for schwa, the lexicon is further reduced, to
                                                                     TRACE to account for top-down effects emerges from a
462 words, and there is a very modest improvement in
                                                                     mechanism with an important functional purpose.
accuracy. Reducing the lexicon back to the original 212
                                                                        Why does feedback help? As we discussed earlier, the
items and using the original parameter settings brings               top-down/bottom-up resonance that feedback generates
accuracy above 98% in the no- and low-feedback                       makes an interactive activation model approximate a
conditions. The results with this lexicon are shown in Figure        Bayesian analyzer; lexical representations encode sublexical
3.                                                                   patterns of varying grain sizes that guide the system as a
   Our current best explanation is that the accuracy decline         whole towards the most likely cause of a particular input
with lexicon size reflects a scaling problem related to              pattern. Given noisy input that is consistent with two
TRACE’s small phoneme inventory. Neighborhoods                       sublexical patterns, one of which occurs in one or more
become unrealistically dense as we increase the size of the          lexical items but the other of which does not occur (e.g., a
lexicon, since we sample only from a small portion of the            segment midway between /s/ and /S/ preceding /tr/), lexical
overall phonological space of the full English lexicon.              feedback provides sublexical base-rate information, and
Furthermore, a few of the vowel representations in TRACE             guides the system to a rational response given the input.
seem to be insufficiently specific, as they occur in a larger           Some (e.g., Norris et al., 2000) have claimed that
than expected proportion of items that are not correctly             feedback   in a model like TRACE entails that the model will
recognized. For more detail, please see Magnuson et al. (in          hallucinate clear inputs when it “hears” ambiguous ones.
preparation).                                                        However, whether the model hallucinates or not is a
   The effects on response time are clear. Feedback speeds           function of the amount of feedback. Indeed, examples like
recognition (of those items recognized correctly), with an           Figures 13 and 30 in the original TRACE paper
additional advantage to increasing feedback (with an                 (McClelland & Elman, 1986) demonstrate how sensitive
accuracy trade-off, as increasing feedback also hurts                TRACE is to distorted input. In cases where ambiguous or
                                                                     incorrect phonemes are presented (e.g., /tluli/ instead of
accuracy at low levels of noise). A general benefit is
                                                                     /truli/), TRACE recognizes a word, but one cannot claim it
observed, which increases with noise.
                                                                     hallucinates the word or the restored phoneme. The word is
   In short, feedback helps.
                                                                     recognized more slowly than a clear version, and the same
                                                                     holds at the phoneme level – e.g., in the /tluli/ example, /r/ is
                    General Discussion                               activated by feedback recurrence, but not as much as it
When the performance of TRACE is examined on a large                 would be given /truli/ as the input. Furthermore, the trace
number of items under clear and noisy conditions, the                from which the model takes its name – the bank of memory
helpful role of feedback becomes apparent. Feedback is not           units aligned with points in time – contains substantial
                                                                1383

information about the surface details of the input, and                                    References
evidence that in fact /l/ rather than /r/ was “heard.”
                                                                    Cairns, P., Shillcock, R., Chater, N., & Levy, J. (1995).
   Some (e.g., Cairns et al., 1995; Norris et al., 2000) have
                                                                     Bottom-up connectionist modeling of speech. In J. P. Levy,
argued that one could account for apparent top-down lexical
                                                                     D. Bairaktaris, J. A. Bullinaria, & P. Cairns (Eds.),
effects sublexically. For example, one could build in
                                                                     Connectionist models of memory and language (pp.
sublexical base rate information by encoding diphone
                                                                     289–310). London: UCL Press.
transitional probabilities at a phonemic level of
                                                                    Dahan, D., Magnuson, J. S., & Tanenhaus, M. K. (2001a).
representation. Proponents of this view often make the
                                                                     Time course of frequency effects in spoken-word
additional argument that this is how simple recurrent
                                                                     recognition: Evidence from eye movements. Cognitive
network models of spoken word recognition work –
                                                                     Psychology, 42, 317-367.
especially those without explicit lexical representations.
                                                                    Frauenfelder, U. H., & Peeters, G. (1998). Simulating the
However, Magnuson et al. (2003) report transitional
                                                                     time course of spoken word recognition: An analysis of
probability analyses that demonstrate that for many lexical
                                                                     lexical competition in TRACE.; In J. Grainger & A. M.
effects, the relevant base rate information is item-specific;
                                                                     Jacobs (Eds.), Localist connectionist approaches to human
that is, a transitional probability explanation for one item
                                                                     cognition (pp. 101-146). Mahwah, NJ: Erlbaum.
must appeal to diphones, while triphone or larger sequences
                                                                    Knill, D. C. & Richards, W. (1996). Perception as Bayesian
are needed to account for other lexical effects. What is
                                                                     Inference, Cambridge University Press, New York, NY.
apparently needed is a dynamic, context-specific n-phone
                                                                    Magnuson, J. S., McMurray, B., Tanenhaus, M. K., &
representation, where n equals uniqueness point or word
                                                                     Aslin, R. N. (2003). Lexical effects on compensation for
length – which is exactly what lexical representations
                                                                     coarticulation: The ghost of Christmash past. Cognitive
provide.
                                                                     Science, 27, 285-298.
   Magnuson et al. also argued that such representations are
                                                                    Magnuson, J. S., Strauss, T. J., & Harris, H. D. (in
precisely what simple recurrent networks encode, even
                                                                     preparation). Feedback in models of speech perception and
though the locus of the representation need not be an
                                                                     spoken word recognition.
explicit lexical level; hidden units become sensitive to
                                                                    McClelland, J.L., & Elman, J.L. (1986). The TRACE model
context-specific short- and long-range dependencies,
                                                                     of speech perception. Cognitive Psychology, 18, 1-86.
providing a distributed lexical representation. Note that
                                                                    McClelland, James L.; Rumelhart, David E. (1981). An
those representations depend on top-down feedback: the
                                                                     interactive activation model of context effects in letter
input to a simple recurrent network at a given time step
                                                                     perception: I. An account of basic findings. Psychological
includes bottom-up signal information as well as
                                                                     Review, 88, 375-407.
information about the states of the hidden units at previous
                                                                    Movellan, J. R., & McClelland, J. L. (2001). The Morton-
time steps (via context units).
                                                                     Massaro law of information integration: Implications for
   We have made a strong case that feedback can help
                                                                     models of perception. Psychological Review, 108, 113-148.
recognition. But what of Norris et al.’s (2000) larger point –
                                                                    Norris, D. (1990). A dynamic-net model of human speech
that feedback is never necessary? Norris et al. have
                                                                     recognition. In G.T.M. Altmann (Ed.), Cognitive Models of
abandoned the strong view contained in the extended quote
                                                                     Speech Processing: Psycholinguistic and Computational
we used earlier. They now acknowledge that there are times
                                                                     Perspectives, 87-104. Cambridge: MIT.
when prior knowledge – even lexical knowledge – has a
                                                                    Norris, D., McQueen, J. M., & Cutler, A. (2000). Merging
prelexical influence (e.g., Norris, McQueen, & Cutler,
                                                                     information in speech recognition: Feedback is never
2003). We have argued against one solution – encoding
                                                                     necessary. Behavioural and Brain Sciences, 23, 299-370.
diphone transitional probabilities at the phoneme level – as
                                                                    Norris, D., McQueen, J. M., & Cutler, A. (2003). Perceptual
insufficient and certainly less efficient than lexical feedback
                                                                     learning in speech. Cognitive Psychology, 47, 204-238.
for accounting for the dynamic, context-sensitive scope of
                                                                    Pitt, M. A. and McQueen, J. M. (1998). Is compensation for
relevant probabilities. Norris et al. have speculated that
                                                                     coarticulation mediated by the lexicon. Journal of Memory
there is another solution that avoids online lexical feedback:
                                                                     and Language, 39, 347-370.
feedback for learning (in analogy to backpropagation) could
                                                                    Rubin, P., Turvey, M. T., & van Gelder, P. (1976). Initial
change feedforward phoneme-to-lexeme weights after
                                                                     phonemes are detected faster in spoken words than in
processing. It remains to be seen whether such a mechanism
                                                                     spoken nonwords. Perception & Psychphys., 19, 384–398.
can be implemented, but it keeps open the possibility that
                                                                    Samuel, A. G. (1981). Phonemic restoration: Insights from a
online feedback may not be necessary. However, given that
                                                                     new methodology. Journal of Experimental Psychology:
online feedback can help – as we have demonstrated here –
                                                                     General, 110, 474-494.
it has the potential to provide a more parsimonious account,
                                                                    Samuel, A. G. & Pitt, M. A. (2003). Lexical activation (and
if online feedback can also provide a basis for short- and
                                                                     other factors) can mediate compensation for coarticulation.
long-term learning. Learning is beyond the current scope of
                                                                     Journal of Memory & Language, 48, 416-434.
TRACE, and we leave this question for future research.
                                                                    Strauss, T. J., Magnuson, J. S., & Harris, H. D. (2005).
                                                                     jTRACE: A reimplementation and extension of the
                    Acknowledgments                                  TRACE model of speech perception and spoken word
Supported by National Institute on Deafness and Other                recognition.
Communication Disorders Grant DC-005765 to JSM.
                                                               1384

