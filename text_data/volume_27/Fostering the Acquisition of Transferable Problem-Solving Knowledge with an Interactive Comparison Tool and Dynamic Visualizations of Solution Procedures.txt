UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Fostering the Acquisition of Transferable Problem-Solving Knowledge with an Interactive
Comparison Tool and Dynamic Visualizations of Solution Procedures

Permalink
https://escholarship.org/uc/item/7126h2xg

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Gerjets, Peter
Scheiter, Katharina
Schuh, Julia

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Fostering the Acquisition of Transferable Problem-Solving Knowledge with an
Interactive Comparison Tool and Dynamic Visualizations of Solution Procedures
Julia Schuh (j.schuh@iwm-kmrc.de)
Virtual Ph.D. Program: Knowledge Acquisition and Knowledge Exchange with New Media
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany
Peter Gerjets (p.gerjets@iwm-kmrc.de)
Multimedia and Hypermedia Research Unit, Knowledge Media Research Center
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany
Katharina Scheiter (k.scheiter@iwm-kmrc.de)
Department of Applied Cognitive Psychology and Media Psychology, University of Tuebingen
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany

Abstract
Learning from worked-out examples is seen as a very efficient
way to foster the acquisition of problem schemas. In this paper
we demonstrate that computer-based instruction provides possibilities to further enhance example-based learning. In an experiment carried out with 59 pupils with an average age of 14.0
years from a German high school we first demonstrated that a
tool which prompted learners to compare examples across different problem categories in the domain of algebra fostered performance on near transfer problems, which differed from the
instructional examples with regard to their surface features.
However, only the dynamic visualizations of the examples’
solution procedures additionally improved performance on far
transfer problems, which differed from instructional examples
with regard to their structural features. It is assumed that while
the comparison tool supports the induction of an abstract problem schema, the visualizations help to understand relations below the category level, which is required to successfully adapt
known solution procedures to changes in the problem structure.
Keywords: skill acquisition; problem solving; visualization;
animation; worked-out examples; transfer

Acquiring Transferable Problem-Solving
Knowledge from Worked-Out Examples
The problem-solving knowledge that is characteristic for expertise in well-structured domains like mathematics, science,
or programming is usually assumed to consist of interrelated
and hierarchically organized sets of problem schemas
(Sweller, van Merriënboer, & Paas, 1998; VanLehn, 1996).
Problem schemas are cognitive structures that represent
problem categories together with category-specific solution
procedures in an abstracted way. Schemas can be acquired by
either solving or studying concrete instances of problem categories (i.e., example problems). However, they go far beyond
these concrete instances by highlighting structural problem
features that are important for a problem’s category membership and by detaching these structural features from merely
incidental surface features of the domain context or cover
story that are irrelevant to the problem’s solution. Because of
their abstract nature problem schemas allow to efficiently
1973

solve problems that belong to one of the represented problem
categories. Once a to-be-solved problem has been identified
as belonging to a known problem category the relevant
schema can be retrieved from memory, can then be instantiated with the information that is specific to the problem, and
finally the category-specific solution procedure attached to
the schema can be executed in order to generate a solution.
Studying worked examples (i.e., example problems together
with a step-by-step solution) has been demonstrated to be an
efficient instructional method to foster the acquisition of
problem schemas (for an overview see Atkinson, Derry,
Renkl, & Wortham, 2000).
With regard to problem-solving transfer, abstracting problem schemas from concrete examples is assumed to be a pivotal cognitive process to overcome the so-called near-transfer
problem, which occurs when learners have to deploy knowledge that has been acquired in one concrete problem-solving
situation to solve structurally equivalent problems that merely
differ with regard to their superficial problem features. However, the availability of problem schemas per se does not
seem to be sufficient to tackle the far-transfer problem that
occurs when learners have to solve novel tasks that do not fall
into known problem categories and that accordingly require
an adaptation of a known solution procedure. To improve
learners’ ability for far transfer it is necessary to help them
understand relations below the category level, that is, relations holding irrespective of category membership such as
relations between individual structural task features and individual solution steps (Gerjets, Scheiter, & Catrambone,
2004). Understanding the rationale behind the overall solution
procedure might result in more meaningful knowledge on
modular solution elements that enables learners to directly
translate individual structural task features into characteristics
of the problem solution. This knowledge might be much more
helpful than conventional knowledge on problem categories
and solution recipes for adapting solution procedures to novel
problems beyond the known categories (cf. Catrambone,
1998).

As research on problem-solving transfer has shown, the
mere availability of worked-out examples is not sufficient to
guarantee an adequate schematic representation of problem
categories and an understanding of solution procedures.
Rather, a profitable processing of worked examples has to be
ensured. Such processing is likely to include example comparisons and example elaborations as the most important activities. Therefore, we will investigate two instructional devices in this paper that can be expected to facilitate the acquisition of transferable problem-solving knowledge. First, we
will explore whether a computer-based comparison tool that
prompts learners to compare worked-out examples with regard to their similarities and differences might facilitate the
induction of problem schemas and therefore improve neartransfer performance. Second, we will test whether the use of
dynamic visualizations for the illustration of meaningful solution elements might be suitable to deepen learners’ example
elaborations and their understanding of the rationale behind
the overall solution procedure, thereby improving their ability
to solve far-transfer problems.

Comparing Instructional Examples
It has often been advocated to provide learners with multiple
examples that allow them to compare examples within and
among problem categories with regard to their differences
and similarities. These comparisons might enable learners to
identify the defining features of problem categories and to
avoid confusions by examples' surface features (Quilici &
Mayer, 1996). For instance, learners can infer that shared
properties of examples from the same problem category may
potentially be the structural features that determine a problem’s membership to a specific problem category. These
features cannot be altered without altering the solution procedure that applies to a problem. Without these comparison
processes learners might tend to induce superficial problem
schemas, to categorize test problems according to their surface features, and in turn to apply inappropriate solution procedures to them. In previous research (Scheiter, Gerjets, &
Schuh, 2004) we could, however, demonstrate that comparing
multiple examples within problem categories is not a necessary prerequisite for the acquisition of problem schemas.
Rather, there are promising example-processing strategies
that rely on single examples per problem category and that
are similarly effective, namely comparing examples across
problem categories. However, in order to have learners profit
substantially from across-category comparisons it is necessary to carefully design example combinations so that they
enable useful inferences with regard to structural and surface
features of the examples presented. In particular, the surface
features of examples should be kept constant across problem
categories in order to allow learners to recognize that these
surface features are not suitable to determine a problem’s
membership to a specific problem category (cf., Quilici &
Mayer, 1996). Accordingly, the comparison tool used in this
study is designed to prompt learners to compare worked-out
examples that share surface features, but differ with regard to
the problem category they belong to according to their com1974

munalities and differences. These across-category comparison
processes can be expected to facilitate the identification of
structural and surface features of the examples and thus to
stimulate the acquisition of correct problem schemas that
enable learners to solve near-transfer problems.

Dynamic Visualizations of Solution Procedures
A common finding in learning from worked-out examples is
that learners “tend to form solution procedures that consist of
a long series of steps – which are frequently tied to incidental
features of the problems – rather than more meaningful representations that would enable them to successfully tackle new
problems” (Catrambone, 1998, p. 355). To overcome these
shallow representations of solutions, learners have to draw
inferences concerning the structure of example solutions, the
rationale behind solution procedures, and the goals that are to
be accomplished by individual solution steps. Without such
an understanding it cannot be expected that learners are able
to flexibly modify a known solution procedure in order to
adapt it to novel problems beyond the known problem categories. In this paper we investigate whether embellishing
worked-out examples with dynamic visualizations of solution
procedures is a suitable method to stimulate learners’ inferences with regard to the relations between solution steps,
goals, and abstract principles that provide the rationale behind
a solution procedure.
Visualizations of solution procedures may act as external
representations, which support reasoning in the domain by
facilitating the interpretation of the problem situation and
inferences based on the information given. Thus, they can be
more computational effective than a mere text-based representation of the same information (Larkin & Simon, 1987).
Moreover, as Stenning and Oberlander (1995) have noted,
visualizations may reduce the ambiguity of a verbal problem
statement, because they depict the intended interpretation
rather than allowing for multiple interpretations like verbal
representations often do. Thus, visualizations may be more
specific than verbal representations and may guide learners in
understanding what a problem is about and how it can be
solved. According to Mayer’s multimedia principle (2001)
embellishing textual learning materials by static pictures or
dynamic visualizations (i.e., animations) helps promote learners’ understanding of instructions. With regard to the acquisition of problem-solving knowledge, visualizations of workedout examples may first help learners to understand the situation described in the problem statement (i.e., the initial problem state) and thus to correctly represent its meaning in a
situation model. Second, visualizations of the solution steps
may promote the understanding of changes with regard to the
initial problem state, which are achieved by applying a solution step to a problem (Scheiter, Gerjets, & Catrambone, in
press).
Several findings suggest that animations can be used successfully for delivering abstract content such as mathematical
rules, Newton’s laws, or computer algorithms (Byrne, Catrambone, & Stasko, 1999; Catrambone & Seay, 2002). With
respect to conveying problem-solving knowledge, the visualspatial properties of the visualization may be used to deliver

information on the current problem state and its relevant
structural features. Moreover, the changes over time that can
be depicted in an animation may be used to reflect the
changes in problem states that result from applying a solution
step to a specific problem state of the example (Scheiter et al.,
in press). Having this type of dynamic visualizations of solution procedures at their disposal might enable learners to better understand individual solution steps as a prerequisite for
solving not only near-transfer problems but also far-transfer
problems.

Hypotheses
As a first hypothesis we advocate that the provision of an
interactive comparison tool as well as the provision of dynamic visualizations leads to a superior overall problemsolving performance.
Second, it is hypothesized that an increase in problemsolving performance when learning with the interactive comparison tool can be traced back to improvements for near
transfer test problems.
Third, we assume that an increase in problem-solving performance when learning with dynamic visualizations can be
traced back to improvements both for near and far transfer
test problems.

Experiment
Method
Participants. Subjects were 59 pupils (9th grade) from a
German high school who attended a project day on “learning
with new media”. The average age was 14.0 years.
Materials and Procedure. The pupils used a computer-based
learning and problem-solving environment, which conveyed
knowledge on how to solve algebra word problems. The experiment was divided into two phases, a learning and a test
phase. During the learning phase pupils were asked to read
three textbook chapters on different school subjects, namely
biology, chemistry, and politics, which were presented on the
computer screen. They started with a chapter taken from a
biology textbook that dealt with forest dieback, which was
followed by a chapter from a chemistry schoolbook that explained alcoholic fermentation. Finally, pupils worked on a
chapter from a politics book, which pointed out some general
rules about the election process of the German parliament.
Embedded in each of the three chapters were three algebraic worked-out examples that illustrated how to solve specific problems in these domains. The following biology example is related to forest dieback. It can be solved by using
the algebraic formula: A = a1/b1 * c1 + a2/b2 * c2:
In an experimental area for the observation of forest
dieback, one part of the trees are deciduous trees
and the other part are coniferous trees, the latter including spruces and pines. 1/10 of the 489 pines and
1/4 of the 1793 spruces are damaged. How many
coniferous trees have been damaged?
1975

For each of the nine worked-out examples, the solution formula as well as each step of the solution procedure were presented. Depending on the experimental condition the workedout examples were either presented as text only or they were
accompanied by an interactive comparison tool, a dynamic
visualization of their solution procedure, or both.
Within each chapter, the three worked-out examples differed with regard to the complexity of their underlying solution procedure, that is, each worked-out example required a
different algebraic formula. These three formulas were identical across the three school subjects. That is, participants read
nine worked-out examples embedded into three different domain contexts (variation of superficial example features) and
they were confronted with three different algebraic formulas
(variation of structural example features).
Learners were asked to intensively study the three chapters
and especially to pay attention to the worked-out examples
before entering the test phase of the experiment. In the test
phase pupils were instructed to solve 21 algebraic word
problems. The worked-out examples of the learning phase
were not available during the test phase. Learners were asked
to write down their solutions on a sheet of paper. For solving
the problems, they were allowed to use a calculator. The
overall time for learning and problem solving was restricted
to 120 minutes.
Design and Dependent Measures. As a first independent
variable the provision of a comparison tool for the workedout examples during learning was varied. As a second independent variable we implemented dynamic visualizations of
solution procedures that learners either could retrieve or not.
Thus, the following four experimental conditions of the resulting 2x2-design can be differentiated:
In an experimental condition without comparison tool and
without dynamic visualizations (baseline condition) learners
were presented with text-based worked-out examples only.
The experimental condition with comparison tool but without dynamic visualization (comparison condition) contained
the same three textbook chapters and the same worked-out
examples as the baseline condition. But after the learners had
read the three chapters they were instructed to use an interactive comparison tool before switching to the test phase (cf.
Figure 1). This interactive comparison tool was based on
hyperlinks and multiple pop-up windows that allowed learners to quickly compare different worked-out examples from
the biology content domain with regard to their similarities
and differences. Based on our prior research (Scheiter et al.,
2004), the comparisons across problem categories (i.e., examples with different solution formulas) that were highlighted
by this tool were considered to be particularly helpful for
learning. Learners were instructed to use the comparison tool
as often as they wanted, but in minimum three times before
entering the test phase.

zation depicted the two forest species. This visualization was
transformed into an abstract visualization, in which the trees
were represented by small squares (in the abovementioned
example 489 small squares represented pines and 1793 small
squares represented spruces). The small squares were merged
into two bigger squares, which each represented the numbers
of objects mentioned in the example problem (i.e., 489 and
1793). The rates mentioned in the word problem were represented by dividing these bigger squares into parts of equal
size (in the abovementioned example 1/10 and 1/4). The final
addition of the two rates was illustrated by merging the two
square parts that represented the numbers of damaged pines
and spruces. This type of abstract visualization using squares
was used for all examples so that the visualizations of all examples shared a common representation of objects and their
relevant relations. Learners could replay each visualization as
often as they wanted, but were asked to view it at least once
for each of the example’s components.

Figure 1: The comparison tool
(Note: The upper part depicts the start screen of the comparison tool. The lower part illustrates how to-be-compared examples were presented, once a learner had selected a comparison on the start screen).
In the experimental condition without comparison tool but
with dynamic visualizations (visualization condition), we
provided learners with dynamic visualizations of worked-out
examples and their solution procedure (cf. Figure 2). For each
worked-out example there was one dynamic visualization of
the problem statement and one visualization for each of the
individual steps of the solution procedure. The visualizations
of a problem statement illustrated the transition between a
concrete problem representation and a more abstracted representation of its structural features. The problem statement was
first depicted by using the concrete objects mentioned in the
example, which then changed into more abstract objects so
that only the structural problem features were represented in
the visualization, while superficial features were excluded.
For instance, if an example dealt with calculating a certain
number of damaged coniferous trees out of two different forest species with different damage rates, the concrete visuali1976

Figure 2: Screenshot of a worked-out example with dynamic visualizations of the solution procedure
We assumed that the common abstract visual representation
across examples would help learners to focus on the structural
similarities and differences between the examples while being
able to ignore their surface features. Furthermore, breaking
down a solution procedure into a sequence of meaningful
steps and visualizing the rationale behind each step should

This analysis yielded a significant main effect for the comparison tool (F(1,55) = 6.42; MSE = 199.27; p < .02), showing
that this tool led to an increase in problem-solving performance as expected. Additionally, dynamic visualizations also
fostered learning outcomes (F(1,55) = 18.72; MSE = 199.27; p
< .001). The interaction between these two factors was not
significant (F < 1).
To test whether improvements in performance in the comparison conditions are due to a performance increase for near
transfer problems only, we conducted two separate ANOVAs
(comparison tool x dynamic visualization) for performance
on near and far transfer problems (Figure 4 and 5). As expected, this analysis yielded a significant main effect of the
comparison tool on near transfer problems (F(1,55) = 6.66;
MSE = 268.48; p < .02), but not on far transfer problems
(F(1,55) = 2.58; MSE = 250.71; p > .10).
probl.-solv. performance (%)

enhance learners’ understanding of the solution procedure and
thus also foster far transfer.
The experimental condition with comparison tool and dynamic visualization (combined condition), provided learners
with a combination of both instructional methods. Thus, we
offered to them the dynamic visualizations as described before while they studied worked-out examples. Additionally,
learners were asked to use the interactive comparison tool to
compare different worked-out examples at the end of the
learning phase. However, the worked-out examples that could
be retrieved by using the comparison tool were purely textbased and did not comprise any pictorial information.
As a dependent measure, we registered learners’ performance for solving 21 problems in the test phase of the experiment. These problems differed in their transfer distance with
regard to the examples presented in the learning phase. We
distinguished between two levels of transfer, namely, near
transfer and far transfer. For both, near and transfer problems,
new cover stories were used that learners had not encountered
in the learning phase. Some of these cover stories were related to domain contexts already known from the learning
phase (e.g., biology), while others were related to new domain contexts (e.g. physics). Whereas near transfer problems
could be solved by using one of the three solution formulas
presented during the learning phase (e.g., A = a1/b1 * c1 +
a2/b2 * c2), far transfer problems could only be solved by constructing a new solution formula, for instance by modifying a
known formula (e.g., A = a1/b1 * c1 + a2/b2 * c2 + K). Each of
the 21 problems resulted in a maximum of five points (i.e.,
two points for setting up the right formula, two points for
inserting the right values into the formula, and one point for
solving the formula correctly). For each individual the percentage of correct responses in relation to the maximum score
was calculated for easier interpretation.

90

Comparison
Tool

Dynamic
Visualization

80
70
60

Far
Transfer

80
70
60
50
40

with comparison tool

Figure 4: Problem-solving performance (in %) for near
and far transfer problems as a function of the
provision of the comparison tool
Finally, we were able to demonstrate that dynamic visualizations improved performance for both, near transfer problems
(F(1,55) = 6.38; MSE = 268.48; p < .02) and far transfer
problems (F(1,55) = 35.15; MSE = 250.71; p < .001). There
was no interaction between the two factors (F < 1).
probl.-solv. performance (%)

probl.-solv. performance (%)

100

90

Near
Transfer

without comparison tool

Results
Due to the time limitations in the experiment all conditions
where comparable with regard to learning times. In a first step
we compared participants’ overall problem-solving performance across the four conditions (Figure 3) by means of an
ANOVA (comparison tool x dynamic visualization).

100

100
90

Near
Transfer

Far
Transfer

80
70
60
50
40

50

without dynamic visualization

40

without

with

without

with dynamic visualization

with

Figure 5: Problem-solving performance
(in %) for near and far transfer problems as a
function of the provision of dynamic visualizations

Figure 3: Overall problem-solving performance
(in %) as a function of the provision of the
comparison tool and dynamic visualizations
1977

Summary and Conclusions
In this paper we were able to demonstrate that a tool that
helps learners abstract from the irrelevant surface features of
examples by having them compare these examples facilitates
performance for solving near transfer problems. While near
transfer problems require learners to apply their knowledge to
problems that are unfamiliar with regard to the cover story
they are embedded in, far transfer problems additionally make
it necessary to adapt known solution procedures to differences in structural features. Providing learners with dynamic
visualizations that depict the initial problem state as well as
changes to this problem state resulting from applying a solution step to the problem did not only foster learners’ performance when solving near transfer problems (like the comparison tool), but also improved far transfer.
This experiment confirms prior findings (Quilici & Mayer,
1996; Scheiter et al., 2004) that comparing examples with the
same surface features across categories supports the acquisition of abstract problem schemas. Unfortunately, this schematic knowledge is tied to the boundaries of problem categories, thus only fostering performance on near transfer problems, which originate from the same categories as the examples previously studied. However, in order to foster knowledge on relations below the category level as required for
solving far transfer problems, an instructional approach is
needed that guides learners’ attention to the individual solution steps carried out to solve a problem. While the dynamic
visualizations used in this experiment proved very suited to
provide this guidance, there is evidence that not every visualization is similar effective. In the study by Scheiter et al. (in
press) visualizations that used the examples’ concrete objects
throughout the whole solution procedure actually led to deteriorations in problem-solving performance. Thus, the effectiveness of the visualizations of the current study seem to
reside in the fact that they help learners to translate a concrete
example into an abstracted representation, based on which
mathematical operations can be carried out more easily (e.g.,
determining ratios for different objects). This conclusion is
line with the work by Larkin and Simon (1987) hinting to the
fact that the effectiveness of external representations is based
on the way they support specific cognitive processes that have
been deemed important in the domain in question. Accordingly, the statement that text and pictures aid learning more
than text does alone – as expressed in Mayer’s multimedia
principle (2001) – is an oversimplification. Rather, the usefulness of a visualization very much depends on the learning
domain itself, the kind of cognitive processes required for
achieving deeper understanding in this domain, and the way
the visualization is designed to support these processes. Thus,
the current results do not necessarily tell us anything regarding the effectiveness of visualizations in general; rather, they
show that abstraction as a cognitive process relevant to the
acquisition of transferable problem-solving knowledge can be
facilitated if the dynamic visualization is designed to reflect
this abstraction by showing the transition from a concrete
problem statement to an abstract mathematical representation
of the problem and its solution. Further research, however,

needs to be conducted to investigate whether the benefits of
visualizing worked-out examples can also be demonstrated
for more difficult problems that require more extensive adaptations of known solution procedures than the far transfer
problems used in the current study.
It is important to note that both the comparison tool and the
dynamic visualizations were more effective than the baseline,
while not requiring more time for learning (thus they were
also more efficient). From an instructor’s perspective the efficiency of an instructional method is an important argument
that needs to be considered in particular when designing instructional materials for classroom settings.

References
Atkinson, R. K., Derry, S. J., Renkl, A., & Wortham, D. W.
(2000). Learning from examples: Instructional principles
from the worked examples research. Review of Educational
Research, 70, 181-214.
Byrne, M. D., Catrambone, R., & Stasko, J. T. (1999). Evaluating animations as student aids in learning computer algorithms. Computers & Education, 33, 253-278.
Catrambone, R., & Seay, F. A. (2002). Using animations to
help students learn computer algorithms. Human Factors,
44, 495-511.
Catrambone, R. (1998). The subgoal learning model: Creating
better examples to improve transfer to novel problems.
Journal of Experimental Psychology: General, 127, 355376.
Gerjets, P., Scheiter, K., & Catrambone, R. (2004). Designing
instructional examples to reduce intrinsic cognitive load:
Molar versus modular presentation of solution procedures.
Instructional Science, 32, 33-58.
Larkin, J. H., & Simon, H. (1987). Why a diagram is (sometimes) worth ten thousand words. Cognitive Science, 11, 6599.
Mayer, R. E. (2001). Multimedia learning. Cambridge, MA:
Cambridge University Press.
Quilici, J. L., & Mayer, R. E. (1996). Role of examples in how
students learn to categorize statistics word problems. Journal of Educational Psychology, 88, 144-161.
Scheiter, K., Gerjets, P., & Catrambone, R. (in press). Making
the abstract concrete: Visualizing mathematical solution
procedures. Computers in Human Behavior.
Scheiter, K, Gerjets, P. & Schuh, J. (2004). The impact of
example comparisons on schema acquisition: Do learners
really need multiple examples? In Y. B., Kafai, B. Sandoval, N. Enyedy, A. S. Nixon & F. Herrera (Eds.), Proceedings of the 6th International Conference of the Learning Sciences. Mahwah, NJ: Erlbaum.
Stenning, K., & Oberlander, J. (1995). A cognitive theory of
graphical and linguistic reasoning: Logic and implementation. Cognitive Science, 19, 97-140.
Sweller, J., van Merriënboer, J. J. G., & Paas, F. W. C. (1998).
Cognitive architecture and instructional design. Educational
Psychology Review, 10, 251-296.
VanLehn, K. (1996). Cognitive skill acquisition. Annual Review of Psychology, 47, 513-539.

1978

