UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Role of Neurocomputational Principles in Skill Savings
Permalink
https://escholarship.org/uc/item/5m63x7v1
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Gupta, Ashish
Noelle, David C.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

            The Role of Neurocomputational Principles in Skill Savings
                                            Ashish Gupta & David C. Noelle
                                     ({ashish.gupta, david.noelle}@vanderbilt.edu)
                                 Department of Electrical Engineering and Computer Science
                            Vanderbilt University, Box 1679 Station B Nashville, TN 37235, USA
                            Abstract                                 behaviors. From this perspective, savings arise when
                                                                     the interference produced by experience with new be-
   Humans exhibit savings in skills. A skill is rarely forgot-       haviors is insufficient to completely erase the synaptic
   ten completely, even if it remains unused for long peri-          modifications introduced by the initial learning of the
   ods. Also, the reacquisition of a skill to its previous level
   of competence is faster than initial skill learning. Tradi-       skill. This lack of “unlearning” could be due to neu-
   tional artificial neural network models of skill learning         ral specialization, with some neurons being employed by
   have been unable to exhibit savings comparable to that            the first skill but not by subsequent activities. To the
   seen in humans because they suffer from catastrophic in-          degree that the sets of neurons associated with differ-
   terference. They are commonly trained to perform only
   one specific task, and when trained on a new task, they           ent skills are disjoint, learning one skill will not affect
   forget the original task completely. A number of special-         the synapses associated with another. When neurons
   ized connectionist architectures and learning rules have          are shared between skills, savings could be due to sub-
   been suggested as means to avoid catastrophic interfer-           threshold residual synaptic weights associated with the
   ence. Instead of introducing such a new mechanism,                initial skill — weights that have been driven down by
   we have investigated the degree to which the founda-
   tional neurocomputational principles embodied by the              interfering experiences to below the threshold for neural
   Leabra cognitive modeling framework are sufficient to             firing, but not all the way down to their initial values.
   ameliorate catastrophic interference. In particular, this         Finally, skills may share components or “sub-tasks”. To
   framework includes both fast lateral inhibition and a             the degree that such components have isolated neural
   local synaptic plasticity model that incorporates both
   Hebbian and error-based dynamics, grounded in known               representations, learning a new skill may actually rein-
   properties of cortical circuits. In this paper, we provide        force portions of a previously learned skill.
   evidence that these fundamental computational proper-                Traditional artificial neural network models of skill ac-
   ties of neural circuits can support savings during sequen-
   tial learning of multiple motor skills.                           quisition fail to display savings when skills are learned se-
                                                                     quentially. Instead, these networks exhibit “catastrophic
                                                                     interference”, where the later learning of a second re-
                        Introduction                                 lated skill obliterates essentially all knowledge of an ini-
Learned motor skills are central to many activities, from            tially acquired skill (McCloskey and Cohen, 1989). Re-
bicycle riding to piano playing, from typing to playing              searchers have proposed a number of specialized neu-
ping-pong. To maintain and improve our motor skills,                 ral network architectures and learning algorithms de-
we need practice. If a ping-pong player does not play                signed to reduce catastrophic interference (French, 1994;
for a while, it is likely that his proficiency will wane,            Brashers-Krug et al., 1995; McClelland et al., 1995).
but the skill will not be forgotten completely. Further-             Most of these proposed mechanisms involve isolating the
more, reacquistion of proficiency will typically be rapid,           sets of neurons associated with different skills, either
as compared to the period of initial learning. This re-              through some form of explicit architectural modulariza-
tention of skill knowledge, sometimes in a latent form, is           tion, or through the use of learned sparse representa-
called savings.                                                      tions, where only a few neurons in some internal layer of
   Why do skills degrade when unpracticed? What is                   the network are highly active at any one time.
the neural basis of skill savings? A common explana-                    We have explored the possibility that computational
tion of proficiency loss involves interference. The ini-             models of skill acquisition need not posit dedicated
tial acquisition of a skill is driven by synaptic plasticity         mechanisms for shielding from catastrophic interference.
shaped by experience. Plasticity continues once practice             Instead, it is possible that biological constraints im-
on that skill ceases. Thus experience with other activ-              posed by the structure of cortical circuitry may em-
ities continues to shape neural circuits, often in a way             body the necessary properties to promote skill savings.
that interferes with the proper performance of the orig-             Specifically, we have examined the neurocomputational
inal skill. The interfering task experience may modify               principles forming the Leabra cognitive modeling frame-
the response properties of neurons that are directly in-             work (O’Reilly and Munakata, 2000), and we have found
volved in the performance of the original skill, or the              that these biologically motivated principles give rise to
interference might take the form of a strengthening of               savings without the need for auxiliary mechanisms. We
the response of competing neurons that encode the new                trained a Leabra network to produce motion trajectories
                                                                 863

for a three joint planar arm. After an initial trajectory       across synapses. In addition to this error-correction
was mastered, an interfering trajectory was taught, and         mechanism, Leabra also incorporates a Hebbian corre-
savings was assessed on the retention of knowledge con-         lational learning rule. This means that synaptic weights
cerning the initial trajectory. Our findings suggest that       will continue to change even when task performance is
Leabra’s implementation of fast acting lateral inhibition       essentially perfect. This form of correlational learning
acts in concert with its synaptic plasticity mechanism          allows Leabra to capture certain effects of overlearning.
in order to produce adequately sparse representations to           We have investigated the degree to which the sparse
support skill savings.                                          representations enforced by Leabra’s lateral inhibition
   In the next section, we provide a brief overview of re-      mechanism, in conjunction with Leabra’s synaptic learn-
lated work. We follow that with a description of our            ing rule, cause Leabra simulations of cortical circuits
model simulation experiments. Then, we offer the re-            to escape the pitfalls of catastrophic interference when
sults of our experiments, and we close with a general           those circuits are required to sequentially learn multiple
discussion.                                                     temporally-extended motor trajectories.
                       Background                               Catastrophic Interference
Leabra                                                          Many past studies have shown that artificial neural net-
The Leabra framework offers a collection of integrated          works suffer from catastrophic interference in a manner
cognitive modeling formalisms that are grounded in              uncharacteristic of human performance. The seminal ex-
known properties of cortical circuits but are sufficiently      ample involves an AB-AC paired-associate list-learning
abstract to support the simulation of behaviors aris-           task, in which the learning of a second list of paired-
ing from large neural systems (O’Reilly and Munakata,           associates was shown to interfere with memory for an
2000). It includes dendritic integration using a point-         initially studied list in a much more mild way than pre-
neuron approximation, a firing rate model of neural             dicted by a backpropagation network model (McCloskey
coding, bidirectional excitation between cortical regions,      and Cohen, 1989).
fast feedforward and feedback inhibition, and a mecha-             Since this observation was made, a number of com-
nism for synaptic plasticity. Of particular relevance to        putational mechanisms have been proposed for avoiding
skill savings are Leabra’s lateral inhibition formalism and     catastrophic interference. Some of these involve segre-
its synaptic learning rule.                                     gating the neural units associated with different skills in
   The effects of inhibitory interneurons tend to be strong     order to avoid the damage caused by “reuse” of synaptic
and fast in cortex. This allows inhibition to act in a          weights (French, 1999). For example, forcing layers of
regulatory role, mediating the positive feedback of bidi-       neural units to form sparse representations reduces the
rectional excitatory connections between brain regions.         probability that a given unit will be active while per-
Simulation studies have shown that a combination of             forming multiple skills and thereby reduces the probabil-
fast feedforward and feedback inhibition can produce            ity of interference when learning the skills in sequence.
a kind of “set-point dynamics”, where the mean firing           Leabra offers a biologically justified mechanism for pro-
rate of cells in a given region remains relatively constant     ducing sparse representations. With a low k parameter,
in the face of moderate changes to the mean strength            Leabra’s kWTA lateral inhibition implementation limits
of inputs. As inputs become stronger, they drive in-            the overlap between the neural representations used for
hibitory interneurons as well as excitatory pyramidal           different skills. This has been shown to improve per-
cells, producing a dynamic balance between excitation           formance on the AB-AC list-learning task (O’Reilly and
and inhibition. Leabra implements this dynamic using            Munakata, 2000). We have found that the benefits of
a k-Winners-Take-All (kWTA) inhibition function that            kWTA inhibition extend to the learning of motor se-
quickly modulates the amount of pooled inhibition pre-          quences, and we have systematically studied the effects
sented to a layer of simulated cortical neural units based      of varying sparsity and layer size on savings.
on the layer’s level of input activity. This results in a          One extreme form of segregation between neurons de-
roughly constant number of units surpassing their fir-          voted to different skills involves isolating them into dis-
ing threshold. The amount of lateral inhibition within a        crete modules. Modular artificial neural network ar-
layer can be parameterized in a number of ways, with the        chitectures have been proposed in which differences be-
most common being the percentage of the units in the            tween skills are explicitly detected during learning, and
layer that are expected, on average, to surpass thresh-         a “fresh” module of neural units is engaged to learn the
old. A layer of neural units with a small value of this k       skill, protecting previously trained modules from inter-
parameter (e.g., 10-25%) will produce sparse representa-        ference (Brashers-Krug et al., 1995). Importantly, over-
tions, with few units being active at once.                     learning of a skill can strengthen its consolidation in a
   With regard to learning, Leabra modifies the strength        module, increasing resistance to interference, as is ob-
of synaptic connections in two primary ways. An error-          served in humans (Brashers-Krug et al., 1996; Shadmehr
correction learning algorithm changes synaptic weights          and Holcomb, 1997). While such modular models can ex-
so as to improve network task performance. Unlike               hibit robust savings and appropriately limited forms of
the backpropagation of error algorithm, Leabra’s error-         interference, we question the biological plausibility of a
correction scheme does not require the biologically im-         reserve of untrained neural modules awaiting assignment
plausible communication of error information backward           when a new skill is to be learned.
                                                            864

   Modular approaches of this kind should be distin-
guished, from the hypothesis that the hippocampus and
the neocortex form distinct learning systems (McClel-
land et al., 1995). This hypothesis asserts that catas-
trophic interference is alleviated through the use of a
fast hippocampal learning system that uses sparse rep-
resentations. While neocortical systems are assumed to
use a less sparse representations, making them more vul-
nerable to interference, problems are avoided through a
hippocampally mediated process of consolidation, where
neocortical networks receive interleaved “virtual” prac-
tice in multiple skills. In addition to explicit hippocam-
                                                                Figure 1: Left: A three joint planar arm. The state of
pal models, this strategy has also been embodied in
pseudo-pattern models, in which savings is facilitated by       the arm at any point in time is given by the vector of
a process of knowledge transfer between multiple sep-           joint angles: (q1, q2, q3). Right: The Leabra network.
arate networks (Robins, 1995). While we see this ap-
proach as extremely promising, there is evidence that                Task 2    Nothing in common with Task 1.
humans can continue to learn new motor skills even af-               Task 3    Joint 1 matches Task 1 at all steps.
ter complete removal of the hippocampus (Jenkins et al.,             Task 4    Joints 1 & 2 match Task 1 at all steps.
1994). From our perspective, this suggests that neocorti-            Task 5    For steps 6–10, all joints match Task 1.
cal representations may be sufficiently sparse to support            Task 6    For steps 6–15, all joints match Task 1.
savings in motor skills. Thus, we report the results of
simulations exploring the effects on savings of varying
sparsity of representation. We have also tested the abil-       Table 1: Similarities between various tasks as compared
ity of Leabra’s learning rule to account for overlearning       to Task 1, over the 18 time steps that make up each task.
effects without recourse to a separate memory consoli-
dation mechanism.
   While sparsity may play an important role in sav-            by a Leabra network (Figure 1). The state of the arm at
ings, other neurocomputational mechanisms may also              any point in time is represented by the three joint angles.
contribute. It is possible that synaptic changes dur-           The position of a joint can range from 0◦ to 90◦ . Six dif-
ing the learning of an interfering skill may drive certain      ferent motion trajectories were used in our simulations:
neurons associated with a previously learned skill below        Task 1 to Task 6. Each trajectory is discretized into 18
their firing threshold — but just below — allowing them         time steps. Thus, motion trajectories are represented as
to recover quickly once practice of the previous skill is       a sequence of arm states at successive points in time.
resumed. This is exactly the mechanism posited for sav-         Each of the six trajectories were non-Markovian with re-
ings after extinction in a biophysically detailed model of      gard to individual joint angles but were Markovian with
the role of the cerebellum in eye blink conditioning (Med-      regard to the complete state of the arm. In other words,
ina et al., 2001). Savings through subthreshold respond-        it is not possible to reliably predict the future position
ing is consistent with the Leabra learning rule, and it         of a joint given only its current position, but the set of
will be the focus of future analysis.                           three joint angles is always sufficient to predict the arm
   Lastly, it is worth noting that savings might be facili-     configuration at the next time step.
tated if the multiple skills to be learned share some com-         Task 1 was used as the primary task in all the simula-
mon structure, such as a shared sub-task. In this case,         tions. The network was always trained on this task first.
training in a skill may reinforce components of a previ-        Then, the network was trained on one of the other tasks.
ously learned skill. Artificial neural networks trained         Finally, we measured the extent to which the network
in an interleaved manner to produce multiple motor              remembered Task 1. Table 1 describes the similarities
sequences have been found to generate internal repre-           between tasks.
sentations that reflect common sub-sequences, allowing             Each of the joint angles was encoded in the Leabra
knowledge of those sub-tasks to be generalized across           network over a pool of 12 neural units. Each of the 12
tasks (Botvinick and Plaut, 2004). We have found sim-           units had a preferred angle, ranging from −10◦ to 100◦
ilar generalization of sub-tasks when skills are learned        in 10◦ increments. If the angle to be encoded was a mul-
sequentially by a Leabra network, and we have found             tiple of ten, the corresponding unit, as well as its two
that this has a positive effect on savings. Thus, Leabra’s      neighbors, were set to their maximal firing rates. Oth-
support for sparse representations does not prevent neu-        erwise, the two units with preferred angles that straddle
ron sharing across skills when doing so is appropriate.         the angle to be encoded were set to fire maximally, and
                                                                their neighbors were set to an intermediate activation
                        Methods                                 level. Similarly, patterns of activity over the 12 units
                                                                were decoded by locating the three or four adjacent units
The Tasks                                                       that were all active and computing the weighted sum of
We have performed simulation experiments involving the          the preferred angles of those units, weighted by their ac-
learning of motion trajectories of a three joint planar arm     tivity (i.e., normalized firing rate). Other patterns of
                                                            865

activity were considered ill-formed. With each joint an-
gle encoded over 12 units in this way, the complete arm
configuration could be encoded over a layer of 36 units.
The Network
Figure 1 shows the Leabra network used in our simula-
tions. On each time step, the network was provided with
a 36 unit input that encodes the current state of the
arm. Complete interconnections from this input layer
to a hidden layer produced an internal representation of
the current arm state, with the sparsity of this repre-
sentation controlled by lateral inhibition within the hid-       Figure 2: Savings as a function of sparsity. An SSE
den layer. Complete bidirectional excitatory connections
                                                                 ratio of one or more indicates no savings, while lower
map this internal representation to an output layer that
is intended to encode the next arm state in the current          values indicate retention of Task 1 knowledge. The k
trajectory. Lateral inhibition in the output layer was           parameter roughly equals the percentage of active units
set to encourage well-formed angle codes (i.e., approx-          in the hidden layer. Error bars display standard errors
imately 9 units highly active out of the 36). During             of the mean.
training, the output layer was also provided with a tar-
get signal, indicating the correct arm configuration for
the next time step. The arrow on the right side of Fig-                                    Results
ure 1 indicates that the output on a given time step be-
came the network’s input on the subsequent time step,            Sparse Representations
matching other recurrent network architectures (Jordan,
1986). The context layer contained two units, each cor-          In this set of experiments, we explored the contribution
responding to one of the two learned tasks, indicating           of sparse representations to savings. For this set of ex-
which trajectory was to be produced by the network.              periments, the size of the hidden layer was set to 100
This context information was not initially included in           units, but the amount of lateral inhibition was varied.
our simulations and is described later.                          Tasks were trained until a zero SSE (within error toler-
   Most of the parameters used in our simulations were           ance) was achieved for three successive trajectory execu-
Leabra default values. Hebbian learning was strength-            tions. Using Task 2 as the second task, the SSE Ratio as
ened in our simulations, contributing to 1% of synaptic          a function of the hidden layer kWTA parameter is shown
weight changes rather than the default 0.1%. An error            in Figure 2.
tolerance of 0.25 was used, treating outputs within 0.25            Savings were greater (lower SSE ratio) when sparser
normalized firing rate of their targets as correct. A small      representations were used (lower k value). The likely
amount of activation noise was also added to the input           reason for this effect is a decrease in the overlap between
layer, sampled uniformly from [-0.05, +0.05].                    Task 1 and Task 2 hidden layer activation patterns as
   There are two common measures of savings: exact               representations become more sparse. To test this hy-
recognition and relearning (French, 1999). The exact             pothesis, we counted the number of hidden layer units
recognition measure assesses the percentage of the origi-        that were active (at least 0.05 activation) during one task
nal task that the network performs correctly after it has        but not during the other. This number of discriminating
learned a second task. The relearning measure exam-              units was high for sparse representations (e.g., about 30
ines how long it takes the network to relearn the original       for k = 10) and very low for dense representations (e.g.,
task. The two measures are usually correlated. We used           about 2 for k = 50). Thus, increasing inhibition pro-
an exact recognition measure to assess savings. In par-          duced more distinct internal representations between the
ticular, we measured the sum-squared error (SSE) of the          tasks and resulted in improved savings. The BP network
network output on the first task after training the second       performed worse than the sparse Leabra network. This
task. In order to contrast this SSE value with “complete         was as expected, since there was no explicit mechanism
forgetting” of the first task, the SSE was also recorded         to facilitate non-overlapping hidden layer representation
prior to the first task training, and we report the ratio of     in the BP network.
SSE after interference training to SSE of the untrained             We also manipulated sparsity by fixing the number
network. A value of one or more for this ratio indi-             of active units in the hidden layer to 10 while varying
cates complete forgetting of the initial task, while lower       the absolute number of units in the layer to 25, 100 and
values indicate savings. We repeated each experimental           1000. Once again, savings, as measured by the SSE ra-
condition five times in order to deal with stochastic vari-      tio, increased substantially with sparsity in the Leabra
ations in our simulations. We report the average of these        network. With a layer size of 25 units, the SSE ratio was
repetitions. For comparison, we have also reported the           about 0.6, but it dropped to less than 0.2 with 1000 hid-
results of running all the experiments on a traditional          den units. The SSE ratios for the BP network dropped
backpropagation (BP) artificial neural network.                  from 0.63 to 0.28 as hidden layer size increased.
                                                             866

Figure 3: Savings as a function of sparsity and task sim-       Figure 4: Savings as a function of sparsity and shared
ilarity. The three shaded bars correspond to the use            joint motion. The three shaded bars correspond to the
of Task 2, Task 5, and Task 6, respectively, for the in-        use of Task 2, Task 3, and Task 4, respectively, for the
terfering task. Low SSE ratio values indicate increased         interfering task. Low SSE ratio values indicate increased
savings. Error bars display standard errors of the mean.        savings. Error bars display standard errors of the mean.
Generalization Due To Shared Sub-Tasks                          Contextual Cues
We also explored the effects of similarity between the          In the simulations presented so far, the network received
initial task and the interfering second task. In particu-       no information about the appropriate trajectory to pro-
lar, we considered second tasks that shared a common            duce except for the current position of the arm. In most
sub-task with Task 1, assessing the contribution of this        real-world situations, however, there are distinct sensory
common task component to savings. We examined three             or internal control cues that are associated with different
different second tasks — Task 2, Task 5, and Task 6             skills. The presence of such cues may not only assist in
— which varied in the number of time steps for which            the selection of a known skill, but they may help shape
their trajectories exactly matched that of Task 1. We           internal representations so as to separate the representa-
expected shared task components to improve savings, as          tions for different skills. This could improve savings. In
the shared sub-task would be reinforced by training on          order to investigate this possibility, we included a two-
the second task. Using a network with 100 hidden units          unit context layer (Figure 1). One unit in this layer was
produced the confirmatory results shown in Figure 3.            active for each of the two tasks that were learned. These
   We also counted hidden units whose activity discrim-         two units were randomly connected to the units in the
inated between the tasks, and found that the number of          hidden layer, with an 80% probability of any particular
such units dropped substantially during the time steps          connection being formed. The magnitudes of the synap-
corresponding to shared motion between the tasks. For           tic weights were determined by standard Leabra learn-
the maximally sparse networks, the number of discrim-           ing mechanisms. The use of this contextual cue greatly
inating units fell from as many as 27 units during time         increased savings, though savings remained sensitive to
steps involving differing motion to as few as 2 units dur-      sparsity. The results of using Task 2 as the interfering
ing shared sub-tasks. Thus, the same neural units were          task are shown in Figure 5. Analysis of hidden layer
used to encode shared sub-tasks, even when tasks were           activation patterns found many more units whose activ-
learned sequentially.                                           ity discriminated between the tasks when the cue was
   Next, we examined the case in which the first and sec-       present. For k = 10, the number of discriminating units
ond tasks share common motion for only a subset of the          rose from about 30 to over 60 when a contextual cue was
joints. This is another way in which two tasks might be         incorporated. The BP network showed no improvement
seen as sharing a common sub-task. We compared sav-             in savings due to the incorporation of a contextual cue.
ings when the interfering second task was Task 2 (noth-
ing in common), Task 3 (joint 1 in common), or Task 4
                                                                Overlearning
(joints 1 and 2 in common). We were surprised to find           Humans display increased savings in motor skills when
that there were no reliable effects of this form of task        the initial skill is overlearned (Shadmehr and Holcomb,
overlap (Figure 4). It is interesting to note that since        1997). In order to assess if this effect is captured by
our tasks are non-Markovian with regard to individual           Leabra’s biologically-based learning rule, we performed
joint angles, the network is forced to integrate informa-       a set of experiments in which training time on the two
tion about all joint angles in order to produce correct         tasks was varied. Specifically, we varied the number of
output. This could be the reason for the lack of savings        consecutive task executions that had to be performed by
in this case. The control of a joint having common mo-          the network with zero SSE (within error tolerance) in or-
tion across the two tasks had to be learned differently for     der for the task to be considered mastered. In order to
the two tasks, because its motion depended on the posi-         simulate overlearning, this number of successes was in-
tion of other joints in different ways for the two tasks.       creased to 10. We also examined “weak learning” by re-
                                                            867

                                                                training is made more stringent by reducing the error
                                                                tolerance. Future simulation experiments will focus on
                                                                understanding the relationship between retraining time
                                                                and lateral inhibition in Leabra, with the goal of col-
                                                                lecting additional evidence concerning the suitability of
                                                                Leabra’s biologically-based modeling framework for ex-
                                                                plaining skill acquisition and skill savings.
                                                                                      References
                                                                Botvinick, M. and Plaut, D. C. (2004). Doing without
                                                                     schema hierarchies: A recurrent connectionist ap-
                                                                     proach to normal and impaired routine sequential
Figure 5: Savings as a function of sparsity and inclusion            action. Psychological Review, 111(2):395–429.
of a contextual cue. Low SSE ratio values indicate in-          Brashers-Krug, T., Shadmehr, R., and Bizzi, E. (1996).
creased savings. Error bars display standard errors of               Consilidation in human motor memory. Nature,
                                                                     382:252–255.
the mean.
                                                                Brashers-Krug, T., Shadmehr, R., and Todorov, E.
                                                                     (1995). Catastrophic interference in human motor
quiring only one successful execution. We expected that              learning. In Advances in Neural Information Pro-
Leabra’s Hebbian learning mechanism would strengthen                 cessing Systems, volume 7, pages 19–26.
synaptic weights during the overlearning period, making         French, R. M. (1994). Dynamically constraining connec-
them more difficult to perturb during the learning of the            tionist networks to produce distributed, orthogonal
second task. Using Task 2 as the interfering task and                representation to reduce catastrophic interference.
k = 10, we found that savings improved in the Leabra                 In Proceedings of the Fifteenth Annual Conference
network when both tasks were overlearned, and it im-                 of the Cognitive Science Society, pages 335–340.
proved even more substantially when the first task was          French, R. M. (1999). Catastrophic forgetting in con-
overlearned and the second was “weakly learned”. Thus,               nectionist networks. Trends in Cognitive Sciences,
the effect of overlearning on savings falls out of Leabra’s          3(4):128–135.
learning mechanism. As expected, overlearning did not           Jenkins, I. H., Brooks, D. J., Nixon, P. D., Frackowiak,
improve savings in a BP network.                                     R. S. J., and Passingham, R. E. (1994). Motor
                                                                     ssequence learning: A study with positron emis-
                       Conclusion                                    sion tomography. The Journal of Neuroscience,
                                                                     14(6):3775–3790.
We have shown that the neurocomputational principles            Jordan, M. I. (1986). Attractor dynamics and parallelism
embodied by the Leabra modeling framework are suf-                   in a connectionist sequential machine. Proceedings
ficient to exhibit substantial savings in the sequential             of the fifteenth Annual Conference of the Cognitive
learning of temporally-extended motor skills. No auxil-              Science Society, pages 531–546.
iary computational mechanisms are needed in order to            McClelland, J. L., McNaughton, B. L., and OReilly,
avoid catastrophic interference. Savings was found to be             R. C. (1995). Why there are complementary learn-
sensitive to the amount of lateral inhibition in internal            ing systems in the hippocampus and neocortex: In-
network layers, with sparser representations encourag-               sights from the successes and failures of connection-
ing skill savings. Interestingly, our data actually show             ist models of learning and memory. Psychological
noteworthy savings even for internal representations that            Review, 102(3):419–457.
aren’t very sparse, suggesting that some amount of mo-          McCloskey, M. and Cohen, N. J. (1989). Catastrophic
tor skill savings may be directly supported by dense rep-            interference in connectionist networks: The sequen-
resentations in neocortex. We found generalization to                tial learning problem. In Bower, G. H., editor, The
sub-sequences of motor actions, but not to individual                Psychology of Learning and Motivation, volume 24,
joint motions, but this has been in the context of tasks             pages 109–164. Academic Press, New York.
that require a tight interdependence between joints. It is      Medina, J. F., Garcia, K. S., and Mauk, M. D. (2001).
likely that a similar lack of generalization would be seen           A mechanism for savings in the cerebellum. The
in humans who are learning skills that involve many syn-             Journal of Neuroscience, 21(11):4081–4089.
chronized component motions, like swimming or typing.           O’Reilly, R. C. and Munakata, Y. (2000). Computational
Contextual cues were found to greatly benefit savings in             Explorations in Cognitive Neuroscience. MIT Press.
Leabra. Also, the general pattern of overlearning effects       Robins, A. (1995). Catastrophic forgetting, rehearsal,
observed in humans were reproduced.                                  adn pseudorehearsal. Connection Science, 7:123–
   We have focused on an error ratio measure of sav-                 146.
ings in this work, but retraining time in Leabra would          Shadmehr, R. and Holcomb, H. H. (1997). Neural cor-
also be interesting to assess. Initial simulation experi-            relates of motor memory consolidation. Science,
ments have found savings in the form of reduced retrain-             277:821–825.
ing times, but we have found this measure to be insen-
sitive to the sparsity of internal representations unless
                                                            868

