UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How Diagnostic are Spatial Frequencies for Fear Recognition?
Permalink
https://escholarship.org/uc/item/1752w5cv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Authors
Alleysson, David
Guyader, Nathalie
Marendaz, Christian
et al.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                     How Diagnostic are Spatial Frequencies for Fear Recognition?
                      Martial Mermillod                                                               Nathalie Guyader
          Psychology and NeuroCognition Laboratory                                       Psychology and NeuroCognition Laboratory
                         CNRS UMR 5105                                                                 CNRS UMR 5105
                University Pierre Mendes France                                                University Pierre Mendes France
           (martial.mermillod@upmf-grenoble.fr)                                                     (nguyader@yahoo.fr)
                      Patrik Vuilleumier                                                               David Alleysson
      Laboratory of Neurology and Imaging of Cognition                                              Christian Marendaz
                       University of Geneva                                              Psychology and NeuroCognition Laboratory
          (patrik.vuilleumier@medecine.unige.ch)                                                       CNRS UMR 5105
                                                                                               University Pierre Mendes France
                                                                                            (David.Alleysson@upmf-grenoble.fr
                                                                                          Christian.Marendaz@upmf-grenoble.fr)
                              Abstract                                       layers receiving preferentially projections from Y retinal
                                                                             ganglion cells, whereas X cells project to both parvo and
Vuilleumier, Armony, Driver & Dolan (2003) have shown that                   magnocellular layers.
amygdala cells to fearful expressions of human faces seem to be more              Formally, in the visual thalamus, the magnocellular layer is
activated by intact or low spatial frequency (LSF) faces than high
                                                                             equivalent to a high-pass filter in the temporal frequency domain
spatial frequency (HSF) faces. These fMRI results may suggest that
LSF components might be processed by a subcortical pathway that is
                                                                             and a low-pass filter in the spatial frequency domain. Thus,
assumed to bypass the striate cortex in order to process LSF                 magnocellular neurons mainly provide rapid but low spatial
components faster than HSF components of visual stimuli. The purpose         frequency (LSF) information encoding configural features, as
of the present paper is to test the usefulness of LSF information as         well as brightness and motion of objects; whereas the
compared to HSF information in a visual classification task performed        parvocellular neurons provide slower but high spatial frequency
by an artificial neural network and a statistical classifier. Our results    (HSF) information about local shape features, color, and texture.
show that visual information, conveyed by LSF faces, allows the                   Testing the role of magnocellular inputs in fearful face
statistical and connectionist models to better recognize or categorize       recognition, Vuilleumier, Armony, Driver & Dolan (2003)
fearful faces amongst neutral faces than HSF faces. These results
                                                                             conducted a functional magnetic resonance imaging (fMRI)
suggest that high-speed connections from the magnocellular layers to
the amygdala might be a fast and efficient way to perform classification     experiment in which human observers were exposed to different
of human faces with respect to their emotional expressions.                  spatial frequency components of faces (i.e. LSF only, HSF only,
                                                                             or the integral broad spatial frequency (BSF) images), with
                                                                             either a fearful or a neutral expression. Results showed that HSF
                           Introduction                                      and BSF faces produced more activation of the fusiform cortex
                                                                             than LSF faces, irrespective of expression; this suggests
      Neuropsychological results have shown “blindsight” for
                                                                             predominant contribution of the parvocellular information to the
fearful faces in a hemianopic patient (with unilateral destruction
                                                                             ventral visual stream for face identification. In contrast, the
of primary visual cortex) when he was exposed to emotional
                                                                             amygdala and subcortical tecto-pulvinar areas were “blind” to
stimuli in his blind visual hemifield (de Gelder, Vroomen,
                                                                             the difference of expressions conveyed by HSF information, but
Pourtois & Weiskrantz, 1999; Rossion, de Gelder, Pourtois,
                                                                             selectively activated by fearful relative to neutral faces seen in
Guérit & Weiskrantz, 2000). This has led to the hypothesis that a
                                                                             LSF or BSF images; this suggests an important role of
neural route, by-passing the striate cortex, might reach the
                                                                             magnocellular information for the activation of amygdala-related
amygdala using a subcortical visual pathway from the lateral
                                                                             circuits in face emotion recognition.
geniculate nucleus (LGN) through the pulvinar and superior
                                                                                  The purpose of the present paper is to examine the
colliculus.
                                                                             usefulness of LSF cues in fearful face recognition by comparing
      Enroth-Cugell & Robson (1966) reported the
                                                                             the performance of a distributed neuronal and a statistical models
spatiotemporal characteristics of X (responding to high-
                                                                             of visual processing exposed to different spatial frequency
resolution stimuli) and of Y (responding to low-resolution
                                                                             information. We tested how facial information provided by LSF
stimuli) retinal ganglion cells; they showed that, following retinal
                                                                             and HSF images influenced two different computational models
processing, there is a difference between high and low spatial
                                                                             for an emotional classification task of face images.
frequencies. Hubel & Wiesel (1977) reported that this distinction
remains for the lateral geniculate nucleus: the magnocellular
                                                                         1501

                  Neuro-computational models                            Statistical and connectionist models of categorization
Our simulations were based on two computational models.                      We tested two different models in categorization tasks.
Computational model of vision                                                The connectionist network involves a distributed model of
                                                                        categorization based on a 3-layer back-propagation neural
      Several recent advances in computer vision for the                network. We used the standard hetero-association training
categorization of facial emotions have been made during the last        algorithm, whose function is to associate each of the different
decade. Some models have used a feature-based approach                  category exemplars with a specific output vector coding for
(Brunelli & Poggio, 1993), or a more holistic approach based on         them. This training algorithm is completely supervised because
principal component analysis (Turk & Pentland, 1991; Abdi,              each category is associated with a unique label coding for it.
Valentin, Edelman & O’Toole, 1995; Cottrell, Branson &                  Previous simulations have shown that the combination of these
Calder, 2002), or non-linear neural-network (Cottrell, 1990).           two artificial models allows reliable categorization capacities
These different techniques, promising at a computational level,         with respect to empirical data (French, Mermillod, Quinn,
do not explore the role of spatial frequency (SF) information.          Chauvin & Mareschal, 2002; Mermillod, Guyader & Chauvin,
However, some connectionist simulations of visual processes             2004).
have permitted successful categorization and recognition tasks               The statistical model is based on supervised classifier.
using Gabor wavelet coding of visual inputs (Cottrell, Branson          Using a Principal Component Analysis we reduce the dimension
& Calder, 2002). Dailey & Cottrell (1999) used this technique           of our data and describe each category by its mean vector and its
to differentiate faces from objects. Moreover, Dailey, Cottrell,        eigenvectors. Then, test data are projected into the “training”
Padgett & Ralph (2002) have shown by means of Gabor wavelet             eigenspace where a Mahalanobis distance is applied in order to
filtering the possibility to provide good classification                classify the data. The combination of PCA and Mahalanobis
performance on database of facial expressions.                          distance is often used for classification purposes. This was also
      Gabor functions provide an efficient way to describe the          used in Face recognition (Sirovich & Kirby, 1987). The
content of the frequency domain while losing the minimum of             difference here is that, following Dailey & Cottrell (1999), we
information in the spatial domain (Gabor, 1946). Therefore, it          applied PCA not to the face images but to the Gabor responses
was shown that visual information is reliably compressed by             to the face images.
Gabor wavelet decomposition. For example, for face                           The aim of these simulations was to test the role of low
recognition, Wiskott (1997); Wiskott, Fellous, Krüger & Von             spatial frequency content in faces on the expression recognition
der Malsburg (1999) proposed applying several jets of Gabor             performance of a distributed classifier network. In the case of a
wavelets to extract different orientation and spatial frequency         failure of the neural network to categorize emotions based on
information at specific locations. Moreover, at both the                LSF images only, the hypothesis of an important functional role
computational and behavioral levels, it has been shown that             of coarse (subcortical) magnocellular inputs to the amygdala
accurate categorization can be achieved using the energy                would have to be seriously questioned.
spectrum of natural images (Ginsburg, 1986; Guyader, Chauvin,
Peyrin, Hérault & Marendaz, 2004; Hughes, Nozawa & Kitterle,
                                                                        Simulation 1: Testing spectral information in a
1996; Hérault, Oliva & Guerin-Dugué, 1997; Mermillod,
Guyader & Chauvin, 2004; Torralba & Oliva, 2003).
                                                                        connectionist network
      Our model describes images by sampling their energy               Network
spectrum. It is divided into the following steps. First, an Hanning          We used a standard 24-6-2 feedforward backpropagation
window is applied to avoid an over-representation of vertical and       hetero-associator (learning rate: 0.1, momentum: 0.9).
horizontal orientations (due to image edges) in the Fourier
domain. After this pre-processing, images were transferred into         Stimuli
the Fourier domain using a two-dimensional Fast Fourier                      For all simulations, stimuli were the original stimuli used in
Transform algorithm and, then, filtered by a set of Gabor filters.     the neuro-imaging study by Vuilleumier et al. (2003). These
Filter sizes were normalized with respect to a 1/f decreasing of       included 160 human faces from two categories (80 neutral face
the amplitude spectrum for natural images (Field & Brady,              exemplars and 80 fearful face exemplars). Each of 80 different
1997). We applied a bank of fifty-six Gabor filters                    individuals appeared with the two emotional expressions (fearful
corresponding to seven different spatial frequency bands (one            vs. neutral), always in a frontal viewpoint. Face images were
octave per spatial frequency channel) and eight different              grey level photographs with an average stimulus luminance, on a
orientations (each 22.5 deg of visual angle). Then the mean            256 gray-level scale, of 112, 118, and 115 for BSF, HSF, and
energy at each filter output is measured. An image is then             LSF stimuli, respectively, and of 117 and 114 for the neutral and
described by 56 different values that correspond to the image          fearful face categories, respectively. These average luminance
energy in different orientation and frequency bands.                   values did not significantly differ across the different stimulus
                                                                       conditions (Vuilleumier et al., 2003). The size of all images was
                                                                       squared to the same frame for computational reasons, by
                                                                   1502

applying an area of 198×198 pixels on the centre of each face, in            After training on the high spatial frequency of natural
such a way to retain a similar amount of information for each          images, the neural network produced an average of 87.2 % of
stimulus and to keep all internal facial details from the original     correct response when tested on new fearful faces. When tested
images (from the base of the chin to the top of the forehead).         on new neutral faces, the network produced 92.1 % of correct
And as we described in the first part, each image is then              responses. More importantly, the difference between
described by 56 different values that correspond to the image          generalization performance produced by LSF fearful faces
energy in 8 different orientation and 6 different frequency bands.     compared to HSF fearful faces was significant (χ2 (1)=90.36,
      In their fMRI study, Vuilleumier et al. (2003) used a high-      p<.001). Similarly, the difference of performance between LSF
pass cut-off >24 cycles per image for HSF faces and a low-pass         neutral faces compared to HSF neutral faces was significant (χ2
cut-off <6 cycles per image for LSF faces. In order to reproduce       (1)= 12.6, p<.001).
this cut-off in the connectionist simulations, we removed the 4
lowest spatial frequency channels (or Gabor filters), coding for       Discussion
HSF faces, and the 4 highest spatial frequency channels (Gabor               This first simulation has important implications for the
filters), coding for LSF faces. Thus, we kept the three highest SF     neurobiological and cognitive underpinnings of emotional face
bands for the HSF face inputs, and the three lowest SF bands for       recognition, particularly fearful expressions. The lower
the LSF face inputs. This method allowed us to remove spectral         performance produced by the network after training on HSF
information that was not relevant for one or the other simulation,     information suggests a problem for a distributed classifier in this
while keeping the same vector-size for both simulations.               task.
Consequently, the input vector size was 24 units (3 spatial                  Therefore, we suggest that the statistical distribution of
frequency bands by 8 orientations).                                    LSF and HSF faces in terms of their spectral energy vector may
                                                                       provide a clear explanation for human imaging and connectionist
Procedure                                                              results. The orientation and spatial frequency decomposition
       The procedure included two phases: a training phase with a      occurring in the human visual system is able to provide a pattern
subset of fearful and neutral faces, and a testing phase in which      of responses that clearly distinguish between fearful and neutral
the neural network was tested on its ability to categorize new         expressions at the level of LSF information, whereas HSF
facial expressions. The procedure described below concerns LSF         information is worse for this particular classification task.
faces. Exactly the same procedure as described below was then          Therefore, the LSF information provided by the magnocellular
applied on HSF faces.                                                  layers may be capable of providing the necessary information to
Training phase. Twenty LSF fearful and twenty corresponding            do the classification of fearful expressions.
LSF neutral faces were randomly extracted from the categories
of emotional expression. Then, the 24-dimensional energy vector        Simulation 2: Testing spectral information in a
was associated with the corresponding output vector by the 3-          statistical model
layer back-propagation network. Then, a new image from the
                                                                       Statistical model
training set was coded and associated by the neural network in
                                                                           We used, for this second simulation, a classical Principal
an iterative process. Each run began with a random selection of
                                                                       Component Analysis (PCA) in order to reduce the
40 training exemplars (20 exemplars per category). Then the
                                                                       dimensionality of our data. Then, to classify images we used the
training consisted of associating each of the 20 exemplars with
                                                                       Mahalanobis distance.
the suitable output (0 1 coding for “fearful” face, 1 0 coding for
“neutral” face) for a fix number of 500 epochs.                        Stimuli
Test phase. The neural network was trained on the two                       The stimuli were exactly the same as the one used in the
expression categories and then tested on the 60 remaining             simulation 1. (cf. Simulation 1). We had two sets of data: one
exemplars from the trained category versus the corresponding 60       set for LSF and another one for HSF. Each set corresponded to a
exemplars from the other category. Results were averaged over         160 × 24 matrix (160 different faces, 80 neutral and 80 fearful,
50 runs of the above training-test procedure. After applying a        each described with 24 values).
winner-take-all on the output nodes, the dependent measure was         Procedure
the correctness of the outputs produced by the tested vector.                The procedure also included two phases: a training phase
Results                                                               with a subset of fearful and neutral faces, and a testing phase in
       After training on the low spatial frequency of natural         which the neural network was tested on its ability to categorize
images, the neural network produced an average of 94.3 % of           new facial expressions. The procedure described below concerns
correct response when tested on new fearful faces. When tested        LSF faces. Exactly the same procedure as described below was
on new neutral faces, the network produced 94.4 % of correct          then applied on HSF faces.
responses. The difference between the two test conditions is not
significant.                                                          Training phase. The 2 principal eigenvectors of the 30 LSF data
                                                                      were computed using a Principal Component Analysis (PCA).
                                                                  1503

These 2 principal vectors preserved around 90% of the total                receive LSF inputs from either subcortical or cortical pathways,
variance. Then each face category: neutral and fearful is                  although preserved activation by fearful faces during masked
described by its gravity center in this reduced space.                     presentations or in blind patients (Morris et al., 2001; de Gelder
                                                                           et al., 1999; Pegna et al., 2004) may suggest an important role of
Test phase. The remaining data, the test ones, were projected on           the subcortical tecto-pulvinar pathways known to carry LSF
the 2- eigenvector space computed during the training phase.               inputs (Vuilleumier et al., 2003).
Then, in order to attribute a class to each test data we computed                 On the other hand, it has been shown that HSF information
the Mahalanobis distance between each test data and the learnt             can also play an important role in face processing, particularly
gravity center of each class. The Mahalanobis distance is proved           for the accurate identification of specific exemplars (Morrison &
to be a good distance for classification purpose (Yambor, W.,              Schyns, 2001). Therefore, depending on the situational
Draper, B. & Beveridge, 2000).                                             constraints (i.e. identify a target or categorize a stimulus in terms
                                                                           of danger), one or the other spatial frequency channel might be
Results                                                                    preferentially used by the cognitive system to deal efficiently
      This classification reaches a percentage of correct                  with its visual environment.
classification of approximately 89% for LSF data, and only 58%                    Furthermore, our new results do not only support the
for HSF data.                                                              observations previously made at a neurophysiological level
                                                                           concerning the possible substrates for fast, non-conscious
Discussion                                                                 process of fearful faces (de Gelder et al., 1999; Vuilleumier et
     Globally, these results imply that the whole spatial                  al., 2003), but also more generally provide additional evidence
frequency spectrum available from the retinal image may not be             for the hypothesis of coarse-to-fine processing in visual
entirely needed to perform a visual categorization of human                recognition. The coarse-to-fine hypothesis suggests an advantage
faces in terms of basic emotional expressions, such as fear vs.            of LSF information for the initial categorization of visual objects
neutral. Therefore, it might indeed be useful for a distributed            or scenes (Ginsburg, 1986; Parker, Lishman, & Hughes, 1992,
system (i.e. visual and emotional pathways in the brain) to                1997; Parker & Costen, 1999; Schyns & Oliva, 1994), prior to
exploit the most rapid neuronal pathways conveying LSF                     finer visual analysis based on HSF information. These
information (i.e., the magnocellular channel), in order to achieve         psychological data are supported by anatomical evidence
sufficiently reliable but also fast categorization of fearful stimuli.     showing faster LSF integration at the level of the magnocellular
                                                                           layers in the lateral geniculate nucleus of the thalamus (Hubel &
                           Conclusions                                     Wiesel, 1977). In other words, a fast propagation of LSF
                                                                           information within the perceptual system might constitute an
      The purpose of that paper was to explore the computational           efficient mechanism for the fast categorization of visual stimuli
basis in support of the hypothesis that LSF pathways within the            into most salient or relevant entities (see also Bullier 2001, Bar,
visual system may be preferentially responsible for carrying               2004). Thus, rapid connections from the magnocellular visual
visual information to the amygdala about the emotional (fearful)           neurons in early thalamic and other subcortical relays to the
expression of faces. However, our network model did not make               amygdala might be in general agreement with the computational
any definite assumptions about the anatomical neuronal stream              demands of a distributed cognitive system. Such a functional
potentially involved in this visual processing pathway (i.e., the          architecture would be highly consistent with results from the
geniculo-striate cortical stream vs. the tecto-pulvinar subcortical        present simulations showing more efficient visual classification
stream). Taking our different simulations together, the main               of facial expressions based on their LSF content (rather than
results suggest that an artificial model of categorization can             HSF alone), and with previous neuro-imaging results showing
perform a more reliable categorization of faces in terms of                more robust amygdala activation to fearful faces seen from LSF
emotional expression based on their LSF content rather than                images (Vuilleumier et al., 2003).
their HSF content. This provides indirect support for a                           These empirical results reported here provide a first
computational advantage of extracting LSF cues from faces, as              attempt to understand the complex relationships unifying basic
previously hypothesized for the amygdala on the basis of brain             visual perceptual processes with higher cognitive and emotional
imaging results showing greater activation to LSF than HSF                 recognition systems. A next step will be to use such
fearful faces (Vuilleumier et al., 2003).                                  computational modeling to simulate and to predict further
      In the human visual system, LSF inputs from magnocellular            empirical results. Based on their elementary physical properties,
visual neurons project to a wide range of different areas                  it is possible to generate stimuli for which magnocellular
including subcortical tecto-pulvinar regions (Schiller et al. 1979;        pathways would be completely blind, and then, test the response
Orban, 1984) and fronto-parietal cortical areas (Bullier, 2001;            of recognition systems for different emotional categories and
Bar, 2004), but also to ventral temporal cortex (Livingstone &             different categorization processes. Schyns & Oliva (1999) have
Hubel, 1988; Merigan & Maunsell, 1993). By contrast, HSF                   reported psychological evidence showing that different regions
information from parvocellular neurons predominantly projects              of the SF spectrum are used depending on the task: LSF is
to the ventral temporal cortex. The amygdala may therefore                 preferentially used to describe facial emotions in explicit terms
                                                                      1504

of happy, angry or neutral whereas HSF seems to be used to             Field, D.J. & Brady N. (1997). Visual sensitivity, blur and the
determine if a face is expressive or not. Future simulation               sources of variability in the amplitude spectra of natural
models should therefore also investigate whether training on the          scenes. Vision Research, 37, 3367-3383.
same set of faces may lead to specialized processing streams           French, R. M., Mermillod M., Quinn P. C., Chauvin A. &
(i.e., at the level of hidden-layer or in different subparts of the       Mareschal D. (2002). The Importance of Starting Blurry:
network) extracting distinct LSF or HSF components for                    Simulating Improved Basic-Level Category Learning in
different task purposes (e.g. emotion recognition based on LSF            Infants Due to Weak Visual Acuity. Proc. of the 24th Annual
in some neurons, identity or age recognition based on HSF in              Cog. Sci. Society Conference. NJ:LEA. 322-327.
other neurons).                                                        Gabor, D. (1946). Theory of Communication. The Journal of the
                                                                          Institution of Electrical Engineers. London: Unwin Brothers.
                        Acknowledgments                                   93(3): 429-457.
                                                                       Ginsburg, A. P. (1986). Spatial filtering and visual form
This work was supported by a post-doctoral grant from the                 perception. In K. Boff, L. Kaufman, & J., Thomas (Eds.),
Fyssen Foundation to MM, the French CNRS to DA and CM                     Handbook of perception and human performance. Volume
and a grant from the Swiss National Science Foundation to PV.             2: Cognitive processes and performance (pp. 34-1 to 34-41).
                                                                          New York: Wiley.
                          Bibliography                                 Guyader, N., Chauvin, A., Peyrin, C., Hérault, J., & Marendaz,
                                                                          C. (2004). Image phase or amplitude? Rapid scene
Abdi, H., Valentin, D., Edelman, B.E., O’Toole, A.J. (1995).              categorization is an amplitude based process. C. R. Biologies
    More about the difference between men and women:                      327, 313-318.
    Evidence from linear neural networks and the principal             de Gelder B., Vroomen, J., Pourtois G. & Weiskrantz, L. (1999).
    component approach. Perception, 24, 539-562.                          Non-conscious recognition of affect in the absence of striate
Bar, M. (2004). Visual objects in context. Nature Reviews:                cortex. NeuroReport, 10(18), 3759-3763.
    Neuroscience, 5, 619-629.                                          Hérault, J., Oliva, A., & Guerin-Dugué, A. (1997). Scene
Breiter H.C., Etcoff N.L., Whalen P.J., Kennedy W.A., Rauch               Categorisation by Curvilinear Component Analysis of Low
    S.L., Buckner R.L., Strauss M.M., Hyman S.E. & Rosen                  Frequency Spectra. 5th European Symposium on Artificial
    B.R. (1996). Response and habituation of the human                    Neural Network., Bruges, Belgium. pp. 91-96.
    amygdala during visual processing of facial expression.            Hubel, H. D. & Wiesel, T. N. (1977). Ferrier lecture: Functional
    Neuron 17(5), 875-887.                                                architecture of macaque monkey visual cortex. Proc. Roy.
Brunelli, R., & Poggio T. (1993). Face Recognition: Features              Soc. Lond. [Biol.], 98, 1-59.
    versus Templates. IEEE Trans. Pattern Analysis and                 Hughes, H.C., Nozawa, G. & Kitterle, F. (1996). Global
    Machine Intelligence, 15(10), 1042-1052.                              precedence, spatial frequency channels, and the statistics of
Cottrell, G.W. (1990). Extracting features from faces using               natural images. Journal of Cognitive Neuroscience, 8, 197-
    compression networks: Face, identity, emotion, and gender             230.
    recognition using holons. In Proceedings of the 1990               Jones, J.P. & Palmer L.A. (1987). The two-dimensional spatial
    Connectionist Models Summer School, (eds. D. Touretsky, J.            structure of simple receptive fields in cat striate cortex.
    Elman, T. Sejnowski & G. Hinton) Kaufman, 328-337.                    Journal of Neurophysiology, 58, 1187-1211.
Cottrell, G. W., Branson, K. & Calder A. J. (2002). Do                 Jones, J.P., Stepnoski A. & Palmer L.A. (1987). The two-
    expression and identity need separate representations? In             dimensional spectral structure of simple receptive fields in
    Proceedings of the 24th Annual Cognitive Science                      cat striate cortex. Journal of Neurophysiology, 58(6), 1212-
    Conference, Fairfax, Virginia. Mahwah: LEA                            1232.
Dailey, M. N. & Cottrell, G. W. (1999). Organization of Face           Livingstone, M., & Hubel, D. (1988). Segregation of form,
    and Object Recognition in Modular Neural Networks.                    color, movement, and depth: anatomy, physiology, and
    Neural Networks, 12(7-8), 1053-1074.                                  perception. Science, 240,(4853), 740–749.
Dailey, M. N., Cottrell, G. W., Padgett, C., & Ralph A. (2002).        Lundqvist, D. & Litton, J.E (1998). The Karolinska Directed
    EMPATH: A neural network that categorizes facial                      Faces (Karolinska Institute).
    expressions. Journal of Cognitive Neuroscience 14(8), 1158-        Merigan, W. H., & Maunsell, J. H. (1993). How parallel are the
    1173.                                                                 primate visual pathways? Annual Review of Neuroscience,
Enroth-Cugell, C., & Robson, J. (1966). The contrast sensitivity          16, 369–402.
    of retinal ganglion cells of the cat. Journal of Physiology,       Mermillod M., Guyader N. & Chauvin A. (2004). Does the
    187, 517-552.                                                         energy spectrum from Gabor wavelet filtering represent
Esteves, F., & Ohman, A. (1993). Masking the face: Recognition            sufficient information for neural network recognition and
    of emotional facial expressions as a function of the                  classification tasks? In H. Bowman, C. Labiouse (Eds.)
    parameters of backward masking. Scandinavian Journal of
    Psychology, 34, 1-18.
                                                                   1505

   Connectionist Models of Cognition, Perception and Emotion            Schiller, P. H., Malpeli, J.G. & Schein, S. J. (1979).
   II. Progress in Neural Processing (vol. 15). World Scientific,          Composition of geniculostrate input to the superior colliculus
   pp 148-156.                                                             of the rhesus monkey. Journal of Neurophysiology,
Morris, J.S., Frith, C.D., Perrett, D.I., Rowland, D., Young,              (42), 1124-1133.
   A.W., Calder, A.J. & Dolan, R.J. (1996). A differential              Schyns, P. G., & Oliva, A. (1994). From blobs to boundary
   neural response in the human amygdala to fearful and happy              edges: Evidence for time and spatial-scale-dependent scene
   facial expressions. Nature, 383(6603), 812-5.                           recognition. Psychological Science, 5, 195-200.
Morris, J.S., Ohman, A.. & Dolan, R.J. (1998). Conscious and            Schyns P.G. & Oliva A. (1999). Dr. Angry and Mr. Smile: when
   unconscious emotional learning in the human amygdala [see               categorization flexibly modifies the perception of faces in
   comments]. Nature, 393(6684), 467-70.                                   rapid visual presentations. Cognition, 69(3). 243-265.
Morrison, D.J. & Schyns, P.G. (2001). Usage of spatial scales           Sirovich, L. & Kirby, M. (1987). A low-dimensional procedure
   for the categorization of faces, objects and scenes.                     for the characterization of human faces. The Journal of the
   Psychonomic Bulletin & Review, 8, 454-469.                               Optical Society of America, 4:519 – 524.
Orban, G.A. (1984). Neuronal operations in the visual cortex.           Torralba, A. & Oliva, A. (2003). Statistics of natural image
   Studies in brain function, Vol. II. Berlin: Springer-Verlag.            categories. Network: Comput. Neural Syst., 14, 391–412
Parker, D. M. & Costen, N. P. (1999). One extreme or the other          Turk, M. & Pentland, A. (1991). Eigenfaces for recognition.
   or perhaps the golden mean? Issues of spatial resolution in             Journal of Cognitive Neuroscience, 3(1), 71-86.
   face processing. Current Psychology, 18, 118-127.                    Vuilleumier, P., Armony, J. L., Driver, J., & Dolan, R. J. (2003).
Parker, D. M., Lishman, J. R. & Hughes, J. (1992). Temporal                Distinct spatial frequency sensitivities for processing faces
   integration of spatially filtered visual images. Perception, 21,        and emotional expressions. Nature Neuroscience, 6(6), 624-
   147-160.                                                                631.
Parker, D. M., Lishman, J. R., & Hughes, J. (1997). Evidence            Wiskott L. (1997). Phantom Faces for Face Analysis. Pattern
   for the view that temporospatial integration in vision is               Recognition 30(6), 837-846.
   temporally anisotropic. Perception, 26, 1169-1180.                   Wiskott, L., Fellous, J.M., Krüger, N. & Von der Malsburg C.
Pegna, A.J., Khateb, A., Lazeyras, F. & Seghier, M.L. (2004).              (1999). Face Recognition by Elastic Bunch Graph Matching.
   Discriminating emotional faces without primary visual                   In Intelligent Biometric Techniques in Fingerprint and Face
   cortices involves the right amygdala. Nature Neuroscience,              Recognition, eds. L.C. Jain et al., CRC Press, 11, 355-396.
   8(1) 24-25.                                                          Yambor, W., Draper, B. & Beveridge, R. (2002). Analyzing
Rossion, B., de Gelder B., Pourtois G., Guérit J.M. &                      PCA-based Face Recognition Algorithms: Eigenvector
   Weiskrantz, L. (2000). Early extrastriate activity without              Selection and Distance Measures, in Empirical Evaluation
   primary visual cortex in humans. Neuroscience Letters,                  Methods in Computer Vision, H. Christensen and J. Phillips
   279(1), 25-28.                                                          (eds.), World Scientific Press, Singapore, 2002
                                                                   1506

