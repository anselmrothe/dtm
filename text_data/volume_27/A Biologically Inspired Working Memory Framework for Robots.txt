UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Biologically Inspired Working Memory Framework for Robots
Permalink
https://escholarship.org/uc/item/6xd1d32g
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)
Author
Nokes, Timothy J.
Publication Date
2005-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       A Biologically Inspired Working Memory Framework for Robots
                                        Joshua L. Phillips & David C. Noelle
                                  ({joshua.l.phillips,david.noelle}@vanderbilt.edu)
                                Department of Electrical Engineering and Computer Science
                                                      Vanderbilt University
                            Abstract                               difficulties that arise when robots interact with the world
                                                                  are representative of the tasks that humans encounter
   This work focuses on a particular neurocomputational           daily. Thus, robotic tasks provide a rich and effective
   account of working memory function that has been used
   to explain a wide range of working memory phenomena            domain for testing the scalability of our working mem-
   in terms of interactions between the prefrontal cortex         ory model.
   and the mesolimbic dopamine system. Using the mech-                This paper reviews important properties of human
   anisms prescribed by this theory, we have constructed a         working memory processes, as well as our computational
   software toolkit for creating working memory modules
   for use in robotic control systems. The challenges faced        approach to modeling those processes. The benefits that
   by embodied robots are similar to those experienced by          such a working memory system might bring to robot
   humans in everyday living, making this domain useful            control are briefly discussed. We then introduce an
   for testing the utility and scalability of this computa-        open source software library, called the Working Mem-
   tional theory of working memory. We report the results          ory Toolkit, which provides an abstraction of our pre-
   of a feasibility study, involving a robotic version of the
   delayed saccade task, and we discuss future plans to test       vious computational neuroscience models of prefrontal
   our working memory model in the context of robot con-           cortex. Through a simulation study, we show that this
   trol and learning.                                              toolkit offers sufficient working memory functionality to
                                                                   learn a behavior commonly used to examine the working
                                                                   memory abilities of non-human primates: the delayed
                       Introduction                                saccade task. The paper closes with a discussion of the
Research in the cognitive sciences has provided substan-           more elaborate robot navigation and object manipula-
tial insight into the nature of working memory and the             tion tasks that are currently being implemented using
biological mechanisms that produce it. Psychological               our biologically inspired working memory system.
studies have provided evidence of capacity limitations
for working memory and have shown that working mem-                                       Background
ory contents are immediately available for executive and
deliberative processing. Electrophysiological and neu-             The Nature of Working Memory
roimaging studies have implicated regions of prefrontal            Working memory is what allows you to keep a particu-
cortex (PFC) as being central to working memory func-              lar book’s call number in mind while you search for it
tion. These experimental findings have led to the devel-           in the library. Working memory is what allows you to
opment of biologically-based theories of working mem-              remember what phone number the operator told you,
ory, and some of these theories have been explicitly in-           just long enough to dial it. Working memory is what
stantiated in computational neuroscience models.                   allows you to remember information that is critical to
   In the work reported here, we have focused on one par-          correct decision making in the current situation, but is
ticular computational account of working memory func-              then discarded once it has served its purpose. Due to
tion, and we have endeavored to evaluate the ability of            its involvement in so many aspects of mental function,
this account to scale to the challenges faced by human             working memory is a central component of almost all
working memory systems every day. This working mem-                theories of human cognition. Working memory is often
ory model has been previously used to explain a vari-              described in terms of its storage, manipulation, updat-
ety of laboratory findings, but it is uncertain whether            ing, and executive processing components (Baddeley and
this model is capable of addressing real-world contin-             Hitch, 1974). Perhaps more succinctly, working memory
gencies (O’Reilly et al., 1999). Our approach to assess-           has been described as a system that stores a small num-
ing the power of our working memory model is some-                 ber of “chunks” of information, protecting them from
what unorthodox. We have begun the process of em-                  interference from other processing systems and position-
bedding this working memory mechanism into robotic                 ing them so as to directly influence the generation of
control systems, with the goal of using robotic platforms          behavior (Goldman-Rakic, 1987).
as challenging testbeds for our computational theory of               While many theories of working memory exist (Miyake
working memory function. We believe that the study of              and Shah, 1999), they tend to agree on several key prop-
working memory in robots can provide deeper insights               erties. One such property is the limited capacity of the
into working memory function in humans, because the                working memory system. Recent estimates of this ca-
                                                              1750

pacity suggest that the number of “chunks” that can be            grounded in interactions between dopamine neurons and
stored and used by working memory is approximately                circuits in other brain areas, such as the striatum (Barto,
four (Cowan, 2001). Note that this is somewhat lower              1994; Montague et al., 1996). These models have been
than earlier estimates which suggested a capacity of              able to account for biological and behavioral findings as-
“seven plus-or-minus two” items (Miller, 1956). A sec-            sociated with conditioning and motor sequence learning.
ond key property of working memory is that its contents              It is important to note that midbrain dopamine neu-
are readily accessible to other cognitive processes. This         rons also project broadly to the PFC, as well as to loop-
property, combined with the first, suggests that working          like circuits between PFC and the basal ganglia, medi-
memory may be adapted to retain only the information              ated by the thalamus. Thus, the midbrain dopamine
that is most important for influencing behavior. A re-            system is not only well positioned to assist in the learn-
lated key property is the volatility of working memory            ing of overt motor actions, but it may also contribute to
contents. The constituents of working memory may be               the learning of the appropriate timing for covert actions,
updated and manipulated very quickly. Thus, working               such as working memory updating (Braver and Cohen,
memory can allow new information to influence behavior            2000). This is the basis of the working memory model
much faster than other memory systems, which change               explored here. A temporal difference learning algorithm,
at a slower rate (Waugh and Norman, 1965).                        implemented, in part, by the midbrain dopamine system,
   There is substantial evidence that regions of prefrontal       learns to identify situations in which working memory
cortex (PFC) play an important role in working mem-               contents should be actively maintained and situations in
ory (Goldman-Rakic, 1987). Neurons in this brain re-              which working memory contents should be rapidly up-
gion have been found to actively maintain high firing             dated. In this way, the working memory system adapts
rates in the absence of stimuli, encoding relevant bits of        to the reward contingencies of the organism’s environ-
information during delay periods. Many different kinds            ment. This model has been successfully used to account
of information appear to be actively maintained in the            for a variety of working memory phenomena, including
PFC, including spatial locations (Funahashi et al., 1989),        deficits seen in schizophrenia and under focal frontal le-
recently viewed objects (Cohen et al., 1994; Miller and           sions (Braver and Cohen, 2000; O’Reilly et al., 2002).
Desimone, 1994), action rules (Wallis et al., 2001), and
even verbal information (Demb et al., 1995). Dense re-
                                                                  Temporal Difference Learning
current connections in PFC are thought to support ac-             The temporal difference (TD) learning algorithm (Sut-
tive maintenance of high firing rates through mutual ex-          ton, 1988) is a powerful method for learning to select
citation (Camperi and Wang, 1998).                                actions based on reinforcement signals: sporadic, scalar
   Recurrent excitation is not a sufficiently flexible mech-      measures of how “good” or “bad” the current situation
anism to account for the fluidity of working memory               is. The algorithm uses these sparse measures of perfor-
function. In some situations, working memory contents             mance to adjust behavior over time. The central com-
must be actively maintained in the face of distractions.          ponent of this algorithm is an estimator of future re-
In other situations, contents must be rapidly updated,            ward, called the adaptive critic. The adaptive critic is
discarding old contents in favor of new contents. In or-          commonly a simple artificial neural network that takes
der to account for working memory performance, some               information about the current state of the animal and
intelligent mechanism must be placed in control of mem-           maps it onto an estimate of how good or bad the current
ory updating. But how does the brain know what infor-             situation is. Importantly, this mapping is not fixed, but
mation should be retained and what can be safely dis-             is learned through experience.
carded?                                                              Every situation is assumed to be immediately evalu-
                                                                  ated by the animal, assigning the situation with some
   This issue of intelligent updating is the focus of our         scalar amount of “reward”, labeled r(s) for situation
computational model of working memory. Our model as-              s. This scalar identifies things that are inherently good
serts that working memory is adaptive in the sense that           (e.g., food) with positive values, inherently bad (e.g.,
proper control of updating is learned from experience. If         pain) with negative values, and neutral situations with
the retention of a particular kind of informational chunk         a value of zero. The goal of the adaptive critic is not to
in a given situation results in reward, the system will be        estimate this value, however, but to estimate the value
more likely to retain similar chunks in similar situations.       function, V (s), of the situation in terms of the likely
The question then becomes one of how such a reinforce-            reward to be received in the future. In other words, a
ment learning scheme is implemented in the brain.                 situation’s worth is not measured entirely by the amount
   One candidate for a neural substrate for reinforce-            of reward we receive at that instant. For example, when
ment learning involves the mesolimbic dopamine system.            playing chess it is sometimes desirable to sacrifice one
Recordings of dopamine cell firing in awake behaving              of your pieces (a pawn) in order to win the game. The
animals suggest that dopamine cells fire in response to           adaptive critic is to estimate expected future reward. If
changes in expected future reward (Shultz et al., 1997).          (s + 1) is the situation that follows situation s in time,
Interestingly, such a measure of change in expected fu-           this expected future reward may be formalized as:
ture reward is a key component of a machine learn-
ing algorithm known as temporal difference (TD) learn-                 V (s) = γ 0 r(s) + γ 1 r(s + 1) + . . . + γ n r(s + n)
ing (Sutton, 1988). This has led researchers to construct
computational models of neural reinforcement learning,            The value of the current situation, V (s), is the sum of
                                                             1751

all of the rewards we will receive over the next n time                                   Methods
steps. The rewards on each time step are “discounted”             Our computational model of working memory updating,
by a factor, γ, in the range [0, 1]. This discounting factor      grounded in interactions between PFC and the dopamine
makes rewards that occur in the near future more “valu-           system and implemented as a neural network version of
able” than those that occur much later. This equation             TD learning, has been found to match the performance
may be rewritten in a recursive form:                             of humans and non-human primates on a variety of lab-
                                                                  oratory tasks. We hope to demonstrate the utility of
     V (s) = γ 0 r(s) + γ 1 V (s + 1) = r(s) + γV (s + 1)         such an adaptive working memory system in much more
Any estimate of the value function that deviates from             complex task domains that reflect the constraints of ev-
this equality is inaccurate, and the magnitude of the             eryday cognition. We believe that such a demonstra-
inaccuracy is captured by the temporal difference error :         tion might be had by integrating our working memory
                                                                  model into the control systems of autonomous robots,
             δ(s) = (r(s) + γV (s + 1)) − V (s)                   using the embedded working memory system to assist in
                                                                  the performance of such tasks as visual search in clut-
The TD learning algorithm incrementally updates the               tered environments, tracking of moving and transiently
adaptive critic’s estimate of V (s) in proportion to δ(s),        occluded target objects, retention and tracking of ob-
increasing the estimate if δ(s) is positive and decreasing        jects that make for good landmarks for navigation, and
the estimate if δ(s) is negative.                                 localization of occluded objects during tool manipulation
    In order for the adaptive critic to make value function       tasks. We are currently in the process of constructing
estimates for novel states, its estimate is computed as           such systems for both mobile robots and a stationary
a parameterized function of features of the current sit-          humanoid robot.
uation. A common parameterization is an affine trans-                Contemporary robot control systems are not con-
formation of situation features. Thus, if the situation,          ducive to direct integration with computational neuro-
s, is encoded as a vector of real valued features, si , the       science models. Computational neuroscience simulation
adaptive critic will estimate the value function as:              software typically does not respond in real time, and the
                                                                  interfaces expected by robot control systems typically do
                                     Xn
                                                                  not deal in the currency of neural firing rates. Thus, in
                  V (s) = w0 +           wi si                    order to facilitate integration, we have generated an ab-
                                     i=1                          straction of our working memory model in the form of
                                                                  an open source software library that may be embedded
Thus, the adaptive critic may be implemented by a sin-
                                                                  in robot control software. As an initial demonstration
gle linear connectionist processing element. In order to
                                                                  of the functionality of this library, we have simulated a
modify value function estimates according to the tempo-
                                                                  robotic version of a common neuroscientific test of spa-
ral difference error, weights are modified as follows:
                                                                  tial working memory: the delayed saccade task.
           ∆wi = α δ(s) si            ∆w0 = α δ(s)                The Working Memory Toolkit
. . . where α is a learning rate parameter. Many imple-           We have developed a set of software tools for developing
mentations of TD learning use a technique called absorb-          working memory systems that can be easily and tightly
ing reward, in which V (s+1) is forced to zero when s is a        integrated into robotic control mechanisms. This set of
“goal” situation, marking the end of an episode or trial.         tools, called the Working Memory Toolkit (WMtk), is a
Often the gradient with respect to each weight is carried         software library which is general and flexible enough to
over from one time step to the next, but exponentially            be used on a variety of robotic platforms. The toolkit is
discounted according to a parameter λ which is in the             written in ANSI C++ and consists of a set of classes and
range [0 − 1]. This learning algorithm produces adaptive          methods for constructing a working memory system that
critics that generate good estimates of expected future           uses TD learning to select working memory contents.
reward in various situations.                                        When using the WMtk, the first step in building a
    Given a good estimate of the value of situations, the         robotic working memory system involves the creation of
learning algorithm can choose actions that lead to sit-           a WorkingMemory object. This object is configured to
uations of high value. In many TD learning systems,               hold some limited number of chunks, with the capac-
this action selection process is performed by a separate          ity specified by the designer. There is no limitation
component, called the actor (Barto, 1994), but such a             on what kind of information may be grouped into a
component is not needed if the situations resulting from          chunk. Chunks are not restricted to a particular data
actions can be reliably simulated. In such a case, the            type, and the WorkingMemory object simply maintains
adaptive critic is used to estimate the values of all of          untyped pointers to the chunks stored within it. When
the situations that can be immediately reached from the           the robot encounters a new situation, its control systems
current situation, and the action that leads to the high-         are expected to generate a list of candidate chunks. For
est value situation is taken. This is the strategy taken          example, object recognition systems may detect the pres-
by our adaptive working memory system, where the dif-             ence of a salient object, producing candidate chunks for
ferent situations considered involve different collections        the existence of the object, its location, and other rele-
of chunks actively retained in working memory.                    vant properties. Control systems may also produce can-
                                                             1752

didate chunks that correspond to actions or goals, such          bined with the chunks that are currently stored in the
as a desire to grasp a particular object. Importantly,           working memory. The working memory system is then
candidate chunks are not automatically stored in work-           faced with the problem of deciding which chunks to re-
ing memory. Instead, the list of candidates is passed to         tain. The system examines every possible subset of the
the WorkingMemory object, and the object then uses the           collection of chunks that can fit within the limited ca-
TD learning algorithm to learn which chunks to retain            pacity of the working memory. Each subset of chunks is
and which to discard.                                            translated into vectors of real valued features, and these
   In order to evaluate the retention of a chunk, the adap-      are combined with the vector encoding of the robot’s cur-
tive critic needs to be input real valued features of the        rent situation to produce an input vector for the adaptive
chunk that may be predictive of task success and, thus,          critic. The combination of chunks that yields the highest
future reward. Since the WMtk does not limit the struc-          estimate of future reward is the one that is selected, and
ture of chunks, however, it cannot automatically extract         all of the chunks in that subset are retained. All other
meaningful features from the candidate chunks for this           chunks are discarded. The temporal difference error is
purpose. Thus, the WMtk requires the designer to spec-           then calculated, using the reward function value for the
ify a function that maps any chunk into a vector of real         previous time step, our estimated future reward from
values that may be used by the adaptive critic to assess         the previous time step, and our estimated future reward
the value of the chunk.                                          that was just calculated. This temporal difference error
   A chunk rarely has intrinsic value, however, but is           is then used to adjust weights in the adaptive critic. In
only worthy of retention in certain contexts. Thus, the          order to encourage the adaptive critic to explore various
adaptive critic must have access to a representation of          new memory combinations from time to time, a noise pa-
the current context in which the robot finds itself. In          rameter () is used to specify the probability with which
order to provide this information, the system designer           a random combination of chunks will be maintained in
is required to specify another function which maps the           preference to the optimal subset, as determined by the
robot’s current situation (e.g., its sensory state) into a       adaptive critic.
vector of real values.
                                                                 Delayed Saccade Task
   Finally, the TD learning mechanism of the working
memory system needs to be aware of the arrival of re-            As an initial test of the utility of the WMtk, we imple-
ward. This is provided by the system designer in the             mented a software simulation of a classic working mem-
form of a reward function which returns the scalar re-           ory task known as the delayed saccade task. In this task,
ward value associated with the current situation. At             the robot is expected to fix its gaze on an object in the
each update cycle (i.e., next time step or new state), the       center of the screen (a crosshair). Then another object
WorkingMemory object calls this function to get the in-          (a brightly colored dot) is presented in the periphery for
stantaneous reward associated with the current situation         a brief period of time. Finally, once a “go” signal is
in order to compute the TD error, which drives learning          provided (the crosshair vanishing), the robot is expected
in the adaptive critic.                                          to shift its gaze to where the peripheral object had ap-
   The WMtk is designed to be easy to reconfigure but            peared earlier. Rather than program the robot to per-
proficient when used in the default configuration. For           form this task, we required it to learn correct behavior
example, the system designer may specify how the real            via a working memory system using the WMtk.
vectors encoding chunk features and the real vector en-             The spatial working memory system used for this task
coding the current situation are combined and prepro-            used a simple configuration. The capacity was set to
cessed before presentation to the adaptive critic network.       three chunks, which was more than what was needed
By default, the vectors for the situation and for each           for this task. We limited the number of screen loca-
chunk being considered for retention are simply concate-         tions at which objects could appear to five, allowing us
nated together to form the input to the adaptive critic.         to encode the sensory state of the robot using fifteen bi-
Other input encoding options are available. For example,         nary features: five for the location (if any) of a displayed
there are cases in which the features of individual chunks       crosshair, five for the location (if any) of a displayed dot,
are unimportant as long as at least one of the retained          and five for the current location of the robot’s gaze.
chunks possess a feature of interest. In these cases, the           Three different kinds of chunks were considered for re-
vector representations for the considered chunks might           tention. These chunk types were “remember the location
be combined using a logical OR operation, producing              of the crosshair” (cross chunk), “remember the location
a compact “OR code” of the collection of chunks that             of the dot” (target chunk), and “remain fixated on what-
may be presented to the adaptive critic for evaluation.          ever you’re looking at” (fixation chunk). Only the type
Similarly, a “NOISY-OR code” option is provided, which           of the chunk was presented to the adaptive critic, en-
combines considered chunk vectors using the information          coded over a vector of three binary features, one for each
theoretic NOISY-OR function.                                     chunk type. Location information, while not available to
   Given this collection of designer-specified functions,        the adaptive critic, was stored in chunk data structures.
the WorkingMemory object executes the following rou-             These chunks were generated by the robot control sys-
tine. On each time step of the task, a new list of can-          tem based on the current state of the environment. The
didate chunks is given to the WorkingMemory object by            robot would sense whether there was a crosshair or a tar-
the robot control system. Initially, these chunks are com-       get present, and, for each object present, it would create
                                                            1753

a corresponding candidate chunk that recorded the lo-               only be consistently produced if the working memory
cation of the object. Also, if the robot happened to be             system learned, from experience, to retain appropriate
looking at an object, a fixation chunk was generated for            considered chunks. Specifically, failure to remember the
consideration. Once generated, all of these chunks were             location of a briefly presented target dot would make
provided to the WorkingMemory object as candidates for              it virtually impossible for the robot to saccade to the
retention. (New chunks that duplicated current working              correct location at the end of the trial. Conversely, the
memory contents were not considered, however.)                      spurious retention of a cross chunk would cause the robot
   With regard to the reward function, a scheme was used            to prefer to look at the middle of the screen than at the
that both matched standard practice in the primate lab-             location of the previously presented target. Thus, the
oratory and matched reward functions found in the re-               robot was required to learn which chunks needed to be
inforcement learning literature. The robot was provided             remembered and which needed to be ignored.
with a scalar reward value of 0 for all situations until the
very end of a trial. If the robot’s behavior was perfect
for the trial — remaining centrally fixated until the “go”                                   Results
signal was given and only then saccading to the location
of the previously presented target — the robot was pro-
vided with a reward of 20.1 If the robot did not perform            Each trial varied in length from thirteen to twenty time
the trial correctly, a reward of 0 was provided at the end.         steps. The first three time steps of each trial consisted of
   The final critical component of this demonstration was           a blank screen. Then the sequence of stimuli — crosshair
the control system that made use of working memory                  appearance, target dot flash, and crosshair removal —
contents in order to select behaviors. This control sys-            was presented, with the onset time of each event vary-
tem contained two parts. The first corresponded to rela-            ing randomly. The last time step always consisted of a
tively automatic processes that would be automatically              blank screen, corresponding to the point just after the
engaged unless actively blocked by working memory con-              the disappearance of the crosshair. At this point, the
tents. The second part implemented controlled behav-                robot would either be rewarded for never looking away
iors driven by the presence of working memory chunks.               from the crosshair and then looking at the proper loca-
This division is consistent with models of the role of PFC          tion or not rewarded for having looked away from the
working memory circuits in cognitive control, with the              crosshair too early or not looking at the correct location
working memory actively maintaining chunks that focus               on the last time step.
attention on particular goals in an effort to inhibit more             A simulation consisted of running trials back-to-back
automatic behaviors (Braver and Cohen, 2000).                       until the system performed the task correctly for twenty
   The automatic behaviors of the robot were very basic,            trials in a row. The weights of the adaptive critic were
and they would not be able to reliably perform the de-              initialized to random values in the range [−0.001, 0.001].
layed saccade task on their own. If there are no objects            The learning rate (α) was set to 0.01, the discount rate
displayed, the robot will look at a random location. If             (γ) was set to 0.99, and the backup rate (λ) was set
objects are displayed, it will look at one of them, chosen          to 0.7. The working memory noise parameter () was
randomly, with high probability.2 These simple behav-               set to 0.05. The total number of trials taken to reach
iors were sometimes useful for learning the task (e.g., en-         the stopping criterion was recorded for 1000 simulations.
couraging the robot to look at the crosshair), but they             The average number of trials taken to reach criterion was
would not drive correct responding by themselves.                   459.3 with a standard error of 25.4.
   The controlled behaviors were only invoked by par-
                                                                       This number of trials is not unreasonable. It is much
ticular combinations of chunks. The fixation chunk had
                                                                    less than the number of trials typically needed to train
the highest priority. If a fixation chunk was present,
                                                                    monkeys on this task. Consider that the system must not
and the robot was currently looking at either an object
                                                                    only learn to overcome its automatic search processes,
or a location specified by another retained chunk, then
                                                                    but it must also decide which informational chunks will
the robot would continue to gaze at the current location
                                                                    cause proper controlled processes to be activated. An
with high probability. If a cross chunk or a target chunk
                                                                    examination of the system’s learning trajectory showed
was being maintained, the robot would consider the set
                                                                    that it did not learn to go to the optimal solution im-
of locations corresponding to all such retained chunks,
                                                                    mediately. Several other options were available. For in-
as well as the location of any object that the robot was
                                                                    stance, the robot sometimes simply remembered to look
currently looking at, and randomly choose one of these
                                                                    at the crosshair and then chose a random location at
locations to look at, with high probability. In short, in
                                                                    the end of the trial. This strategy produced a 20% suc-
the absence of fixation chunks and focal visible objects,
                                                                    cess rate. During learning, the system often appeared
the robot would look at a remembered location.
                                                                    to return to this strategy until it discovered the utility
   It is important to note that correct behavior would              of retaining the target location and forgetting the lo-
    1                                                               cation of the crosshair. Once it discovered the correct
      This value was selected because it produced good perfor-      strategy, it did not abandon it, with only random noise
mance when using default WMtk parameters.
    2
      With low probability (0.001), the robot always had a          affecting performance negatively, afterward. The system
chance of ignoring the objects and its memory contents, opt-        performed very well given that its only feedback was the
ing to look at a random location, instead.                          reward or lack of reward at the end of the trial.
                                                               1754

                      Conclusion                                Cowan, N. (2001). The magical number 4 in short-term
Our theory of working memory function, based on the                  memory: A reconsideration of mental storage capac-
biology of the PFC and midbrain dopamine system, has                 ity. Brain and Behavioral Sciences, 24(1):87–185.
been used to account for many phenomena observed in
                                                                Demb, J. B., Desmond, J. E., Wagner, A. D., Vaidya,
the laboratory, but it has yet to be validated in the con-
                                                                     C. J., Glover, G. H., and Gabrieli, J. D. E. (1995).
text of more complex real-world working memory tasks.
                                                                     Semantic encoding and retrieval in the left inferior
In order to test this theory, we have begun to incor-
                                                                     prefrontal cortex: A function mri study of task dif-
porate an associated computational neuroscience model
                                                                     ficulty and process specificity. Journal of Neuro-
into robot control systems. We have demonstrated that
                                                                     science, 15:5870–5878.
the robotic version of this model is functional and ca-
pable of simulating performance on a simple standard            Funahashi, S., Bruce, C. J., and Golman-Rakic, P. S.
spatial working memory task.                                         (1989). Mnemonic coding of visual space in the
   The next step will involve using the WMtk for more                monkey’s dorsolateral prefrontal cortex. Journal of
complex aspects of robot control. We are currently in-               Neurophysiology, 61:331–349.
tegrating the WMtk with an object recognition system
embedded in a mobile robot. This working memory sys-            Goldman-Rakic, P. S. (1987). Circuitry of the prefrontal
tem will be rewarded if it remembers the location of en-             cortex and the regulation of behavior by represen-
vironmental objects that make for good landmarks —                   tational knowledge. In Plum, F. and Mountcastle,
objects that are easily reacquired and are useful for lo-            V., editors, Handbook of Physiology, pages 373–417.
calization. We hope to show that the adaptive working                American Psysiological Society, Bethesda, MD.
memory mechanisms of our model are capable of learning
                                                                Miller, E. K. and Desimone, R. (1994). Parallel neu-
to identify the features of good landmarks from experi-
                                                                     ronal mechanisms for short-term memory. Science,
ence. Such a result will provide further evidence of the
                                                                     263:520–522.
power and scalability of this computational account of
the neural basis of working memory.                             Miller, G. A. (1956). The magical number seven, plus or
                                                                     minus two: Some limits on our capacity for process-
                 Acknowledgments                                     ing information. Psychological Review, 63:81–97.
This work has been supported by the National Science
Foundation under grant EIA-0325641. The authors ex-              Miyake, A. and Shah, P., editors (1999). Models of
tend their thanks to their collaborators on this NSF ITR             Working Memory: Mechanisms of Active Mainte-
project, the members of the Computational Cognitive                  nance and Executive Control. Cambridge University
Neuroscience Laboratory at Vanderbilt University, and                Press, Cambridge.
three anonymous reviewers.
                                                                 Montague, P. R., Dayan, P., and Sejnowski, T. J. (1996).
                      References                                     A framework for mesencephalic dopamine systems
                                                                     based on predictive hebbian learning. Journal of
Baddeley, A. D. and Hitch, G. J. (1974). Working mem-                Neuroscience, 16:1936–1947.
     ory. In Bower, G. A., editor, Recent Advances in
     Learning and Motivation, volume 8, pages 47–90.             O’Reilly, R. C., Braver, T. S., and Cohen, J. D. (1999). A
     Academic Press, New York.                                       biologically based computational model of working
                                                                     memory. In (Miyake and Shah, 1999), chapter 11,
Barto, A. G. (1994). Adaptive critics and the basal
                                                                     pages 375–411.
     ganglia. In Houk, J. C., Davis, J. L., and Beiser,
     D. G., editors, Models of Information Processing in         O’Reilly, R. C., Noelle, D. C., Braver, T. S., and Cohen,
     the Basal Ganglia, pages 215–232. MIT Press.                    J. D. (2002). Prefrontal cortex and dynamic cate-
Braver, T. S. and Cohen, J. D. (2000). On the con-                   gorization tasks: Representational organization and
     trol of control: The role of dopamine in regulating             neuromodulatory control. Cerebral Cortex, 12:246–
     prefrontal function and working memory. In Mon-                 257.
     sell, S. and Driver, J., editors, Control of Cognitive      Shultz, W., Dayan, P., and Montague, P. R. (1997). A
     Processes, volume 18 of Attention and Performance,              neural substrate of prediction and reward. Science,
     chapter 31, pages 713–737. MIT Press.                           275:1593–1599.
Camperi, M. and Wang, X.-J. (1998). A model of visu-             Sutton, R. S. (1988). Learning to predict by the methods
     ospatial working memory in prefrontal cortex: Re-               of temporal differences. Machine Learning, 3:9–44.
     current network and cellular bistability. Journal of
     Computational Neuroscience, 5:383–405.                      Wallis, J. D., Anderson, K. C., and Miller, E. K. (2001).
                                                                     Single neurons in prefrontal cortex encode abstract
Cohen, J. D., Forman, S. D., Braver, T. S., Casey, B. J.,            rules. Nature, 411:953–956.
     Servan-Schreiber, D., and Noll, D. C. (1994). Acti-
     vation of prefrontal cortex in a nonspatial working         Waugh, N. C. and Norman, D. A. (1965). Primary mem-
     memory task with functional MRI. Human Brain                    ory. Psychological Review, 72:89–104.
     Mapping, 1:293–304.
                                                            1755

