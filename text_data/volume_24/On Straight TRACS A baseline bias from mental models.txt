UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
On Straight TRACS: A baseline bias from mental models
Permalink
https://escholarship.org/uc/item/6rg5q5pm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Author
Burns, Kevin
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                  On Straight TRACS: A baseline bias from mental models
                                             Kevin Burns (kburns@mitre.org)
                                         The MITRE Corporation, 202 Burlington Road
                                                   Bedford, MA 01730-1420 USA
                            Abstract                                 From a psychological perspective, TRACS is useful
                                                                  because it provides a naturalistic micro world for
   TRACS (Tool for Research on Adaptive Cognitive                 experiments and simulations. Unlike other approaches
   Strategies) is a family of games played with a special         to research on probabilistic reasoning, which often
   deck of two-sided cards (see www.tracsgame.com).
                                                                  employ verbal stimuli in the form of static questions,
   TRACS has the advantage of being both mathematically
   tractable to theoretical analysis and psychologically
                                                                  TRACS employs graphical stimuli in a game of
   relevant to practical applications. The simplest game,         dynamic situations. This reduces artificial framing
   called Straight TRACS, is a series of choices where the        effects (see Nickerson, 1996) and introduces realistic
   player must turn over one of two cards to match a third        temporal context.
   card. The object is to make the most matches on a trip            We are using TRACS to perform experiments on
   through the deck. The challenge is to track the changing       human subjects and to perform simulations with
   odds in order to make the best choices. We performed           software agents. Our experiments are designed to elicit
   experiments and simulations to measure human                   cognitive strategies and our simulations are designed to
   performance in this probabilistic and dynamic task. We
                                                                  evaluate these strategies against normative standards.
   present our finding of a Baseline Bias, in which
   subjective odds are (incorrectly) anchored to the baseline
                                                                  Taken together, our experiments and simulations allow
   odds. This is an interesting result because it is contrary to  us to build and test models of cognitive competence
   other well-known biases, such as Gambler’s Fallacy, in         that are relevant to practical applications in command
   which subjective odds are (incorrectly) not anchored to        and control (Burns, 2001c).
   the baseline odds. We propose a theory of mental models           This paper reports on our first experiment and
   to reconcile our finding with previous research on             simulations using the simplest version of the game,
   heuristics and biases.                                         called Straight TRACS. We explain the game, discuss
                                                                  our experiment and present our finding of a Baseline
                        Introduction                              Bias. We also propose a theory of mental models to
A dilemma of decision research is to obtain the rigors            reconcile our finding with previous research on
of controlled experimentation yet maintain some                   heuristics and biases.
relevance to practical applications. Our approach is a
synthetic task environment (Gray, in press) called                                       The Game
“TRACS” (Burns, 2001a) that replicates the cognitive              Straight TRACS is a solitaire game played with 24 two-
challenges of naturalistic decision-making (Klein,                sided cards (Table 1). The backs of the cards, called
1998), including probabilistic risk assessment and                “tracks”, show black shapes (triangle, circle or square).
dynamic resource allocation.                                      The fronts of the cards, called “treads”, show colored
   TRACS is both a unique game and a useful tool                  sets (Red or Blue) of these same shapes. Table 1 shows
(Burns, 2001b). From a mathematical perspective,                  the distribution of shape/color (track/tread) cards in the
TRACS is unique because it is played with a special               deck. This distribution defines the baseline odds. For
deck of two-sided cards, and because it has extensible            example, at the start of the game, a triangle track is
rules that allow the same game to be played alone or              likely (6/8 = 75%) to be Red, a square track is likely
with others.                                                      (6/8 = 75%) to be Blue and a circle track is 50-50.
   Unlike standard playing cards, the backs of the cards          However, during the game, the odds change as the deck
provide clues to the fronts, and the deck contains                is depleted.
unequal numbers of each card type (Table 1).
Compared to Poker and other games of imperfect
information, the two-sided cards make TRACS more                    Table 1: Distribution of cards in the deck. The backs
tractable to theoretical analysis of optimal solutions.             are called “tracks” and the fronts are called “treads”.
Compared to Chess and other games of perfect
                                                                       # of Cards     6      4      2       2      4     6
information, the two-sided cards make TRACS more
                                                                      Front (tread)  Red   Red     Red    Blue   Blue   Blue
relevant to diagnoses and decisions in practical domains
like business, medicine and warfare.
                                                                      Back (track)   ▲      ●       ■      ▲      ●      ■

   To play Straight TRACS, the deck is held face down                               Analysis
and three cards are dealt to a field. Two cards are dealt
face down (showing their tracks) and the third card is
dealt face up (showing its tread). The player’s task is to  Baseline Bias
turn over one of the two tracks (revealing its tread),      The player’s problem is illustrated in Figure 2, which
trying to match the tread (color) of the third card. The    shows the actual odds for a typical game. By
turn is scored a “save” if the treads match or a “strike”   convention, we measure odds in % Red, where % Blue
if the treads clash. The two treads are removed from the    = 100 - % Red. Figure 2 shows that the odds for each
field and the remaining track is turned to reveal its       track type start at their baseline values (75% Red for
tread. This becomes the tread to match on the next turn.    triangles, 50% Red for circles and 25% Red for
Two new tracks are dealt from the deck, a track is          squares). However, the actual odds change (moving
turned, the treads are scored, etc. Play continues until    up/down on Figure 2) as tracks are turned to reveal their
all cards (except the last two, which do not count) have    treads (moving right on Figure 2).
been paired and scored. The object of the game is to
minimize strikes on a trip through the deck.
                      Experiment
The goal of our experiment was to measure how people
track the changing odds in TRACS. The probe in our
experiment was a confidence meter that players set
before each turn to indicate their subjective belief in the
color (tread) of each shape (track) on the field. We used
two different confidence meters (Figure 1), both based
on a spectrum that runs from 100% Red to 100% Blue.
One confidence meter displayed a discrete set of
qualitative values on an octal scale. The other
confidence meter displayed a continuous set of
quantitative values on a decimal scale.
            Red                             Blue
                 “Button” Confidence Meter
                                                                 Figure 2: Change in actual odds (typical game).
                                            Blue
                                                               Figure 3 illustrates a typical player’s solution to the
            Red
                                                            problem illustrated in Figure 2, as reported by the
                                                            player’s setting of the confidence meter for each track
                 “Pointer” Confidence Meter
                                                            (before each turn). Relative to the actual odds (Figure
                                                            2), we see that the reported odds exhibit a bias towards
        Figure 1: Two different confidence meters.          the baseline odds. For example, after a minor
                                                            adjustment near the start of the game, the player (Figure
   We tested 43 adults playing 10 games each. Subjects      3) reported constant odds for circles even after the
were tested on a personal computer using a mouse to set     actual odds (Figure 2) had moved far from the baseline.
the confidence meter. There were no time limits, but        This Baseline Bias is explored further below.
each game was typically completed in less than 5
minutes. Each subject played in two blocks of 5 games,
                                                            Odds Inversions
one block with each confidence meter in balanced
design to control for fatigue and learning effects. The     Recall that the object of Straight TRACS is to turn the
two blocks were separated by a short break. Before data     track that is most likely to match a given tread. At the
collection, subjects read a playbook that described the     start of the game, this is a simple task since the baseline
cards and rules, watched a demo and played a practice       odds specify which track to turn, e.g., triangle rather
game. All games were played with random shuffles of         than circle to match Red. However, as the deck is
the deck and all 43*10 = 430 shuffles were unique. The      depleted, the actual odds for two track types may
experimental results were similar for Button and            become “inverted” with respect to their baseline
Pointer confidence meters, so all data is combined here,    configuration. This occurs whenever there is a
rounding Pointer data to the nearest Button for             crossover of two track types on the dynamic odds plot
consistency.                                                (Figure 2).

                                                          Average Error
                                                          Each odds inversion (see above) involves a pair of
                                                          tracks. As another measure of cognitive competence,
                                                          we also examine confidence errors for single tracks.
                                                          Figure 5 shows the average error versus turn in game,
                                                          for human subjects and for a simulated agent that
                                                          always plays the baseline odds.
                                                             Figure 5 shows that error increases with turn, i.e., as
                                                          the actual odds deviate more from the baseline odds, for
                                                          both the human subjects and the baseline agent. This
                                                          shows that people have a Baseline Bias relative to the
                                                          actual odds (zero error). Figure 5 also shows that the
                                                          average error is higher for human subjects than for the
                                                          baseline agent at the start of the game. This is a
                                                          surprising result because: (1) The baseline odds are
                                                          explicitly illustrated on the cards (treads) for the player
                                                          to see. (2) The actual odds are obviously equal to the
                                                          baseline odds at the start of the game. (3) Playing the
    Figure 3: Change in reported odds (typical game).     baseline odds is a strategy that requires virtually no
                                                          mental effort.
   For example, in Figure 2, a crossover near the middle
of the game causes the odds to be less % Red for
triangles than for circles for the remainder of the game.
This is an inversion of the baseline odds relation
between triangles and circles. Figure 3 shows that the
player failed to detect this odds inversion.
   As a gross measure of cognitive competence, we treat
each odds inversion as a signal that a player must detect
in order to minimize strikes in Straight TRACS. Figure
4 shows the total number of hits, misses and false
alarms for this signal (for all players and all games).
The relatively small number of hits compared to misses
demonstrates that subjects exhibit a Baseline Bias. The
occurrence of some hits and false alarms suggests that,
although biased towards the baseline odds, subjects are
at least trying to update odds, i.e., they are not just
playing the baseline odds.
                                                                   Figure 5: Average error in reported odds.
                                                          Kinds of Errors
                                                          To help explain Figure 5, we define a taxonomy of
                                                          errors (Table 2). We first distinguish between Cognitive
                                                          Errors, which are mental errors in judging odds, and
                                                          Manipulative Errors, which are physical errors in
                                                          moving the mouse to match the mind. We then
                                                          distinguish between two kinds of Cognitive Errors:
                                                          Update Errors are mental errors in updating odds
                                                          relative to baseline odds, and Baseline Errors are
                                                          mental errors in estimating the baseline odds
                                                          themselves. Finally, we further distinguish between two
                                                          kinds of Update Errors: Omission Errors are where no
                                                          mental update is performed when it should be, and
         Figure 4: Detection of odds inversions.          Commission Errors are where a mental update is
                                                          performed but the result is incorrect.

                                                            Anchoring and Adjustment
                Table 2: A taxonomy of errors.              These results are consistent with the well-known
                                                            heuristic strategy of “anchoring and adjustment”
                            Errors                          (Tversky & Kahneman, 1974). In our case, the baseline
                                                            odds (with some Baseline Error, see above) are the
                                                            anchor to which people make adjustments. The
                                                            adjustments are, on average, better than pure anchoring
       Cognitive Errors            Manipulative Errors      but significantly worse than optimal adjusting.
                                                               To gain further insight into the adjustments, we
                                                            examine how the confidence meter settings change
                                                            from turn to turn (for the same track type). We define
         Update Errors                Baseline Errors       various magnitudes of adjustment (i.e., no-button jump,
                                                            one-button jump, two-button jump, etc.) and compute
                                                            the number of times each magnitude of adjustment was
                                                            made. Figure 6 compares the results for human subjects
        Omission Errors             Commission Errors       to an optimal agent (playing the same games) who
                                                            always sets the confidence meter at the actual odds. As
                                                            expected from anchoring, human subjects most often
                                                            make a no-button adjustment. This is in contrast to the
   The baseline agent makes no Manipulative Errors, no      optimal agent, who most often makes a one-button
Baseline Errors and no Commission Errors, i.e., it          adjustment.
makes only Update Errors of Omission. In fact, since
the baseline agent never updates odds, its performance
provides an upper bound on the magnitude of Omission
Errors. Figure 5 shows that the baseline agent’s Update
Error is non-zero on turn 1. This is because the tread on
the first field can cause a change in odds before the first
turn. For example, assume that the cards on the first
field are circle (track), Red circle (tread) and square
(track). The baseline odds for circles are 4/8 Red, but
since one Red circle is revealed as a tread on the field,
the actual (updated) odds for circles are 3/7 Red. The
same effect is magnified on later turns as more treads
are revealed, hence the Omission Error increases with
turn (Figure 5, curve for baseline agent).
   For human subjects, the total error comprises
Manipulative Error, Baseline Error and Update Error
(Omission and Commission). The difference between
total human error and baseline agent error on turn 1 is
attributed to Manipulative Error and Baseline Error,
which we assume are relatively independent of turn in           Figure 6: Number of adjustments (by magnitude).
game. Thus, the curve for total human error can be
shifted downwards (curve * in Figure 5) to get an              Besides the magnitude of adjustment, we also
estimate of human Update Error.                             examine various types of adjustments. We define five
   This shifted curve for human error is directly           types of adjustments (Table 3) and compute the number
comparable to the error curve for the baseline agent,       of times each type of adjustment was made. Figure 7
which also includes only Update Error. The comparison       compares the results for human subjects to an optimal
(Figure 5) shows that human subjects are biased             agent (playing the same games) who always sets the
towards the baseline agent, relative to the actual odds     confidence meter at the actual odds.
(zero error). However, the shifted curve also shows that
human subjects outperform the baseline agent (who           Table 3: Types of adjustments (anchor = baseline odds).
does not update odds), and the difference grows with
turn as the difference between actual odds and baseline
                                                              Type 0     No adjustment
odds increases. Thus, we conclude that human subjects
                                                              Type 1     From on-anchor to off-anchor
make fewer Omission Errors than the baseline agent,
and that the Commission Errors made by human                  Type 2     From off-anchor to more off-anchor
subjects are not significantly larger in number and           Type 3     From more off-anchor to less off-anchor
magnitude than the baseline agent’s Omission Errors.          Type 4     From off-anchor to on-anchor

   As expected from anchoring, Figure 7 shows that          We further claim that: (1) Mental models are
human subjects make many more Type 0 adjustments         bounded by natural regularities of the world. (2) Mental
(actually non-adjustments) and less Type 1 and Type 2    models have a normative basis within their natural
adjustments than the optimal agent. Figure 7 also shows  bounds. (3) Cognitive competence can be explained and
that the difference between Type 1 and Type 4            predicted by specifying the natural bounds and
adjustments is smaller for human subjects than for the   normative basis of mental models (i.e., in bounded
optimal agent. This suggests that, when people do move   rationality, see Simon, 1990).
off the baseline anchor (Type 1) in an attempt to adjust    More specifically, we claim that probabilistic mental
odds, they often “lose it” and return to the baseline    models can be characterized as computational “mind
anchor (Type 4). The optimal agent moves off the         sets” (Burns, 2002). Like the term “model”, which is
baseline anchor (Type 1) more often and returns to the   both noun and verb, we use the term “set” in dual sense
anchor (Type 4) only when the actual odds are equal to   to refer to both the mental representation of classes
the baseline odds (i.e., the agent never “loses it”).    (e.g., declarative knowledge) and the mental operation
   These results (Figures 6 and 7) further support our   of routines (e.g., procedural knowledge). The central
conclusion that Baseline Bias in TRACS (Figures 4 and    tenet of our theory (Burns 2002) is that these mind sets
5) is caused by a heuristic strategy of anchoring and    are normative within their cognitive bounds.
adjustment.                                                 As an initial test, below we sketch how our theory
                                                         can explain Baseline Bias in TRACS. We also sketch
                                                         how our theory can reconcile Baseline Bias with
                                                         previous findings of Gambler’s Fallacy and Base Rate
                                                         Neglect in other probabilistic reasoning tasks (Tversky
                                                         & Kahneman, 1974). This is a non-trivial test of the
                                                         theory, since Gambler’s Fallacy and Base Rate Neglect
                                                         appear at first glance to be contrary to Baseline Bias.
                                                         Gambler’s Fallacy and Base Rate Neglect
                                                         In Baseline Bias (in TRACS), people do not update the
                                                         baseline odds when they should. Conversely, in
                                                         Gambler’s Fallacy, people update the baseline odds
                                                         when they should not. Furthermore, in Base Rate
                                                         Neglect, people discount or ignore the baseline odds
                                                         altogether. How can we explain these differences?
                                                         According to our theory, all three biases occur because
                                                         people reason about probabilities with mind sets.
                                                            For Base Rate Neglect (Tversky & Kahneman, 1974;
       Figure 7: Number of adjustments (by type).        Koehler, 1996; Cosmides & Tooby, 1996), we suggest
                                                         that people ignore the baseline odds in light of other
   The question, of course, is how (exactly) do people   evidence because they believe that the baseline odds
decide when and how much to move off anchor? That        reflect a less relevant (not applicable) set of
is, what (exactly) are the mental limits that prevent    occurrences. It is difficult in theory, let alone in
more accurate adjustments? The answer is crucial if we   practice, to aggregate probabilities that are derived from
are to explain and predict human performance in          diverse sources with different pedigrees. As such, it is a
TRACS or any other domain where people must think        bounded-Bayesian strategy to rely on the one source
probabilistically about things that are changing         that is judged to be most relevant and reliable. Base
dynamically. Below we propose a theory of mental         rates that are judged irrelevant or unreliable are
models that takes a first step in this direction.        therefore neglected.
                                                            For Gambler’s Fallacy (Tversky & Kahneman,
                          Theory                         1974), we suggest that people update the baseline odds
                                                         because they are judging odds for a finite (bounded) set
Mind Sets                                                rather than for an infinite set. For example, after seeing
                                                         10 heads and 2 tails, a gambler who believes the coin is
We claim (Burns, in press; 2002; 2001b; 2001c; 2001d)    fair will think that the future holds more tails than
that people make sense of the world by forming           heads, simply because he thinks that the eventual (large
probabilistic models in their heads (see Knill &         but finite) set of many tosses for this coin will be
Richards, 1996; Johnson-Laird, 1994; Gigerenzer et al.,  balanced. As such, it is a bounded-Bayesian inference
1991).                                                   to conclude that the future odds are slightly higher for
                                                         tails than for heads.

  For Baseline Bias (in TRACS), we suggest that             Burns, K. (in press). Mental models and normal errors.
people want to update odds (as they tell us) but that it is   In Brehmer, B., Lipshitz, R., Montgomery, H. (Eds.),
simply beyond their cognitive capacity. To do so,             How Do Professionals Make Decisions? (Lawrence
players must count cards in each of six sets (see Table       Erlbaum). Also presented at 5th Conference on
1) and normalize to convert the counts to odds. These         Naturalistic Decision Making, Tammsvik, Sweden,
two tasks, i.e., concurrent counting and normalizing          May 2000.
numbers, are naturally hard for the unaided mind            Cosmides, L., & Tooby, J. (1996). Are humans good
(Dehaene, 1997; Dehaene, 1992; Gallistel & Gelman,            intuitive statisticians after all? Rethinking some
1992; Nickerson, 1996). Thus, with self-knowledge of          conclusions from the literature on judgment under
mental limits, it is a bounded-Bayesian strategy to           uncertainty. Cognition, 58, 1-73.
remain anchored to the baseline odds unless and until       Dehaene, S. (1992). Varieties of numerical abilities.
the evidence for an adjustment is compelling. For             Cognition, 44, 1-42.
example, in the extreme case, pure anchoring to             Dehaene, S. (1997). The Number Sense: How the Mind
baseline odds (i.e., never adjusting) is the bounded-         Creates Mathematics (New York: Oxford).
Bayesian strategy for a decision maker who knows that       Gallistel, C., & Gelman, R. (1992). Preverbal and
he cannot remember which cards have been revealed in          verbal counting and computation. Cognition, 44, 43-
the course of a game.                                         74.
                                                            Gigerenzer, G., Hoffrage, U., Kleinbölting, H. (1991).
                     Conclusion                               Probabilistic mental models: A Brunswikian theory
                                                              of confidence. Psychological Review, 98, 506-528.
Our initial experiment and simulations show that
                                                            Gray, W. (in press). Simulated task environments: The
TRACS provides a useful micro world for investigating
                                                              role of high-fidelity simulations, scaled worlds,
how people make diagnoses and decisions under
                                                              synthetic environments and micro worlds in basic and
uncertainty. Our finding in Straight TRACS is that
                                                              applied cognitive research. Special Joint Issue of
players exhibit a Baseline Bias, which we attribute to a
                                                              Cognitive          Science        Quarterly       and
heuristic strategy of anchoring and adjustment. We
                                                              Kognitionswissenschaft.
sketched a theory of set-based mental models that
                                                            Johnson-Laird, P. N. (1994). Mental models and
reconciles our finding with previous research on
                                                              probabilistic thinking. Cognition, 50, 189-209.
heuristics and biases. Our future plans are to use
                                                            Klein, G. (1998). Sources of Power: How People Make
TRACS to investigate the mental limits of concurrent
                                                              Decisions (Cambridge, MA: MIT Press).
counting, normalizing numbers and other facets of
                                                            Knill, D., & Richards, W. (1996). Perception as
cognitive competence in probabilistic and dynamic
                                                              Bayesian Inference (New York: Cambridge
reasoning.
                                                              University Press).
                                                            Koehler, J. (1996). The base rate fallacy reconsidered:
                Acknowledgements                              Descriptive,     normative     and      methodological
This research was supported by the MITRE Technology           challenges. Behavioral and Brain Sciences, 19, 1-53.
Program. Thanks to Craig Bonaceto, Eric Forbell and         Nickerson, R. (1996). Ambiguities and unstated
Fritz Behr for their work on the experiment and               assumptions in probabilistic reasoning. Psychological
simulations.                                                  Bulletin, 120, 410-433.
                                                            Simon, H. (1990). Invariants of human behavior.
                     References                               Annual Review of Psychology, 41, 1-19.
                                                            Tversky A., & Kahneman, D. (1974). Judgment under
                                                              uncertainty: Heuristics and biases. Science, 185,
Burns, K. (2001a). TRACS: A Tool for Research on              1124-1131.
  Adaptive Cognitive Strategies: The Game of
  Confidence and Consequence. Published on the
  World Wide Web, www.tracsgame.com.
Burns, K. (2001b). Introducing TRACS: A unique
  game and a useful tool. Annual Meeting of the
  Society for Judgment and Decision Making, Orlando,
  Florida.
Burns, K. (2001c). A Bayesian basis for mental models.
  Draft manuscript.
Burns, K. (2001d). Mental models of line drawings.
  Perception, 30, 1249-1261.
Burns, K. (2002). Mind sets at TRACS: How people
  deal with changing odds. 40th Annual Bayesian
  Research Conference, Studio City, California.

