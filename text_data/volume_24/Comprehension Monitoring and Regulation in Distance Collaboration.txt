UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Comprehension Monitoring and Regulation in Distance Collaboration

Permalink
https://escholarship.org/uc/item/23d0z07b

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Authors
Cho, Kwangsu
Schunn, Christian D
Lesgold, Alan M

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Comprehension Monitoring and Regulation in Distance Collaboration
Kwangsu Cho (kwangsu@pitt.edu)
Christian D. Schunn (schunn@pitt.edu)
Alan M. Lesgold (al@pitt.edu)
Learning Research and Development Center, University of Pittsburgh
3939 O’Hara Street, Pittsburgh, PA 15260, USA
Abstract
Comprehension monitoring and regulation in a distance
learning situation were examined in comparison to individual
learning through an error-detection paradigm. The
collaborative learning condition produced significantly better
learning and monitoring. These results were interpreted as the
effect of regulative interaction in the collaboration. Then, the
specific interactions of 3 good and 3 poor pairs were
contrasted to examine their interaction pattern in terms of
monitoring and regulation. The results showed that the good
pairs had a higher level of monitoring and regulative
interaction. Also when the good and poor groups successfully
monitored comprehension failure, the poor groups
implemented less effective regulation strategies.

To understand text, learners need to integrate successively
encountered information from that text into a coherent and
well-integrated (mental) representation (Kintsch, 1998).
According to Kintsch this comprehension process proceeds
in a piecemeal way, sequentially developing a bigger and
more coherent representation. This process tends to be prone
to errors such as representation of incorrect information
and/or misrepresentation of correct information due to
omissions, inconsistencies, and/or anomalous and unclear
text. When these comprehension failures occur, learners
should be able to use metacognitive monitoring to detect the
failures and regulation strategies to repair them and thus
construct a more coherent understanding of the text in order
not to end with a lack of understanding or misunderstanding.
However, despite the significance of monitoring and
regulation strategies to text understanding, learners tend to
fail to detect their own misunderstandings (Markman, 1979),
ignore incorrect information (Otero & Kintsch, 1992), and
overestimate their own understandings (Glenberg,
Wilkinson, & Epstein, 1982) and capabilities (Presseley &
Ghatala, 1990). Learners are too often satisfied with their
faulty understanding to challenge given tasks and hence fail
to trigger regulation processes. Accordingly, various efforts
such as metacognitive strategy training, setting up explicit
comprehension goals, or self-generating feedback have been
made to improve learners’ comprehension.
Considering that effective learning often takes place in
social settings, and that individual learners’ comprehension
could be affected by their peers’ comprehension, it seems
worthwhile to examine comprehension monitoring and
regulation in collaborative learning situations. More

specifically, comprehension monitoring and regulation seem
especially critical in distance collaboration situations where
a lot of learning takes place from text. Therefore, the goals
of this research are to examine whether distance
collaboration improves individuals’ comprehension
monitoring and regulation abilities, as well as the conditions
that make distance collaboration produce effective or
ineffective text comprehension.

Monitoring and Regulation in Collaboration
Monitoring and regulation have been considered critical
in effective face-to-face collaboration because they help
learners construct a more coherent understanding. First,
externalizing thinking and understanding through
communication might help collaborators better monitor and
regulate their performance (Miyake, 1997) because it causes
thinking and understanding to become objects that can be
sharable and manipulable between collaborators (Miyake,
1986). While learners working alone are often subject to
self-confirmation bias, learners can benefit from working
with peers thanks to a ‘checking mechanism’ in
collaboration (Miyake, 1986) that advances comprehension
monitoring and regulation. Second, the division of cognitive
processes in collaboration (Dillenbourg, Baker, Blaye, &
O’Malley, 1995) may play a part in improving monitoring
and regulation in collaboration. For example, one peer
might take the role of leader, while another peer might take
the role of monitor (e.g. Miyake, 1986). In the process of
collaboration, many errors made are detected and corrected
by partners (Miyake, 1986; Resnick & Salmon, 1993). Also,
Karabenick (1996) recently showed that learners may have
better comprehension monitoring after receiving questions
from colearners. Third, comprehension monitoring and
regulation could be easily implemented when peers have
conflicting perspectives. As Piaget’s socio-cognitive
conflict theory suggests, collaborating individuals with
different understandings of the same task may advance their
understanding in the process of resolving their differences.
Fourth, regulating comprehension problems seems
fundamental to collaboration processes because the
regulation process in collaboration may be activated
automatically (Schegloff, 1991), and incorrect elements of
their representation might then be fixed through
communicative interactions such as engaged discussion
(Kruger, 1992), elaboration or arguments (van Boxtel, van

der Linden, & Kanselaar, 2000), or other repairs (Lumpe &
Staver, 1995).
Because collaborating learners may have higher chances
of monitoring (detecting that there might be something
wrong) and of regulation (knowing what could be correct
knowledge), it might be straightforwardly expected that
collaborating learners will have better comprehension than
isolated learners. However, when distance between learners
is involved in learning, the above inference seems
complicated because people working together at a distance
report various kinds of difficulties that seem to deteriorate
collaboration. First, the lack of nonverbal communication
cues in distance communications may torture clear
communications (Armstrong & Cole, in press) that help to
manipulate thinking. Second, distance learners have
difficulty in grounding communications and spend a long
time doing so (Kiesler, Siegel, McGuire, 1984). Third, some
studies report that cognitive conflicts are not only well
detected (Armstrong & Cole, in press), but also rather
emotionally charged with no easy method of cognitive
resolution. Finally, anonymous individuals who are placed
in group distance learning situations tend to be less
supportive of each other because of low perceptions of
group cohesion and conformity.
Therefore, one could propose the following model of
effective distance collaboration. When comprehension
failures occur, they should be detected. If not, the failures
might end up with non- or mis-comprehension. Once the
failures are detected, they should be repaired. If not, the
failures also might lead to non- or mis-comprehension. To
test the model, we hypothesized that if interactions between
individuals working at a distance (e-Pairs) are sufficiently
effective, they will be better than the individuals working
alone (Singles) in learning scores because of better
comprehension monitoring and regulation and that good ePairs will be better than poor e-Pairs in comprehension
monitoring and regulation.

Method
Comprehension monitoring and repairing during distance
collaboration was compared to monitoring and repairing
during individual learning. Unlike typical face-to-face
collaboration studies that emphasize ecological validity, we
wanted better experimental control and a wider range of
data.
Participants. Sixty-nine undergraduates (Male = 27,
Female = 42) taking introductory psychology courses
volunteered in this study. All the participants received
course credits for participation. The first language of all the
subjects was English. They all reported that they had
experience using chatting interfaces on the internet and were
familiar with these interfaces. Randomly, thirty-seven of
them were assigned to an individual learning condition
(Singles: male=15, female=22) and the other 32 to the
collaborative learning condition (e-Pairs: male=12,

female=20). All e-Pairs participants were randomly paired
with a same sex partner. One pair was removed from the
data analysis because of a problem with the interface.
Materials. Two expository texts about theories of
knowledge representation were used. One text concerned
symbolism and the other connectionism. The text content
was selected because undergraduate students were not
familiar with these theories of representation, and this
allowed us to minimize the pre-knowledge effect and
maximize the purity of comprehension monitoring and
regulation strategies. Each text consisted of 15 sentences
and had two versions: Consistent and inconsistent.
Following Markman (1979)’s error-detection paradigm,
inconsistent versions had contradictory or inconsistent
information at the 5th, 10th and 15th sentences. For example,
the first five sentences used in the symbolism text were (1)
One of the major theories about representation is called
symbolic representation. (2) The symbolic representation
view is that the human mind represents information as a
language-like or symbolic form. (3) Because most of us
think and all of us write linguistically, we tend to couch our
ideas in symbols like a natural language form. (4) We can
understand thought, belief, problem solving in a languagelike symbolic form. (5c) Thus, in this view, symbols
(roughly, words) are used to represent information in the
human mind. (5i) Thus, in this view, symbols (roughly,
words) are not used to represent information in the human
mind. Here the 5c was a consistent sentence, while 5i was an
inconsistent sentence. Thus, when subjects came to read the
fifth sentence, either (5c) or (5i) was displayed to them.
Detecting the first inconsistent sentence located at the 5th
position was manipulated to be the easiest, that of the
second at 10th position the middle, and that of the last at the
15th position the most difficult in terms of the amount of
correct representation needed to detect the inconsistency.
Interface. A computer interface (see Figure 1) was used to
manage the experiment automatically, to collect data, and to
provide an environment in which the participants could
work. The interface for the main experiment session
consisted of five units: (1) a new sentence display unit, (2) a
history window, (3) a monitoring detection task unit, (4) a
comprehension self-rating slider, and (5) an IRC (internet
relay chatting) as a distance communication channel. The
new sentence display unit was used for displaying each new
sentence. When each new sentence appeared, the previous
sentence moved up to be located at the bottom in the history
window which accumulated all the previous sentences. Thus,
the participants could focus on comprehension instead of
memorizing sentences. The distance communication
channel was an internet relay chatting interface where each
pair communicated without any verbal and nonverbal
interaction. The individual learning condition was identical
except for not having the distance communication channel.

Figure 1: Computer interface
Comprehension monitoring task. There were two
monitoring tasks: Detection and comprehension self-rating.
The detection task was to decide whether or not each
sentence was consistent with previous sentences. The selfrating of comprehension was measured with a rating scale
labeled with 0%, 25%, 50%, 75%, and 100%, indicating the
approximate percentage of the meaning that the subject
believed he/she understood. However, self-rating measures
appeared unreliable and were thus removed from the results.
Comprehension regulation interaction coding scheme.
Each episode (the period between the end of one sentence
and the start of the next new sentence), was evaluated in
terms of the level of monitoring and regulation quality
exhibited. The conversation levels were coded using the
following hierarchical scheme: 0: off-task – coded when an
episode consisted of task-unrelated things; 1: Checking
answers – coded when an episode consisted only of asking
for and providing each other’s answers; 2: Rephrasing –
coded when an episode consisted of providing answers and
rephrasing the given sentence as their rationale; 3:
Explanation – coded when an episode included integrating,
relating, or generating information to explain answers, 4:
Elaboration – coded when subjects proceeded to elaborate
or clarify each other explanation, and 5: Negotiation –
coded when an episode was resolved with an agreed
cognitive solution. This scheme was hierarchical in that the
higher, the better in comprehension as a continuum from
low level monitoring (Checking answers) to high level
regulative behavior (Negotiation). When multiple levels in
an episode appeared together, the highest one was selected
to represent the quality of interaction of the episode. Two
coders independently coded two randomly selected groups
for the analysis and achieved a 0.84 inter-coder reliability.
Procedure. Each participant was randomly assigned to
either the Singles condition or the e-Pairs condition. The
participants went through an instruction session, a pretest
session where they answered 20 multiple choice questions
about the main texts, a warm-up session that had two short
texts to familiarize them with the interface, a 2nd instruction
session that was exactly same as the 1st instruction, a main
task session, and a posttest session. In the instructional

sessions, they read that they would study, with or without a
partner, two draft texts that might or might not have
inconsistent information. They were also instructed that they
should explain the meaning of each sentence – to
themselves in the Singles or with their peer in the e-Pairs –
and that they would get bonus credits based on their
performance. Both the pre- and post-test comprehension
questions, and their alternatives about the main tasks, were
completely randomized. In the main task session, all the
participants in the e-Pairs were randomly paired with a
same-sex partner with whom they had no interaction before
the main task session. The order of presentation of the two
texts was randomized and the selection of either version was
counterbalanced. Thus, the participants studied two texts but
only one of them was an inconsistent version. In each
episode identified as each sentence level interaction,
whenever a new sentence appeared, the participants
individually read the sentence, performed the
comprehension monitoring tasks (the detection and selfrating task) with no means of communication. Then they
studied the sentence by explaining the meaning of the
sentence either alone in the Singles or together with a peer
through the distance interaction channel in the Pairs. When
they decided to finish studying, they hit a button to request
another sentence, at which point the communication channel
was automatically disabled. These sentence level activities
repeated until the end of the two tasks. Note that the e-Pairs
were not asked to reach an agreement, did not have an
interaction before the main task session, and only their first
names were shown on the communication channel interface.

Results
1-1. e-Pairs will be better than Singles in learning
A one-way ANOVA showed no significant difference in the
pretest scores between the Singles and e-Pairs. Another oneway ANOVA was done with the learning defined as the
difference between the post- and pre-test scores. The e-Pairs
(M = 4.47, SD = 1.73) were significantly better than the
Singles (M = 2.62, SD= 1.88) (F(1,65) = 5.13, p = .03).
Finally, the effect size as Cohen’s d was 1.02. These results
provided a rationale to conduct further analyses.
1-2. e-Pairs will be better than Singles in monitoring
The detection task performance as comprehension
monitoring was examined (see Figure 2). In the consistent
versions, the e-Pairs (M = .92, SD = .06) and Singles (M =
.88, SD = .04) were not significantly different on any
sentence. However, in the inconsistent versions, the e-Pairs
were significantly better for the first inconsistent sentences,
the easiest one (5th sentence: for e-Pairs M = .75, SD = .18;
for Singles M = .18, SD=.01) at text 1: F(1,32) = 18.03, p =
.00 and at text 2: F(1,33) = 5.05, p = .02), not for the second
(10th) and the third (15th) inconsistent sentence.
2-1. Good e-Pairs will be better in monitoring

To examine what mechanisms drive effective distance
collaboration, three good (M = 13.3, SD =2.1) and three
poor e-Pairs (M = 4.0, SD = 7.0) were selected, t (4) = 5.74,
p =.00). This selection was made after removing e-pairs
where peers had large knowledge differences, to avoid
looking at extreme cases. No significant differences
between the good and poor Pairs were found in the pretest
scores (Good: M=11.0, SD=2.0; Poor: M=13.0, SD=5.6),
the pretest difference between members in each pair (Good:
M=1.0, SD=.0; Poor: M=1.0, SD=1.0), the mean number of
turns per episode (Good: M=6.7, SD=.3.3; Poor: M=6.4,
SD=5.0), the total time spent per group (Good: M = 52.7
min, SD=15.0; Poor: M=47.2, SD=14.3), and time per
episode (Good: M=1.76 min, SD=.5; Poor: M=1.6, SD=.5).
These non-significant indices formed the baseline against
which to examine differences in the level of monitoring and
regulation quality in collaboration.
1.00
0.97

0.95
0.94 0.94
0.89

1.00
0.81

0.80

0.75

0.75

Hit rate

1.00
0.97
0.92 0.94 0.89
0.81 0.81

0.97
0.94 0.95
0.89 0.92 0.87
0.84

0.72

0.60
Singles

0.40

e-Paris

0.21

0.27

0.20

0.19

0.11
0.06

0.00

1st 2nd 3rd 4th 5th 6th 7th 8th 9th 10th 11th 12th 13th 14th 15th
Sentence No.

Figure 2. Comprehension monitoring task performance
Then, the hypothesis that high e-Pairs will be better in
comprehension monitoring was tested. There were no
significant differences at all three inconsistent sentences,
although the pattern looks similar to that of the comparison
between the e-Pairs and Singles.
5

Quality of Interaction

2-3. Given successful monitoring, good e-Pairs will be
better than poor e-Pairs in regulative interaction.
Before answering the question, we examined when ePairs had longer conversations, which means they tried to
do something more like repairing. Based on each individual
decision on the detection task before starting each
interaction period, each episode was categorized into one of
three categories: both members’ answers or perspectives
were ‘same and correct’, ‘same and incorrect’, or different.
Then comparisons were made between good e-Pairs and
poor e-Pairs. According to a two-way ANOVA (F(2,174) =
8.2, p = .00) and its Scheffe, the only significant difference
was on the category dimension, especially between the level
different and the others (see Table 1).
Table 1: The mean number (SD) of turns in episode
Categories

Good

Poor

Mean

Same & Correct

6.3 (3.1)

5.7 (4.8)

6.0 (4.0)

Same & Incorrect

5.0 (2.5)

6.8 (4.2)

6.0 (3.3)

Different

9.8 (3.0)

8.8 (4.9)

9.2 (4.3)

Mean

6.7 (3.3)

6.4 (5.0)

6.5 (4.1)

5

Quality of interaction

1.00

1.0), F(1,178) = 58.40, p = .00 (see Figure 3). In general, the
good e-Pairs interaction quality was around explanation
level, whereas the poor e-Pairs interaction quality was
between just checking answer and rephrasing (refer to
coding scheme in the method section).

4

3.6

3
2.2
2
1

4
3

0

2.77

Good

1.64

2

Poor
e-Pairs

Figure 4: Quality of interaction given successful monitoring

1
0
Good

Poor
e-Pairs

Figure 3. Quality of regulative interaction in general
2-2. Good e-Pairs will have higher quality of monitoring
and regulative interaction than poor e-Pairs
Another difference was found in the level of monitoring
and regulation quality in their interaction. The good e-Pairs
(M = 2.77, SD = .97) had a significantly higher level of
regulative interactions than the poor e-Pairs (M = 1.64, SD=

Then we examined the hypothesis that good e-Pairs will
have higher quality of interaction (see Figure 4). Regulative
interaction qualities between the good and the poor e-Pairs
were compared when they all had successful monitoring.
Given the total 24 episodes (good: n = 10; poor: n = 14)
where peers in an e-Pair had different perspectives that
signaled there might be something wrong, their interaction
qualities were examined. Interestingly, the poor e-Pairs (M
= 2.21, SD =1.31) showed a significantly lower level of
regulative behavior than the good e-Pairs (M= 3.60, SD =
.52), F(1,23) = 9.95, p = .00. The interaction quality of the
good e-Pairs was between the explanation and elaboration

level, while that of the poor e-Pairs was around rephrasing.
For example, the following episode from a good e-pair
shows that when peers had different opinions they tried to
resolve the difference.
1: Lao i put incorrect b/c i had no clue what that was
about
2: Lao sorry:(
3: Cat haha
4: Cat that's alright
5: Lao i just thought that the info sounded like
conflicting symbols
6: Cat it's just saying that by adding another symbol to a
sentence you can make it a fact
7: Cat the sentence is kinda weird
8: Lao oh ok
9: Lao yeah it is
10: Cat maybe the next sentence will be about
displacement
11: Lao ok
However, another episode from a poor e-pair shows that
after they checked their answers they did not try to resolve
their comprehension failure.
1: Cu
2: Ja
3: Cu
4: Cu
5: Ja
6: Cu
7: Ja

hmm
i wasn't sure about this one
me either
I chose incorrect
oh, i chose correct. i don't know why though...
me either
oh well

Discussion
Comprehension processes are error-prone because they are
constructive and approximate. Learners need to be error
sensitive to attain error-proof comprehension. In this study,
we examined the role of collaboration in improving
comprehension monitoring and regulation in a distance
communication situation, a matter that had not been
investigated before. With a relatively well-controlled
collaboration experiment, we first showed that distance
collaboration is more beneficial to learning than working
alone. In addition, performance in detecting contradictory
information is also somewhat better in collaboration.
Therefore, the better learning that occurred in the e-Pairs
may be attributed to the process of collaboration.
Furthermore, to examine the role of collaboration in
comprehension monitoring and regulation in detail, 3 good
e-Pairs and 3 poor e-Pairs were examined. The good e-Pairs
were not significantly better than the poor e-Pairs in
comprehension monitoring (error detection). However, the
regulative interaction quality of good e-Pairs’ interactions
was generally higher than that of poor e-Pairs. In general,

the good e-Pairs interaction quality was around the
explanation level, whereas the poor e-Pairs interaction
quality was between just checking answer and rephrasing.
Another interesting finding was from the comparison
when both the good e-Pairs and the poor e-Pairs had
successful monitoring. The poor pairs’ regulative
interactions were not highly activated even though their
comprehension problems were monitored explicitly, while
the good groups tended to indulge in higher level of
regulative interaction.
Therefore, the results can be interpreted as supporting the
claim that participants in distance collaboration benefit from
collaborative interaction by improving their detection of
comprehension failures, and implementing repair processes
through regulative interaction. Also, the results support the
research model that states that when comprehension failures
or cognitive conflicts happen they should be detected and
repaired to achieve correct comprehension or learning.
Thus, the model explains why some research on cognitive
conflict finds increased learning while other research does
not. As the model states, cognitive conflicts do not
necessarily result in learning unless the conflicts are
detected and resolved. In this experiment, no case was found
to reach a cognitive resolution coded as negotiation. Instead,
a lot of cases ended up with social negotiation. Here social
negotiation means that conversants agree to blur their
conflicts without reaching a clear resolution, as seen in the
example conversation from the good e-Pair. Interestingly,
there was also no instance of flaming, which is frequently
reported in distance collaboration studies.
The so-called ‘checking mechanism’ (Miyake, 1986) may
be a key for suppressing self-confirmation bias that may be
dominant in solo learning. Self-confirmation bias is a
tendency to stick to an already held explanation rather than
developing alternative explanations. This tendency, when
learning alone, tends to block learners from changing their
representation by suppressing (Otero & Kintsch, 1992)
and/or ignoring (Chinn & Brewer, 1993) inconsistent
information that does not match with their representations.
However, the confirmation bias in a group may be smaller,
because groups are better than individuals at rejecting
presuppositions (Gorman, Gorman, Latta & Cunningham,
1984), so long as they entertain hypotheses and alternative
ideas, and consider justifications (Okada & Simon, 1997).
The results of this research are consistent with other
research in the collaboration community. For example,
Brown and Campione (1986) argued that “understanding is
more likely to occur when a student is required to explain,
elaborate, or defend his or her position to others; the burden
of explanation is often the push needed to make him or her
evaluate, integrate, and elaborate knowledge in new ways”
(p. 1060). Also, Forman and Cazden (1994) identified
parallel, associative, and cooperative interaction patterns,
of which cooperative is the highest level – characterized as
constantly monitoring, guiding and correcting each other’s

work. Additionally, Barron (2000) argued that after
contrasting a high-achievement group with a lowachievement group, greater monitoring for coordination
between members would result in higher results. Therefore,
collaboration might be an ideal way to improve individuals’
monitoring and regulation abilities.
Finally, some aspects of this study should be noted that
may limit generalizations of the results. One is that this
experiment was highly controlled compared to other face-toface collaboration research. We tried to separate the
collaboration period from individuals’ comprehension
monitoring decision periods, to examine the effect of
collaboration on individual learners’ comprehension. Also,
we tried to remove socially confounding variables. For
example, the participants in each pair did not interact before
the main tasks. Although this may appear to limit the
ecological validity of this study in terms of face-to-face
collaboration, it seems acceptable in terms of e-cological
validity since distance collaboration is often between
anonymous individuals. Also it may provide a cleaner
demonstration of the cognitive effects of collaboration on
learning.

Acknowledgments
This study was supported by the NetLearn project funded by
a Technology Innovation Challenge Grant from the
U.S. Department of Education to New York City
Community School District No. 2 and the University of
Pittsburgh and by Microsoft Corporation. We thank Randi
Engle, Heisawn Jeong, Lelyn Saner, Mark McGregor,
Patrick Jermann, Amy Soller, and Brad Morris for their
sincere help.

References
Armstrong, D. J. & Cole, P. (In press). Managing distances
and differences in geographically distributed work
groups. To appear in P. Hinds & S. Kiesler (Eds.),
Distributed Work (working title).
Barron. B. (2000). Achieving coordination in collaborative
problem-solving groups. The Journal of the Learning
Science, 9 (4), 403-436.
Brown, A. L., & Campione, J. C. (1986). Psychological
theory and the study of learning disabilities American
Psychologist, 41, 1059-1068.
Chinn, C. A., & Brewer, W. F. (1993). The role of
anomalous data in knowledge acquisition: A theoretical
framework and implications for science instruction.
Review of Educational Research, 63, 1-49.
Dillenbourg, P., Baker, M., Blaye, A., O’Malley, C. (1995)
The Evolution of Research on Collaborative Learning. In
Reimann, P., Spada, H. (eds.) Learning in human and
machines. Towards an interdisciplinary learning science,
London: Pergamon.

Forman, E.A. & Cazden, C.B. (1985). Exploring
Vygotskian perspectives in education: The cognitive
value of peer interaction. In J.V. Wertsch (Ed.), Culture,
communication and cognition: Vygotskian perspectives.
New York: Cambridge University Press.
Glenberg, A. M., Wilkinson, A. C., & Epstein, W. (1982).
The illusion of knowing: Failure in the self-assessment of
comprehension. Memory & Cognition, 10(6), 597-602.
Gorman, M. E., Gorman, M. E., Latta, R. M., &
Cunningham, G. (1984). How disconfirmatory,
confirmatory and combined strategies affect group
problem solving. British Journal of Psychology, 75,65-79.
Karabenick, S. A. (1996). Social influences on
metacognition: Effects of colearner questioning on
comprehension monitoring. Journal of Educational
Psychology, 88, 689-703.
Kiesler, S., Siegel, J., & McGuire, T. W. (1984). Social
psychological
aspects
of
computer-mediated
communication. American Psychologist, 39, 1123-1134.
Kintsch, W. (1998). Comprehension. Cambridge Univ.
Press.
Kruger, A. C. (1992). Peer collaboration: conflict,
cooperation, or both? Social Development, 2&3, 165-182.
Lumpe, A. T. & Staver, J. R. (1995). Peer collaboration and
concept development: Learning about photosynthesis.
Journal of Research in Science Teaching, 32(1), 71-98.
Markman, E. M. (1979). Realizing that you don't
understand: Elementary school children's awareness of
inconsistencies. Child Development, 50, 643-655.
Miyake, N. (1986). Constructive interaction and the iterative
process of understanding. Cognitive Science, 10, 151-177.
Miyake, N. (1997). Making internal process external for
constructive collaboration. In Marsh, J., Nehaniv, C., and
Gorayska, B., eds., Cognitive Technology, 119--123.
IEEE Computer Society.
Okada, T., & Simon, H. A. (1997). Collaborative discovery
in a scientific domain. Cognitive Science, 21(2), 109-146.
Otero, J., & Kintsch, W. (1992). Failures to detect
contradictions in a text: What readers believe versus what
they read. Psychological Science, 3(4), 229-235.
Pressley, M., & Ghatala, E. S. (1990). Self-regulated
learning: Monitoring learning from text. Educational
Psychologist, 25(1), 19-33.
Resnick, L., & Salmon, M., et al. (1993). Reasoning in
conversation. Cognition and Instruction, 11, 347-364.
Schegloff, E. A. (1991). Conversation analysis and socially
shared cognition. In L. B. Resnick, J. M. Levine, & S. D.
Teasley, Perspectives on socially shared cognition.
Washington, D.C.: American Psychological Association.
van Boxtel, C., van der Linden, J., & Kanselaar, G. (2000).
Collaborative learning tasks and the elaboration of
conceptual knowledge. Learning and Instruction, 10, 311330.

