UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Model of Spatio-Temporal Coding of Memory for Multidimensional Stimuli
Permalink
https://escholarship.org/uc/item/9w15d32v
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Johnson, Todd R
Wang, Hongbin
Zhang, Jiajie
et al.
Publication Date
2002-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

        A Model of Spatio-Temporal Coding of Memory for Multidimensional Stimuli
                                         Todd R. Johnson (Todd.R.Johnson@uth.tmc.edu)
                                           Hongbin Wang (Hongbin.Wang@uth.tmc.edu)
                                             Jiajie Zhang (Jiajie.Zhang@uth.tmc.edu)
                                                Yue Wang (Yue.Wang@uth.tmc.edu)
                                           University of Texas Health Science Center at Houston
                                       School of Health Information Sciences, 7000 Fannin Suite 600
                                                         Houston, TX 77030 USA
                                Abstract                                 Nissen (1985) reported an experiment that suggested that
                                                                      visual features of objects (in this case color and shape) are
      This paper presents a model of memory for                       stored separately, but are indexed or bound by their spatial
   multidimensional stimuli. The model captures the                   location. Subjects were presented with four different shapes,
   independence of features in memory, their recovery using
                                                                      each of a different color, and each in one of four positions,
   spatial location and temporal cues, and the role of verbal
   recoding in building integrative feature memories. The model
                                                                      followed by either a location or color cue. When given a
   fits data showing that object features may be retrieved            location or color cue, subjects were told to report the other
   independently when given a location cue, but that correct          two values indexed by that cue (color and shape, and shape
   retrieval of missing features given a feature cue depends on       and location, respectively). Subjects were tested in separate
   the correct retrieval of location. The model also suggests that    location-cue and color-cue conditions with 64 unique trials
   positional codes implicated in many memory models may be           in each condition. Color, shape, location and cue were
   the result of the initial positional encoding of stimuli by        systematically randomized so as to ensure statistical
   perception.                                                        independence among the stimuli and cues.
                                                                         Nissen found that when the cue was a location, correct
                            Introduction                              recall of color and shape were statistically independent;
Although perception appears to integrate multidimensional             however, when the cue was a color, correct recall of shape
stimuli, mounting evidence suggests that object features,             depended on correct recall of location. These results suggest
including color, form, motion, orientation, texture and               that object features are represented independently, with each
location are independently processed by our visual system             feature associated with the object’s spatial location. Thus,
and can even remain independent in memory (e.g.,                      retrieving the shape of an object given its color as a cue
Healthcote, Walker, & Hitch, 1994). This paper reviews the            requires one to first retrieve the location containing an
evidence for the independence and re-integration of features          object with that color, followed by retrieving the shape at
in memory and proposes a model of the spatio-temporal                 that location.
coding of memory for multidimensional stimuli. The model                 Nissen’s results showing independence in the location-cue
is implemented as a modification of the ACT-R cognitive               condition were questioned by Monheit and Johnston (1994)
architecture (Anderson & Lebiere, 1998) and shown to fit
                                                                      who argued that because of the effects of guessing, very
the results of a representative experiment.
                                                                      little deviation from independence was possible. By
                                                                      increasing the number of colors and forms (using letters
            Feature Independence in Memory                            instead of shapes) they reduced the effects of guessing and
Evidence for the independent encoding of features in                  increased the expected deviation from independence. They
memory typically involves conjunction errors in recall or             also increased the number of trials to increase the chance of
recognition tests (Reinitz, Lammers, & Cochran, 1992). In a           detecting a smaller deviation from independence. In a series
recognition test, a conjunction error occurs when a subject           of experiments that were similar to Nissen’s location-cue
reports previously seeing a new stimulus that consists of a           condition, they found consistent evidence for the
conjunction of features from old stimuli. In a recall test, a
                                                                      dependence of color and shape given a location cue. They
conjunction error occurs when subjects recall a stimulus that
                                                                      explained their results by arguing that selective attention to
erroneously conjoins features of previously seen stimuli.
Conjunction errors have been demonstrated for a variety of            an object tightly binds all features, but that in the Nissen
stimuli, including faces (Reinitz et al., 1992; Treisman,             experiment subjects have only enough time to selectively
Sykes, & Galade, 1977), two syllable nonsense words                   attend to a subset of the objects. Features of attended objects
(Reinitz et al., 1992), colored forms (Stefurak & Boynton,            tend to be reported correctly, whereas features of unattended
1986), and colored bars at different orientations (Isenberg,          objects must be guessed. The combination of correct
Nissen, & Marchak, 1990). Presentation times for study                conjunction trials and those involving guessing produced
stimuli in these experiments range from 100 ms to several             the amount of dependence observed in their experiments.
minutes, hence the results show that features are                        Despite Monheit and Johnston’s results, Nissen’s
independently stored in both short- and long-term memory.             experiment still supports a special role for location in
                                                                      binding object features. Monheit and Johnston’s critique of

Nissen’s experiment should apply equally well to the color-     the cues (verbal, temporal, or spatial) that are thought to
cue condition, meaning that it would have been just as          mediate feature integration.
difficult to detect dependence. However, Nissen found              Because verbalization appears to result in an integrated
dependence in both the aggregate data and 8 of the 9            feature memory, it appears that verbal codes act in a
individual subjects. The fact that Nissen’s experiment was      different manner than spatial and temporal codes. Instead of
sufficient to detect dependency in the color-cue condition      acting as a tag for separate perceptual memories, it seems
suggests that location still plays an important role in binding likely that the perceptual features are simply recoded as
object features. However, it is possible that selective         verbal cues. For example, the features “red” and “triangle”
attention may increase the association among object             may be recoded as a verbal chunk “red triangle” that may be
features, making location less important in the recovery of     retrieved as a whole. Likewise, a display containing
feature conjunctions. Indeed, Wolfe and Cave (Wolfe &           multiple stimuli may be recoded as a verbal list, such as
Cave, 1999) suggested that pre-attentive features are loosely   “red triangle,” “blue square” where each item is given a
bound, whereas features of attended objects are more tightly    temporal position code.
bound.                                                             To summarize, features of multidimensional stimuli
   Additional evidence suggests that features may also be       appear to be represented independently in memory, but
bound by temporal cues (Treisman, 1977). In one                 bound by temporal and spatial cues. Integrated feature
experiment a series of several letters, a number, and several   representations are possible, but only if verbalization is
more letters were rapidly presented either at the same          possible.
location or were alternated above and below the fixation
point (Keele, Cohen, Ivry, Liotti, & Yee, 1988). Subjects                                ACT-R 5.0
were told to report the color of the background surrounding     Our model of feature integration in memory is embedded in
the digit. When the items were presented at the same            the ACT-R 5 cognitive architecture (Bothell, 2002), where it
location, more errors came from reporting the color of          adopts ACT-R’s theory of memory and cognition (as
letters at the –1 and +1 temporal positions, items that         described below), but slightly modifies ACT-R’s perceptual
appeared just before and just after the target. However,        system. This section describes ACT-R 5. Modifications
when the items were alternated among two locations, more        needed to support the model are described in the next
errors came from the –2 and +2 temporal positions, items        section.
that occurred at the same spatial location as the target, but      Unlike previous versions of ACT-R, ACT-R 5 (hereafter
that were temporally more distant than the –1 and +1 items.     called ACT-R) consists of several interacting, asynchronous
Based on the results of several similar experiments, the        modules for perception, cognition, memory, and action. The
authors argued that spatial contiguity is the dominant          cognitive module consists of a procedural (production rule)
requirement for binding features and that temporal              long-term memory and a goal buffer that holds the current
contiguity is of use only when features appear in the same      goal and goal-relevant information. The declarative memory
location. However, the dominance of location may be an          module consists of declarative memory chunks and a
artifact of the task. Other researchers have argued that        retrieval buffer that holds the last item retrieved. Each
subjects may use multiple strategies to recover feature         declarative chunk has a unique identifier, a type, and zero or
conjunctions, depending on the available cues at study and      more attributes and values, such as:
test (Heathcote, Walker, & Hitch, 1994).
   There is also evidence that conjunction errors are affected       Obj1 isa shape-map feature triangle location loc1
by the distance and similarity among stimuli. Several
experiments have found that subjects are more likely to         where “Obj1” is the identifier of the memory chunk, “shape-
erroneously conjoin features of adjacent or similar stimuli     map” is the chunk type, “feature” and “location” are
(for a review see Ashby, Prinzmetal, Ivry, & Maddox,            attributes, and “triangle” and “loc1” are their respective
1996).                                                          values.
   Other lines of research have shown that verbalization can       The perceptual-motor module has subsystems for vision,
result in an integrated stimulus memory. In a recognition       hearing, speech production, and motor commands. The
task using colored animal shapes and long presentation          visual module has a buffer that holds the currently attended
times, Stefurak and Boynton (1986) demonstrated that            visual location and the visual stimulus at that location. It
subjects had memory for feature conjunctions unless they        accepts commands from cognition (via production rules) to
were prevented from naming study stimuli by engaging in a       conduct visual search and shift visual attention. The motor
secondary verbal task, in which case they appeared to have      module accepts commands from cognition to do simple
absolutely no memory of feature conjunctions. In addition to    computer-based physical tasks, such as moving the mouse
suppressing verbalization, their experimental task provided     to a certain location, pressing a mouse button, and typing
neither temporal nor location cues, because the study stimuli   commands.
were presented simultaneously, and the test stimulus was           Much of the coordination between perception and action
not presented in its study location. As a result, the           is done by production rules. The condition side of a rule is
suppressed verbalization condition did not provide any of       limited to testing the buffers (including whether a particular

  module is busy), whereas the action side can only initiate a      value of the kth attribute in the retrieval cue and the value in
  limited set of actions that modify buffers or send commands       the corresponding attribute of chunk i. Pk (which defaults to
  to one of the other modules. When a rule fires, its action        1) reflects the weighting given to the similarity of attribute
  side initiates commands to the other modules, such as             k. By default, Mki is 1 if the kth attribute value in the cue is
  shifting visual attention or retrieving a red object from         identical to the corresponding value in chunk i, otherwise it
  memory, after which the rule system is free to fire additional    is –10.
  rules. The other modules in ACT-R handle these actions               To model the random fluctuations of human memory,
  asynchronously, usually resulting (after some delay) in           activations vary with time by adding noise as a logistic
  changes to the buffers. Rules can then detect these changes       function of the parameter s, where s is related to the
  and take appropriate actions. Although more than one rule         variance of the noise by
  can match at a given time, ACT-R only fires one rule in                            p2
  each cycle. A psychologically realistic conflict-resolution                 s2 =       s                          (EQ 2)
  mechanism, based on cost and probability of success,                                3
  determines which of several matching rules will fire.                Finally, the activation threshold t specifies the minimum
     To understand how this works, suppose that ACT-R is            activation value for retrieving a chunk. If all chunks
  given a cued recall task, where it must report a remembered       matching the cue fall below this value, the retrieval request
  shape with a cued color. Furthermore, assume that ACT-R is †      fails. As with chunks, the retrieval threshold varies from
  attending to a fixation point that changes to the cue word        time to time according to the noise parameter s.
  “red.” When the visual system detects the change, it updates         The approximate probability of retrieving a chunk i given
  the visual buffer to indicate that the word “red” is now          k competitors (including the threshold and chunk i) is given
  attended. A production rule that is conditioned on seeing a       by
  word in the visual buffer fires and initiates a memory recall
  request for a red shape, plus notes on the goal that such a                               e Ai / s 2
  request was initiated. As the declarative memory module                      P(i) =                               (EQ 3)
  begins to process this request, the rule system continues to
  check for and fire any matching rules. This allows ACT-R
                                                                                         Â e Ak / s 2
                                                                                           k
  to engage in additional cognitive processing, including
  initiating commands to the perceptual-motor system, while            where An is the mean activation of chunk n.
  the memory system processes the retrieval request. When
  the retrieval request is complete, the retrieval buffer is filled      A Model of Memory for Multidimensional
  with either the newly retrieved chunk or an indication of a                                   Stimuli
  retrieval failure. Two separate rules, both sensitive to the    † The model assumes that attending to a multidimensional
  goal annotation indicating the retrieval request, handle these
                                                                    stimulus results in a set of feature chunks in memory, where
  possibilities. One rule tests for a shape in the retrieval buffer each chunk encodes one feature along with one or more
  and initiates a speech command to say the name of the             temporal and spatial tags. While attention is fixed on the
  shape, the other rule tests for a retrieval failure and initiates stimulus these chunks also appear in the corresponding
  a second retrieval to guess a shape.                              perceptual buffer. If a stimulus is recognized (either
     To understand the model presented below, it is also            identified or classified or both), perception may also deliver
  necessary to understand how ACT-R processes retrieval             a separate chunk encoding the identity (or class) of the
  requests. Retrieval requests specify a chunk type and one or      stimulus along with spatial and temporal tags.
  more attribute-value pairs. The memory module returns the            Suppose that ACT-R attends to a red square at location
  chunk of the specified type with the highest activation           Loc22 on a computer screen at time t1. ACT-R’s visual
  value, where activation of chunk i is determined by               buffer is then filled with chunks encoding red at Loc22 t1,
     Ai = Bi + Â Wj Sji +         ÂP   k Mki      (EQ 1)            square(shape) at Loc22 t1, and square(class) at Loc22 t1.
                   j               k                                These same chunks are also added to ACT-R’s declarative
     Bi is the base level activation of the chunk, reflecting how   memory. This is shown graphically in Figure 1, where
  recently and frequently it has been retrieved. The first          squares represent chunks and arrows indicate chunk
  summation reflects associative priming of the chunk by            attributes. Locations (e.g., loc22) are chunks that correspond
  chunks in the goal buffer, where W j is the available             to unique locations using the computer-screen as the frame
†                                                                   of reference.
  activation and Sji is the strength of association from chunk j
  to chunk i. W j is typically set to 1/n, where n is the total        A spatial tag encodes where the feature occurs and may
  number of chunks in the goal buffer. Sji is initially set to S-   be given in any number of frames of reference (e.g., Wang,
  ln(n), where S is a constant and n is the number of chunks        Johnson, Zhang, 2001). For instance, one spatial tag might
  that have chunk j as an attribute value. This setting produces    give object heading and distance in egocentric (body-
  the classic fan effect (Anderson, 1974).                          centered) coordinates, whereas another spatial tag might
     The second summation in EQ 1 reflects similarity of the        indicate the exocentric heading and bearing of the object
  chunk i to the retrieval cue. Mki is the similarity between the   from another object. Because ACT-R’s perceptual-motor

system is designed to work with two-dimensional computer            The critical production rules for modeling the
displays, the model provides a spatial tag relative to the       experimental results are those for retrieving location given a
frame of the display. Evidence for frame-relative location       color, and those for retrieving color and shape given a
encoding has been found in both monkeys and humans.              location. When given a location cue the model first attempts
Rolls (1999) found that some neurons in the monkey               to retrieve a chunk encoding the color at that location (such
hippocampus responded to where the monkey looked on a            as obj1c in Figure 1), and then attempts to retrieve a chunk
screen independent of the position of the monkey relative to     encoding the shape at the given location (such as obj1s).
the location of the screen. Hock, et al. (1989) showed that      When given a color cue, the model attempts to retrieve a
subjects unintentionally retained frame-relative locations of    color-map chunk containing that color (e.g., obj1c). It then
circles forming patterns in a frame, such that they could        uses the location in this chunk to retrieve a chunk encoding
estimate the frequency with which circles appeared at a          the shape at that location.
particular location within the frame.                               If a rule fails to retrieve a chunk, the model will guess an
   Given enough time, rules may recode the features. For         appropriate value. For example, if the model fails in
instance, a set of rules may verbalize the visual features       retrieving a color-map chunk with color red, it will simply
“red” and “triangle” resulting in a redundant verbal code        guess a location, and then use that location when it attempts
with appropriate temporal tags. Rules may also recode the        to retrieve the shape.
features into an integrated representation, such as a single        Fitting the Nissen data requires estimating the parameters
chunk that binds “red” and “triangle.” Whether or not a          in EQ 1, as well as the activation threshold, and the noise
stimulus is recoded, and the nature of the recoding, is          parameter. The activation threshold and the base level
dependent on the production rules, which in turn depend on       activation B i for all stimulus chunks were set at 0—the
the current goal and the strategy being used to achieve it.      default value. The amount of activation available for
                                                                 associative priming was also set at 0, because chunks in the
                                                                 goal buffer are redundant with attribute values in the
                                                                 retrieval cue. Similarity among matching attribute values,
                                                                 including locations, was set to 1 with mismatching values
                                                                 set to 0. The noise parameter s was the only parameter tuned
                                                                 to fit the data. We used EQ 3 and the results from the Nissen
                                                                 experiment to determine an initial value of s, then iteratively
                                                                 refined it over several model runs to produce the fit reported
                                                                 below (where s = 0.39).
                                                                    A. Location-Cue Condition
   Figure 1. Representation of color, shape and location                             Shape
in the ACT-R model. Temporal cues are not shown.                                                  Correct    Incorrect
                                                                                                  0.485      0.212      0.697
   The model assumes that the similarity (M in EQ 1) of                              Correct
                                                                                                  (0.450)    (0.219)    (0.669)
temporal and spatial tags is inversely proportional to their                Color
                                                                                                  0.213      0.090      0.303
temporal and spatial distance; however, the exact nature of                          Incorrect
                                                                                                  (0.175)    (0.156)    (0.331)
this relationship is left to the model builder. As a result, the                                  0.698      0.302
model will tend to confuse spatially adjacent features.                                           (0.625)    (0.375)
       Applying the Model to the Nissen Task
As a partial test of the model, we applied it to the Nissen         B. Color-Cue Condition
(1985) experiment described earlier. The critical phenomena
in this experiment is that recall of color and shape is                                  Shape
independent given a location cue, but when given a color                                              Correct   Incorrect
cue, recall of shape is dependent on correct recall of                                                0.477     0.221      0.698
                                                                                         Correct
location.                                                                                             (0.494)   (0.234)    (0.728)
                                                                            Location
   The ACT-R model contains production rules for attending                                            0.032     0.271      0.303
                                                                                         Incorrect
to the four colored objects, attending to the cue, retrieving                                         (0.051)   (0.221)    (0.272)
the answers, and pressing keys to record its responses.                                               0.509     0.492
When presented with the 4 objects, the model visually                                                 (0.545)   (0.455)
attends to each object, resulting in automatic encoding of a
                                                                 Figure 2: Results of simulating 50 subjects for each
color-map and shape-map chunk for each object. It then
                                                                 condition. Values in parentheses are the experimental
waits for the cue to appear, at which point it attends to the
                                                                 results from Nissen.
cue and begins the retrieval and response process.

   The results of running the model for 50 subjects in each      Positional codes were used to account for chunk position
of the two conditions are shown in Figure 2 along with the       effects in alphabetic retrieval response times (Klahr, Chase,
Nissen data. As expected, shape and color recall are             & Lovelace, 1983) and positional errors in serial recall
statistically independent in the location-cue condition (c2 =    (Anderson, Bothell, Lebiere, & Matessa, 1998). It is
0.131, p = 0.72), whereas location and shape are dependent       possible that these codes may be the direct result of the
in the color-cue condition (c2 = 901.23, p < 0.01). The          positional (temporal or spatial) encoding of stimuli by
proportions of correct and incorrect recall across both          perceptual processes.
conditions produce a good fit to the Nissen data: R2= 0.95.         One limitation of the model is that it treats all errors as
                                                                 memory retrieval errors. However, the model could be
                          Conclusion                             extended to include probabilities for correctly perceiving
                                                                 features, or a theory of feature perception. However, since
The model described in this paper can account for the basic
phenomena of memory-based feature integration. The               our emphasis is on the representation of features in memory
special role of location was demonstrated by applying the        and their later reintegration, we saw no need to introduce
model to the Nissen task. The use of temporal cues, such as      additional theory.
that reported by Keele, et al. and discussed earlier, is            Monheit and Johnston’s demonstration of dependence of
supported by the model’s use of temporal tags for each           color and shape given a location cue provides a challenge to
feature. If location is given a stronger association to the      the model presented here. To account for the dependence
features than is the temporal tag, this would produce Keele’s    our model must be modified to provide for some strength of
results showing a role of temporal contiguity only for items     association between features of attended objects. In the
that appear in the same spatial location. The tendency to        present model, knowing the color of an object does not
erroneously conjoin spatially adjacent features and features     activate the object’s shape (e.g., the strength of association
of similar stimuli is captured in the model using ACT-R’s        between color and shape, Sji in EQ 1, is 0). In the revised
theory of memory retrieval which tends to confuse similar        model, the color of a previously attended object would
stimuli (see the discussion of EQ 1). This means that            activate its shape, allowing for some dependence among
features of spatially proximal objects will be confused more     features of objects. This would make our model consistent
often than those of spatially distant objects. It also means     with Wolfe and Cave’s view that preattentive features are
that if the model is trying to recall the color of an oval, it   loosely bound, whereas features of objects that have been
would be more likely to confuse its color with that of a         attended are more tightly bound.
circle than with a square.                                          Finally, the model is meant to provide a foundation for a
   The effects of recoding, including verbalization, are         comprehensive theory of spatial cognition embedded in
captured in the model by assuming that the names of              ACT-R. By embedding the model in ACT-R other
individual features or the name or semantic identity of an       researchers can use it in their models, where it may provide
object may be memorized instead of the individual visual         additional constraints and enable more realistic memory
features. If there is enough time for object identification, the representations and behavioral predictions.
subject need only remember an object’s identity and
location during study. At test, the object’s identification
                                                                                     Acknowledgments
provides a cue for reporting essential object features. Such
recoding will produce integrated memories, because the           This research was supported by the Office of Naval
individual features are already well-learned and “bound” to      Research, Cognitive Science Program under Grant No.
the object identity. If a subject remembers seeing a banana,     N00014-01-1-0074.
conceptual knowledge of bananas is sufficient to recall that
it was yellow and crescent shaped—there is no need to                                      References
encode the specific perceptual features in a new memory          Anderson, J. R. (1974). Retrieval of propositional
trace.                                                                information from long-term memory. Cognitive
Such a strategy will not work, however, if the task presents          Psychology, 6, 451-474.
bananas in unnatural colors. In this case, verbal rehearsal      Anderson, J. R., Bothell, D., Lebiere, C., & Matessa, M.
and the resulting verbal memory may be of use. For                    (1998). An integrated theory of list memory. Journal of
instance, given enough time a subject might remember                  Memory and Language, 38, 341-380.
objects in the Nissen task by verbally rehearsing “red           Anderson, J. R., & Lebiere, C. (1998). The Atomic
triangle, blue square…” and so on. Recall of these items              Components of Thought. Hillsdale, NJ: Lawrence
would then be subject to serial recall effects, such as the           Erlbaum.
serial position curve and positional errors. It seems likely     Ashby, F. G., Prinzmetal, W., Ivry, R., & Maddox, W. T.
that such a strategy would result in fewer conjunction errors,        (1996). A formal theory of feature binding in object
which would explain why verbalization results in integrated           perception. Psychological Review, 103(1), 165-192.
feature memory.                                                  Bothell, D. (2002). Act-R 5.0 Beta. Retrieved February 6,
   The model provides a possible explanation for the need to          2002, from http://act.psy.cmu.edu/ACT-R_5.0/
use positional codes (instead of integrated codes or
associative chaining) in cognitive models of memory tasks.

Heathcote, D., Walker, P., & Hitch, G. J. (1994). Feature
    independence and the recovery of feature conjunctions.
    The Journal of General Psychology, 121(3), 253-266.
Hock, H. S., Smith, L. B., Escoffery, L., Bates, A., & Field,
    L. (1989). Evidence for the abstractive encoding of
    superficial position information in visual patterns.
    Memory & Cognition, 17(4), 490-502.
Isenberg, L., Nissen, M. J., & Marchak, L. C. (1990).
    Attentional processing and the independence of color
    and orientation. Journal of Experimental Psychology:
    Human Perception and Performance, 16(4), 869-878.
Keele, S. W., Cohen, A., Ivry, R., Liotti, M., & Yee, P.
    (1988). Tests of a theory of attentional binding. Journal
    of Experimental Psychology-Human Perception and
    Performance, 14(3), 444-452.
Klahr, D., Chase, W. G., & Lovelace, E. A. (1983).
    Structure and process in alphabetic retrieval. Journal of
    Experimental Pschology: Learning, Memory, and
    Cognition, 9(3), 462-477.
Monheit, M. A., & Johnston, J. C. (1994). Spatial attention
    to arrays of multidimensional objects. J Exp Psychol
    Hum Percept Perform, 20(4), 691-708.
Nissen, M. J. (1985). Accessing features and objects: Is
    location special? In M. I. Posner & O. S. M. Marin
    (Eds.), Attention and Performance XI (pp. 205-219).
    Hillsdale, NJ: Lawrence Erlbaum Associates.
Reinitz, M. T., Lammers, W. J., & Cochran, B. P. (1992).
    Memory-conjunction errors: Miscombination of stored
    stimulus features can produce illusions of memory.
    Memory & Cognition, 20(1), 1-11.
Rolls, E. T. (1999). The representation of space in the
    primate hippocampus, and its role in memory. In N.
    Burgess, K. J. Jeffery & J. O'Keefe (Eds.), T h e
    hippocampal and parietal foundations of spatial
    cognition (pp. 320-344). Oxford: Oxford.
Stefurak, D. L., & Boynton, R. M. (1986). Independence of
    memory for categorically different colors and shapes.
    Perception & Psychophysics, 39(3), 164-174.
Treisman, A. (1977). Focussed attention in the perception
    and retrieval of multidimensional stimuli. Perception &
    Psychophysics, 22, 1-11.
Treisman, A., Sykes, M., & Galade, G. (1977). Selective
    attention and stimulus integration. In S. Dornic (Ed.),
    Atention and performance VI (pp. 333-361). Hillsdale,
    NJ: Erlbaum.
Wolfe, J. M., & Cave, K. R. (1999). The psychophysical
    evidence for a binding problem in human vision.
    Neuron, 24(1), 11-17, 111-125.
Wang, H., Johnson, T. R., Zhang, J. (2001). The mind’s
    views of space. In proceedings of the 4th International
    Conference of Cognitive Science.

