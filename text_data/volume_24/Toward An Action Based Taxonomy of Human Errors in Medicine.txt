UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Toward An Action Based Taxonomy of Human Errors in Medicine

Permalink
https://escholarship.org/uc/item/7k09r058

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Authors
Zhang, Jiajie
Johnson, Todd R
Patel, Vimla L
et al.

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Toward An Action Based Taxonomy of Human Errors in Medicine
Jiajie Zhang1, Vimla L. Patel2, Todd R. Johnson1, & Edward H. Shortliffe2
1

School of Health Information Sciences
University of Texas at Houston
7000 Fannin, Houston, TX 77030
{Jiajie.Zhang, Todd.R.Johnson}@uth.tmc.edu

Abstract
One critical step in addressing and resolving the problems associated with human errors is the development of a cognitive
taxonomy of such errors. In the case of errors, such a taxonomy may be developed (1) to categorize all types of errors
along cognitive dimensions, (2) to associate each type of error
with a specific underlying cognitive mechanism, (3) to explain why, and even predict when and where, a specific error
will occur, and (4) to generate intervention strategies for each
type of error. Based on Reason’s (1992) definition of human
errors and Norman’s (1986) cognitive theory of human action,
we have developed a preliminary action-based cognitive
taxonomy of errors that largely satisfies these four criteria in
the domain of medicine. We discuss initial steps for applying
this taxonomy to develop an online medical error reporting
system that not only categorizes errors but also identifies
problems and generates solutions.

1. Introduction
The medical error report from the Institute of Medicine
(Kohn, Corrigan, & Donaldson, 1999) has greatly increased people’s awareness of the frequency, magnitude,
complexity, and seriousness of medical errors. As the 8th
leading cause of death in the US with 98,000 preventable
deaths per year, ahead of motor vehicle accidents, breast
cancer, or AIDS, medical errors need immediate attention
from academic, healthcare, and government institutions
and organizations. To achieve the goal of reducing medical
errors by 50% in five years set by the former Clinton Administration, we need to understand the fundamental
causes of medical errors such that medical errors can be
prevented or greatly reduced systematically at a large scale.
In our opinion, cognitive factors are fundamental in medical errors. This can be seen from the view of the healthcare
system hierarchy and the view of action chains.
Cognitive factors are critical at various levels of the
healthcare system hierarchy of medical errors (Figure 1).
At the lowest core level, it is individuals who trigger errors. Cognitive factors of individuals play the most critical
role here (Reason, 1992). At the next level, errors can occur due to interactions between an individual and technology. This is an issue of human-computer interaction where
cognitive properties of interactions between human and
technology affect and sometimes determine human behavior (Helander, Landauer, & Prabhu, 1997; Zhang, 1997;

2

Department of Medical Informatics
Columbia University
622 West 168th Street, New York, NY 10032
{Patel, Shortliffe}@dmi.columbia.edu

Zhang & Norman, 1994). At the next level, errors can be
attributed to the social dynamics of interactions between
groups of people who interact with complex technology in a
distributed cognitive system. This is the issue of distributed
cognition and computer-supported cooperative work
(Baecker, 1993; Hutchins, 1995a, 1995b; Zhang, 1997). At
the next few levels up, errors can be attributed to factors of
organizational structures (e.g., coordination, communications, standardization of work process), institutional functions (e.g., policies and guidelines), and national regulations. At these higher levels, cognitive factors also play
some roles. Although the properties at the six levels can be
to some extent studied independently, a cognitive foundation for the system is essential for a complete and in-depth
understanding of medical errors.
National Regulations

Institutional functions (policy, guidelines)
Organizat ional structures (coordination,
commun ication, and standardizat ion of work
process, skills, input and output)
Distributed systems: interactions among
indiv iduals and interact ions between
groups of people and techonology
Individual-techonology
interaction
Individuals

Figure 1. The system hierarchy of human errors in medicine
From the view of action chains, the critical roles of
cognitive factors in medical errors are also clear. Figure 2
shows the chain of events and factors that lead to an error in
a system. It is clear that individuals are at the last stage of
the chain, although the individuals may not be the root cause
of the error. If the chain of events can be stopped at the in-

dividual’s stage through cognitive interventions, errors
could be potentially prevented.
Medical errors are human errors in healthcare. By
definition (Kohn et al., 1999; Reason, 1992), human errors
are errors in human actions. Human actions are primarily
cognitive activities. It is not surprising to see that human
errors occur primarily due to inadequate information processing in cognitive tasks (Bogner, 1994; Norman, 1981;
Reason, 1992; Woods, Johannesen, Cook, & Sarter, 1994).
In order to prevent or greatly reduce medical errors, it is
critical to understand the underlying cognitive mechanisms
of medical errors.
SYSTEM
Factor 5

Factor 4

Factor 3

Factor 1

Factor 2

Individual

Error

Factor 6

sound cognitive theory that has explanatory and predictive
power. Since human errors are defined as errors in human
actions, a cognitive theory of human actions can provide the
theoretical foundation for the cognitive taxonomy. In our
opinion, the cognitive theory of human action most appropriate for medical errors is the seven-stage action theory
developed by Norman (Norman, 1986, 1988) and refined by
Zhang and colleagues (Zhang, 1987; Zhang, Patel, & Johnson, in press). The seven-stage action theory is shown in
Figure 3, with a demonstration showing the action of deleting a file on a DOS system. According to this theory, any
action has seven stages of activities: (1) establishing the
goal (e.g., “delete file”); (2) forming the intention (e.g., “use
remove command”); (3) specifying the action specification
(e.g., “remove ../../home/paper/talk_old.ver1”); (4) executing the action (e.g., “typing command text, hit return”); (5)
perceiving the system state (e.g., “prompt symbol :\>, no
feedback”); (6) interpreting the state (e.g., “nothing happened”); and (7) evaluating the system state with respect to
the goals and intentions (e.g., “form sub-goal to find out
current state of the system”).
Delete File

Figure 2. The chain of events leading to an error
Goal

2. Theoretical Background
To understand the cognitive mechanisms underlying medical errors, we first need to develop a cognitive taxonomy
of medical errors that can (1) categorize all types of medical errors along cognitive dimensions, (2) associate each
type of medical error to a specific underlying cognitive
mechanism, (3) explain why and even predict when and
where a specific error will occur, and (4) generate intervention strategies for each type of error.
The purpose of this paper is to develop an action
based cognitive taxonomy that can be potentially expanded
to include all four features listed above.

Use delete
command

Intention

Evaluation

Form subgoal

“del ../../
home/paper/
error-v1.doc”

Action
Specification

Interpretation

Nothing
happened

Typing
command text,
hit return

Execution

Percepton
User Activities

Prompt
symbol (:\>),
no feedback

Physical System
System Activities

2.1. Reason’s definition of human error
Reason’s (Reason, 1992) definition of human error
is the most widely accepted: an error is a failure of achieving the intended outcome in a planned sequence of mental
or physical activities. According to Reason, human errors
are divided into two major categories: (1) slips that result
from the incorrect execution of a correct action sequence
and (2) mistakes that result from the correct execution of
an incorrect action sequence. In comparison with mistakes,
slips have been extensively studied and better understood
(for reviews, see Norman, 1986; Reason, 1992).

2.2. Norman’s action theory
To be comprehensive, descriptive, predictive, and
generalizable, a cognitive taxonomy should be based on a

Figure 3. Norman’s seven-stage theory of action.

3. The Cognitive Taxonomy
Reason developed one taxonomy of human errors (Reason,
1992); however, it was not based on a systematic theory of
human action; it was primarily for slips, not for mistakes;
and it has not been systematically applied to medical settings. Norman’s (Norman, 1986) seven-stage action theory
was developed for the study of human-computer interaction
and the design of user interfaces--it has not been applied to
the study of errors.

Mistakes

Slips
Execution Slips

Goal
text
Intention

Action
Specification

Execution

Evaluation Slips

Goal

Evaluation

Intention

Interpretation

Action
Specification

Percepton

Execution

User Activities

Evaluation

Interruptions

Interpretation

Percepton
User Activities

Physical System

Physical System

System Activities

System Activities

Figure 4. Slips can occur at all stages, whereas mistakes can only occur at the first three stages.
The cognitive taxonomy we develop here is an
application and extension of Norman’s action theory
to the categorization of medical errors. It is an actionbased cognitive taxonomy. This taxonomy covers all
types of human errors, because a human error is an
error in an action and any action has to go through the
seven stages. According to our taxonomy, errors can
occur at any of the seven stages of action and between
any two adjacent stages: due to incorrect translation
from goals to intentions, incorrect action specifications
from intentions, incorrect execution of actions, misperception of system state, misinterpretation of data
perceived, and misevaluation of interpreted information with regard to the goal of the task. Unlike other
taxonomies, our taxonomy specifies the places where
mistakes and slips may occur (Figure 4). A slip is the
incorrect execution of a correct action sequence. Slips
can occur at all seven stages of action and between
stages. Mistakes, however, can only occur at the first
three stages of action because a mistake is the correct
execution of an incorrect action sequence and only the
first three stages can contribute to the formation of an
incorrect action sequence.

3.1. Slips
Under our cognitive taxonomy, slips can be divided into execution slips and evaluation slips (see
Figure 4 and Table 1).
Execution slips are associated with the execution of an action. They occur at stages of Goal, Intention, Action Specification, and Execution. For the slips
at each stage, there are corresponding cognitive
mechanisms. A correct goal could be distorted due to
its strongly shared schema with another irrelevant
goal. A correct intention could be deactivated due to

memory decay or swapped by another irrelevant intention due to similarity of schemas. A correct action
specification could be distorted due to many factors
such as attention shift, situational stimulation, etc. The
execution of an action sequence could misfire due to
memory and attention problems or various environmental factors. Table 4 shows a list of possible cognitive mechanisms for slips at each of the stages.
Similarly, evaluation slips are associated with
the evaluation of the outcomes of an action. They occur
at the stages of Perception, Interpretation, and Evaluation. There are also corresponding cognitive mechanisms associated with the slips at each of these stages.
The outcome of an action might be impossible to perceive, hard to perceive, or perceived in an incorrect
way. The interpretation stage may also induce errors
due to prior knowledge, lack of context, or as a direct
result of misperception. The evaluation stage may fail
due to insufficient feedback, delayed feedback, information overload, memory failure, and other factors.
Table 1 shows not just the types of slips under
the cognitive taxonomy but also examples of slips in
each category and potentials solutions that can prevent
the slips from happening.

3.2. Mistakes
Under our cognitive taxonomy, mistakes are
categorized into goal mistakes, intention mistakes, and
action specification mistakes. These correspond to the
first three stages in the action cycle where mistake can
occur. Goal mistakes and intention mistakes are mostly
knowledge-based mistakes, such as faulty conceptual
knowledge, incomplete knowledge, biases and faulty
heuristics, incorrect selection of knowledge, information overload, etc. Action specification mistakes are

mostly rule-based mistakes, such as misapplication of
good rules, encoding deficiencies in rules, action defi-

ciencies in rules, dissociation between knowledge and
rules, etc.

Table 1. An Action Based Cognitive Taxonomy: Slips
Stage in Action
Cycle
Goal slips

Intention Slips
Execution
Slips
Action Specification Slips

Execution slips

Perception slips

Evaluation
Slips
Interpretation
slips

Evaluation slips

Examples

Cognitive mechanisms

Potential solutions

A doctor was called out
of the room to answer an
urgent call and afterwards he went to the
room of a different patient who was next in the
queue. (Loss of activation)
“I went into my bedroom
intending to fetch a book.
I took off my rings,
looked in the mirror and
came out again—without
the book.” (Loss of activation)
IL-11 (Oprelvekin , or
Interleukin-eleven) was
misinterpreted as IL-2
(Aldesleukin, or Interleukin-two). 11 was read
as the Roman numeral
two. (Associative activation)
“I meant to turn off the
antibiotics IV only, but
turned off the infusion
pump completely.” (Double capture)

•Loss of activation
•Cross talk (concurrent)
•Cross talk (sequential)
•Altered goal
•Delayed activation
•Overflow of goal stacks

•Provide memory aids
•Reduce multitasking
•Reduce interruptions
•Reduce goal stacks
•Train users

•Loss of activation
•Cross talk (concurrent)
•Cross talk (sequential)
•Reversal of schema
•Activation of incorrect
schema

•Provide memory aids
•Reduce multitasking
•Situated actions
•Reduce interruptions

•Associative activation
•Failure of retrieval
•Sequence mutation
•Situated activation
•Description
•Cross talks

•Automation
•Decision support
•Situated actions
•Train users
•Direct action

•Capture
•Double capture
•Perceptual confusion
•Deviation of motor skills
•Misfiring
•Omission
•Lack of perception
•Misperception
•Mis-anticipation

•Automation
•Visualization
•Display design
•Reduce interruption
•Memory aids

•Misinterpretation
•Default schema
•Confirmation bias
•Information overload
•Loss of memory

•Display design
•Decision support
•User training
•Memory aids
•Situation awareness

•Lost goal
•Insufficient information
•Evaluating different goal
•Information overload
•Lack of feedback

•Memory aids
•Display design
•Action tracking
•Information reduction

A patient died of liquid
aspiration Because the
water trap connected
with a tube had no
mechanism to protect
against reflux to patient’s
trachea, and there was no
feedback in the system.
(Lack of perception)
A yellow flashing light on
a medical device was
interpreated as noncritical when it really
meant critical. (Misinterpretation)
A nurse repeated radiation therapy to a patient
three times in a row, due
to poor feedback. The
patient died three months
later. (Lack of feedback)

•Direct perception
•Immediate feedback

Table 2. An Action Based Cognitive Taxonomy: Mistakes
Stage in Action
Cycle
Goal mistakes

Knowledgebased Mistakes

Intention mistakes

Action Specification mistakes
Rule-based Mistakes

Examples

Cognitive
Mechanisms

Potential solutions

Stick with a diagnosis
that was generated
through a large investment of time and effort
even if there was evidence indicating other
possibilities. (Biases)
A physician treating a
patient with oxygen set
the flow control knob
between 1 and 2 liters
per minute, not realizing that the scale numbers represented discrete, rather than continuous, settings. (Incorrect knowledge)
Strange burn scars
appeared in postoperative patients in a
hospital. The problem
was caused by electric
discharge of the device
that was not grounded.
The device has a blinking red to signal for the
problem, but the device
operators did not know
the meaning of the signal. (Incomplete
knowledge)

•Misdiagnosis
•Faulty conceptual
knowledge
•Incomplete knowledge
•Biases
•Faulty heuristics

•Training
•Education
•Representational Aid
•Decision support

•Incorrect selection of
knowledge
•Misapplication of
knowledge
•Information overload
•Incorrect knowledge

•Training
•Education
•Decision support
•Information reduction
•Display design
•Representational Aid

•Misapplication of good
rules
•Encoding deficiencies
in rules
•Dissociation between
knowledge and rules
•Action deficiencies in
rules
•Incomplete knowledge

•Decision support
•Automation
•User training
•Representational Aid

Table 2 shows not only the types of mistakes
under the cognitive taxonomy but also examples of
mistakes in each category and potentials solutions that
can prevent the mistakes from happening. In comparison with slips, mistakes are more complex and less
understood.
Most studies about mistakes in the past were
byproducts of studies of reasoning biases and heuristics in decision-making tasks (Hogarth & Einhorn,
1992; Tversky & Kahneman, 1974). Recently there
have been a growing number of studies that explicitly
examine various types of mistakes in medicine (Patel
& Kaufman, 2000; Patel, Lloyd, & Melanson, 2000;
Patel & Ramoni, 1997). We expect to see more studies
of this kind and we will expand our taxonomy to accommodate new data and theories.

4. Discussion and Conclusion
One critical step towards reducing medical errors in
particular and human errors in general is a cognitive

taxonomy of errors that can (1) categorize all types of
medical errors along cognitive dimensions, (2) associate each type of medical errors to a specific underlying
cognitive mechanism, (3) explain why and even predict
when and where a specific error will occur, and (4)
generate intervention strategies for each type of error.
Based on Reason’s (Reason, 1992) definition of human
errors and Norman’s (Norman, 1986) cognitive theory
of human action, we developed a preliminary actionbased cognitive taxonomy of medical errors that to
some extent satisfy these four criteria. Our taxonomy
can categorize all types of errors (slips and mistakes)
according the stages of the action cycle. We have identified a set of cognitive mechanisms (though not exhaustive) that underlie each type of slip or mistake. Our
taxonomy can also explain why a specific error occurs,
although we have not developed the taxonomy in
enough detail to make predications on when and where
an error will occur. Finally, at a high and conceptual

level, we have generated a set of possible solutions
addressing each type of errors.
One important practical implication of the cognitive taxonomy of medical errors is that it can provide
systematic, principled methods for the design of medical error reporting systems. Current medical error reporting systems are mostly based on free text in an
unstructured format. Medical error data collected in
this way are rarely useful for the detection of patterns,
discovery of underlying factors, and generation of
solutions, because user entered free text do not contain
the right types of information needed for interventions
and is difficult to analyze in a systematic way. Medical
error reporting systems should not be merely record
keeping systems. They should be systems for the identification of problems and generation of solutions. We
are currently developing an online medical error reporting system that is based on the cognitive taxonomy we have been developing. In this system, questions and inquiries are generated to encode cognitively
relevant information; the categorization of errors is
along relevant cognitive dimensions; and it is designed
to generate immediate recommendations on possible
intervention strategies.

5. References
Baecker, R. M. (Ed.). (1993). Readings in groupware
and computer-supported cooperative work:
Assisting human-human collaboration. San
Francisco: Morgan Kaufmann.
Bogner, M. S. (Ed.). (1994). Human error in medicine.
Hillsdale, NJ: Erlbaum.
Helander, M. G., Landauer, T. K., & Prabhu, P. V.
(Eds.). (1997). Handbook of human-computer
interaction (2nd ed.). New York: NorthHolland.
Hogarth, R. M., & Einhorn, H. J. (1992). Order effects
in belief updating: The belief-adjustment
model. Cognitive Psychology, 24, 1-55.
Hutchins, E. (1995a). Cognition in the wild. Cambridge, MA: MIT Press.
Hutchins, E. (1995b). How a cockpit remembers its
speed. Cognitive Science, 19, 265-288.
Kohn, L. T., Corrigan, J. M., & Donaldson, M. S.
(1999). To err is human. Washington, DC:
National Academy Press.
Norman, D. A. (1981). Categorization of Action Slips.
Psychological Review, 88, 1-15.
Norman, D. A. (1986). Cognitive engineering. In S.
W. Draper (Ed.), User centered system design. Hillsdale, NJ: Lawrence Erlbaum Associates.
Norman, D. A. (1988). The psychology of everyday
things. New York: Basic Books.
Patel, V. L., & Kaufman, D. R. (2000). Conceptual
and procedural errors in medical decision-

making. Proceedings of the Cognitive Society
Conference.
Patel, V. L., Lloyd, S. J., & Melanson, P. (2000). Decision making in emergency care: The use of
data and heuristics: Centre for Medical Education, McGill University.
Patel, V. L., & Ramoni, M. (1997). Cognitive models of
directional inference in expert medical reasoning. In R. Hoffman (Ed.), Expertise in context.
Menlo Park, CA: AAAI Press.
Reason, J. (1992). Human error. Cambridge, UK:
Cambridge University Press.
Tversky, A., & Kahneman, D. (1974). Judgment under
uncertainty: Heuristics and biases. Science,
185, 1124-1131.
Woods, D. D., Johannesen, L., Cook, R. I., & Sarter, N.
(1994). Behind human error: Cognitive systems, computers and hidsight. Dayton, OH:
Crew Systems Ergonomic Information and
Analysis Center, WPAFB.
Zhang, J. (1987). The effect of the timing of interruption
on human action (Unpublished Report). San
Diego: University of California, Department of
Psychology.
Zhang, J. (1997). The nature of external representations
in problem solving. Cognitive Science, 21(2),
179-217.
Zhang, J., & Norman, D. A. (1994). Representations in
distributed cognitive tasks. Cognitive Science,
18(1), 87-122.
Zhang, J., Patel, V. L., & Johnson, T. R. (in press).
Medical error: Is the solution medical or cognitive? Journal of American Medical Informatics Association.

