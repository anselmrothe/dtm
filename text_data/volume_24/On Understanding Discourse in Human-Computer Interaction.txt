UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
On Understanding Discourse in Human-Computer Interaction
Permalink
https://escholarship.org/uc/item/3w7352tv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Maglio, Paul P
Matlock, Teenie
Gould, Sydney J
et al.
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

             On Understanding Discourse in Human-Computer Interaction
                                    Paul P. Maglio (pmaglio@almaden.ibm.com)
                                  Teenie Matlock (tmatlock@psych.stanford.edu)
                                   Sydney J. Gould (sydneygould@hotmail.com)
                                      Dave Koons (dkoons@almaden.ibm.com)
                            Christopher S. Campbell (ccampbel@almaden.ibm.com)
                                                IBM Almaden Research Center
                                                    650 Harry Rd, B2-NWE
                                                   San Jose, CA 95120 USA
                          Abstract                               that are specialized for individual jobs and embedded in
                                                                 the everyday environment (Norman, 1998). If point-
  We report on an experiment that investigated how people        and-click graphical user interfaces (GUI) have enabled
  naturally communicate with computational devices using         wide use of PCs, what will be the paradigm for
  speech and gaze. Our approach follows from the idea
                                                                 interaction with pervasive computing systems? As
  that human-human          conversation     involves    the
  establishment of common ground, the use of gaze
                                                                 natural human-computer interfaces and pervasive
  direction to indicate attention and turn-taking, and           systems converge, what form will technology take?
  awareness of other’s knowledge and abilities. Our goal            To address these questions, we explored the design of
  is to determine whether it is easier to communicate with       a pervasive system with speech input in an office
  several devices, each with its own specialized functions       setting. We were concerned specifically with
  and abilities, or with a single system that can control        conversational cues that people rely on when
  several devices. If conversations with devices resemble        interacting with the system. Some evidence suggests
  conversations with people, we would expect interaction         that people can attribute human-like or social qualities
  with several devices to require extra effort—both in
                                                                 to computers with which they interact; for instance,
  building common ground and in specifying turn-taking.
  To test this, we observed participants in an office mock-
                                                                 networked computers described as physically close to
  up where information was accessed on displays through          the user are judged as more helpful than those described
  speech input only. Between groups, we manipulated              as physically distant (Reeves & Nass, 1996). Although
  what participants were told: in one case, that they were       people do not treat computers as true conversational
  speaking to a single controlling system, and in the other,     partners (Yankelovich, Levow & Marx, 1995), these
  that they were speaking to a set of individually               sorts of results suggest that people apply natural ways
  controlled devices. Based on language use and gaze             of interacting to situations in which the conversational
  patterns, our results suggest that the office environment      partner is a computer or other computational device.
  was more efficient and easier to use when participants
                                                                    Our main concern is whether it is easier for people to
  believed they were talking to a single system than when
  they believed they were talking to a several devices.
                                                                 talk to a single system or to a collection of devices. In a
                                                                 previous study of a speech-controlled office, we found
                       Introduction                              behaviors and attitudes depended on whether users
                                                                 received simple command recognition feedback (a
One approach to human computer interaction is to                 blinking light) from the various devices that performed
improve the usability, user experience, and intuitiveness        tasks or from a single, central location (Maglio,
of technology by creating natural user interfaces. Here,         Matlock, Campbell, Zhai & Smith, 2000; Matlock,
natural refers to interactions that are like those people        Campbell, Maglio, Zhai & Smith, 2001). In that study,
have with one another. Such is the goal of multimodal            users were faced with simple office tasks (such as
or attentive systems (Maglio, Matlock, Campbell, Zhai            looking up information, dictating a letter, and printing a
& Smith, 2000; Oviatt & Cohen, 2000), and speech and             letter) to be completed using speech input only. To do
conversational        interfaces      (Maybury,         1997).   this, users were given a set of physical displays
Understanding cues in conversation, language use,                dedicated to various functions (such as address book,
perceptual abilities, and expectations is vital to building      calendar, and so on). Between groups of participants,
systems that can be used with little training.                   we manipulated whether feedback was associated with
  Advances in technology are resulting in smaller,               individual displays or with the room as whole. This
cheaper, and more pervasive computational systems                feedback manipulation was meant to suggest either
than ever before. But are we ready for this surge of             central control or distributed control. Behaviorally, we
electronics and information? No longer confined to               found that regardless of condition, participants rarely
desktop or laptop machines, computational systems will           addressed individual devices verbally, but they looked
soon extend across numerous “information appliances”             at the devices that they expected to display the results

before they spoke (Maglio et al., 2000).               In a  those who interact with several devices. In human-
questionnaire aimed at uncovering attitudes toward the       human communication, the number of words used by
office, we found that participants in the central            participants in a conversation decreases over time,
condition were more likely to rate their interactions        suggesting that the more common ground, the easier the
with the office as being similar to interactions with        communication (Clark & Wilkes-Gibbs, 1986). Thus,
people than were those in the distributed condition          if people treat the system in the central condition in
(Matlock et al., 2001). The results show that although       some ways like a single other person and they treat each
people judge the central controller to be more like a        of the devices in the distributed condition in some ways
person, they interact with devices individually in both      like several other people, participants may feel that they
cases, looking at devices when they speak. One design        need to establish common ground with the single
implication is that the feedback provided by blinking        system only once but that they need to establish
lights enables natural user-computer interactions. But       common ground with each of the devices individually,
the question of whether it is easier to speak to a single    and we can measure this by counting words used—
system or to multiple devices remains.                       specifically, words that refer to things mentioned
   Let us first consider how people use language to          previously. Moreover, if establishing common ground
communicate. There are many theories. A popular              is easier in the central condition than it is in the
view is that discourse is a shared activity whereby two      distributed condition, many predictions follow; for
or more individuals cooperate to build and achieve           instance, participants should make fewer mistakes in
understanding (Clark, 1996). This joint activity view        the central, and participants should be more engaged
implies that the meaning of an utterance is determined       with the central system, as shown by gaze.
not only by what the speaker wishes to say to the               An alternative to the joint activity view is that
listener, but also by context. This includes speaker’s       discourse is simply a process of transferring
beliefs about the situation, (e.g., what speaker assumes     information without reference to context or to those
the listener knows about the context), common ground         involved. On this view, meaning is derived from what
(e.g., shared history), and listener’s ability to accurately is spoken without concern for who the speaker is or
interpret the speaker's message (e.g., listener is paying    what the situation is. If this is the case, maintaining
attention).    For example, imagine that it’s early          separate functions in separate devices might make it
afternoon and you have just come back from a favorite        easier for users to keep the various functions straight, as
lunch spot. A friend looks at you and asks, “Was it          each device naturally conveys its own range of
crowded?”, where it refers to the restaurant. It is no       available options (e.g., email device for email). Thus,
problem to use the indexical it because the friend can       on this view, common ground is not constructed over
assume that you know which restaurant is being asked         time but is established once by what the device can do.
about. The question can even be reduced further by           If this is the case, talking to a single system ought to be
simply asking, “Crowded?”, and you are still likely to       more difficult than talking to multiple devices, as the
understand what is meant. This type of coordinated           single system does not make the options apparent.
interaction is so common and natural that people do not
think twice about it.                                                                Experiment
   Given context’s role in understanding, the joint          The goal of the experiment was to investigate whether
activity view implies that the process of conversation       and how language use and gaze would differ between
also involves verbal (e.g., prosodic) and non-verbal         participants interacting with a central system and those
(e.g., gaze) cues to convey meaning. Feedback is             interacting with a distributed system. Our study was
critical for supporting user interactions with               done in a mock office in which participants completed
computational systems (Perez-Quinones & Sibert,              office tasks under the illusion that they were controlling
1996); for instance, appropriate acknowledgments (e.g.,      what was displayed on four specialized screens. This
“uh-huh”) based on prosodic cues in users’ speech can        sort of mock-up or Wizard-of-Oz method is often used
improve user evaluation of the system (Tsukahara &           to investigate user expectations and performance with
Ward, 2001). Likewise, gaze provides important cues          speech-based systems (Dählback, Jönsson &
to attention and turn-taking in group interactions           Ahrenberg, 1993; Gould, Conti & Hovanyecz, 1983).
(Kendon, 1967; Argyle & Cook, 1976).                         The Wizard-of-Oz method relies on human controllers
                                                             behind the scenes to create the appearance of an
Hypotheses                                                   intelligent system, mocking up displays and interaction
Following the joint activity view of conversation, our       results to collect performance data.
main hypothesis is that given complex tasks and their           In one condition, the experimenter instructed
dependencies on one another, participants who interact       participants to speak to a system that controlled all the
with a single system will be more likely to establish        devices, and in the other, to speak to the individual
context and then assume the system shares it than will       devices. Unknown to participants, two other

                                                                 Table 1. Tasks completed by participants.
experimenters in a separate room watched and listened,
controlling what was displayed from a palette of many         Update Address Book
possible screens. The rules of the game were for the               open new address form
experimenters to simply behave intelligently: if what              dictate name, address, city, state, zip, phone, email
the participant was trying to do was clear from speech        Register for XYZ Conference
and other context, the system was to respond                       find XYZ information screen
appropriately. The experimenters controlling the system            obtain Bob's personal information
                                                                   compose new email to XYZ
were blind to which participants were given which                        dictate name, email, phone, credit card
instructions.                                                      add XYZ to calendar
                                                              Find and Reserve Flights
Method                                                             find airline reservation screen
Between two groups of participants, we manipulated                 interact with reservation "system"
only the instructions.         In the central condition,                 dictate cities, dates, non-stop, under $400
                                                                         reserve/book itinerary
participants were repeatedly told that they were to talk                       obtain Bob's personal information
to a single computer system that displayed information                         dictate name, email, credit card
on four displays.         In the distributed condition,                  add flights to calendar
participants were repeatedly told that they were to talk      Reschedule Meetings
to four separate information devices. Tasks were                   obtain Kathy's personal information
identical in both cases: sending and receiving email,              compose new email message to Kathy
                                                                   read Kathy's response
updating address information, scheduling appointments,             modify Kathy's meeting
arranging a flight, and registering for a conference.
                                                              Notify Bob of Status
Information was displayed the same way in both cases.
                                                                   compose new email to Bob
                                                                   read Bob's response
Participants Eighteen participants (13 females and 5               adjust calendar , cancel meeting
males) were recruited from summer student interns and              modify airline reservation
office staff at our research lab, and paid for their time.               find reservation for Bob
                                                                         specify vegetarian meal
Materials and Apparatus Our office mock-up
contained four 15-inch liquid crystal displays (LCDs)      requests. In addition, a few tasks were given in email
arranged on an L-shaped desk. Embedded in the bezel        messages sent to the temp during the course of the
of two of the LCDs were pinhole video cameras, which       session. Table 1 shows the set of tasks and subtasks
enabled eye gaze and body position to be easily            each participant was expected to carry out.
recorded. A third camera mounted on the wall above
the room recorded an overview of the scene. Each           Procedure Participants read the instruction sheet and
display was dedicated to a different function or task:     were told their input was valuable because it would
email, calendar, travel planning, and address book.        help ensure that the “BlueSpeak system” or the
   There were two sets of instructions, one for each       “BlueSpeak devices” would be tested on a wide range
condition. Instructions for the central condition told     of voices. Participants were then taken into the “Office
participants to talk to the “BlueSpeak system”, a single   of the Future”, and asked to test out their voices by
computer system that controlled four displays.             reading a short passage to the system in the central
Instructions for the distributed condition told            condition or to the devices in the distributed condition.
participants to talk to a set of “BlueSpeak devices”, four Participants were then told to carefully read the memo
separate devices that ran autonomously. In both cases,     left by Bob Wilson. In all cases, participants were
the script was written as a memo from a fictitious         instructed to speak naturally and to do the best they
manager named Bob Wilson. The memo told the                could. They were told that there was no right or wrong
participant that he or she was to be his temporary         way to speak to the system or the devices, and that if
assistant (or temp) for the day. It asked the temp to      they were not understood, to try speaking differently.
register Bob for a conference, add a new address to his    After issuing a command, the system did not give any
address book, get a flight from San Jose to New York,      feedback other than displaying the result of the request.
reschedule a meeting, and request a vegetarian meal on
the flight. The script purposely did not specify how to    Results
issue commands. It included statements such as “You        All participants successfully completed the session.
will need to arrange my travel to New York and from        Few problems arose and on average it took participants
San Jose”, “I need to register for the XYZ Conference,”    13 min 43 sec to complete all tasks. Data analysis
and “Make sure my calendar is updated”. Such               targeted language-use and eye-gaze during the session.
language made for many possible ways of making             Only reliable differences are reported, except as noted.

                                                                                   100
Language Qualitatively, participants spoke to the                                   90
system in a variety of ways. For instance, requests to                              80                                            distributed
                                                              Percent Utterances
send email included, “Let’s send an email to Kathy                                  70                                            central
                                                                                    60
Webster,” “I need to send an email now – I would like
                                                                                    50
to send it to k webster at ibm dot com,” “Email k                                   40
webster at ibm dot com,” and “Write an email to Kathy                               30
                                                                                    20
Webster”. Requests to get Bob a vegetarian meal on
                                                                                    10
included, “Request vegetarian meal,” “Vegetarian                                     0
meal,” “Let’s make this a vegetarian meal”, and                                          imperative   elliptical   first person   question
“Special request, vegetarian meal for this flight”.                                                      Utterance Type
  More precisely, transcribed utterances in both
conditions were examined for certain characteristics of                            Figure 1. Percentage of the time participants
language use. First, requests were placed into four                                used different types of requests.
categories: imperative, elliptical, first person, and
question (cf. Maglio et al., 2000). Imperative requests     participant assumes the system is following the
are commands, such as, “update the address book”,           discourse, and that once established, the context (the
“view addresses”, “register for conference”. Elliptical     conference event) need not be repeated. We calculated
requests contain no a verb, such as, “XYZ conference”,      the proportion of statements that assumed context
“new entry”, and “Kathy Webster”. First person              available in a previous statement across all participants
requests include either a singular or plural first person   in each condition (see Figure 2). Overall, participants
subject, such as “let’s read this email”, and “I want a     in the central condition assumed that the system would
vegetarian meal”. Question requests include queries         understand the context more often than participants in
such as, “can I check my email?” and “are there any         the distributed condition (central, 7.0%; distributed,
other flights available?”. Figure 1 shows the break         1.4%; 2 = 14.50, p < 0.01).
down of requests for both conditions. There were more         Finally, we charted how language use changed during
imperatives (central, 70.4%; distributed, 80.3%; 2 =        the course of a session. Each participant’s discourse
9.75, p < 0.01) and more ellipticals (central: 11.8%;       was cut in half, based on the task breakdown in Table 1.
distributed: 16.9%; 2 = 4.16, p < 0.05) in the              The number of times each participant relied on
distributed condition, and there were more first persons    established context (as defined previously) was tallied
(central, 13.3%; distributed, 2.8%; 2 = 26.9, p < 0.01)     separately for the first half and for the second half (see
and questions (central, 4.5%; distributed, 0.0%; 2 =        Figure 2).       No difference between central and
16.4, p < 0.01) in the central condition.                   distributed conditions was found for the first half
  Second, we examined how participants verbally             (central, 5.5%; distributed, 2.2%; 2 = 2.45, NS), but a
addressed individual devices. Specifically, we counted      reliable difference was found for the second half
the number of times a device was specifically addressed     (central, 8.5%; distributed, 0.6%; 2 = 13.59, p < 0.01).
by name, such as, “Address book, what is Kathy
Webster’s address?”. The proportion of requests             Behavior and Gaze Behaviors—including actions
containing an addressee was greater in the distributed      participants took and where they looked—were
condition than in the central condition (central, 1.7%;     analyzed in terms of the task breakdown in Table 1.
distributed, 14%; 2 = 40.87, p < 0.01).                     Specifically, all overt physical actions taken by
  Third, we examined the way participants recovered         participants were transcribed from the videotapes and
from errors. We were interested in how requests were        time-stamped. From these data, we extracted number of
reformulated after an initial attempt had failed. To take   tasks, time taken per task, number of gazes or looks to
one example, the most problematic part of the script        task-relevant and to task-irrelevant locations, and
was ordering a vegetarian meal for the flight (last task    number and kind of the errors made. For all results,
in Table 1). Overall, in the central condition, the meal    scores falling outside two standard deviations from the
request was restated 9 times. In the distributed            mean were removed and replaced by mean scores; these
condition, it was restated 13 times. Three participants     outliers constituted 8% of the scores.
in the distributed condition were unable to complete          Mean completion time was 13 min 17 sec for the
this task at all and eventually gave up.                    central condition and 14 min 10 sec for the distributed
  Fourth, we looked at the way participants relied on       condition. To calculate the time taken for each
previously established context. For example, when           individual action for each participant, the time taken for
interacting with the system, a participant might say        each task (e.g., “Update Address Book,” “Register for
“register Bob Wilson for XYZ conference” and then a         Conference,” etc.) was divided by the number of
short time later say, “add event to calendar”, referring    actions (e.g., “open address book”, “find Bob’s
implicitly to the conference.         In this case, the     personal information”, etc.) actually taken to complete

                         100                                    Central
                                                                                                        100
                          90                                                                             90
                                                                Distributed                                                                                     Central
                                                                               Percent of Gaze Shifts
                          80                                                                             80
    Percent Statements
                                                                                                                                                                Distributed
                          70                                                                             70
                          60                                                                             60
                          50                                                                             50
                          40                                                                             40
                          30                                                                             30
                          20                                                                             20
                                                                                                         10
                          10
                                                                                                          0
                           0
                                                                                                                 Looked before speaking    Looked away while speaking
                               First Half     Second Half       Total
                                                                                                                      (a)    Eyes on Relevant Displays    (b)
                                            Relied on Context
                                                                                                              Figure 3. Percentage of time participants
         Figure 2. Percentage of time participants                                                            (a) shifted gaze to display before speaking,
         relied on established context.                                                                       and (b) away from display while speaking.
the task. A difference was found between central and                          1.      dominant use of the imperative in both cases,
distributed conditions on the mean time to take an                                   and more use of first-person and question forms
action in the address book task (central, 21.1;                                      in the central case
distributed, 27.1; t(16) = 3.18, p < 0.01), and a marginal                       2. less verbal addressing in the central case
difference was found between the mean times to take an                           3. less reformulation—and more successful
action in the flight reservation task (central, 54.0;                                reformulation—of requests in the central case
distributed, 73.4; t(16) = 1.71, p < 0.11).
                                                                                 4. more reliance on context in the central case,
  Unnecessary actions and omitted actions constituted                                which increased over time
errors. Number of errors was calculated for each                                 5. slightly faster overall completion time for the
participant. Percentage of errors was determined by                                  central case, and significantly faster for certain
dividing the total number of errors by the total number                              tasks (updating address book, reserving a flight)
of actions taken for each participant. Overall, there
                                                                                 6. less of the time, gaze shifted to the appropriate
were 20% errors in the central condition and 16% in the
                                                                                     display before speaking in the central case
distributed condition. This difference was not reliable.
                                                                                 7. more of the time gaze shifted away from the
   Finally, we examined where people looked and when                                 appropriate display in the central case
they altered their gaze. In particular, we counted the
                                                                                 Returning to our hypotheses, we can conclude that
total number of times a participant looked at a specific
                                                                              participants in the central condition relied more heavily
display when making a request for which that display
                                                                              on context they had established previously, shown by
would be expected to show a result (see also Maglio et
                                                                              the number of times they implicitly referred to objects
al., 2000). For instance, we counted times when a
                                                                              and information. This is what we expected given the
participant looked at the address book and then said
                                                                              joint activity view of discourse (Clark, 1996). It
“Michael Smith’s address,” but not times when the
                                                                              follows that participants in the central condition
participant would say “Michael Smith’s address” before
                                                                              behaved more like they were speaking to a single entity
looking at the address book. The percentage of the time
                                                                              than those in the distributed condition. The way
each participant looked at the appropriate display when
                                                                              participants addressed displays and shifted gaze also
taking action was calculated by dividing the number of
                                                                              supports this conclusion. Participants in the central
appropriate looks by the number of actions. As shown
                                                                              condition addressed individual devices less frequently,
in Figure 3a, a difference was found between the two
                                                                              suggesting that they were less likely to be speaking
conditions (central, 80%; distributed, 96%; t(16) = 2.79,
                                                                              directly to devices. Moreover, participants in the
p < 0.05). In addition, we counted the number of times
                                                                              central condition shifted gaze to individual devices
a participant looked away from a display they were
                                                                              when starting a task less frequently, also suggesting that
using to complete an action (again, normalizing with
                                                                              they were less likely to be speaking directly to
respect to total number of actions). As shown in Figure
                                                                              individual devices. Finally, participants in the central
3b, a difference was found between the two conditions
                                                                              condition more frequently shifted gaze from device to
(central, 53%; distributed 10%; t(16) = 2.39, p < 0.05).
                                                                              device while engaged in a task, suggesting that they
Discussion                                                                    were unconcerned with keeping eye contact with a
In summary, participants interacting with the single                          specific device. Taken together, these results suggest
system had an easier time than those interacting with                         that participants in the central condition behaved more
multiple devices. Specifically, the data show                                 like they were engaged with a single entity than those in
                                                                              the distributed condition.

                      Conclusion                            Fifth, giving devices obvious ways of collecting
                                                            information from the room, such as a visible camera,
The present study was intended to investigate how
                                                            allows users to understand what kind of common
people speak to computational systems. Controlling
                                                            ground the system is likely to have. For instance, the
whether users believed they were speaking to a single
                                                            camera may make users more likely to use gestures
centralized system or to several separate devices, we
                                                            (e.g. pointing) to reference information.          Finally,
found a centralized system was more efficient and
                                                            providing users with a single point of control need not
easier to use than separate devices in several ways. Not
                                                            have consequences for implementation; it might simply
surprisingly, the main difference was that users of the
                                                            be enough to tell users to speak with a single device.
central system treated the system as a single entity
whereas users of the separate devices treated the
devices as independent entities. By relying on a single                             References
controller, users in the centralized condition were more    Argyle, M. & Cook, M. (1976). Gaze and mutual gaze.
likely to reuse conversational context than users in the       London: Cambridge University Press.
distributed condition.        Moreover, because they        Clark, H. H. (1996). Using language. Cambridge
interacted with a single entity, users did not need to         England: Cambridge University Press.
divide attention across several conversational partners.    Clark, H. H. & Wilkes-Gibbs, D. (1986). Referring as a
   What are some implications for Clark’s joint activity       collaborative process. Cognition, 22, 1-39.
view of conversation? It may initially seem misguided       Dahlbäck, N., Jönsson, A., & Ahrenberg, L. (1993).
                                                               Wizard of Oz studies – why and how, in Proceedings
to apply this theory to human-computer interaction, for
                                                               of the Workshop on Intelligent User Interfaces ’93.
it was intended to deal with human-human interaction
                                                            Gould, J. D., Conti, J., & Hovanyecz, T. (1983).
only. And afterall, computers and other devices are not        Composing letters with a simulated listening
true conversational partners because they are controlled       typewriter. Communications of the ACM, 26(4), 295-
by their users and cannot really engage in conversation.       308.
Nonetheless, Clark’s theory was in fact predictive of       Kendon, A. (1967). Some functions of gaze direction in
behavior in this study, demonstrating that in this             social interaction. Acta Psychologica, 32, 1-25.
human-computer interaction context, many of the same        Maglio, P. P., Matlock, T., Campbell, C. S., Zhai, S., &
assumptions about human-human interaction apply.               Smith, B. A. (2000). Gaze and speech in attentive
   What are some implications for the design of future         user interfaces, in Proceedings of the International
computing environments? First, for the sorts of tasks          Conference on Multimodal Interfaces 2000.
considered here, it is clear that a single controller is to Matlock, T. Campbell, C. S., Maglio, P. P., Zhai, S., &
be preferred over multiple devices. Thus, when                 Smith, B. A. (2001) Designing feedback for an
designing a system that requires a user to coordinate          attentive office, in Proceedings of Interact 2001.
information and activities among a set of distinct          Maybury, M. T. (1997). Conversational multimedia
displays or information sources, it would be appropriate       interaction. In Y. Wilks, (Ed.) Machine
to provide the user a single point of contact with the         Conversations. Kluwer Academic, Norwell, MA.
overall system, as this would allow the user to establish   Norman, D. A. (1998). The invisible computer.
an ongoing relationship with a single entity. Second,          Cambridge, MA: MIT Press.
because maintaining context seems critical for              Oviatt, S. & Cohen, P. (2000). Multimodal interfaces
efficiency (and possibly for ease of use as well),             that process what comes naturally. Communications
providing users with appropriate state information             of the ACM, 43(3), 45-53.
                                                            Perez-Quinones, M. A. & Sibert, J. L. (1996). A
would likely encourage them to rely on established
                                                               collaborative model feedback in human-computer
context. Third, because users tended to fix their gaze
                                                               interaction, in Proceedings of the Conference on
on individual devices in the multiple device condition,        Human Factors in Computing Systems, CHI ‘96.
gaze cues (in addition to language cues) might be useful    Reeves, B. & Nass, C. (1996). The media equation.
in helping the system determine level of engagement            Cambridge, England: Cambridge University Press.
and to disambiguate referential statements, but cannot      Tsukahara, W., & Ward, N. (2001). Responding to
be relied on completely in the single controller case.         subtle, fleeting changes in the user’s internal state, in
Fourth, if assumptions about common ground can be              Proceedings of the Conference on Human Factors in
manipulated by instructions, then the physical design of       Computing Systems, CHI 2001, 77-84.
a system should be carefully considered. For example,       Yankelovich, N., Levow, G. A., & Marx, M. (1995).
putting several screens in the environment with the            Designing SpeechActs: Issues in speech user
same physical size and characteristics might suggest           interfaces, in Proceedings of the Conference on
multiple devices, whereas one large display and a few          Human Factors in Computing Systems, CHI ’95.
smaller displays might appear to be a single system
with one point of contact and several output monitors.

