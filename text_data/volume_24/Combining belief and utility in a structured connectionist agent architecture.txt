UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Combining belief and utility in a structured connectionist agent architecture
Permalink
https://escholarship.org/uc/item/33d995rj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Wendelken, Carter
Shastri, Lokendra
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                      University of California

Combining Belief and Utility in a Structured Connectionist Agent Architecture
                                             Carter Wendelken and Lokendra Shastri
                                             International Computer Science Institute
                                                   1947 Center Street, Suite 600
                                                        Berkeley, CA 94704
                                                 carterw,shastri @icsi.berkeley.edu
                            Abstract                                                                                         type hierarchy
                                                                                                                  +e    +v      ?v    ?e      Person
   The SHRUTI model demonstrates how a system of sim-
   ple, neuron-like elements can encode a large body of re-
   lational causal knowledge and provide the basis for rapid                  fact                   type          +e     +v     ?v    ?e      Man
   inference. Here we show how a representation of util-
   ity can be integrated with the existing representation of               buy(Person,-,-)          entity              +          ?      John
   belief, such that the resulting architecture can be used to
   reason about values and goals and thereby contribute to
   decision-making and planning.                                                                                        focal cluster
                                                                                      + - ?                                   enabler
                                                                        buy(buyer,thing,seller)                               collector
                        Introduction                                                                                          role node
To understand how the brain creates the mind, one could                                                    to +e:Money
                                                                                  + ?                                                rule mediator
work mainly from the top down, characterizing mental
                                                                                                             to ?e:Object
processes, or from the bottom up, trying to understand
the capabilities of neurons and simple circuits. In devel-
                                                                                       + - ?
oping the SHRUTI model we have pursued both these ap-                                                                             rule
proaches simultaneously in order to understand how net-                    pay(payer,payee,payment)
works of neurons can perform complex cognitive tasks.
In past work, we have demonstrated how such networks
can make predictive and explanatory inferences with re-            Figure 1: Diagram showing core elements of the
spect to a large body of causal knowledge. In this paper,          SHRUTI model, including relational focal clusters, a
we show how the SHRUTI architecture can be extended                fact, a rule, and a simple type hierarchy.
to represent and reason not only about beliefs but also
about utilities, values and goals. The resulting model
uses a single causal structure to seek explanations, make             A focal cluster is a collection of nodes with varying
predictions, and identify expected utilities of world states       functionality all subserving a common representation. A
and actions.                                                       relational focal cluster consists of a positive (+) and a
                                                                   negative (-) collector node, an enabler (?) node, and role
               The SHRUTI architecture                             nodes. The activity of the positive (negative) collector
First we present the basic elements of the SHRUTI archi-           node reflects the amount of evidence collected in sup-
tecture. The model is described in considerably more               port of belief (disbelief) in the given relation. Activity
detail in [Shastri, 1999, Shastri and Ajjanagadde, 1993,           of the enabler (?) node reflects the strength with which
Shastri and Wendelken, 2000]. SHRUTI is a neurally                 information about the relation is being sought. A link
plausible (connectionist) model that demonstrates how              from collector to enabler ensures that the system auto-
a network of neuron-like elements could encode a large             matically seeks explanation for what it believes. Role
body of structured knowledge and perform a variety of              bindings are represented by synchronous firing of rela-
inferences within a few hundred milliseconds. SHRUTI               tional role nodes with nodes in a connectionist type hi-
suggests that the encoding of relational information               erarchy. A relational cluster with active role bindings
(frames, predicates, etc.) is mediated by neural circuits          represents a relational instance. Rules are encoded with
composed of focal clusters and that the dynamic rep-               links that enable the propagation of rhythmic activity
resentation and communication of relational instances              from one relational focal cluster to the next. Specif-
involves the transient propagation of rhythmic activity            ically, a rule is formed by linking the antecedent col-
across these clusters. A role-entity binding is represented        lector to the consequent collector, the consequent en-
in this rhythmic activity by the synchronous firing of ap-         abler to the antecedent enabler, and matching role nodes
propriate cells.                                                   in both directions, through an intervening focal cluster

termed the rule mediator. Type restriction and instanti-                        Representing utility in SHRUTI
ation of unbound variables are handled via connections              SHRUTI’s            representation          of          utility
between the rule mediator structure and the type hierar-            [von Neumann and Morgenstern, 1947]             is     analo-
chy. Long-term facts are encoded in SHRUTI as tempo-                gous to its representation of belief. This consists
ral pattern matching circuits. Episodic facts (E-facts) are         primarily of a set of utility nodes associated with each
tuned to particular relational instances and represent spe-         relational focal cluster, reward facts denoting reward and
cific knowledge or memories, while taxon facts (T-facts)            punishment, value facts denoting learned utility values,
are typically responsive to a range of relational activa-           probabilistically weighted utility-carrying connections
tions and represent more general statistical knowledge              between relations, and various modulatory mechanisms
about the world.                                                    that affect utility flow differently in different situations.
                                                                    Thus belief and utility in SHRUTI are tightly integrated,
Probabilistic reasoning                                             sharing much of the same structure, and are not separate
                                                                    modules in any conventional sense.
Previous work has shown that the inferential behavior
of SHRUTI does not, in most cases, stray far from a                 Utility nodes
probabilistic ideal [Wendelken and Shastri, 2000]. With             Recall that the representation of beliefs in SHRUTI is built
appropriate assignment of link weights, a simple                    around relational focal clusters, which contain several
rule structure can be shown to compute probabili-                   different types of nodes including positive and negative
ties correctly in both the forward and backward di-                 collectors, an enabler, and role nodes. Alongside these
rection. A set of evidence combination functions al-                nodes representing belief, there are additional nodes rep-
lows for flexible combination of evidence from multi-               resenting associated utility. Thus there is a utility node
ple sources, while maintaining a relatively simple con-             tied to each of the two collectors, with activation range
nectionist structure in which each antecedent commu-                [-1,1]. These nodes are denoted by $+ and $-; positive
nicates with the consequent via a single weighted link              activity of $+ ($-) indicates that positive utility value is
[Shastri and Wendelken, 1999]. Explaining away occurs               associated with the truth (falsity) of the relation, while
via inhibitory interconnections between antecedents, so             negative activation value of $+ ($-) indicates that nega-
false patterns of circular reasoning are not introduced.            tive utility is associated with the truth (falsity) of the re-
   Inference in SHRUTI is essentially an anytime algo-              lation. Links from each utility node to the enabler node
rithm. Unlike in a belief net, responses to a query are             ensure that whenever something is marked as having util-
generated almost immediately, based on the prior infor-             ity, it is automatically investigated by the system.
mation stored for the queried relation. As inference is al-            Activation of a relational utility node can indicate that
lowed to progress, early estimates are repeatedly refined           reward is currently being experienced, or that it is ex-
as more and more evidence is brought in from further up             pected. In either case, it reflects not only reward that
or down the causal chain. In a neural system, the depth to          is directly associated with its relation (as, for example,
which this search for evidence occurs would be limited,             satisfying a sweet tooth is associated with eating cake),
such that only evidence within a certain distance (along            but also sources of reward that are more distantly related
any casual chain) would be considered. Presumably, this             (such as potential weight gain). In this respect, the util-
depth could be modulated by attention or other factors.             ity node is comparable to the value funcion of traditional
Importantly, this is a model which scales up naturally to           reinforcement learning; however, utility node activity is
large domains without performance loss (with reference              transient and cannot by itself represent any permanent
to a parallel network of nodes and links).                          learned value associated with a relation instance (how
                                                                    this information is maintained will be described shortly).
                                                                    Instead, activity at a relational utility node reflects the
                                          P(A)
                                 prior                              combination of more permanent representations of value
                                                                    with the transient factors that make up current context.
                                 +        A         ?
                                                                    Reward facts
                                          1 / P(A)
       P(B | only A)                                         P(B|A) Some relations have reward facts (R-facts) tied to them,
                                            P(B)                    designating certain relational instances as goals. Re-
             collector link                           enabler link
                                                                    ward facts represent the source of reward and punish-
                                  +         B       ?               ment in the system. Activation of a positive reward fact
                            inverse prior
                                                                    indicates the attainment (real or imagined) of some re-
                                           1 / P(B)                 ward, while activation of a negative reward fact indicates
                                                                    the suffering (real or imagined) of some punishment.
Figure 2: An illustration of the link weights for a simple          Like episodic facts in the belief system, reward facts
rule (roles not shown). If B is believed true (+:B active           are temporal pattern matching circuits that respond only
                                                                    when the specified set of role-fillers are active. In this
with value 1.0) then activity at +:A will equal P(A—B)
                                                                    case, activation of a relational collector along with syn-
                                                                    chronous activation of role nodes and appropriate type

node role fillers leads to activation of an associated fact    few connected predicates, and not on the entire system
node, which in turn leads to activation of that relation’s     state. Because of the similarity in the Bellman equation
appropriate utility node. Many different reward facts can      and SHRUTI’s value-updating algorithm, the latter has
be linked to a single relation; for example, a relation like   been termed Causal Heuristic Dynamic Programming
eat x might have associated with it positive reward facts      (CHDP) [Thompson and Cohen, 1999]. Like taxon facts
such as eat Cake as well as negative reward (punish-           in the belief system, value facts hold a statistical sum-
ment) facts such as eat Dirt .                                 mary of past activity. They too are associative, meaning
                                                               that matching of relational activity to the fact is stronger
                                                               with more role matches, but is not necessarily blocked
        +     -      ?      eat $+ $-                          by a single role mismatch; this helps with generalization
                                                               of value to multiple related instances.
                                                                  A typical relation has many value facts associated with
                                                       +e:Cake it, some very specific and some quite general. In this
               eat( Cake )         0.8                         way, particularly important or salient items are explic-
                                                               itly encoded, whereas novel or less important items can
                                                       +e:Dirt fall back on more general representations. For the hy-
                                       - 0.5                   pothetical agent for which eating cake is a paramount
                       eat( Dirt )
                                                               goal, f ind Cake should be a highly-rewarding value
                                                               fact. Eating other things may still be beneficial, so the
     Figure 3: Two reward facts for the relation eat(x)        more general f ind Food may also appear as a weaker
                                                               value fact; finding anything is more often good than bad,
   Research with rats and brain-stimulus reward suggests       so even the most general value fact f ind T hing might
that both idiosyncratic and common currency represen-          appear in the agent’s internal representation. When the
tations of utility exist in the brain [Shizgal, 1998]. The     agent with these value facts happens upon a dollar bill,
representation of utility as activation values of relational   it will immediately perceive this as a positive situation
utility nodes is a common currency representation which        according to the value of the f ind T hing value fact. If
allows the activity of one node to be directly compared to     finding money turns out to be significantly more reward-
the activity of another in order to guide decision-making.     ing than finding that average-value random thing, then
This is vital in order to allow successful decision mak-       this should be learned and explicitly represented as a new
ing that takes into account disparate sources of reward        value fact.
and punishment. More domain-specific representations
of utility must also exist, since the relative weighting of    Communication of utilities
utilities from different sources can vary. The utility of      Links connect utility nodes of different relations in the
eating, for example, is greatly influenced by degree of        same way that they connect belief nodes. These links
hunger, while the utility of play is not. Reward facts rep-    run parallel to the belief system connections, but in the
resent the connection between the common currency and          consequent to antecedent (backward) direction. Figure 4
the more domain-specific representations of utility. In        provides a simple illustration of these connections: for
order to model the latter, we allow that the weights on        the rule A B         C, there are utility connections from
reward facts might vary depending on some internal state       the utility nodes of C, through the rule mediator, back to
of the agent.                                                  those of A and B. Weights on these connections are sim-
                                                               ilar to the weights on the collector-collector links. Their
Value facts                                                    purpose is to introduce probability into the calculations
While relational utility nodes represent value estimates       of value, such that the value estimate at some antecedent
in the current context, and reward facts represent basic       relation is based on both the value of its consequent (ac-
goals, the task of storing learned value estimates rests       tivity at its utility node) and the probability that it will
with the value facts, or V-facts. Value facts are simi-        be reached (weight on the connecting link). For the rule
lar in form to reward facts, but instead of directly rep-      A      C, where the utility node of C ($:C) has a value
resenting reward, they represent predicted future reward.      of α, the utility node of A ($:A) should obtain the value
For both value facts and reward facts, utility values are      α PCA .
stored as link weights (specifically, as the weight on the        This structure has the effect that assertion of a par-
link leading from the fact node to the associated rela-        ticular goal, via activation of a utility node, leads in
tional utility node). The value fact associated with a re-     the simplest case to assertion of its potential causes as
lation plays a similar role to the value function in tra-      subgoals, via spreading activation backwards along the
ditional reinforcement learning, and the update function       causal chain. Belief in some relation, represented as ac-
for a value fact, depending as it does on local reward         tivation of a collector node, leads to internal reward or
and maximization (or some other combination) of util-          punishment (activation of a reward fact) or recognition
ity values of possible consequents, closely resembles the      that such reward or punishment is likely (activation of a
Bellman equation [Bellman, 1957]. Note, however, that          value fact) if there is an intact causal chain leading from
value updates in SHRUTI depend only on activity of a           that relation to some goal relation.

         +  $     A    ?
                                 WB
                                             +       $          B         ?   simplicity of the resulting connectionist structure is im-
                                                                              portant, since it lends plausibility to the notion that such
                                           WB
                              WA                                              a mechanism could be learned in the brain. Results for
               WA                                                             three combination functions, and, or, and avg, are shown
                    +    $  ?
                                                                              below. The connectionist structure that computes these
                                                        utility-carrying link
                                                                              functions is shown in figure 4.
                                                        modulatory link
                                       Collector and enabler links omitted.
                                                                                    ECF    $:A/$:C
                  +   $    C     ?                                                  and    WA ∏ni 1 1        1 bi WBi
                                                                                    or     WA ∏ni 1 1       biWBi
Figure 4: A diagram showing structure of utility connec-                            avg    WA
tions for a two-antecedent rule.
                                                                                  Action focal clusters are given special treatment
                                                                              within this framework. Since the agent has control over
Utility modulation                                                            whether or not an action is performed, activity of an ac-
                                                                              tion collector does not modulate the utility values flow-
The model of utility propagation described so far is per-                     ing to any sibling antecedents. Also, while activity of an
fectly adequate for simple cause-effect relationships or                      action’s utility node indicates that the action is beneficial
chains of these. However, with multiple-antecedent or                         or harmful, activity of its enabler simply indicates that
multiple-consequent rules, or with multiple rules involv-                     the action is potentially relevant.
ing a common relation, additional mechanisms must be
introduced. Consider first a rule with two antecedents,                       Distribution and recombination
such as f ind x edible x            eat x . The utility of find-              Just like beliefs, utilities from different sources must be
ing something, which is derived from the utility of eat-                      combined. In general, the same approach is used here
ing something, depends directly on whether or not that                        as with calculation of belief - a range of simple evidence
thing is edible. Thus, there should be an interaction be-                     combination functions are available and can be inserted
tween the two antecedents such that if edible x is false,                     into the connectionist structure as appropriate. Because
then the propagation of utility from eat x to f ind x is                      many rewards are generally better than one, combina-
at least partially blocked. The reverse holds true as well                    tion functions selected should generally have the prop-
- utility of a thing being edible depends not only on the                     erty that a combined utility value is greater than any of
utility of eating it, but also on whether or not it has been                  the individual utilities; summation and or are two likely
found.                                                                        candidates. However, using such a combination function
   The interaction described here is appropriate for the                      leads to a difficult problem when we allow multiple paths
and-combination, but different interactions should occur                      to exist between two relations. Consider the scenario, il-
when different relations hold between the antecedents                         lustrated in figure 5 where exploration can lead to finding
and the consequent. For example, when antecedents are                         fruit or finding game, and that either of these consequents
combined with an or function, then belief in the truth of                     can lead to the goal relation of being able to eat. Util-
one should tend to discount the propagation of utility to                     ity associated with eating is propagated in full to both
the others. In this case, when one cause is established,                       f indFruit and f indGame (assuming an or-combination
then redundant causes are no longer particularly useful.                      and that neither is currently true), and from each it is
For the avg (weighted average) function, each antecedent                      further propagated back to explore. Now if explore has
contributes independently to the total, and so belief in the                  the sort of combination function described above, it can
truth of one antecedent should have no impact on the per-                     obtain a local utility value greater than that originating
ceived utility of another.                                                    at the goal eat. This is clearly an unacceptable situa-
   In general, the utility value at an antecedent relation                    tion, and it comes from the fact that locally there is no
should reflect the value of any associated consequents                        information to distinguish between utility arriving from
times the extent to which truth of the antecedent affects                     different sources (which should be added together) and
truth of the consequent. For a rule with antecedents                          utility values that originate from the same source (which
A and B1 through Bn and consequent C, this might be                           should not).
stated as “What difference does A make, in the context                            One solution to this problem might be to disallow mul-
B1 ... Bn , for the attainment of C”, or in terms of prob-                    tiple paths between relations. Indeed, this is the solu-
abilities, P C A B1 b1              Bn b n               P C A B1             tion adopted for belief nets to solve essentially the same
b1       Bn b n .                                                             problem. However, connections between relations are
   If the above expression is expanded for each different                     assumed to be learned from experience based only on
combination function, an interesting result is obtained,                      local information; it is difficult to imagine any plausible
namely, that it is possible to compute it exactly for each                    mechanism by which learning of multiple paths could be
different combination function using only the existing                        inhibited when these provide the best fit for experience.
weight on the utility link along with a single additional                     Another solution would be to reduce the amount of util-
weight from each associated antecedent. This relative                         ity distributed along each path according to the number

                             +    explore    $
     + find-Fruit   $        +  find-Game     $        + find-Shelter $
                  +    eat    $                        +      rest    $
                       + 1/2                                 + 1/3
                                     +    eat & rest $
                                           + 2/3
Figure 5: A proposed solution to the problem of utility
combination.
                                                                        Figure 6: A captured moment from the simulation of
of such paths; in this case that would mean that only half              the caveman scenario. Activity of -:inSeason blocks the
of utility at the eat relation is propagated to f indFruit              propagation of utility to $:gather, resulting in a higher
and f indGame. But this clearly leads to an underestima-                valuation of the hunt action.
tion of utility along each. Finally, we might abandon the
use of summation and similar combination functions for
utility and instead use something like max. This solves                 such that hunt Game has associated with it a utility of
the problem at hand but also makes it impossible to pro-                0.4. In order for gathering fruit to be perceived as use-
ductively combine multiple sources of utility. The “com-                ful, the agent must have some knowledge that the fruit is
mom currency” representation of utility becomes some-                   in season. Suppose first that the query inSeason Fruit
what modified; utilities can be directly compared within                is answered in the negative, either as a result of im-
this framework but can no longer be directly combined.                  mediate knowledge of the agent or of further reasoning
Instead, reward combinations must be explicitly repre-                  along paths not illustrated here. Then, according to the
sented in order to be used. This is illustrated in figure 5,            equation for distribution of utility values around an and-
where the basic goals eat and rest are supplemented by a                combination given above, and by means of a simple in-
combination goal eat&rest.                                              hibitory mechanism, the flow of utility to the gather rela-
                                                                        tion is blocked. Simlarly, If inSeason is uncertain, utility
                      Simulation example                                propagation to gather will be partially blocked. In ei-
                                                                        ther case, the hunt action, with a higher utility, will be
The operation of the network is illustrated here. The                   favored. This is the situation illustrated in figure 6 and
screen capture from the Shruti-Agent Simulator in Fig-                  indicated by a numeral one in figure 7. If on the other
ure 6 shows a simple network representing the caveman’s                 hand the agent is reasonably certain that fruit is in sea-
dilemma of whether to hunt or gather. Successful hunt-                  son, then sufficient utility will propagate from the f ind
ing yields the greatest reward (represented by the reward               relation and gather will obtain a higher utility value than
fact eat Game ). Gathering, on the other hand, is more                  hunt, marking it as the preferred action.
reliable, but only productive during the right season. We
                                                                           Figure 8 illustrates a larger domain wherein the possi-
examine the propagation of beliefs and utilities around
                                                                        bility of moving to a location where food can be found
this simple network in detail. First, suppose that the
                                                                        is included, as is the possiblility of being injured while
caveman agent is hungry, and hence reward facts related
                                                                        hunting. When the assumption is made that skilled is
to eating are fully active. Eating game or eating fruit are
                                                                        true, (i.e. caveman is a skilled hunter), utility and belief
the current active goals of the system. Activity from the
                                                                        propagate in this network such that moveTo RiverBank
reward facts flows to multiple banks of the eat relation
                                                                        (i.e. go to where the game is) is marked as a useful ac-
and from there back to kill Game and f ind Fruit . The
                                                                        tion.
agent has realized that either killing game or finding fruit
would be useful eventualities. Alongside the propagation
of utility, a querying belief state is also being transmitted                                  Conclusion
from relation to relation; this is represented in the activity          We have demonstrated that SHRUTI, a neurally plausible
of the enabler nodes. Since neither eventuality is thought              model of knowledge representation and reasoning, can
to be true of the current world state, there is no compet-              be enhanced to deal effectively with utilities, values, and
itive modulation of utility values; thus, kill Game has                 goals. The resulting connectionist machinery is suffi-
the full 0.8 value from the eat Game reward fact while                  cient to guide an agent through a wide range of decision-
 f ind Fruit has the full 0.6 from eat Fruit .                          making tasks, such as those illustrated in the previous
    Utility value propagates further back to the hunt re-               examples. However, there is a class of decision prob-
lation, this time modified by the uncertainty of hunting,               lems for which the model presented here is inadequate.

                                                          In order to deal effectively with complex decision tasks,
      RF: eat(Game)                                       a measure of higher-level control must be introduced.
      RF: eat(Fruit)                                      Extensions to the model described here that enable
                  $
                                                          it to perform complex decision-making and planning
       eat(1)     ?
                                                          are described elsewhere [Wendelken and Shastri, 2002,
                  x                                       Garagnani et al., 2002].
                  $
      eat(2)      ?
                                                                                References
                  x                                       [Bellman, 1957] Bellman, R. (1957). Dynamic Pro-
        kill
                  +                                          gramming. Princeton University Press.
                   $
                                                          [Garagnani et al., 2002] Garagnani, M., Shastri, L., and
                    +
                                                             Wendelken, C. (2002). A connnectionist model of
                   $
      hunt                                                   planning via back-chaining search. In Proc. 24th
                   ?
                   x
                                                             Conf. of the Cognitive Science Society.
       find
                   +                                      [Shastri, 1999] Shastri, L. (1999). Advances in SHRUTI
                   $                                         - a neurally motivated model of relational knowl-
                   +                                         edge representation and rapid inference using tempo-
   inSeason        $                                         ral synchrony. Applied Intelligence, 11.
                   ?
                   +                                      [Shastri and Ajjanagadde, 1993] Shastri, L. and Ajjana-
                   $
                                                             gadde, V. (1993). From simple associations to sys-
     gather
                   ?
                                                             tematic reasoning. Behavioral and Brain Sciences,
                   x                                         16(3):417–494.
         Game:?v
                                                          [Shastri and Wendelken, 1999] Shastri, L. and Wen-
         Fruit:?v
                                                             delken, C. (1999). Soft computing in SHRUTI. In
                           1             2    3
                                                             Proc. 3rd Int. Symposium on Soft Computing, pages
                                                             741–747, Genova, Italy.
Figure 7: A stylized trace of node activations during ex- [Shastri and Wendelken, 2000] Shastri, L. and Wen-
ecution of the caveman scenario.                             delken, C. (2000). Seeking coherent explanations -
                                                             a fusion of structured connectionism, temporal syn-
                                                             chrony, and evidential reasoning. In Proc. 22nd Conf.
                                                             of the Cognitive Science Society, Philadelphia.
                                                          [Shizgal, 1998] Shizgal, P. (1998). Foundations of hedo-
                                                             nic psychology: Scientific perspectives on enjoyment
                                                             and suffering, On the neural computation of utility:
                                                             implications from studies of brain stimulation reward.
                                                          [Thompson and Cohen, 1999] Thompson,            B. and
                                                             Cohen, M. (1999).         Naturalistic decision mak-
                                                             ing and models of computational intelligence.
                                                             In A. Jagota et al. editors, Connectionist Sym-
                                                             bol Processing:       Dead 0r Alive?, volume 2
                                                             of Neural Computing Surveys, pages 1-40.
                                                             http://www.icsi.berkeley.edu/ jagota/NCS.
                                                          [von Neumann and Morgenstern, 1947] von Neumann,
                                                             J. and Morgenstern, O. (1947). Theory of Games and
                                                             Economic Behavior. Princeton University Press.
                                                          [Wendelken and Shastri, 2000] Wendelken, C. and
                                                             Shastri, L. (2000).       Probabilistic inference and
                                                             learning in a connectionist causal network. In Proc.
                                                             2nd Int. Symposium on Neural Computation.
                                                          [Wendelken and Shastri, 2002] Wendelken, C. and
                                                             Shastri, L. (2002). Decision-making and control
Figure 8: An expanded version of the caveman scenario.       in a structured connectionist agent architecture. In
                                                             submitted.

