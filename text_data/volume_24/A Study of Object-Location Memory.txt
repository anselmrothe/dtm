UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Study of Object-Location Memory
Permalink
https://escholarship.org/uc/item/62s8d5p0
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Wang, Hongbin
Johnson, Todd R
Zhang, Jiajie
et al.
Publication Date
2002-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                        A Study of Object-Location Memory
                                         Hongbin Wang (Hongbin.Wang@uth.tmc.edu)
                                      Todd R. Johnson (Todd.R.Johnson@uth.tmc.edu)
                                             Jiajie Zhang (Jiajie.Zhang@uth.tmc.edu)
                                               Yue Wang (Yue.Wang@uth.tmc.edu)
                   School of Health Information Sciences, University of Texas Health Science Center at Houston
                                            7000 Fannin, Suite 600, Houston, TX 77030 USA
                             Abstract                                 a computational model of the object-location memory and
                                                                      its implications on modeling human spatial cognition in
   This paper aims to study the representational nature of human      general.
   object-location memory. Two experiments are reported,
   including both performance data and eye movement data. The
   results show that multiple allocentric frames of reference are
                                                                                    The Experimental Paradigm
   used to encode spatial relationships among objects and late        We adopted an experimental paradigm developed by Milner
   computation in object-location memory retrieval in object-         and colleagues in the 1990s, which we call the Milner
   cued conditions is often inevitable. The implications on           paradigm (e.g., Johnsrude, Owen, Crane, Milner, & Evans,
   developing a general model of human spatial cognition are          1999; Milner, Johnsrude, & Crane, 1997; Owen, Milner,
   discussed.
                                                                      Petrides, & Evans, 1996). Though their focus was on
                                                                      neuroimaging studies of the brain foundations of object-
                         Introduction                                 location memory, the Milner paradigm offers an elegant
One important aspect of human spatial memory has to do                experimental design that allows a systematic evaluation of
with remembering the location of objects relative to each             multiple schema for representing spatial relationships. In
other. For example, you might recall that the book you read           addition, the availability of neuroimaging data provides
last night is on your office desk between your computer and           invaluable constraints on both understanding behavioral
the desk lamp. This type of memory for spatial relationships          results and developing computational models (e.g., Wang,
is an essential component of a more general type of memory            Johnson, & Zhang, 2001).
for spatial layout and is obviously critical for many spatial            There are two phases in the Milner paradigm. In the
tasks including locating and navigation (see Tversky, 2000,           encoding phase (Figure 1A), eight drawings (objects) are
for a review).                                                        individually presented on a computer screen to subjects,
   It is not clear, however, how spatial relationships among          with each drawing accompanied by two landmarks (solid
objects are encoded in memory. While it seems apparent                squares). Subjects are asked to remember the locations of
that allocentric frames of reference (i.e., locations defined         drawings, relative to the landmarks. In the retrieval phase,
relative to external objects) rather than egocentric frames of        subjects are presented some cues plus two identical
reference (i.e., locations relative to the observer self) are         drawings. One of the two identical drawings (target) is
often used to describe these spatial relationships, the               presented in its original location, and the other one (noise) is
representational and computational nature of this description         presented in a different location (or more accurately, it
is controversial (see Hunt & Waller, 1999; Klatzky, 1998).            occupies the original location of another object). Subjects
For example, are object-based spatial relationships encoded           are required to perform a forced-choice recognition of the
and stored directly (early computation)? Or do they have to           target, relative to the cues. Milner and colleagues originally
be inferred much later at the retrieval stage (late                   used four retrieval conditions:
computation)? What factors determine which                               1. In the fixed-landmark condition (Figure 1C), the two
representational scheme is used?                                              landmarks were presented as cues, along with the
   In this paper we report two experiments we conducted to                    target-noise pair. The absolute location of landmarks
directly address these issues. The results show that multiple                 and objects on the screen was unchanged from their
allocentric frames of reference are used to encode spatial                    original encoding positions.
relationships among objects and late computation in object-              2. In the shifted-landmark condition (Figure 1D), the
location memory retrieval in object-cued conditions is often                  two landmarks were presented as cues, along with
inevitable.                                                                   the target-noise pair. Though the spatial relationships
   This paper consists of three major parts. In the first                     among the landmarks/drawings remained
section, the experimental paradigm is briefly introduced. In                  unchanged, the absolute locations of the
the second section, the experiments are reported, including                   landmarks/drawings on the screen were shifted.
both performance data and eye movement data. In the final                3. In the fixed-object condition (Figure 1E), two
section, we briefly discuss our ongoing work of developing                    encoded drawings instead the two landmarks were

        presented as cues, along with the target-noise pair.    representational drawings of common objects, selected from
        The absolute locations of drawings on the screen        the database of (Snodgrass & Vanderwart, 1980). The
        were unchanged.                                         drawings, 100x100 pixels in size, were presented against a
   4. In the shifted-object condition (Figure 1F), two          white background on a 19’’ VGA monitor with a resolution
        encoded drawings instead the two landmarks were         of 1024x768. The monitor was in front of the subjects
        presented as cues, along with the target-noise pair.    within 2 feet. Subjects were asked to respond by clicking
        Though the spatial relationships among the drawings     with a mouse which was within comfortable reach. 11
        remained unchanged, the absolute locations of the       subjects wore a head-mounted ISCAN eye-tracker while
        drawings on the screen were shifted.                    they were doing the experiment.
   One significant feature of the Milner paradigm is that it
simultaneously involves multiple spatial representations,
                                                                Design and Procedure
including screen-based, landmark-based, and object-based.       Each subject performed all 5 experimental conditions, each
While landmark-based representations are perceptually           with a different stimulus set. The design is illustrated in
accessible in the encoding phase (because an object was         Figure 1.
always presented along with the two landmarks in the               In each encoding trial, subjects were presented one
encoding phase), object-based representations are not           drawing and two landmarks and were instructed to
(because no two objects are presented at the same time in       remember the location of the drawing relative to the
                                                                landmarks. Subjects clicked the drawing to go on to the next
the encoding phase). Therefore, this fact alone might
                                                                trial. There were 32 encoding trials in each condition, with
suggest that object-based retrieval would be harder than
                                                                each drawing presented 4 times. The presentation order was
landmark-based retrieval. Systematic alignment of the           randomized. During the study subjects did not know which
different testing conditions allowed Milner and colleagues      testing condition would follow.
to use a subtraction method to determine the brain areas that      In each retrieval trial, subjects were presented the cues
dominate in the different test conditions.                      and the target-noise pair according to the testing condition.
   Behavioral data was only briefly reported in Johnsrude et    Subjects were instructed to choose the target, by clicking, as
al (1999). It was found that the shifted-object condition was   quickly as possible and as accurately as possible. As soon as
harder (e.g., longer RTs and lower accuracy) than any other     the subjects clicked, the next trial was presented. Each
conditions, which did not differ from each other.               drawing was tested 4 times.
Neuroimaging data suggested that object-location memory
in general involved the parahipocampal system, and the
shifted conditions, as compared to the respective fixed-           A                                    B
conditions, activated the posterior inferotemporal cortex.
Both areas have been believed to subserve important
functions of spatial cognition (e.g., Burgess, Jeffery, &
O'Keefe, 1999).
                       Experiment 1
In Experiment 1 we added one more testing condition to the         C                                   D
original Milner paradigm. In this additional condition, called
the fixed-nocue condition, no cues were presented along
with the target-noise pair in the retrieval phase. Subjects had
to make the forced-choice based solely on the absolute
location of objects on the screen. This condition was added
to explicitly test the effect of screen-based spatial
representations in location retrieval.
   Another purpose of experiment 1 was to collect eye
                                                                   E                                    F
movement data. Both perceptually encoding and cognitively
computing spatial relationships invite eye movements. The
trace of natural eye movements during the task provides an
indication of the deployment of attention (e.g., Corbetta et
al., 1998) and may shed light on the underlying spatial
representations and operations (e.g., Colby & Goldberg,
1999).
                                                                   Figure 1. The design of Experiment 1. A, an encoding
Subjects, Apparatus, and Materials                                 trial; B, fixed-nocue retrieval; C, fixed-landmark
21 subjects, 8 females and 13 males, with normal or                retrieval; D, shifted-landmark retrieval; E, fixed-object
corrected-to-normal vision, were paid to participate in the        retrieval; F, shifted-object retrieval.
experiment. Five sets of stimuli (each consisting of eight
drawings) were created using digitized black and white

Results                                                                        Summary & Discussion
Accuracy data. The average accuracy was at least 93%, and                      Experiment 1 resulted in two major findings that have not
there was no difference among the 5 testing conditions.                        been reported by Milner and colleagues. First, the reaction
                                                                               time in the fixed-nocue condition was not different from that
                      5000
                                                                               in the fixed-landmark condition. Since a screen-based
                                 landmark
                                                                               spatial representation had to be used in order to perform the
                                 object                                        fixed-nocue condition, this result indicates that a screen-
                                                                               based spatial representation might be implicitly encoded and
                      4000
                                                                               stored (because subjects were specifically instructed to pay
                                                                               attention to the drawing’s location relative to the
                                                                               landmarks), and be adopted to perform the fixed-landmark
                      3000
                                                                               condition. This hypothesis was further supported by the eye
RT (ms)                                                                        movement data. The number of eye fixations in both
                                                                               conditions was about 2, the minimal fixations needed to
                      2000
                                                                               identify the target if a conservative check-both-target-and-
                                                                               noise-before-click strategy was used. The eye movement
                                                                               traces also indicated that subjects often ignored landmarks
                      1000
                                    fixedNocue       fixed     shifted
                                                                               in the fixed-landmark condition.
                                                 Array Types                      Second, the significant interaction between the cue type
                                                                               (landmark vs object) and the array type (fixed vs shifted)
                      Figure 2. RT data in Experiment 1. The error bars
                                                                               was surprising. The reaction time in the shifted-object
                      represent 95% confidence intervals.
                                                                               condition was significantly longer than that in any other
                                                                               conditions (the RT in the shifted-object condition was about
RT data. The reaction time data is shown in Figure 2. An
                                                                               1800ms, 2100ms, and 2700ms longer than that in the fixed-
ANOVA shows a significant interaction between the cue
                                                                               object, shifted-landmark, and fixed-landmark conditions,
type (landmark vs object) and the array time (fixed vs
                                                                               respectively, see also Table 1), indicating some additional
shifted). In addition, a post-hoc comparison shows that the
                                                                               operations occurred in that condition. An analysis of the
shifted-object condition takes significantly longer than any
                                                                               computational differences among conditions sheds light on
other conditions, consistent with Johnsrude et al (1999)
                                                                               what these operations could be. a) Landmark cues (solid
results.
                                                                               squares) were much more perceptually distinct than object
                                                                               cues. In both object-cued conditions, an additional search
Eye movement data. Eye movements are needed to search
                                                                               operation was necessary in order to distinguish the target-
the scene and measure spatial relationships. The number of
                                                                               noise pair from the two object cues. b) Compared to the
eye fixations in each trial is counted and reported here. The
                                                                               fixed conditions, both shifted conditions required explicit
result is shown in Figure 3. It is interesting to note that the
                                                                               access of spatial relationships, either landmark-based or
eye fixation pattern is remarkably similar to the RT pattern,
                                                                               object-based. While landmark-based spatial relationships
indicating that the number of eye fixations is a good
                                                                               might be directly encoded in the encoding phase and later
predictor of RT.
                                                                               directly retrieved in the retrieval phase, it seems that object-
                                                                               based spatial relationships had to be derived through late
                                                                               computation because subjects never saw any two objects at
                                 landmark
                                 object
                                                                               the same time.
                      6
                                                                                  Eye movement data, however, indicated that this
                                                                               hypothesis might be oversimplified. In the encoding phase,
                      5                                                        we quite often observed that subjects moved his/her eyes
                                                                               back and forth between the currently presented object and
                      4
                                                                               the location of the previously displayed object (in the
                                                                               previous trial, which has already disappeared), indicating
                                                                               some form of object-based spatial relationships might be
Number of Fixations
                      3                                                        encoded directly and quite early. In general, however, it
                                                                               seems likely that shifted-object conditions involved quite
                      2
                                                                               extensive late computation in determining object-based
                                                                               spatial relationships.
                                  fixednocue        fixed        shifted          We speculate that a race model can be used to explain the
                                                 Array Types
                                                                               data. Specifically, when multiple types of representations
                      Figure 3. The number of eye fixations in Experiment 1.   for spatial relationships are available to solve the task at
                                                                               hand, they compete. Though often the representation that
                                                                               affords easiest operations dominates, sometimes they

interfere with each other. A decomposition of the                  condition between the pure object-cued condition and the
representations/operations for each condition is summarized        pure landmark-based condition.
in Table 1. It seems that the race model explains the RT data        These changes resulted in six testing conditions, as shown
reasonably well.                                                   in Figure 4. 14 subjects were paid to participate in the
                                                                   experiment.
           Table 1: A representational decomposition
                                                                      A                                B
                          Accessible representations/operations
                 RT          Early             Late         Addn.
                (ms)     computation       computation       ops
    Fixed-      1874     Screen-based
    nocue
    Fixed-      1723     Screen-based
  landmark             Landmark-based
    Fixed-      2599     Screen-based     Object-based      Search
                                                                      C                                D
    object
   Shifted-     2324   Landmark-based
  landmark
   Shifted-     4402                      Object-based      Search
    object
   Experiment 1 raised two issues. The first one is the role of
search in the object-cued conditions. Since the target-noise
                                                                      E                                F
pair and the object cues are visually indistinguishable, a
non-spatial visual search component is necessary to perform
the task. The search component was a free parameter in the
above race model that could be estimated but it obviously
confounded the results. It would be useful to eliminate this
confound. The second issue also has to do with the object-
cued conditions. In Experiment 1, the two objects that were
chosen to be cues in each trial were randomly selected from          Figure 4. The design of Experiment 2. A, fixed-
all possible objects (i.e., those that were not the target-noise     landmark retrieval; B, shifted-landmark retrieval; C,
pair). This made the task hard in the sense that all possible        fixed-object retrieval; D, shifted-object retrieval; E,
object-based spatial relationships (there were 78 of them!)          fixed-object consistent mapping retrieval; F, shifted-
might be relevant in the retrieval phase. This was in sharp          object consistent mapping retrieval.
contrast with the landmark-cued conditions, which had only
16 relevant spatial relationships (8 for each landmark).
Therefore, it might be the pure number of relevant spatial         Results & Discussion
relationships but not the late computation of object-based         Accuracy data. The average accuracy was at least 88%, and
representations that made the object-cued conditions more          there was no difference among the 6 testing conditions.
difficult. We designed experiment 2 to explore these two
issues.                                                            RT data. The reaction time data is shown in Figure 5. An
                                                                   ANOVA reveals similar effects to Experiment 1, including
                        Experiment 2                               the significant interaction between cue types (object vs
Experiment 2 adopted the same Milner paradigm, but                 landmark) and array types (fixed vs shifted).
differed from Experiment 1 in three aspects. First, the              The effects of the two manipulations we adopted in
landmarks were changed from solid black squares to a               Experiment 2 were evident. First, combining the results
white-filled black square. Second, in the object-cued              from both experiments, it is clear that the elimination of the
conditions, the object cues were framed in a black squared         search operations (by framing the object cues) did decrease
to make them visually salient. The purpose of the change           reaction time in certain object-cued conditions. However,
was to eliminate the search component in retrieval. Third,         this time saving had a surprising interaction with the array
we added two more object-cued conditions, which we called          types. Specifically, while the time saving in the fixed-object
consistent mapping conditions. In these conditions, instead        condition was not significant (2599ms in Experiment 1 vs
of selecting two cue objects at random for every trial, the        2494ms in Experiment 2) the saving was significant in the
two objects were selected at the beginning of the testing          shifted-object condition (4402ms in Experiment 1 vs
session and consistently served as the object cues for every       3548ms in Experiment 2). It is not so obvious how to
trial in that session. This change greatly reduced the relevant    explain this interaction. Second, the manipulation of
spatial relationships and could be viewed as a middle              consistent mapping in object-cued conditions also reduced

the reaction time. However, again, a reliable interaction with                                               General Discussion
array types was found. While the time reduction was about
                                                                                           Memory for object-location is an essential aspect of human
450ms in the fixed-object conditions (2494ms vs 2044ms),
                                                                                           spatial memory. However, the underlying representational
the reduction was about 900ms in the shifted-object
                                                                                           mechanisms and computational operations are controversial.
conditions (3548ms vs 2640ms). Similarly, it is not obvious
                                                                                           The empirical study reported here adopted and extended the
how this interaction occurred without a detailed
                                                                                           Milner paradigm and produced interesting data toward a
computational model.
                                                                                           better understanding of the problem. In this section, we
                                                                                           would like to discuss three issues related to the implications
                                                                                           of the study and the future work.
                                         landmark
                     3700                object                                              First, the current study supports the argument that
                                         object consistent mapping
                                                                                           memory for spatial relationships can take multiple forms of
                     3200
                                                                                           representations, each encoded in a different frame of
                                                                                           reference. Some of these representations may result from an
                                                                                           early computation, often due to a direct perceptual
                     2700
                                                                                           experience in the early encoding phase. These
 RT (ms)
                                                                                           representations can be encoded implicitly, such as the
                     2200
                                                                                           screen-based representations, or explicitly, such as the
                                                                                           landmark-based representations and some object-based
                     1700                                                                  representations (e.g., spatial relationships between objects
                                                                                           presented in consecutive trials). However, most of the
                     1200                                                                  object-based spatial relationships have to be inferred when
                                                       fixed                     shifted
                                                                                           necessary through a late computation, resulting in longer
                                                                  Array Types
                                                                                           reaction time in the object-cued conditions. When multiple
     Figure 5. RT data (in ms) in Experiment 2. The error                                  forms of representations are simultaneously available, a race
     bars represent 95% confidence intervals.                                              model seems plausible. The processes supported by each
                                                                                           representation compete with each other, and typically the
Eye movement data. Similar to Experiment 1, eye                                            one that affords fast response dominates. Eye movement
movement data corresponded quite well with the reaction                                    results support this hypothesis
time data (see Figure 6). Fewer numbers of eye fixations                                     Second, the results from the current study are also
were observed in the fixed array conditions than in the                                    consistent with the neuropsychological evidence that
shifted array conditions. In addition, the object-cued                                     suggests there exist multiple spatial representational systems
conditions induced more eye fixations than the landmark-                                   in the brain (e.g., Burgess et al., 1999; Wang et al., 2001).
cued conditions. In particular, both the elimination of the                                The PET imaging results from Milner and colleagues (1997)
search component and consistent mapping in object-cued                                     revealed that when object-location memory is retrieved,
conditions significantly reduced the number of eye                                         brain activity increases in the parahippocampal system, an
fixations (by about 1 and 1.5, respectively), indicating                                   area that is generally believed to subserve allocentric spatial
both manipulations successfully reduced the efforts of                                     representations.
object recognition and late computation of spatial                                           Finally, while the current study generated interesting
relationships.                                                                             results, it is clear that to fully understand these results a
                                                                                           detailed computational model is necessary. Questions about
                                                                                           how multiple forms of spatial relationships are represented
                                      landmark                                             and how they interact can be better explored only when a
                                      object
                                  5
                                      object consistent mapping                            computational model is developed. Efforts are being taken
                                                                                           to develop such a model in the Act-R cognitive architecture
                                  4
                                                                                           (Anderson & Lebiere, 1998). The long-term goal is to
                                                                                           develop a framework that can be used to model human
                                                                                           spatial cognition in general, including object-location
                                  3
                                                                                           memory and spatial layout memory.
           Numbers of Fixations
                                  2                                                                           Acknowledgments
                                                                                           This work is supported by a grant from the Office of Naval
                                  1
                                                                                           Research (Grant No. N00014-01-1-0074).
                                                     fixed                      shifted
                                                                  Array Types
     Figure 6. The number of eye fixations in Experiment 2.

                         References
Anderson, J. R., & Lebiere, C. (1998). The atomic
   components of thought. Hillsdale, NJ: Lawrence
   Erlbaum Press.
Burgess, N., Jeffery, K. J., & O'Keefe, J. (Eds.). (1999). The
   hippocamal and parietal foundations of spatial
   cognition. New York: Oxford University Press.
Colby, C. L., & Goldberg, M. E. (1999). Space and attention
   in parietal cortex. Annual Review of Neuroscience, 22,
   319-349.
Corbetta, M., Akbudak, E., Conturo, T. E., Snyder, A. Z.,
   Ollinger, J. M., Drury, H. A., Linenweber, M. R.,
   Petersen, S. E., Raichle, M. E., Essen, D. C. V., &
   Shulman, G. L. (1998). A common network of
   functional areas for attention and eye movements.
   Neuron, 21, 761-773.
Hunt, E., & Waller, D. (1999). Orientation and wayfinding:
   A review.Unpublished manuscript, Arlington, VA.
Johnsrude, I., Owen, A. M., Crane, J., Milner, B., & Evans,
   A. C. (1999). A cognitive activation study of memory
   for spatial relationships. Neuropsychologia, 37, 829-841.
Klatzky, R. L. (1998). Allocentric and egocentric spatial
   representations: Definitions, distinctions, and
   interconnections. In K. F. Wender (Ed.), Spatial
   cognition: An interdisciplinary approach to representing
   and processing spatial knowledge. New York: Springer-
   Verlag.
Milner, B., Johnsrude, I., & Crane, J. (1997). Right medial
   temporal-lobe contribution to object-location memory.
   Phil. Trans. R. Soc. Lond. B, 352, 1469-1474.
Owen, A. M., Milner, B., Petrides, M., & Evans, A. C.
   (1996). A specific role for the right parahippocampal
   gyrus in the retrieval of object-location: A positron
   emission tomography study. Journal of Cognitive
   Neuroscience, 8, 588-602.
Snodgrass, J. G., & Vanderwart, M. (1980). A standardized
   set of 260 pictures: Norms for name agreement, image
   agreement, familiarity, and visual complexity. Journal of
   Experimental Psychology: Human Learning & Memory,
   6, 174-215.
Tversky, B. (2000). Remembering spaces. In F. I. M. Craik
   (Ed.), The Oxford handbook of memory. New York:
   Oxford University Press.
Wang, H., Johnson, T. R., & Zhang, J. (2001). The mind's
   views of space. Paper presented at the Fourth
   International Conference of Cognitive Science.

