UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Providing Distinctive Cues to Augment Human Memory

Permalink
https://escholarship.org/uc/item/36b1w4pk

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Authors
Stefanucci, Jeanine K
Proffitt, Dennis R

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Providing Distinctive Cues to Augment Human Memory
Jeanine K. Stefanucci (jks8s@virginia.edu)
Department of Psychology, 102 Gilmer Hall, Box 400400
Charlottesville, VA 22904-4400

Dennis R. Proffitt (drp@virginia.edu)
Department of Psychology, 102 Gilmer Hall, Box 400400
Charlottesville, VA 22904-4400

Abstract
Previous research in our lab (Tan, Stefanucci, Proffitt &
Pausch, 2001) demonstrated that a multimodal prototype
computer system, the InfoCockpit, could increase users’
memory of information compared to a standard desktop
computer. Displaying information on multiple monitors
with ambient visual and auditory dispays engages
context-dependent memory and memory for location,
thus facilitating recall. We replicate this finding and
isolate the memory cues to find whether the combination
of contextual information and spatial location is
necessary to obtain this memory advantage. Our
findings show that contextual information alone provides
users with the best strategy for later recall.

Introduction
In the past years, computer interfaces have been
designed with the goal of promoting usability. These
interfaces have a consistent “look and feel” that fosters
usability but does not help the user remember
information learned on the system. Our research
examines a newly built interface, termed the
InfoCockpit, which supports and aids human memory
and performance while preserving usability.
The design of the InfoCockpit is based on
psychological research that has uncovered many ways
of improving memory through the use of spatial and
environmental memory cues.
These cues are
incorporated into the InfoCockpit so that users can
more easily recall information that they learn on the
computer. This system provides users with “locations”
and “places” to hook their memories onto without
compromising usability.

Creating Place
Memories are tied to the environmental context in
which they take place (Smith, Glenberg, & Bjork,
1978). For example, one might try to help a friend
remember a conversation by referencing the context of
that conversation (e.g. “don’t you remember we talked
about this at the coffee shop downtown?”). Having
recalled the place of the conversation, the friend can
more easily remember what was said. This strategy

recruits an important cue for human memory; the
context or “place” is a reference to start a search for the
information discussed. Being in places, or referencing
them, evokes memories and increases the chances of
remembering information.
Psychologists have researched the use of
environmental context as a cue for memory for the past
few decades (Godden & Baddeley, 1975; Smith,
Glenberg & Bjork, 1978). Smith (1979) found that
people associate information and the environmental
context in which it is learned.
Although these
associations are often incidental, they can be useful
retrieval cues when recalling information. Smith
(1982) also had participants encode information in
multiple learning environments or different “places”.
He showed that the amount of information recalled
increases when learning takes place in different
contexts. In further studies, however, Smith (1984)
found that recall performance in multiple learning
contexts was not significantly improved when
participants returned to the place that they were in at the
time of encoding. Diverse learning environments
provide a memory advantage over a single learning
environment but this advantage is not contingent upon
reinstatement of the context at retrieval.
In addition to the number of learning environments,
contexts that are distinctive can also increase memory
performance. Places that draw attention are the most
effective in producing a memory advantage (Smith,
Vela, & Williamson, 1988). Learning information
through different sensory modalities can create a
distinctive context. In addition to visual cues, ambient
three-dimensional sounds can serve as distinctive cues
for memory. It has been shown that ambient sounds
enhance memory for visual information presented in
their context (Davis, Scott, Pair, Hodges, & Oliverio, J.,
1999).

Providing Location
Memories are also tied to a location in space (Gordon,
1903). Whereas we use “place” to denote an ambient
environmental context, “location” refers to the position
of information within that “place”. We cannot help but

notice, for example, the position of an object in a room.
The location of that object in space is processed
preattentively and remembered almost automatically
(Logan, 1998). Similarly, most people comment that
they can remember where on a page they read
something without remembering the information they
read. Several studies confirmed this anecdote by
showing the reliability of spatial location as an
important memory cue (Rothkopf, 1971; Zechmeister &
McKillip, 1972). Given the evidence above, it follows
that spatially distributed information is easier to
remember than information presented in a single
location (Gordon, 1903).

Combining Location and Place: The
InfoCockpit
The InfoCockpit (see Figure 1) uses multiple projectors
to display a panoramic image of a “place” onto large
screens. It provides a context for users to reference
when they are retrieving information from memory.
Ambient three-dimensional surround sound is added to
immerse the user in the place. For example, panoramas
of a woodland scene are projected with consistent 3D
sounds like leaves rustling, birds chirping, and insects.
The InfoCockpit provides spatial cues by presenting
information to users on multiple monitors. When
learning the information, users inadvertently notice on
which monitor information is presented.
We
hypothesized that users would be more likely to
remember the information if they could recall on which
monitor it was presented.

Previous research has not attempted to construct
environments that present “location” and “place” cues
to systematically examine whether a large effect can be
obtained. In our lab, we combined these cues (location
and place) to see if they produced a greater memory
advantage than when presented independently (Tan,
Stefanucci, Proffitt, Pausch, 2001). Tan et al. found
that users of the InfoCockpit had a 56% improvement in
memory performance when compared to users of a
standard desktop computer.
The current paper addressed whether users of the
InfoCockpit systematically relied on one cue over the
other or if the combination of “location” and “place”
was the best way to promote later recall. Each of the
cues was examined in isolation to assess its solitary
contribution to the larger effect. Based on our previous
findings, we assumed that participants using the
InfoCockpit would be able to remember more than
participants using a standard desktop computer. And
indeed, this was true. In addition, we hypothesized that
“more is better”; participants in the InfoCockpit
condition would remember significantly more word
pairs than participants who received “location” or
“place” cues in isolation. Contrary to our hypothesis,
our experiment revealed that participants receiving only
“place” cues performed significantly better than
participants in all other conditions.

Method
Participants
Eighty University of Virginia students (40M, 40F)
participated in the experiment. Participants were paid
$20 for their participation. They were naïve to the
purposes of the experiment and had not participated in a
previous memory experiment like this one.

Apparatus

Figure 1. – The InfoCockpit uses multiple monitors
to provide “location” cues and ambient visuals with
three-dimensional sounds to create “place” cues.
This system stands in stark contrast to current
desktop systems, which present all information to the
user on a single monitor, and do not display a place cue.
Desktop users do not have to orient themselves to
information; windows simply bring information to
them. There are no spatial cues encoded with the
information and no way of easily retrieving information
by remembering the context in which it was seen.

The apparatus used to display materials, the
InfoCockpit, is a large multiple screen display system
(see Figure 1). The displays are run from a Dell
Precision Workstation with 620 Pentium III Xeon dual
processors. Installed in the Dell are two Appian
Jeronimo Pro 4-port graphics cards that allow the
computer to drive the six display screens. Two sets of
displays are arrayed three across, with NEC 18” LCD
monitors directly below the projection surfaces. The
LCD monitors serve as the main working area on which
users interact with information. The projection displays
provide a horizontal viewing angle of approximately
145 degrees and are used to immerse the user in a
particular place. Three Sharp Notevision 6 projectors
(2200 lumens) display the context images on the
projection screens.
We created and played back audio contexts on a
Macintosh G4 using a Digidesign Pro Tools Mix24

digital audio workstation. The contextual environments
were comprised of 6 channels of sound. Speakers were
placed surrounding the user at ear level and at 4 feet
above ear level, +/- 30 degrees at ear level, and +/- 120
degrees at 4 feet above ear level. The ear level speakers
were 5 feet away from the user while the speakers
above were 8 feet away.

Procedure
The experimental design consisted of two phases: a
training phase and a testing phase.
Training Phase Participants learned three lists of
words, each list containing ten pairs of words (all
common, high frequency nouns). All participants
learned the lists one at a time. Each list consisted of 10
cue words and 10 target words. The 10 cue words were
the same for the 3 lists, but the target words varied from
list to list (i.e. ‘plate-passenger’, ‘plate-string’, and
‘plate-scientist’). We named the lists Lawn, Museum,
and History to help the participants parse the lists in
memory. For the participants in the InfoCockpit or
Context conditions, these names referred to projected
places.
The training phase consisted of both a study period
and a learning period. During the study period
participants were presented with each pair of words
once (for 5 seconds each). After study was completed,
the learning task began. One of the cue words from a
pair was randomly presented to the participants.
Participants then typed the target word that went with
the cue. Feedback was given to the participants. If they
were incorrect, the correct word was presented.
Another cue word would then appear and they would
have to type its target. This went on iteratively until
participants had recalled all of the pairs correctly in one
iteration (meeting 100% criteria). This ensured that all
participants’ knowledge of the material was equivalent
before testing. Participants had unlimited time to finish
the learning portion. The procedure for learning the
word lists was explained to participants before training
began.
Participants were assigned to one of four conditions
(Desktop, InfoCockpit, Spatial, or Context) defined by
the display configuration on which they learned pairs of
words. An equal number of males and females were
randomly assigned to each condition. Participants in
the InfoCockpit group studied and learned the word
lists, each on a different monitor and associated with
different contextual images and sounds. For example,
participants would see images and hear sounds from a
museum while they were learning the word pairs for the
“Museum” list on the middle monitor.

The Desktop group performed the task on a standard
desktop computer with a single monitor. They learned
the same three lists (Lawn, Museum, and History) on
one screen, with no projected context images or threedimensional sounds.
For the Spatial condition, participants learned the
three word lists on different monitors. However, they
did not learn the lists in different projected contexts.
They also had no sounds. This condition was designed
to assess the individual contribution of spatial cues in
the InfoCockpit.
Participants in the Context condition learned the three
lists on one monitor. Each list was presented with its
corresponding context. Participants learned the lists
with the projected context images and sounds, all on the
same monitor. This condition tested the importance of
contextual place cues on learning in the InfoCockpit.
Testing Phase The testing phase of the experiment
took place a day later. All participants returned to the
lab and were tested on how many word pairs they
remembered from the training phase. Retrieval was
done on a laptop in a different room than the training
phase. Participants were given cue words from each of
three lists, one list at a time, and were asked to type in
as many of the targets as they could remember. They
received no feedback on their performance.

Results
Out of 30 possible items, the mean recall scores were
8.80 for the Desktop group, 11.65 for the InfoCockpit
group, 9.60 for the Spatial group, and 15.05 for the
Context group. A one-way analysis of variance
(ANOVA) comparing the four conditions revealed
significant differences between the groups, F (3, 76) =
9.065, p < 0.000 (see Figure 2). Post hoc comparisons
using the Fisher LSD test showed that participants in
the Context condition recalled significantly more word
pairs than the Spatial, Desktop and InfoCockpit
conditions. In addition, the InfoCockpit condition
remembered significantly more word pairs than the
Desktop condition. A one-way analysis of variance
(ANOVA) comparing number of iterations to learn the
word pairs to criteria did not show a significant
difference among the conditions, p = 0.762.

18

# Pairs Recalled

16
14
12
10

Desktop

8
6

Spatial

4
2

InfoCockpit

0
Condition

Figure 2.
condition.

Context

Number of word pairs recalled by each

Discussion
InfoCockpit participants remembered significantly
more word pairs than participants using a standard
desktop computer. Adding “location” and “place” cues
to a computer enhanced participants’ memory for
information learned on that system. This conclusion
replicates previous research from our lab (Tan,
Stefanucci, Proffitt, Pausch, 2001).
We assumed the individual components of the
InfoCockpit would improve memory with relation to
the standard desktop computer, but we did not believe
they would be as effective as the ensemble of cues. Our
hypothesis that “more is better” was incorrect for this
task. Participants receiving only “place” cues at
encoding recalled more words than participants in all
other conditions.
This finding may be a consequence of the strategy the
InfoCockpit participants used when retrieving the word
pairs. We believe these participants had two strategies
available at recall for remembering the information.
One of the strategies involved the location of the list on
one of the monitors. Participants could retrieve the
appropriate target by recalling the location of the
monitor on which it was learned.
Likewise,
InfoCockpit participants could access environmental
place cues to recall the pairs. To remember the target
word they could imagine the contextual images and
sounds displayed when learning the pair. It is possible
that these two recall strategies interfered with each
other, compromising the best recall strategy (simply
recalling the “place” cue) by the evoking the less
effective location recall strategy. In the task we
describe, the contextual place information was a more
reliable cue for later recall and those participants in the
Context condition were able to exploit it to the fullest.
While participants in the InfoCockpit condition
performed better than participants in the standard
desktop computer, they were not as successful as
participants in the Context condition. Providing users
with a single cue in isolation (place) was more effective
than providing them with two sets of cues. This finding

is not surprising given previous research. For instance,
Jones (1976) and Smith (1984) found that isolated cues
could help their participants retrieve an entire memory,
even when combinations of cues were present at
encoding. More recently, Parker and Gellatly (1997)
showed that an increase in the amount of cues at
encoding did not produce a reliable increase in recall.
They gave their participants both music and odors while
encoding information. At retrieval, either both or only
one of the cues was reinstated. In either condition,
participants recalled the same amount of information.
In contrast, our findings suggest that participants
receiving only one of the cues (place) at encoding had
an advantage over the other conditions. The type of cue
we used may account for the difference. Perhaps the
place cue was more distinctive than the location cue and
people were more successful in associating it with the
words. The “more is better” approach to the design of
computer interfaces should be examined closely
because there may be situations in which a “less is
more” attitude can augment performance to a higher
degree.

Conclusions
The InfoCockpit increased memory compared
to a standard desktop computer. It utilized both “place”
and “location” cues to facilitate memory retrieval.
When presented with “place” cues in isolation,
participants’
memory
performance
increased
significantly in comparison to performance on the
InfoCockpit. Providing multiple memory cues at
encoding increases recall.
However, interference
between contextual and spatial cues may have a
negative effect on performance. Evaluation of the
interactions between cues, as well as the cues
themselves, is necessary to ensure a complete
understanding of the role that these cues play in
memory.
Acknowledgments For their collaboration on this
project, we would like to thank Tom Banton, Cedar
Riener, and Jessi Witt of the Proffitt Perception Lab at
the University of Virginia; Barbara Spellman at the
University of Virginia; Adam Fass, Andrew Faulring,
Desney Tan and Randy Pausch of the Stage 3 Research
Lab at Carnegie Mellon University; Chris Kyriakakis at
the University of Southern California. Many thanks to
Shawn O’Hargan and Jae Lee for their help in
collecting the data.

References
Davis, E. T., Scott, K., Pair, J., Hodges, L. F., &
Oliverio, J. (1999). Can audio enhance visual
perception and performance in a virtual environment?

Proceedings Of The Human Factors And Ergonomics
Society 43rd Annual Meeting, 1197-1201.
Godden, D. R., & Baddeley, A. D. (1975). Contextdependent memory in two natural environments: On
land and underwater. British Journal of Psychology,
66(3), 325-331.
Gordon, K. (1903). Meaning in Memory and in
Attention: Memory as dependent upon the
complexity of its content. Psychological Review, 11,
267-283.
Jones, G. V. (1976). A fragmentation hypothesis of
memory; cued recall of pictures and sequential
position.
Journal of Experimental Psychology:
General, 105, 277-293.
Logan, G. D. (1998). What is learned during
automatization? II. Obligatory encoding of spatial
location. Journal of Experimental Psychology:
Human Perception & Performance, 24(6), 17201736.
Parker, A., & Gellatly, A. (1997). Moveable cues: A
practical method for reducing context-dependent
forgetting. Applied Cognitive Psychology, 11(2), 163173.
Rothkopf, E. Z. (1971). Incidental memory for location
of information in text. Journal of Verbal Learning
and Verbal Behavior, 10, 608-613.
Smith, S. M., Vela, E., & Williamson, J. E. (1988).
Shallow input processing does not induce
environmental
context-dependent
recognition.
Bulletin of the Psychonomic Society, 26, 537-540.
Smith, S. M. (1984). A comparison of two techniques
for reducing context-dependent forgetting. Memory &
Cognition, 12, 477-482.
Smith, S. M. (1982). Enhancement of recall using
multiple environmental contexts during learning.
Memory & Cognition, 10(5), 405-412.
Smith, S. M. (1979). Remembering in and out of
context. Journal of Experimental Psychology: Human
Learning and Memory, 5(5), 460-471.
Smith, S. M., Glenberg, A., & Bjork, R. A. (1978).
Environmental context and human memory.
Memory& Cognition, 6(4), 342-353.
Tan, D.S., Stefanucci, J.K., Proffitt, D.R., & Pausch, R.
(2001). The InfoCockpit: Providing Location and
Place to Aid Human Memory. Workshop on
Perceptive User Interfaces 2001, Orlando, Florida.
Zechmeister, E. B., & McKillip, J. (1972). Recall of
place on the page. Journal of Educational
Psychology, 63, 446-453.

