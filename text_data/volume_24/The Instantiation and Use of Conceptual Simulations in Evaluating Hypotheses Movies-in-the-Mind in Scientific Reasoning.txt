UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Instantiation and Use of Conceptual Simulations in Evaluating Hypotheses: Movies-in-
the-Mind in Scientific Reasoning
Permalink
https://escholarship.org/uc/item/0gc2c1zr
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Trickett, Susan B
Trafton, J Gregory
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

     The Instantiation and Use of Conceptual Simulations in Evaluating Hypotheses:
                                     Movies-in-the-Mind in Scientific Reasoning
         Susan B. Trickett (stricket@gmu.edu)                             J. Gregory Trafton (trafton@itd.nrl.navy.mil)
    Department of Psychology, George Mason University                         Naval Research Laboratory, NRL Code 5513
                 Fairfax, VA 22030-4444 USA                                            Washington, DC 20375 USA
                               Abstract                                What strategies besides experimentation might scientists
                                                                    use to evaluate hypotheses? Prior research on scientific
   This study investigates the strategies used by expert scientists thinking suggests several possibilities. One likely strategy is
   to evaluate hypotheses when they analyze data. We used an in     extracting information from data, whether by reading off
   vivo methodology to observe experts' on-line thinking. In
                                                                    information, transforming data, replotting data), or looking
   contrast to the results of laboratory studies of scientific
   reasoning, we found that the scientists rarely used
                                                                    at data that is not currently on view but that is available.
   experimentation but relied on a variety of other strategies,     Trafton found that expert meteorologists spent considerable
   including conceptual simulation. This strategy was most          time on information extraction (Trafton et al., 2000).
   prevalent in evaluating a hypothesis about a phenomenon that        Given the cost of experimentation, it is also likely that
   violated the scientists' expectations.                           scientists use different strategies to reason about hypotheses
                                                                    before committing to an experiment. Analogical reasoning
                            Introduction                            has been shown to be a powerful strategy in science
How do scientists test and evaluate hypotheses? One                 (Clement, 1988; Dunbar, 1997; Gentner et al., 1997). It
obvious answer is that they design and conduct experiments.         allows people to make inferences about an unknown entity
The canonical method of scientific inquiry is represented by        based upon their knowledge of a different, known entity
a cycle of hypothesis generation, experimentation, data             (Gentner, 1983) and has been proposed as a mechanism of
analysis and hypothesis refinement that has its roots in the        conceptual change in numerous historic scientific advances
philosophy of science (Popper, 1956) and is frequently              (Gentner et al., 1997; Nersessian, 1992; Thagard, 1992). It
taught explicitly to students (Okada & Shimokido, 2001).            is also a strategy used by successful contemporary scientists
   Psychologists investigating the processes of scientific          in scientific problem-solving, such as hypothesis generation
reasoning have also been influenced by the "scientific              (Clement, 1988), experimental design (Dunbar, 1997), and
method" and so have focused on experimentation in                   discovery itself (Ueda, 1997). Given its widespread use in
investigating hypothesis-evaluation strategies,. There have         other aspects of scientific reasoning, it seems plausible that
been numerous laboratory studies of scientific reasoning in         analogy may be used as a hypothesis-testing strategy;
which participants are asked to find the cause of a given           however, whether this is the case remains an open question.
effect (e.g. Dunbar, 1993; Schunn & Anderson, 1999), or to             Conceptual simulation has also been shown to be a means
identify the role of a causal mechanism (e.g., Klahr &              of successful scientific reasoning (Nersessian, 1999; Qin &
Dunbar, 1988; Trafton & Trickett, 2001a; Trickett, Trafton,         Simon, 1990; Schraagen, 1993). A conceptual simulation is
& Raymond, 1998; Vollmeyer, Burns, & Holyoak, 1996). In             a mentally constructed model of a phenomenon or data
these studies, participants propose hypotheses, then design         representation that is manipulated in such a way that there is
and run experiments to test them                                    a resulting change of state (a formal definition is provided
   There are several reasons why participants in laboratory         below). As with analogy, conceptual simulations have been
studies of science use experimentation to evaluate                  proposed as a strategy used by both historical and practicing
hypotheses. The instructions in these studies explicitly tell       scientists. In historical reconstructions, Ippolito and Tweney
participants to run experiments. Participants have little           have developed a model of insight that involves the
choice—they are provided with limited time, equipment,              construction of a dynamic, “runnable” mental model
and materials. Moreover, they are frequently asked to reason        (Ippolito & Tweney, 1995), and Nersessian proposes that
in a domain about which they have no relevant knowledge.            scientists construct and conduct mental experiments that
Running an experiment is also “cheap”—the variables are             yield usable data, in a process that mirrors an empirical
already identified, it involves a few mouse-clicks, and the         experiment (Nersessian, 1999). In contemporary scientific
results are almost instantaneous and easy to interpret.             problem-solving, Hegarty has found that people develop
   However, practicing scientists have a wider array of             sequences of mental animations (Hegarty, 1992). Qin and
options. They can select their own methods and equipment,           Simon (1990) found that people used a series of mental
and, as experts, they have domain knowledge to guide their          processes of manipulation, control, and inspection in order
problem-solving. Experimentation may n o t be the best              to extract information that was only implicit in their initial
strategy, as it is expensive in terms of planning, paperwork,       mental image. Similarly, participants in Schraagen's study
personnel, the need for special equipment, the complexity of        of experimental design used a strategy of mental simulation
data interpretation, and the high cost of errors.                   to project what experimental procedures would look like
                                                                    under particular circumstances (Schraagen, 1993). As with

analogy, how much scientists use conceptual simulations in      comments from the scientists to the experimenter and post-
evaluating hypotheses remains an open question.                 session interviews of the scientists were excluded from
   One can imagine several other means whereby scientists       analysis. The number and percentage of on-task utterances,
might evaluate a hypothesis. For example, a scientist might     the number of participating scientists, and the duration of
consult a colleague or other expert or attempt to tie the       the relevant portion of each individual session are reported
hypothesis into current theoretical understanding of the        in Table 1. Finally, a coding scheme (described below) was
domain. A scientist might also defer evaluation until some      developed to examine how the scientists evaluated
later time or even abandon a hypothesis altogether.             hypotheses they developed in the course of analyzing data.
   The purpose of this research is to investigate the means by
which scientists evaluate hypotheses. In order to investigate                 Table 1: Characteristics of datasets
this issue, we adapted Dunbar’s in vivo methodology
(Dunbar, 1997), an observational technique developed to                                Utterances:          Time           #
                                                                    Domain
study creative and complex thinking in a real-world context.                      On-Task         Total    (mins)      scientists
The main advantage of Dunbar's method is that it allows the         Astronomy        649          859        49            2
collection of on-line measures of thinking by experts                 CFD sub        430          954        39            1
engaged in authentic scientific tasks.                             CFD laser 1       172          400        15            1
                                                                   CFD laser 2       184          249        13            1
                             Method                                      fMRI        317          373        55            2
We chose to investigate scientists at work during the data       Neuroscience        219          343        54            2
analysis phase of their research because it is a stage at which  Psychology 1        482          541        31            3
a great deal of scientific reasoning takes place. Scientists     Psychology 2        914         1426        75            2
must integrate their expectations about the data with the
actual data; it is thus likely to be rich in hypotheses.          Although each scientist or group used different tools, their
   We analyzed 8 different datasets from 9 scientists           tasks shared several characteristics. All the scientists were
working in one of 4 domains—neuroscience, astronomy,            analyzing data that they themselves had collected, from
computational fluid dynamics (CFD), and psychology. Each        observations, from a controlled experiment, or from running
dataset consists of a recorded session in which one or more     a computational model. They displayed this data using their
scientists analyzed their data.                                 regular tools, whether custom-built visualization programs,
   Participants were all working scientists recruited through   while others used widely available commercial products,
personal connection of the experimenters. Either they were      such as Microsoft's Excel. Figure 1 shows an example of the
expert scientists who had earned their PhDs more than 6         type of data examined by the astronomers. Visualizations
years previously, or they were graduate students working        used in other domains were similarly complex.
alongside one of these experts. Only experts with a Ph.D.         .
worked alone; in the group sessions involving graduate
students, the scientist in charge always had a Ph.D.
   Participants agreed to contact a member of the research
team when they were ready to conduct some analysis of
recently acquired data, and an experimenter visited the
scientists at their regular work location. Participants
working alone were trained to give talk-aloud verbal
protocols. For scientists working in groups, we recorded
their conversation as they engaged in scientific discussion
about their data. All participants were instructed to carry out
their work without explanation to the experimenter
(Ericsson & Simon, 1993). It is important to emphasize that
all participants were performing their usual tasks in the
manner in which they typically did so. At the beginning of
the session, some participants gave the experimenter an
explanatory overview of the data and the questions to be
resolved, and after the session, the experimenter interviewed
the participants to gain clarification about any uncertainties.
During the analysis session itself, however, the
experimenter did not interrupt the participants.
   All utterances were later transcribed and segmented
according to complete thought. All segments were coded by         Figure 1: Example of data examined by astronomers.
2 coders as on-task (data analysis) or off-task (e.g., software Radio data (contour lines) are laid over optical data.
management, phone interruptions, jokes, etc.). Inter-rater
reliability for this coding was more than 95%. Introductory

    Almost all sessions represented the initial investigation of to run such an experiment, or plans to collect additional data
this data (the exception was the second CFD session, which       for an experiment that has already been run (e.g., increasing
was a follow-up to the first session). Although in some          the sample size or making some other adjustment) or to
sessions the scientists did not have strong a priori beliefs     collect more observational data. Data collection strategies
about the data (these sessions were thus exploratory), in        also include plans to build and run computational models.
others, the scientists did approach the task with particular
hypotheses that they expected to be supported by the data. It    Information extraction Statements that "read off" data
is interesting to note, however, that none of the scientists     from the visible display (i.e., extract information) were
performed any statistical analyses                               coded as information extraction (Trafton et al, in press). In
                                                                 addition, we coded as information extraction strategies
Coding Scheme                                                    statements that refer to looking at data in a different way
    In addition to coding all segments as on- or off-task, we    (e.g., replotting the data or displaying it in a different
coded the following (see Table 2 for examples):                  visualization), to "tweaking" data (by transformation,
                                                                 removing outliers, etc.), or to looking at data that is not
              Table 2: Examples of coding scheme                 currently on view but that is available.
                   (Coded utterance in italics)
                                                                 Consult a colleague Utterances that refer to showing the
      Code                         Utterance                     data to or asking the opinion of a co-worker or other expert
                 You'd       think      [the    number      of   were coded as consulting a colleague.
                 reclassifications] would go up for condition
  Hypothesis     C, but it didn't…So maybe the subjects are      Tie-in with theory We expected that expert scientists with a
                 having a better memory of the ones they've      vast array of domain knowledge stored in memory were
                 already done (Psychology 2)                     likely to apply that theoretical domain knowledge to their
                 Do you think it’s worth getting some more       hypotheses. We coded as “tie-in with theory” utterances that
          Data                                                   refer to theoretical underpinnings of the data.
                 time, just to do an offset plane, or offset
    collection
                 velocity? (Astronomy)
                 Well, that’s a really clean neuron,, uh it      Analogy/Alignment Although different theories of analogy
 Information                                                     specify different processes by which the mapping between
                 goes down and up and away from the edges
    extraction                                                   source and target occurs (Gentner, 1983; Holyoak, 1985), all
                 (Neuroscience)
                                                                 theories share these elements: source, target, and a process
       Consult   I’m gonna have to discuss it with ah, Robbie
                                                                 of mapping or alignment. During alignment, the relevant
     colleague   when he gets back. (CFD submarine)
                                                                 parts of the source are "applied" to the target. It is thus
  Tie-in with    OK, so how do these Fourier modes work?
                                                                 during this phase that inferencing occurs, and hence we
        theory   (CFD laser 1)
                                                                 expected that scientific reasoning would occur during this
      Analogy
                 Think of this as a spiral arm (Astronomy)       part of the analogical process.
     (general)
                                                                    We coded analogies using the definition and coding
                 And, if I’ve got a scaling problem, then it     scheme developed by Dunbar (1997). According to this
      Analogy
                 should show up here too, but it doesn’t
 (alignment)                                                     scheme, analogy is coded when a scientist either refers to
                 show up here (CFD submarine)
                                                                 another base of knowledge to explain a concept or uses
                 In a perfect sort of spider diagram, if you     another base of knowledge to modify a concept. Analogies
                 looked at the velocity contours without any     were coded at both a "general" level (e.g., "The atom is like
                 sort of streaming motions, no, what I’m         the solar system") and at the level of the actual mapping or
  Conceptual
                 trying to say is, um, in the absence of         alignment. Statements of similarity (i.e., "X is like Y") were
   simulation
                 streaming motions, you’d probably expect        not considered analogies; they do not provide explanations
                 these lines here to go all the way across,      nor result in mapping features from the source to the target.
                 you know, the ring (Astronomy)
                                                                 Conceptual Simulations Recall that a conceptual
Hypotheses All statements that attempted to explain or           simulation is a mentally constructed model of a
account for a phenomenon identified in the data were coded       phenomenon or data representation. The initial
as hypotheses. After a hypothesis, utterances that pertain to    representation may be grounded in memory (e.g., theoretical
(elaborate) that hypothesis were identified. Such utterances     knowledge of the phenomenon) or in a mental modification
constitute further investigation of the hypothesis and may be    of the displayed image. The key feature of a conceptual
support or oppose the hypothesis. All subsequent utterances      simulation is that it involves a simulation “run" that alters
pertaining to a hypothesis were coded as follows:                the representation, such that there is a change of state.
                                                                    To code conceptual simulations, we adapted Trafton's
Data collection Utterances in which the scientist proposed       spatial transformation framework (Trafton & Trickett,
to collect more data were coded as data collection strategies.   2001b; Trafton, Trickett, & Mintz, in press; ). We conducted
These include statements that propose an experiment, plans

a spatial transformation analysis to determine for each on-    them to devote a significant amount of time to extracting
task utterance whether the speaker was extracting              information directly from the data itself. Similarly, the
information from the display (“read-off") and which mental     second most frequent strategy, tie-in with theory, might also
operations, if any, were applied to a representation. Some     be predicted from an understanding of the general
possibilities include rotation, modification, moving an        procedures of science. These scientists have significant
image, creating a mental representation, animating features,   expertise and knowledge of the theories relevant to their
and comparison. Conceptual simulations may be defined          domains, and one would expect them to consider new data
formally as a specific sequence of spatial transformations:    in the context of current theoretical understanding of the
1. Create representation: The scientist creates a mental       domain. One might also expect data collection strategies
representation that is not the same as the currently displayed (which include plans to design or conduct experiments) to
representation. This representation creation may occur via     occur frequently; however, these were one of the least
the display (it modifies the display), via theory, (a          frequent strategies used by these scientists.
theoretical construct); or via memory (the scientist recalls a
previously viewed representation).                                 Table 3: Frequency of hypothesis-evaluation strategies
2. Simulation Run: The scientist builds on the created
representation by spatial transformation (e.g., extend, add,                  Strategy             Frequency
delete) such that its state is changed.                                Information extraction          268
   Note that these codes are not mutually exclusive, and that               Tie-in with theory          36
the created representation and explicit run can occur in the           Conceptual simulation            34
same utterance. Approximately 20% of the data has been                    Analogy/Alignment             30
coded for conceptual simulations by 2 independent coders,                       Data collection         3
and initial inter-rater reliability was greater than 90%.                 Consult a colleague           1
                             Results                              The use of analogy is also of interest. Of the 30 uses of
   Eight in vivo datasets, comprising 330 minutes of relevant  the analogy/alignment strategy, only one consisted of a
protocol and 3508 on-task utterances were analyzed. We         "general" analogy. The remaining 29 were alignments in
coded 68 hypotheses, an average of approximately 1             which the mapping between source and target actually took
hypothesis every 5 minutes. 57 hypotheses (84%) were           place. This result is consistent with findings of other studies
elaborated; that is, the scientist made some follow-up         in which analogy use has been found to be more "local" than
utterance(s) that further explored the hypothesis.             "global" (Dunbar, 1997; Saner & Schunn, 1999). The use of
                                                               alignment is discussed in more detail below.
How did the scientists evaluate the hypotheses?                   Of particular interest is the relative frequency of the
   We identified and counted the type of utterance following   conceptual simulation strategy. Specifically, this strategy
each hypothesis. Table 3 summarizes this count. Counts         was linked with the alignment strategy in a sequence that
were performed in the following manner: Each individual        took the form of conceptual simulation followed by
instance of information extraction was included in the count.  alignment. There were 34 conceptual simulations and 29
For example, the sequence “If I look at the average of that,   alignments; out of these, there were 27 Conceptual
it’s a nice clean spike” (utterance 1) “and I can look at the  Simulation —> Alignment sequences. Thus most (79%) of
standard deviation around that and it’s pretty tight right in  the conceptual simulations were immediately followed by
the middle where it needs to be” (utterance 2) was coded as    an alignment, and most (93%) of the alignments
two instances of information extraction. Each utterance        immediately followed a conceptual simulation.
identifies a different piece of information extracted             The frequency of the Conceptual Simulation—>
(average, standard deviation). In all other cases, the count   Alignment sequence suggests a tight coupling between the
was based on the number of instances of the coded              two strategies. It appears that the scientists used conceptual
phenomenon. For example, the sequence “In a perfect sort       simulation to build a "mental model" of the data, based on
of spider diagram” (utterance 1) “if you looked at the         assumption that the hypothesis under evaluation was true.
velocity contours without any sort of streaming motions,       The scientists used the data on display and their domain
(utterance 2) “no, what I’m trying to say is, um, in the       knowledge to investigate the implications of the hypothesis,
absence of streaming motions,” (utterance 3) “you probably     by dynamically constructing a mental simulation of a series
would expect these lines here [gestures] to go straight        of processes. The result of this conceptual simulation was an
across, you know, the ring” (utterance 4) was coded as one     inspectable mental model that was used as the source of
conceptual simulation because each utterance contributed to,   comparison with the actual data in the alignment process.
but did not constitute, one conceptual simulation.             To the extent that the two models aligned, the hypothesis
   As Table 3 shows, the most frequent strategy used for       was supported; if there were relevant differences between
evaluating hypotheses was information extraction. This         the models, the hypothesis would be rejected. Figure 2
result is unsurprising, in that the scientists' task was to    illustrates this process of model-building and alignment.
examine and analyze the data; one would therefore expect

                                                                pertained to some expected phenomenon. The coding
                                   [Scientist proposes pattern  criteria for this categorization were adapted from Trickett et
           Hypothesis              displayed is caused by       al., 2000. In some cases, the scientists made explicit verbal
                                   streaming motions]
                                                                reference to the fact that something was expected or
                                                                unexpected. If there was no explicit reference, domain
                                                                knowledge was used to determine whether a phenomenon
              Initial               In a perfect sort of spider
                                    diagram,
                                                                was expected or not. A phenomenon might be associated
        Representation                                          with (i.e., identified as similar or dissimilar to) another
                                                                phenomenon that had already been established as expected
                                                                or not, or the scientist might question a phenomenon, thus
                                  if you looked at the velocity implying that it was not what was expected. This coding
                                  contours without any sort of  scheme was applied by two independent coders to a subset
           Simulation             streaming motions, no, what   of the data (the entire astronomy protocol), and agreement
                Run               I'm trying to say is, in the  between those coders was 87%. Table 4 provides examples.
                                  absence of streaming
                                  motions
                                                                     Table 4: Examples of expectation-violation hypotheses
                                    you'd probably expect                              (hypotheses in italics)
               Result               these lines here [gestures]
             (Source)               to go all the way across,        Domain                          Utterance
                                    you know, the ring,                            Computational model does not agree with
                                                                           CFD
                                                                                   the experiments in the least…It could be
                                                                   (submarine)
                                                                                   that the turbulence is all screwed up too.
           Alignment              without any sort of, um,                         That, that's odd…Why isn't there star
                                                                    Astronomy      formation going on there?…It may be
                                  changes here         in the
                                                                                   because of the large velocity dispersion.
              Target              slope and stuff
                                                                   After we coded the hypotheses as associated with
         Figure 2: Conceptual simulation as source of           expectation violation or confirmation, we counted the use of
                comparison in alignment process                 conceptual simulation and information extraction strategies
Why were conceptual simulations used?                           to evaluate each type of hypothesis. Note that the purpose of
   There were 57 elaborated hypotheses in these datasets,       the analysis was to determine the circumstances under
and 34 conceptual simulations. The high frequency with          which each strategy was used, not the frequency with which
which conceptual simulation was used as an evaluation           the strategy followed a hypothesis; thus, only the first
strategy indicates that its use is important and significant.   instance of each strategy use was counted. We performed a
Under what circumstances did the scientists use this            phi coefficient association measure. The correlation between
strategy? Conceptual simulations were used across a variety     hypothesis type and conceptual simulation was significant,
of criteria: in both group and individual settings, when the    rφ = .487, p < .01. There was no correlation between
data consisted of either images or numerical tables, in         hypothesis type and information extraction, r = .006. Table
exploratory and confirmatory analysis sessions, and across a    5 summarizes the results of this analysis.
variety of domains. It seems, therefore, less likely that
conceptual simulations were motivated by characteristics of                 Table 5: Strategy use and hypothesis type
the data than by some characteristic of the task.
   An examination of the structure of a conceptual                                Violate Expectation      Confirm Expectation
simulation reveals that its dynamic nature allows an              Conceptual
                                                                                           22                        3
understanding of the processes involved in constructing the       Simulation
revised mental representation of the relevant phenomenon.        Information
                                                                                           27                       20
Understanding process may be particularly important when           Extraction
there is significant uncertainty. For example, a poorly
understood phenomenon is likely to evoke more                            General Discussion and Conclusion
investigation than one that is well understood (Trickett,          The protocol data discussed above have provided a rich
Trafton, & Schunn, 2000). Thus we conjectured that the use      dataset by which to investigate the on-line thinking of
of conceptual simulation, with its associated construction of   working scientists analyzing data. The scientists develop
underlying process, was associated with attempts to account     hypotheses to account for the data and then evaluate those
for a phenomenon that violated the scientists' expectations.    hypotheses in light of theoretical knowledge and the data
   In order to investigate this possibility, the hypotheses in  itself. In contrast to results of laboratory studies of scientific
this dataset were categorized into those that attempted to      reasoning, the analyses presented above reveal that the
account for some expectation that wasn't met, and those that    scientists r a r e l y chose to evaluate hypotheses by

experimentation (including planning experiments). They          Giere, (Ed.), Cognitive models of science (pp. 3-44).
frequently used a strategy of conceptual simulation followed    Minneapolis, MN: University of Minneapolis Press.
by alignment. In particular, they used the conceptual         Nersessian, N. J. (1999). Model-based reasoning in
simulation-alignment strategy most often to evaluate a          conceptual change. In L. Magnani, N. J. Nersessian, & P.
hypothesis about something that violated their expectations.    Thagard (Eds.), Model-based reasoning in scientific
   Conceptual simulation is a process of mental model-          d i s c o v e r y (pp. 5 - 22). New York: Kluwer
building and manipulation that results in a revised mental      Academic/Plenum Publishers.
model, or “Qualitative Mental Model” (QMM) (Trafton et        Okada, T., & Shimokido, T. (2001). The role of hypothesis
al., 2000). This QMM serves as the source of an analogy         formation in a community of psychology. In K. Crowley,
that allowed the scientists to compare the QMM with the         C. D. Schunn, & T. Okada (Eds.), Designing for Science:
observed data and from there to evaluate the scientist’s        Implications from everyday, classroom, and professional
current hypothesis. Insofar as the QMM matched the data,        settings . Mahwah, NJ: Erlbaum.
the scientist found evidence for the hypothesis; in the
absence of a match, the scientist needed to revise the        Popper, K. R. (1956). The logic of scientific discovery (rev.
hypothesis. The alignment between source (QMM) and              ed). New York: Basic Books.
target (data) occurred as a series of mental processes, which Qin, Y, & Simon, H. A. (1990). Imagery and problem-
amount to a recreation of the processes that underlie the       solving. In Proceedings of the 12th Annual Conference of
external manifestation of the phenomenon of interest.           the Cognitive Science Society. Pp. 646-653.
                                                              Saner, L., & Schunn, C. D. (1999). Analogies out of the
                    Acknowledgments                             blue: When history seems to retell itself. In Proceedings
                                                                of the 21st Annual Conference of the Cognitive Science
This research was supported in part by grants N00014-00-        Society.
WX-20844 and N00014-00-WX-4002 to the 2nd author. We          Schraagen, J. (1993). How experts solve a novel problem in
thank Christian D. Schunn for comments on this research.        experimental design. Cognitive Science, 17(2), 285-309.
                                                              Schunn, C. D., & Anderson, J. R. (1999). The
                         References                             generality/specificity of expertise in scientific reasoning.
Clement, J. (1988). Observed methods for generating             Cognitive Science, 23(3), 337-370.
   analogies in scientific problem solving. Cognitive         Thagard, P. (1992). Conceptual revolutions. Princeton, NJ:
   Science, 12(4), 563-586.                                     Princeton University Press.
Dunbar, K. (1993). Concept discovery in a scientific          Trafton, J. G., Kirschenbaum, S. S., Tsui, T. L., Miyamoto,
   domain. Cognitive Science, 17(3), 397-434.                   R. T., Ballas, J. A., & Raymond, P. D. (2000). Turning
Dunbar, K. (1997). How scientists think: On-line creativity     pictures into numbers: Extracting and generating
   and conceptual change in science. In T. B. Ward & S. M.      information from complex visualizations. International
   Smith (Eds.), Creative thought: An investigation of          Journal of Human Computer Studies, 53(5), 827-850.
   conceptual structures and processes (pp. 461-493).         Trafton, J. G. & Trickett, S. B. (2001a). Note-taking for
   Washington, DC, USA: APA                                     self-explanation and problem-solving. Human-Computer
Ericsson, K. A., & Simon, H. A. (1993). Protocol analysis:      Interaction, 16(1), 1-38.
   Verbal reports as data. (2nd ed.). Cambridge, MA: MIT      Trafton, J. G. & Trickett, S. B. (2001b). A new model of
   Press.                                                       graph and visualization use. Proceedings of the 23rd
Gentner, D. (1983). Structure Mapping: A theoretical            Annual Conference of the Cognitive Science Society.
   framework for analogy. Cognitive Science, 7, 155-170.        Mahwah, NJ: Erlbaum
Gentner, D., Brem, S., Ferguson, R. W., Markman, A. B.,       Trafton, J. G., Trickett, S. B., & Mintz, F. E. (in press).
   Levidow, B. B., Wolff, Pl.& Forbus, K. D. (1997).            Connecting internal and external images: Spatial
   Analogical resoning and conceptual change: A case study      transformations of scientific visualizations. Foundations
   of Johannes Kepler. Journal of the Learning Sciences,        of Science.
   6(1), 3-40.                                                Trickett, S. B., Trafton, J. G., & Raymond, P. D. (1998).
Hegarty, M. (1992). Mental animation: Inferring motion          Exploration in the experiment space: The relationship
   from static displays of mechanical systems. Journal of       between systematicity and performance. In Proceedings
   Experimental Psychology: LMP, 18(5), 1084-1102.              of the 20th Annual Meeting of the Cognitive Science
Holyoak, K. J. (1985). The pragmatics of analogical             Society.
   transfer. In G. H. Bower (Ed.), The psychology of          Trickett, S. B., Trafton, J. G., & Schunn, C. D. (2000).
   learning and motivation (Vol. 19) (pp. 59-87). New York:     Blobs, dipsy-doodles and other funky things: Framework
   Academic Press.                                              anomalies in exploratory data analysis, Proceedings of the
Ippolito, M. F., & Tweney, R. D. (1995). The inception of       22nd Annual Conference of the Cognitive Science Society.
   insight. In R. J. Sternberg & J. E. Davidson (Eds.), The   Ueda, K. (1997). Actual use of analogy in remarkable
   nature of insight (pp. 433-462). Cambridge, MA, USA:         scientific discovery. In Proceedings of the 19th Annual
   MIT Press.                                                   Meeting of the Cognitive Science Society.
Klahr, D., & Dunbar, K. (1988). Dual space search during      Vollmeyer, R., Burns, B. D., & Holyoak, K. J. (1996). The
   scientific reasoning. Cognitive Science, 12, 1-48.           impact of goal specificity on strategy use and the
Nersessian, N. J. (1992). How do scientists think? Capturing    acquisition of problem structure. Cognitive Science,
   the dynamics of conceptual change in science. In R.          20(1), 75-100.

