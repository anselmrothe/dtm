UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Detecting the Local Maximum: A Satisficing Heuristic

Permalink
https://escholarship.org/uc/item/2nm1t2c7

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Authors
Sun, Yanlong
Tweney, Ryan D

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Detecting the Local Maximum: A Satisficing Heuristic
Yanlong Sun (suny@bgnet.bgsu.edu)
Ryan D. Tweney (tweney@bgnet.bgsu.edu)
Department of Psychology, Bowling Green State University
Bowling Green, OH 43403 USA

Abstract
In a simulated yard sale task, participants were asked to sell a
series of objects, each of which would attract three customers
making a randomly determined offer. Participants were told to
maximize the total "take" from the sale. The analysis of the
data revealed that high-performing naive participants were
using a strategy that made them relate the current event to the
seemingly irrelevant preceding events. We argue that this
strategy is consistent with Simon’s (1982) notion of
“satisficing heuristic”, which accounted for both partic ipants’
limited computation capacity and the task environment.

Introduction
Intuitive predictions and probabilistic judgments are often
used as tasks to evaluate people’s performance in judgment
and decision-making research, and a common scheme is to
collect incorrect predictions and misjudgments by “setting
up a ‘trap’ that subjects would fall into if they were using a
particular heuristic” (W. Goldstein & Hogarth, 1996, p.26).
In this type of research, predictions derived from probability
theory are often used as an objective criterion, and
violations of the normative models are labeled as biased or
irrational. Tversky and Kahneman’s “heuristics and biases”
program has been the most influential in this field. They
suggested that intuitive predictions and judgments are often
mediated by a small number of distinctive mental operations,
which they called judgmental heuristics. “These
heuristics … are often useful but they sometimes lead to
characteristic errors or biases” (Kahneman & Tversky, 1996,
p.582). For example, people’s tendency to use a small
sample of preceding events to evaluate an overall process
was attributed to a “representativeness” bias (Tversky &
Kahneman, 1973). This bias has been used to account for
many cognitive behaviors, such as the tendency to see
streaks in random sequences (Gilovich, Vallone & Tversky,
1985), and failure to “acquire a proper notion of regression”
(Tversky & Kahneman, 1973). In a recent study on
gambling behaviors, Thaler & Johnson (1990) concluded
that “current choices are often evaluated with the knowledge
of the outcomes which have preceded them, (but) such
knowledge can often be a handicap” (p.643).
However, the heuristics and biases research program has
recently been controversial, partly because “biases”
sometimes appear highly adaptive. Thus, Tweney &

Doherty (1983) argued that confirmatory tendencies
(“confirmation biases”) can be adaptive when hypotheses
are relatively new and untested. Further, in an extensive
series of studies, Gigerenzer and his colleagues (e.g. 1991,
1994, Gigerenzer & Todd, 1999) found evidence which led
them to strongly disagree with Kahneman and Tversky.
They argued that many seemingly naïve “fast and frugal
heuristics” are adaptive in an uncertain environment.
Similarly, Kareev, et al., suggested that the limited capacity
of working memory (hence the use of small samples) could
actually help the early detection of covariation since small
samples of correlated variables are highly skewed (Kareev,
1995; Kareev, Lieberman & Lev, 1997).
The present study followed Simon’s (1982) notion of
“bounded rationality”, which takes into account both
people’s limited computation capacity, and the structure of
task environments. Our findings suggest that under
circumstances when the precise prediction derived from
statistics or probability theory is not the only criterion,
heuristics based on a small sample size can be valuable.
With a satisficing strategy that only needs to “look for a
satisfactory alternative” (Simon, 1982, p.295), naïve
participants were able to effectively accomplish the goal of
the task, based on the evaluation of a few preceding events.

Recognizing the Maximum of a Sequence
The statistical properties of sequential lists of evidence
have long been of interest to mathematicians. The dowry
problem (or the secretary problem) is a classic example in
the dynamic programming literature, one analyzed by
Cayley in 1875 (see Ferguson, 1989). As a mathematical
problem, the dowry problem is difficult to solve, requiring
advanced mathematical knowledge and problem solving
ability. Obviously, few, if any, people are likely to work out
the exact stopping point mathematically in an everyday life
situation when a similar problem is encountered. Instead,
without complicated calculations, a player might need to use
“common sense” to make decisions. The present study
adopted a simplified version of the problem – a simulated
“yard-sale” task – to test how naïve people evaluate
preceding events and make decisions when facing sequential
events generated by an unknown process.
Participants were asked to sell a series of objects in a
simulated yard sale. Each object attracted three potential
buyers, each of whom came at a different time and made a

different offer. It was explained that offers that were
rejected would not return, so that the task was to guess
which was the best offer, and to take it when available.
Imagine that a person is selling a used car, and that
visitors with different offers come up in a random order.
After 5 offers have been declined in a week, a visitor comes
in with a price higher than any of the previous ones.
Another 5 offers will probably take another week and by
then this car must be sold. Whether to stop waiting and grab
the currently available offer then depends on how satisfied
the car owner feels about the current offer. The only
information available to evaluate the current situation is the
previous encounters. Probably, “common sense” would tell
this car owner to take the offer now, because future offers
might not get better.
This is in effect a satisficing heuristic (Simon, 1990),
which is a strategy that only needs to “look for a satisfactory
alternative” (Simon, 1982, p.295), as suggested by the
notion of bounded rationality. The strategy also fits the
category of fast and frugal heuristics suggested by
ecological rationality, because it makes “a choice from a set
of alternatives encountered sequentially when one does not
know much about the possibilities ahead of time”
(Gigerenzer & Todd, 1999, p.13).
We show that in at least one situation – when the random
process that generates offers is independently and
identically distributed – this satisficing strategy is optimal.
Let Ri denote the offer at time i, where i = 0 is the current
offer, -1 is the previous one, +1 is the next one, and so on.
Assume the car owner has encountered m R’s (from R-1 to
R-m) and found that R0 is the best one so far. If he actually
chooses it, because R0 now is the biggest number in a local
sequence of (m + 1) numbers, in the long run, the value of
such R0 has a good chance to be higher than the population
mean. For a continuous distribution from 0 to 1, the
expected value of such R0 is (m+1)/(m+2). Further, R0 might
just be a good stopping point because the potential gain
from the following n offers after R0 might not have a good
chance to get better. To see this, let A denote the event that
R0 is higher than its previous m offers, and B denote the
event that R0 is higher than its following n offers. Then two
prior probabilities can be described as
p(A) = p (R0 > R-1 , …, R-m) = 1/(m+1)
p(B) = p (R0 > R1 , …, Rn ) = 1/(n+1)
And the conditional probability can be calculated as
p(B|A) = p(AB)/p(A) = (m+1)/(m+n+1)
Note that, with a fixed n, p(B|A) approaches to an asymptote
of 1 as m increases. That is, with an appropriate m (after
considering a certain number of offers), the car owner can
make a better decision than a random guess. For example,
when m = 5, n = 5, p(B|A) is 6/11, and this favors selling. To
take the message of p(B|A) in another way, it has suggested
a stopping point, because the coming n offers do not have a
good chance to get better.

Two Optimal Strategies for the Yard Sale Task
With the development above, we can easily determine the
optimal strategy for the yard sale task. Suppose there is only

one trial in the task (only one object for sale). Let P1 denote
the first offer, P2 the second and P3 the third. Before
knowing any of the three offers, the prior probability for
each offer to be the best is equal:
p(P1 is best) = p(P2 is best) = p(P3 is best) = 1/3
Note that knowing the exact value of P1 does not change
this probability. With a random guess, the chance of hitting
any of the three possible prices is 1/3. However, if we skip
P1 and consider P2 , the conditional probability is no longer
equal. If P2 is higher than P1 , we should take it immediately
because p(P2 > P3 | P2 > P1 ) = 2/3. Otherwise, we should
take P3 . A pay-off matrix (Table 1) shows that the optimal
strategy (Option B*) is to always skip P1 . If P2 is better than
P1 , accept P2 ; if P2 is worse, choose P3 . This strategy
increases the chance of hitting the best offer to 1/2, with a
1/3 chance of hitting the middle price, and a 1/6 chance of
hitting the lowest one. For convenience, we will refer to this
strategy as the “one deal strategy”.
Table 1: The pay-off matrix for the seller
Option
A
B*
C

Rank orders of offers
LMH

MHL

LHM

MLH

HLM

HML

-1
0
1

0
1
-1

-1
1
0

0
1
-1

1
0
-1

1
-1
0

Total
0
2
-2

Note: L is the lowest price, M the middle, H the highest.
“LMH” means that the lowest price comes first, and so on.
Option A: always choose P1 (random guess).
Option B*: choose P2 if P2 > P1 , otherwise choose P3 .
Option C: choose P2 if P2 < P1 , otherwise choose P3
Gains: the seller gains –1 when hitting the lowest offer; 0
for the middle offer; 1 for the highest offer.
However, in a real-life situation, decisions are rarely made
in temporal isolation. Thus, as in a common scheme in
laboratory experimental settings, our yard sale task used
repeated trials to collect multiple data points from each
individual participant. This fact had a significant impact on
the optimal strategy. Recall that the single deal strategy
assumes that in each deal, the order in which three offers
appear is completely independent from any other events,
and requires that the first offer always be ignored. What if
the first offer actually is the best one? With the information
from the preceding trials, we can actually evaluate how
good the first offer is. Calculating an optimal strategy for
deals in a sequence is very complicated because it needs to
specify a distribution of three offers for each deal. However,
when distributions of offers in several deals within a local
sequence are similar, as an approximation, the principles we
presented above can be generalized. In our experiment, we
set the basic price for each object to range from $50 to $100,
with a maximum random fluctuation of ± $16. Figure 1
shows the overall distribution of these offers.

Method

0.15
0.10
0.05

40

50

60

70

80

90

100

110

120

130

Figure 1 The distribution of offers. N = 5760, x-axis is
price, y-axis is proportion.
The satisficing principle suggests that the offers for
previous objects (in previous trials) can be used to predict
whether you are getting a good offer for the next item. In
other words, when you are considering a first offer for a
table, if you can recall that the last several visitors, who
were seeking other items, were not as generous as the
current customer, you may want to sell the table right now.
It seems quite against a researcher’s intuition that a
normative strategy would predict that previous offers for an
umbrella will help to predict the current offers for a table,
especially when one thinks that the umbrella deal is “over”,
and the two deals should be independent. The answer to this
counter-intuitive puzzle is that the independence is only
partial. While the order in which different offers come out
for each deal is independent, the values of these offers, if
they are in the same or similar distributions, regress to the
population mean.
There are two ways to evaluate the first offer for a given
trial. The “local count strategy” is based upon a count of
the number of previous low offers. That is, if the current
first offer is higher than a certain number of previous offers
(for other items), take it. The optimal strategy depends on
the specific distribution of the random offers and the payoff
matrix. In our specific experimental setting, we used
computer simulations and found that the best number of
comparisons was 6. A modification of the local count
strategy, the “moving average strategy” compares the
current offer with the average of previous several offers. We
reasoned that participants might not remember the exact
values of the previous offer but might still have a vague
memory of the overall average in a short local sequence. A
logistic regression over simulated data showed that in our
experiment setting, the value difference of the first offer for
a given item from the mean of the previous 6 offers (for the
other two items), is significant as a predictor of whether the
first offer is the best among all three offers: χ2 (1, N = 1888)
= 191.03, p<.01. That is, as this difference increases, this
first offer is more likely to be the best of the three.
With this background, we were ready to find out whether
participants are good at detecting good offers when they
actually appear, and whether they use information from
previous encounters to help their current decision-making.

Participants were 15 undergraduate students from an
introduction to psychology class at Bowling Green State
University, none of whom had taken a course on game
theory or probability theory. We refer to them as novice
participants. One graduate student with extensive experience
in judgment and decision-making and related research also
participated, and will be referred as the expert participant.
The task was conducted using a self-paced computer
program. Each participant completed 120 trials (the number
of objects to be sold). One object was to be sold in each trial.
Participants could take any of the three offers at the time it
was available, but could not go back to an earlier declined
offer. Once an offer was taken, offers thereafter were not
presented. The third offer was forced if the first two were
rejected by the participant, and this was the only case when
participants knew exactly if they had hit the best out of three
offers. After each trial, participants were given a
confirmation that the object was sold at the price they
selected. Participants’ choices and their total earnings were
recorded. An average experiment session lasted about 25
minutes.

Results
Overall Performance To evaluate participants’ overall
performance, we ran a simulation 5000 times using each of
the three strategies: a random guess (randomly choosing one
of the three offers), the “single deal strategy” and the “local
count strategy”. Each time the simulation sold 120 items
using the actual selling list that was used in the experiment.
In the local count strategy, the first offer for each item was
compared with 6 previous offers (which were for the
preceding items 1 ). It was accepted when it was the highest
in the comparison. Otherwise, it was declined and the single
deal strategy was applied. Table 2 shows the simulation
results and the actual participant data.
Table 2 Comparisons between human participants and 3
simulations

Group
Random Guess
Single Deal
Strategy
Local count
Strategy
Human
Participants

N
5000

Mean Score
(95% confidence
interval)
8889.8 ± 2.0

Std
Dev.
72.74

5000

9160.7 ± 2.1

75.54

5000

9277.7 ± 3.4

121.22

16

9196.0 ± 31.0

58.15

Note that all 16 participants received a score that was at
least 1.5 SD above the mean of the random guess simulation.

________
1

When an offer was taken before all offers were presented, the
number of items whose offers were being compared may exceed 2.

Each participant’s score was then compared to the result as
if the single deal strategy had been applied to his/her actual
selling list. Ten participants’ scores were higher than the
result of the single deal strategy. Using the standard
deviation resulting from the single deal strategy simulation
(75.54), four participants’ scores were at least 1.5 SD above
the score resulting from the single deal strategy. We will
refer to these four as the “outstanding participants”.

Table 3.1 Compared to previous 1 offer

Strategy Use We looked at participants’ choice patterns in
regard to their consistency with the optimal strategies, at
three steps when each offer was being considered. The
following three choices are consistent with the optimal
strategies (single deal or multiple deals):
C1. Accept the 1st offer if it is better than several previous
offers (for other items).
C2. Decline the 1st offer, and accept the 2nd offer if it is
better than the 1st one.
C3. Accept the 3rd offer if the 2nd is worse than the 1st .
C2 and C3 are equivalent to the single deal strategy, now
separated into two parts. All three choices above are
consistent with the local sequence strategy. Since choices at
the 3rd offer were forced, whether participants’ actual
choices were consistent with the optimal strategies could be
looked at whether they had met or violated the conditions at
C1 and C2. Note that the single deal strategy actually
forbids C1. Specifically, C1 can result from considering the
count of the previous low offers (the local count strategy) or
the value difference of the first offer compared to the mean
of the previous offers (the local average strategy), and we
tested them separately.
Of all 16 participants, only the expert participant found
the single deal strategy, and followed C2 and C3
consistently. The 15 novice participants, by contrast, often
violated either C2 or C3 or both. However, to a significant
extent, their choices did follow C1. For each individual
novice participant, we ran a logistic regression, using the
value difference of the first offer from the mean of the
previous 6 offers, to predict the participant’s acceptances of
the first offers. Of the 15 participants, 11 showed significant
results at a 0.01 level. On the group level, the result is also
significant: χ2 (1, N=1770) = 304.69, p<.01. This indicates
that the novices were at least partly using the moving
average strategy.
Since the one deal strategy is a subset of the local count
strategy, we combined the 16 participants’ reactions on all
three offers to see if their behaviors were consistent with the
local count strategy. Table 3.1 and Table 3.2 show that they
did show such consistency when the previous 1 or 6 offers
were compared to the current offer. That is, if the offer
being considered was better than all of the previous 1 or 6
offers, participants were more likely to accept it. Otherwise,
they were more likely to decline it. This finding was
consistent with the local count strategy.

Table 3.2 Compared to previous 6 offers

Decline
Accept
Total

Decline
Accept
Total

Worse Better
1773
952
616
1424
2389
2376
χ2 = 580.177, p<.01

Worse Better
2397
328
1553
487
3950
815
χ2 = 114.140, p<.01

Total
2725
2040
4765

Total
2725
2040
4765

All of the 4 “outstanding participants” were novice
participants. However, they actually outperformed the
expert participant and the one deal strategy. They were
different from the other 11 non-expert participants in that
their behaviors were consistent with one of the requirements
of the one deal strategy (C2 and C3), although not both.
Their gains on the first offers when these offers were the
best had offset the losses from violations of the condition of
C2.
Learning across Trials In a study of the Monty Hall
dilemma, Granberg & Dorr found that participants showed
signs of learning across trials under certain conditions. In
our study, we also looked at whether there were systematic
changes in participants’ choices across trials. Specifically,
we suspected that participants might have learned the
specific distribution of random offers in earlier trials, so that,
in later trials, they only needed to recognize “globally big
numbers” instead of applying their heuristics independently
and locally. For example, an offer of $116 might have been
the best one for an item sold in an early trial. If participants
had this number memorized, they might just pick an offer of
$116 or higher in a later trial, no matter when this offer was
presented (whether it was the 1st , 2nd , or 3rd offer). If this
were the case, “big wins” might have been over-represented
in terms of participants’ uses of simple heuristics.
However, in our experimental setting, each item's 3 offers
varied around its own basic price. Although these basic
prices could be close, there was no way to tell that $116 was
the best offer for item A only because it had been the best
offer for item B. In other words, recognizing “big numbers”
alone would not help in optimizing the total performance. In
fact, when we partitioned each participant’s 120 trials into 3
blocks with 40 trials each, we did not find any significant
differences across blocks, indicating that learning was
probably not important across trials.

Discussion
None of the 15 novice participants found and consistently
used the one deal strategy. We reasoned that this was
because finding and consistently applying this strategy
required participants to use background knowledge in
probability theory, and they simply did not have this
training. Their consistency with the local sequence strategy
explained why they had good performances. This does not
suggest that they actually did the calculation and found the
correct mathematical solution, because this would require
even more knowledge and computational capacity, not to
mention that it was within a short experiment session.
However, as we suggested before, it is not necessary for a
person to work out the correct mathematical proof to use the
local sequence strategy. Such a strategy could arise from
participants’ everyday life experiences, from which they had
learned a simple satisficing heuristic: “grab any good
chance when you can”.
Surprisingly, the outstanding performers actually
outperformed the expert participant who found and
consistently applied the one deal strategy. This was because
the one deal strategy has to give up all opportunities of
accepting the first offers when they were the best. One
reason that prevented the expert participant from finding the
local sequence strategy might have been that the everyday
life heuristic had been “blocked” by his knowledge of
probabilistic judgment research. This finding is very similar
to Goldstein and Gigerenzer’s (1999) “less-is-more” effect,
that relative ignorance can actually benefit a decision maker.
By isolating the previous encounters from the current
decision-making situation, the expert participant had to
search the infinite probability space again, and previous
experience, either beyond or within the experiment task,
could not help.
In their 1973 paper, Kahneman and Tversky suggested
that “people do not acquire a proper notion of regression, …
they do not expect regression in many situations where it is
bound to occur”, because “regression effects typically
violate the intuition that the predicted outcome should be
maximally representative of the input information”. On the
contrary, the finding in this study that participants’
behaviors were consistent with the local sequence strategy,
indicated that people do have good intuitions about such
regression, and can also take advantage of it.
We argue that to evaluate naïve people’s probabilistic
judgment and decision-making, one has to take into account
both people’s limited computation capacity and the task
environment. One obvious message of the task was that, if
we had used the single deal strategy as the only criterion, we
might have concluded that participants were being irrational,
and would then have to face the puzzling evidence that they
actually performed very well. Instead, the results suggest
that the advantages of the satisficing principle are important
and cannot be ignored. By using these strategies, people can
benefit from their own experiences, even from a small
sample of preceding events.

References
Ferguson, T. S. (1989). Who solved the secretary problem?
Statistical Science, 4(3), 282-296.
Gigerenzer, G. (1991). How to make cognitive illusions
disappear: Beyond “heuristics and biases.” In W. Stroebe
& M. Hewstone (Eds.), European review of social
psychology. Chichester, England: Wiley.
Gigerenzer, G. (1994). Why the distinction between singleevent probabilities and frequencies is important for
psychology (and vice versa). In G. Wright & P. Ayton
(Eds.), Subjective probability. New York: Wiley.
Gigerenzer, G., & Todd, P. M. (1999). Fast and frugal
heuristics: The adaptive toolbox. In Gigerenzer, G., Todd,
P. M. & the ABC Research Group (Eds.), Simple
heuristics that make us smart. New York: Oxford
University Press.
Gilovich, T., Vallone, R., & Tversky, A. (1985). The hot
hand in basketball: On the misperception of random
sequences. Cognitive Psychology, 17, 295-314.
Goldstein, D., & Gigerenzer, G. (1999). The recognition
heuristic: How ignorance makes us smart. In Gigerenzer,
G., Todd, P. M. & the ABC Research Group (Eds.),
Simple heuristics that make us smart. New York: Oxford
University Press.
Goldstein, W. M, & Hogarth, R. M. (1996). Judgment and
decision research: Some historical context . In Goldstein,
W. M & Hogarth, R. M. (Eds.), Research on judgment
and decision making: Currents, connections, and
controversies. New York: Cambridge University Press.
Granberg, D., & Dorr, N. (1998). Further exploration of
two-stage decision making in the Monty Hall dilemma.
American Journal of Psychology, 111(4), 561-579.
Kahneman, D., & Tversky, A. (1973). On the psychology of
prediction, Psychological Review, 80, 582-591.
Kahneman, D., & Tversky, A. (1996). On the reality of
cognitive illusions, Psychological Review, 3, 582-591.
Kareev, Y. (1995). Through a narrow window: Working
memory capacity and the detection of covariation.
Cognition, 56, 263-269.
Kareev, Y., Lieberman, I., & Lev, M. (1997). Through a
narrow window: Sample size and the perception of
correlation. Journal of Experimental Psychology: General,
126(3), 278-287.
Simon, H. A. (1982). Models of bounded rationality, Vol.3,
Cambridge, MA: MIT Press.
Simon, H. A. (1990). Invariants of human behavior, Annual
Review of Psychology, 41, 1-19.
Thaler, R. H., & Johnson, E. J. (1990). Gambling with the
house money and trying to break even: The effects of
prior outcomes on risky choice. Management Science, 6,
643-660.
Tversky, A., & Kahneman, D. (1974). Judgment under
uncertainty: Heuristics and biases. Science, 185, 11241131.
Tweney, R. D. & Doherty, M. E. (1983). Rationality and the
psychology of inference. Synthese, 57, 139-162.

