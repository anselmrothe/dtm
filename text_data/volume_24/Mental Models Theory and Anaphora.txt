UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Mental Models Theory and Anaphora
Permalink
https://escholarship.org/uc/item/9rk7d625
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Boella, Guido
Lesmo, Leonardo
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                 Mental Models Theory and Anaphora
                                             Guido Boella and Leonardo Lesmo
                               Dipartimento di Informatica and Centro di Scienza Cognitiva
                                                      Università di Torino
                                              email: guido, lesmo @di.unito.it
                          Abstract                                 that comprehension results in the construction of repre-
                                                                   sentations of situations in the real world [...] These mod-
   We argue that anaphora cannot be resolved at the level          els are finite and computable, and they are constructed
   of the formal language representing meaning, but, rather,       incrementally, with the model so far acting as part of the
   by making direct reference to the extension of the sen-
   tences. Johnson-Laird’s mental models theory provide            context for interpreting the current text. (p.20)
   the tool for coping with extensional representations in a          A simple preliminary example illustrates our solution.
   cognitively plausible way.                                      In the following sentences, the acceptability is guaran-
                                                                   teed just for the pair where the (intended) antecedent (a
                                                                   donkey) and the pronoun (they) do not agree in their syn-
                       Introduction                                tactic number:
Anaphoric expressions are traditionally viewed as sub-             (1) Every farmer owns a donkey. *It is pink.
stitutes for more complex linguistic expressions which             (2) Every farmer owns a donkey. They are pink.
have already occurred earlier in the text. Anaphora has            When the second sentence in each discourse is inter-
proven difficult to analyze at a purely syntactic level,           preted, it produces a mental model which must be
so that structural approaches like DRT [10] or semantic            integrated with the preceding one: a referent must
ones like Dynamic Semantics [4] cope with this problem             be found for the anaphoric expressions. If we ex-
by enriching the formal language used to build or to rep-          amine in the Figure below how the first sentences
resent the meaning of sentences.                                   of the two pairs are represented in mental models
   We believe that the limit of these approaches is that           theory, we see that the problem is easily solved.
they have chosen the wrong level of representation for             The        mental
dealing with anaphora: we will show that it is necessary           model contains                       own
                                                                                                 f             d
to make direct reference to extensional representations            a finite num-                        own
of meaning. In particular, the representation of the con-          ber of tokens                 f             d
text should put at disposal the elements of the situation,         (placeholders                 f
                                                                                                        own
                                                                                                               d
which anaphors can refer to, instead of hiding them be-            for individuals,
hind quantified expressions.                                       here farmers       and donkeys ) and relations among
   However, extensions can possibly be infinite or too             tokens (the arrows labeled with own). Given the model
large to be dealt with directly. But there is a proposal           above, which donkey, out of the represented ones, can
which uses extensional representations of finite and lim-          we relate to the singular it, appearing in the second
ited size, and which has been shown to be cognitively              sentence of (1)? The problem of identifying the referent
plausible, i.e., the mental models theory of [9]. Johnson-         appears to be the same as in: (3) I have three sisters.
Laird has used mental models in order to explain how               *She is blonde where we have to choose one referent
people reason without having to resort to formal logic.            out of three candidates. One is given no (or not enough)
Inferences are performed by manipulating extensional               information to identify the antecedent (among the three
representations of sentences which are composed of a fi-           sisters) denoted by she. On the contrary, the they
nite number of elements and relations: “a mental model             pronoun in (2) can be interpreted as referring to the set
represents the extension of an assertion, i.e., the situation      of donkeys appearing in the model, due to its plural
it describes, and the recursive machinery for revising the         syntactic number.
model represents the intension of the assertion, i.e., the
set of all possible situations it describes.” (p.100)                   The mental model building algorithm
   In [8]’s words: “mental models theory is a psycholog-           First of all, the sentence undergoes a syntactic and se-
ical theory of language processing and reasoning. The              mantic interpretation process that produces a semantic
theory provides a framework within which more detailed             network (see [6], [11] and [2] for details on the network
accounts of the component processes of comprehension               representation). Then, following the proposal by [9], that
[...] such as anaphora interpretation [...] and reasoning          “a propositional representation can be used as the input
can be developed, [...] Mental models theory assumes               to a procedural semantics that constructs mental mod-

els”, a mental model representing the meaning of the sen-
tence is built.                                                                  agt        obj
                                                                           set ind          set ind
The network representation                                                       agt        obj
For the present purposes, we will describe briefly                         set ind          set ind
only the mechanism of Distributivity Ambiguity Spaces                            agt        obj
(DAS) which deals with the possible distributive read-
ings of an NP (see [11] for details).                                      set ind          set ind
                                                                                 agt        obj
The nodes of the network can be simple or DASs. The                                  DEP-ON
latter correspond to plural NPs, and they were introduced                  set ind          set ind
to deal with the distinction between collective and dis-                         agt        obj
tributive readings of predicates: each DAS includes two                    set ind          set ind
subnodes Set and Indiv.                                                          agt        obj
   In case of (4) Three men lifted three tables, if the sub-                         DEP-ON
ject NP is given a reading as a set, the men are seen as be-               set ind          set ind
ing jointly involved in the act of lifting tables. Viceversa                   Figure 1: Six readings of (4).
in the individual reading of the subject, each man exe-
cuted a separate lifting act. If the tables are interpreted as
a set too, they were lifted all together (perhaps they were    A relation is an ordered sequence r, x , . . . , x , A
stacked). On the contrary, if they are interpreted as indi-    where r is a relation symbol, x , . . . , x are tokens in
viduals, the men lifted them one at a time. The four com-      T and A is a set of annotations. Annotations are “the
binations of Set, Indiv readings for the subject and the       propositional enrichment of the analogical structure of
object do not cover all possibilities. In fact, it may hap-    the model” [1]. In particular, the “not” annotation ap-
pen that, for the Indiv reading of the subject, there exist    plies to any feature of the models. For models and re-
just three tables, and each man lifted one of them (three      lations, a negation means that they are not the case; for
individual lifting acts); or that each man lifted three ta-    entities, that they are absent in a model. The “...” anno-
bles (possibly, but not necessarily, the same three tables;    tation means that the model can be further extended.
9 different tables could be involved), so that nine individ-   [1] consider relations such as ‘above’, ‘faster’ and two
ual lifting acts have been executed. Or, in the Set reading    special relations “connected with” (CW) and “never con-
of the object, the three men lifted three different stacks     nected with” (NCW). The CW relation forms an individ-
of tables (so, we have two more readings, for a total of 6)    ual by connecting two of its properties. The NCW one
The extra readings (see Figure 1) are accounted for by         states that two properties cannot hold for the same indi-
means of a mechanism other than the DAS described              vidual. Usually the two relations are used to represent
above (but independently motivated, see [11]), i.e. by the     the meaning of, respectively, all humans are mortals and
presence of DEP-ON (dependent on) arcs. They are sim-          most lawyers are not poor. With respect to [1]’s frame-
ilar to Skolem functions in first order logic, and were in-    work, we introduce an extension for what concerns the
troduced for representing quantifier scoping. Each node        NCW relation. In fact, NCW is originally meant to apply
which is not universally quantified can be specified to be     only to unary predicates such as being humans or mortal.
dependent on another ‘plural’ node. For instance, in Ev-       We introduce a version of the NCW relation relativized
ery farmer owns a donkey, the most natural reading is          to a predicate rel, NCW(rel). In fact, the “not” annota-
where each farmer owns a different donkey, so that the         tion of a relation means that the relation is not true of the
particular donkey ‘depends on’ the particular farmer.          given entities involved in the relation. In faster, john,
                                                               bill, not , the negation does not concern the existence
Mental models                                                  or not of the two individuals John and Bill, which are in-
In order to use a more unambiguous version of the frame-       troduced as existing entities. But this is not sufficient to
work with respect to the ‘diagrammatic’ original version       represent the meaning of a sentence like John does not
of [9], we refer to the formalization of mental models         have a car: since the phrase a car inside a negation does
provided by [1].                                               not introduce or refer to an entity in the model, the mean-
   According to [1], a model is triple T, R, A , where         ing of the sentence cannot be represented by the negation
T is a (non-empty) bi-dimensional matrix of tokens, R is       of the ‘have’ relation: in fact, a relation as have, john,
a set of relations on T, and A is a set of annotations. For    c , not       does not express the fact that from the model
dealing with some interpretations, more than one model         it is not possible to infer that there is a car. Rather, this
can be required.                                               annotated relation expresses the fact that there is a car in
A token is either a model or an element. An element is         the model and John is not its owner.
a pair S, A where S is a symbol from a given vo-               What we need is something similar to the interpretation
cabulary and A is a set of annotations; the vocabulary         of the sentence no lawyer is a crook from which is not
consists of named individual entities (john for the proper     possible to infer that there is some crook in the model.
name John) and generic entities belonging to some cate-        The model of this sentence in [1] is not represented by a
gory (c for cars, f for farmers, etc.).                        negation of some predicate ‘is’ but with the NCW rela-

 tion discussed above: NCW, lawyer , crook . Anal-                treatment of syllogism in [9]).
 ogously, for interpreting John does not have a car we            A special case, as in the mental models theory of
 introduce a NCW(have) predicate, which not only ex-              [9], is represented by the quantifier no: its meaning
 presses the negation of the “have” predicate, but which          is represented by selecting all the tokens F represent-
 also does not assert the existence of any car (see the Fig-      ing the denotation of the noun it quantifies (Q(F)=F);
 ure below).                                                      but when the relation rel involving the NP is intro-
    In        NCW(have),                                          duced, it is interpreted as negated either in the sense
 john, c ,       , cars, as                                       of a NCW(rel) relation or in the sense of being an-
 in      NCW, bicycle ,                                           notated as negated. As an example, in no farmer
 c,           (no bicycle                                         owns a donkey the owning relation, is transformed in a
 is a car), are kept separate from the other entities in          NCW(own) relation which keeps apart all the farmers
 the model: they cannot play the role of antecedents of           from the set of donkeys.
 pronouns.                                                        (c) If the NP is an indefinite such as a car, two cases
    For what concerns the treatment of logical connec-            are possible according to the presence of a negation
 tives, we stick to the proposal of [1].                          and the role played by the NP in the main predicate:1
 From the network to the mental model                                  If the NP is the subject of the verb or it appears
                                                                       in a non-negated relation, a single new token rep-
 The model constructing procedure takes as input an ex-
                                                                       resenting a car is added to the matrix T of the model
 isting mental model (representing the context) and the
                                                                       and annotated as “...”, since it does not convey any
 network representation of the new sentence (still asso-
                                                                       uniqueness presupposition.
 ciated with the syntactic tree): the newly constructed
                                                                       If the NP appears in a negated predicate and it is not
 model is integrated with the existing ones by overlapping
                                                                       the subject of the predicate rel, some tokens repre-
 identical tokens and finding referent tokens for anaphoric
                                                                       senting the denotation of the noun F = x , . . . , x
 expressions.
                                                                       are introduced in T and appear in a NCW(rel) rela-
    The process starts from the non-dependent entity                   tion to keep them separate from the other tokens of
 nodes of the network which derive from the interpreta-
                                                                       the model.2
 tion of NPs (i.e. NPs without exiting DEP-ON arcs), and
 proceeds with the other NPs, according to the (partial)          (d) If the entity in the network W is the interpreta-
 order imposed by (reversed) DEP-ON arcs. After that,             tion of a definite NP or a definite pronoun, then an
 all co-references are solved. For instance, in (5) Every         antecedent must be searched for in the mental model
 farmer who owns a donkey beats it, every farmer is pro-          constructed so far; according to the number, one or
 cessed first, then a donkey and, the pronoun it which de-        more tokens existing in the model are sought in T to
 pend on the subject NP.                                          act as the potential referents: further, the set of rela-
    More precisely, given a context M composed by a               tions R must satisfy the description provided by the
 model T, R, A , we have that a network W is inter-               NP. This kind of unification, however, cannot be ac-
 preted as a new model T , R , A , in the following               complished with items which are linked to other ones
 way:                                                             only by a NCW(rel) relation in which they appear in a
1. Each non-dependent entity node in the network W de-            non-subject role t               rel, x , . . . , x ( NCW(rel),
    riving from the interpretation of an NP is treated sep-       x , ..., t , ..., x ,             R i 1 ) , i.e., these items
    arately:                                                      are implicitly assumed as ‘non existing’ in the model.
                                                                  Moreover, if the set of possible referents X = t , . . . ,
    (a) If the entity node is represents an NP which is           t        is composed of a subset of tokens which occur
    a proper noun (e.g., John), an individual token (e.g.,        in relations with other tokens and a subset of tokens
    john) is introduced in the matrix T of the model M;           which are unrelated:
    if that token is already present in the model, the two           t       rel, A, x , . . . , x ( rel, x , . . . , t , . . . , x , A
    tokens are identified.                                             R)         t         rel, A, x , . . . , x ( rel, x , . . . , t ,
    (b) If the NP is a quantified Noun (e.g., every farmer),      ..., x , A           R)
    a set of distinct tokens F = x , . . . , x representing       then only the former set can be considered by the uni-
    the denotation of the noun is added to the context ma-
                                                                    1
    trix T; depending on the quantifier Q, a subset of them,          Note that John does not love a girl in his office where the
    Q(F), will be selected for linking to other tokens by the  indefinite is a specific one (see [10]) and the speaker could iden-
                                                               tify a unique referent for it, is not covered by this rule.
    relation where the NP occurs as an argument (selecting          2
                                                                      This treatment of indefinites is justified also from a linguis-
    the whole set in case of every and all, a proportioned     tic point of view. As [10] notice, the negation of a verb must
    subset of it in case of most, etc). The annotation A of    be interpreted as having an inner scope which does not include
    the model can be augmented with a             , since, de- the subject of the verb, otherwise sentences as someone does
    pending on the quantifier, more tokens could be added      not like a Porsche would be true in case there is no people at
                                                               all. And it finds a similarity in DRT where indefinites inside the
    to the matrix T or the set        could be revised (e.g.,  scope of a negation are interpreted in a subordinate DRT struc-
    if =“some”,              could be initially 2 or 3, but it ture which will not be accessible for the resolution of anaphoric
    can be increased in case of necessity, as in the standard  expressions.

   fication process (e.g., in the interpretation of John has             come part of the context. When a subsequent sentence
   many donkeys. They are pink where the model in-                       is interpreted, its interpretation must be compatible
   cludes a number of donkeys but only a subset of them                  with all the models in the context. In particular, if
   is related with John: the pronoun they refers only to                 the interpretation of the subsequent sentence produces
   this subset).                                                         more than one model, for each model in the context,
   Note that the set of annotations is not constrained to                at least one of the newly constructed models must be
   be empty: in fact, it is possible to make reference to a              compatible (even if not the same one for all the model
   set of entities which is involved in a negated relation               in the context). Otherwise, the sentence will be re-
   as in: (6) the soldier didn’t see some of the enemies.                jected (as in example (14) below).
   They were hiding in the trees.
   Finally, since a definite pronoun is a definite reference,                           Logical connectives
   the found referent must be non-ambiguous: if differ-              According to [10] the interplay of anaphora and logical
   ent possibilities exist, then, for pragmatics reasons, the        connectives is a fundamental testbed for any theory of
   reference fails (see example (3)).                                language interpretation. Here, the meaning of connec-
2. If the entity node of the NP np is “dependent on” an-             tives is expressed by their possible models in [9]’s style.
   other node which is built from the NP np , its inter-             First the implicit models are constructed and if necessary
   pretation depends on the one of np : this means that,             the explicit ones are fleshed out.
   for each token built in correspondence with np the in-            Let’s start with a simple example involving negation: (7)
   terpretation of np must be repeated according to the              *John does not own a car. He washes it.
   rules in 1 described above for non-dependent NPs. In              Since, according to the representation outlined in the pre-
   particular, if np is a singular indefinite and the cor-           vious section, cars are included in NCW(own) relations,
   responding relation is not negated, a new token is in-            no referent can be found in the model for the pronoun it:
   troduced for each token associated with np ; if np is                  T=      , c , john, , , R=            NCW(own), john,
   plural, a different set of example tokens is added to the         c ,      , A=
   model for each token associated with np .                         So, the sentence is not interpretable according to that
   For example in the distributive interpretation of Every           reading.
   farmer has a donkey. They beat it, they is unified with           An example a bit more complex is: (8) No farmer has a
   the tokens f , . . . , f representing farmers, but the in-        car. *It is red.
   terpretation of it (which in this reading cannot but be           A sentence like no farmer is rich is represented by a
   dependent on them) is performed for each f (1 i                   NCW relation between farmers and rich people see rule
   n) relatively to the set of tokens t           rel, x , . . . , x 1.b. In our model, this relation is extended to arbitrary
   ( rel, x , . . . , f , . . . , t , . . . , x ,   R) . In the      predicates. Hence, the first sentence produces a model
   example, for each i, it is unified with the d such that           where cars appear in the set of never connected with en-
      beat, f , d ,     .                                            tities, so that the interpretation (and failure in integration)
                                                                     is exactly the same as in the previous example:
3. Finally, the tokens are linked by the relations described             T=         ,c    ,c     ,c , f , , f , , f ,
   by the predicates. The number of relations which are                , R=       NCW(own), f , c ,           , NCW(own), f ,
   introduced depends on the set or individual interpre-             c ,         , NCW(own), f , c ,             , A= ...
   tation of the DAS of the NPs involved: if an NP is                On the contrary: (9) No farmer has a car. They prefer
   considered as a set, the tokens resulting from its inter-         donkeys. is acceptable, in spite of the negation appearing
   pretation are included as a whole in the role they play           in the subject NP and of its singular number. In fact, the
   in the relation. Otherwise, each element of the set is            farmers (appearing as ‘existing’ entities) are available for
   introduced in different instance of the relation.                 integration.
4. As we discuss in the following Section, the interpreta-               If we now consider conjunctions and disjunctions, an-
   tion of a sentence which includes logical connectives             other interesting anomaly arises:
   can result in more than one model. The rule 1 is iter-                (10) John owns a car and Fred washes it
   ated for each of the clauses in the complex sentence.                 (11) *John owns a car or Fred washes it
   During the interpretation process some of the possi-              The syntactic structures are identical but the acceptabil-
   ble models must be discharged as inconsistent. This               ity is not. In order to explain this fact, [10] introduced
   is a correct move but it can lead to the refection of             an accessibility constraint at the structural level: “no dis-
   the sentence for pragmatic reasons (as in example (11)            junct of a disjunctive condition is accessible from any
   below). In fact, if the interpretation of a sentence re-          other”.
   sults in a reduced set of models which can be better                  The mental model representation of a conjunction in-
   described by another sentence (that is, its interpreta-           volves the inclusion in the same model of the conjoined
   tion does not discard any model), then by the Gricean             sentences. So, no problem arises with (10), since the ref-
   principle of cooperation, the speaker should have used            erent for it can be found in the same model where the
   it instead of the one he chose.                                   second conjunct must be integrated. Compare the unac-
5. On the other hand, if the interpretation of the sentence          ceptability of *John does not have a Porsche and Fred
   leads felicitously to a set of models, these models be-           washes it.

   On the contrary, a disjunction A B requires the con-     car, in fact, is connected with a NCW relation). As pre-
struction of two separate models (one with A and one        scribed by rule 4 of the algorithm, a new sentence must
with B). So, in the second model of (11) there is no        be integrated with all the pre-existing models in the con-
available referent for the pronoun (B, i.e., Fred washes    text, otherwise it is unacceptable.
it). But when a difficulty (such as the impossibility of       An analogous reasoning explains the oddity of *If
understanding a sentence) occurs in a mental model, the     John does not own a car, Fred washes it. Moreover,
model can be manipulated and fleshed out; in principle,     so called examination sentences as (15) no students will
when applied to the second model (B), this process could    be admitted to the exam unless they have registered four
produce two alternatives. In the first one John owns a car  weeks in advance can be dealt with by interpreting the
(A and B), while in the second one he does not (not A       conjunction unless as an if not or a stronger exclusive or.
and B, i.e., John does not have a car and Fred washes
it). So, it seems that the first extension could solve the                            Plurals
problem: John, in fact, owns a car and Fred washes it:      A number of interesting anaphoric phenomena are re-
                                                            lated to plurals. The first situation concerns a plural pro-
                                                            noun referring to a set of singular antecedents which oc-
                                                            cur in the model: (16) Mary met John. They talked.
                                                               Even if in mental models the first sentence introduces
                                                            separately two tokens, the rule 1.d can cope with these
                                                            case as if they were introduced simultaneously as by the
                                                            NP two people. So it can resolve the anaphora without
The lower part of the figure shows the three resulting      explicitly summing the antecedents to form a plural dis-
models: the second one (A and B) includes the first (A)     course referent, as DRT does.
and the third (not A and B) is discharged since Fred can-      Quantifier phrases such as many of the farmers do not
not wash a car which does not exist (see the * in the third always introduce the referents with which subsequent
box).                                                       pronouns will be co-referential. For example, those pro-
However, it seems that from any disjunction at least two    nouns refer to sets that have to be constructed from ex-
distinct models must be constructed, and that none of       plicit information in the text. Here, quantifiers introduce
them must be included in the other: otherwise, the com-     in the model a set of tokens which pronouns can refer to
mon part of the two models would be necessarily true        in the subsequent discourse: (17) Susan has found every
and according to Grice, the speaker should not have used    book which Bill needs. They are on his desk.
a disjunction to express such a meaning (see rule 4 of the  To resolve they we need only the set of tokens introduced
interpretation algorithm).                                  in the model by the analysis of the first sentence. The
   An example that supports the previous analysis is the    right subset of books is identified in the model thanks to
acceptability of the following sentence, as the reader can  rule 1.d (see discussion below). In DRT, in contrast, a
easily test: (12) John does not own a car or he washes      new discourse referent is constructed via an abstraction
it. The second model (the one of he washes it) can be       rule which copies the content of the DRSs introduced by
fleshed out with the negation of the first disjunct (not A  the previous sentence.
and B, i.e., John does own a car and Fred washes it):          In some approaches, definite NPs and pronouns inside
after this extension, the resulting model puts at disposal  the scope of a quantifier are considered like bound vari-
the required referent for the pronoun. We are left with     ables in a logical system. In (18) every waiter wants cus-
two different models, equivalent to the [10]’s interpreta-  tomers to give him large tips the pronoun does not seem
tion of the example, i.e John does not own a car or John    to refer to any particular entity, while it does in (19) John
owns a car and he washes it. In [10] this result is ob-     wants customers to give him large tips. DRT in order
tained by copying the negation of the first conjunct in     to deal with both cases in a uniform way introduces the
the second DRS: such a rule, however, presupposes that      notion of discourse referent which does not correspond
disjunctions in natural language are always interpreted a   directly to any individual in the world, while providing
exclusive disjunctions.                                     antecedents for the pronouns.
It is interesting to note that Dynamic Semantics [4], in    In contrast, mental models theory allows unifying both
order to explain this kind of examples, has to introduce a  cases, since quantifier phrases, in an extensional repre-
new class of anaphora, E-type.                              sentation introduce sets of entities in the model.
   The last connective to be considered is implication:        Not all definite pronouns following quantifiers behave
(13) If John owns a car, he washes it.                      like bound variables, in particular, if they appear in a fol-
This sentence involves two models (A and B, and not A       lowing clause, i.e., outside the quantifier scope: (20)
to be further extended): in the first one, John owns a car  few congressmen admire Kennedy and they are very ju-
and washes it, while in the second one he does not own      nior. They refers to those (few) congressmen who admire
any car. But, if the sentence is followed by (14) *It is    Kennedy, even if there is no such an expression referring
a Porsche, the pronoun of the second sentence can find      to them. If the pronoun were interpreted as a variable, the
a referent only in the first model in the context, while    sentence would be equivalent to (21) Few congressmen
no antecedent is accessible in the second one (where the    admire Kennedy and are very junior. In [5]’s terms, there

is an antecedent trigger, a linguistic expression which          Similarly, the so called donkey sentence, (27) Every
introduces the antecedent of the pronoun but it does not     farmer who owns a donkey beats it, is acceptable: the
have the same referent of the pronoun.                       procedure first interprets the subject phrase, thus obtain-
In our model, after the interpretation of the first clause   ing, in the wide-scope reading of the universal, a repre-
the mental model contains the set of congressmen and a       sentation where each farmer has at least a donkey; then
(small) subset of them which are in an “admire” relation     it extends the representation by searching for a referent
with Kennedy. For rule 1.d above, the definite pronoun       through each relation own, f , d ,            ; so, in the dis-
they can be resolved with this subset.                       tributive reading the sentence, as in the example above,
   But as it might be expected, quantifiers focus on the     for each farmer, a different referent for it is found, i.e. the
subset of the set specified by the head noun. Hence, the     donkey owned by him. The possible antecedent must sat-
unification process must be suitably constrained. In: (22)   isfy the restriction carried by the number of the singular
Some farmers of this valley own a donkey. They don’t like    pronoun (compare *Every farmer who has two donkeys
cars, the pronoun they can in principle refer either to the  beats it).
farmers of this valley who own a donkey or to the com-
plement set; according to rule 1.d in the interpretation                             Conclusion
algorithm, if the set of candidate referents can be parti-   Since mental models are a cognitively plausible theory
tioned in different sets, the pronoun is unified only with   of human reasoning, they can be also useful in finding
the entities which are involved in a relation (of owning a   an explanation of linguistic phenomena. In [3], we ex-
donkey).                                                     ploited mental models to provide an explanation of lex-
   The possibility of a plural anaphor resolved against      ically triggered presuppositions. In [2] more complex
referents described by a singular indefinite is explained    anaphorical phenomena related to the different readings
by rule 1.d which deals with the interpretation of depen-    of donkey sentences have been coped with in the same
dent NPs in distributive readings (see the Figure on first   framework.
page). In (23) Every farmer owns a donkey. They are              The limit of logical approaches in explaining anaphora
pink the distributive reading expresses explicitly the plu-  is that they exploit representations that are not isomor-
rality of donkeys so that the correct referents are avail-   phic to our conception of the described situation. The
able for the plural pronoun. In contrast, in (24) Every      necessity of resorting to a referential level in explain-
farmer owns a donkey. *He is a wise man, the singular        ing anaphora has been highlighted also by [7]. We
definite pronoun he cannot be resolved, since we do not      followed his suggestion, but going in a different direc-
have any information to choose one of the farmers (see       tion, where mental models replace the classical model-
rule 1.d).                                                   theoretic framework to provide a cognitively plausible
An example slightly more complex is: (25) Three farm-        approach to language interpretation.
ers own a donkey. They beat them. The latter sentence
can be interpreted only as far the second clause is inter-                           References
preted with two individual readings of the NP without          [1] B. Bara, M. Bucciarelli, and V. Lombardo. Model theory
DEP-ON arcs between them (case 3 of Figure 1). In this             of deduction: A unified computational approach. Cogni-
                                                                   tive Science, 25(6), 2001.
case the donkeys who form the antecedent of them are re-
                                                               [2] G. Boella, R. Damiano, and L. Lesmo. Beating a don-
lated each by a different relation with the farmers. Which         key: a mental model approach to complex anaphorical
farmer is selected for relating with the beating relation to       phenomena. In Proc. of European Congress of Cognitive
a given donkey? as in case of rule 2 the interpretation            Science of ECCS’99, Pontignano, 1999.
of an anaphor is performed exactly with respect to the         [3] G. Boella, R. Damiano, and L. Lesmo. Mental models
other tokens which are linked to it by some relation. In-          and pragmatics: the case of presuppositions. CogSci99
                                                                   Conference, 1999.
deed, in the context is maintained the relation between
                                                               [4] G. Chierchia. Anaphora and dynamic binding. Linguistics
each farmer and the donkey he owns: hence, the inter-              and Philosophy, 15:111–183, 1992.
pretation of the sentence leads to a situation where each      [5] F. Cornish. Antecedentless anaphors: Deixis, anaphora or
farmer beats the donkey he owns, and not a different one           what? Journal of Linguistics, (32):19–41, 1996.
(as it happens in some formal models of anaphora).             [6] B. DiEugenio and L. Lesmo. Representation and interpre-
Finally, plural and singular pronouns can be mixed: (26)           tation of determiners in natural language. In Proc. 10th
                                                                   IJCAI, pages 648–653, Milano, 1987.
Every farmer owns a donkey. They beat it. Since it
                                                               [7] D. A. H. Elworthy. A theory of anaphoric information.
in the second sentence is dependent on the subject they,           Linguistics and Philosophy, 18:207–332, 1995.
the interpretation of the second sentence is parallel to the   [8] A. Garnham. Mental models and the interpretation of
interpretation of the first: the object (it) can be resolved       anaphora. Psychology Press, Hove, 2001.
against an antecedent only if it is interpreted as depen-      [9] P.N. Johnson-Laird. Mental Models. Cambridge Univer-
dent on the subject; according to rule 1.d of the interpre-        sity Press, Cambridge, 1983.
tation algorithm, they is unified with the set of farmers    [10] Hans Kamp and Uwe Reyle, editors. From Discourse to
appearing in the model and, again, since there is an ex-           Logic. Kluwer, Dordrecht, 1993.
plicit relation (own) linking each of them to a donkey,      [11] L. Lesmo, M. Berti, and P. Terenziani. A network for-
                                                                   malism for representing natural language quantifiers. In
this link is followed to determine the (singular) referent         Proceedings of ECAI-88, pages 473–478, 1988.
of it.

