UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Mutual Adaptive Meaning Acquisition by Paralanguage Information: Experimental Analysis of
Communication Establishing Process

Permalink
https://escholarship.org/uc/item/53p3m4t7

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Authors
Komatsu, Takanori
Suzuki, Kentaro
Ueda, Kazuhiro
et al.

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Mutual Adaptive Meaning Acquisition by Paralanguage Information:
Experimental Analysis of Communication Establishing Process
Takanori Komatsu (komatsu@cs.c.u-tokyo.ac.jp)
Kentaro Suzuki (suzuki@cs.c.u-tokyo.ac.jp)
Kazuhiro Ueda (ueda@gregorio.c.u-tokyo.ac.jp)
Kazuo Hiraki (khiraki@idea.c.u-tokyo.ac.jp)
Department of System Sciences, The University of Tokyo
3-8-1 Komaba, Meguro-ku, Tokyo, 153-8902 JAPAN

Natsuki Oka(oka@mrit.mei.co.jp)
Advanced Technology Research Laboratories, Matsushita Electric Industrial Co., Ltd.
3-4 Hikaridai, Seika, Souraku, Kyoto 619-0237 JAPAN
Abstract
The effects of adjustments in teaching strategy and of
paralanguage information in speech sound on the meaning acquisition process were determined by means of an
experiment in which the game “Pong” was played by a
team of two subjects. One subject (the teacher) coached
the other one (the operator), instructing the operator in
which direction to move the game paddle and when to
hit the “ball.” However, the teacher’s speech was rendered linguistically incomprehensible. Three phenomena
were observed. First, the use of a high-pitched voice by
the teacher caused the operator to pay more attention to
her/his actions. Second, meaning acquisition could be
regarded as a reinforcement learning process based on a
multi-reward system (i.e., one for successful game action
and a different one from the teacher’s high-pitched voice
for the wrong action). Third, the subjects adapted to each
other; that is, they learned to respond more appropriately
to each other’s behaviors (we call this mutual adaptation). These three phenomena are thought to play important roles in the acquisition of meaning from incomprehensible speech.

Introduction
How do people who speak different languages learn to
communicate? How do they acquire the meanings of
each other’s speech? One way to interpret the meaningacquisition process is to view it as statistical learning
in which a certain speech sound is linked to the situation in which it was given. Several research groups
have constructed general meaning-acquisition models
based on this simple interpretation (for instance, Siskind,
1996). Testing of these models demonstrated that the
word meanings can be acquired using statistical learning
methodologies.
Some groups have investigated the teaching of word
meanings to robot agents, which can move by themselves
(Billard et al., 1998; Roy, 1999). For example, Kaplan
(2000) showed that a four-legged robot could learn the
names of a dozen objects shown in front of its “eyes”
(camera) by the experimenter during its action experiences.
One study in particular demonstrated that an autonomous agent could learn not only the meanings of
instruction words but also the meanings of evaluation instructions such as “good” and “bad”. Suzuki et al. (2002)
developed a learning agent model that could learn the

meanings of words and evaluation instructions during its
action experiences.
A large variety of learner models have thus been
demonstrated. Siskind’s learner model was a computer
that processed string inputs; Kaplan’s was a four-legged
robot that could learn object names; and Suzuki’s was a
computer agent that could move by itself in a virtual environment. In contrast, only one type of “teacher” has
been demonstrated, one who gave instruction based on
unchangeable rules. In real life, however, good teachers adjust their teaching strategy to fit the learner’s mode
of learning. For example, a caregiver will speak to a
preverbal infant using only simple words. Then, when
the infant starts to speak, the caregiver will start to use
more complex words and speak in different ways. So far,
there have been no studies on how dynamically adjusting the teaching strategy affects the meaning acquisition
process.
Investigating the process involved in acquiring meanings from speech sounds requires investigating the effects of not only phoneme information, which can be
expressed using characters and text, but also of paralanguage information, such as prosody, speech speed and
loudness, which cannot be expressed using characters
and text. The effects of paralanguages information have
been studied in various acoustic studies. For example,
many studies have focused on the turn-taking mechanism
(Pirrehumbert & Hirschberg, 1990) and emotional recognition (Hirose et al., 1997). However, so far, there have
been none on the effect of paralanguage information on
the meaning acquisition process.
We investigated the effects of adjustments in teaching strategy and of paralanguage information in speech
sounds on the meaning acquisition process. We carried
out a communication experiment, in which a team of
two subjects played “Pong”. One subject (the teacher)
coached the other one (the operator), instructing her/him
in which direction to move the game paddle and when
to hit the “ball.” However, the teacher’s speech was rendered linguistically incomprehensible. We observed how
the listener acquired the meanings of the given instructions. For the paralanguage information, we focused on
prosodic information, because data extraction should be
easier and the possibility of the engineering realization
is higher. The results provide a new point of view about
meaning acquisition process and can be used to develop

are migi and hidari, which have different numbers of
phonemes. The display of the teacher and operator were
thus made symmetrical with respect to the dashed line in
Figure 2 to prevent biasing of the results.

Subjects
Eleven teams, each composed of two subjects (Japanese,
20-28 years old, 18 men and 4 women), participated in
the experiment. The members of each team were required to know each other. One additional team participated in two control experiments: one without LPF and
one without instructions.
Figure 1: Game Environment

Figure 2: Different Display Settings
basic technologies for constructing interactive robots that
can understand what is said to them, enabling them to
communicate smoothly with people.

Experiment
Method
The experimental game environment is depicted in Figure 1. The two subjects were placed in separate rooms:
the teacher in Room A, and the operator in Room B. The
teacher’s spoken instructions to the operator were transmitted through a low-pass-filter (LPF) and played over
a speaker in Room B. The LPF masked the phoneme
information, which included the symbolic elements of
speech sound; it did not affect the prosodic elements.
This means that the operator could hear only the prosodic
information; s/he could not understand the teacher’s instructions as meaningful linguistic information. They
were simply noisy sound.
The team playing the game was awarded 10 points
each time the operator hit the ball, and 10 points were
deducted each time s/he missed it. As shown in Figure 2, the game display of the teacher differed from that
of the operator: the teacher’s display showed the ball,
whereas the operator’s did not. The operator could see
only her/his paddle and the score information, indicating
whether s/he had hit or missed the ball.
Even thought the instructions were masked by the
LPF, the operator still might be able to guess which instruction was given based on the number of phonemes
heard. For example, “right” and “left” in Japanese

Procedure
First, the experimenter explained to the subject team (one
operator and one teacher) that the purpose of the experiment was to score as high a total score as possible by
working together. Then, the experimenter let the team
hear a vocal sample, with and without LPF masking, to
demonstrate the filter’s effects. The experimenter did not
mention the differing displays.
The test was then started. Each team played two consecutive 10 minutes games, with 3 minutes of rest between them. The roles of teacher and operator were
fixed, and the team members did not have an opportunity to talk face to face and share information.

Results
To evaluate team performance, values were assigned to
two types of actions, moving the paddle and hitting the
ball. For each move action, if the operator moved the
paddle in the teacher’s intended direction, Correct Direction Value (CDV) was assigned one point; if s/he
moved it in a different direction, CDV was assigned zero
point. For each hit action, if the operator hit the ball, Hit
Value (HV) was assigned one point; if s/he missed it,
HV was assigned zero points. Testing statistical hypothesis using binominal distribution was used to group the
subjects, and actually the teams were divided into three
groups as follows.
Group 1 Average CDV less than 0.8 point.
Group 2 Average CDV more than 0.8 point; Average
HV less than 0.7 point.
Group 3 Average CDV more than 0.8 point; Average
HV more than 0.7 point.
Table 1 shows the average values of the last ten hit
and move actions for the three groups. Out of the 11
teams, two failed to understand any instructions (Group
1). Among the nine remaining teams, five succeeded
in moving the paddle in the direction the teacher intended but could not hit the ball well (Group 2). We
call this achievement “learning to recognize direction instructions.” The four remaining teams could move to
the teacher’s intended position. We call this achievement
“leaning to recognize distance instructions”(Group 3).

Table 1: Correct Direction Value (CDV) and Hit Value
(HV)
Group
Group 1 (2 pairs)
Group 2 (5 pairs)

(CDV, HV)
(0.5, 0.5), (0.3, 0.2)
(0.9, 0.3), (1.0, 0.2), (1.0, 0.5)
(0.8, 0.6), (1.0, 0.6)
Group 3 (4 pairs) (1.0, 0.9), (1.0, 0.7)
(1.0, 0.7), (0.9, 0.8)
*control
no instructions (0.5, 0.2), (0.4, 0.3)
without LPF (1.0, 0.7), (1.0, 0.8)

Figure 3: Trend in Comprehension of Instructions for
Typical Group 3 Team
Table 1 shows that the values of two teams in Group
1 were the same as those for the control pair when they
did not received instructions. Most of the teams in Group
2 and Group 3 had an average score between that of the
two control settings, and some teams in Group 3 scored
as high as the control group without the LPF.
We used Comprehension of Instructions Value to
evaluate the operator’s comprehension of the instruction.
This value was assigned 0 points if the paddle was moved
in the wrong direction, 1 point if it was moved in correct direction but the ball was not hit, and 2 points if
it was moved in the correct direction and the ball was
hit. The value for a typical team in Group 3 are plotted in Figure 3. The curve shows the moving average
of the ten hit opportunities. When the curve was between 0 and 1 point, the operator is thought to have focused on understanding the direction instructions; when
it was between 1 and 2 points, the operator is thought
to have focused on understanding the distance instructions. The operator more quickly learned to comprehend
the direction instructions than the distance ones. We investigate the processes of these two learning phases in
terms of the prosodic elements of the instructions, the
movement of the paddle, and the variety of instructions
given. We focused on the pitch of the teacher’s voice,
which, among the prosodic elements, had the strongest
relationship with the meaning of the instructions. As
shown in Figure 6, when the pitch was increased, the operator tended to suddenly changed her/his action.

Phase 1: Focused on Direction
The operator on nine of the 11 teams learned to comprehend the direction instructions. A particular teaching/learning process was used by most of the nine teams.
First, the teacher gave a wide variety of instructions to
the operator, e.g., “move to the center of the display”,
“move a bit right”, etc. The pitch curve of this initial
teaching is depicted on the left side of Figure 4. It would
have been difficult for the operator to discriminate between the “ue, ue, ue... (up, up, up...)” instructions for
the right direction and “shita, shita... (down, down...)”
instructions for the left.
As the teaching continued, the teacher gradually decreased the variety of instructions, typically converging
on only two, such as ue and shita. In contrast, the teachers on the unsuccessful teams did not decrease the variety
and continued to use a wide variety (Figure 5). Decreasing the variety of instructions apparently makes it easier
to understand direction instructions.
In conjunction with this gradual decrease in the variety of instructions, the difference in the pitch curves of
these two instructions became more distinct. Most teachers started to repeat the instructions, e.g., “ueueue...” and
“shitashita...” The former was audible as one long, continuous voice, while the latter sounded like many choppy
utterances (see the right side of Figure 4).
Here, the operator learned to recognize the type of instructions according to the differed sounds. At the same
time, subjects were ready to make her/his paddle actions
correspond to them. The operator then started exploring this correspondence by trial and error. If the operator succeeded in hitting the ball, even by chance, s/he
learned to associate the given instruction with her/his last
action. The teacher elicited a correct response by using
higher vocal tones (depicted in the circle in Figure 6).
When the pitch at a certain point in a series of teaching voices was about 20 [Hz] higher than the pitch at the
onset, and when this higher pitch continued for at least
500 [msec], the operators intuitively recognized this as a
warning from the teacher. Specifically, when the operator
heard instructions delivered at a higher pitch, s/he recognized that her/his current action was wrong and modified
it accordingly. Therefore, high-pitched vocalizations in
Phase 1 served as a negative reinforcement of the operator’s last action. The operators thus learned to compre-

Figure 4: Pitch Curves of “Ue” and “Shita” in Phase 1.
Left: 250 sec, Right: 540 sec

Figure 5: Variety of Instructions used by Successful/Unsuccessful Teams

Figure 7: Pitch Curve of “Ue” and “Shita” in Phase 2.
Left: 1070 sec, Right: 1270 sec

cess.

Phase 2: Focused on Distance

Figure 6: High-Pitch Element in Teaching Voice
hend the teacher’s instructions by reinforcement learning
based on a positive reward (hitting the ball) and a negative one (hearing a high-pitched voice).
Learning to recognize the instructions during Phase 1
was due not only to the teacher’s efforts but also to the
operator’s action. The actions of operators on the successful teams were initially reluctant, concentrated on
inferring the teachers’ intentions from the given instructions. The operators started reacting actively after they
inferred the intentions. Their actions thus indicated their
comprehension of the given instructions. The operators
on the unsuccessful teams were also reluctant at the beginning of the experiment, but over time they started
moving actively, even though no instructions had been
given: the operators seemed to disregard the instructions.
In this case, the operator’s actions did not indicate any
comprehension of the instructions.
Although at a first glance it seems that meaning acquisition was achieved only by the operator adapting to the
teacher’s instructions, the teacher actually changed the
instructions and method of delivery based on the operator’s comprehensions, which was judged from the operator’s reaction. The subjects actually learned to respond more appropriately to each other’s behavior, so
that meaning acquisition was a mutual adaptation pro-

In this “Pong” game experiment, learning to recognize
the direction instruction was not sufficient for achieving a high score. The distance information was also
needed to consistently hit the ball with the paddle. Of
the nine teams that learned to recognize the direction instructions, four were able to recognize the distance instructions. These four teams exhibited two distinct approaches to learning to recognize distance instructions.
One team used the “stop” instruction, and three teams
did not.
“Stop” Instruction Used One team developed a common understanding of the “stop” instruction before developing one for direction instructions. The sound of
“stop” has a short, skipping sound, so it was not difficult for the operator to understand this literally as “stop”.
This team then developed a common understanding of
direction instruction, like the repetitive “ueueue...” for
move right and “shitashita...” for move left. In the case
of using of “ue”, the teacher had to give repetitive instructions; otherwise the independent usage of “ue” was
recognized as a choppy sound, meaning the opposite
(left, “hidari”) direction. Therefore, the instruction to
move right had to be repetitively elongated to avoid confusion with the usage of independent “ue”. Otherwise,
the operator tended to go past the teacher’s intended position. When this “overrun” problem occurred, the teacher
started saying “ueueue, stop, shitashita” to bring the operator back to the intended position. Finally, when the
teacher said “stop” after a repetitive “ueueue...”, the operator immediately reversed direction so as not to overrun the teacher’s intended position. Thus, the operator
took the “stop” instruction as the literal meaning or as
meaning “go left”. This is a typical example of mutual
adaptation in this experiment.

“Stop” Instruction Not Used The three teams that did
not use the “stop” instruction learned to recognize direction instructions in a manner similar to that of the
other team. In a typical case, after teaching the operator
to learn to recognize direction instructions, the teacher
pitched her/his voice higher at the onset of utterance and
lower at the end, i.e., the intonation decreased, as shown
on the left side of Figure 7. When the distance from the
paddle appeared to the teacher to be too short, the teacher
gradually increased the pitch at the end of the utterance.
Specifically, the teacher increased the pitch at the end of
the instructions utterance when a long distance appeared
to be needed (see the right side of Figure 7), whereas
s/he reduced it when the distance appeared to be short.
In this way, the teacher controlled the operator’s action
by increasing or decreasing the pitch at the end of the instruction utterance. High-pitched utterances spurred the
operator’s actions, which can be broadly interpreted as
drawing the operator’s attention to her/his actions.
Even among the nine teams who learned to recognize
the direction instructions, five were unable to learn to
recognize the distance instructions. The teachers on the
successful teams came to realize that repetitive instructions were important to learning to recognize the direction instructions. They did this by observing the operators’ actions. The teachers on the unsuccessful teams
apparently did not came to this realization and were thus
perplexed when the operators headed in the opposite direction when an “ue” instruction was given.
Comparison of the successful teams with the unsuccessful ones in the two meaning acquisition phases
showed that the team members had to learn to respond
appropriately to one another’s behaviors to acquire a high
score. The series of dynamic behaviors shown by the
successful teams can be regarded as mutual adaptation.
Three points in particular were observed for the successful teams.
1. The use of a high-pitched voice by the teacher caused
the operator to immediately focus on her/his action.
2. The operator learned to recognize the teacher’s instructions by reinforcement learning composed of a
positive reward (hitting the ball) and a negative one
(hearing a high-pitched voice).
3. During the meaning acquisition process, mutual adaptation was observed. That is, team members learned to
respond more appropriately to each other’s behaviors.
Thus, paralanguage information functioned as a negative reward in the reinforcement learning process, and the
teacher’s adjustment in teaching strategy was observed as
a mutual adaptation process. Paralanguage information
and adjustment in teaching strategy thus play important
roles in learning to recognize unknown teaching utterances.

Discussion
Effects of Adjusting Teaching Strategy
In this experiment, we observed a mutual adaptation process: the two members (the teacher and operator) learned
to respond more appropriately to each other’s behaviors.
This study did not, however, consider how substantial
differences between dynamic and static teaching strategies affect the meaning acquisition process. The actual
effects of the teacher’s dynamic instructions on meaning acquisition are thus unclear. We plan to investigate this effect by carrying out additional experiments
in which we will control the behavior of the teachers. In
any case, we observed that the teachers on the successful teams adjusted their teaching strategy according to
the operator’s comprehension of the given instructions.
This observed behavior differs from one-directional, or
fragmented communication aspect, such as that in the
code model of Shannon & Weaver (1949). Wiener et
al. (1972) argued that a symbol exchange model, which
is a code model, is a primitive model of communication.
Sperber and Wilson (1986) refuted this argument and argued instead that their “relevance theory” is a primitive
model of communication. Although this theory might
approach the essence of human communications and thus
overcome the bottleneck of the code model: inferences in
this theory can only be made using simple “deductive”
inference rules (Kimura, 1997). Therefore, this theory
is equivalent to the code model if we regard the inference “rules” as a complicated “code”. This theory, moreover, has another problem: technical terms in the theory
are not connected through physical existence. These unsolved problems reduce the theory’s ability to explain actual communications.
In our experiment, it seemed at first that only the operator adapted to the teacher’s behavior, because only the
teacher could give spoken instructions. However, during
the process of establishing communication, we observed
that not only did the operator adapt to the teacher’s behavior, the teacher adapted to the operator’s behavior.
While it is not uncommon for a teacher, who is a usually an information transmitter, to sometimes become an
information receiver, in our experiment, the transmitting
and receiving occurred simultaneously. This observed
phenomenon cannot be explained by the code model.
Thus, the results of our experiment suggest that the actual
communication process cannot be expressed using a onedirectional communication view like the code model. Instead, a mutual adaptive view that cannot be decoded into
one-directional relationships is needed.

Effects of Paralanguage Information
In this experiment, we observed that the use of a highpitched voice by the teacher caught the operator’s attention. In general, the pitch of a speech sound decreases as
the utterance draws to the end. If the pitch deviates from
this pattern, the listener immediately catches the change.
The observed function of the high-pitched voice in our
experiment can be explained by this “prominence mech-

anism.” Each team, regardless whether it was successful
or not, actually made use of this function, which might
be a universal trait among humans.
An infants’ salient attention to a motherese voice, as
revealed in various cognitive development studies, suggests that sensitivity to prosodic information is either
an innate function or is learned just after birth. From
our results, it might be said that infants react to the
prosodic information in the caregiver’s speech, not to
the phoneme information. The meaning acquisition process observed in our experiment can be regarded as
reinforcement learning with multiple-rewards, and the
high-pitched voice among the various types of prosodic
information functioned as one of two rewards. That
is, prosodic information affects the meaning acquisition
process at some basic levels. Thus, it can be assumed that
the infants’ language acquisition process and the meaning acquisition process in our experiment are similar in
both depend on receiving prosodic information before
acquiring the actual meanings of speech or teachings.
Further research should reveal how this assumption is related to the language acquisition processes.

Application Based on Results
From the results of our experiment, we conclude that paralanguage information and adjustments in teaching strategy play important roles in learning the meaning of unknown utterance. If an autonomous robot had such abilities, it should be able to learn the meanings of human
utterances and thus be able to communicate with people
smoothly. In the traditional method of developing an interactive robot system, the designer needs to map specific
utterance to the robot’s functions. However, by applying
the phenomena observed in our experiment, the designer
need not to define such a mapping a priori, but simply
needs to define “high-pitched voice = negative reward”
and “successful action = positive reward”. From these
definitions, the robot can learn by itself the mapping between unknown utterances and its possible actions by using a reinforcement learning process based on the two
types of rewards. Consequently, the robot will be able to
adapt to its owner by trial and error, and over time the
robot and owner can create an intimate relationship.

Conclusions
A communication experiment was carried out to observe
the effects of a teacher’s adjustment in teaching strategy and of paralanguage information in terms of learning the meanings of unknown utterances. An adjustment
in teaching strategy was observed as a mutual adaptation
process, in which the two subjects on a team learned to
respond more appropriately to each other’s behavior, and
paralanguage information was observed to function as a
negative reward in a reinforcement learning process for
meaning acquisition. These two phenomena thus play
important roles in learning the meaning of unknown utterances.

References
Billard, A., Dautenhahn, K., & Hayes, G. (1998). Experiments on human-robot communication with robota, and interactive learning and communicating doll
robot. In B. Edmonds and K. Dautenhahn (Eds.), Socially situated intelligence workshop (SAB98) (pp. 4–
16).
Hirose, K., Kawanami, H., & Ihara, N. (1997). Analysis of intonation in emotional speech. Proceedings of
ESCA tutorial and Research Workshop in Intonation:
Theory, Models and Applications.
Kaplan, F. (2000). Talking AIBO: First Experimentation
of verbal interactions with an autonomous four-legged
robot. In A. Nijohlt & D. Jokinen (Eds.), Learning to
behave: interacting agents CELE-TWENTE Workshop
on Language Technology (pp. 63–75).
Kimura, D. (1997). Information, regularity and communications – comparison between Shannon and Bateson. In Tani, Y (Eds.), Communication no shizen-shi
(in Japanese), Tokyo: Shin-yosha.
Pirrehumbert, J. B., & Hirschberg, J. (1990). The meaning of intonational contours in the interpretation of discourse. In P. R. Cohen, and M .E . Pollack (Eds.),
Intentions in Communication, Cambridge, MA: MIT
Press.
Shannon, C. & Weaver, W. (1949). The Mathematical
Theory of Communication. Urbana: University of Illinois Press.
Siskind, J. (1996). A computational study of cross–
situational techniques for learning word to meaning
mapping. Cognition, 61, 39–91.
Sperber, D. & Wilson, D. (1986). Relevance: Communication and Cognition. Oxford: Blackwell.
Suzuki, K., Ueda, K., & Hiraki, K. (2002). A Computational Model of an Instruction Learner: How to learn
Good or Bad through Actions. Cognitive Studies(In
Japanese)., in press.
Roy, D. (1999). Learning from sights and sounds: A
computational model. Doctoral dissertation, MIT Media Laboratory.
Wiener, M., Davoe, S., Rubinow, S., & Geller, J. (1972).
Nonverbal behavior and nonverbal communication.
Psychological Review, 79.

