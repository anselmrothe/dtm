UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Case, Word Order, and Language Learnability: Insights from Connectionist Modeling
Permalink
https://escholarship.org/uc/item/8nf95595
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Lupyan, Gary
Christiansen, Morten H
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

     Case, Word Order, and Language Learnability: Insights from
                                      Connectionist Modeling
                                     Gary Lupyan (il24@cornell.edu)
                            Morten H. Christiansen (mhc27@cornell.edu)
                                             Department of Psychology
                                                   Cornell University
                                                Ithaca, NY 14853 USA
                        Abstract                             and case markings. In a strict WO language like En-
                                                             glish, declarative sentences follow a Subject-Verb-
   How does the existence of case systems, and strict        Object (SVO) pattern. It is the occurrence of the
   word order patterns a↵ect the learnability of a given     subject in the first position, and the object in the
   language? We present a series of connectionist sim-       second, that allows the hearer to comprehend who
   ulations, suggesting that both case and strict word
   order may facilitate syntactic acquisition by a se-       did what to whom. In contrast, languages such as
   quential learning device. Our results are consis-         Russian or Japanese allow multiple word orders and
   tent with typological data concerning the frequen-        rely on case markings to disambiguate subjects from
   cies with which di↵erent type of word order pat-          objects. For instance, Masha lubit Petyoo (SVO),
   terns occur across the languages of the world. Our        Petyoo lubit Masha (OVS), and Lubit Petyoo Masha
   model also accommodates patterns of syntactic de-
   velopment across several di↵erent languages. We           (VOS) are all grammatical in Russian and all mean
   conclude that non-linguistic constraints on general       Mary loves Peter (albeit with di↵erent emphases on
   sequential-learning devices may help explain the re-      the constituents), due to the nominative -a, and ac-
   lationship between case, word order, and learnabil-       cusative -u case markers.
   ity of individual languages.
                                                                While long-standing theories describe acquisition
                                                             of language through an innate language acquisition
                    Introduction                             device (e.g., Pinker, 1995), an alternative approach
In language acquisition, children are faced with             that is gaining ground is the adaptation of linguistic
many formidable tasks, yet they normally acquire             structures to the human brain rather than vice versa
most of their native language within the first five          (e.g., Christiansen, 1994; Kirby, 1998). On this ac-
years of life. One of the most difficult of these tasks      count, language universals may reflect non-linguistic
involves mapping a sequence of words onto some sort          cognitive constraints on learning and processing of
of interpretation of what that sequence is supposed          sequential structure, rather than constraints pre-
to mean. That is, in order for the child to under-           scribed by an innate universal grammar. Previ-
stand a sentence, she needs to determine the gram-           ous work has shown that sequential-learning devices
matical roles of the individual words so that she can        with no language-specific biases are better able to
work out who did what to whom. Although the chil-            learn more universal aspects of language as com-
dren appear to bring powerful statistical learning           pared to aspects encountered in rare languages (e.g.,
mechanisms to bear on the acquisition tasks (e.g.,           Ellefson & Christiansen, 2000; Christiansen & De-
Sa↵ran, Aslin, & Newport 1996), the existence of             vlin, 1997; Van Everbroeck, 1999, 2001).
linguistic universals common across radically di↵er-
ent languages (Greenberg 1963) points to the pres-              Here, we examine the ways in which case markings
ence of innate constraints on such learning. Without         and word order may function as cues for a sequen-
such constraints, it becomes difficult to explain why        tial learning device acquiring syntactic structure. In
there are few, if any, Object-Subject-Verb (OSV)             simulation 1, we model di↵erent word orders, and
languages (van Everbroeck, 1999) even though in              hypothesize that typologically common languages
principle such a language appears to be as good as           should be easier to learn by a sequential-learning
any other. In this paper, we propose that these con-         device than the more rare ones. We expand on this
straints may arise from non-linguistic limitations on        idea in simulation 2 by studying the performance of
the sequential learning of statistical structure, and        networks trained on languages of varying degrees of
examine how this perspective may shed light on how           case markings and flexibility. Finally, in simulation
children learn to map the words in sentences onto            3, we establish that our trained networks are able
their appropriate grammatical roles. There are two           to mimic syntactic performance of children learn-
major ways in which languages signal syntactic rela-         ing English, Italian, Turkish, and Serbo-Croatian
tionships and grammatical roles—word order (WO),             (Slobin and Bever, 1982).

         Acquisition of Word Order                       dicate syntactic relationships—there is nothing in-
Generative linguists have long relied on parameter       herently special about word order or case markings.
setting to explain how children acquire the distinct     In short, we posit that a major reason for the ob-
patterns of their native language. For instance, it      servable asymmetries among the world’s languages
has been assumed that the way a child knows to           is that certain patterns make a language more eas-
generate SVO and not SOV English sentences is            ily learnable by a general sequential-learning device,
through the setting of a VO/OV parameter (Neele-         ensuring the proliferation of such a language in the
man, 1994). This account has been unsatisfactory         human population.
because it does not account for many observed cor-
relations; for instance, OV languages typically have              Simulation 1: Exploring the
flexible word orders (Koster, 1999). More generally,      Learnability of Case and Word Order
parameter theory has been largely unable to account      In the view that the frequency of certain WOs is
for the asymmetries and patterns in the distribution     correlated with their learnability, we hypothesized
of world languages. Why, for instance, are the most      that typologically rare languages will be more dif-
common word orders SOV, SVO, and VSO (Green-             ficult to learn by a sequential-learning device than
berg 1963: Universal 1)? Why do verb-final lan-          the more common languages. To test this predic-
guages almost always have a case system (Greenberg       tion, we trained simple recurrent networks (SRNs:
1963: Universal 41)? And even more fundamentally,        Elman, 1990) on a total of 14 artificial grammars,
why do case languages have flexible word orders to       reflecting the 6 possible strict word orders (SWO)
begin with? It is our position that these observations   and a flexible word order (FWO), with or without
can be at least partially accounted for by examining     the presence of case markings.
the learnability of languages from the viewpoint of
sequential learning.                                     Method
   Generative linguistics also leaves largely unex-      Networks Ten SRNs were used in each condition.
plained the process children use to actually set the     The networks were initialized with random weights
parameters. With regard to word orders, an ex-           in the interval [-0.1, 0].1 Each input to the net-
planation espoused by Pinker (e.g., 1995) involves       works consisted of a distributed representation of a
the so-called Subset Principle. According to the         word, spliced with a case marker. Words were rep-
Subset Principle, children take the most conserva-       resented by 20-unit randomly generated bit-vectors.
tive strategy and so, by default, assume a fixed or-     Although some vectors were bound to be close in the
der. Alternative word orders are only accepted if        representation space, random assignment to words
a child is exposed to these orders, at which time a      assured that any such interaction would not bias the
free word order parameter gets switched on. Under        results. Having words represented by random vec-
this assumption, FWO languages are predicted to be       tors may seem odd considering the complex phonol-
more difficult to learn. Although the idea that all      ogy that underlies human languages. However, for
languages are initially approached as having strict      present purposes such a representation seems to
word-order (SWO) was popular in the sixties and          work just as well as phonological (e.g., van Ever-
seventies (Slobin, 1966), Slobin and Bever (1982 con-    broeck 2001), while dramatically decreasing train-
clude that the primacy assigned to word order was        ing time. Case markings (nominative, accusative,
unduly influenced by languages such as English.          dative, and genitive) were represented by a four-bit
   There is ample evidence that children learning        vector appended to the word vector. This made for
a strict word-order language such as English never       a total of 24 input units. There were seven out-
leap to the conclusion that it is a free-word order lan- put units, corresponding to the grammatical roles
guage (Pinker 1995). While Pinker has used this ev-      the network was supposed to predict: subject, di-
idence for reinforcing parameter-setting—the reason      rect object, indirect object, genitive noun, verb, or
children never leap to such conclusions is because a     end-of-sentence. In all simulations, the learning rate
word-order parameter has been set—we suggest an          was set to 0.1, and momentum to 0.01. Each SRN
alternative explanation. Simply, children learning       had 30 hidden units and 30 context units.
English generally do not produce non-SVO sentences
because non-SVO sentences are incomprehensible in        Materials The lexicon contained 300 nouns and
English. In the absence of case markings, Kicked         100 verbs. This noun-to-verb ratio is generally con-
John Bill is ambiguous as to who did the kicking.        sistent with human languages (e.g., British National
Children learning English, use the statistical prop-     Corpus). The verbs were evenly divided into intran-
erties of the language to learn that word order is a re- sitive, transitive, and ditransitive categories. As il-
liable cue to syntactic relationships. Children learn-   lustrated in Table 1, each grammar included three
ing a case-based language such as Russian, make a            1
                                                               It was found that the slightly inhibitory start-
similar observation about case markings. This view       ing weights provided for better performance across the
obviates the need for a default strategy. What is        board. A similar conclusion was reached by van Ever-
important is that there exist some set of cues to in-    broeck (2001).

Table 1: A Sample SOV Grammar Used to Generate                Table 2: Network performance and Language Dis-
Training Corpora                                              tributions
S ! Intransitive [.35] | Transitive [.35] | Ditransitive [.3]    Word     Words Correct – No Attested Frequency
Intransitive ! NP-nom V-intrans                                  Order    Case Condition (%)             (%)
Transitive ! NP-nom NP-acc V-trans                                SOV              90            51 (most w/cases)
Ditransitive ! NP-nom NP-acc NP-dat V-ditrans                     VOS              85                      8
NP ! N | N N-gen [.25]                                            OVS              80                    0.75
                                                                  OSV              74                    0.25
                                                                Flexible           65              0 (all w/cases)
                                                                Note. Attested language frequencies taken from Van
                                                                Everbroeck (1999).
types of sentences: intransitive, transitive, and di-
transitive. A sentence consisted of noun phrases
(NP) and one of three verb classes. Twenty-five per-
                                                              as being correctly mapped.
cent of noun phrases contained a noun in the genitive
                                                                 It may seem that providing the networks with di-
form (e.g., John’s brother. The simplest sentence
                                                              rect mapping from word to grammatical category is
generated by such a grammar was a simple intran-
                                                              not ecologically valid. After all, it has long been
sitive: e.g., John walks. The most complex sentence
                                                              recognized that kids are not given sufficient osten-
contained 7 words: Mary’s friend gave Peter’s key
                                                              sive cues to syntactic relationships and word mean-
[to] John’s brother. A fully flexible grammar was
                                                              ings. No one explains to the child after each encoun-
identical to the strict WOs except the order within
                                                              tered sentence that word A referred to the “do-er”
each element was randomly varied from sentence
                                                              and word B to the “do-ee”. However, Tomasello
to sentence. In an e↵ort to model the languages
                                                              and colleagues have shown that children are able to
as naturalistically as possible, we modeled genitives
                                                              use pragmatic cues such as eye gaze to help figure
based on Greenberg’s (1963) universal 2: in typi-
                                                              out which object is being referred to (Tomasello &
cally prepositional languages (SVO and VSO) gen-
                                                              Akhtar, 1995). Twenty-four month olds show un-
itives generally follow the governing noun, while in
                                                              derstanding of adult intentions in inferring mean-
postpositional languages (SOV), the reverse is true.
                                                              ings of novel verbs (Tomasello & Barton, 1994), and
We modeled the remaining three word orders with
                                                              18-month old children are able to learn new words
genitives following the noun. We also added a geni-
                                                              in non-ostensive contexts (Tomasello, Strosberg, &
tive case-marking to SWO-no case languages. With-
                                                              Akhtar, 1996). Such use of pragmatic cues enables
out this, it was impossible for the networks to dis-
                                                              children to map words onto meanings and correctly
cern governing nouns from genitives. This addition
                                                              infer who did what to whom. Considering that
is motivated by the observation that even normally
                                                              our networks live in a purely linguistic world, the
case-less languages have some form of genitive case
                                                              method of direct mapping seems reasonable.
markings (e.g., in English: Mary’s house) (van Ever-
broeck, 2001).                                                Results
Procedure We used a crossover design of 7 word                All networks trained in the case condition were able
orders (6 strict, and one flexible), by two case con-         to map 100% of the words to the correct categories.
ditions (with or without case) resulting in 14 train-         When case was not available, the network perfor-
ing corpora. For each condition, we generated 3,000           mance roughly corresponded to attested language
random sentences of the appropriate order. Such               frequencies (Table 2). Only two caseless WOs ob-
a corpus occupies a very small part of the possible           tained nearly perfect performance: SVO and VSO
sentences that can be generated by the corpus. For            (99%). There, however, appears to be a discrep-
instance, 9 million di↵erent sentences are possible for       ancy. While SOV is the most common WO, it is
a transitive SOV configuration (300 x 300 x 100).             outperformed by both SVO and VSO. According to
   The networks were trained for 100,000 sweeps (in-          Greenberg’s Universal 41, however, the great major-
put/output pairs), corresponding to about 7 passes            ity of SOV languages have case, and most caseless
through the corpus. During each training sweep, the           languages turn out to be either SVO or VSO (e.g.,
network was presented with a word, and depending              English, Welsh). This finding supports our learn-
on the condition, a case marking. A corpus of 200             ability hypothesis: verb-final languages presumably
novel sentences was created for testing. In the test-         have a case system because reliance on WO results
ing corpus, 50% of words were completely new—ones             in suboptimal learnability.
to which the network has never been exposed. Per-                The likely reason SOV-no case grammars did not
formance was measured by assessing the network’s              achieve perfect accuracy is because they contained
ability to map a given word to its correct gram-              two unmarked nouns prior to the verb. Since the
matical role. During testing, the network’s highest-          networks learn to map di↵erent types of verbs to
activated output unit was compared to the expected            di↵erent argument constructions, verb-final gram-
output. If the units matched, the word was marked             mars are at a disadvantage—in these grammars the

grammatical role that provides the most informa-
tion about what is to come, is received last (van
Everbroeck, 2001). The poor performance of VOS is
due to the intervening indirect subject in ditransi-
tive sentences. We should also note that even though
FWO-no case languages perform poorly, their per-
formance is consistently above chance. This can be
explained by the networks’ learning to map familiar
verbs to intransitive, transitive or ditransitive word
schemas.
   These simulation results confirm the idea that
FWO-case languages are no more difficult to learn
than common SWO-no case languages such as SVO
and VSO, counter to predictions of the subset princi-
ple. The difficulty associated with learning a FWO
language without case markings is underscored by
typological evidence, suggesting that such languages
use case markings to signal grammatical relation-      Figure 1: Network performance in simulation 2 for
ships (Payne 1992).                                    increasing degrees of case markings as a function of
                                                       word order.
 Simulation 2: The Impact of Case on
            Word Order Flexibility                     Procedure Each group of networks had case cues
                                                       added to the sentences based on case condition. The
In natural languages, case markings are not wholly
                                                       testing proceeded as in Simulation 1.
deterministic. For instance, Slavic languages such
as Russian and Serbo-Croatian, contain a number        Results
of nouns which, perhaps for historical reasons, do
not take case markings. Additionally, because these    As expected, SWO languages such as English and
markings often take the form of suffixes, they change  Italian were little-benefited by case (Figure 1). In
the phonology of words. This results in potential      contrast, the probabilistic addition of case mark-
phonological ambiguity. For instance, in Russian       ings to FWO languages consistently improved per-
stali is either the genitive form of steel or a con-   formance. The slightly lower performance of Italian
jugated verb meaning we stopped. By examining the      is due to it having a more flexible word order than
e↵ects of varying cases on di↵erent word orders, we    English (see Table 3). To compensate for possible
hoped to show that (1) even probabilistic case mark-   ambiguities, Italian relies heavily on prosodic and
ings improve performance for FWO languages, and        contextual information (Slobin & Bever, 1982) which
(2) case markings do not improve performance for       was not available to our networks. In summary, the
languages that already rely on WO.                     precise nature of the cue: case, or WO, does not
                                                       seem to matter. Neither needs to be primary.
Method
                                                          Simulation 3: Interactions between
Networks Ten SRNs were used for each condition.
The initial conditions and training details were the     Case and Word Order Flexibility in
same as in Simulation 1.                                                 Development
Materials We generated five artificial grammars        In this simulation, we demonstrate that networks
varying on the salience of case markings—from only     trained on corpora similar to those used in simu-
genitive markings, to full case markings. A gram-      lation 2 are able to mimic syntactic performance
mar with case marked 50% of the time corresponded      of children learning English, Italian, Turkish, and
to a language in which 50% of case markings are        Serbo-Croatian. Slobin and Bever (1982) tested 48
possibly phonologically ambiguous, or a language in    children divided into 8 age groups (24-52 months).
which certain of nouns do not take on case mark-       Each child was tested on their ability to demonstrate
ings. Five more grammars varying on strictness of      familiar actions (e.g., scratch, bump, pick up) using
word order—from a completely flexible order, to a      familiar toy animals after hearing a transitive lan-
completely strict one (SVO). The word orders ap-       guage in their native language. The authors hypoth-
proximated distributions found in natural languages    esized that Turkish, English, and Italian-speaking
(Italian, and Turkish: Slobin & Bever 1982); Polish:   children would have the easiest time due to the con-
Jacennik & Dryer 1992). The two conditions were        sistent, unambiguous case markings available in the
crossed, for a 5x5 matrix. As in simulation 1, 3000    case of Turkish, and the consistent word-order in-
sentences were generated for each condition.           formation available in English and Italian. Children

Table 3: Word Order Distributions for Simulation 3
  Language         Words Order              Cases
  English     100% SVO                Genitive only
  Italian     82% SVO, 2% SOV,        Genitive only
              11% VSO, 5% OVS
  Serbo-      55% SVO, 16% SOV,       Full for non-SVO
  Croatian    16% VSO, 3% VOS,        For SVO: 55%
              2% OVS, 8% OSV          nom, 55% acc,
                                      100% dat, 70%
                                      gen
  Turkish     48% SOV, 25% SVO,       Full
              13% OVS, 8% OSV,
              6% VSO
acquiring Serbo-Croatian would have a more difficult
time due to its more ambiguous case markings, re-
quiring them to pay attention to word-order as well     Figure 2: The pattern of performance across training
as cases.                                               for Turkish, English, Italian, and Serbo-Croatian in
                                                        simulation 3
Method
Networks The networks and training details were         Table 4: Percentage correct performance for gram-
identical to simulation 2. We used 12 SRNs in each      matical sentences in a given language in the Slobin
condition, mirroring the number of subjects used by     and Bever (1982) study.
Slobin and Bever (1982).
Materials We created 4 types of grammars moti-                              Language
vated by the four languages used in the study. En-         Age    English     Italian   Serbo-Croatian   Turkish
glish was modeled as being 100% SVO, and having           24-28     58          66            61            79
                                                          32-36     75          78            58            80
only genitive case markings. The word orders for          40-44     88          85            69            82
the remaining languages were modeled based on the         48-52     92          90            79            87
data provided by Slobin and Bever’s (1982) corpus of
adult speech, reflecting the linguistic input available
the children.
                                                        markings were deleted from 55% of nouns in SVO
   Although Turkish does not have an explicit nom-
                                                        sentences. Serbo-Croatian neuter nouns do have da-
inative case, it was found that such a marker was
                                                        tive case-markings, hence the datives are marked
necessary in this simulation. In the absence of se-
                                                        100% of the time. However, plural neuter nouns are
mantic information and case markings, the networks
                                                        not declined in genitive constructions. If plural gen-
must rely on the syntactic position of a word to cor-
                                                        itive nouns are used an estimated 30% of the time,
rectly identify its category. However, in a relatively
                                                        then 70% of SVO sentences will have genitive case
FWO language such as Turkish, this information is
                                                        markers.
ambiguous. Without a nominative case, both verbs
and subjects are unmarked, and the network natu-        Procedure Training proceeded as in simulation
rally has trouble telling them apart. In contrast to    1. The extent of training was varied for networks
these networks, children rely on semantic informa-      corresponding to di↵erent age groups. Testing was
tion, in addition to syntax, to tell apart verbs and    done following the procedure employed by Slobin
nouns. In other words, a Turkish child knowing the      and Bever (1982). We used transitive sentences us-
meanings of “dog” and “sni↵”, will not confuse the      ing only words which the networks have seen during
two even when “dog” is an unmarked agent in the         training. Performance was quantified by measuring
sentence.                                               the percentage of subjects and objects the network
   Serbo-Croatian has all four of the cases we were     identified correctly, and averaging the data with the
modeling, however, only masculine and feminine          overall percentage of words correctly identified.
nouns take on accusative and nominative markings.
Sentences containing one or more neuter nouns are       Results
typically ordered as SVO. We did not have data on       The networks’ performance (Figure 2) closely
the proportion of neuter nouns in Serbo-Croatian        matched Slobin and Bever’s (1982) data (Table 4).
or the percentage of SVO sentences containing such      As predicted, networks trained and tested on Turk-
nouns. It was estimated that about 55% of SVO sen-      ish had the easiest time mapping words onto gram-
tences would contain one such noun, therefore case      matical roles. Networks trained on Serbo-Croatian,

had the most difficult time, highlighting the higher        Proceedings of the 22nd Annual Conference of the Cog-
processing-cost associated with having to pay atten-        nitive Science Society. (pp. 113-118). Mahwah, NJ:
tion to WO and case markings. This pattern of re-           Erlbaum
sults runs counter to the subset principle since the      Christiansen, M. H. (1994). Infinite languages, finite
                                                            minds: Connectionism, learning and linguistic struc-
latter predicts case-languages to be more difficult to      ture. Unpublished doctoral dissertation, Centre for
acquire. Performance on Italian was slightly worse          Cognitive Science, University of Edinburgh, U. K.
than on English, reflecting the more flexible WO of       Ellefson, M.R. & Christiansen, M.H. (2000). Subja-
Italian. It is predicted that with the addition of          cency constraints without universal grammar: Evi-
prosodic and semantic cues, the performance of Ital-        dence from artificial language learning and connec-
ian would more closely parallel that of a fully SWO         tionist modeling. In The Proceedings of the 22nd An-
                                                            nual Conference of the Cognitive Science Society. (pp.
language such as English.                                   645-650). Mahwah, NJ: Erlbaum
                                                          Elman, J.L. (1990). Finding structure in time. Cognitive
                     Conclusion                             Science, 14, 179-211.
Our findings confirm that learnability of languages       Greenberg, J. H. (1963) Some universals of grammar
                                                            with particular reference to the order of meaningful
may be a major factor in the frequency of certain           elements. In: Universals of language. Greenberg, J.H.
language types. In the view of language as an organ-        (ed.). Cambridge, MA.: MIT Press.
ism (Christiansen, 1994), languages which are easily      Jacennik, B. & Dryer, M.S. (1992). Verb-subject order
learnable by the human sequential-learning device           in Polish. In Pragmatics of word order flexibility, ed.
proliferate, while languages not easily learnable die       Payne, D. L. Amsterdam: John Benjamins.
out or never come into existence. Our simulations         Kirby, S. (1998). Language evolution without natural se-
suggest that all that is needed to learn syntactic re-      lection: From vocabulary to syntax in a population of
                                                            learners. Edinburgh Occasional Paper in Linguistics,
lations is a reliable cue: case, or word order—neither      EOPL-98-1.
needs to be primary. As such, no parameter-setting        Koster, J. (1999) The word orders of English and Dutch:
or subset principle is needed to account for the data.      Collective vs. individual checking. In: Groninger Ar-
These results also provide added support for a con-         beiten zur germanistischen Linguistik, Abraham, W.
nectionist approach to studying acquisition and evo-        (ed.), University of Groningen, Groningen. 1-42.
lution of language.                                       Neeleman, A. (1994) Complex predicates. PhD Disserta-
   The simulations described here have several no-          tion Utrecht University, Utrecht.
table limitations. The sentences used for training        Payne, D. L.(1992). Verb-Subject Order in Polish. In
                                                            Pragmatics of Word Order Flexibility, Amsterdam:
were admittedly simple. Although simple intransi-           John Benjamins.
tive, transitive, and ditransitive sentences are very     Pinker, S. (1995). Language acquisition In An invitation
frequent in speech, natural languages are rife with         to cognitive science. Vol 1: Language Gleitman, L.R.
more complex structures such as relative clauses and        & Liberman, M. (Eds.) Cambridge, MA.: MIT Press.
embedding. O↵setting the simple grammars, how-            Sa↵ran, J.R., Aslin, R.N., & Newport, E.L. (1996). Sta-
ever, were the limited cues available to the networks,      tistical learning by 8-month-old infants. Science, 274,
which relied solely on distributional information of        1926-1928.
grammatical categories. In contrast, children rou-        Slobin , D. I. (1966). The acquisition of Russian as a
                                                            native language. in F. Smith and G. A. Miller (eds.),
tinely use semantics and prosodic cues, and even            The genesis of language: A psycholinguistic approach.
more subtle cues such as di↵erential word length of         Cambridge, MA: MIT Press
nouns and verbs (Cassidy & Kelly, 1991—see Chris-         Slobin, D. I., & Bever, T. G. (1982). Children use canon-
tiansen & Dale, 2001, for a review). It is therefore        ical sentence schemas: A crosslinguistic study of word
quite remarkable that relying only on word order            order and inflections. Cognition 12: 229-265
or case, the performance of the networks was near-        Tomasello, M. & Akhtar, N. (1995). Two-year-olds use
perfect for common language types.                          pragmatic cues to di↵erentiate reference to objects
                                                            and actions. Cognitive Development, 10, 201-224.
                                                          Tomasello, M. & Barton, M. (1994). Learning words
                      References                            in non-ostensive contexts. Developmental Psychology,
British    National     Corpus.           Located     at:   30, 639-650.
   www.hcu.ox.ac.uk/BNC                                   Tomasello, M., Strosberg, R., & Akhtar, N. (1996).
Cassidy, K.W. & Kelly, M.H. (1991). Phonological infor-     Eighteen-month-old children learn words in non-
   mation for grammatical category assignments. Jour-       ostensive contexts. Journal of Child Language, 23,
   nal of Memory and Language, 30: 348-369.                 157-176.
Christiansen, M.H. & Dale, R.A.C. (2001). Integrating     Van Everbroeck, E. (1999). Language type frequency
   distributional, prosodic and phonological information    and learnability. A connectionist approach. In Pro-
   in a connectionist model of language acquisition. In     ceedings of the 21st Annual Conference of the Cog-
   Proceedings of the 23rd Annual Conference of the Cog-    nitive Science Society (pp. 755-760). Mahwah, NJ:
   nitive Science Society (pp. 220-225). Mahwah, NJ:        Erlbaum
   Lawrence Erlbaum.                                      Van Everbroeck, E. (2001). Language type frequency and
Christiansen, M.H. & Devlin, J.T. (1997). Recursive in-     learnability from a connectionist perspective. Submit-
   consistencies are hard to learn: A connectionist per-    ted Manuscript.
   spective on universal word order correlations. In The

