UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Predicting Agent Spatial Information: A Comparison Between Neural Networks and Dead
Reckoning Algorithms
Permalink
https://escholarship.org/uc/item/0sq6h19c
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Henninger, Amy E
Gonzalez, Avelino J
Reece, Douglas A
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

   Predicting Agent Spatial Information: A Comparison Between Neural Networks
                                            and Dead Reckoning Algorithms
                                              Amy E. Henninger (amy@soartech.com)
                                           Soar Technology, Inc. 3361 Rouse Road Suite 240
                                                            Orlando, FL 32826
                                             Avelino J. Gonzalez (ajg@isl.engr.ucf.edu)
                                         School of Electrical Engineering and Comupter Science
                                            University of Central Florida, Orlando, FL 32816
                                                Douglas A. Reece (reeced@saic.com)
                                                     SAIC 12479 Research Parkway
                                                         Orlando, Florida 32817
                             Abstract                                   plans are. For example, an agent may want to infer what
    In tune with the 24th Annual Cognitive Science                      plan an opponent is executing so that the agent can select
    Conference’s emphasis on application, this paper presents           countermoves. Han and Veloso (1995), Rao (1994), Rao
    an empirical comparison between two methods used in                 and Georgeff (1995), Tambe and Rosenbloom (1995), and
    agent tracking. The need to predict an agent’s intents or           Tambe (1996) have studied various forms of recognizing
    future actions has been well documented in multi-agent              an agent’s intents.
    system’s literature and has been motivated by both                     Sometimes it is necessary to infer facts that are normally
    systematically-practical and psychologically-principled             observable, such as agent location, because of sensor or
    concerns. However, little effort has focused on the
                                                                        other limitations. For example, a pilot agent may need to
    comparison of predictive modeling techniques. This paper
    compares the performance of two predictive models both              predict where a threat aircraft is flying after it enters a
    developed for the same, well-defined modeling task.                 cloud. There are many approaches to predicting agent
    Specifically, this paper compares the performance of a              trajectories, including Newtonian mechanics (Lin and Ng,
    neural network based model and dead-reckoning model,                1993), neural networks (Kim et al, 1999), Hidden Markov
    both used to predict an agent’s trajectory and position.            Models (Washington, 1998) and others. This paper
    After introducing the background and motivation for the             addresses a particular application of trajectory prediction in
    research, this paper reviews the form of the dead-reckoning         distributed simulation and compares the effectiveness of a
    algorithms, the architecture and training algorithms of the
                                                                        neural network to a commonly used Newtonian approach
    neural networks, the integration of the models into a large-
    scale simulation environment, and the means by which the
                                                                        for this application.
    performance measures are generated.             Quantitative           The remainder of this section defines the trajectory
    measures from our experiments indicate that, for the task           estimation problem in the distributed simulation application
    considered, the neural network based model provides                 and describes a previous use of neural networks for
    greater predictive utility, but at an increased cost in             estimating agent trajectory in a visual scanning application.
    processing time. Performance measures are presented over            The paper then describes a neural network approach for
    increasing levels of error tolerance.                               trajectory estimation in distributed simulation and presents
                                                                        results and comparisons with Newtonian dead reckoning.
                         Introduction                                   Dead Reckoning in Distributed Simulation
Intelligent agents typically operate in an environment                  In a Distributed Interactive Simulation (DIS) (DIS Steering
populated by other intelligent agents. Agents may help                  Committee, 1994), simulation software for each agent runs
each other, hinder each other, get in each other’s way, or              independently of other agents and broadcasts the ground
ignore each other, often without directly communicating                 truth about the state of the agent through network packets
their intent. In order for an agent to achieve its goals, it is         known as protocol data units (PDUs). Each simulation in
thus sometimes necessary for the agent to determine where               DIS uses trajectory estimation so that the state of the agents
the other agents are, what they are doing, and what their               does not have to be broadcast frequently. Lin and Ng

(1993) explain how dead-reckoning can be used to maintain                   reckoning model. When the error exceeds the threshold,
coherence among entities' states in a DIS environment.                      the models are brought into correspondence by the issuance
Each simulator uses Newtonian equations of motion such as                   of an entity state PDU (ESPDU). Thus in the figure, only 3
equation 1                                                                  ESPDUs are broadcast instead of one at every time step.
                                                                            The goal of the research presented here is to reduce the
                                   a 0 ∗ (∆t ) 2
            p = p 0 + (v0 ∗ ∆t ) +                                          number of ESPDUs sent in by DIS simulations below the
                                         2                              (1)
           v = v 0 + a 0 (∆t )                                              number needed using Newtonian dead reckoning.
where      p   =   current position
           p0  =   initial position                                         Neural Networks for Trajectory Estimation
           v   =   current velocity                                         Kim et al (1999) developed a system to generate short-term
           v0  =   initial velocity                                         predictions of an agent’s trajectory such that it can be used
           a0  =   initial acceleration                                     to predict the agent’s position at any future instance, given
           ∆t  =   elapsed time
                                                                            some window of time. They use this model as part of a
                                                                            helicopter agent’s perceptual system to enhance the agent’s
to predict the trajectory of other agents. Each simulator                   ability to visiually track ground vehicles, and their
also uses the same equation to model the trajectory of its                  motivation for this model is both psychologically and
own agent; the output of this equation can be compared to                   practically rooted. Psychologically, this model can be used
the output of the true dynamics model for the agent to                      to simulate a helicopter pilot’s gaze shifting as he attempts
determine when the models diverge. When, and only when,                     to visually track and reaquire multiple targets. Thus,
the error between models reaches a certain threshold, the                   instead of operating in a state of omniscience, the agent is
simulator broadcasts new state information for its agent.                   required to juggle the act of determining spatial information
Figure 1 shows this process in a DIS simulation called                      across multiple agents, as would be the human helicopter
ModSAF (Calder et al, 1993) that we used for our                            pilot. The functional ramification of this approach is that
experiments.                                                                the total number of perceptual inputs to the agent is reduced
                                                                            at any given instance. In other words, instead of getting
                                                                            continuous perceptual information on all of the ground
   ModSAF                                    ModSAF Entity
                                                                            entities within the helicopter agent’s field of view, by using
                                             Entity Data                    this predictive model, the agent only requires updated
   DR Model Update                     +                                    information on entities when its attention is focused on
                                       -                                    those entities.
                                                             State Data
       Last             Dead-Reckoning Model
                                                                              The high level architecture of this system is presented in
      ESPDU                                                                 Figure 3. The agent architecture is embedded in the
                                                                                      ModSAF
                                        Entity State Updates                           Soar
    DIS Network
                                                                                                                   Long-term Memory
 Figure 1. Dead-Reckoning Implementation in ModSAF                                                                 •Decision Making
Figure 2 shows how at a series of time steps, the true
                                                                                                                   Working Memory
position of an agent computed by the agent dynamics model
(shown by the curve) deviates from a linear dead                                                      Output link WMEs                    Input link WMEs
                                                                                        Soar-ModSAF Interface
                                                                                                                                         Neural Networks
                                                                                             Output Commands                          Perceptual Analysis
                                                                                            Motor Command                                            Environment
                                                                                                                    Helicopter Agent
                                                                                                                               Entity State Updates
                                                                                       DIS Network
           Figure 2. DIS Dead-Reckoning Process
                                                                                  Figure 3. Visual attention for helicopter agent

Modular Semi-automated Forces (ModSAF) simulator, a              approximately 7 kilometers long and takes a tank entity
system used by the military for training and research.           about 15 minutes of simulation time to travel at a March
ModSAF is elaborated on in section 2, “Methodology”.             Order speed of 8 m/s. From this 15 minute period, a total
The agent’s intelligence is modeled in Soar (Rosenbloom et       of 13760 movement updates were performed, generated at a
al, 1993; Newell, 1990). As a model of natural intelligence,     rate of 15 HZ.
the Soar software architecture combines the abilities to
react immediately to situations, use knowledge in
deliberative decision making, step back from the immediate
situation to perform various forms of problem solving and
planning, and learn from experience. As an indicator of the
maturity and sophistication of Soar-based agents, the
system has been used successfully as the production model
in a number of large-scale military exercises (Hill et al,
1997; Jones et al, 1999; Nielsen et al, 2000).
  The inputs to the neural networks developed for this
application consist of entity data (e.g., call-sign, sim-time,
position, velocity, etc.) and abstracted terrain information
germane to both “on-roads” and “cross-country” travel and
correlated to the entity’s visual field (hill, road, lake, etc).
All together, the input vector consists of 196 fields and the
                                                                                Figure 4. Route Used for Experiment
output vector consists of 15 output fields corresponding to
discretized changes in heading ranging from –35° to 35°.           For this application, a feed-forward architecture
The selected heading change, coupled with an assumed             developed with back-propagation training was used to
constant speed and “delta” time since last prediction, can be    develop the neural networks. One of these networks
used to predict the entity’s expected location at some time,     predicts the change in an entity’s speed and the second
t. With this prediction, the virtual helicopter pilot is able to network predicts the change in the entity’s heading. Each
look away from the ground entity for up to 7 seconds,            network used a sigmoid function at the hidden nodes and a
within some error threshold.                                     linear transformation at the output nodes.                              The
                                                                 configuration of the networks in each of the models may be
                       Methodology
                                                                 seen in Table 1
This paper seeks to compare the performance of a neural-
network based model with the dead-reckoning model. Like                        Table 1. Neural Network Architecture
both systems described in sections on dead-reckoning and
neural networks for trajectory estimation, this experiment is       Model            Arch                     Predictors              Resp
implemented in ModSAF, a training and research system
developed by the Army’s Simulation, Training, and                   Speed          8-20-5-1        Rat −1,Rbt −1,Rct −1,Rpt −1,       ∆St
                                                                                                   Rst −1,HRabt −1,HRbct −1,Hzt −1
Instrumentation Command (STRICOM).                    ModSAF
provides a set of software modules for constructing                Heading         7-20-5-1        Ra t −1 ,Rbt −1 ,Rct −1 ,Rp t −1 , ∆θ t
computer-generated force behaviors at the company level                                            Rs t −1 ,HRabt −1 ,HRbc t −1
and below. Typically, ModSAF models are employed to
represent individual soldiers or vehicles and their              where the inputs were normalized according to equations 2
coordination into orderly-moving squads and platoons; but,       – 19 below. Fundamentally, the inputs for each of the
their tactical actions as units are planned and executed by a    networks were a function of the entity’s state at the last
human controller. The human behaviors represented in             simulation clock and how this state related to the road
ModSAF include move, shoot, sense, communicate, tactics,         characteristics (width, heading, length of segment, etc) and
and situation awareness. The authoritative sources of these      March Order parameters (speed, end-point, etc). The
behaviors are subject matter experts and doctrine provided       specific predictors are expressed in 4 – 10, and the
by the Army Training and Doctrine Command (TRADOC).              parameters making up those inputs are explained in 11 – 19.
ModSAF uses state transition constructs inspired by finite
state machines (FSMs) to represent the behavior and                S t = S t −1 + ∆S t                                                 (2)
functionality of a process for a pre-defined number of             where ∆S t = f(Ra t −1 ,Rbt −1 ,Rc t −1 ,Rp t −1 ,
states.                                                                                Rs t −1 ,HRabt −1 ,HRbc t −1 ,Hz t −1 )
  The scenario used for the comparison was a road-march
for a tank entity 45-segment route shown in Figure 4 It is

  θ t = θ t −1 + ∆θ t                                            (3) Z-axis of tank). A typical threshold for dead-reckoning
  where ∆θ t = f(Rat −1,Rbt −1,Rct −1,Rpt −1,                        error tolerance in DIS is 10% of the vehicle’s dimensions.
                      Rst −1,HRabt −1 , HRbct −1 )
                                                                     In this case then, the error tolerance for this entity’s
  Ra t = S t ( Da t + M )                                        (4) location would translate into .356m along the X-axis,
  Rbt = S t ( Dbt + M )                                          (5) .734m along the Y-axis of the tank, and .233m along the Z-
                                                                     axis of the tank.
  Rct = S t ( Dc t + M )                                         (6)
  Rp t = S t Pt M                                                (7)
                                                                             ModSAF                                   ModSAF Entity
  Rst = S t / M                                                  (8)
  HRabt = Habr × Hxy t                                           (9)                                          Entity
                                                                                                              Data
                                                                                                                                NN Weights
  HRbct = Hbc r × Hxy t                                         (10)        NN Model Update                +
                                                                                                           -
  S t = entity speed at t                                       (11)                           NN            State Data
                                                                                Last           Model                             NN Engine
  Dat = distance to previous waypoint                           (12)           ESPDU                        Inputs/Outputs
  Dbt = distance to current waypoint                            (13)                             Inputs
                                                                                            ModSAF Environmental Variables
  Dct = distance to next waypoint                               (14)
  M = march order speed                                         (15)
  Pt = perpindicular distance to road                           (16)                                          Entity State Updates
                                                                              DIS Network
  Habt = direction of road segment ab                           (17)
                                                                        Figure 5. Neural Network Implementation used for
  Hbc t = direction of road segment bc                          (18)                        Experiments in ModSAF
  Hxy t = entity orientation                                    (19)
Of these, 860 examples were used for training the speed              The second way of determining an update threshold is with
network, 860 examples for training the heading network,              respect to the orientation of the vehicle. In this case, the
and 859 examples were used for validating the training of            components of the                  dead-reckoned euler angles are
both of these networks. The training rate was selected as            compared with the components of the entity’s true
0.01 and the initial momentum parameter was .9. The                  orientation. For tracked ground entities in ModSAF, this
momentum parameter was periodically adjusted to speed                measure is defaulted at 3°. That is, if the dead-reckoned
the rate of descent along the error surface. The training and        prediction is more than 3° off about X-axis, Y-axis, or Z-
validation results for each of the networks may be seen in           axis, an error is generated. Overall, at these error
Table 2.                                                             tolerances, the number of updates (ESPDUs) required by
                                                                     the dead-reckoning model was 351. Using these same error
             Table 2. Training and Validation Errors                 thresholds, the neural network models required 263
                                                                     updates. Thus, the neural networks required 25% fewer
                           Delta Speed               Delta Heading   updates than the dead-reckoning models. This information
                                ∆S                        ∆θ         is presented in Figure 6 according to type of update. In the
                           Error(m/s)                 Error(rads)    DR case, a small number of the required updates occurred
  Training            0.259977±2.04558             0.004578±0.00781  simultaneously between location and rotation.
  Validation          0.206374±0.82532             0.014221±0.06766
                                                                                    400
                                                                                    350
                       Experimental Results                                     U
                                                                                    300
                                                                                p   250
The neural network models were implemented in such a                            d   200
way that their performance for predicting entity location                       a
                                                                                 t  150
could be compared with the dead-reckoning model. This                           e
                                                                                    100
implementation is presented in Figure 5.                                        s
                                                                                     50
  There are two ways of generating an error in our system.
                                                                                      0
The first is according to the enity’s location. This error is                                Loc             Rot                   Total
measured in terms of comparing the entity’s dead-reckoned                          DR        205             154                   351
XYZ with the entity’s true XYZ and is proportioned                                 NN        112             151                   263
according to the width of the entity along its X, Y, and Z
axes. For example, an M1A2 tank is 3.56m in width                      Figure 6: Number of Updates Required by DR Model
(defined along X-axis of tank), 7.34m in length (defined                                        versus NN Model
along Y-axis of tank), and 2.33m in height (defined along

Although the neural network based model was able to                      5       1.78       3.67          15         119         137
predict the entity’s path with more accuracy, as evidenced               7      2.492      5.138          21          98         109
in Table 3, this increase in predictive utility comes at a cost          9      3.204      6.606          27          88          92
in processing time.                                                     11      3.916      8.074          33          70          79
                                                                        13      4.628      9.542          39          69          75
 Table 3. Execution Time Using Neural Networks and                      15       5.34      11.01          45          62          73
                                                                        20       7.12      14.68          60          51          60
             Dead-Reckoning Equations
                                                                        25        8.9      18.35          75          48          55
                                                                        30      10.68      22.02          90          44          48
                      Processing Time (in 10-5 seconds )
                 NN           NN            Total          DR            As evidenced in Table 4, as the error tolerance increases,
                Speed       Heading          NN                        the predictive advantage that neural networks have over
 Min            6.89029      6.19888       13.08981        2.2888      dead- reckoning models becomes less significant for this
 Mean           7.77692      7.47008       15.24700        2.7974      modeling task.
 Max            20.5993      29.7999        50.3992       6.35981
                                                                                    Summary and Conclusions
Using the UNIX “gettimeofday” function, the processing                 As one might expect, the choice of tool must be driven by
speed was calculated on a Pentium III, 500 Mhz machine,                the modeling constraints. The results reported above
running RedHat Linux 6.2. As shown in Table 3, the neural              suggest heuristics for when to apply which modeling
network based model required, on average, about 6 times                technique. For example, in an application where processing
more processing time than did the dead-reckoning based                 time is not the primary constraint e.g., multi-agent systems
model. As stated in Section 2, the simulation time was                 communicating over a wireless network, then the increased
approximately 15 minutes. On average then, the dead                    processing costs incurred from using a neural network may
reckoning model produced about 23 updates per minute or                be defendable. Alternatively, in an application where
rather, 1 update every 2.5 seconds (at a threshold of .356m            processing time is a limiting factor, then dead-reckoning
in the X direction and .734m in the Y direction).                      models may be the more prudent approach. It is interesting
Alternatively, the neural network based model required                 to note, also, that the differences in predictive utility of the
about 17 updates per minute, or approximately 1 update                 two modeling approaches becomes less prominent as the
every 3.5 seconds (at the same thresholds). Coupling this              error threshold is increased. This speaks to the power of
information with the information on processing time                    dead-reckoning models to generalize and scale.
tradeoffs, it becomes clear that for applications where                   It is important to recognize, of course, that the modeling
processing time is at a premium, the use of dead reckoning-            task in this research is limited in scope. Also, a different
models may be preferred, in spite of their poorer predictive           neural network could have yielded different results. We
performance.                                                           can not claim that this is the best network architecture or
  To further examine the relationship between the                      configuration for this specific modeling task. We can only
predictive power of the dead-reckoning models and this set             claim that it was one of the more promising configurations
of neural network models, we conducted experiments over a              with which we experimented. Other configurations may be
range of error tolerances. So, whereas the initial results,            better. One approach Henninger et al (1999) found
reported in Figure 6, were measured according to DIS                   particularly effective in improving the neural network based
default values for a tank entity (i.e., .356m, .734m, and 3°),         model’s performance was to work with modularized
follow-on tests incremented these error thresholds by those            models. This approach has been advocated in the control
exact amounts. Results are presented in Table 4 and                    literature (Murray-Smith and Johansen, 1997; Narendra et
reported only by total number of required updates.                     al, 1995) and robotics literature (Brooks, 1986), and we
                                                                       have started exploring this approach. One of the benefits of
      Table 4. Updates Required Over Increasing Error                  adopting this approach is the ability to mix different
                        Thresholds                                     modeling techniques as they best apply to the problem
                                                                       locally. For example, combinations of architectures and/or
                 Error Threshold              Updates Required         algorithms that can be applied to individual sub-problems,
 Factor of
             X-axis     Y-axis      All-                               make it possible to exploit specialist capabilities. In the
              (m)        (m)       axes                                problem discussed in this paper, one interesting test would
                                                NN              DR
                                   (deg)                               be to use dead-reckoning algorithms in straight parts of the
      1        .356        .734         3           263          351   road data base and then use neural networks to guide the
      2        .712       1.468         6           193          237   turn, as this appears to be where the majority of updates are
      3       1.068       2.202         9           157          188   required.
      4       1.424       2.936        12           138          156

                 Acknowledgements                            on Computer Generated Forces             and   Behavioral
                                                             Representation, (Orlando FL), 35-38.
This work was sponsored by the U.S. Army Simulation,
Training, and Instrumentation Command, contract N61339-      Lin, K., and Ng, H. 1993. Coordinate transformations in
98-K-0001. That support is gratefully acknowledged.          distributed interactive simulation (DIS). Simulation, vol.
                                                             61(5):326-331.
                       References                            Murray-Smith, R., and Johansen, T.A. 1997. Multiple
Brooks, R.A. 1986. A robust layered control system for a     Model Approaches to Modelling and Control. Taylor and
mobile robot. IEEE Journal of Robotics and Automation,       Francis, UK.
RA-2, 14-23.
                                                             Narendra, K. S., Balakrishnan, J., and Ciliz, K. 1995.
Calder, R.B., Smith, J. E., Courtemanche, A.J., Mar, J.M.,   Adaptation and learning using multiple models, switching
and Ceranowicz, A. (1993). ModSAF Behavior Simulation        and tuning. IEEE Control Systems Magazine June, 37-51.
and Control. In Proceedings of the 3rd Conference on
Computer Generated Forces and Behavioral Representation      Nielsen, P., Smoot, D., Martinez, R., and Dennison, J.
(Orlando FL), 347-356.                                       2000. Participation of TacAir-Soar in Road Runner and
                                                             Coyote exercises at Air Force Research Lab, Mesa, AZ.
DIS Steering Committee 1994. “The DIS Vision: A Map to       Proceedings of the 9th Conference on Computer Generated
the Future of Distributed Simulation”, Technical Report,     Forces and Behavioral Representation, (Orlando FL), 173-
IST-ST-94-01. Institute for Simulation and Training,         180.
University of Central Florida.
                                                             Newell, A. 1990. Unified Theories of Cognition. Harvard
Han, K. and Veloso, M. 1995. Automated robot behavior        University Press, Cambridge, MA.
recognition applied to robot soccer. Sixteenth International
Joint Conference on Artificial Intelligence. Workshop on     Rao, A. 1994. Means-end plan recognition. In Proceedings
Team Behaviour and Plan Recognition, 53-64.                  of KR-94, the Fourth Internatioanl Conference on
                                                             Principles of Knowledge Representation and Reasoning .
Henninger, A., Gonzalez, A., and Georgiopoulos, M. 1999.
Modeling Semi-automated forces with neural networks:         Rao, A. and Georgeff, M. 1995. BDI agents: From theory
Performance improvement through a modular approach.          to practice, In Proceedings of the First International
Proceedings 9th Conference on Computer Generated Forces      Conference on Multi-Agent Systems, (San Francisco CA).
and Behavioral Representation, (Orlando FL), 261-268.        Rosenbloom, P., Laird, J., and Newell, A. 1993. The Soar
Hill, R. W., Chen, J., Gratch, J., Rosenbloom, P., and       Papers: Research on Integrated Intelligence. MIT Press,
Tambe, M. 1997. Intelligent agents for the synthetic         Cambridge, MA.
battlefield: A company of rotary-wing aircraft.           In Tambe, M. and Rosenbloom, P. 1995. RESC: An
Proceedings of the Ninth Conference on Innovative            approach for real-time, dynamic agent tracking. In
Applications of Artificial Intelligence, 1006-1012. Menlo    Proceedings of IJCAI.95.
Park, CA: AAAI Press.
                                                             Tambe, M.        1996. Tracking dynamic team activity.
Jones, R. M., Laird, J. E., Nielsen, P. E., Coulter, K. J.,  Proceedings of AAAI-96.
Kenny, P., and Koss, F. V. 1999. Automated intelligent
pilots for combat flight simulation. AI Magazine, 20(1):     Washington, R. 1998. Markov tracking for agent
27-41.                                                       coordination. In Proceedings of the Second International
                                                             Conference on Autonomous Agents (Minneapolis/St. Paul
Kim,Y., Hill, R., and Gratch, J. 1999. How long can an       MN.
agent look away from a target? Proceedings 9th Conference

