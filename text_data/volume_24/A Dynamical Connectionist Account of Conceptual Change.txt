UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Dynamical Connectionist Account of Conceptual Change
Permalink
https://escholarship.org/uc/item/0hw159wk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)
Authors
Raftopoulos, Athanassios
Demetriou, Andreas
Publication Date
2002-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                      A Dynamical Connectionist Account of Conceptual Change
                                           Athanassios Raftopoulos (raftop@ucy.ac.cy),
                                             Andreas Demetriou (ademet@ucy.ac.cy)
                                      Department of Educational Sciences, University of Cyprus
                                                P.O. Box 20537, 1678 Nicosia, Cyprus.
                             Abstract                                cognitive level by transforming representations, such as
                                                                     Newell and Simon’s (1972) “problem behavior graph” in
   Conceptual change can be accounted for at various levels of       production systems. In the connectionist paradigm one can
   explanation. The cognitive level (Marr’s computational level),    study the processes of the emergence of new attractors, and
   the representational (Marr’s “algorithmic”), and the              repositioning of points realizing representational states in
   implementational level. In this paper, we offer a dynamical       high-dimensional state spaces (Horgan and Tienson, 1996),
   account of types of conceptual change at the representational
   level. Our aim is to show that some classes of neural models can
                                                                     or the changes in the connection weights and network
   implement the types of change that we have proposed elsewhere.    structure (Elman et al., 1996; Schultz et. al., 1995; Plunkett
   First we briefly describe at the cognitive level certain types of & Sinha, 1992).
   change that purport to account for some of the kinds of                In this paper, we will discuss a theory of different types
   conceptual change. Then we lay forth the framework of             of cognitive change and their implementation at the
   dynamical connectionism; we discuss the representational level    representation level. Our aim is to show how certain classes
   realizations of the cognitive level and claim that these can be   of neural networks could implement some of the types of
   depicted as points in the system’s activational landscape. We     change that the authors have proposed (Demetriou and
   offer, third, a dynamical account of some types change and we     Raftopoulos, 1999). First, we will summarize these types of
   claim that conceptual change can be modeled as a process of       change. In the second part we will sketch the framework for
   modification, appearance of new and disappearance of attractors
   and/or basins of attraction that shape the system’s landscape.
                                                                     the dynamics of change, relying on the dynamical
   Finally, we discuss the kinds of mechanisms at the                interpretation of connectionist networks to explore possible
   representational level that could produce the types of change     means of modeling the stipulated types. In the third part we
   observed at the cognitive level, as modeled by means of           offer a dynamical account of some types change and we
   dynamic connectionism.                                            claim that conceptual change can be modeled as a process of
                                                                     modification, appearance of new and disappearance of
                                                                     attractors and/or basins of attraction that shape the system’s
                          Introduction                               landscape. Finally, we discuss the kinds of mechanisms at
      Conceptual change can be accounted for at various              the representational level that could produce the types of
levels of explanation. Following Marr (1980), one can                cognitive change.
distinguish between three levels: the computational, the                  To that end we will employ neural networks whose
algorithmic, and the implementational level of explanation           behavior can be viewed as falling under one or the other of
of cognitive systems. We prefer the term “cognitive” to              our kinds of change, and describe the behavior that neural
“computational”, and the term “representational” to                  networks should exhibit if they are to implement type of
“algorithmic”, since there are accounts of cognition that            change.
deny the algorithmic nature of mental operations.
     At the cognitive level, one can discuss cognitive
operations that apply to information-processing content                                   Types of Change
(such as addition and subtraction), operations that apply to         Demetriou and Raftopoulos (1999) previously published a
structures as wholes, such as differentiation or coalescence         theory of conceptual change that addresses the issue of how
(Carey, 1985; Chi, 1992), or, conceptual combination,                a learning system makes the transition from one state to
generalization and abduction, and hypothesis formation               another. The theory provides a detailed analysis of the types
(Thagard, 1992). This level addresses the issue of the               of change that are observed both in cognitive development
functions computed by the information processing system.             and during learning. The types of change are summarized in
       At the representational level one can examine the             Figure 1.
algorithmic processes that realize conceptual change at the

                              Cognitive Mechanisms of
                              Change
                                                                        Neural Networks as Dynamical Systems
                                                                             Recurrent neural networks (Elman, 1990) with
                                                                        distributed representations and continuous activation levels
                                                                        can naturally be construed in a dynamical way. They can be
                                                       Tunings
                                                                        described by means of the evolution of the activation values
                      Mappings                                          of their units over time. To be able to model growth and
                                                                        avoid problems of lifelong (mainly catastrophic
                            Fusion           Differentiation            interference), one needs to consider a special class of
           Bridging                                          Refinement networks, namely adaptive or generative networks. These
                                                                        networks can modify their structure during learning by
                                                                        adding or deleting nodes and can change their learning rates.
                     Structural Analogy                                      The number of units of the network determines the
         Interweaving                                                   number of dimensions of the state-space associated with the
Combination                                                             system. Their activation values constitute the actual position
                  Restructuring Conflation
                                                                        in the state-space of the system. Adding a time-dependent
                                                                        parameter yields the phase-space of the system. Both in
Fig. 1. The types of change                                             state- and phase-space, one can represent all the possible
                                                                        states that a system can take in time. Hence, in the
     We will briefly present here combination, and fusion.              connectionist account, the states of a cognitive system are
Bridging is a class of types of change, whose unifying                  depicted by the sets of activation values of the units that
feature is that (a) two or more existing structures are                 distributively encode these states.
brought together to bear on each other and form a more                       These activation values are the variables of the
complex structure, and (b) after bridging the constituent               dynamical system and their temporal variation constitutes
structures retain their functional autonomy, even though                the internal dynamics of the system. In addition to the state-
they may have been modified. The blended structures may                 space of a system, an external control space is also defined.
remain unaltered and the resulting structure(s) may retain              The external space contains the real-value control
the characteristics of the constituent structures (as when              parameters that control the behavior of the system, i.e., the
“striped” and “apple” are combined to produce “striped                  connection weights, biases, thresholds, and, in networks in
apple”. In this case, the type of change is combination.                whose structural properties are implemented as real-value
     Fusion differs from bridging in that the mapped                    parameters (Raijmakers et. al., 1996), the structure of the
structures do not retain their relative autonomy after the              system. In dynamical systems the fast internal dynamics is
mapping; instead, they fuse to one of the existing structures,          often accompanied by a slow external dynamics. The
or form a new structure. An example would be the fusion of              external dynamics consist of the temporal paths in the
retrieval and counting strategies, which are involved in                external control space. The external dynamics consist of the
simple operations of addition and subtraction performed by              network’s learning dynamics (the various learning rules)
children aged 4-6. After fusion, around the age 6-7, the                and the dynamics that determine structural changes, such as
predominant strategy is retrieval by rote memory (Siegler,              the rules for inserting nodes in cascade correlation and
1996).                                                                  growing radial basis function networks.
                                                                             When the network receives input, activation spreads
                The Representational Level                              from the input units to the rest of the network. Each pattern
     We discuss here the way representations can be                     of activation values defines a vector or a point, within the
modeled as properties of cognitive systems. At this level               activational space of the system whose coordinates are the
one examines the mathematical implementation of the                     activation values of the pattern. The activation rules
cognitive level. In other words, we examine the way                     determine the state transitions that specify the internal
cognitive states are represented and how they are                       dynamics of the system, i.e., the functions of the evolution
transformed and processed by means of operations                        of the system in time. Thus, the behavior of such a system is
performed on data structures.                                           depicted as a trajectory between points in the activational
     These transformations can be either algorithmic                    state space.
(determined by a set of rules that apply to discrete static                  The activation rules, the number of units, the pattern of
symbols that are the representations of the system) or                  their connectivity, and the learning rate(s) of the network
dynamical (determined by mathematical relations that apply              determine the architecture of the system. These factors are
to continuous variables and specify their interrelations and            determined by its long-term history of experiences, since the
evolution in time). This is why we call these transformative            class of networks discussed here may modify either their
processes mathematical-state transitions; they describe the             patterns of connectivity, as they learn, by adding nodes,
way the system moves between points in its state-space. We              deleting nodes, and sharpening their connections, or their
will address the issue of change from the perspective of                biases and learning rates. The activation vectors and the
connectionist theory interpreted in a dynamical way. Thus,              behavior of the system evolve as a result of the synergies
will assume that a cognitive system is associated with a                among the architecture of the network, the input it receives,
dynamical system physically realized by a neural network.               and the previous activity of the network, under the control
                                                                        of the external dynamics.

     The behavior of the system is a collective effect of        inputs (tokens) give rise to the same stable point of
cooperation and competition, (Kelso, 1995). The                  attraction, the attractor (type), which in this sense offers a
competition is due to the effort of the system to retain its     dynamical analog of the classical symbol (Elman, 1995).
current state in the face of incoming information. If this            The dynamical “symbols”, unlike the symbols of
information cannot be assimilated by the system, then the        classical cognitivism, are dynamic and fluid rather than
weights of a network change and the network may alter its        static and context independent. The dynamic properties
structure to accommodate the new input.                          result from the dynamical nature of the activations of
     The activation states, in which a network may settle into   associative patterns of units. As the network learns and
after it is provided with an input signal, are the attractors of develops, the connection strengths continuously change.
the system. These are the regions in state-space toward          The same happens when new units emerge and old units
which the system evolves in time. The points in state-space      “die” and the system reconfigures to maintain its knowledge
from which the system evolves toward a certain attractor lie     and skills. All these cause changes in the original pattern in
within the basin of attraction of this particular attractor.     which an attractor/symbol was created in the first place, and
Thus, the inputs that land within the basin of attraction of an  as a result, subsequent activations differ. The same effects
attractor will be transformed by the connectivity of the         are caused by the different contexts in which the “symbol”
network so that they end up at this attractor where the          may be activated. This happens because connections from
system will settle.                                              the differing contextual features bias the activation of the
     Networks in which the outputs change over time until        units of the original pattern in different ways emphasizing
the pattern of activation of the system settles into one of      some feature of the pattern or other. Thus, the
several states, depending upon the input, are called attractor   attractor/symbol is almost never instantiated with the same
networks. The sets of possible states into which the system      activation values of the units that realize it.
can settle are the attractors. If the network is used to model        The activational state-space of a network is a high-
cognitive behavior, then the attractors can be construed as      dimensional mathematical landscape. The state transitions in
realizing cognitive states to which the system moves from        such a system are trajectories from one point on to another.
other cognitive states that lie within the attractor’s basin of  Attractors correspond to cognitive states and the activation
attraction.                                                      pattern that realizes each state is a vector, or a point. Thus,
     The signal of the input is transformed as it moves          cognitive states are realized by points on this landscape.
through the hidden units into an attractor pattern as follows:   Since the distributed encoding of a cognitive state does not
a given input moves the system into an initial state realized    involve all units of the system, there will be points on the
by an initial point. This input feeds the system with an         activational landscape that will realize more than one
activation that spreads causing the units of the system to       cognitive states (the set of coordinates of a point may satisfy
change their states. The processing may take several steps,      the partial coordinates given by several activational
as the signal is recycled through the recurrent connections in   vectors).
the network. Since any pattern of activity of the units               During the phase of activation-value changes the system
corresponds to a point in activation space, these changes        passes through various possible outputs. All these outputs
correspond to a movement of the initial point in this state      can be viewed as lying on an energy surface. When the
space. When the network settles, this point arrives at the       system passes through a certain output-state whose energy is
attractor that lies at the bottom of the basin in which the      not lower than the energies of the neighboring states, it goes
initial point had landed. In this sense, the inputs fed into the through another phase of activation-value changes in order
system are the initial conditions of the dynamic system.         to reduce the energy of the output state. When it reaches a
Similarly to a dynamical system that settles into a mode         point at which all the neighboring states have higher
depending on its initial conditions, a neural network settles    energies, it settles.
into the attractor state in whose basin of attraction the input       These states of minimum local energy are the attractors
falls.                                                           and can be construed as valley bottoms on energy surfaces.
     For instance, in a semantic network meanings of words       Thus, attractors should be distinguished from the networks’
are represented as patterns of activity over a large number of   outputs in general. Not all outputs are settling points.
semantic features. However, only some of the combinations        Attractors form a subset of the set of outputs of a network,
of semantic features are features of objects. The patterns       in that they are those outputs at which the system can settle.
that correspond to these combinations are the attractors of      When the input of the system is such that the activation state
the network, which are points in the state space                 of the system lies within the walls of the valley, the system
corresponding to the semantic features of the prototype of       will settle at the attractor at its bottom. Hence, the valley is
the object signified by the word. These attractors are the       the basin of attraction that leads to the specific attractor-
meanings of words.                                               state of minimum energy. Since the network has many
     The concepts “attractor” and “basin of attraction”          attractors and basins of attraction, their relative position
suggest a way of simulating the classical notion of symbol.      shapes the relief of the activational landscape of the system.
The attractor basins that emerge as the network interacts
with specific inputs might be construed to have symbolic-          Modeling the Dynamics of Cognitive Change
like properties, in that inputs with small variations that fall       In this theoretical framework, cognitive change results
within the same attractor basin are pulled toward the same       from the molding of the activational landscape, as a result of
attractor (or cognitive state) of the system. Thus, various      changes in the weights and the architecture of the network,

as the network attempts to accommodate new input signals.
The molding may result either in the emergence of new,
and/or disappearance of old, attractors, or in the reshaping
of the basins of attraction. This process corresponds to a
trajectory on the activational landscape. The idea that                                                by
change is to be modeled by means of transitions in the state                 B
space of a dynamic system is at the heart of dynamical
theories of cognition. Transitions in the state space of a                                   do        dy
dynamic system substitute for the algorithmic syntactically                  D
governed transitions of cognitivism.
     The relief of the landscape determines the trajectories
that are allowed, and the possible transformations among                     N
cognitive states. Cognitive change, thus, depends on the
activational landscape of the system that learns. When
information enters, the system tends to assimilate it within                               O        Y
the existing framework of knowledge, which, in neural
networks, is determined by the connection weights and the         Figure 2. Componential attractors
architecture of the network, which, in their turn, distribute
the points that realize cognitive states on the network’s              After the new pronunciation is learned, the two basins
landscape. We have posited certain types of cognitive             change their relative positions so that they intersect. Their
change. In what follows we will sketch their dynamic              intersection (i.e., the pattern corresponding to both sets of
realization at the representational level.                        features) forms a new basin, which is the area in which the
                                                                  two basins overlap. The appearance of a new basin of
Combination                                                       attraction represents the learning of a new concept. The new
     This type of change involves the combination of              basin of attraction is superimposed onto the two intersecting
structures in such a way that the existing attractors and the     basins. The basins of attraction (sub-basins) and the
landscape’s relief (their basins of attraction) of the system     attractors do not change. Whatever input was falling within
are not affected. The new structure is superimposed, as it        one of the two basins before learning, still does so after the
were, on the constituent structures. Consider the networks        network has learned the new concept. The only change after
that simulate learning to pronounce words and non-words           learning is that some inputs fall within both the new basin
(Plaut et. al. 1996). These networks learn the pronunciation      and the old basins of attraction, This is a result of the
of both regular and irregular words, by building the              superimposition of the new basin of attraction onto the two
appropriate attractors. The attractors of regular words           sub-basins.
consist of componential attractors, in which case the basin
of attraction is the intersection of the sub-basins of attraction Fusion
of the componential attractors. The exception words have                Stable structures within the neural net can be thought
their own attractors with a lesser degree of componentiality.     of as attractor states. Thus, the activation pattern of the
Combination explains the ability of the network to learn the      structure attracts all other activation patterns that are similar
pronunciation of words and non-words, in that this                enough with it (that is, all activation patterns that fall within
knowledge is the result of the combination of the sub-            the basin of attraction of the attractor). As a network learns,
knowledge encoded by the componential attractors, as is           a new attractor state may emerge, which swallows the
shown in Figure 2.                                                attractors that existed before. This is what happens in fusion.
    In this figure only two componential attractors are           The two initial basins of attraction are also swallowed by
depicted, for onset and the vowel in the reduced two-             the new one, so that all patterns that were falling within the
dimensional activation space of the phonemic units of the         one or the other now fall within the new basin of attraction.
network. The basins of attraction for the word “by” and the       The system undergoes a phase transition that can be
non-word “dy” are the intersections of the sub-basins for         described as a reverse Hopf bifurcation (Figure 3), in which
pronunciation of b, d, and y, that is, the regions in the state   two stable states (bistability) are fused and disappear, and
space in which these sub-basins overlap. The black circle is      one stable state emerges (unistability).
the attractor for the word by, and the striped circle is the           Figure 4 displays the phase transitions associated with
attractor for the non-word dy. The trained network learns to      the fusion of “counting from one” and “memory retrieval”
pronounce words by applying its knowledge regarding the           strategies (used by 4-6 year old children in simple arithmetic
pronunciation of the parts of the words (and of the role of       tasks) to the “memory retrieval” strategy that becomes
context in pronunciation when it comes to exception words).       predominant between 6 and 7 years of age.
The reduced componentiality of the exception words is
depicted by means of a deformation of the intersection of
the salient attractors for the onset d and the vowel o. The
componential attractors and their basins of attraction remain
unaltered.

                                                 V
                                                              and the activation functions, its molding is the result of
                     S
                                                              changes in the structure of the network. Networks evolve as
                                                    S         a result of the system’s effort to adapt to a new
                                                              environment, by superimposing new representations to old
    V
                                                              ones. Thus, the system modifies the “knowing assumptions”
                                                              that do not fit in.
                              Control Parameter
                                                                   The account of cognitive change at the representational
            S
                                                              level allows us to recast the discussion regarding strong and
                                                 V
                                                              weak representational change in terms of dynamic systems
                                                              theory. Whether a cognitive change is weak or strong
                                                   S          depends on whether the new structure increases the
                                                              representational resources of the system. Since
Figure 3. Fusion as an inverse Hopf bifurcation               representations are points in the state space of the system,
                                                              the expressive contents of the system correspond to such
                                                              points. If the relief of the landscape is such that the system
      The generative networks designed by Schultz et. al.,    cannot settle at a content realizing point, that is, if this point
(1995) to model a series of cognitive tasks simulate the      is not a possible attractor state, the content that is realized
variability of the strategies available to children. Networks by this point is not within the expressive capabilities of the
at some stage of their training in the balance-beam tasks     system. When changes in the relief render this point an
may “employ” two different strategies to solve the same       attractor, the change is strong; it results in an increase in
problem and, as training continues, progress to using         representational power.
reliably the more advanced strategy. These networks                But the mere appearance of an attractor does not
implement “fusion”, by moving from bistability to             necessarily imply that a radical change has taken place, that
unistability.                                                 is, that this is a novel attractor state. This is so if the content
                                                              realizing point that appears as a new attractor was in fact
                       counting retrieval                     expressible within the system; that is, if the system could
                                                              have settled at that point, even if it had not done so, up to
                                                              that time. When the structures “striped” and “apple” are
                                                              combined an attractor state “appears and the system
                                                              acquires the new concept of “striped apple”. This “new”
                                                              attractor is a region in the state space, which realizes the
                                                              content “striped apple” and is superimposed on the
                                                              attractors of “apple” and “striped”. But this is not a novel
                                                              attractor, because this content was already within the
                                                              expressive power of the system, since the relief of the
                                                              landscape was such that the system could have settled if fed
                                                              with the appropriate input at this point. In other words, the
                                                              “new” attractor was situated at a local energy minimum in
                                                              which the system could have settled if it had been fed with
                       collective variable (age)              the appropriate input (the experience of a striped apple). The
                                                              attractor appears without the landscape being molded and
Figure 4. Fusion of two counting strategies                   this attractor is just the sum of information expressed by the
                                                              other attractors, which remain intact. In this case, the
                                                              ensuing change is weak.
         Strong and Weak Cognitive Change                          Weak change refers to changes in the semantic content
      In this context of dynamical connectionism, cognitive   of representations, which broaden their field of application
change consists in changes in connection weights, the         but do not increase the expressive capabilities of the system.
structure, and the learning rates of the network. In          Attractors are merely repositioned in the landscape, which
connectionist networks an individual’s state of knowledge is  means that the activation patterns that define them do
determined by the weights of the hidden units. Cognitive      change. Reposition of any content-realizing point is
representational change is regarded as the individual’s       accompanied by changes in the activation values that
actual path through the space of possible synaptic            constitute the point’s activation pattern, and changes in its
configurations, that is, as the transformations of the weight spatial relations with other content realizing points. Since
vector in an n-dimensional weight space, where n is the       semantic information in dynamic systems is captured by the
number of the weights.                                        relative positions of content realizing points, repositioning is
      The appearance of novel cognitive states, and thus, the accompanied by semantic change.
appearance of new attractors and the disappearance of old          This scenario does not apply to the case of fusion. No
ones, implies a change of relief in the network’s landscape   mere intersection of existing basins of attraction or any
(molding). Since the relief depends on the structure of the   simple repositioning, could accommodate the salient input.
network, that is, the number of nodes, their connectivity,    A reshaping of attractor basins is required, as well as the

disappearance of an older attractor and the emergence of a                             References
novel one. These changes mould the landscape.                   Carey, S. (1985). Conceptual change in childhood.
     Thus, when new information is learned with                    Cambridge, MA: The MIT Press.
repositioning of attractors and basins of attraction, and       Chi, M. T. H. (1992). Conceptual Change within and across
attractors are preserved (though the slope of the basins may       Ontological Categories. In R. Giere (Ed.), Cognitive
change, with some becoming steeper and others becoming             models of science. Minnesota University Press, 112-136.
less steep), the resulting change is weak. Updating the         Demetriou, A., & Raftopoulos, A. (1999). Modeling the
connection weights seems to suffice for this. If the change in     developing mind: From structure to change.
weights does not suffice for learning, the landscape is            Developmental Review, 19, 319-368.
molded by changes in the network’s structure (Horgan and        Elman, J. L. (1990). Finding structure in time. Cognitive
Tienson, 1996). This may induce the appearance of new              Science, 14 , 179-211.
attractors; since the attractors are points on the landscape,   Elman, J. L. (1995). Language as a dynamic system. In R.
the appearance of new cognitive states realizing points on         F. Port & T. Van Gelder (Eds.), Mind As motion:
this landscape, and the disappearance of old constitute            exploration in the dynamics of cognition. Cambridge,
strong changes, since the content-expressive power of the          MA: The MIT Press.
system increases. This process may require structural, i.e.,    Elman, J. L., Bates, E. A., Johnson, M. H., Karmiloff-
qualitative, change.                                               Smith, A., Parisi, D., & Plunkett, K. (1996). Rethinking
                                                                   innateness: a connectionist perspective on development.
                    Mechanisms of Change                           Cambridge, MA: The MIT Press.
     At the cognitive level, the main Piagetian mechanisms      Horgan, T., & Tienson, J. (1996). Connectionism and the
driving      conceptual      changes      are     assimilation,    philosophy of psychology. Cambridge, MA: The MIT
accommodation, and equilibration. It is time now to                Press.
consider the mechanisms driving change at the                   Kelso, S. (1995). Dynamic patterns: the self organization of
representational level. In each of the types of change             brain and behavior. Cambridge MA: The MIT Press.
discussed previously the processes that lead to the change      Marr, D. (1982). Vision: A computational investigation into
are the same, always reducing to quantitative and qualitative      human representation and processing of visual
changes in connection weights and the architectural                information. San Francisco, CA: Freeman.
structure of the network. These processes cause the             McClelland, J. L. (1989). Parallel distributed processing:
repositioning of existing attractors, the disappearance of old     implications for cognition and development. In R. G. M.
ones, the appearance of new ones, and changes in the basins        Morris (Ed.), Parallel distributed processing:
of attraction that shape the relief of the landscape. It could     Implications for psychology and neurobiology. Oxford:
hardly be otherwise. In connectionism the computational            Oxford University Press.
mechanisms are domain general, statistical learning             Newell, A., & Simon, H. A. (1972). Human Problem
mechanisms, based on brain-style computation, that is, (a)         Solving. Englewood Cliffs, NJ: Prentice Hall.
on the spreading of the activation of each unit to other units, Plunkett, K., & Sinha, C. (1992). Connectionism and
(b) on the modification of the connection weights, and (c)         developmental theory. British Journal of Developmental
on the modification of the network structure.                      Psychology, 10, 209-254.
     McClelland (1989) argued that Piagetian “assimilation”     Raijmakers, M. E. J., van der Maas, H. L. J., & Molenaar,
corresponds to the activation spread in a network when a           P. C. M. (1996a). Numerical bifurcation analysis of
signal is presented to the input units and propagates through      distance-dependent on-center off-surround shunting
the network causing the activation of its units. The alteration    neural networks. Biological Cybernetics, 75, 495-507.
of the weights, as a result of the network’s learning, models   Shultz, T. R, Schmidt, W. C., Buckingham, D., &
Piaget’s “accommodation”, that is, the change that the             Mareschal, D. (1995). Modeling cognitive development
network undergoes trying to fit in new experiences. Shultz,        with a generative connectionist algorithm. In T. J. Simon
et al., (1995), and others, have proposed networks that adapt      & G. S. Halford (Eds.), Developing cognitive
their structure as they learn by increasing their hidden units     competence: new approaches to process modeling.
to accommodate the demands of the task. They offer a               Hillsdale, NJ: Erlbaum.
variation of McClelland’s account that is suited better for     Siegler, R. S. (1996). Emerging minds. Oxford: Oxford
networks that can modify their structure. The quantitative         University Press.
phase of error reduction and weight change may correspond       Plaut, D. C., McClelland, J. L., Seidenberg, M. S., &
to Piaget’s “assimilation” of information in a pre-existing        Patterson, K. (1996). Understanding normal and
structure, whereas the qualitative structural change               impaired word reading: Computational principles in
corresponds to Piaget’s “accommodation” of the system.             quasi-regular domains. Psychological Review, 103(1),
Quantitative change renders possible knowledge acquisition         56-115.
within a fixed representational framework, whereas              Thagard, P. (1992). Conceptual Revolutions. Princeton, NJ:
qualitative change allows an increase in representational          The Princeton University Press.
power.

