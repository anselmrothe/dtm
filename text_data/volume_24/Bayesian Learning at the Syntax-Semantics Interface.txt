UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Bayesian Learning at the Syntax-Semantics Interface

Permalink
https://escholarship.org/uc/item/5rk8v7v7

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Author
Niyogi, Sourabh

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Bayesian Learning at the Syntax-Semantics Interface
Sourabh Niyogi (niyogi@mit.edu)
Massachusetts Institute of Technology
Cambridge, MA USA

Abstract
Given a small number of examples of sceneutterance pairs of a novel verb, language learners
can learn its syntactic and semantic features. Syntactic and semantic bootstrapping hypotheses both
rely on cross-situational observation to hone in on
the ambiguity present in a single observation. In
this paper, we cast the distributional evidence from
scenes and syntax in a unified Bayesian probablistic
framework. Unlike previous approaches to modeling lexical acquisition, our framework uniquely: (1)
models learning from only a small number of sceneutterance pairs (2) utilizes and integrates both syntax and semantic evidence, thus reconciling the
apparent tension between syntactic and semantic
bootststrapping approaches (3) robustly handles
noise (4) makes prior and acquired knowledge distinctions explicit, through specification of the hypothesis space, prior and likelihood probability distributions.

Learning Word Syntax and Semantics
Given a small number of examples of scene-utterance
pairs of a novel word, a child can determine both the
range of syntactic constructions the novel word can
appear in and inductively generalize to other scene
instances likely to be covered by the concept represented (Pinker 1989). The inherent semantic, syntactic, and referential uncertainty in a single sceneutterance pair is well-established (c.f. Siskind 1996).
In contrast, with multiple scene-utterance pairs, language learners can reduce the uncertainty of which
semantic features and syntactic features are associated with a novel word.
Verbs exemplify the core problems of sceneutterance referential uncertainty. Verbs selectively
participate in diﬀerent alternation patterns, which
are cues to their inherent semantic and syntactic features (Levin 1993). How are these features
of words acquired, given only positive evidence of
scene-utterance pairs?
The syntactic bootstrapping hypothesis (Gleitman
1990) is that learners exploit the distribution of
“syntactic frames” to constrain possible semantic
features of verbs. If a learner hears /glip/ in frames
of the form /S glipped G with F/ and rarely hears /S
glipped F into G/, the learner can with high confidence infer /glip/ to be in the same verb class as

/fill/ and have the same sort of argument structure. A diﬀerent distribution informs the learner
of a diﬀerent verb class. Considerable evidence has
mounted in support of this hypothesis (c.f. Naigles
1990, Fisher et al 1994). In contrast, the semantic
bootstrapping hypothesis (Pinker 1989) is that learners use what is common across scenes to constrain
the possible word argument structures. If a learner
sees a liquid undergoing a location change when /S
glipped F/ is uttered, then /glip/ is likely to be in
the same verb class as /pour/ and have the same
sort of meaning.
Both hypotheses require the distribution of crosssituational observations. Prior accounts to model
word learning have either ignored the essential role of
syntax in word learning (Siskind 1996, Tenenbaum
and Xu 2000), or require thousands of training observations (Regier et al 2001) to enable learning. In
this paper we present a Bayesian model of learning
the syntax and semantics of verbs that overcomes
these barriers, by demonstrating how word-concept
mappings can be achieved from very little evidence,
where the evidence is information from both scenes
and syntax.

Bayesian Learning of Features
We illustrate our approach with a Bayesian analysis
of a single feature. On some accounts, verbs possess a cause feature which may be valued 1, *, or 0
(Harley and Noyer 2000); depending on the value of
the cause feature, the verb may appear in frame F1,
F0, or both:
1 Externally caused - Ex: touch, load
F1: He touched the glass.
F0: *The glass touched.
* Externally causable - Ex: break, fill
F1: He broke the glass.
F0: The glass broke.
0 Internally caused - Ex: laugh, glow
F1: *He laughed the children.
F0: The children laughed.

Assuming this analysis, learners who hear utterances
containing a novel verb, not knowing the value of its
cause feature, must choose between 3 distinct hypotheses H1 , H§ , and H0 . Clearly, one utterance
cannot uniquely determine the value of the feature:
if learners hear F1 (/S Ved O/), the feature sup-

ports H1 or H§ ; similarly, if learners hear F0 (/O
Ved/), the feature may be H0 or H§ . Two utterances cannot determine the feature uniquely either.
Learners might receive both F1 and F0, supporting
H§ uniquely. But they may also accidentally receive
2 utterances of the same form (F0, F0 or F1, F1),
thus not resolving the ambiguity. If learners received
6 utterances of the same form F0 or F1, however,
then there is overwhelming support for H0 or H1
respectively, and H§ seems far less likely.
A Bayesian analysis renders the above analysis
precise and quantitative. Knowledge is encoded in
three core components: (1) the structure of the hypothesis space H; (2) the prior probability p(Hi ) on
each hypothesis Hi in H, before learners are provided any evidence; (3) the likelihood of observing
evidence X given a particular Hi , p(X|Hi ). Given
evidence X = [x1 , . . . , xN ] of N independent observations, by Bayes’ rule the posterior probability of a
particular hypothesis Q
Hi is:
N
j=1 p(xj |Hi )p(Hi )
p(Hi |X) =
(1)
p(x1 , . . . , xN )
signaling the support for a particular hypothesis Hi
given evidence X.
In this case, xj is the observation of a syntactic
frame (F0 or F1), and X is a distribution of syntactic frames. One simple prior probability model
p(Hi ) has each of the 3 hypotheses are equally likely,
encoding that a verb is equally likely to be of the
/touch/, /laugh/ or /break/ class:
1
p(H1 ) = p(H§ ) = p(H0 ) =
(2)
3
and a likelihood model p(xj |Hi ) encoding how likely
we are to observe frames F0 or F1 for the 3 diﬀerent
feature values of cause:
p(xj = F 1|H1 ) = .95 p(xj = F 0|H1 ) = .05
p(xj = F 1|H§ ) = .50 p(xj = F 0|H§ ) = .50 (3)
p(xj = F 1|H0 ) = .05 p(xj = F 0|H0 ) = .95
The above likelihood model says that when a verb
has cause=1, we expect frames of the form /S Ved
O/ 95% of the time; when a verb has cause=0, we
expect /O Ved/ 95% of the time; when a verb has
cause=*, we expect both syntactic frames.
Both the prior probability model and likelihood
model are stipulated, encoding a learner’s prior
knowledge of grammar. Given these probability
models, this allows for explicit computation of the
support of each hypothesis. Suppose a learner receives F0. Then the support for each of the 3 hypotheses may be computed to be:
(.05)(.33)
= .033
(.05 + .50 + .95)(.33)
(.50)(.33)
p(H§ |F 0) =
= .333
(.05 + .50 + .95)(.33)
(.95)(.33)
p(H0 |F 0) =
= .633
(.05 + .50 + .95)(.33)
p(H1 |F 0) =

(4)

Any number of situations may be analyzed as such:
1
2
3
4
5
6

Evidence X
p(H1 |X) p(H§ |X) p(H0 |X)
F0
.033
.333
.633
F0, F0
.002
.216
.781
F0, F0, F0, F0, F0, F0
2e-8
.021
.979
F0, F1
.137
.724
.137
F0, F1, F0, F1, F0, F1
.007
.986
.007
F0, F1, F1, F1, F1, F1
.712
.288
5e-6

When only F0 is given as evidence (situation 1),
while both H0 and H§ are consistent with the observation, H0 is nearly twice as likely. However, with
2 observations of F0 (situation 2) or 6 observations
(situation 3), it is increasingly likely that H0 is the
correct hypothesis. With both F0 and F1 as evidence (situation 4), in contrast, H§ is far more likely;
with more evidence (situation 5), it becomes more
so. Finally, if the first frame is a “noise” frame and
followed by 5 representative frames of F1 (situation
6), then H1 is more likely instead.
Given this framework, just one or two observations is suﬃcient to make an informed judgement.
Note that each additional observation increases certainty, and noise is handled gracefully.

Modeling Semantic Bootstrapping
In this section, we extend the single feature analysis to multiple features, where each feature represents information from scenes (from any modality,
whether perceptual, mental, etc.). Setting aside verbal aspect, we may model possible verb meanings as
a set of M features, where each feature represents
a predicate on one or more of the arguments of the
verb. For example, a set of single argument predicates might include:
moving(x), rotating(x), movingdown(x),
supported(x), liquid(x), container(x)

specifying the perceived situation about the argument of the verb (e.g. if it is moving, or moving in a
particular manner, etc.) while a second set of twoargument predicates might specify the relationships
between arguments, given that this is an externally
caused (cause=1) event:
contact(x, y), support(x, y), attach(x, y)

Using these predicates, an idealized (partial) lexicon
might contain the following word-concept mappings:
/lower/
/raise/
/rise/
/fall/

cause One arg x Two arg x, y
1
1*11**
11*
1
1*01**
11*
0
1*0***
0
1*1***

specifying, in linear order, the value of each of the
one and two-argument predicates above, e.g. that
/lower/ has cause=1, moving(x)=1, rotate(x)=*,
movingdown(x)=1, etc. – and thus its concept covers externally-cased motion events where an agent
moves a theme downwards through supported contact. The verb /raise/ is nearly identical except it
has movingdown(x)=0, while /fall/ and /rise/ involve internally-caused motion (cause=0) and do not

specify any two argument predicates. The values of *
for the 4 rotating(x), liquid(x), container(x), and attach(x,y) predicates signal that these features are irrelevant to the verb’s concept. Perception of a scene
amounts to evaluating these predicates; scenes may
or may not fall under the verb concept, conditioned
on the values of these predicates. The presence of q
of “irrelevant” features valued as * implies 2q possible scenes consistent with the concept.
Given a hypothesis space of possible verb concepts
formed by M of these sorts of predicates, the task
of learning a verb’s meaning given N observations
X = [x1 . . . xN ] of scenes, is to determine which of
the 3M possible concepts is the most likely. Just
as before, a Bayesian model does so by computing
the posterior probability distribution p(Hi |X) over
concepts, given a prior distribution on hypotheses
p(Hi ) and a likelihood distribution of generating a
particular xjΩexample given Hi :
1
1
if xj 2 Hi
2q
p(xj |Hi ) =
; p(Hi ) = M (5)
0
otherwise
3
We can use Bayes’ rule (Eq (1)) to compute the likelihood of any hypothesis given N independent examples. Intuitively, the above likelihood model says
that out of the 2q possible scenes that might fall under the concept Hi , all of them are equally likely;
likewise, the prior probability model holds that all
of the 3M concepts are equally likely.
3:

Consider a reduced hypothesis space where M =
q Concepts
0 000, 001,
1 00*, 01*,
1*0, 1*1,
2 0**, *0*,
3 ***

010,
10*,
*00,
**0,

011,
11*,
*01,
1**,

100,
0*0,
*10,
*1*,

101, 110, 111
0*1,
*11
**1

Given any distribution of scenes X, we can directly
compute the posterior probability p(Hi |X) of any
of the 27 diﬀerent concepts. Four are shown here,
of increasing generality from a very specific concept
(H000 ) covering only one scene (000) to the most
general concept H§§§ covering 2M possible scenes:
1
2
3
4
5
6

Observation X:
H000 H00§ H0§§ H§§§
000
.30 .15 .07 .03
000, 000, 000
.70 .09 .01 .001
000, 001
.00 .64 .16 .04
000, 001, 000
.00 .79 .10 .01
000, 001, 000, 001, 000 .00 .94 .03 .001
000, 101, 010, 111, 000 .00 .00 .00 1.0

A single scene observation 000 is explained by all 4
hypotheses (situation 1) in a graded fashion. However, with 3 repeated observations (situation 2),
most of the mass is concentrated on H000 . When
scene observations require abstracting away irrelevant features, the more specific concepts must be
discarded in favor of more general concepts (situation 3 vs 6). Each example consistent with the
general concept further reduces ambiguity over the
possible concepts (situation 4 vs 5).

Modeling Syntactic Bootstrapping
In this section, we demonstrate a Bayesian model
of how the distribution of syntactic frames, as envisioned by Gleitman (1990), may be used to determine the semantic features of a verb. To do so,
we introduce a new notion of semantic agreement,
wherein features of a lexical head must agree with its
complement. Consider the following idealized lexicon:
/fill/
fig: [0] con: [1]
/pour/ fig: [1] liq: [1]
/load/ fig: [*]

/into/
/with/
/glass/
/water/

fig: [1]
fig: [0]
con: [1]
liq: [1]

A lexical head /fill/ agrees with a complement of /a
glass with water/ but not with /water into a glass/,
because the lexical head and its complement have
a value 1 along the fig dimension. Likewise, a lexical head /pour/ agrees with a complement of /water into a glass/ but not /a glass with water/, because of the opposite value of fig. Finally, a lexical
head such as /load/, because § agrees with 0 and
1, accepts both complements. Thus, both /load the
wagon with hay/ and /load hay into the wagon/ are
valid derivations. A large number of verb classes can
be seen to pattern into three classes along diﬀerent
feature dimensions in this way (Nomura et al 1994).
Any number of feature dimensions may be hypothesized, and may include selectional features, such as
/fill/ requiring a container (con:[1]) or /pour/ requiring a liquid (liq:[1]) as its complement.
Suppose a learner hears /S glipped a glass with
water/. The features of the novel verb /glip/ are unknown and the features of its complement /a glass
with water/ are known. For the fig feature dimension of /glip/, there are 3 possible values, with 3
corresponding hypotheses H0 , H1 , H§ . As before,
one observation is insuﬃcient to infer H0 , as H§ is
also possible. The following likelihood model for an
unknown verb feature value V and the feature value
of its complement C agreeing can be used for each
feature dimension (fig, loc, con, etc.) to compute a
probability distribution over the Hi :
p(V, C) V = 0 V = 1 V = §
C=0
.22
.01
.11
C=1
.01
.22
.11
C=°
.11
.11
.12

Intuitively, the above says that with high probability, V and C agree, and with low probability
(i.e. .01), they do not agree. The above joint distribution encodes both the prior distribution on V
and the conditional distribution p(C|V ):
p(V = 0) = p(V = 1) = p(V = §) =
p(C = V |V = 0 or 1) = .65
p(C 6= V |V = 0 or 1) = .03
p(C = §|V = 0 or 1) = .32

1
3

(6)

p(C = 0, 1|V = §) = .32
p(C = §|V = §) = .35
(7)

Given an assumption of perfect knowledge of the feature values of the complement, over multiple observations, the distributional evidence X in support of
the 3 hypotheses can be readily evaluated. We can
test how diﬀerent distributions of syntactic frames
correctly yield diﬀerent probability distributions of
a verbs syntactic and semantic features; this is thus
a Bayesian model of Gleitman’s (1990) “syntactic
bootstrapping”. Suppose a learner gets 4 syntactic
frames of /glip/, all of the form /S glipped O with
Z/. This is equivalent to having 4 perfect observations of fig:[0], which we annotate as X = 0000.
Then the likelihood p(X|V ) and posterior probability p(V |X) of the 3 possible hypotheses can be evaluated directly via Bayes’ rule:
Likelihood p(X|V )
p(X|V = 0) = (.65)4
p(X|V = 1) = (.03)4
p(X|V = §) = (.32)4

This is shown below, along with other distributions
of syntactic frames:
Sit Utterances (X)
V =0 V =1 V =§
1 4 /S Ved O with Z/ (0000)
.941 .000
.059
2 4 /S Ved O/ (****)
.292
.292 .416
2 /S Ved O with Z/,
3 2 /S Ved O into Z/ (0011)
.032
.032 .936
2 /S Ved O/,
4 2 /S Ved O with Z/ (**00) .769 .000
.230
23 /S Ved O with Z/
5
1.00 .000
.000
10 /S Ved O/
23 /S Ved O with Z/
6 5 /S Ved O into Z/
.960 .000
.040
10 /S Ved O/

With only 4 examples, the uncertainty of the value
of the feature V is rapidly reduced (situations 1-4).
As the number of examples increases (situation 4
vs 5), the evidence supports “all-or-none” or “rulelike” behavior, even with a significant number noisy
frames (situation 5 vs 6).

Modeling Integrated Syntactic and
Semantic Bootstrapping
We now integrate the two forms of bootstrapping
described above, where given a distribution of both
scenes and syntactic frames, a probability distribution over concepts consistent with both sources of
evidence is determined. Consider the following possible syntactic frames:

and perceptually-derived
scenes:

u Attention
***
1**
W
1**
W
***
W
0**
G
***
G

semantic

features

Description/Semantic Features
Person pouring water into a glass, filling it
Glass: Manner: None (0) State: Full (1)
Water: Manner: Pouring (1) State: None (0)
Person splashes water into a glass, filling it
Glass: Manner: None (0) State: Full (1)
Water: Manner: Splashing (2) State: None (0)
Person sprays water into a glass, filling it
Manner: None (0) State: Full (1)
Manner: Spraying (3) State: None (0)
Person pouring water out of glass, emptying it
Manner: None (0) State: Empty (2)
Manner: Pouring (1) State: None (0)
Person splashes water out of glass, emptying it
Manner: None (0) State: Empty (2)
Manner: Splashing (2) State: None (0)
Person pouring some water into a glass
Manner: None (0) State: None (0)
Manner: Pouring (1) State: None (0)
Person sprays water into a glass
Manner: None (0) State: None (0)
Manner: Spraying (3) State: None (0)

where features are ordered as:
fig, manner-of-motion, change-of-state

Posterior p(V |X)
p(V = 0|X) = .941
p(V = 1|X) = .000
p(V = §|X) = .059

Utterance
/Glipping!/
/S glipped water from a glass/
/S glipped water into a glass/
/S glipped water/
/S glipped a glass with water/
/S glipped a glass/

Scene s
pour-fill
G001
W110
splash-fill
G001
W120
spray-fill
G001
W130
pour-empty
G002
W110
splash-empty
G002
W120
pour-none
G000
W110
spray-none
G000
W130

of

for each utterance u and scene possibility s. The
subscripts on G and W annotate the observation of
that argument for each of the 3 dimensions.
We may describe, just as before, how the crosssituational distributional evidence X of N independent scene-utterance pairs:
X = [(s1 , u1 ), . . . , (sN , uN )]
(8)
yields diﬀerent word-concept mappings p(Hi |X)
through independent combination of the two sources
of evidence:
QN
j=1 p(sj |Hi )p(uj |Hi )p(Hi )
p(Hi |X) =
(9)
p(X)
For expository purposes, we will consider how the
learner would rank each of the 6 precise hypotheses,
and will assume they entertain only these:
English Verb Hypothesis Feature
pour
Hpour
11*
spray
Hspray
12*
splash
Hsplash
13*
fill
Hf ill
0*1
empty
Hempty
0*2
move
Hmove
1**

The likelihood p(sj |Hi ) for each of the D independent dimensions (D = 3) is:
D
Y
p(sj = s1 . . . sD |Hi ) =
p(sk |Hi )
(10)
k=1

where our model for scene observations along the
kth dimension8is:
1 ° dk ≤ ifsk = 0, Hik = §
>
>
<
≤
ifsk 6= 0, Hik = §
p(sk |Hi ) =
(11)
1 ° dk ± ifsk = Hik , Hik 6= §
>
>
:
k
k
±
ifsk 6= Hi , Hi 6= §
We annotate the value of the kth dimension of hypothesis Hi as Hik above. The first two lines model
that when a feature is not valued (Hik = §), then
scenes typically have 0 for the kth dimension (d1 =
2; d2 = 3; d3 = 3), but do not match with probability ≤. That is, observing pouring, spraying, splashing
manners (s2 = 1, 2, or 3), and observing filling, emptying, or breaking change-of-states (s3 = 1, 2, or 3)

Situation
Scene s
Utterance u
Hpour Hspray Hsplash Hf ill Hempty Hmove
1
pour-fill
{G001 , W110 }/S glipped water into a glass/ (1**) .889 .008 .008 .000 .000 .093
2
pour-fill
{G001 , W110 }/S glipped glass with water/ (0**) .000 .000 .000 .990 .009 .000
3
pour-fill
{G001 , W110 }/Glipping!/
(***) .468 .004 .004 .468 .004 .049
4
none
/S glipped water into a glass/ (1**) .246 .246 .246 .004 .004 .254
5
none
/S glipped glass with water/ (0**) .007 .007 .007 .485 .485 .007
6
none
/Glipping!/
(***) .166 .166 .166 .166 .166 .170
7
pour-fill
{G001 , W110 }/Glipping!/
(***)
pour-empty {G002 , W110 }/S glipped water from a glass/(1**) .998 .000 .000 .000 .000 .001
pour-none {G000 , W110 }/S glipped water/
(***)
8
pour-fill
{G001 , W110 }/Glipping!/
(***)
splash-fill
{G001 , W120 }/S glipped a glass with water/(0**) .000 .000 .000 .999 .000 .000
spray-fill
{G001 , W100 }/S glipped a glass/
(***)
9
pour-fill
{G001 , W110 }/Glipping!/
(***)
splash-empty{G001 , W120 }/S glipped water/
(***) .064 .064 .064 .000 .000 .808
spray-none {G001 , W100 }/S glipped water/
(***)

Figure 1: Word-concept mapping p(Hi |X), given scene-utterance evidence X of a novel verb, /glip/
is far less likely than observing no manner of motion
(s2 = 0) or change of state (s3 = 0) at all. Since
observing a diﬀerent value sj 6= 0 is unlikely to have
occurred by accident, it may be an important feature
to the concept. The second two lines of (11) model
that if a feature is valued (Hik 6= §), then scenes typically match that feature in value, but do not match
with probability ±. That is, for example, given hypothesis Hpour , then most of the scenes will contain
pouring in them. In our examples, ≤ = .1, ± = .01;
qualitatively, results are not sensitive to changes in
these values.
The output of our model is shown in Figure 1.
Suppose, as in Situation 1, a learner is given a
single scene-utterance pair (pour-fill, /S glipped water into the glass/): X = [(s1 = {G110 , W110 }, u1 =
1 § §, W )], and we wish to compute p(Hi |X) for all
Hi 2 H. We assume the learner can attend to the
argument so as to extract relevant features from the
scene. Given the scene pour-fill paired with utterance /S glipped water into a glass/, our Bayesian
model places high weight on Hpour .
In Situation 2, the scene is the same, but now the
syntax /S glipped a glass with water/ provides the
learner with the information to attend not to the
water’s manner-of-motion but to the glass’ change
of state. Given X = [(s1 = {G110 , W110 }, u1 =
0 § §, G)] our model weights Hf ill heavily.
In Situation 3, the scene is the same, but now
the syntax /Glipping!/ gives the learner less information, since the argument in the scene that the
speaker may be referring to is unknown: X = [(s1 =
{G110 , W110 }, u1 = ° ° °)] If there are A arguments in the scene, the speaker must have had a
particular argument z in mind. The learner must
condition on all the possibilities of z:
A
X
p(sj |Hi ) =
p(sj |Hi , za )p(za )
(12)
a=1

If learners consider all arguments equally salient
(p(zi ) = A1 ) then this eﬀectively models /Glipping!/

as equivalent to /S is glipping Z1/ with probability
p(z1 ) = .5 and /S is glipping Z2/ with probability
p(z2 ) = .5. For simplicity, we assume A = 2 where
Z1 is water, Z2 is the glass – but further referential
uncertainty can be modeled with higher A. Because
of the conditioning on each of A possibilities, this
yields a less certain word-concept mapping.
In situation 4 through 6, the same syntactic
frames are provided as in situations 1 through 3,
but without the scene information. When some syntactic information is provided by the frame (situation 4, /S is glipping water into a glass/), then the
manner-of-motion locative verbs are preferred over
the change-of-state locative verbs, but no diﬀerentiation is possible without the scenes. Likewise, when
the frame provides the opposite cue (situation 5, /S
is glipping a glass with water/), the opposite preference is achieved, again with no diﬀerentiation between possible change-of-state verb concepts. When
zero syntactic information is available (situation 6,
/Glipping!/), all hypotheses prove equally likely.
Whereas in situation 3 the verb-concept mapping
was ambiguous, primarily between Hpour and Hf ill ,
in situation 7 and 8, learners are provided 2 additional examples to disambiguate. Both the scenes
and syntactic frames in situation 7 support Hpour ,
while in situation 8 the scenes and syntactic frames
support Hf ill .
Finally, in situation 9, 2 diﬀerent scene-utterance
pairs primarily support the “superordinate” concept Hmove , and not any “subordinate” manner-ofmotion concept Hpour , Hsplash , or Hspray .

Discussion
The reason why our analysis is able to infer so much
from so little evidence is because so much is embedded in the given knowledge sources:
• the structure of the hypothesis space H. Our examples contained a small number of feature dimensions and their possible values, but these may

•

•
•

•

be specified by interfaces to perceptual, motor,
memory, or other “theory” representations. If so,
whether these are innate or acquired are conditional on their source.
priors p(Hi ) on hypotheses in H. We used equal
priors, but updating p(Hi ) based on language input is natural. In the verbal domain, such phemonena are commonly observed (e.g. manner vs.
path, tight/loose-fit biases).
likelihood of scenes s given the word concept
p(sj |Hi ). We stipulated static values of ≤ and ±,
but this can be acquired from observation.
perfect knowledge of the features of the complement. We made this simplifying assumption to
illustrate the essential elements of our model, but
learners must acquire these features in parallel.
the likelihood of agreement, p(C|V ), between a
feature of a novel verb V and its complement C.
We speculate that there is suﬃcient structure in
partially learned words so as to acquire the structure in the joint distribution of feature values.

This richness of knowledge is in contrast to the
models employed by Regier et al (2001) and Desai (2001), who train connectionist neural networks
so as to learn the word-scene associations for adjectives/ nouns and verbs respectively. The high
dimensionality of their models forces the need for
thousands of training trials, and the interpretation
of the weights is notoriously diﬃcult. The assumptions behind these models are not justified by these
authors. In contrast, our Bayesian approach makes
the hypotheses, priors, and likelihoods explicit, holding this structure to be central.
Siskind (1996) views lexical acquisition as constraint satisfaction, and oﬀers a robust algorithm
where the mapping between input and hypothesis
space is accomplished by pruning hypotheses that
do not occur cross-situationally. Provided an idealized tokenization of the world, the algorithm does
not need a large number of examples. However,
Siskind’s model does not yield any form of preference between diﬀerent concepts, which is especially important when two or more concepts may
be equally constrained by the data. We have shown
how a Bayesian analysis explicitly yields preferences
between concepts in the posterior probability distribution p(Hi |X).
Tenenbaum and Xu (2000) take the important
step of putting word learning in the Bayesian framework that we adopt here, showing how noun learning can occur with a small number of examples in a
continuous-variable input space.
Crucially, however, the above models ignore the
constraining role of syntax, despite considerable evidence that children use syntax to guide their verbconcept hypothesis space (Gleitman 1990, Naigles
1990, Naigles 1994, Fisher et al 1994, Snedeker and

Gleitman 2002). Qualitatively, our models’ performance matches the preferences of child learners,
modeling their acquisition from as little as one example.
Our use of statistics does not imply any commitment to radical empiricism. Much prior knowledge
is stipulated: the structure of the hypothesis space,
the priors on hypotheses, and the likelihood of sceneutterance pairs given the hypotheses. It is not specified whether these stipulations are innate or themselves learnable. Linguistics and lexical semantics
provide detailed theories of a much larger syntactic
and semantic hypothesis space, and little prevents
their inclusion in this framework.

Acknowledgements
Many thanks to Robert C. Berwick for motivating and
supporting this work. Jesse Snedeker and Josh Tenenbaum provided many stimulating discussions. This work
was funded by a provost grant to Prof. Joel Moses.

References
Desai, R. (2001). Bootstrapping in Miniature Language
Acquisition. In Proceedings of the Fourth International Conference on Cognitive Modeling, pp. 61-66.
Hillsdale, NJ: Erlbaum.
Harley, H. and Noyer, R. (2000) Licensing in the nonlexicalist lexicon. In Bert Peeters, (Ed.) The LexiconEncyclopedia Interface, Amsterdam: Elsevier Press.
Fisher, C., Hall, D., Rakowitz, S., and Gleitman, L.
(1994). When it is better to receive than to give:
Syntactic and conceptual constraints on vocabulary
growth. Lingua, 92:333-375.
Gleitman, L. (1990) The structural sources of verb meanings. Language Acquisition, 1990, 1:3-55.
Levin, B. (1993) English Verb Classes and Alternations:
A Preliminary Investigation, University of Chicago
Press, Chicago, IL.
Naigles, L. (1990). Children use syntax to learn verb
meanings. Journal of Child Language, 117:357-374.
Nomura, N., Jones, D.A. and Berwick, R.C. (1994) An
Architecture for a Universal Lexicon: A Case Study
on Shared Syntactic Information in Japanese, Hindi,
Bengali, Greek, and English. COLING 1994, 243-249.
Pinker, S. (1989) Learnability and Cognition. MIT Press,
Cambridge, MA.
Regier et al (2001). The Emergence of Words. In Proceedings of the 23rd Annual Conference of the Cognitive Science Society.
Siskind, J. (1996) A Computational Study of CrossSituational Techniques for Learning Word-to-Meaning
Mappings. Cognition, 61:39- 91
Snedeker, J. and Gleitman, L. (2002) Why it is hard to
label our concepts. In G. Hall and S. Waxman (eds.),
Weaving a Lexicon, Cambridge, MA: MIT Press.
Tenenbaum, J.B. and Xu, F. (2000) Word learning as
Bayesian inference. In Proceedings of the 22nd Annual
Conference of the Cognitive Science Society (pp. 517522)

