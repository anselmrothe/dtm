UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Atomistic and Systems Approaches to Consciousness

Permalink
https://escholarship.org/uc/item/8vf1q504

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Authors
Brook, Andrew
Jerzykiewicz, Luke

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Atomistic and Systems Approaches to Consciousness
Andrew Brook (abrook@ccs.carleton.ca)
Luke Jerzykiewicz (ljerzyki@ccs.carleton.ca)
Cognitive Science, Carleton University, Ottawa, Ontario, Canada
Abstract
The approach to consciousness taken by most philosophers is very different from the approach taken by most cognitive
psychologists, so different that one could be forgiven for wondering if they are talking about the same thing. Most
philosophers focus on individual psychological states. By contrast, most psychologists focus on properties of cognitive
systems as a whole such as global workspace or attention. (Some philosophers favour this approach, too, Dennett and
P. M. Churchland for example.) We will expose some of the peculiarities of the dominant philosophical approach and,
by looking briefly into what is needed to give an adequate account of consciousness, advance some reasons for
favouring the approach dominant among psychologists.

Two Approaches to Consciousness
Reading recent writings on consciousness by philosophers
and cognitive psychologists, one could be forgiven for
wondering if they are talking about the same thing. Most
philosophers focus on individual psychological states ñ
individual perceptions or feelings or imaginings ñ or at
most tiny combinations of such states (Rosenthal, 1991;
Chalmers, 1996; Tye 1995). Experimental psychologists by
contrast focus on properties of cognitive systems as a
whole: global workspace (Baars 1988), intermediate level
of processing (Jackendoff 1987), or attention. Attention
has been particularly singled out for ... attention. For
Posner or Mack and Rock, for example, to be conscious of
something simply is to pay attention to it (Posner 1994;
Mack and Rock 1998).
First we will lay out the main contours of the two
dominant approaches, starting with the one favoured by
most philosophers (though not all: both Dennett (1991) and
P. M. Churchland (1995) favour the approach taken by
psychologists). Then we will assess them. There are
serious prima facie shortcomings in the dominant
philosophical approach, but there is also a serious worry
about the dominant psychological approach. To bring out
these shortcomings and this worry, we will need to
distinguish two kinds of consciousness and lay out some of
the things that an adequate account of consciousness must
explain.

The dominant approach in philosophy
Two things characterize the dominant approach to
consciousness in recent philosophical work on the topic.
The first is a kind of atomism. These philosophers tend to
talk about conscious states one by one (ëwhat is it like for
something to look red?í) or at most in tiny groups. In both
cases, the cognitive system that has them is pretty much

ignored. (Theorists may add, ë...look red to meí but they do
nothing with the addition.) Almost the whole of the
massive literature on qualia exhibits this feature. (Qualia
are the felt quality of conscious states, ëwhat it is like to
have themí, in Thomas Nagelís (1974) famous phrase.)
The thing that has such states, the subject of conscious
states, is ignored. Let us call this view of consciousness
atomism.
Atomism ñ the view that conscious states can be
studied one by one or in small groups, without
reference to the cognitive system that has them.
When you think about it, this atomism is remarkable. It
seems obvious that consciousness does not come in
atomically separable states in this way.
This atomism about consciousness goes with another
view that we will call local realism. Local realism is the
view that consciousness or what is distinctive about
consciousness, for example that in virtue of which it is like
something to have a psychological state, is a property of
individual psychological states or tiny groups of
psychological states.
Local realism ñ the view that consciousness or what
is distinctive about consciousness is either a nonrelational property of individual psychological states
or a relationship among very small numbers of
psychological states.
Specifically, this approach to consciousness views it as
either a nonrelational property of single psychological
states or, though a relational property, one that ties only
very small groups of psychological states to one another. A
relationship between one state and another single state
would be an example. This account is not very precise but
it is precise enough for our purposes. What matters is the
contrast with the kind of properties that figure centrally in
theories that view consciousness as a relationship between
a great many psychological states and a conscious being

whose states they are.
Local realism is a realist view because it takes the
states in question to be real, not postulated abstract entities
that we believe in merely because of certain concepts or
explanatory strategies or something of the kind.
There are (at least) three types of local realism. In one
type, appearing red to me would be a property of an
experience of red, being painful would be a property of a
pain, and so on. We find a second type in what have come
to be called transparency theories, theories holding that we
see right through conscious states (hence transparency) and
are conscious only of what such states are about. In this
approach, something appearing red is not a property of any
experience, it is a matter of experiencing something that
appears to be red, feeling pain is a matter of experiencing
something painful, and so on. In the third type, a
representation of red gets to be conscious by being related
to another psychological state, for example by being the
object of a thought about that representation (Rosenthalís
1991 higher-order thought view of consciousness).
It might seem that atomism requires local realism but
in fact that is not clear. Some atomists about consciousness
are simply neutral about whether qualia, for example, are
local or nonlocal properties of the states they discuss. This
neutrality is a bit curious because these theorists believe
that they can say other important things about qualia, e.g.,
that when it is like something to have a representation, this
quale, this being like something, is radically different from
other aspects of the representation, but neutral they have
been. Nonetheless, local realism would certainly promote
atomism: if consciousness is a local property of certain
states, it would be at least very tempting to hold that one
could study such states one by one and in isolation from
the system that has them.
It is important to note that local realism about
consciousness is not necessarily the same thing as realism
about consciousness. Even if consciousness is not a local
property of individual psychological states, it could still be
a real property of cognitive systems as a whole. We
mention this now because there have been influential
treatments of consciousness recently that back off from any
form of cognitive-system realism about consciousness, for
example Davidsonís (1996) view. In Davidsonís view,
consciousness arises out of a complex triangular
interaction among oneself, other purposive beings, and the
world. By itself, this triangulation picture need not depart
from realism; the result of the triangulation, consciousness,
could still be a real property of cognitive systems. For
Davidson, however, not only does consciousness arise out
of triangulation, it is (roughly) nothing more than
triangulation. When triangulation results in stable
attributions of consciousness to self and others, that is what
consciousness is. And this view is incompatible with most
versions of realism about consciousness.
One central issue in this atomist, local realist literature

is the relationship of consciousness to representation. At
minimum, being conscious of something is one way of
representing something. Of course, things can also be
represented unconsciously. In fact, probably the vast bulk
of our representations never make us conscious of
anything. Certainly a representation does not need to make
us conscious of anything to be cognitively active. But now
ask: can the difference between conscious and
nonconscious representation be captured by appealing to
representational properties or are the properties that make a
state conscious nonrepresentational properties? Here there
is a major split in the atomist, local realist camp, with some
researchers opting for the representational alternative
(Lycan 1987, Tye 1995), others insisting on the
nonrepresentational one (Block 1995, Chalmers 1996). For
the anti-representationalists, the difference between a state
that is conscious and one that is not is not a difference in
how that state represents anything or a difference in the
kind of representation it is or a difference in anything else
representational. Since we will eventually come to raise
some doubts about anti-representationalism, let us flag the
view explicitly:
Anti-representationalism ñ the view that the
difference between a state that is conscious and one
that is not is not a difference in how that state
represents anything or a difference in the kind of
representation it is or a difference in anything else
representational.
Here is how the anti-representationalist view can arise.
When something appears to us to be a certain way,
the representation in which it appears that way can play
two roles in our cognitive economy. On the one hand, the
representation (or the contents of the representation) can
connect inferentially to other representations: if the stick
appears to have two straight parts with a bend in the
middle, this will preclude representing it as forming a
circle. The representation can also connect to belief: if the
stick appears straight with a bend in it, we will not form a
belief that it bends in a circle. And to memory: we can
compare this stick as it appears to sticks I recall from the
past. And action: if I want something to poke into a hole, I
might reach for the stick. In all these case, so long as I am
representing the stick in the appropriate way, it would
seem to be irrelevant whether I am conscious of the stick
or not. My representation could do these jobs for me just as
well even if I were not aware either of the stick or of my
representation of it. But I am also conscious of the stick ñ
it does appear to me in a certain way. This can easily seem
to be something different from any representational
properties of the representation, at any rate properties such
as those we just considered.1
1.

Chalmersí well-known (1995) distinction between what
he calls the easy problem and the hard problem of consciousness
starts from this distinction between the cognitive role of

Arguments for this conclusion often take the following
form: the felt quality of a state could change while its
representational properties remain the same. The
arguments are usually based on thought experiments such
as the inverted spectrum argument (how colours appear to
us could be inverted without changing how our
representations of colour function as representations) or the
zombie argument (there could be creatures for whom it is
not like anything to represent anything whose
representations nevertheless function cognitively just as
representations function in us).
Sometimes such arguments go so far as to conclude
that what is distinctive to consciousness is not just not
representational, it is not even physical. One way of
arguing for this to make oneís zombie a microphysical
duplicate of conscious beings. If a zombie such as this is
possible, then qualia are not a physical property of
conscious beings. Another is Jacksonís (1986) famous
thought experiment concerning Mary, the colour scientist.
Mary knows everything there is to know about the
experience of colour, therefore everything physical there is
to know about the experience of colour, but she has never
experienced colour herself. Then she experiences colour.
Clearly she gains something she did not have before.
However, she knew everything physical about colour.
Therefore, what she gains must be something nonphysical.
It is not clear that any of these thought experiments
establish real possibilities, or, if they do, entail the
conclusions drawn from them. For reasons of length, in
this paper we will pass on that issue. Instead, we will turn
to alternative approach to consciousness introduced earlier,
the one found more often in the work of experimental
psychologists.

The dominant approach in psychology
In sharp contrast to atomism and local realism (whether in
its representational or its anti-representational form), the
dominant approach to consciousness in experimental
psychology holds that consciousness is a property of the
cognitive system as a whole. Let us call it the system
approach to consciousness:
System approach to consciousness ñ approaches to
consciousness that view it as a property of whole
cognitive systems, not individual or small groups of
representations.
There is a great diversity of opinion as to what the relevant
property is. We cannot begin to explore the whole range of
options but here are a few examples. Baars (1988) holds
that consciousness consists in a global workspace of a
certain kind. Jackendoff (1987) urges that it is an

representations and something appearing to be like something in
them.

intermediate level of representation, a phonetic or similar
level between acoustic or visual input and full-blown
conceptual content. Many theorists link consciousness very
closely to attention. For example, Mack and Rock say that,
ìAttention [is] the process that brings a stimulus to
consciousnessî (Mack and Rock 1998), ìif a ... percept
captures attention, it then becomes an explicit percept, that
is, a conscious perceptî (Mack 2001, 2). Posner (1994)
captures the spirit of this line of thinking about
consciousness nicely:
an understanding of consciousness must rest on an
appreciation of the brain networks that subserve
attention, in much the same way as a scientific
analysis of life without consideration of DNA would
seem vacuous. [Posner 1994, 7398]
Nor is this approach without its philosophical allies.
Dennettís (1991) multiple drafts model in which states
become conscious by seizing control of cognitive resources
is a similar approach. (Curiously, he says almost nothing
about attention.) Paul Churchland is another example. Here
is how Churchland summarized his approach recently:
[Consider] the brainís capacity to focus attention on
some aspect or subset of its teeming polymodal
sensory inputs, to try out different conceptual
interpretations of that selected subset, to hold the
results of that selective/interpretive activity in shortterm memory for long enough to update a coherent
representational ënarrativeí of the world-unfolding-intime, a narrative thus fit for possible selection and
imprinting in long-term memory. Any [such]
representation is ... a presumptive instance of the class
of conscious representations. [Churchland 2002, 74]
This is a different conception of consciousness from the
atomist one! Are there reasons to favour one over the
other? There are. First reason: the systems approach has
the potential to account for two kinds of consciousness, the
atomist approach only one.

Two kinds of consciousness
The variety of different things that we can have in mind
when we use the word ëconsciousnessí is a big topic, too
big a topic to explore here. However, we can make one
distinction fairly briefly and when we do, something quite
interesting about the two approaches becomes apparent.
The distinction we have in mind is between
consciousness of the world around us and consciousness of
our own psychological states. Blindsight is sometimes
invoked to illustrate this distinction but what is
tendentiously called ëinattentional blindnessí works better.
(Tendentiously because there is actually a huge debate
about whether the phenomenon in question has anything to
do with attention [Mack,
http://psyche.cs.monash.edu.au/v7/psyche-7-16-

mack.htm].) In inattentional blindness research, the subject
fixates on a point and is asked to note some feature of an
object introduced at or within a few degrees of fixation.
After a few trials, a second object is introduced, in the
same region but clearly distinct from the first object.
Subjects are not told that a second object will appear.
When the appearance of the two objects is followed by 1.5
seconds of masking, at least one-quarter of the subjects and
sometimes almost all subjects have no awareness of having
seen the second object.
Yet ñ and this is what makes inattentional blindness
better for our purposes than blindsight ñ when the second
object is a word, subjects clearly encode it and process its
meaning. Evidence? When asked shortly after to do, for
example, a ëstem completion taskí (i.e., to complete a
word of which they are given the first two or three letters),
they complete the word in line with the word they claim
not to have seen much more frequently than controls do. In
short, in inattentional blindness, subjectsí access to the
word they are not aware of seeing is nevertheless very
deep-running.
In inattentional blindness, it is important to note,
objects appear in a certain way to the subject, as is
evidenced by the subject processing semantic information
provided by it.2 What we have here is not merely Blockís
A-consciousness, "a state ... poised for direct control of
thought and action" (Block 1995, 233). The access to the
unattended object is Blockís -consciousness or something
very much like it: the object actually appears to the subject.
(Note that if this claim is correct, it poses a considerable
problem for attention theories of consciousness ñ
something else we donít have space to go into.) In these or
similar cases of access without attention, subjects can, for
example, point to the items in question. The objects can
increase the subjectís level of alertness, especially the level
of alertness concerning the objects themselves. And
ensuing behaviour is often appropriate, not to the way the
object actually is, but to how the objects looked to the
subject (Dennett, 1978). Let us call the kind of
consciousness that can be present in cases of inattentional
information access and so on consciousness of the world.
By contrast, let us call the consciousness that we have
when we are conscious of representing items in the world

consciousness of self.3
Consciousness of the world ñ the kind of
consciousness that can be present in cases of
inattentional information access and so on
Consciousness of self ñ the consciousness that we
have when we are conscious of representing items in
the world
Now a reason for favouring the systems approach: all
anti-representational versions of atomism and many
representational versions (e.g., higher-order thought or
experience models) have anything to say only about
consciousness of self, the felt quality of psychological
states, what it is like to have them, and cannot say anything
about consciousness of the world, i.e., the way the world
appears to someone. Systems approaches not only have
something to say about consciousness of the world, they
generally focus on it. When theorists talk about paying
attention to something, for example, they generally have in
mind paying attention to something in the world, not
paying attention to oneís own states.

What a theory of consciousness must explain
A second reason for favouring a systems over an atomistic
approach to consciousness: what a theory of consciousness
actually needs to be able to explain.
If consciousness is a matter of things appearing ñ just
appearing, in the case of consciousness of the world,
consciousness that they are appearing in the case of (one
kind of) consciousness of self ñ, then consciousness is a
property of the activity of representing, not of individual
representations. Consciousness is a matter of something
being conscious of something. If so, an adequate theory of
consciousness has to address the question: What is a
system capable of consciousness like?
Here are some of the features of such a system:

!

It is aware of whole groups of representations in one
ëact of consciousnessí

!

Often when it is aware of whole groups of representations, it is also aware of itself as the common
subject of these representations.

!

Its consciousness can be faint, full, etc.

!

It has many global cognitive faculties and some of

3.

2.

Change blindness, attentional blink, and visual neglect
and the double dissociation between the ventral and the dorsal
streams in the brain discovered by Milner and Goodale (1995)
are related phenomena. In all these phenomena, information that
the subject is not conscious of having nevertheless enters into
cognitive tasks that use semantic information , disambiguation
tasks, for example.

Consciousness of self needs to be broken down into
consciousness of oneís psychological states and consciousness of
oneself, the thing having those states. Moreover, there are
radically different views afoot about what consciousness of oneís
psychological states consists in. Some theorists even maintain
that it is nothing more than consciousness of the world plus a
shift of attention (Dretske 1995, Tye 1995). We have to ignore all
these issues here.

them are closely linked to consciousness, memory, for
example, or attention, or language.

!

In particular, attention is closely linked to
consciousness.

!

For consciousness, a system simply having
information as a result of representing this, that or the
other is not enough; the system must make cognitive
use of the information.

!

Consciousness in a cognitive system can be
independent of sensory inputs

!

Its consciousness disappears in deep sleep, and . . .

!

reappears in dreams.4

When faced with issues like these, the atomistic approach
to consciousness has so far just clawed the air ñ and it is
hard to think of circumstances under which it could do any
better.
Take, for example, the unity of consciousness.
Conscious subjects are aware at the same time, indeed in a
single act of consciousness, of a great many items. A
theory of the conscious subjects has to be able account for
this unity.
The unity of consciousness comes in a number of
kinds. Mental unity in general comes in at least six
different kinds and four of them are kinds of unified
consciousness:
1. unity of our cognitive elements (we can bring, for
example, beliefs, desires, perceptions, intentions, and
many other things to bear on a single situation);
2. unified consciousness of our world (we are aware of
a whole host of things around us in a single, unified
representation) and
3.unified consciousness of oneís own representations;
4. unified consciousness of self (one is aware of
oneself as the ìsingle, common subjectî of oneís
experience, as Kant put it),
5. unified focus of a number of cognitive resources on
a single item of attention;
and,
6. unified behaviour (our behaviour is highly and
multiply unified ñ think of a concert pianist playing a
sonata).
Set items (i) and (vi) aside. Items (ii) to (v), the various
kinds of unified consciousness, have a common core:
Unity of consciousness ñ a group of representations
being related to one another such that to be conscious

4.

This list started from but goes beyond Churchlandís list of
the Magnificent Seven requirements on a theory of consciousness
in (1995), pp. 213-14.

of any of them is to be conscious of others of them and
of the group of them as a single group.
Given how central unified consciousness is to the
conscious mind, it is remarkable how little attention it is
has received in recent writings on consciousness,
especially philosophical writings. Paul Churchland (1995,
p. 209) includes it as one of his Magnificent Seven, the
things that a theory of consciousness has to explain, and
the notion is mentioned by a few other philosophers but in
general it has received little attention (the topic and what
has been done with it is reviewed in Brook 2000).
That consciousness is unified has immediate
implications for atomism and local realism. If
consciousness is unified, consciousness cannot be a
property of single representations or tiny groups of
representations (e.g., a representation and a thought
directed at it on the HOT model) by themselves. Nor it is
something that could fruitfully be studied by studying
single representations in isolation. At present, we donít
think that there is a theory of consciousness,
representational or nonrepresentational, that provides an
adequate account of the fact that consciousness is unified.
To pay attention to it is to see the prospects for atomism
about consciousness immediately plummet.

A Problem for the Systems Approach?
If the systems approach to consciousness seems more
likely than atomism to be able to explain what a theory of
consciousness has to explain, it also faces some problems.
In particular, many theorists worry that it may leave out
just the most crucial element, the consciousness itself. This
worry arises in the following way. ëSurelyí, an objector
will say, ëa cognitive faculties and capacities central to
your favourite systems approach to consciousness could
exist, and not only exist but function as they do, in the
absence of consciousness?í This line of objection is the
home of zombie thought-experiments: surely something
could be just like us behaviourally, or (as in this case)
functionally, or even physically, and yet not be conscious.
All we can say here is that if zombie thought-experiments
are coherent, then the systems approach is in trouble, as is
every other representational theory of consciousness. But
that is a big ëifí. Since the price of buying the idea that
zombie thought-experiments are coherent is that
consciousness has to be something deeply mysterious,
maybe beyond cognitive ken altogether, we want to make
very sure that zombie thought-experiments are coherent.
Adjudicating that issue and the background issue of
the merits of anti-representational atomism vs. the systems
picture of consciousness is a task for another occasion.
Here we have merely tried to introduce the two
approaches, lay out one reason to favour the systems
approach, and look briefly at one difficulty it faces.

References
Baars, B. 1988. A Cognitive Theory of Consciousness
Cambridge: Cambridge University Press
Brook, A. 2000. Unity of Consciousness. Stanford
Encyclopedia of Philosophy. http://plato.stanford.edu
Chalmers, D. 1996. The Conscious Mind Oxford: Oxford
University Press
Churchland, P. M. 1995. The Engine of Reason, the Seat of
the Soul MIT Press
Churchland, P. M. 2002. Catching consciousness in a
recurrent net. In: Andrew Brook and Don Ross, eds.
Daniel Dennett New York: Cambridge University Press
Davidson, D. 1996. Subjective, Intersubjective, Objective.
In Paul Coates, ed. Current Issues in Idealism. Bristol,
UK: Thoemmes.
Dennett, D. 1978. Toward a cognitive theory of
consciousness. In his Brainstorms Bradford Books, 149-73
Dennett, D. 1991. Consciousness Explained. Boston:
Little, Brown
Dretske, F. 1995. Naturalizing the Mind. MIT Press
Jackendoff, R. 1987. Consciousness and the
Computational Mind MIT Press
Jackson, F. 1986. What Mary didnít know Journal of
Philosophy 83:5, 291-5
Lycan, Wm. 1987. Consciousness Cambridge, MA: MIT
Press
Mack, A. http://psyche.cs.monash.edu.au/v7/psyche-7-16mack.htm.
Mack, A. and Rock, I. 1998. Inattentional Blindness
Cambridge, MA: MIT Press
Nagel, T. 1974. What it is like to be a bat? Philosophical
Review 83: 435-50
Posner, M. 1994. Attention: the mechanism of
consciousness Proceedings of the National Academy of
Science USA 91: 7398-7403
Rosenthal, D. 1991. The Nature of Mind Oxford: Oxford
University Press
Tye, M. 1995. Ten Problems of Consciousness.
Cambridge, MA: MIT Press

