UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Sensory-Dependent Nature of Audio-Visual Interactions for Semantic Knowledge
Permalink
https://escholarship.org/uc/item/431997rj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Vallet, Guillaume
Riou, Benoit
Versace, Remy
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

        The Sensory-Dependent Nature of Audio-Visual Interactions for Semantic
                                                              Knowledge
                                      Guillaume Vallet (guillaume.vallet@univ-lyon2.fr)
                           Université Lumière Lyon 2. Laboratoire EMC, 5 avenue Pierre Mendès France,
                                                       69676, Bron cedex, France &
                                 Laval University, School of Psychololgy, 2325 rue des Bibliothèques
                                                Quebec City (Quebec), G1V 0A6 Canada
               Benoit Riou (benoit.riou@univ-lyon2.fr), Rémy Versace (remy.versace@univ-lyon2.fr)
                           Université Lumière Lyon 2. Laboratoire EMC, 5 avenue Pierre Mendès France,
                                                         69676, Bron cedex, France
                                        Martine Simard (martine.simard@psy.ulaval.ca)
                                 Laval University, School of Psychololgy, 2325 rue des Bibliothèques
                                                Quebec City (Quebec), G1V 0A6 Canada
                              Abstract                                     Communication between different modalities is called in-
                                                                        teraction (or interplay). If this interaction involves a repre-
   The nature of audio-visual interactions is poorly understood         sentation of higher level, this interaction is called integration
   for meaningful objects. These interactions would be indirect
   through semantic memory according to the amodal nature of            (Driver & Noesselt, 2008). An integrated object is a represen-
   knowledge, whereas these interactions would be direct accord-        tation that is more than the sum of its part. Previous research
   ing to the modal nature of knowledge. This question, cen-            in the multisensory perception theoretical framework princi-
   tral for both memory and multisensory frameworks, was as-
   sessed using a cross-modal priming paradigm from auditory            pally studied the neural basis of the integration mechanism
   to visual modalities tested on familiar objects. For half of the     using meaningless stimuli (for review see Calvert & Thesen,
   sound primes, a visual abstract mask was simultaneously pre-         2004; Koelewijn, Bronkhorst, & Theeuwes, 2010). Fewer
   sented to the participants. The results showed a cross-modal
   priming effect for semantically congruent objects compared to        studies were conducted with meaningful stimuli, and the goal
   semantically incongruent objects presented without the mask.         of these studies was also to determine the brain substrates of
   The mask interfered in the semantically congruent condition,         multisensory integration (Doehrmann & Naumer, 2008). The
   but had no effect in the semantically incongruent condition.
   The semantic specificity of the mask effect demonstrates a           semantic constraint is generally assessed by manipulating the
   memory-related effect. The results suggest that audio-visual         semantic congruency. A congruent trial is when the prime
   interactions are direct. The data support the modal approach         and the target refer to the same semantic object (meowing
   of knowledge and the grounded cognition theory.
                                                                        sound - cat’s picture). Semantic congruent stimuli usually fa-
   Keywords: Memory; Perception; Audio-visual; Masking;                 cilitate information processing (Chen & Spence, 2010), and
   Priming; Grounded Cognition.
                                                                        may enhance memory performances in semantic (Laurienti et
                                                                        al., 2004) and episodic tasks (Lehmann & Murray, 2005).
                          Introduction
                                                                           In the memory theoretical framework, cross-modal inter-
Our environment is filled with meaningful objects repre-
                                                                        actions tested on meaningful stimuli are generally studied
senting semantic knowledge. These objects are perceptually
                                                                        by inserting a delay between the stimuli. The most famous
processed using several sensory channels in which the
                                                                        paradigm in this field is the cross-modal priming paradigm.
auditory and visual modalities dominate the other senses in
                                                                        The cross-modal priming effect is the facilitation of the pro-
Human (for a review see Spence, 2007). The sensory infor-
                                                                        cessing of one stimulus in one modality (the target) by the
mation is mainly integrated on the basis of the temporal and
                                                                        previous presentation of another stimulus in another modal-
spatial relationships between the stimuli (Calvert & Thesen,
                                                                        ity (the prime). The cross-modal priming effect may be ob-
2004), and also on the basis of the semantic relationships
                                                                        served between different modalities, such as the haptic and vi-
existing between them (Laurienti, Kraft, Maldjian, Burdette,
                                                                        sual modalities (Easton, Srinivas, & Greene, 1997), but most
& Wallace, 2004). Yet it remains uncertain how semantic
                                                                        of the studies were realized between the auditory and visual
memory aspects are involved in multisensory perception
                                                                        modalities (for a review see Schneider, Engel, & Debener,
(for a review see Doehrmann & Naumer, 2008). This issue
                                                                        2008). The increasing number of studies on the audio-visual
depends on the perceptual or semantic nature of cross-modal
                                                                        interactions involving meaningful stimuli are aimed at a bet-
interactions, and thus questions the modal or amodal nature
                                                                        ter understanding of these effects. Nevertheless, the nature of
of knowledge (Vallet, Brunel, & Versace, 2010). The present
                                                                        audio-visual interactions, which is the central issue underly-
study therefore aims at assessing the nature of audio-visual
                                                                        ing these effects, remains poorly understood.
interactions using an innovative masking procedure.
                                                                           The nature of these interactions depends on the nature
                                                                    2077

of knowledge. This question is much less studied since it             not manipulated in this particular study. Consequently, the
was supposed that semantic knowledge is amodal, i.e., con-            nature and the specificity of the mask remain unexplored.
text free (e.g., Coccia, Bartolini, Luzzi, Provinciali, & Lam-
bon Ralph, 2004). Semantic knowledge was defined as gen-                 The objective of the present study is therefore to assess the
eral knowledge on objects and their properties, words mean-           nature and the specificity of the mask effect for audiovisual
ing and facts in general (Tulving, 1972). In the amodal               interactions in the processing of meaningful stimuli and then
knowledge theoretical framework of memory, the interactions           in semantic knowledge. This research topic questions the na-
between the auditory and visual modalities are supposed to            ture of semantic audio-visual interactions and is thus an at-
be semantic. The co-activation between modalities is sup-             tempt to clarify the issue about the amodal or modal nature
posed to be indirect through an abstract semantic represen-           of knowledge. To this aim, the paradigm used by Vallet et
tation (Chen & Spence, 2010). In other words, the presenta-           al. (2010) was adapted into a short-term priming paradigm.
tion of one component in one modality (e.g., meowing sound)           In this form, the prime is immediately followed by the tar-
should activate the abstract conceptual representation in se-         get in the same trial so that semantic congruency can be ma-
mantic memory (”cat”) through a bottom-up activation. In a            nipulated. In each trial, the participants first heard a sound
second step, this activation would activate all the associated        as prime. Half of these primes were presented with a visual
features through a top-down activation (e.g., visual represen-        abstract mask. Then, they had to categorize the picture tar-
tation of a cat).                                                     get as an animal or as an artefact. Half of the trials were
   The amodal nature of knowledge is challenged nowadays              category-congruent, i.e. the sound prime and the picture tar-
by the grounded cognition theory (e.g., Brunel, Labeye,               get belonged to the same category. The other half of the tri-
Lesourd, & Versace, 2009). In this approach, knowledge is             als were category-incongruent, i.e. the sound prime and the
modal and the cognitive system is supposed to simulate the            picture target belonged to two different categories. In ad-
situation to be processed (Barsalou, 2008; Versace, Labeye,           dition, half of the trials in the category-congruent condition
Badard, & Rose, 2009), so that processing a familiar sound            were item-congruent (e.g., meowing sound - cat’s picture)
shall automatically activate the associated representations in        and half item-incongruent (e.g., meowing sound - eagle’s pic-
the other sensory modalities (e.g., Molholm, Martinez, Sh-            ture). The item-congruency manipulation permits the precise
paner, & Foxe, 2007). Since the simulation is done in the             assessment of the specificity of the mask effect and the avoid-
same brain areas than perception (e.g., Slotnick & Schacter,          ance of cognitive interference resulting from the utilization of
2006), then the co-activation between modalities should be            two different categories (Taylor, Moss, & Tyler, 2007).
direct and perceptual (Brunel et al., 2009; Vallet et al., 2010).        Two hypotheses may be contrasted. First, according to the
                                                                      amodal framework, a sensory meaningless mask effect should
   As perception remains dominant, the simulation should              be explained by attention since no direct link should exist be-
not occur efficiently if a rival sensory perception is pre-           tween the modalities. In this case, the mask should modulate
sented at the same time in the simulation’s modality. This            the processing of the target regardless of the semantic con-
hypothesis was recently tested in young adults (Vallet et al.,        gruency. On the contrary, according to the modal hypothe-
2010). In this study, we developed an innovative long-term            sis, a sensory mask should alter the processing of the target
cross-modal priming paradigm using familiar bimodal items             only in the semantically congruent condition. In this case, the
(sound-picture). In a long-term priming paradigm all the              mask should have a perceptual memory effect. A visual mask
primes are first presented in the study phase, whereas all            should interfere with the automatic activation of the visual
the targets are presented in a second phase, called the test          representation associated to the auditory prime (semantically
phase. A mask was presented with half of the primes and it            congruent). The authors of the present study hypothesize that
shared the target’s modality rather than the prime’s modality.        the mask will have a perceptual effect.
For instance, in the auditory to visual modalities direction, a
visual abstract mask was presented with half of the auditory                                      Method
primes. A cross-modal priming effect was observed for the
                                                                      Participants
targets associated with unmasked primes in the study phase
compared to new pictures (no sound heard). The main result            Twenty-four right-handed students (4 men; 20 women; x̄ =
was that visual targets associated to auditory masked-primes          21.71 ± 3.87) recruited at Lyon 2 University (France) took
in the study phase were processed as new pictures. No                 part in the experiment. The participants had no history of
significant effect was observed in the study phase for the            medical or psychiatric disorder. They were all native French
masked primes suggesting that the mask interfered with the            speakers and demonstrated adequate visual and hearing per-
simulation of the representations associated to the prime.            formances.
Nevertheless and coherent with amodal approach of knowl-
edge, attention resources could have been divided between             Stimuli and material
modalities. In this case, the mask might have produced a              Overall 200 stimuli were used: half of them were sounds and
less efficient processing of the prime and thus of the target         half photographs. Half of the stimuli were familiar animals
(Mulligan, 2003). In addition, the semantic congruency was            (e.g., cow, cat, dog, lion), and the other half familiar artefacts
                                                                  2078

(e.g., piano, guitar, bell, airplane). All the photographs had       ditions) by masking (masked, unmasked primes). All
the same format (393 x 295 pixels, resolution of 72 x 72 dots        the stimuli of the category-congruent condition (item-
per inch). All the sounds were edited to last 1,000 ms. Each         congruent and item-incongruent, 10 stimuli per condition)
participant himself adjusted the auditory intensity in order to      were counterbalanced between subjects into the unmasked
reach a comfortable level. Ten visual color masks were cre-          item-congruent, masked item-congruent, unmasked item-
ated using Photoshop CS3 Mac. A ripple effect was applied            incongruent and masked item-incongruent conditions ac-
to 10 color pictures not included in the experimental material.      cording to 4 different lists. The uncontrolled stimuli (20
This procedure was meant to make the result impossible to be         per condition) were assigned into the 2 following condi-
identified just like an abstract painting. Different masks were      tions: unmasked category-incongruent and masked category-
created to avoid a systematic association between the stimuli        incongruent conditions.
and a specific mask, and to avoid repetition.
                                                                     Procedure and design
   Prediction in the categorization task was avoided by defin-
ing an equal number of category-congruent trial (in which            The experiment was conducted using a Macintosh MacBook
primes and targets belong to a same category) and of                 Pro. Psyscope software X B53 (Cohen, MacWhinney, Flatt,
category-incongruent trials (in which primes and targets be-         & Provost, 1993) was used to set up and manage the experi-
long to different semantic categories). This design is the most      ment. Informed written consent was obtained from each par-
used to manipulate semantic congruency. Yet some attention           ticipant. Each participant was tested individually in one ses-
effect such as inhibition may be involved when the prime and         sion lasting approximately 12 minutes (see Figure 1 for an
the target belong to different categories (Taylor et al., 2007).     illustration of the protocol). The participants were informed
Consequently, we chose to focus on the item-congruency               that they were taking part in a study on reaction speed to vi-
level to assess precisely the specificity of the mask effect. In     sual stimuli. Participants were told that before the presenta-
this case, the prime and the target belong to the same general       tion of each picture, they will hear a sound which could match
category, and could either be semantically congruent (e.g.,          or not to the picture. They were also informed that sometimes
meowing sound then cat’s picture) or semantically incongru-          a color rectangle may appear on the center of the screen as
ent (e.g., meowing sound then eagle’s picture).                      they hear the sound. The participants were instructed to ig-
   Out of these stimuli, 120 were the same items (60 pho-            nore these stimuli (sounds and rectangles) in order to focus
tographs and 60 sounds) as in our previous study (Vallet et          only on the pictures and the categorization task.
al., 2010). These items were selected in a pre-test experi-
ment to be easily recognizable in each modality, and to be
as prototypical and familiar as possible. The pre-test has
also assessed the sound-picture association (see Vallet et al.,
2010). From these items, 20 bimodal items (20 sounds - 20
pictures) were assigned to the item-congruent condition (e.g.,
meowing sound–cat’s picture). Twenty sounds with 20 differ-
ent pictures were assigned to the item-incongruent condition
(e.g., barking sound–eagle’s picture). These two conditions
were included in the category-congruent condition in which
the sound and the picture belong to the same general semantic
category.
   Eighty new stimuli (40 sounds, 40 pictures) were included
in the category-incongruent condition (e.g., photocopier’s           Figure 1: Illustration of the experimental protocol. A sound
sound – ant’s picture). However, these new items were                is presented as the prime. For half of the sound primes, an
not counterbalanced with the others conditions (category-            abstract visual mask is presented. Then, a photograph is cat-
congruent), because it was impossible to find the same ex-           egorized as an animal or as an artefact.
act bimodal, familiar, and recognizable features as those pre-
viously chosen. These items were thus excluded from the                 The experiment began with 16 practice trials which were
analyses. The item-congruency level was preferred to the             followed by the 80-trial test phase. Each trial started with
category-congruency level since it allows a more precise eval-       a central fixation point displayed for 800 ms. This was fol-
uation of the mask specificity.                                      lowed, 300 ms later, by a 1,000 ms sound presented bi-aurally
   Finally, 16 sounds and 16 pictures were included as               through a stereo headset: half of these sounds corresponded
practice trials representing all the experimental conditions.        to animals and the other half to artefacts. For half of these
They were the same for all the participants.                         sounds, a visual mask was presented simultaneously during
                                                                     1,000 ms. Five hundred ms later, a centrally positioned pic-
   In summary, the general design was congruency (item-              ture appeared for 1,000 ms.
congruent, item-incongruent and category-incongruent con-            Each mask was associated with four different sounds. Finally,
                                                                 2079

a white screen was displayed for 3,000 ms or until the par-                                                    unmasked condition were processed faster than masked
ticipant responded. The participants were asked to judge, as                                                   items, t(23) = 2.96, p < .05, d = .46. In contrast, no
quickly and as accurately as possible, whether the picture cor-                                                significant difference was observed in the item-incongruent
responded to an animal or to an artefact. They answered by                                                     condition between the unmasked and masked items, t(23)
pressing the appropriate key on the keyboard. Response log-                                                    = .39, p = .70. The subtraction of the reaction times of the
ging started with the presentation of the picture.                                                             unmasked item-congruent condition from the reaction times
   The sounds and the pictures were presented in random or-                                                    of the unmasked item-incongruent condition indicated a
der. The response keys were counterbalanced across the par-                                                    priming effect of 36 ms.
ticipants.
                                                                                                                  In summary, the analyses revealed no effect of any
                                                                Results                                        factor for the correct response rates. Regarding the re-
The mean correct reaction times and mean rates of cor-                                                         action times, the main finding was that the unmasked
rect responses were calculated across subjects for each                                                        semantically-congruent were processed faster than the
experimental condition. The practice trials were excluded                                                      masked semantically-congruent items.
from the analyses as were the category-incongruent items1 .
Reaction times that differed by more than 2.5 standard                                                                                 Discussion
deviations from the mean in each condition were treated
as outliers (less than 2% of the data). Separate analyses of                                                   This study was designed to assess the nature of audio-visual
variance (ANOVA) were performed on percentages of correct                                                      interactions in semantic knowledge using a masking short-
responses and correct reaction times. The analyses were                                                        term cross-modal paradigm with familiar bimodal objects.
performed with subjects as random variable according to a 2                                                    Half of the sound primes were presented simultaneously with
(item-congruency: item-congruent vs. item-incongruent) x 2                                                     a visual abstract mask. The picture targets were categorized
(mask: masked vs. unmasked) within-subjects variables. The                                                     into animals or artefacts. The picture targets and the sound
data were analyzed using PASW for Macintosh (SPSS Inc.).                                                       primes could be semantically congruent (item-congruent),
                                                                                                               or semantically incongruent (item-incongruent and category-
   The analyses performed on correct responses revealed no                                                     incongruent).
significant effect of any factor. There might be ceiling effects                                                  The reaction times analyses showed that congruent stim-
since the overall correct response rate was 95.1%.                                                             uli were processd faster than incongruent stimuli, as typically
   The analysis of reaction times revealed a main effect of the                                                expected (Laurienti et al., 2004). The results also demon-
item-congruency, F(1, 23) = 12.91, p < .05, η2partial = .35.                                                   strated a cross-modal priming effect. The unmasked item-
There was no effect of the mask (F(1, 23) = 2.82, p = .11), but                                                congruent stimuli were processed faster than the unmasked
a significant interaction between item-congruency and mask,                                                    item-incongruent stimuli with a gain of 36 ms. This re-
F(1, 23) = 5.96, p < .05, η2partial = .21.                                                                     sult replicates the finding of a cross-modal priming for fa-
                                                                                                               miliar objects (e.g., Schneider et al., 2008). However, the
                                      580	  
                                                                                                               most important finding of this study was the mask by item-
                                      570	                                                                    congruency interaction. The results demonstrated that the
       Reac7on	  Times	  (ms)	  
                                      560	                                                                    mask interfered with the processing of the target only in the
                                      550	                                                                    item-congruent condition. In the item-incongruent condition,
                                      540	                                                                    no significant difference was observed between masked and
                                      530	  
                                                                                                               unmasked items. The mask interference replicated our pre-
                                      520	  
                                      510	  
                                                                                                               vious findings in a long-term cross-modal priming paradigm
                                      500	                                                                    (Vallet et al., 2010).
                                                Unmasked	       Masked	     Unmasked	       Masked	           The mask interference could be explained in an amodal ap-
                                                 Primes	        Primes	      Primes	        Primes	  
                                                                                                               proach of knowledge by an attention effect only since, ac-
                                                    Item-­‐Congruent	           Item-­‐Incongruent	  
                                                                                                               cording to this theory, no direct relation is supposed to ex-
                                                                                                               ist between the sensory modalities (cf. the SPI model, Tul-
Figure 2: Means and standard errors for reaction times of the                                                  ving, 1995). Should this hypothesis be true, an attention ef-
item-congruency by mask interaction.                                                                           fects should impact both congruent and incongruent seman-
                                                                                                               tic items conditions, because attention would be divided into
  The detailed analysis of this interaction (see Figure 2)                                                     the different modalities (Mulligan, 2003) or because atten-
demonstrated that the items in the semantically congruent                                                      tion would be enhanced by a multisensory stimulation (e.g.,
    1 ANOVA with the category-incongruent condition revealed no                                                Koelewijn et al., 2010; Sperdin, Cappe, Foxe, & Murray,
effect for the correct response rates. For the reaction times, the                                             2009). In the present study, the attention hypothesis can be
ANOVA revealed an effect of the item-congruency, F(1,23) = 6.18,                                               rejected since the mask effect is specific to the semantically
p<.05 and item-congruency by mask interaction, F(1,23) = 4.79,
p<.05. No difference in the category-incongruent conditions t(23)                                              congruent condition. In addition, an attention effect was also
= .30, p=.76.                                                                                                  insufficient to explain the interference observed in our previ-
                                                                                                            2080

ous study (Vallet et al., 2010). Indeed, in this study, there was     of the prime, and until 300 ms after (Enns & Di Lollo, 2000).
no significant difference on correct response rates and reac-         Consequently, an ISI of 500 ms should be long enough to al-
tion times between the prime presented with the mask and the          low an integration of the features and long enough to avoid
prime presented without the mask in the study phase.                  forward masking (i.e. a perceptual interference of a mask on
    Supporting our hypothesis, the mask interference is spe-          a stimulus presented after the mask).
cific to the semantically associated features. The masking               In conclusion, this study showed that cognition could
procedure used here is unusual since the masking proce-               be multimodal as supposed by the grounded cognition the-
dure is classically explained by a superposition of the same          ory. Knowledge would be sensory-dependent so that the co-
kind of sensory information on the prime (for a review see            activation between sensory modalities should be automatic
van den Bussche, van den Noortgate, & Reynvoet, 2009). Yet            and direct. The masking effect observed in the present study
the mask seems to interfere with the target rather than with the      seems to refer to both memory and multisensory perception.
prime in our paradigm. This effect is not a forward masking,          This effect is an additional argument in favour of studies com-
i.e. a mask before the stimulus. Indeed, forward masking is           bining multiple sub-domains of cognition. The modal hy-
limited to 300 ms (Enns & Di Lollo, 2000) whereas an inter-           pothesis has important repercussions on the understanding
stimuli interval (ISI) of 500 ms was used in the present study.       of cognition and eventually has an impact on clinical prac-
This interference effect thus appears to be related to memory         tice. Sensory-dependent knowledge has also recently been
rather than to perception. While perception is supposed to oc-        demonstrated in healthy aging (Vallet, Simard, & Versace, in
cur at a lowest level than memory recent studies have demon-          press). Consequently, memory disorders and memory reha-
strated that learned associations or expertise could play a cen-      bilitation programs in the elderly might find some new per-
tral role in multisensory perception (Mitterer & Jesse, 2010;         spectives based on multisensory knowledge. Some cognitive
Petrini, Russell, & Pollick, 2009). These data suggest that           rehabilitation programs focusing on the link between percep-
memory and perception are closer that previously hypothe-             tion and memory may eventually be developed, that may im-
sized. Results from different studies support this hypothe-           prove memory functioning by enhancing multimodal presen-
sis with common activations for visual imagery and visual             tation and mental imagery.
perception (Ishai & Sagi, 1995) and with direct influence of
memory features on perceptual tasks (Riou, Lesourd, Brunel,                               Acknowledgments
& Versace, in press). These relationships between memory              Guillaume Vallet and Rémy Versace are supported by a grant
and perception are supposed to exist in the grounded cogni-           from the Rhône-Alpes Region through the cluster “Handicap
tion theory (Barsalou, 2008). The presentation of a visual            – Aging – Neurosciences”.
mask during the perception of a sound prime would interfere
with the simulation of the visual associated representation of                                 References
the object in memory. This hypothesis could explain why, in
                                                                      Barsalou, L. W. (2008). Grounded cognition. Annual Review
our study, the mask’s interference is specific to the semanti-
                                                                         of Psychology, 59, 617–645.
cally congruent condition.
                                                                      Brunel, L., Labeye, E., Lesourd, M., & Versace, R. (2009).
    Our interpretation of the mask-congruency interaction                The sensory nature of episodic memory: Sensory priming
is therefore that the visual mask has interfered with the                effects due to memory trace activation. Journal of Experi-
automatic and direct activation of the visual representation of          mental Psychology: Learning, Memory, and Cognition, 35,
the object associated with the sound prime. The visual mask              1081–1088.
might then overlap with the activation (simulation) of the            Calvert, G. A., & Thesen, T. (2004). Multisensory integra-
visual associated representation of the sound prime. These               tion: Methodological approaches and emerging principles
data support a perceptual (or sensory-dependent) nature of               in the human brain. Journal of Physiology, 98, 191–205.
the audio-visual interactions and thus support the grounded           Chen, Y. C., & Spence, C. (2010). When hearing the bark
cognition theory.                                                        helps to identify the dog: Semantically-congruent sounds
                                                                         modulate the identification of masked pictures. Cognition,
    However, the present study has some limitations. For in-             114, 389–404.
stance, the time window chosen might be surprising. An ISI            Coccia, M., Bartolini, M., Luzzi, S., Provinciali, L., & Lam-
of 500 ms is unusual for a study on multisensory interaction             bon Ralph, M. (2004). Semantic memory is an amodal,
(e.g., Chen & Spence, 2010). Yet multisensory interaction                dynamic system: Evidence from the interaction of naming
and integration could occur with an ISI of 500 ms as in the              and object use in semantic dementia. Cognitive Neuropsy-
present study (Wallace et al., 2004). This ISI was chosen                chology, 21, 513–527.
based on a study demonstrating that shorter ISI (100 ms) pro-         Cohen, J., MacWhinney, B., Flatt, M., & Provost, J. (1993).
duced an additive effect compared to longer ISI (300) leading            Psyscope: A new graphic interactive environment for de-
to an integration of the activations (Labeye, Oker, Badard, &            signing psychology experiments. Behavior Research Meth-
Versace, 2008); and because the masking effect was observed              ods, 25, 257–271.
if the mask was presented until 250 ms before the presentation        Doehrmann, O., & Naumer, M. (2008). Semantics and the
                                                                  2081

  multisensory brain: How meaning modulates processes of             Sperdin, H., Cappe, C., Foxe, J., & Murray, M. (2009).
  audio-visual integration. Brain Research, 1242, 136–150.             Early, low-level auditory-somatosensory multisensory in-
Driver, J., & Noesselt, T. (2008). Multisensory interplay              teractions impact reaction time speed. Frontiers in Integra-
  reveals crossmodal influences on ’sensory-specific’ brain            tive Neuroscience, 3, 1–10.
  regions, neural responses, and judgments. Neuron, 57, 11–          Taylor, K., Moss, H., & Tyler, L. (2007). The conceptual
  23.                                                                  structure account: A cognitive model of semantic memory
Easton, R., Srinivas, K., & Greene, A. (1997). Do vision               and its neural instantiation. In J. Hart & M. Kraut (Eds.),
  and haptics share common representations? Implicit and               The neural basis of semantic memory (pp. 265–301). Cam-
  explicit memory within and between modalities. Journal               bridge University Press.
  of Experimental Psychology: Learning, Memory, and Cog-             Tulving, E. (1972). Episodic and semantic memory. In E. Tul-
  nition, 23, 153–163.                                                 ving & W. Donaldson (Eds.), Organization of memory (pp.
Enns, J., & Di Lollo, V. (2000). What’s new in visual mask-            381–403). New York: Academic Press.
  ing? Trends in Cognitive Sciences, 4, 345–352.                     Tulving, E. (1995). Organization of memory: Quo Vadis?
Ishai, A., & Sagi, D. (1995). Common mechanisms of visual              In M. Gazzaniga (Ed.), The cognitive neurosciences (pp.
  imagery and perception. Science, 268, 1772–1774.                     839–847). Cambridge, Mass: MIT Press.
Koelewijn, T., Bronkhorst, A., & Theeuwes, J. (2010). At-            Vallet, G., Brunel, L., & Versace, R. (2010). The percep-
  tention and the multiple stages of multisensory integration:         tual nature of the cross-modal priming effect: Arguments
  A review of audiovisual studies. Acta Psychologica, 134,             in favor of a sensory-based conception of memory. Exper-
  372–384.                                                             imental Psychology, 57, 376-382.
Labeye, E., Oker, A., Badard, G., & Versace, R. (2008). Acti-        Vallet, G., Simard, M., & Versace, R. (in press). Sensory-
  vation and integration of motor components in a short-term           dependent knowledge in young and elderly adults: Argu-
  priming paradigm. Acta psychologica, 129, 108–111.                   ments from the cross-modal priming effect. Current Aging
Laurienti, P., Kraft, R., Maldjian, J., Burdette, J., & Wallace,       Science.
  M. (2004). Semantic congruence is a critical factor in mul-        van den Bussche, E., van den Noortgate, W., & Reynvoet, B.
  tisensory behavioral performance. Experimental Brain Re-             (2009). Mechanisms of masked priming: A meta-analysis.
  search, 158, 405–414.                                                Psychological Bulletin, 135, 452–477.
                                                                     Versace, R., Labeye, E., Badard, G., & Rose, M. (2009).
Lehmann, S., & Murray, M. (2005). The role of multisensory
                                                                       The contents of long-term memory and the emergence of
  memories in unisensory object discrimination. Cognitive
                                                                       knowledge. European Journal of Cognitive Psychology,
  Brain Research, 24, 326–334.
                                                                       21, 522–560.
Mitterer, H., & Jesse, A. (2010). Correlation versus causa-
                                                                     Wallace, M., Roberson, G., Hairston, W., Stein, B., Vaughan,
  tion in multisensory perception. Psychonomic Bulletin &
                                                                       J., & Schirillo, J. (2004). Unifying multisensory signals
  Review, 17, 329–334.
                                                                       across time and space. Experimental Brain Research, 158,
Molholm, S., Martinez, A., Shpaner, M., & Foxe, J. (2007).
                                                                       252–258.
  Object-based attention is multisensory: Co-activation of an
  object’s representations in ignored sensory modalities. Eu-
  ropean Journal of Neuroscience, 26, 499–509.
Mulligan, N. W. (2003). Effects of cross-modal and in-
  tramodal division of attention on perceptual implicit mem-
  ory. Journal of Experimental Psychology: Learning, Mem-
  ory, and Cognition, 29, 262–276.
Petrini, K., Russell, M., & Pollick, F. (2009). When know-
  ing can replace seeing in audiovisual integration of actions.
  Cognition, 110, 432–439.
Riou, B., Lesourd, M., Brunel, L., & Versace, R. (in press).
  Visual memory and visual perception: When memory im-
  proves visual search. Memory & Cognition, 1–9.
Schneider, T., Engel, A., & Debener, S. (2008). Multisen-
  sory identification of natural objects in a two-way cross-
  modal priming paradigm. Experimental Psychology, 55,
  121–132.
Slotnick, S. D., & Schacter, D. L. (2006). The nature of mem-
  ory related activity in early visual areas. Neuropsychologia,
  44, 2874–2886.
Spence, C. (2007). Audiovisual multisensory integration.
  Acoustical Science and Technology, 28, 61–70.
                                                                 2082

