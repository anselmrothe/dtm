UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Unifying Deduction, Induction, and Analogy by the AMBR Model

Permalink
https://escholarship.org/uc/item/79h4k2sh

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Petkov, Georgi
Vankov, Ivan
Kokinov, Boicho

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Unifying Deduction, Induction, and Analogy by the AMBR Model
Georgi Petkov (gpetkov@cogs.nbu.bg)
Ivan Vankov (i.i.vankov@gmail.com)
Boicho Kokinov (bkokinov@nbu.bg)
Central and East European Center for Cognitive Science, Department of Cognitive Science and Psychology,
New Bulgarian University, 21 Montevideo Street
Sofia 1618, Bulgaria

2001, Grinberg & Kokinov, 2003; Petkov & Kokinov,
2009), analogy and perception (Petkov & Shahbazyan,
2007, Petkov & Kokinov, 2009; Kokinov, Vankov &
Bliznashki, 2009), analogy and judgement (Petkov &
Kokinov, 2006). In this paper we return to the initial idea to
model the three traditionally considered separate types of
reasoning (since the time of Aristotle) by the same
mechanisms.
Meanwhile other models of analogy started to explore the
relations between analogy and induction (schema
generalization). The SME has been used in the
generalization of structurally similar situations (Kuehne,
Forbus, Gentner, & Quinn, 2000; Lovett, Lockwood,
Dehghani, & Forbus, 2007). The LISA model and its close
relative DORA have been specifically addressing the
generalization problem and its integration with the
analogical mapping (Hummel & Holyoak, 2003; Doumas,
Hummel, & Sandhofer, 2008).
There are not that many attempts to integrate analogy and
deduction with the exception of PI (Holland, Holyoak,
Nisbett, & Thagard, 1986) and of integrating the SME and
qualitative reasoning (Forbus, 2001).
The current paper describes an attempt to demonstrate
that deduction, induction, and analogy can be produced by a
common pool of simple mechanisms (those postulated in the
DUAL architecture) and that only the context and the
specific interplay between these mechanisms will determine
which of these processes will emerge out of the
computational process. Thus this is an attempt to model
examples of these three processes in a single simulation
experiment – without tuning the parameters or changing the
mechanisms for each of the cases.

Abstract
This paper presents a series of simulations performed with the
AMBR model that demonstrate how deduction, induction, and
analogy can emerge from the interaction of several simple
mechanisms. First, a case of deductive reasoning is
demonstrated when a problem is solved based on general
knowledge. The system represents the target in different ways
depending on the goal, and different solutions are generated.
Second, the constructed solutions of the problems are
remembered and later on used as a base for remote analogy.
Finally, on the basis of the analogy made, a generalized
solution of the class of problems is induced. One important
characteristic of the model is that representation of the task,
problem-solving, and learning are not viewed as separate
modules. Instead, they are different aspects of one and the
same joined work of the basic mechanisms of the architecture.
Keywords: cognitive
generalization.

modeling,

analogy,

deduction,

Introduction
It has been suggested that analogy is the core of human
cognition (Hofstadter, 2001; Holyoak, Gentner, & Kokinov,
2001). The reason is that “relational reasoning” can be
found in a variety of cognitive processes.
Traditionally, however, models of analogy-making have
been isolated from and contrasted to models of deductive
reasoning (Gentner, 1983, 1989; Holyoak & Thagard, 1989,
Hummel & Holyoak, 1997, Hofstadter, 1995). Somehow
gradually analogy-making became a separate and important
domain of study (Gentner, Holyoak, Kokinov, 2001).
When the AMBR model was first launched (Kokinov,
1988) it was suggested as a unified model of deduction,
induction, and analogy. It has been claimed that deduction,
induction, and analogy “are not separate cognitive
mechanisms, but rather a slightly different manifestations of
the same basic mechanisms” (Kokinov, 1988). A few
experiments have been run to demonstrate that deduction,
induction, and analogy have common properties – being
primed by recent experience (Kokinov, 1990), and
transferred knowledge being evaluated on the basis of the
structural correspondence between the target and the
memorized base (Kokinov, 1992). Even though AMBR was
suggested as a unified model of these three “kinds” of
reasoning, the line of its further development has gone in
different directions like exploring the relations between
analogy and memory (Kokinov, 1994a, Kokinov & Petrov,

Brief description of the DUAL architecture
The DUAL architecture was launched (Kokinov, 1994b,
1994c) as a general cognitive architecture that will provide
mechanisms for modeling various cognitive processes.
The knowledge in DUAL is represented by a huge
number of interconnected micro-agents. Each agent‟s
symbolic aspect represents a small piece of knowledge
while its level of activation represents the relevance of this
piece of knowledge to the current context. The activation
spreads through the network as in connectionists networks.
There are two sources of activation – INPUT and GOAL
nodes. Each agent may also have a residual activation that

574

slowly decreases in time. Thus, the pattern of activation
dynamically represents the current context. The agents may
perform symbolic operations – creation of new agents;
changing weights of links, passing markers – with speed,
proportional to their activation level.
Each active instance-agent emits a marker through the
class hierarchy. The marker spreads up with a speed,
proportional to the relevance of the respective concepts.
When two markers cross somewhere, a hypothesis for
correspondence between the two origins is created locally.
In other words, the system performs a micro-analogy – it
„notices‟ that there is something in common between two
items, and makes a micro-generalization of them.
The hypotheses are created independently by local
computations; the hypothesis nodes interconnect themselves
with supporting or inhibitory links; and a constraint
satisfaction network gradually emerges.
When some agents are mapped to the arguments of a
certain relation, the relations involving theses nodes try to
be transferred, enveloping the respective agents. Initially,
the relations are transferred as anticipation-agents – a
hypothesis that something is present in the environment or
that a certain action can be performed. The anticipation may
be verified by a simulated perceptual system. The agents on
the GOAL list in turn activate further the chains of relations
that lead to achieving the goals.
Finally, large structures emerge from the local dynamic
interactions. Many pressures (for consistency, for goal
completion) work in parallel to resolve the competition
between the coalitions of hypotheses. Finally, some
hypotheses win the competition (in different moments of
time), whereas many losers fizzle out. The most promising
hypotheses and anticipations remain in memory for further
usage. Thus, the system learns during the problem solving
and new generalizations and coalitions of generalizations
enrich the system‟s memory.
All mechanisms in DUAL work in parallel and influence
each other. There is no separation between the processes of
retrieval, mapping, formulation of hypotheses and
anticipations; achieving the goal, and learning. Instead, they
run in parallel and influence each other.

double

want

Sister-2

Sister-1

orange
desire

desire

cake

shake

Figure 1. Simplified representation of the problem: two
sisters quarrel for an orange and do not recognize that they
want different parts of it and can divide it.

Simulation 1: Transfer of a solution from
general knowledge (Deduction)
The first simulation (Simulation 1A) models the mind of the
first sister. Her goal is to make a shake, having an orange.
Thus, there are two agents that receive initial activation: a
representation of an orange is on the INPUT; a
representation of a shake is on the GOAL (Fig. 2).
GOAL

INPUT

shake

orange

Sister 1

cake
Sister 2

Domain of the simulations

Figure 2. Part of the initial state of the first simulation.

In order to demonstrate some of DUAL‟s important abilities
in a coherent set of simulations, we decided to apply the
model to a series of negotiation problems which require a
trade-off solution (see Gentner, Loewenstein, Thompson, &
Forbus, 2009). An example of a trade-off problem is the
classical story of the two sisters quarrelling over an orange
(see Figure 1 for a simplified representation) which is
compared to the conflict between Egypt and Israel.

The activation spreads through the class hierarchy – to the
concepts of „orange‟ and „shake‟; upward to the more
abstract concepts; and then back to some of their instances.
Relatively easily, the general knowledge of the recipe for
shake is activated (Fig. 3). There are other instances of
orange and shake in the recipe and the mechanisms for
marker-passing, the creation of hypotheses, and transfer do
their job to produce the mapping between the given
products and the recipe. Soon, the relations that are
necessary for completion of the situation are transferred
back from the recipe knowledge (Fig. 4). Namely, the sister
should take the orange; this implies that she can squeeze out

575

the juice; this in turn is a necessary condition for making a
shake.
Of course, some other instances of orange may be
activated, mapped to the target, and some other relations
may be transferred. The completion of the causal chain from
the initial situation to the goal, however, increases
dramatically the activation of the agents from this chain.
Furthermore, the pressure of this active chain causes the
respective mapping to win the competition. Thus, the
system „solves‟ the problem. As a consequence, the
hypotheses and anticipations, relevant to this „solution‟ are
transformed into permanent agents and remain in the
memory of AMBR for further use. The others fizzle out.

squee
ze

The simulation has finished at the time of 68.06 AMBR
cycles (compare with the longer duration of the other two
simulations).
Simulation 1B is performed to simulate the mind of the
second sister. It is analogous to the first one, except for the
goal. Thus an orange is on the INPUT list, while a cake is
on the GOAL list, and the system successfully transferred
and learned a respective relational chain from the general
knowledge: the sister should take the orange, should peel it,
and should use the pieces of peel for making the cake.
The simulations successfully demonstrate the ability of
the model to select from an un-separated general knowledge
the relevant relations; to transfer them; and to combine them
into a coherent solution. This approach differs from the
traditional analogy-making models, in which the base
situation is separated from the other knowledge.

shake

orange

cause

take
peel

Simulation 2: Context sensitivity and the role
of the goal (Deduction)

General knowledge – receipt
for a shake

Simulation 2 simulates the mind of a third person – a
judge. There is again an orange on the INPUT, but an agent,
which represents the relation that both sisters should be
satisfied, is attached on the GOAL (Fig.5). The same longterm memory that has been used for the previous simulation
is used.

cake

orange

cause

divide

General knowledge – receipt
for a cake
Have juice and
peel

GOAL

INPUT
orange

cause

General knowledge –
separation of an orange

orange

Both happy

Figure 3. Part of representation of the general knowledge
of the model.
Sister 1

squeeze

Sister 2

cause

cake

Figure 5. Part of the system‟s representation of the
situation for simulation 2 (only a part of the chain is shown).

cause
take

orange

shake

The goal, however, is different and this changes
dramatically the further representation of the situation by
the system. It is easy for the model to activate the recipes
for making shake and cake, and to transfer the respective
relations. In other words, it can combine the two solutions
from the previous simulations. However, this is not enough
for achieving the goal, because it is not possible that the two
sisters take the orange at the same time. Thus, no chain of
relations to the goal is created and the activation continues
to spread. Since both the juice and the peel are active,
another piece of knowledge „springs up into the mind‟ of the
model. The juice, the peel, the seeds, etc. are all parts of an
orange. Now knowledge of how to separate an orange into
its parts becomes active. Another chain of transferred
relations reaches the goal, wins the competition, and finally,

shake

sister
GOAL

Figure 4. Part of the dynamically created representation of
the situation. Some agents (dashed) are transferred from
general knowledge.

576

a completely different representation of the situation has
been made by the system (Fig. 6).
The simulation has finished at time 84.00; which is longer
than the first one.
The second simulation additionally demonstrated the
ability of the system to use the basic DUAL mechanisms for
solving problems that formally are not problems for
analogy-making, but rather deductive tasks. Further, the
simulation highlights the importance of the contextsensitivity of DUAL. Depending on the goal of the system,
different relations may be transferred into the representation
of the situation. The initial and the final representation of
the situation may be viewed as two ends of a continuum of
dynamic re-representations of the situation until the goal is
reached.

GOAL. DUAL-agents for Israel and Egypt are attached to
the INPUT (Fig. 7). One instance of orange is also attached
to the INPUT, simulating that the judge is by accident in
front of a table with oranges on it. This is done to help the
system retrieve the story about the two sisters. It is also hard
for people to make such remote analogies (Gick & Holyoak,
1980) because it is difficult to activate the respective remote
bases. May be a certain non-trivial context is necessary in
order remote analogies to be initiated. The mechanisms of
DUAL are context-sensitive and thus certain contexts may
help them make the appropriate remote analogy.
want
desires

double

double

land
Egypt

desert
want

peace
Israel
Sister-2

desires

Sister-1

orange

INPU
T

orange
Both happy

GOA
L

desire

desire

Figure 7. The initial state of the third simulation.
cake

divide
cause

Egypt wants more land and taking the desert will satisfy
it. Israel wants peace and taking the desert will ensure it. All
this knowledge is encoded in the long-term memory as
general knowledge, analogically to the encoding of the
sister‟s recipes. Simulating the point of view of Egypt
(putting „land‟ on the GOAL), the system would transfer the
respective relations from the general knowledge and would
conclude that it should take the desert. The same is for the
Israeli point of view.
However, there is a constraint that both Israel and Egypt
should be satisfied on the GOAL list. The system cannot
solve this problem by retrieving and applying general
knowledge only. It cannot succeed in the same way as in
simulation 2, because there is no such general knowledge in
LTM that land and peace are two separate properties of the
desert.
Thus, the model makes an analogy between the target and
the base learned in the second simulation – how to divide
the orange. Note that this analogy-making does not wait
until the general knowledge is fully exhausted and
deduction has failed (like in PI). Instead, everything runs in
parallel.
Of course, initially the contextual orange is mapped to the
sister‟s orange, and the goal agent – „both satisfied‟ to the
base‟s goal. However, soon the pressure for consistency
ensures the right mapping: Israel and Egypt correspond to
the sisters; and the desert to the orange.

shake

Both
happy

Figure 6. The long-term memory has been enriched with a
new base after the simulation 2 (compare with figure 1).
The process of learning is not a separate sub-process.
Instead, it is a natural consequence of the problem solving
process. The set of winner hypotheses (the solution) is
formed dynamically - its elements emerge at different
moments of time. The increase of the relevance of these
elements is modeled for different reasons (for the sake of
the reasoning process). However, a side effect is that the
system actually learns the solution for further usage.
The next simulation tests how to use this learned cases.

Simulation 3: Remote analogy and
generalization of the solutions
In the third simulation a representation of the classical
Israel-Egypt problem is created and attached to the input of
the system. The mind of a „judge‟ is simulated. Thus, an
instance of the relation „both are satisfied‟ is attached to the

577

The chain of relations to the goal is closed when the
proposal to use separately the two properties of the desert (it
can be used to live on; it can be used as a buffer zone for
ensuring peace, if it is demilitarized) is generated. We have
not yet simulated how the transferred separation of the
desert properties may be used for solving the task. i.e. how
can the land be used for living by Egypt and at the same
time be demilitarized for ensuring peace for Israel. This is
part of our further work but it was already demonstrated that
DUAL is able to combine relations from general knowledge
in order to complete a representation of a certain situation.
Generalization of the solution is simulated. Every winner
hypothesis has a justification (which was the reason for its
creation). Actually, this justification is the common superclass for the two mapped elements. Thus, every winner
hypothesis is a super-class of the base and target elements
and in turn a subclass of the common superclass found.
Thus, it is a generalization of the two mapped elements. At
the same time, the links among hypotheses, created from the
structural correspondence mechanisms, keep all these
winning hypotheses together – as a coalition that represents
the whole generalized solution. Part of it is shown on Fig. 8.
part1

mathematical problems (Anderson & Thompson, 1989),
negotiation problems (Gentner, Loewenstein, Thompson &
Forbus, 2009), everyday physics problems (Klenk &
Forbus, 2007), designs problems (Davis, Goel &
Nersessian, 2009). The goal of the current paper was to
show that the mechanisms underlying analogy-making are
universal enough to be able to solve any kind of problems,
including ones which are traditionally thought to be out of
the scope of analogy-making. To this end, we attempted to
show that the basic mechanisms of the DUAL architecture
can be used to model a variety of reasoning tasks.
A series of simulations has been run in the domain of
trade-off problems with the AMBR model without any
changing and tuning in between. The model demonstrated
its ability to use general knowledge in a deductive way in
order to solve a specific task; to remember the solution, and
then retrieve it and use it as a remote analogy to solve
another problem, and finally construct a generalized
solution to a class of trade-off problems. The simulations
are run sequentially and continuously so that the results of
the previous reasoning become available for subsequent
problem solving by memorizing and learning. The model is
yet to be further extended and specific predictions will be
generated by further simulations, these predictions will then
be tested against psychological data. At this point, the
simulations are a proof of concept. They demonstrate that
AMBR can model deductive, inductive, and analogical
reasoning via the same simple mechanisms and that
depending on the task and context each of these cognitive
processes can emerge.

……
.

cause
part2

cause
divide

Acknowledgments
object
of quarrel

This research was supported financially by the European
Office for Aerospace Research and Development under
grant FA8655-10-1-3061 (Adaptive Problem Solving by
Analogy).

both
satisfied

References
Anderson, J. R., & Thompson, R. (1989). Use of analogy in
a production system architecture. In A. Ortony, et al.
(Eds.), Similarity and Analogy, 367-397.
Davies, J., Goel, A. K., & Nersessian, N. J. (2009). A
Computational Model of Visual Analogies in Design.
Cognitive Systems Research: Special Issue on Analogies,
10, 204--215.
Doumas. L. A. A., Hummel, J. E., & Sandhofer, C. M.
(2008). A theory of the discovery and predication of
relational concepts. Psychological Review, 115, 1 - 43.
Forbus, K. (2001). Exploring analogy in the large. In
Gentner, D., Holyoak, K., and Kokinov, B. (Eds.)
Analogy: Perspectives from Cognitive Science. MIT
Press.
Gentner, D. (1983). Structure–mapping: A theoretical
framework for analogy. Cognitive Science, 7, 155-170.
Gentner, D. (1989). Mechanisms of analogical learning. In
S. Vosniadou and A. Ortony, (Eds.), Similarity and

Figure 8. Part of the generalized solution obtained by the
system during the third simulation (not all elements are
shown).
The simulation finished at time 165.18; much later than
the previous two simulations.
The third simulation demonstrates two abilities of
AMBR. First, it is able to use simultaneously general
knowledge and remote analogous situations for problemsolving. Second, it is demonstrated that a generalization of
the solution may emerge from the process of problemsolving without any specialized learning mechanisms.

Conclusion
The idea to use analogy-making for solving complex
problems is not new to the research in the field of cognitive
science and artificial intelligence. Computational models of
analogy-making have been applied successfully in solving

578

Analogical Reasoning, 199-241. London: Cambridge
University Press.
Gentner, D., Holyoak, K., Kokinov, B., eds. (2001). The
Analogical Mind: Perspectives from Cognitive Science.
Cambridge, MA: MIT Press.
Gentner, D., Loewenstein, J., Thompson, L., & Forbus, K.
(2009). Reviving inert knowledge: Analogical abstraction
supports relational retrieval of past events. Cognitive
Science, 33, 1343-1382.
Gick, M. L., & Holyoak, K. J. (1980). Analogical problem
solving. Cognitive Psychology 12, 306--355
Grinberg, M., Kokinov, B. (2003). Analogy-Based Episode
Blending in AMBR. In: Kokinov, B., Hirst, W. (ed.)
Constructive Memory. Sofia: NBU Press.
Holland, J. H., Holyoak, K. J., Nisbett, R. E., & Thagard, P.
(1986). Induction: Processes of inference, learning, and
discovery. Cambridge, MA: MIT Press.
Hofstadter, D. & the Fluid Analogies Research Group
(1995). Fluid concepts and creative analogies. New
York: Basic Books
Hofstadter, D. (2001). Analogy as the Core of Cognition. In:
Gentner, D., Holyoak, K., Kokinov, B. (eds.) The
Analogical Mind: Perspectives from Cognitive Science.
Cambridge, MA: MIT Press
Holyoak K. & Thagard P. (1989). Analogical mapping by
constraint satisfaction. Cognitive Science, 13, 295-355
Holyoak, K., Gentner, D., Kokinov, B. (2001). The Place of
Analogy in Cognition. In: Holyoak, K., Gentner, D.,
Kokinov, B. (eds.) The Analogical Mind: Perspectives
from Cognitive Science. Cambridge, MA: MIT Press.
Hummel, J. & Holyoak, K. (1997). Distributed
representation of structure: A theory of analogical access
and mapping. Psychological Review, 104, 427-466.
Hummel, J. E., & Holyoak, K. J. (2003). A symbolicconnectionist theory of relational inference and
generalization. Psychological Review, 110, 220-264.
Klenk, M. and Forbus, K. (2007). Cognitive modeling of
analogy events in physics problem solving from
examples. Proceedings of the 28th Annual Conference of
the Cognitive Science Society. Erlbaum, Hillsdale, NJ.
Kokinov, B. (1988). Associative memory-based reasoning:
How to represent and retrieve cases. In T.O'Shea &
V.Sgurev (Eds.), Artificial intelligence III: Methodology,
systems, applications (pp. 51-58). Amsterdam: Elsevier
Science Publ.
Kokinov, B. (1990). Associative memory-based reasoning:
Some experimental results. Proceedings of the 12th
Annual Conference of the Cognitive Science Society (pp.
741-749). Hillsdale, NJ: Erlbaum.
Kokinov, B. (1992). Inference evaluation in deductive,
inductive and analogical reasoning. Proceedings of the
Fourteenth Annual Conference of the Cognitive Science
Society (pp. 903-908). Hillsdale, NJ: Erlbaum.
Kokinov, B. (1994a). A hybrid model of reasoning by
analogy. In K. Holyoak & J. Barnden (Eds.), Advances in
connectionist and neural computation theory: Vol.2.

Analogical connections (Chapter 5, pp. 247- 318).
Norwood, NJ: Ablex.
Kokinov, B. (1994b). The context-sensitive cognitive
architecture DUAL. Proceedings of the Sixteenth Annual
Conference of the Cognitive Science Society. Hillsdale,
NJ: Erlbaum.
Kokinov, B. (1994c). The DUAL cognitive architecture: A
hybrid multi-agent approach. In: Proceedings of the
Eleventh European Conference of Artificial Intelligence
(ECAI-94). London: John Wiley & Sons, Ltd
Kokinov, B., Petrov, A. (2001). Integration of Memory and
Reasoning in Analogy-Making: The AMBR Model. In:
Gentner, D., Holyoak, K., Kokinov, B. (eds.) The
Analogical Mind: Perspectives from Cognitive Science,
Cambridge, MA: MIT Press.
Kokinov, B., Vankov, I., Bliznashki, S. (2009). How
Analogy Could Force Re-representation of the Target and
Inhibition of the Alternative Interpretation. In: Kokinov,
B., Holyoak, K., Gentner, D. (eds.). New Frontiers in
Analogy Research. Sofia: NBU Press.
Kuehne, S., Forbus, K., Gentner, D. and Quinn, B. (2000).
SEQL: Category learning as progressive abstraction using
structure mapping. Proceedings of CogSci 2000, August.
Lovett, A., Lockwood, K., Dehghani, M., & Forbus, K.
(2007). Modeling human-like rates of learning via
analogical generalization. Proceedings of Analogies:
Integrating Multiple Cognitive Abilities. Nashville,
Tennessee.
Petkov, G. & Kokinov, B. (2006). JUDGEMAP Integration of Analogy-Making, Judgment, and Choice.
Proceedings of the 28th Annual Conference of the
Cognitive Science Society. Erlbaum, Hillsdale, NJ.
Petkov, G, Shahbazyan, L. (2007) The RecMap Model of
Active Recognition Based on Analogical Mapping. In
Lewis, R, Polk, T, Laird, J (Eds): Proceedings of the 8th
International Conference on Cognitive Modeling. Ann
Arbor, Michigan, pp. 293 – 298
Petkov, G.,Kokinov, B. (2009) Modeling cued recall and
memory illusions as a result of structure mapping.
Proceedings of the 30 Annual Conference of the Cognitive
Science Society, Erlbaum, Hillsdale, NJ, pp. 863-868.

579

