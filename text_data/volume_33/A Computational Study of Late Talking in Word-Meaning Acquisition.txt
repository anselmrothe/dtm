UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Study of Late Talking in Word-Meaning Acquisition
Permalink
https://escholarship.org/uc/item/0cd4w3pq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Nematzadeh, Aida
Fazly, Afsaneh
Stevenson, Suzanne
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            A Computational Study of Late Talking in Word-Meaning Acquisition
                                   Aida Nematzadeh, Afsaneh Fazly, and Suzanne Stevenson
                                                     Department of Computer Science
                                                           University of Toronto
                                                 {aida,afsaneh,suzanne}@cs.toronto.edu
                               Abstract                                 and ambiguous context. Computational models of cross-
                                                                        situational learning have helped shed light on how various
   Late talkers (LTs)—children who show a marked delay in vo-
   cabulary learning—are at risk for Specific Language Impair-          factors affect the timecourse of word learning (e.g., Frank et
   ment (SLI), and much research has focused on identifying fac-        al., 2007; Yu & Ballard, 2008; Fazly et al., 2010b). How-
   tors contributing to this phenomenon. We use a computational         ever, to our knowledge, there are no computational models of
   model of word learning to further shed light on these factors.
   In particular, we show that variations in the attentional abili-     word learning in context demonstrating the effects of possible
   ties of the computational learner can be used to model various       factors that contribute to late talking.
   identified differences in LTs compared to normally-developing           We address this gap here by exploring the relation be-
   children: delayed and slower vocabulary growth, greater diffi-
   culty in novel word learning, and decreased semantic connect-        tween an attentional factor and the phenomenon of late talk-
   edness among learned words.                                          ing within a computational model of cross-situational word
                                                                        learning. It has been observed that children’s joint attention
                           Introduction                                 skills—which underlie their ability to focus on the intended
Learning word meanings is a key component of the language               meaning for a word—develop over time (Mundy et al., 2007).
acquisition process. While most children are very efficient             However, our computational model as previously formulated
word learners, some show substantial delay. Late talkers                (Fazly et al., 2010a) failed to capture the developmental in-
(LTs) are children at an early stage who are on a markedly              crease in ability to appropriately attend to what is being talked
slower path of vocabulary learning, without evidence of any             about. Here, we extend the model with an attentional mecha-
specific cognitive deficits. Although many LTs eventually               nism that improves over time, and show how it can be varied
catch up to their age-matched peers, some continue on a                 in computational experiments, corresponding to simulations
slower path of learning, and at some point in development are           of normally-developing children and LTs. We examine the
considered as exhibiting specific language impairment (SLI)             impact of the model’s differing attentional abilities, both on
(Thal et al., 1997; Desmarais et al., 2008).                            the timecourse of vocabulary acquisition, and on the prop-
   Early identification of children at risk for SLI is very im-         erties of the learned knowledge. In comparing the different
portant, since early intervention is key to alleviating its ef-         instantiations of the model, we find that a model with weaker
fects. Because late talking can be an early sign of SLI, many           attentional abilities, like LTs, shows a delayed and slower vo-
psycholinguistic studies have attempted both to understand              cabulary growth, as well as less semantic connectivity among
its properties and to identify the factors that contribute to           the words it has encountered. We also investigate whether the
it. Research has shown that LTs exhibit not only a delay                attentional factor we explore may underlie behaviour relevant
in vocabulary learning, but a slower learning rate as well              to the observed subgroups of late talkers: those who eventu-
(e.g., Weismer & Evans, 2002). Moreover, the vocabulary of              ally catch up, and those who are more likely to permanently
LTs appears to exhibit less semantic connectivity than that of          stay on a slower path of learning.
normally-developing children (Beckage et al., 2010; Sheng
& McGregor, 2010). Numerous factors may contribute to                          Overview of the Computational Model
late talking, including environmental conditions, such as the           Model Input and Output
quantity or quality of the linguistic input (Paul & Elwood,
1991; Rowe, 2008), as well as cognitive properties of the               The input to our word learning model consists of a sequence
learner, such as differences in categorization skills, working          of utterance–scene pairs that link an observed scene (what the
memory, or attentional abilities (Jones & Smith, 2005; Stokes           child perceives) to the utterance that describes it (what the
& Klee, 2009; Rescorla & Merrin, 1998).                                 child hears). We represent each utterance as a set of words
   Computational modeling is necessary for investigating pre-           (with no order information), and the corresponding scene as
cise proposals of how such a variety of complex environmen-             a set of semantic features, e.g.:
tal and/or cognitive factors can interact in the process of vo-              Utterance: { anne, broke, the, box }
cabulary learning. One key mechanism believed to help chil-                  Scene: { PERSON, ANNE, TOUCH, CHANGE, SUDDENNESS,
                                                                                     DETERMINER , IS - SOLID , MADE - OF - WOOD , · · · }
dren hone in on the appropriate meaning of a word (given
an infinitely large number of possibilities) is cross-situational          Given a corpus of such utterance–scene pairs, our model
learning (Quine, 1960). Children gradually glean the mean-              learns the meaning of each word w as a probability distribu-
ing of a word by attending to the common elements of the                tion, p(.|w), over all possible semantic features: p( f |w) is the
meaning across its various usages, each occurring in a noisy            probability of feature f being part of the meaning of word w.
                                                                    705

Initially, since all features are equally likely for each word,             Modeling Changes in Attention over Time
the model assumes a uniform distribution for p(.|w). Over
                                                                        The model as presented above does not address the find-
time, this probability is adjusted in response to the cross-
                                                                        ings that children’s attentional skills develop over time (e.g.,
situational evidence in the corpus.
                                                                        Mundy et al., 2007). In particular, we assume that a child at
Learning Algorithm                                                      earlier stages of cross-situational learning will consider that
Our model gradually learns the meanings of words through                a word may be associated with some irrelevant semantic fea-
a bootstrapping interaction between two types of probabilis-            tures, and that gradually, she will attend more and more to
tic knowledge. Given an utterance–scene input received at               only the relevant features for the word. However, the input to
time t, It =(Ut , St ), the model first calculates an alignment         our model consists of the words of an utterance paired with
probability at (w| f ) for each w ∈ Ut and each f ∈ St , that cap-      only semantic features that are relevant to those words. Thus
tures how likely w and f are associated in It . This calculation        to reflect a less-developed attentional mechanism, our model
uses the meaning probabilities learned up to time t − 1, i.e.,          must be made to give some weight to unobserved word–
p(t−1) (f |w), as described in Step 1 below. The model then             feature pairs.
revises the meaning of the words in Ut by incorporating evi-               In fact, the model does provide for such a mechanism.
dence from the alignment probabilities at , as in Step 2 below.         The function λ(t) in Eqn. (3) determines how much of the
This process is repeated for all input pairs It , one at a time.        probability mass of p( f |w) is allocated to unseen word–
                                                                        feature co-occurrences, and thus conversely, reflects the de-
Step 1: Calculating the alignment probabilities. We ex-                 gree to which the model attends to the (relevant) observed
ploit the cross-situational learning assumption that words and          co-occurrences. In the original model of Fazly et al. (2010a),
features that have been associated in prior observations are            however, λ was a very small constant, assuming a highly
more likely to be associated in the current input pair. Since           competent (and unchanging) attentional mechanism in place
the meaning probability, p(t−1) (f |w) (the probability of f be-        even in early stages of word learning. Here we have mod-
ing a meaning element of w), captures this prior strength of            ified the model so that λ is a function of time, in order to
association, the higher this probability, the more likely it is         simulate a learner whose ability to attend to relevant word–
that w is aligned with f in It . In other words, at (w| f ) is pro-     feature co-occurrences improves with age. Specifically, early
portional to p(t−1) (f |w). We normalize this probability over          on the model should give significant weight to unobserved
all word–feature pairs for that feature f in the current input          word–feature pairs, reflecting immature attentional skills, but
in order to capture the relative strength of association of w           over time this weight should decrease, reflecting improved
with f among the current possible alignments. Specifically,             attentional processes that can appropriately focus on the ob-
we use a smoothed version of the following formula:                     served word–feature pairs. This type of development can be
                                                                        achieved by devising λ as an inverse function of time: it starts
                                  p(t−1) (f |w)
                  at (w|f ) =                                   (1)     reasonably large (allocating more probability mass to unseen
                                ∑    p(t−1) (f |w0 )                    word–feature pairs), and gradually decreases (increasing the
                                0
                               w ∈Ut                                    probability mass assigned to observed pairs).
Step 2: Updating the word meanings. We next need to up-                 Modeling Normal and Late-talking Learners
date the probabilities p(t) (f |w) based on the evidence from the
current alignment probabilities. For each w ∈ Ut and f ∈ St ,           The literature provides evidence for individual differences in
we add the current alignment probability for w and f to the             the development of the ability of a learner to respond to joint
accumulated evidence from prior co-occurrences of w and f .             attention (Morales et al., 2000). In particular, late-talking
We summarize this cross-situational evidence in the form of             children exhibit difficulty in using communicative cues and
an association score, which is updated incrementally:                   in initiating joint attention with their partner (Paul & Shif-
                                                                        fer, 1991; Rescorla & Merrin, 1998). Varying the λ function
        assoc(t) (w, f ) = assoc(t−1) (w, f ) + at (w| f )      (2)     provides a way for our model to simulate such individual dif-
                                                                        ferences, by manipulating the rate of decrease in λ as a func-
where assoc(t−1) (w, m) is zero if w and f have not co-
                                                                        tion of t. We assume that a “normal” learner’s attentional
occurred prior to t. The association score of w and f is basi-
                                                                        abilities develop fairly quickly over time, modeled by a λ(t)
cally a weighted sum of their co-occurrence counts.
                                                                        that decreases relatively rapidly (while still providing some
   The model then uses these association scores to update the
                                                                        allowance for unseen word–feature pairs). In contrast, for a
meaning of the words in the current input:
                                                                        late-talking learner, λ(t) should decrease less rapidly. Thus
                              assoc(t) (f , w) + λ(t)                   we adopt this simple formulation:
        p(t) (f |w) =                                           (3)
                          ∑   assoc(t) (fj , w) + β × λ(t)                                         1
                        fj ∈M                                                            λ(t) =        , 0<c≤1                       (4)
                                                                                                1 + tc
where M is the set of all features encountered prior to or at
time t, β is the expected number of distinct features, and λ(t)         where the value of c determines the rate at which λ decreases
is a smoothing factor, discussed in the next section.                   over time, and hence determines the type of the learner.
                                                                    706

  box: { IS - SQUARE:0.82, IS - SOLID:0.77, MADE - OF - WOOD:0.62,
         SIZE :0.4, MADE - OF - CHINA :0.18, HAS - LEGS :0.13,
         HAS - LEAVES :0.08, FLIES :0.03, · · · }
 Figure 1: Sample sensory-motor features & their ratings for box.
                     Experimental Setup
Input Utterance–Scene Pairs
The training data for our model consists of a sequence of ut-
terances, each paired with a set of semantic features as the
scene representation. The utterances are extracted from the
Manchester corpus (Theakston et al., 2001, from CHILDES
MacWhinney, 2000), transcripts of conversations with 12
British children between the ages of 1;8 and 3;0. We use the
child-directed speech (CDS) only, and lemmatize the words.
The data from half of the children is used as development
data, and the rest for our final experiments.                                   Figure 2: Proportion of noun/verb word types learned.
   Because a manually-annotated semantic representation is
                                                                         ferent values for c: c = 1 yields a model, ND, correspond-
not available for any such large corpus of CDS, we automat-
                                                                         ing to a normally-developing child; c = 0.5 yields a model,
ically generate a scene representation for each utterance. To
                                                                         LT.5 , corresponding to a late talker with less severe difficul-
do so, we create an input-generation lexicon which contains
                                                                         ties; and c = 0.25 yields a model, LT.25 , corresponding to a
the “true” meaning t(w) for each word w in our two semantic
                                                                         late talker with more severe difficulties. (These values were
resources.1 Each t(w) is a vector over all possible semantic
                                                                         chosen based on behaviour on development data; all mod-
features. For adjectives and closed class words, each feature
                                                                         els with c < 1 showed some degradation in learning perfor-
(taken from Harm, 2002) has value 1 in t(w) if it is part of
                                                                         mance.) We experiment with two versions of the LT settings
the meaning of the word, and 0 otherwise. For nouns and
                                                                         to explore whether we can model two different types of LTs—
verbs, each feature (taken from Howell et al., 2005) has a
                                                                         those that eventually catch up to their normally-developing
value (between 0 and 1) derived from the relevancy ratings
                                                                         peers, and those that fail to do so.
of 98 sensory-motor features for 352 nouns, and of 85 fea-
tures for 91 verbs; see Figure 1 for an example. We then use                                Experimental Results
t(w) to probabilistically generate the set of observed seman-
                                                                         As mentioned in the Introduction, several key behaviours
tic features for each word w in an utterance U. The scene
                                                                         have been observed regarding the learning of word mean-
representation is the union of this set of features for all w in
                                                                         ings by LTs in comparison with their age-matched peers.
U. For each word, we probabilistically sample the features in
                                                                         First, LTs have both delayed vocabulary learning and a slower
proportion to their value—i.e., features rated as more relevant
                                                                         learning rate; while some LTs catch up to their peers, others
to a word are more likely to appear in the scene representation
                                                                         do not. Second, LTs have more difficulty in learning novel
when that word is used. We take this probabilistic approach
                                                                         words in an experimental setting. Third, the learned words of
to more realistically reflect the noise and uncertainty in the
                                                                         LTs seem to have less strong semantic connectedness among
input, as well as the uncertainty of a child in determining the
                                                                         them. Here, we present three corresponding sets of experi-
relevant meaning elements in a scene.
                                                                         ments demonstrating that variation in the attention parameter
Evaluating the Learned Meanings                                          in our model, reflected in the ND, LT.5 , and LT.25 learners,
To measure how well the model has learned the meaning of                 can lead to each of these behaviours observed in children.
a word w, we compare its learned meaning, l(w) (a vector                 Patterns of Learning in the Models
corresponding to the probability distribution p(.|w)), to its
                                                                         LTs have a vocabulary size substantially below typical chil-
true meaning, t(w) (a vector as described above). We cal-
                                                                         dren at the same age. LTs not only show delayed develop-
culate their similarity, sim(l(w), t(w)), using a simple vector
                                                                         ment, but a different rate of vocabulary learning—i.e., they do
distance measure, cosine. The higher the value of sim, the
                                                                         not just start later, but learn more slowly (e.g., see Beckage
closer the learned meaning l(w) is to the true meaning t(w),
                                                                         et al., 2010, Figure 2). To see whether our LT learners dif-
and the better the meaning of w is learned.
                                                                         fer from our ND learner in a similar way, we train each
Model Parameters                                                         learner on 76K utterances, and look at how the proportion of
Recall that c in Eqn. (4) determines the level of learner’s at-          learned words, out of all words the model has been exposed
tentional abilities. In our experiments, we compare three dif-           to, changes over time. We restrict our attention here to nouns
                                                                         and verbs, since we believe their semantic representation is
    1 We also add about 50 high-frequency words, mostly pronouns         more elaborated (and thus more realistic).
and proper nouns, with simple semantic features. Utterances con-
taining words not found in either of the two resources, or our addi-        The vocabulary growth plots of the three learners, depicted
tional word list, are removed from the input.                            in Figure 2, show interesting differences in accord with the
                                                                     707

patterns seen in children. First, the two LT models not only
lag behind the ND model with respect to the onset of word
learning, but also show a different rate and pattern of vocab-
ulary learning (a very marked difference in the LT.25 case).
Whereas ND shows a sharp increase in the rate of vocabulary
learning early on — 60% of words are learned by the time the
model has received about 150 words — the two LT learners
exhibit a slower and more gradual growth rate. In addition,
the two LT models differ from each other. As is observed
in children, some learners (as with LT.5 ) who start off slow
catch up in vocabulary learning, while others (as with LT.25 )
continue indefinitely to lag behind their age-matched peers.
This distinction is important to understand more fully, since
the latter are at risk for SLI.
                                                                        Figure 3: Average Comp probabilities of learners over time.
Novel Word Learning Experiments
To understand how the vocabulary learning process of LTs            this forced-choice task:
differs from that of typical children, psycholinguists test the
performance of the two groups in a contrived novel word                    Comp(wN ) = P(t(wN )|wN ))
learning situation: An experimenter first introduces a novel                                           sim(l(wN ),t(wN ))
                                                                                           =                                        (5)
word and its novel referent to the child, and then examines                                     ∑w0 ∈{wN ,wF } sim(l(wN ),t(w0 ))
the child’s knowledge of the target (novel) word through ex-
plicit tests of comprehension and/or production.                    To ensure that wF is familiar to the model, we select it from
   Here, we simulate a simplified version of the novel word         nouns with a minimum frequency of 5.
learning experiment of Weismer and Evans (2002). First, we
train the model on some number of corpus inputs, simulating         Production. The production test evaluates the ability of a
a child’s normal word learning experience. We then intro-           learner to produce a recently-taught novel word when pre-
duce a novel noun to the model in several teaching trials as        sented with the corresponding novel object. We calculate the
follows: As our novel noun, we randomly pick a noun that            probability that a learner produces the target novel noun wN
has not occurred in the training utterances. To simulate use        given its true meaning t(wN ), as in:
of the novel noun in natural utterances, we add the noun to
                                                                               Prod(wN ) = P(wN |t(wN ))
an actual (as yet unseen) utterance from the corpus, and add
its probabilistically-generated meaning to the corresponding                                          sim(l(wN ),t(wN ))
                                                                                            =                                       (6)
scene. We train our ND and LT learners on N such teaching                                         ∑w0 ∈W sim(l(w0 ),t(wN ))
utterance–scene pairs as usual.
                                                                    where W is the set of all words that we assume the model
   To examine the novel word learning ability of each learner,
                                                                    could produce in response to t(wN ). Here W consists of all
we repeat the above process for 106 novel nouns, for N =
                                                                    words with a minimum frequency of 3.2 Given the above
3 teaching trials, and for different amounts of prior training
                                                                    formulation, the production probability of a word is high if:
utterances (here, 10K, 30K, or 60K), and test as follows.
                                                                    (i) the learned meaning of the word and its true meaning are
Comprehension. To test comprehension of a recently-                 sufficiently similar; and (ii) this similarity is much higher than
taught novel word, the experimenter asks the child to find the      the similarity between the target object and the learned mean-
referent of the novel word, when presented with the novel           ing of the other words.
object along with one or more familiar objects. Note that in        Analysis of the Results. The Comp and Prod probabili-
our computational experimental setting, the “object” corre-         ties of the three learners, averaged over the 106 novel test
sponding to a word is its true meaning, t(w) (i.e., there is no     words, are given in Figure 3 and Figure 4, respectively. Sim-
distinction between the true meaning of a word and a referent       ilar to what Weismer and Evans (2002) reported, here we
corresponding to that meaning). We pair each novel object           can see that ND performs significantly better than LT.25 in
t(wN ) with one familiar object t(wF ), and calculate the like-     the comprehension test, at all three stages of learning (t-test:
lihood of selecting each of these in response to wN as the          p  0.01). In contrast, we observe a significant difference be-
stimulus. Specifically, we test whether the model’s learned         tween the comprehension performance of LT.5 and that of ND
representation of the meaning of the novel noun, l(wN ), is         only at early stages (after processing 10K and 30K utterances;
closer to the true meaning of the novel noun, t(wN ), or that       p < 0.01), again suggesting that LT.5 may represent a group
of the familiar noun, t(wF ). We use the Shepard-Luce rule          of learners who start off late, but eventually catch up to their
(Shepard, 1957; Luce, 1959), to calculate the probability of
choosing the novel object in response to the novel word in              2 We use the frequency of the novel word as this threshold.
                                                                708

     Figure 4: Average Prod probabilities of learners over time.        Figure 5: Semantic connectivity scores of learners over time.
normal peers. In the production test, ND performs signifi-           ference).
cantly better than both LTs during all the stages of learning;          For each learner, we build a semantic network as follows:
however, the difference between ND and LT0.5 is decreasing           We connect each word to all other words the learner has
over time.                                                           encountered during training, weighting each connection by
   One issue should be noted here: The production scores of          the similarity between the learned meanings of the connected
all learners decrease over time. This happens because at later       words. We expect the semantic networks of the two normal
stages the learners know more words, many of which are se-           learners (the age-matched, AM, and the vocabulary-matched,
mantically related (such as cat, dog, lion, etc.). Thus, the de-     VM) to be more connected compared to the two LT learners.
nominator in Eqn. (6) increases over time due to encountering        We calculate a semantic connectivity score for each learner
more words that are semantically similar to the target word          by comparing the connectivity of the nouns in its network to
(to be produced), and this results in lower production proba-        that of nouns in a gold-standard network formed analogously
bilities. Future work will need to consider alternative prob-        using the true meanings of words. (As in other experiments,
abilistic formulations of production, and explore the degree         here we focus on nouns because of their more elaborate se-
to which our particular meaning representation contributes to        mantic representation.) We represent the connection weights
the observed effect.                                                 of each noun in a network as a vector, and measure the sim-
                                                                     ilarity of the noun’s connections in a learned network and in
Semantic Organization Experiments                                    the gold-standard network using cosine over the two corre-
Late talkers have been shown to not only learn more slowly           sponding vectors. The average of these vector similarities
than their age-matched normally developing children, but             over all nouns is taken as the semantic connectivity score of
also to be learning differently (e.g., Beckage et al., 2010;         the target learned network.
Sheng & McGregor, 2010; Jones & Smith, 2005). In partic-                Figure 5 shows the connectivity scores for the four learners
ular, Beckage et al. (2010) examine the vocabulary of several        trained on different amounts of input. The results show that,
late talking and normally developing children, and show that         in line with the findings of Beckage et al. (2010), both AM
the learned words of late talkers are less semantically con-         and VM learners have more semantic connectivity in their
nected than those of normally developing children.                   learned knowledge of nouns compared to both LTs (all dif-
   Recall that in our input representation, features are gener-      ferences are statistically significant; p  0.01). Once again,
ated probabilistically to reflect the noise and uncertainty in       LT.5 seems to be catching up to the ND learners: The seman-
the input and/or the uncertainty of a child’s perception of          tic connectivity of LT.5 is getting closer to that of AM at the
the relevant meanings for a word. Moreover, in our model,            latest stage of learning.
the weaker attentional abilities of our LT learners (especially
LT.25 ) requires them to observe a word–feature pair more                                     Conclusions
times in order to learn that association. This can lead to           There are several possible explanations behind language de-
(some) semantic features of the word being less well learned.        ficiencies in late talkers, such as inadequacies in their general
The more sparsely learned features may then lead to less se-         cognitive abilities (e.g., attention, categorization, and mem-
mantic connectivity among the words. Here, we compare                ory skills), or in the quality and quantity of their linguis-
the “semantic organization” of nouns for our two LT learn-           tic input. Here, we have focused on modeling variations in
ers, with those of two normally-developing learners: an age-         the development of attentional abilities in normal and late-
matched ND (trained on the same number of utterances as the          talking children. Specifically, we have incorporated an at-
two LTs), and a vocabulary-matched (younger) ND (trained             tention mechanism into an existing model of learning word
on a proportion of these utterances to account for the age dif-      meanings in context, enabling us to model both a learner’s
                                                                 709

cognitive development over time, as well as some individual           Howell, S. R., Jankowicz, D., & Becker, S. (2005). A model
differences among learners in lexical development.                      of grounded language acquisition: Sensorimotor features
   Results of our experiments comparing late-talking (LT) and           improve lexical and grammatical learning. J. of Memory
normally-developing (ND) learners are compatible with the               and Language, 53, 258–276.
psycholinguistic findings: Compared to our ND model, the              Jones, S. S., & Smith, L. B. (2005). Object name learning
LT model with severe difficulties (LT.25 ) exhibits marked de-          and object perception: a deficit in late talkers. J. of Child
lay in the onset of vocabulary learning, performs significantly         Lang., 32, 223–240.
worse in learning novel words, and has less strong semantic           Luce, R. D. (1959). Individual Choice Behavior: A Theoret-
connections among its learned words. In contrast, the LT.5              ical Analysis. New York: Wiley.
learner (with less severe difficulties) is significantly differ-      MacWhinney, B. (2000). The CHILDES project: Tools for
ent from ND only at earlier stages of development, reflecting           analyzing talk (3rd ed., Vol. 2: The Database). Erlbaum.
some normal degree of variation in vocabulary learning.               Morales, M., Mundy, P., Delgado, C. E. F., Yale, M.,
   The model presented here has the potential for studying              Messinger, D., Neal, R., et al. (2000). Responding to joint
many more issues pertaining to normal versus impaired lex-              attention across the 6- through 24-month age period and
ical development. One important issue that needs further in-            early language acquisition. Journal of Applied Develop-
vestigation is the (possibly differential) effect of the linguis-       mental Psychology, 21(3), 283–298.
tic input on lexical development in ND and LT children. In            Mundy, P., Block, J., Delgado, C., Pomares, Y., Hecke,
fact, our probabilistic input generation method enables us to           A. V. V., & Parlade, M. V. (2007). Individual differences
vary the input quality, possibly corresponding to the use of            and the development of joint attention in infancy. Child
social cues or some other attentional mechanism children use            Development, 78(3), 938–954.
to hone in on relevant word–meaning associations.                     Paul, R., & Elwood, T. J. (1991). Maternal linguistic input to
   Another future direction is to further examine the effect of         toddlers with slow expressive language development. J. of
semantic connectedness among words in their acquisition, in             Speech and Hearing Research, 34, 982–988.
both ND and LT children. Late talkers have been shown to              Paul, R., & Shiffer, M. E. (1991). Communicative initiations
do worse in explicit word association tasks (Sheng & Mc-                in normal and late-talking toddlers. Applied Psycholing.,
Gregor, 2010), as well as in recognizing abstract categories            12, 419–431.
(e.g., Jones & Smith, 2005). By adding explicit categoriza-           Quine, W. (1960). Word and object. MIT Press.
tion abilities to our model (e.g., as in Alishahi & Fazly, 2010)      Rescorla, L., & Merrin, L. (1998). Communicative intent in
we can further investigate the differences of our various learn-        late-talking toddlers. Applied Psycholing., 19, 398–414.
ers, both in capturing the semantic connections among words,          Rowe, M. L. (2008). Child-directed speech: relation to so-
and in using these connections to bootstrap word learning.              cioeconomic status, knowledge of child development and
                                                                        child vocabulary skill. J. of Child Lang., 35, 185–205.
                         References                                   Sheng, L., & McGregor, K. K. (2010). Lexical–semantic
Alishahi, A., & Fazly, A. (2010). Integrating syntactic knowl-          organization in children with specific language impairment.
   edge into a model of cross-situational word learning. In             J. of Speech, Lang., & Hearing Research, 53, 146–159.
   Proc. of CogSci’10.                                                Shepard, R. (1957). Stimulus and response generalization:
Beckage, N. M., Smith, L. B., & Hills, T. (2010). Seman-                a stochastic model, relating generalization to distance in
   tic network connectivity is related to vocabulary growth in          psychological space. Psychometrika, 22, 325–345.
   children. In Proc. of CogSci’10.                                   Stokes, S. F., & Klee, T. (2009). Factors that influence vo-
Desmarais, C., Sylvestre, A., Meyer, F., Bairati, I., &                 cabulary development in two-year-old children. J. of Child
   Rouleau, N. (2008). Systematic review of the literature              Psychology, 50(4), 498–505.
   on characteristics of late-talking toddlers. Int’l J. of Lang.     Thal, D. J., Bates, E., Goodman, J., & Jahn-Samilo, J. (1997).
   and Communication Disorders, 43(4), 361–389.                         Continuity of language abilities: An exploratory study of
Fazly, A., Ahmadi-fakhr, F., Alishahi, A., & Stevenson,                 late- and early-talking toddlers. Developmental Neuropsy-
   S. (2010b). Cross-situational learning of low frequency              chology, 13(3), 239–273.
   words: The role of context familiarity and age of exposure.        Theakston, A. L., Lieven, E. V., Pine, J. M., & Rowland, C. F.
   In Proc. of CogSci’10 (pp. 2615–20).                                 (2001). The role of performance limitations in the acquisi-
Fazly, A., Alishahi, A., & Stevenson, S. (2010a). A prob-               tion of verb–argument structure: An alternative account. J.
   abilistic computational model of cross-situational word              of Child Lang., 28, 127–152.
   learning. Cognitive Science, 34(6), 1017–1063.                     Weismer, S. E., & Evans, J. L. (2002). The role of process-
Frank, M. C., Goodman, N. D., & Tenenbaum, J. B. (2007).                ing limitations in early identification of specific language
   A Bayesian framework for cross-situational word-learning.            impairment. Topics in Language Disorders, 22(3), 15–29.
   In NIPS’07 (Vol. 20).                                              Yu, C., & Ballard, D. H. (2008). A unified model of early
Harm, M. W. (2002). Building large scale distributed                    word learning: Integrating statistical and social cues. J. of
   semantic feature sets with WordNet (Tech. Rep. No.                   Neurocomputing, 70(13–15), 2149–65.
   PDP.CNS.02.1). Carnegie Mellon University.
                                                                  710

