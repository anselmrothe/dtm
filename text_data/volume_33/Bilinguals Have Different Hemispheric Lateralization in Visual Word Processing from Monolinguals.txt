UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Bilinguals Have Different Hemispheric Lateralization in Visual Word Processing from
Monolinguals
Permalink
https://escholarship.org/uc/item/5350n1mm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Lam, Sze-Man
Hsiao, Janet Hui-wen
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

    Bilinguals Have Different Hemispheric Lateralization in Visual Word Processing
                                                         from Monolinguals
                                                 Sze-Man Lam (fannylam@hku.hk)
                                               Janet Hui-wen Hsiao (jhsiao@hku.hk)
                                          Department of Psychology, University of Hong Kong
                                                         Pokfulam Road, Hong Kong
                               Abstract                                  location of the dot. Therefore, Sewell and Panou’s results
   Previous bilingual studies showed reduced hemispheric
                                                                         (1983) suggested that the processing of some visual tasks
   asymmetry in visual tasks such as face perception in bilinguals       such as spatial dot localization may be influenced by
   compared with monolinguals, which suggested that                      participants’ language experiences. About 20 years later,
   hemispheric asymmetry in visual tasks could be modulated by           Hausmann et al. (2004) examined performance of bilinguals
   experience in reading one or two languages. Here we examined          and monolinguals in visual tasks and found consistent results.
   whether difference in hemispheric asymmetry in visual tasks           They showed that in the accuracy data of both groups, a
   can also be observed in bilinguals who have different language        typical RVF/LH advantage was found in a sequential
   backgrounds. We compared the behavior of three language
   groups in a tachistoscopic English word sequential matching           word-matching task whereas a typical LVF/RH advantage
   task: English monolinguals (or alphabetic monolinguals,               was found in a face detection task; however, the respond time
   A-Ms), bilinguals with an alphabetic language L1 and English          data revealed a significant LVF/RH advantage in the face
   L2 (alphabetic-alphabetic bilinguals, AA-Bs), and bilinguals          detection task only in monolinguals but not bilinguals. This
   with a logographic language (Chinese) L1 and English L2               result suggested that the RH visual processing abilities may
   (logographic-alphabetic bilinguals, LA-Bs). The results               be affected by language experience.
   showed that AA-Bs had a stronger right visual field/ left
                                                                            The above results seemed to suggest that hemispheric
   hemispheric (LH) advantage than A-Ms and LA-Bs,
   suggesting that different language learning experiences can           asymmetry in RH dominant visual tasks such as face
   influence how visual words are processed in the brain. In             perception and spatial localization could be affected by
   addition, we showed that this effect could be accounted for by        language experience, but not for LH dominant visual tasks
   a computational model that implements a theory of                     such as visual word recognition. However, some difference
   hemispheric asymmetry in perception (i.e. the Double Filtering        between the bilinguals and monolinguals was observed in
   by Frequency theory, Ivry & Robertson, 1998); the modeling            Sewell and Panou’s study (1983). In their word naming task,
   data suggested that this difference may be due to both the
   difference in participants’ vocabulary size and the difference in
                                                                         words were presented unilaterally and the participants were
   word-to-sound mapping between alphabetic and logographic              required to report the word they perceived; the display time
   languages.                                                            was 20ms and 40ms for monolinguals and bilinguals
                                                                         respectively. The authors selected these display times where
   Keywords: Hemispheric asymmetry; bilingualism; visual
   word recognition; computational modeling.
                                                                         the two groups made approximately the same number of
                                                                         errors. This suggested that bilinguals might process the
                                                                         words differently compared with monolinguals. In addition,
                          Introduction
                                                                         in the word sequential matching task in which Hausmann, et
Researchers have found different functional dominance                    al. (2004) did not find performance difference between
between the two hemispheres. One of the most salient                     bilinguals and monolinguals, a centrally presented word was
functional differences is the superiority of the left and right          followed by a unilaterally displayed word; the exposure
hemisphere (LH and RH) in language processing, especially                time was 175ms for both groups. As the same display time
in phonology processing (Corina, Vaid, & Bellugi, 1992),                 was used for both groups and performance level between
and in visuospatial processing and face processing                       groups was not controlled, the results from the word
(Kanwisher, McDermott, & Chun, 1997) respectively.                       sequential matching task of Hausmann, et al. (2004) might
   Despite the converging evidences showing the RH                       not completely reflect the difference between bilinguals and
superiority in specific tasks such as face recognition and               monolinguals in visual word processing. Therefore, in this
visuospatial tasks, there have been studies showing reduced              study, we aim to control for the performance level in the
lateralization in these well-known RH tasks in bilinguals                sequential word matching task employed by Hausmann et al.
compared with monolinguals. Back in the 1980s, Sewell and                (2004) for investigating the impact of language experience
Panou (1983) observed the typical right visual field (RVF)/              on hemispheric asymmetry in visual word recognition.
LH advantage in accuracy in an English word naming task in                  Moreover, as all the previous studies investigated only the
both bilinguals and monolinguals; in contrast, the typical left          population of alphabetic language users, here we aim to
visual field (LVF)/ RH advantage in a spatial dot localization           investigate hemispheric asymmetry in visual word
task was only found in monolinguals but not in bilinguals. In            recognition in the following three groups of people with
this task, a 4x5 grid with a dot in one of the boxes was shown           different language experiences: (1) alphabetic monolinguals
unilaterally, and participants were required to report the               (A-Ms), who know only one alphabetic language; (2)
                                                                     3409

alphabetic-alphabetic bilinguals (AA-Bs), who are                  language backgrounds, namely, A-Ms, AA-Bs, and LA-Bs,
proficient in two alphabetic languages; and (3)                    using a divided visual field word sequential matching task
logographic-alphabetic bilinguals (LA-Bs), who acquire a           modified from Hausmann, et al. (2004).
logographic language (e.g. Chinese) and an alphabetic
language with high proficiency in both. We believe that an         Participants
investigation on the behavioral difference between AA-Bs           66 participants were recruited; all were right-handed
and LA-Bs will provide a broader view on how different             according to the Edinburgh handedness inventory (Oldfield,
language experiences modulate hemispheric asymmetry in             1971), and had normal or corrected to normal vision.
visual word recognition. We describe the differences               Participants were undergraduate or postgraduate students at
between alphabetic and logographic languages below.                the University of Hong Kong and were divided into three
   In alphabetic language processing, functional MRI studies       groups of equal size (n=22) according to their language
revealed a specific region in the LH (i.e. the visual word         background: English monolinguals (A-Ms), bilinguals with
form area) that responds to words selectively (McCandliss,         an alphabetic language L1 and English L2 (AA-Bs), and
Cohen, & Dehaene, 2003); some researchers (Maurer &                bilinguals with Chinese L1 and English L2 (LA-Bs). The
McCandliss, 2007) suggested that the observed LH                   A-Ms spoke English as their L1 and could not fluently use
lateralization in alphabetic language processing is due to the     any other languages. The AA-Bs learnt a non-English, west
application of grapheme-phoneme conversion (GPC) rules             European alphabetic language as their L1 (i.e., French,
during learning to read. Behavioral studies also found a           Spanish, Dutch, German or Italian), and English as their L2
RVF/LH advantage in reading words in alphabetic                    during schooling; they were proficient in both their L1 and
languages in tachistoscopic recognition (Bryden & Rainey,          English. Both A-Ms and AA-Bs had none or very limited
1963). In short, the superiority of the LH in processing           knowledge about logographic scripts such as Chinese
alphabetic languages has been consistently reported.               characters. The LA-Bs were local Hong Kong students who
   In contrast to alphabetic languages, the relationship           learnt Chinese as their L1 and English as an L2 since
between written and spoken logographic languages, such as          kindergarten in formal education; they were proficient in
Chinese, is more opaque due to its morphosyllabic features.        both Chinese and English. Average age of acquisition of
Moreover, stroke patterns in Chinese characters do not map         English was 3.3 for LA-Bs and 7.4 for AA-Bs.
to phonemes in the pronunciation, so GPC rules in
alphabetic languages do not apply to Chinese reading.              Stimuli & Procedures
Functional MRI studies (Tan et al., 2001; Tan et al., 2000)
showed more activation in the visual areas in the RH than          We used an English word sequential matching task to
the LH in reading Chinese characters, and this effect has          measure hemispheric lateralization in English word
been argued to be due to elaborated visual analysis required       processing in the three groups. A hundred pairs of English
for processing spatial information and locations of strokes.       words were selected as the test stimuli from the SUBTLEXUS
In behavioral studies, a LVF/RH advantage was observed in          corpus (Brysbaert & New, 2009). In each pair, the two words
tachistoscopic recognition of Chinese characters (Tzeng,           had the same number of letters and the same initial and final
Hung, Cotton, & Wang, 1979); in a recent study, Hsiao and          letters, and were matched in word frequency. The length of
Cottrell (2009) showed a left side bias effect in Chinese          the word stimuli ranged from four to seven and the average
readers but not in non-Chinese readers in a Chinese                frequency of the word stimuli was 407.57 per million words
character perception task, suggesting more RH involvement          in the SUBTLEXUS corpus.
in Chinese characters recognition. In sum, the superiority of         The task consisted of a pre-test and a test. In the pre-test,
the RH in processing the orthography of logographic                the staircase method was employed to determine a perceptual
Chinese, a logographic language, has been consistently             threshold for each participant in the word matching task, in
reported.                                                          which the participant achieved reliably 80% accuracy. A
   Due to the dramatic differences in orthographic                 1-up 3-down staircase rule was applied (Hartmann, 2004).
processing and hemispheric lateralization between                  That is, for every three consecutive correct responds, the
alphabetic and logographic languages, we predict that in           display time was decreased by one refresh rate, and every
visual word recognition, (1) as alphabetic reading involves        single incorrect response made the display time increased by
more LH processing, and AA-Bs have acquired one more               one refresh rate. Three staircases were run in each pre-test,
alphabetic language than A-Ms, AA-Bs may have a stronger           and each run proceeded until eight turnarounds had occurred.
LH lateralization than A-Ms; and (2) although both AA-Bs           Only the third to the eighth turnarounds were averaged and
and LA-Bs acquired two languages, logographic reading              used as the estimate of the threshold. The display time for the
involves more RH processing, and thus AA-Bs may show a             English words in the subsequent sequential matching task
stronger LH lateralization than LA-Bs.                             was then calculated by averaging the estimated thresholds of
                                                                   the three runs 1. The pre-test followed a similar procedure as
                                                                   the test except all the stimuli were presented at the center of
                     Behavioral Study
We examined hemispheric asymmetry in visual word                      1
                                                                        Note that average threshold for A-Ms (53ms) were slightly
recognition in three groups of participants with different
                                                                   lower than LA-Bs (59ms) and AA-Bs (62ms).
                                                               3410

the screen. The stimuli used in the pre-test were not used                                                   Computational Modeling
again in the test.
                                                                                              Here we aimed to account for the behavioral results through
   There were 100 trials in the test. In each trial, after a
                                                                                              computational modeling. We hypothesized that the
1000ms central fixation, the first stimulus was presented
                                                                                              hemispheric lateralization difference in English word
either in the LVF or RVF, at about 1.5o to 5o of visual angle
                                                                                              processing among the three groups may be due to two
away from the centre (thus the size of the stimulus was about
                                                                                              factors: (1) bilinguals have a larger vocabulary size, and (2)
3.5o), for the display time obtained in the pre-test. The second
                                                                                              reading in alphabetic and logographic languages involve
stimulus was then presented at the center of the screen after
                                                                                              different word-to-sound mappings. We applied the
another 1000ms central fixation. There were equal numbers
                                                                                              intermediate convergence model proposed by Hsiao, Shieh,
of stimuli presented in the two visual fields. The presentation
                                                                                              and Cottrell (2008) to model bilingual visual word
order and condition (LVF or RVF) was randomized.
                                                                                              recognition. Hsiao et al. (2008) showed that this model was
Participants were asked to judge whether the two stimuli
                                                                                              able to account for the left-side bias effect in face perception
were the same by pressing corresponding keys on the
                                                                                              observed in human data (Brady, Campbell, & Flaherty,
keyboard.
                                                                                              2005). The model incorporates several known observations
                                                                                              about visual anatomy and neural computation and
Results                                                                                       implements a theory of hemispheric asymmetry in
Here we define the variable hemisphere lateralization as the                                  perception, Double Filtering by Frequency (DFF, Ivry &
performance difference between the LVF/RH and the                                             Robertson, 1998), but does not assume a LH localized
RVF/LH conditions in terms of accuracy; therefore, positive                                   language center. The DFF theory posits that visual
and negative indices reflect RH and LH lateralization                                         information is captured by frequency-based representation
respectively. One-sample t-test against zero and ANalysis                                     at multiple scales, and the frequency information is filtered
Of VAriance (ANOVA) were used for the analysis.                                               at two stages; in the first stage, a task-relevant frequency
Hemispheric lateralization was the dependent variable and                                     range is selected through attention processes; and at the
language background was the independent variable.                                             second stage, asymmetric filtering processing is applied to
                                RH                                                            the two hemispheres: The LH amplifies high spatial
                                  0%                                                          frequency (HSF) information, while the RH amplifies low
   Hemispheric Lateralization
                                 -2%                                                          spatial frequency (LSF) information. We describe our
                                 -4%                                                          modeling details below.
                                 -6%
                                 -8%
                                -10%
                                                              *
                                                     *                 **
                                -12%
                                       Alphabetic        Alphabetic-        Logographic-
                                LH     Monolingual       Alphabetic          Alphabetic
                                                          Bilingual           Bilingual
  Figure 1: Results from the behavioral experiment. (* p
  < .05, ** p < .01). Error bars show one standard error.
   The results from a one-sample t-test against zero showed
a significant LH lateralization among all the participants
(t(65) = -3.538, p = .001). For individual groups, a
                                                                                                  Figure 2: Hsiao et al.’s hemispheric processing model
significant LH lateralization was found only in AA-Bs (t(21)
                                                                                                  (2008)
= -3.598, p = .002), while A-Ms showed a tendency of a LH
lateralization (t(21) = -1.830, p = .082) and LA-Bs did not                                      In the model, each input image (35x60 pixels) was first
exhibit any significant LH lateralization (t(21) = -.478, n.s.).                              filtered with a rigid grid (5x10) of overlapping 2-D Gabor
ANOVA also showed a significant effect of language                                            filters (Daugman, 1986) at five scales and eight orientations.
background on hemispheric lateralization (F(2, 63) = 4.625,                                   Gabor filters were used to simulate neural responses of
p = .013); post hoc analysis showed that the LH                                               complex cells in the early visual system (Lades et al.,
lateralization was significantly stronger in AA-Bs than the                                   1993), and the frequency range represented the task-relevant
other two groups (independent t-test, A-Ms: t(42) = -2.030,                                   frequency range in DFF theory, as the five scales
p = .049; LA-Bs: t(42) = -2.717, p = .01).                                                    corresponded to 2 to 32 (i.e., 21 to 25) cycles per word
   These results are consistent with our predictions that in                                  whereas our image height was 35 pixels. After the Gabor
the English word sequential matching task, AA-Bs have                                         filters, each input image was transformed into a vector of
more LH lateralization than both A-Ms and LA-Bs. Thus, it                                     size 2000 (5x10 sample points x 5 scales x 8 orientations).
suggests that hemispheric lateralization in visual word                                       A base-line condition and a biased condition were then
recognition may be affected by language experience and                                        created. The second stage of the DFF theory was only
also the orthographic processing of the languages.                                            applied to the biased condition, in which the Gabor
                                                                                              responses of the left and right half of the word were biased
                                                                                           3411

to low and high spatial frequencies respectively by applying       the two languages acquired by our AA-Bs have similar
a sigmoidal weighting function. In contrast, in the base-line      alphabets (i.e. one was English and the other was a
condition, equal weights were given to the Gabor responses         west-European language), we assumed that the behavioral
of different scales. The Principal Component Analysis              difference between the two groups was mainly due to a
(PCA), a biological plausible linear compression technique         larger vocabulary size in AA-Bs compared with A-Ms.
(Sanger, 1989), was then applied to the Gabor
representations of the left and right half-words separately to     Logographic Reading Model (L-model) We simulated
compress each representation into a 50-element                     logographic reading by randomizing the mapping between
representation (i.e., 100 elements in total). This PCA             each word and its pronunciation (i.e. no systematic
representation was then used as the input to a two layer           letter-to-phoneme mapping). We also varied the vocabulary
neural network (See Hsiao et al., 2008, for more simulation        size from 16 to 40 and compared the results with the
details).                                                          A-model to examine the difference between logographic and
   Our model was trained to recognize the input images until       alphabetic reading.
the performance on the training set reached 100% accuracy.
The training algorithm used was gradient descent with an           Logographic-Alphabetic Model (LA-model) This model
adaptive learning rate. To test hemispheric asymmetry              was trained to perform both alphabetic and logographic
effects, we used left or right half damaged inputs, which          reading, so that its behavior could be compared with the
were generated by setting one half of the PCA                      LA-Bs in the behavioral data. Two alphabets were used in
representation to zero. When mapping damaged inputs to             each simulation run, in which letters in one of the alphabet
their corresponding outputs, only the representation from          were systematically mapped to phonemes in the
one of the visual fields was informative in recognition. Thus,     pronunciation, whereas in the other alphabet there was no
in the biased condition, a right-damaged word carried only         systematic mapping. The assignment of mapping method to
LSF/RH information and a left-damaged word carried only            the two alphabets was counterbalanced among the runs. The
HSF/LH information. The RH (LSF) lateralization effect             range of the vocabulary size (half from each lexicon) also
was then measured as the accuracy difference between               ranged from 16 to 40.
recognizing a right-damaged word and a left-damaged word
as the original word. The model was run 40 times in each           Our Hypotheses
condition in the analysis.                                         In a recent study adopting also the intermediate convergence
   We created artificial lexicons for the current examination.     model (Hsiao, et al., 2008), Cheung and Hsiao (2010)
Each word consisted of three letters. The task of the model        demonstrated two factors that lead to more LH bias in visual
was to map each word input to its pronunciation with a             word recognition: (a) visual similarity among word stimuli
consonant-vowel-consonant (CVC) structure. Each lexicon            in the lexicon: more HSF information is required when the
consisted of an alphabet of size 13; eight letters were            visual stimuli look more alike; (b) the task requirement to
randomly assigned as consonants and the rest five letters as       decompose visual stimuli into smaller parts for performing
vowels in the pronunciation. Eight different fonts of the          grapheme-phoneme conversion.
words were used as input images; four of them were used as            Here we hypothesize that (1) The LH (HSF) lateralization
the training set and the other four as the testing set. The        of the A-model will increase with vocabulary size, since the
output layer was divided into three parts; each part               similarity of words increase with vocabulary size; this
corresponded to a position in the CVC structure, and each          prediction is consistent with our behavioral data showing
node corresponded to a phoneme in that position. To                that AA-Bs exhibited a stronger LH lateralization compared
counterbalance the information available in the left and right     with A-Ms; (2) the A-model (alphabetic reading) will show
side of the input images, in each lexicon, the frequency of        more LH (HSF) lateralization than the L-model
each letter in the first and third position was kept equal;        (logographic reading), since decomposition of words is not
mirror images were used in half of the simulation runs.            necessary in the L-model; (3) When performing alphabetic
   In order to compare with the behavioral data, we built          reading, the LA-model will show less LH (HSF)
three models of visual word recognition with different             lateralization than the A-model, since during learning,
vocabulary sizes and different orthography-to-phonology            decomposition of words is required in only half of the times.
mappings to capture the behavioral differences among our
three groups of participants, as describe below.                   Results
Alphabetic Reading Model (A-model) We simulated                    In Figures 3 and 4, hemispheric lateralization represents the
alphabetic reading by mapping each letter in a word                performance difference between correctly recognizing a
systematically to each phoneme in the pronunciation; in            right-damage word and a left-damaged word as the original
addition, we examined the effect of vocabulary size by             word, in the biased condition over the base-line condition.
varying the number of words in the artificial lexicons from
16 to 40 (while keeping the alphabet size 13). As both our         Vocabulary Size Both the A-model and the L-model
A-Ms and AA-Bs were experts in alphabetic reading, and             showed an increase in LH (HSF) lateralization with
                                                                   increasing vocabulary size (Figure 3), and the LA-model
                                                               3412

exhibited a similar pattern as the L-model. For all three                                               Comparison with Behavioral Data The modeling data and
models, significant but weak positive correlations were                                                 behavioral data are compared in Figure 4. We assumed that
observed between LH (HSF) lateralization and vocabulary                                                 the vocabulary size of AA-Bs’ was twice of the A-Ms’. In the
size (A-model: R2 = .054, p < .001; L-model: R2 = .070, p                                               three comparisons, A-M data was derived from the A-model
< .001; LA-model: R2 = .083, p < .001). These results                                                   of vocabulary size of 16, 18 and 20; data for AA-Bs and
showed that in all three models, LH (HSF) lateralization                                                LA-Bs were obtained from the A-model and the LA-model of
increased with vocabulary size 2.                                                                       vocabulary size of 32, 36 and 40 respectively; for the
                                                                                                        LA-model, the presented data consisted of the behavior of
Mapping Method Results from Figure 3 showed that the                                                    alphabetic reading only, to match the behavioral study.
L-model (logographic reading) had a weaker LH (HSF)                                                        The modeling data fit with the behavioral data well. All
lateralization than the A-model (alphabetic reading) (p < .01,                                          three comparisons exhibited a significant group difference
except for vocabulary size of 16).                                                                      (1: F(2, 117) = 3.721, p = .027; 2: F(2, 117) = 6.397, p
                                                                                                        = .002; 3: F(2,117) = 5.822, p = .004); post hoc showed a
                                    RH                A-model         L-model
                                                                                                        stronger LH (HSF) lateralization in AA-Bs than LA-Bs (1:
       Hemispheric Lateralization
                                    25%     *** ***                                                     t(78) = -2.980, p = .004; 2: t(78) = -3.574, p = .001; 3: t(78)
                                                        *** *** *** ***
                                    20%                                    ** *** ** ***                = -2.070, p = .042). AA-Bs also showed a stronger LH (HSF)
                                                                                         *** ***
                                    15%                                                                 lateralization than A-Ms in comparison 2 and 3 (2: t(78) =
                                                                                                        -2.620, p = .011; 3: t(78) = -3.531, p = .001).
                                    10%
                                    5%
                                                                                                                      Discussion & Conclusion
                                    0%
                                                                                                        In this study, we examined how hemispheric asymmetry in
                                    LH    16 18 20 22 24 26 28 30 32 34 36 38 40                        visual tasks can be modulated by language experience.
                                                            Vocabulary Size
                                                                                                        Previous studies found that compared with monolinguals,
      Figure 3: Results from computational modeling:                                                    bilinguals have a reduced hemispheric lateralization in RH
      hemispheric lateralization in alphabetic (A-model) and                                            dominant visual tasks such as face perception, but not in LH
      logographic reading (L-model). (* p < .05; ** p < .01;                                            dominant visual tasks such as word naming or word
      *** p < .001).                                                                                    matching. However, we suspected that the lateralization
                                                                                                        difference between the two groups in the LH visual tasks did
Model Comparison In performing alphabetic reading, the                                                  not emerge because the performance level between the two
behavior of the LA-model was more similar to logographic                                                groups was not matched.
reading in the L-model than alphabetic reading in the                                                      Therefore, in the behavioral study, we used a perceptual
A-model; the LA-model showed a significantly weaker LH                                                  threshold match in an English word sequential matching task
(HSF) lateralization than A-model (p < .01, except for                                                  and investigated lateralization difference among three groups
vocabulary size of 16), but no significant differences from                                             of people with different language experiences: A-Ms, AA-Bs,
the L-model.                                                                                            and LA-Bs. We found a stronger LH lateralization in AA-Bs
                                                                                                        over both LA-Bs and A-Ms. We hypothesized that this effect
                                    RH                A-M       AA-B            LA-B                    may be due to at least two factors: (1) vocabulary size: in the
                                                   **             *       ***                           study the languages acquired by A-Ms and AA-Bs used a
  Hemispheric Lateralization
                                                                                       ***       *
                                    20%                                                                 similar alphabet, but AA-Bs learned more words overall than
                                    15%                                                                 A-Ms; and (2) the application of GPC rules in alphabetic
                                                                                                        reading but not in logographic reading: alphabetic reading
                                    10%
                                                                                                        required decomposing a word into letters in order to map
                                    5%                                                                  them to phonemes, and thus involved more LH (HSF)
                                    0%                                                                  processing.
                                    LH         1                      2                      3             To verify our hypothesis, we applied the hemispheric
                                                            Comparison                                  processing model (Hsiao et al., 2008) on visual word
      Figure 4: Results from computational modeling:                                                    recognition; the model implements the DFF theory (Ivry &
      hemispheric lateralization in alphabetic reading. (* p                                            Robertson, 1998) and does not assume any influence from
      < .05; ** p < .01; *** p < .001). Error bars show one                                             the LH-lateralized language processing. The modeling data
      standard error.                                                                                   fit well with the behavioral data, explaining the above two
                                                                                                        factors: (1) vocabulary size: when the vocabulary size
                                                                                                        increases, the words in the lexicon look more similar to each
  2                                                                                                     other, thus more HSF information is required to distinguish
    Note that the RH lateralization of the model, in contrast to the
LH in the human data, was because the stimuli used (3-letter words)                                     words; (2) the application of GPC rules in alphabetic
were simpler and the vocabulary sizes used were much smaller                                            reading but not in logographic reading: since half of the
than the English lexicon (see Cheung & Hsiao, 2010). Here we                                            words in LA-Bs’ lexicon involve logographic mapping and
examined relative changes in lateralization between different                                           thus do not require the application of GPC rules, compared
models rather than the absolute lateralization.
                                                                                                     3413

with AA-Bs, LA-Bs’ behavioral might be influenced by              Gauthier, I., Skudlarski, P., Gore, J. C., & Anderson, A. W.
their logographic mapping experience and thus exhibited             (2000). Expertise for cars and birds recruits brain areas
less LH (HSF) lateralization even in alphabetic reading.            involved in face recognition. Nat. neurosci., 3(2), 191-197.
   Thus, our results showed that differences in hemispheric       Hartmann, W. M. (Ed.). (2004). Signals, sound and sensation
lateralization between bilinguals and monolinguals can also         (5th ed.). NY: American Institute of Physics.
be observed in LH dominant visual tasks; in addition, this        Hausmann, M., Durmusoglu, G., Yazgan, Y., & Gunturkun,
effect can further be modulated by different bilingual              O. (2004). Evidence for reduced hemispheric asymmetries
experiences. This result suggests that our expertise domains        in non-verbal functions in bilinguals. Journal of
(e.g. expertise in different languages) can influence each          Neurolinguistics, 17, 285-299.
other, and is consistent with recent research on perceptual       Hsiao, J. H.-w., & Cottrell, G. W. (2009). Not all visual
expertise, showing that similar brain areas are recruited for       expertise is holistic, but it may be leftist: The case of
different expertise domains, and thus these domains may             Chinese character recognition. Psychological Science,
influence each other (e.g. Gauthier, et al., 2000).                 20(4), 455-463.
   In addition to the two factors we examined in the              Hsiao, J. H.-w., Shieh, D. X., & Cottrell, G. W. (2008).
modeling, there are some other factors that may also                Convergence of the visual field split: Hemispheric
account for the observed difference among the three                 modeling of face and object recognition. Journal of
language groups, such as the difference in word/character           Cognitive Neuroscience, 20(12), 2298-2307.
features between different languages, as well as the age of       Ivry, R. B., & Robertson, L. C. (1998). The Two Sides of
acquisition of the second language in the bilinguals; thus,         Perception. Cambridge: MIT Press.
further investigations are required to examine these factors.     Kanwisher, N., McDermott, J., & Chun, M. M. (1997). The
   In summary, here we show that hemispheric asymmetry              fusiform face area: a module in human extrastriate cortex
in English word sequential matching can be modulated by             specialized for face perception. Journal of Neuroscience,
bilingual language experience, and our modeling data                17(11), 4302-4311.
suggested that at least two factors may account for this          Lades, M., Vorbruggen, J. C., Buhmann, J., Lange, J.,
effect: (1) larger vocabulary size in bilinguals, and (2) the       Malsburg, C. v. d., Wurtz, R. P., & Konen, W. (1993).
difference in word to sound mapping between alphabetic              Distortion Invariant Object Recognition in the Dhynamic
and logographic languages.                                          Link Architecture. IEEE T. Comput., 42(3), 300-311.
                                                                  Maurer, U., & McCandliss, B. D. (2007). The development
                    Acknowledgments                                 of visual expertise for words: The contribution of
We are grateful to the HKU Seed Funding Program for                 eletrophysiology. In E. L. Grigorenko & A. Naples (Eds.),
Basic Research (project #10400471 to J.H. Hsiao) and the            Single-word reading: Cognitive, behavioral and biological
Research Grant Council of Hong Kong (project code: HKU              perspectives (pp. 43-64). NJ: Erlbaum.
744509H and 745210H to J. H. Hsiao).                              McCandliss, B. D., Cohen, L., & Dehaene, S. (2003). The
                                                                    visual word form area: expertise for reading in the fusiform
                                                                    gyrus. Trends Cogn. Sci., 7(7), 293-299.
                          References                              Nicholls, M. E. R., Wood, A. G., & Hayes, L. (2001).
Brady, N., Campbell, M., & Flaherty, M. (2005). Perceptual          Cerebral asymmetries in the level of attention required for
   asymmetries are preserved in memory for highly familiar          word recognition. Laterality, 6(2), 97-110.
   faces of self and friend. Brain and Cognition, 58, 334-342.    Oldfield, R. C. (1971). The assessment and analysis of
Bryden, M. P., & Rainey, C. A. (1963). Left-right differences       handedness: The Edinburgh inventory. Neuropsychologia,
   in tachistoscopic recognition. Journal of Experimental           9(1), 97-113.
   Psychology, 66, 568-571.                                       Sanger, T. D. (1989). An optimality principle for
Brysbaert, M., & New, B. (2009). Moving beyond Kučera               unsupervised learning. In D. Touretzky (Ed.), Adv. Neur.
   and Francis: A critical evaluation of current word               In. (Vol. 1). San Mateo: Morgan Kaufmann.
   frequency norms and the introduction of a new and              Sewell, D. F., & Panou, L. (1983). Visual field asymmetries
   improved word frequency measure for American English.            for verbal and dot localization tasks in monolingual and
   Behavior Research Methods, 41(4), 977-990.                       bilingual subjects. Brain and Language, 18, 28-34.
Cheung, K. C. F., & Hsiao, J. H.-w. (2010). Visual and Task       Tan, L. H., Liu, H.-L., Perfetti, C. A., Spinks, J. A., Fox, P. T.,
   characteristics may explain hemispheric asymmetry in             & Gao, J.-H. (2001). The neural system underlying
   visual word recognition. Proc. of the 32rd Annual Meeting        Chinese logograph reading. NeuroImage, 13, 836-846.
   of the Cognitive Science Society, Portland.                    Tan, L. H., Spinks, J. A., Gao, J.-H., Liu, H.-L., Perfetti, C.
Corina, D. P., Vaid, J., & Bellugi, U. (1992). The linguistic       A., Xiong, J., et al. (2000). Brain activation in the
   basis of left hemisphere specialization. Science, 255,           processing of Chinese characters and words: a functional
   1258-1260.                                                       MRI study. Human Brain Mapping, 10, 16-27.
Daugman, J. G. (1986). uncertainty relation for resolution in     Tzeng, O. J. L., Hung, D. L., Cotton, B., & Wang, W. S.-Y.
   space, spatial frequency, and orientation optimized by           (1979). Visual lateralisation effect in reading Chinese
   two-dimensional visual cortical filters. Journal of Optical      characters. Nature, 282, 499-501.
   Society of America A, 2(7), 1160-1169.
                                                              3414

