UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visual attention during spatial language comprehension: Reference alone isn’t enough
Permalink
https://escholarship.org/uc/item/9vw9g576
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Burigo, Michele
Knowferle, Pia
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                         Visual attention during spatial language comprehension:
                                     Is a referential linking hypothesis enough?
                                        Michele Burigo (mburigo@cit-ec.uni-bielefeld.de)
                             Cognitive Interaction Technology Excellence Center, University of Bielefeld,
                                                         33615, Bielefeld, Germany
                                         Pia Knoeferle (knoeferl@cit-ec.uni-bielefeld.de)
                             Cognitive Interaction Technology Excellence Center, University of Bielefeld,
                                                         33615, Bielefeld, Germany
                               Abstract                                 to the ‘located object’, i.e., the object the location of which
   When people listen to sentences referring to objects and
                                                                        is described (see Fig. 1; see Carlson-Radvansky & Irwin,
   events in visual context, their visual attention to objects is       1994; Carlson & Logan, 2005; Carlson, Regier, Lopez &
   closely time-locked to words in the unfolding utterance. How         Corrigan, 2006; Regier & Carlson, 2001). This prediction is
   precisely people deploy attention during situated language           derived from the Attention Vector Sum model (Carlson,
   understanding and in verifying (spatial) utterances is,              Regier, Lopez & Corrigan, 2006; Regier & Carlson, 2001).
   however, unclear. A ‘visual world’ hypothesis suggests that          Consider a description of spatial relations such as “The plant
   we look at what is mentioned (Tanenhaus et al., 1995) and            is above the clock” (Fig. 1). The plant is the located object
   anticipate likely referents based on linguistic cues (Altmann
   & Kamide, 1999). In spatial language research, in contrast,          and the clock is the reference object. In order to comprehend
   the Attention Vector Sum model (Regier & Carlson, 2001)              such spatial descriptions people must, according to the
   predicts that in order to process a sentence such as “The plant      model; (1) index the objects mentioned in the sentence
   is above the clock”, attention must shift from the clock to the      (spatial indexing); (2) assign a direction to the space
   plant (i.e., in reverse relative to order of mention). An eye-       (selecting a reference frame); and (3) construct a spatial
   tracking study examined whether gaze pattern during                  template (defining the regions of space in which the located
   comprehension of spatial descriptions support the visual
                                                                        object is in a good, acceptable or bad location with respect
   world or the Attention Vector Sum account. Analyses of eye
   movements indicate that we need both accounts to                     to the reference object).
   accommodate the findings.
   Keywords: spatial language; eye            movements;    visual
   attention; referential language process.
                           Introduction
In interacting with the visual environment we must achieve
a variety of navigation tasks such as getting from one place
to the next or finding the comb in the bathroom where you
can see it lying on the shelf above the sink. Navigating in
the world and interacting with people also involves
understanding instructions such as “Keep straight until you
reach the intersection. Then turn left. When you see a big
red banner above a blue door, turn left again.”
   An important part of language understanding thus                          Figure 1: “The plant is above the clock”. The 5x6 grid
concerns relating what has been dubbed ‘spatial language’                                was invisible to participants.
(e.g., “A big red banner above a blue door”) to spatial
arrangements of objects in the world (the big red banner                   According to the model, people focus their attention on
being above the blue door). It is well established that this            that point of the reference object that is closest to the located
process requires attentional mechanisms (Carlson & Logan,               object. Then a population of vectors (whose length is
2005; Logan, 1994) but the specifics of how people deploy               weighted by the amount of attention deployed on the
visual attention in real time, during comprehension of                  reference object) is computed in order to generate a final
sentences about spatial relations, are still unclear.                   vector (the sum of the vectors in the population). The final
                                                                        vector indicates the averaged direction from the reference to
The Attention Vector Sum Model & its Predictions                        the located object. Its direction is compared to the direction
   One possibility is that understanding sentences about                indicated by the respective spatial term (e.g., for ‘above’ the
spatial relations between objects requires a shift of attention         direction is vertical) in order to evaluate the goodness of fit
from a point of reference (often dubbed ‘reference object’)
                                                                    919

of the spatial preposition with respect to the actual               Once people have understood the preposition above, they
arrangement of the reference and located object.                    should shift their gaze from the plant (the located object) to
   The steps of the Attention Vector Sum model are                  the clock (the reference object). Unlike the account derived
motivated by insights from studies with rhesus monkeys.             from the Attention Vector Sum model, the account based on
When a monkey made an arm movement, orientation-tuned               data from visual world studies does not predict people
neurons (with a preferred direction) fired to the extent that       inspect the reference object (the clock) and from there shift
the direction of the monkey’s arm movement aligned with             attention to the located object (the plant).
their direction of orientation. The sum of the directions of           The present paper examines the time course of spatial
this orientation-tuned population of neurons was a good             language processing in visual context, and asks whether the
predictor of the direction of motor action (Georgopoulus,           observed gaze pattern resemble those predicted by the
Schwartz, & Kettner, 1986; see Lee, Rohrer & Sparks, 1988           Attention Vector Sum model or by the linking hypotheses
for related research on saccades).                                  from visual world studies and associated models. To this
   While the Attention Vector Sum model is informed by              end we recorded eye movements while people listened to
these findings (Georgopolus et al., 1986; Lee et al., 1988),        spoken sentences about spatial relations between objects
the direction predicted by the vector population does not           (‘above’ vs. ‘below’) and verified whether the sentence
itself have any explicit motor-goal component. However,             matched (vs. didn’t match) the picture (Fig. 2).
the resulting vector direction can be viewed as predicting
the direction of a motor response (e.g., a reaching
movement or a saccade depending on the task). In a recent
study Coventry, Lynott, Cangelosi, Monrouxe, Joyce, &
Richardson (2010) do just that, and conclude from the
Attention Vector Sum model that “most of the early stages
of attention are given to the RO in the spatial array, and that
attention is then directed to the LO, driven by the conceptual
relation specified by the preposition” (p. 203, RO refers to
‘reference object’; LO refers to ‘located object’).
Accordingly, given the spatial description “The plant is
above the clock” (Fig. 1), visual attention is first deployed
to the reference object (the clock) and then to the located
object (the plant). However the AVS model does not specify
when in time the attention shift takes place. It simply states
that in order to apprehend a spatial relation an attentional
shift from the RO to the LO is obligatory.                                Figure 2: Here illustrated the experimental design: 2
                                                                             (match vs. mismatch) x 2 (above vs. below).
Predictions by Models of Situated Comprehension
   In contrast, an account which makes predictions about the        If we replicate prior findings, we should see longer response
time course with which people relate utterances to non-             latencies for mismatching than matching trials (e.g., Clark &
linguistic visual context comes from ‘visual world’ studies         Chase, 1972), and we may see longer latencies for ‘below’
that monitor a listener’s visual attention in scenes during         than ‘above’ trials (Seymour, 1973; Chase & Clark, 1971).
spoken language comprehension (e.g., Altmann, 1999;                 Gaze pattern can permit us to tease apart the two accounts
Chambers, Tanenhaus, Eberhard, Filip, & Carlson, 2002;              (Attention Vector Sum vs. visual world). We will analyze
Knoeferle & Crocker, 2006; Spivey, Tanenhaus, Eberhard,             fixation proportions across the sentence to the reference and
& Sedivy, 2001; Tanenhaus et al., 1995), and from related           located objects. Recall that based on the visual world
computational models (e.g., Mayberry, Crocker, &                    account, people should begin to anticipate the reference
Knoeferle, 2009). The findings from these studies and               object shortly after hearing the spatial preposition. Looks to
associated model simulations suggest that people                    the reference object should continue throughout its mention
incrementally inspect objects and characters, as they are           following the visual-world linking hypothesis but not
mentioned. Imagine people see a picture showing a princess          following the Attention Vector Sum model predictions.
a pirate and a fencer; upon hearing “the princess”, people             Analyses of visual world data mostly report fixation (e.g.,
mostly inspect the princess. People can further anticipate          Allopenna, Magnuson, & Tanenhaus, 1998) or inspection1
relevant objects and characters based on linguistic cues; for       (Knoeferle, Crocker, Scheepers, & Pickering, 2005)
example, when they hear “Put the whistle into”, they begin          proportions for a given time window. It’s possible that this
to inspect containers more often than non-container objects         relatively coarse grained measure of attention doesn’t fully
before their mention (Chambers et al., 2002).                       capture how people deploy attention and there are many
   Applying these insights to the comprehension of
sentences such as “The plant is above the clock” (Fig. 1)
                                                                       1
predicts people should inspect the plant as it is mentioned.             By ‘inspection’ we mean consecutive fixations to an interest
                                                                    area before looking to another interest area.
                                                                920

other useful gaze measures in visual world studies that have          resized in a 300 x 300 pixel format on a white background.
not yet been considered. To get a better insight into how             Critical sentences were in German and had the following
visual attention is deployed following the spatial                    format: “The [located object] is [spatial preposition] the
preposition, we complement analyses of fixation                       [reference object]”, where the spatial prepositions could be
proportions in a time window with analyses of the first three         über (‘above’) or unter (‘under’).
(a) fixations and (b) inspections following the offset of the            Of the 60 filler sentences, 16 referred to a reference object
spatial preposition and after people have fixated the                 that was not in the picture (e.g., “The plant is below the
reference object once. If the Attention Vector Sum account            cup” with Fig. 1; 1/5 of 92 trials). This discourages people
is correct, then attention must shift from the reference object       from deciding whether the located objects is placed in the
to the located object following the spatial preposition. Thus         correct location on the basis of its absolute location (or in
we should see that immediately after looking at the                   reference to the computer monitor), and helps to avoid
reference object, people look at the located object next.             anticipated answers and no fixations to the reference object
                                                                      (Logan and Compton, 1996; Carlson, West, Taylor and
                          Experiment                                  Herndon, 2002). The others fillers included different
                                                                      sentence structures and other spatial prepositions such as
Method                                                                zwischen (‘between’), nahe bei (‘near’), um herum
Participants Thirty-two students (average age = 23, range             (‘around’).
= 19-33) from the University of Bielefeld received five euro             The design included 2 factors with 2 levels: spatial
each for taking part in this study. All participants had              preposition (über vs. unter) and sentence value (match
normal or corrected-to-normal vision and all were native              condition: objects displayed according to the spatial
speakers of German and monolingual before age 6.                      description; mismatch condition: objects not displayed
                                                                      according to the spatial description). Item-condition
                                                                      combinations were assigned to the experimental lists
Materials and Design The experiment includes 32 critical
                                                                      following a Latin square. Each participant saw one version
trials and 60 fillers totaling 92 trials. Each scene included
                                                                      of an item, and the same number of trials for each condition.
three objects: the located object (the bottle, Fig. 2), the
reference object (the chips) and a competitor object (the
                                                                      Procedure An SMI Eye-link tracker (1000 / 2K), with a
hamburger). The located object and the reference object
                                                                      desktop mount, recorded participants` eye movements at a
were the objects mentioned in the sentence while the
                                                                      frequency of 1000 Hz. Participant were seated at
competitor object was the third object not mentioned in the
                                                                      approximately 65 cm from the screen with their chin on a
sentence. The competitor was included since showing only
                                                                      chin rest. The experiment was presented on a 22-inch color
two objects would permit participants to launch anticipatory
                                                                      monitor at a resolution of 1680x1050 pixels.
saccades to the reference object before the onset of the
                                                                         Participants were asked to try to understand the sentences
spatial term (i.e., since it would be the only other object).
                                                                      and to attentively inspect the image, and to respond per
   The three objects were always vertically aligned. Object
                                                                      button press at the end of the sentence as quickly and
locations were based on a 5 x 6 virtual grid (numbered from
                                                                      accurately as possible whether the sentence matched (vs.
1 to 30 starting from the top left square; see Fig. 1). In order
                                                                      didn’t match) the picture. Before the experiment participants
to discourage people from using the screen boundaries as
                                                                      read the instructions and nine practice trials familiarized
landmarks for utterance comprehension, objects were never
                                                                      them with the procedure. At the beginning of the experiment
shown in the top- and bottom-most rows (squares 1 to 5 &
                                                                      a calibration procedure was performed and a re-calibration
26 to 30, Fig. 1). Note that participants never saw the grid
                                                                      was carried out after half (46) of the 92 trials. Participants
outlined in Figure 1.
                                                                      fixated a circle in the middle of the screen before each trial,
   Given that functional relations between the objects can
                                                                      permitting the eye tracker to perform a drift correction if
influence the processing of spatial descriptions (Coventry et
                                                                      necessary. Then a fixation point appeared in the middle of
al., 2010), we asked participants (N=17) to rate the
                                                                      screen for 1500 ms, after which the picture and the sentence
probability that two objects in a pair (N=350 pairs) can
                                                                      were presented. Given the illusionary delay people
interact (1 = low probability to 7 = very high probability).
                                                                      experience at scene onset (Dahan, Magnuson & Tanenhaus,
The object names in all of the pairs were controlled for the
                                                                      2001), a 750 ms preview was used. An ISI of 2500 ms
number of syllables, article gender, and frequency. A violin
                                                                      ended the trial. Calibration took approximately 5 minutes,
and a violin bow, for instance, would often interact, and
                                                                      and the experiment lasted around 30 minutes.
receive a high rating (e.g., 6 or 7). In contrast, a violin and a
window rarely interact and would receive a low rating (e.g.,
                                                                      Analysis Response times (RTs) in the verification task were
1 or 2). Pairs of objects with a rating above 3 (N=24) were
                                                                      log-transformed before statistical analysis. RTs were
excluded from the experiment. From the remaining items,
                                                                      analyzed by a Linear Mixed Effects Regression (LMER)
we created 32 triplets based on low average functionality
                                                                      analysis integrated in R, including items and participants as
rating for pairs (e.g., a window and a violin; a window and a
                                                                      random factors simultaneously (Baayen, 2008), and the
flower were used to create a triplet with a window, a violin
                                                                      factors spatial preposition and sentence value.
and a flower). The objects were pictures of real objects
                                                                  921

   We analyzed eye movement data from the thirty-two                second noun phrase (NP2). However, fixation proportions to
critical trials. For the present paper, we collapsed across         the located object stay high (relative to the competitor) until
spatial preposition in these analyses since that factor is not      the time of the response. Hierarchical log-linear analyses
informative for our research question (contrasting the              confirmed that people fixated more on the located than the
Attention Vector Sum and visual world accounts)2. We                reference object within NP1 (by subjects and by items ps <
excluded data from mismatching trials (included to have a           .0001) and the Verb (ps < .0001) time windows. For the
clear task), since neither account makes a prediction about         Spatial Preposition (ps < .0001) and the NP2 (ps < .0001)
how mismatching visual context affects comprehension.               time windows they fixated more on the reference than the
   The presentation software (Experiment Builder) recorded          located object. However, for NP1 (ps < .0001), the Spatial
the coordinates of participants’ eye movements during the           Preposition (ps < .05), the Verb (by subjects p < .05), and
experiment. We removed trials with incorrect responses or           the NP2 window (ps < .0001), fixation differences to the
with responses prior to sentence offset. For analyses, we           located vs. reference object interacted with subject,
divided visual scenes in 4 Areas of Interest (AoIs): one for        indicating variability between subjects.
each object plus the background. Regions for the object had
the same size as the original picture, 300 x 300 pixels and            Table 1: Percentage of fixations towards the 4 Areas of
were coded as located object, reference object, and                              Interest for each critical time region.
competitor. We coded five time windows for each sentence:                                                      Located   Reference
‘NP1’ (Mduration = 1078), ‘Verb’ (Mduration = 378), ‘Spatial                    Background      Competitor
                                                                                                                Object    Object
Preposition’ (Mduration = 606), ‘NP2’ (Mduration = 1039),              NP1          4.1           22.7          52.8       20.4
‘Response’ (Mduration = 427). Fixations starting before and            Verb         7.5           23.6          48.9        20
ending within a time window were removed prior to further              SP           6.8           14.7          34.1       44.4
analysis as were fixations below 80 ms.                                NP2          5.7            8.4          32.2       53.7
   For each time window we calculated the percentage of                Resp        10.6           17.1           38        34.4
fixations in the four AoIs. The fixation data was analyzed
using hierarchical log-linear models that included the              The second set of analyses focused on the time window
frequency of inspections to target characters (the reference        between Spatial Preposition offset and Response offset.
object vs. the located object) and either subjects or items         Within this region we selected fixations that took place after
(Howell, 2001). A second analysis was “conditional”, in             people had inspected the reference object once. This was
that it analyzed the fixation and inspection distribution to        done to establish whether people, during comprehension of
the located versus reference object after the offset of the         the spatial preposition, and after having looked at the
spatial preposition and after people had fixated the reference      reference object, looked next at the located object. The
object once.                                                        results indicate a substantial proportion of fixations are
                                                                    directed to the reference objects on the First Fixation and
Results                                                             Second Fixation (Fig. 3) but also a small percentage of
We first present results from the analysis of the verification      fixations are also directed to the located object. The analysis
response latencies, and subsequently the results from the           confirmed that people fixated the reference object more
eye-movement analyses. For the RT analyses, the spatial             often than the located object for their First Fixation (ps <
preposition term, the sentence value term, and their                .0001) and Second Fixation (ps < .0001) after having fixated
interaction all contributed reliably to the linear mixed            the reference object following preposition offset.
effects model (log likelihood ratio test; p < .001) relative to        Further analyses examined whether the tendency to
a baseline model with just the intercept. Significance values       allocate some attention to the located object once the
were calculated according to the Markov chain Monte Carlo           reference object has been fixated, emerges also in the
sampling procedure. Trials for which the sentence matched           overall distribution of fixations across the four areas of
the picture had faster responses (M = 5500 ms) than                 interest (see Fig. 4). As one can observe, participants look
mismatches (M = 5667 ms), and spatial relations had faster          more at the reference object starting around preposition
responses with über (‘above’, M = 5568 ms) than with unter          offset, and fixate the reference object more than any other
(‘below’, M = 5598 ms), corroborating our expectations.             object until NP2 offset. However in this time region people
                                                                    also look (ca. 30 percent) to the located object during NP2.
Eye-movement results As they hear the first noun and                While it might be tempting to conclude that these fixations
continuing into the verb, people mostly look at the named           to the located object represent a “continued” interest in that
located object (Table 1). When encountering the                     object (since it was mentioned earlier in the sentence), recall
preposition, they begin to shift their attention to the             that we examined fixations after preposition offset and after
reference object and continue to do so throughout the               people had then fixated the reference object (Fig. 3). In
                                                                    order to establish whether the number of fixations towards
                                                                    the located object after the first fixation on the reference
   2
     We included that factor to ensure spatial prepositions do      object (within the preposition-offset to NP2 offset interval)
differentially modulate visual attention, and to counterbalance     differs significantly from the looks to the competitor, we
visual factors.
                                                                922

compared them with the number of fixations to the
competitor object. The log-linear analysis revealed a                                 80.0	  
                                                                                                                                           Background	  
significant difference between the number of fixations
                                                                                      60.0	                                               Competitor	  
towards the located object and those to the competitor (ps <
.0001). Thus, people fixate the located object more than the                                                                               Located	  Object	  
                                                                                      40.0	  
competitor during the NP2. However, the interaction of                                                                                     Reference	  Object	  
fixations to the located vs. competitor objects with subjects                         20.0	  
was also significant (p < .0001), suggesting again variation
between subjects.                                                                       0.0	  
                                                                                                FirstInsp	   SecondInsp	   ThirdInsp	  
    80.0	                                            Background	  
    60.0	                                            Competitor	                   Figure 5: First, second and third inspection after exploring
                                                      Located	  Object	          the reference object within in the critical time window from
    40.0	                                            Reference	  Object	              Spatial Preposition offset until the response time.
    20.0	  
                                                                                                        General Discussion
      0.0	                                                                       We assessed how people deploy visual attention as they
              FirstFix	   SecondFix	   ThirdFix	                               listen to spatial descriptions and verify them against a
                                                                                  picture. To this end we recorded people’s eye movements
 Figure 3: First, second and third fixation after exploring the                   while they listened to sentences such as “The bottle is above
   reference object within in the critical time window from                       the chips” and inspected corresponding clipart pictures (Fig.
 Spatial Preposition offset until the response time. Note that                    2). We analyzed proportions of fixations to the bottle and
     the pattern for FirstFix and SecondFix do not change                         the chips across the sentence, as well as the first three
  substantially when we examine later time windows (e.g.,                         fixations and the first three inspections after people had
  200, 350 or 500 ms after offset of the spatial preposition).                    heard the spatial term (e.g., über ‘above’), and had fixated
                                                                                  the chips. The results show that when people have heard the
                                                                                  spatial preposition, they begin to launch anticipatory eye
                                                                                  movements toward the reference object (chip) before it is
                                                                                  mentioned. Then, when the reference object (chip) is named,
                                                                                  fixations to it increase until the offset of the second noun
                                                                                  phrase. This gaze pattern replicates existing findings, and
                                                                                  corroborates mechanisms of establishing reference to
                                                                                  objects and of anticipating likely referents in a closely time-
                                                                                  locked manner with utterance comprehension.
                                                                                     Analyses of the first three fixations after the offset of the
                                                                                  spatial preposition, and after a fixation to the reference
                                                                                  object, showed that people fixate the reference object more
   Figure 4: Proportion of fixation toward each AoI over the                      often (about 70 percent) than the located object (Fig. 3).
                       course of the utterance.                                   This fixation pattern indicates that people establish
                                                                                  reference between the spoken sentence and the scene,
   Some visual world studies have analyzed fixation data,                         corroborating the visual world account. The fixation pattern
while others have relied upon inspection analyses. To get a                       does not contradict the AVS model, however, since the
more detailed picture of how visual attention was deployed,                       model does not specify when after processing the spatial
we thus complemented the analyses of fixation data with                           preposition the shift from the reference to the located object
analyses of inspections as the dependent measure                                  should occur.
(consecutive fixations within the same AoI were counted as                           Indeed, analyses of inspections suggest that people fixate
one inspection). The results (see Fig. 5) tell a different story                  the located object after inspecting the reference object and
from the fixation analyses. People look substantially more                        before deciding whether the description matches the scene.
often to the located object than the reference object during                      The distribution of fixations during the second noun phrase
the First Inspection after inspecting the reference object.                       confirms this view (30 percent of fixations are directed at
Hierarchical log linear analysis confirmed that for the First                     the located object vs. 10 % for the competitor, Fig. 4). These
Inspection (ps < .0001), Second Inspection (ps < .05) and                         analyses support the Attention Vector Sum account and
Third Inspection (ps < .05) people inspected the located                          provide evidence against the visual world account.
object reliably more often than the reference object.                                In sum, while the conditional inspection analyses
                                                                                  corroborate the AVS model predictions, the current
                                                                              923

specification of the model cannot account for the observed          Carlson, L. A., West, R., Taylor, H. A., & Herndon, R.
referential and anticipatory gaze behavior since it lacks any         (2002). Neural correlates of spatial term use. JEP: HPP,
incremental processing mechanism (see Carlson et al., 2006,           28(6), 1391-1408.
for a first extension towards including functional relations        Chambers, C. G., Tanenhaus, M. K., Eberhard, K. M., Filip,
between objects in the scene). The visual-world linking               H., & Carlson, G. N. (2002). Circumscribing referential
hypothesis between eye fixations and language                         domains during real-time language comprehension. JML,
comprehension, in contrast, doesn’t account for the                   47(1), 30-49.
observed inspection of the located object after inspecting the      Chase, W.G. & Clark, H. H. (1971). Semantics in the
reference object during the second noun phrase (Fig. 5).              perception of verticality. British Journal of Psychology,
   It is possible that the task (sentence-picture verification)       62(3), 311-326.
plays a role in how visual attention was deployed during            Clark, H. H. & Chase, W. G. (1972). On the process of
sentence comprehension in the present study. Deciding                 comparing sentences against pictures. Cognitive
whether a sentence matches a picture may lead to a different          Psychology, 3, 472–517.
fixation behavior in relation to language comprehension,            Coventry, K. R., Lynott, D., Cangelosi, A., Monrouxe, L.,
and require different linking hypotheses than act-out or              Joyce, D., & Richardson, D. C. (2010). Spatial language,
passive listening tasks. Future research will examine                 visual attention, and perceptual simulation. Brain &
whether the observed eye-movement pattern replicate in a              Language, 112(3), 202-213.
task for which existing studies have reported visual attention      Dahan, D., Magnuson, J.S., & Tanenhaus, M.K. (2001).
effects closely time-locked to comprehension processes                Time Course of Frequency Effects in Spoken-Word
(e.g., passive listening comprehension). At any rate, the             Recognition: Evidence from Eye Movements. Cognitive
reported findings suggest that a simple referential linking           Psychology, 42, 317-367.
hypothesis alone cannot account for how visual attention is         Georgopoulos, A., Schwartz, A., & Kettner, R. (1986).
deployed when understanding and verifying spatial                     Neuronal population coding of movement direction.
language.                                                             Science, 233, 1416-1419.
                                                                    Knoeferle, P., Crocker, M. W., Scheepers, C., & Pickering,
                    Acknowledgments                                   M. (2005). The influence of the immediate visual context
This research was supported by the Excellence Center 277              on incremental thematic role-assignment: evidence from
Cognitive Interaction Technology (DFG). We thank the                  eye movements in depicted events. Cognition, 95, 95-127.
members of the Language & Cognition Group at Bielefeld              Knoeferle, P. & Crocker, M.W. (2006). The coordinated
University for their comments, as well as Eva Mende and               interplay of scene, utterance, and world knowledge:
Linda Krull for their help with stimulus preparation.                 evidence from eye tracking. Cognitive Science, 30, 481-
                                                                      529.
                                                                    Lee, C.K., Rohrer, W.H., & Sparks, D.L. (1988). Population
                         References                                   coding of saccadic eye-movements by neurons in the
Allopenna, P. D., Magnuson, J. S., & Tanenhaus, M. K.                 superior colliculus. Nature, 332, 357–360.
   (1998). Tracking the time course of spoken word                  Logan, G. & Compton, B. (1996). Distance and distraction
   recognition using eye movements: evidence for                      effects in the apprehension of spatial relations. JEP: HPP,
   continuous mapping models. JML, 38 (4), 419-439.                   22, 159-172
Altmann, G. T. & Kamide, Y. (1999). Incremental                     Logan, G. (1994). Spatial attention and the apprehension of
   interpretation at verbs: restricting the domain of                 spatial relations. JEP: HPP, 1015-1036.
   subsequent reference. Cognition, 73, 247-264.                    Mayberry, M. R., Crocker, M. W. & Knoeferle, P. (2009).
Altmann, G. T. M. (1999). Thematic role assignment in                 Learning to attend: a connectionist model of situated
   context. JML, 41, 124–145.                                         language comprehension. Cognitive Science, 33, 449–
Baayen, R. H. (2008). Analyzing Linguistic Data. New                  496.
   York, NY, US: Cambridge University Press.                        Regier, T. & Carlson, L. (2001). Grounding spatial language
Carlson, L. A. & Logan, G. D. (2005). Attention and spatial           in perception: an empirical and computational
   language. In L. Itti, G. Rees, & J. Tsotsos (Eds.),                investigation. JEP: General, 130, 273-298.
   Neurobiology of attention (pp. 330-336). San Diego, CA:          Seymour, P. (1973). Stroop interference in naming and
   Elsevier.                                                          verifying spatial locations. Perception & Psychophysics,
Carlson-Radvansky, L. A. & Irwin, D. E. (1994). Reference             14, 95-100.
   frame activation during spatial term assignment. JML, 33,        Spivey, M. J., Tyler, M. J., Eberhard, K. M., & Tanenhaus,
   646-671.                                                           M. K. (2001). Linguistically mediated visual search.
Carlson, L.A., Regier, T., Lopez, W., & Corrigan, B.                  Psychological Science, 12(4), 282–286.
   (2006). Attention unites form and function in spatial            Tanenhaus, M.K., Spivey-Knowlton, M.J., Eberhard, K.M.
   language. Spatial Cognition and Computation, 6(4), 295-            & Sedivy, J.E. (1995). Integration of visual and linguistic
   308.                                                               information in spoken language comprehension. Science,
                                                                      268, 1632-1634.
                                                                924

