UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Object Names in Real Time with Little Data
Permalink
https://escholarship.org/uc/item/57s0h9qf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Stevens, Jon
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                         Learning Object Names in Real Time with Little Data
                                          Jon Scott Stevens (jonsteve@ling.upenn.edu)
                                              Department of Linguistics, 255 S. 36th Street
                                                       Philadelphia, PA 19104 USA
                              Abstract                                                         Previous Work
                                                                        Children are able to learn words from context, often taking
   We present an online learning model of early cross-situational       entire sentences as input and breaking that input down to
   word learning which maps words to objects from context with          create word-to-meaning mappings. In addition to this task,
   relatively sparse input. The model operates by rewarding and
   penalizing probabilities of possible word-to-object mappings         which is far from trivial, children must filter out an infi-
   based on real-time observation, and using those probabilities to     nite number of erroneous but logically possible hypotheses
   determine a lexicon. We integrate prosodic and gestural cues         of word meaning, as Quine (1960) famously noticed. The
   and allow the learner to evaluate lexical entries. These en-
   richments allow efficient learning with minimal computational        quantum leap between considering each member of an infi-
   effort, producing results comparable to that of more complex         nite set (an impossible task) and considering each member of
   models.                                                              a finite set, no matter how large, is the basis for the claim
   Keywords: Cross-situational word learning; online learning           that word learning relies fundamentally on innately given hy-
                                                                        pothesis space constraints. The question, then, is not whether
                                                                        learning is constrained, but how it is constrained. We take
                          Introduction                                  computational models to be tests of purported answers to this
                                                                        question. As such, models should reflect the representations
The problem of how children learn the meanings of their first           and, more loosely, the mechanisms present in human learners.
words, a problem for philosophers at least since the time of
Augustine, has become an object of scrutiny in psychology               Experimental Work
and computational cognitive science. On one hand, experi-               We make use of three principles of early word learning that
mental research shows us that young children can use a va-              have emerged from experimental research: (1) mutual exclu-
riety of cues (Bloom, 2000) to learn meanings from context              sivity, (2) the availability of gestural and prosodic cues, and
with only a few exposures (Carey, 1978); on the other hand,             (3) the apparent ability of learners to evaluate hypothesized
computational modeling work underlines the difficulty of the            word meanings against new data.
process, requiring either complex statistical algorithms (Yu               Markman (1992) and others have proposed that word learn-
and Ballard, 2007; Frank, Goodman, and Tenenbaum, 2009)                 ing is guided by a mutual exclusivity assumption, a default as-
or large amounts of data (Fazly, Alishahi, and Stevenson,               sumption that objects have only one name. There is indepen-
2008) to achieve adequate learning. The goal of this paper              dent experimental evidence (Ichinco, Frank, and Saxe, 2009)
is to simplify the computational problem of early word learn-           that suggests that children disprefer many-to-one word-to-
ing by integrating empirically motivated cues into a simple             object mappings, and such a preference improves the perfor-
statistical model that learns object names in real time with            mance of a simple learning model, excluding would-be dis-
speed and precision.                                                    tractors from the semantic hypothesis space when those dis-
   Following Yu and Ballard (2007), we integrate prosodic               tractors already have a name in the learner’s lexicon. Mark-
and gestural cues into a statistical learning algorithm for ob-         man’s view is that mutual exclusivity acts in concert with
ject names (which comprise the bulk of an early child’s vo-             other default assumptions to extract a finite hypothesis space
cabulary in many languages, including English). Unlike other            from Quine’s infamous infinity.
models, we give the learner access to a lexicon that adaptively            Not only must the learner’s hypothesis space be made fi-
changes as new observations are processed. This allows the              nite, but it must interact with the learning mechanism in a
learner to check hypothesized word meanings against new                 way that produces quick results. Since Carey (1978) it has
input and to enforce a preference for one-to-one mappings               been noted that children learn words with impressive speed,
between words and objects. These enrichments have roots                 often after only a few exposures. To achieve this end, we hold
in experimental research and allow us to construct a simple,            that word learning is guided not only by constraints like mu-
effective, and principled online learning model based on re-            tual exclusivity, but also by principles of salience and knowl-
warding and penalizing probabilities (following Yang, 2002)             edge. This view allows the learning algorithm itself to be
associated with semantic hypotheses. We believe that this               quite simple.
foundation of minimal complexity and empirical motivation                  Under our conception of the process, word learning is
produces a more psychologically plausible model.                        guided both by word stress and by gestures, with greater
   Below we briefly outline some recent experimental and                weight being given to semantic hypotheses that map stressed
computational work in this area before presenting the details           words to gesturally indicated objects. Together we call these
of our model and discussing its advantages.                             two cues “salience cues”, reflecting their function of high-
                                                                    903

lighting particularly important words and objects and making         word learning as a process of associating words with sets of
them salient to the learner. Without these crucial components,       multiple co-present objects. The computational model pre-
the data is simply too noisy for a simple learner to navigate.       sented here reflects these developments; we show that it is
But these cues are independently justified. It is well known         helpful for the learner to be able to evaluate the semantic hy-
that babies are attentive to eye gaze and gestures. By nine          potheses contained in their lexicon against new data.
months, they are capable of joint attention (Baldwin, 1991;
Bloom, 2000), even responding to the emotional reactions of          Previous Models
others. In short, humans seem to be programmed to pay atten-         Beginning with Siskind (2000), computational modeling has
tion to the actions of other humans from an early age. Thus,         been a valuable tool for investigating the early word learn-
a gesture can serve as an “attentional magnet” for a young           ing process. Various approaches have been taken, including
word learner.                                                        Bayesian (Niyogi, 2002; Xu and Tenenbaum, 2007; Frank
                                                                     et al., 2009) and machine translation (Yu and Ballard, 2007;
   If gesture serves to draw attention within the visual field,
                                                                     Fazly et al., 2008) approaches.
then patterns of prosodic prominence can be thought of as
                                                                        Yu and Ballard’s (2007) work is particularly interesting for
auditory gesture. Since the prosodic peaks of natural lan-
                                                                     our purposes because it demonstrates the positive effects that
guage have audible acoustic correlates (which are exagger-
                                                                     prosodic and gestural cues can have on model performance.
ated in infant-directed speech), and since babies are known
                                                                     A machine translation algorithm (Brown et al. 1990) serves
to be sensitive to these correlates (Soderstrom, Seidl, Nelson,
                                                                     as a purely statistical core which is expanded by external so-
and Jusczyk, 2003; Thiessen, Hill, and Saffran, 2005), we can
                                                                     cial factors. The authors code corpus data for both prosodic
posit that phonological phenomena such as word stress can be
                                                                     peaks and indication by gesture or eye gaze. The words that
brought to bear on the question of how young learners figure
                                                                     represent peaks on an utterance’s pitch track are given more
out which words in an utterance are meant to refer. Indeed,
                                                                     weight than the other words in the utterance, and objects that
prosodic information has been shown to be a good guide to
                                                                     are judged to be indicated in the visual field are given an anal-
word segmentation (Yang, 2004), an ability that must precede
                                                                     ogous boost. We use a similar coding method, but our model
word learning.
                                                                     differs from that of Yu and Ballard in a crucial way: it oper-
   Finally, recent work suggests that word learning involves         ates in real time. Yu and Ballard’s is a batch learning model,
a form of hypothesis evaluation, whereby learners will guess         which has a complexity disadvantage. Firstly, batch learning
at a word’s meaning and then, as further utterances of that          requires all tokens to be stored in memory, whereas online
word are processed, search the object space for evidence sup-        learning only requires types to be stored. Secondly, a real
porting their guess. Medina,Trueswell, Snedeker, and Gleit-          time implementation of a batch learning model would neces-
man (2009) assess mechanisms of cross-situational learn-             sitate constant recalculation over all observed stimuli; as a re-
ing in adults using the human simulation paradigm (Gillette,         sult, the run time of such an algorithm will increase with the
Gleitman, Gleitman, and Lederer, 1999), a method whereby             square of the number of observed stimuli, a sharper increase
subjects are given video vignettes of naming events with the         than that of an equivalent online model.
audio track removed and a single nonsense word uttered in               One of the most powerful recent models is another batch
place of some real word. Subjects were asked to give their           learning model, the Bayesian model of Frank et al. (2009).
best guesses as to the meaning of the nonsense words uttered         Using Bayesian inference, this model assigns a posterior
in the vignettes. The vignettes were divided into “high infor-       probability score to individual lexicons given a corpus of data.
mative” (HI) and “low informative” (LI) vignettes. The HI            MCMC stochastic search is used to find the lexicon with the
vignettes were those which were guessed correctly a majority         highest score; no claims are made about how human learn-
of the time in isolation (determined in a separate experiment),      ers do this. The scoring algorithm considers all possible in-
and everything else was coded as a LI vignette.                      tended sets of referents for a given scene. For example, if two
   Interestingly, subjects who saw a HI vignette followed by         objects, a pig and a horse, are visible to the learner during a
four LI vignettes were more likely to guess word meanings            particular utterance, four possible intentions must be consid-
correctly at the end of the experiment than subjects who saw         ered: the speaker could be talking about the horse, the pig,
the same five vignettes in a different order. The authors hy-        both, or neither. Each possible intention yields some proba-
pothesize that early low informative instances handicap the          bility value, and those values are added together to obtain the
learner, because rather than using the high informativity of         contribution of that utterance to a lexicon’s overall score.
later instances to make correct guesses, learners instead waste         Although the lack of explicitly given clues about speaker
their time checking and rejecting the erroneous guesses they         intent is perceived as an advantage, there is no indication that
made previously. Subsequent eye-tracking studies show sim-           this reflects the behavior of human learners. Furthermore,
ilar effects (Medina, Hafri, Trueswell, and Gleitman, 2010).         considering all possible intents adds considerable complexity
Subjects behave as if they are choosing a hypothesized mean-         to the model in that the lexicon scoring algorithm becomes
ing for a novel item, and then verifying or falsifying that          exponentially more demanding the more cluttered the room
meaning as new data is received. This process of hypothe-            is. Since values are computed over the power set of visible
sis evaluation opposes the traditional view of cross-situational     objects, a naming event involving n candidate objects will
                                                                 904

contribute 2n calculations to the scoring process. This is not                 BOOK      BIRD      RATTLE      FACE     EYES  NULL
                                                                       look    0.45      0.00      0.01        0.38     NA    0.16
too problematic with relatively clean data, but one can easily
                                                                       we      0.00      0.01      0.00        0.01     NA    0.98
imagine a naturalistic learning environment with 30 distinct           can     0.00      0.01      0.00        0.01     NA    0.98
objects in the visual field, which would require over a billion        read    0.01      0.00      0.01        0.00     NA    0.98
calculations just to score one lexicon.                                books   0.23      0.00      0.00        0.36     NA    0.41
   The authors claim that Bayesian inference explains mutual           david   0.36      0.00      0.00        0.23     NA    0.41
exclusivity. However, it is a choice by the modelers to make         Figure 1: A partial probability matrix for words and objects
the likelihood term of their probability calculation dependent
on the conditional probability P(word|ob ject), rather than
P(ob ject|word). Thus, mutual exclusivity is built into the         updating these probabilities. We use Bush and Mosteller’s
inference mechanism, not explained by it. In the absence of a       (1951) Linear Reward-Penalty (LR-P) scheme, which was
deep explanation, we treat ME as an external cue rather than        first applied to linguistic learning by Yang (2002). Below are
an architectural fact.                                              the LR-P functions for rewarding and penalizing the proba-
   Fazly et al. (2008) present a more computationally plau-         bility of a hypothesis.
sible incremental model, but rather than focusing on object
names as other models do, their model learns rich concep-
tual structures and as a result necessitates larger amounts of      Table 1: Linear Reward-Penalty functions for a hypothesis h.
data to converge on correct meanings. Where their model
                                                                       REWARD (h)        p(h) = p(h) + γ(1 − p(h))
requires as many as 20,000 utterance-situation pairs for ac-
                                                                                         where γ is some constant between 0 and 1
curate learning, our model learns with precision after fewer
than 500, with some words being learned after fewer than six
                                                                                         For all h0 6= h:
exposures. This reflects young children’s famous ability to
                                                                                         p(h0) = p(h0) ∗ (1 − γ)
learn effectively from sparse input via fast-mapping.
                      Model Overview                                   PENALIZE(h)       p(h) = p(h) ∗ (1 − γ)
Word learning is mediated by a probability matrix with word
                                                                                         For all h0 6= h:
types on the vertical axis and object types on the horizontal                                         γ
                                                                                         p(h0) =    n−1  + p(h0) ∗ (1 − γ)
axis, illustrated in Figure 1.
                                                                                         where n is the number of hypotheses being
   The semantic hypothesis space for a potential object name                             considered
is both open-ended and contingent on observation. This
means that:
• A word-to-object mapping gets a value if and only if the              The learning coefficient γ determines the severity of re-
   word and the object have co-occurred.                            wards and penalties. The final version of our model uses
• New words and objects can be introduced into the matrix           variable γ values to represent the privileged status of salient
   at any time.                                                     words and objects. Using these functions we update probabil-
                                                                    ities on the fly, and we use the results to update the learner’s
For example, the words can, read, and books are never uttered       current lexicon of word-object pairs by including all and only
in the presence of the object coded ‘EYES’ in our evaluation        those pairs whose probability values exceed a given thresh-
corpus. Therefore, mappings from these words to ‘EYES’              old. This threshold (set to 0.65 in our simulations) serves to
have no value in Figure 1. This has the effect of reducing the      transform the probabilities into a discrete set of mappings that
size of a word’s hypothesis space and preventing completely         the learner can evaluate.
unfounded mappings from receiving a positive value when                 We implement different versions of the model to test the
other mappings are penalized.                                       effect of each ability we give the learner. We use as our base-
   Novel words are mapped to ‘NULL’ with probability 1,             line a simple nested loop which rewards, in random order,
with co-occurring objects receiving a value of 0. The ‘NULL’        all candidate objects for all words in each utterance (we call
mapping corresponds to the hypothesis that a word does not          this process “multiple-candidate rewarding”). This is essen-
refer to an object. We take this to be the learner’s default        tially a real-time equivalent of simple association frequency.
assumption. New objects are introduced into an old word’s           We then add the hypothesis evaluation component by treat-
hypothesis space with a probability value of 1n , where n is        ing words that are in the current lexicon differently than other
the new size of that word’s hypothesis space. The rest of the       words. If a word is already mapped to an object, then the
probability vector is normalized to accommodate the addi-           probability associated with that mapping is rewarded or pe-
tion. This gives new semantic hypotheses a fair shot at lexi-       nalized depending on whether that object is in the present sit-
con inclusion.                                                      uation (i.e. depending on whether the learner’s hypothesis is
   This matrix provides us with a way to add and track prob-        consistent with current observation). In this case, no other
abilities of word-to-object mappings. Learning proceeds by          candidates are rewarded. In all models, mutual exclusivity
                                                                905

                                                                     • b determines how much weight is given to hypotheses that
    For each observation, consisting of an utterance U and a
    randomly-ordered set of possible object referents O:                map stressed words to gesturally indicated objects during
                                                                        multiple-candidate rewarding.
       For each word w in U:
                                                                     For words already in the lexicon, single hypotheses are re-
      1. If w is novel, assign probability 1 to w → NULL             warded or penalized with γ = γH . For words not in the lexi-
      2. Else, add new objects to w’s hypothesis space.              con, multiple possible mappings are rewarded with a different
      3. If w is in the current lexicon:                             gamma value; mappings between stressed words and gestu-
       ⇒ If w’s hypothesized meaning m is an element of O,
           reward(w → m).                                            rally indicated objects are rewarded with γ = γM ∗ b, while
       ⇒ Else, penalize (w → m).                                     other mappings are rewarded with γ = γM ∗ (1 − b). The best
      4. If w is not in the current lexicon:                         performance is achieved when γH and γM are relatively high
       ⇒ For each o in O:                                            (0.4 and 0.36, respectively), and when most of the weight is
        ⇒ If o is not in the current lexicon, reward(w → o).         given to salient mappings (b = 0.98).
       Update the current lexicon.                                      To restate, the learner rewards and penalizes more drasti-
                                                                     cally when checking their current lexicon against the world
   Figure 2: An online cross-situational learning algorithm          than when making multiple associations, and when the
 [The arrow (→) in the algorithm should be read “maps to”.]          learner is making multiple associations, more weight is given
                                                                     to hypotheses that map stressed words to gesturally indicated
                                                                     objects.
                             x
                                                                        To illustrate, consider the utterance in Figure 3. Assume,
                             x         x              x
                                                                     as shown in Fig. 4, that there are five visible objects accompa-
             x        x      x         x .      x     x .
                                                                     nying this utterance, and only one of them is indicated by ges-
         There’s      a    bear     looking     at  David
                                                                     ture (the mother is pointing to the bear and ignoring the other
               Figure 3: Stress on a prosodic grid                   objects). Upon hearing this utterance, the learner possesses a
                                                                     lexicon of one entry: the word “david” maps erroneously to
                                                                     the object ‘MIRROR’.
is enforced by exempting objects that already have names                These data will be processed incrementally by the learner
from multiple-candidate rewarding. The algorithm with both           in the following way:
multiple-candidate rewarding and single-hypothesis evalua-
tion is outlined in Figure 2.                                       1. Since there’s is not in the lexicon, it undergoes multiple-
   The final component of our model is the integration of the           candidate rewarding rather than single hypothesis evalua-
salience cues. Objects in our video corpus were coded for               tion. Since it is not stressed, all present object meanings
gesture. An object was considered to be indicated by gesture            are rewarded using the coefficient γM ∗ (1 − b).
during an utterance if it any point it was both (1) judged to be
in the baby’s field of vision, and (2) pointed to or held up in     2. The unstressed article a undergoes the same process as
front of the baby. Eye gaze, being less obvious in the videos           there’s.
and therefore more prone to errors, was not coded.
   Words were coded for prosodic accent. Utterances were            3. The lexicon does not have a mapping for bear, so it un-
given prosodic grid structures like the one in Figure 3, repre-         dergoes multiple-candidate rewarding, but since bear is
senting peaks in stress. Any word that received stress above            stressed, the learning coefficient can vary. The gestu-
the lexical level was coded as a stressed word. In typical adult        rally indicated object referent ‘BEAR’ is rewarded with the
speech the acoustic correlates of stress are subtle, and thus           higher coefficient γM ∗ b, while the other non-indicated ob-
coding in this way is prone to subjectivity. However, this              jects are rewarded with γM ∗ (1 − b).
problem is ameliorated here, at least in part, by the exagger-
ated pronunciations utilized in the child-directed speech in        4. The stressed verb looking undergoes the same process as
the evaluation corpus.                                                  bear.
   Information about stress and gesture is used to determine
                                                                    5. The unstressed preposition at behaves like there’s and a.
the value of the learning coefficient γ for each rewarding or
penalizing event. We give the model three parameters:               6. Since david has a mapping in the learner’s current lexicon,
• γH is the learning coefficient used when rewarding or pe-             only that mapping is considered. In this case, david maps
   nalizing a mapping that is already in the lexicon (hypothe-          to ‘MIRROR’, and the object ‘MIRROR’ is not present in
   sis evaluation).                                                     the current scene, so the learner’s hypothesis is penalized.
                                                                        If the penalty lowers the probability value below the given
• γM is the default learning coefficient used when reward-              threshold, then david → ‘MIRROR’ is kicked out of the
   ing possible mappings that are not already in the lexicon            lexicon.
   (multiple-candidate rewarding).
                                                                 906

  uttered:       {there’s, a, bear, looking, at, david}                                     Word     Object      Word      Object
  stressed:      {bear, looking, david}                                                      book    book      piggies     pig
  visible:       {BOOK, BIRD, RATTLE, BEAR, BOTTLE}                                          bear    bear          hat     hat
  indicated:     {BEAR}                                                                    bunny     bunny    moocow       cow
                                                                                         kittycat    cat         meow      cat
  lexicon:       {david → MIRROR}                                                           sheep    sheep     bigbird     bird
                                                                                             bird    duck         ring     ring
    Figure 4: Example stimulus and accompanying lexicon
                                                                                          Figure 5: Most frequent output lexicon
             Performance and Comparisons
All models were run on hand codings of two videos of                        majority of simulations using this model produce the lexicon
mother-child interaction from the Rollins corpus (CHILDES,                  seen in Figure 5.
MacWhinney, 2000). Together the videos consist of 496                           Performance is comparable to the Bayesian model of Frank
utterance-situation pairs (about 20 minutes of video). Per-                 et al. (2009), and our online learning model represents a
formance was evaluated by aggregating the precision and re-                 computational simplification. Beal and Roberts (2009) argue
call against a gold standard over 100 simulations1 , and taking             for the importance of complexity analysis in computational
the harmonic mean of the average precision and recall to pro-               cognitive science. A cognitive model should operate within
duce an F-score. Model performance is detailed in Table 2.                  known limits of human computational power, and complexity
Three online models were tested: the baseline model, which                  analysis is necessary to evaluate how realistic a model could
does not utilize hypothesis evaluation, and two versions of                 be. Beal and Roberts show the Bayesian model of Xu and
the model given in Figure 2, one with a fixed γ value, and one              Tenenbaum (2007) to be quite costly from this perspective.
which uses stress and gesture to determine γ. These models                  Frank et al.’s model is even more costly. As mentioned above,
are compared to two implementations of Frank et al.’s (2009)                it is problematic to sum probabilities for all possible intention
Bayesian model: a direct implementation and a variant that                  sets for each situation. If the number of objects seen at one
only computes over stressed words and indicated objects.2                   time has some upper bound N, then the upper bound asymp-
                                                                            totic complexity will be O(2N ); the time it takes to process
                                                                            one situation will grow exponentially with the number of vis-
            Table 2: Model performance comparison.                          ible objects. This is not a problem for relatively clean data
                                                                            like the videos from the Rollins corpus, where the number of
   Model type                     Precision      Recall    F-score          visible objects does not typically exceed 6 or 7, but an espe-
   Bayesian (FGT 09)              0.36           0.29      0.32             cially cluttered room may force the learner to make billions of
   Bayesian (FGT 09)                                                        calculations to score one lexicon against one interaction. This
   + stress and gesture           0.72           0.38      0.52             problem does not arise in our model. Furthermore, in con-
   Real-time updating             0.24           0.06      0.10             trast to batch learning models, our model necessitates only
   Real-time w/ evaluation        0.36           0.06      0.10             one pass through the input data.
   Real-time w/ evaluation                                                      Finally, the model presented here holds the promise of fur-
   + stress and gesture           0.92           0.32      0.48             ther unification with experimental research. Experiments like
                                                                            those described by Medina et al. (2009, 2010) may prove to
   We see that adding prosodic and gestural information is                  be valuable both as a testing ground and as a source of refine-
a boost to both types of models; however, the cues have a                   ment for research of this type, whose goal is to incorporate
more drastic effect on the real-time model. Once the cues are               observable human behaviors into a psychologically plausible
integrated, the F-scores for both types of models are compa-                computational learning model.
rable. Though the Bayesian model achieves a slightly higher
F-score, the real-time model has a decided advantage in pre-                                          Conclusion
cision, with almost no erroneous mappings remaining in the                  We have presented a model of object name learning that re-
lexicon. This is a desirable result because as learning contin-             lies on gestural and prosodic cues and utilizes both single-
ues beyond 20 minutes of interaction, the absence of mislead-               candidate and multiple-candidate probability updating mech-
ing lexical entries will make for a more efficient process. The             anisms. The model operates in real time, making only one
    1 Multiple simulations account for slight variations in output
                                                                            pass through a corpus and updating a lexicon after each suc-
caused by randomizing the order in which multiple candidates are            cessive utterance-situation pair. Performance is close to that
rewarded.                                                                   of a comparable Bayesian model. The simplicity and success
    2 We used our own hand-coding of the same videos that were              of the model suggests two things: (1) having access to word
used by Frank et al. For the Bayesian implementations, the authors’         stress and gestural information makes word learning consid-
original code was used, strongly suggesting that the discrepancy be-
tween the performance reported here and the performance reported            erably easier, and (2) the ability to test beliefs about indi-
in Frank et al. (2009) is due to differences in the coding of the data.     vidual words makes learning more efficient. The next step
                                                                        907

in this line of research is to link up this computational ap-           interface. Proceedings of the 24th Annual Conference of
proach even closer with experimental findings, and it is our            the Cognitive Science Society, 697-702.
hope that in doing so we may contribute to the growing pool           Quine, W. (1960). Word and object. Cambridge, MA: MIT
of knowledge about how children learn the meanings of their             Press.
first words.                                                          Siskind, J. (2000). Learning word-to-meaning mappings. In
                                                                        P. Broeder & J. Murre (Eds.), Models of language acquisi-
                       Acknowledgments                                  tion. Oxford: Oxford University Press.
Thanks to Charles Yang, John Trueswell, and Tamara Medina             Soderstrom, M., Seidl, A., Nelson, D., & Jusczyk, P. (2003).
for their help with this project, and thanks to the anonymous           The prosodic bootstrapping of phrases: Evidence from
reviewers for their valuable comments.                                  prelinguistic infants. Journal of Memory and Language,
                                                                        49, 249-267.
                           References                                 Thiessen, E., Hill, E., & Saffran, J. (2005). Infant directed
                                                                        speech facilitates word segmentation. Infancy, 7, 49-67.
Baldwin, D. (1991). Infants’ contribution to the achievement          Xu, F., & Tenenbaum, J. (2007). Word learning as bayesian
   of joint reference. Child Development, 62.                           inference. Psychological Review, 114(2).
Beal, J., & Roberts, J. (2009). Enhancing methodological              Yang, C. (2002). Knowledge and learning in natural lan-
   rigor for computational cognitive science: Computational             guage. Oxford: Oxford University Press.
   complexity. Cognitive Science Conference.                          Yang, C. (2004). Universal grammar, statistics, or both?
Bloom, P. (2000). How children learn the meanings of words.             TRENDS in Cognitive Sciences, 8(10), 451-456.
   Cambridge, MA: MIT Press.                                          Yu, C., & Ballard, D. (2007). A unified model of early word
Brown, P., Cocke, J., Pietra, S. D., Pietra, V. D., Jelinek, F.,        learning: Integrating statistical and social cues. Neurocom-
   Lafferty, J., et al. (1990). A statistical approach to machine       puting, 70, 2149-2165.
   translation. Computational Linguistics, 16(2), 79-85.
Bush, R., & Mosteller, F. (1951). A mathematical model for
   simple learning. Psychological Review, 68, 313-323.
Carey, S. (1978). The child as word learner. In M. Halle,
   J. Bresnan, & G. Miller (Eds.), Linguistic theory and psy-
   chological reality. Cambridge, MA: MIT Press.
Fazly, A., Alishahi, A., & Stevenson, S. (2008). A proba-
   bilistic incremental model of word learning in the presence
   of referential uncertainty. Proceedings of the 30th Annual
   Conference of the Cognitive Science Society.
Frank, M., Goodman, N., & Tenenbaum, J. (2009). Us-
   ing speakers’ referential intentions to model early cross-
   situational word learning. Psychological Science, 20(5).
Gillette, J., Gleitman, H., Gleitman, L., & Lederer, A. (1999).
   Human simulations of vocabulary learning. Cognition, 73,
   135-176.
Ichinco, D., Frank, M., & Saxe, R. (2009). Cross-situational
   word learning respects mutual exclusivity. Proceedings of
   the 31st Annual Meeting of the Cognitive Science Society.
MacWhinney, B. (2000). The childes project: Tools for ana-
   lyzing talk (3rd ed., Vol. 2). Mahwah, NJ: Erlbaum.
Markman, E. (1992). Constraints on word learning: Spec-
   ulations about their nature, origin, and domain specificity.
   In M. Gunnar & M. Maratsos (Eds.), Modularity and con-
   straints on language and cognition: The minnesota sympo-
   sium on child psychology. Mahwah, NJ: Erlbaum.
Medina, T., Hafri, A., Trueswell, J., & Gleitman, L. (2010).
   Propose but verify: Fast-mapping meets cross-situational
   word learning. Boston University Conference on Language
   Development.
Medina, T., Trueswell, J., Snedeker, J., & Gleitman, L.
   (2009). Rapid word learning under realistic learning con-
   ditions. LSA Annual Meeting, San Francisco, CA.
Niyogi, S. (2002). Bayesian learning at the syntax-semantics
                                                                  908

