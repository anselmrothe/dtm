UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Multisensory Statistical Learning: Can Cross-Modal Associations Be Acquired?
Permalink
https://escholarship.org/uc/item/2gc8t36d
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Walk, Anne
Conway, Christopher
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

 Multisensory Statistical Learning: Can Associations between Perceptual Categories
                                                              Be Acquired?
                                               Anne McClure Walk (awalk@slu.edu)
                                          Christopher M. Conway (cconway6@slu.edu)
                                              Department of Psychology, 3511 Laclede Ave.
                                                            Saint Louis University
                                                         Saint Louis, MO 63103 USA
                               Abstract                                   a person’s mouth verbalizing one syllable, while an auditory
                                                                          track is played of a different syllable. When the auditory
   Statistical learning, the process by which people learn patterns
   of information from their environment that they can apply to           input does not match the visual input, participants report
   new situations, is central to the development of many higher           perceiving a hybrid syllable constructed from combining the
   order cognitive skills. Despite a growing research literature,         visual and auditory information.
   little is still known about how statistical learning operates             Clearly, multisensory processing is an important
   across perceptual categories. To investigate this issue we             phenomenon. However, it is still unknown to what extent
   assessed college students on their ability to learn a                  cross-categorical inputs can be integrated in the case of
   multisensory artificial grammar containing both auditory and
   visual elements and both within-categorical and cross-
                                                                          statistical learning. One possibility is that statistical learning
   categorical associations. The results of Experiment 1 showed           is domain general, and therefore operates equally across all
   that participants were sensitive to grammatically correct test         modalities and perceptual categories. Under this view, one
   items and ungrammatical test items that contained within-              would expect that multisensory statistical learning would be
   categorical grammatical violations, but were not sensitive to          robust, and that learning would be comparable across
   items that contained cross-categorical violations across               domains. Indeed, Seitz, Kim, Wassenhoven, and Shams
   sensory modalities. Experiment 2 showed that participants              (2007) used a statistical learning paradigm to demonstrate
   were not sensitive to items that contained cross-categorical
   violations within the same sensory modality. Our findings              that participants learned both audio and visual patterns
   suggest that multisensory integration across perceptual                independently when presented with audio-visual pairings,
   categories does not occur easily during statistical learning.          indicating equivalent levels of learning when exposed to
                                                                          stimuli from different sensory modalities. Several studies
   Keywords: statistical learning, artificial grammar learning,
   multisensory processing, domain-general                                have also demonstrated improved performance when stimuli
                                                                          are presented in two rather than a single modality (Kim,
                           Introduction                                   Seitz, & Shams, 2008; Robinson & Sloutsky, 2007), which
                                                                          could indicate that stimuli in different modalities are
Statistical learning, the ability to detect statistical                   integrated together during statistical learning tasks.
associations in the environment (Perruchet & Pacton, 2006),               Furthermore, several studies have shown transfer between
appears to be important across a range of cognitive domains,              sensory domains, suggesting that knowledge resulting from
including language, motor skills, and event segmentation                  statistical learning processes can be easily integrated across
(Conway, Pisoni, Anaya, Karpicke, & Henning, 2011;                        input domains and perceptual categories (Altmann, Dienes,
Conway, Bauernschmidt, Huang, & Pisoni, 2010; Leclerq &                   & Good, 1995; Manza & Reber, 1997).
Majerus, 2010; Zacks & Swallow, 2007). Despite a growing                     On the other hand, recent research suggests that statistical
body of research investigating different aspects of statistical           learning may not be purely domain-general. For instance,
learning, little is known about how learning takes place                  modality constraints exist which bias and affect how
across perceptual categories and sensory modalities.                      statistical patterns are acquired (Emberson, Conway, &
   To illustrate the importance of multisensory processing in             Christiansen, in press; Conway & Christiansen, 2005). The
cognition, we briefly consider its role in speech perception              presence of these modality constraints suggest that although
and production, which require the integration of material                 learning across perceptual domains might operate using
across perceptual categories. Rosenblum (2008) suggested                  similar computational principles, each modality may also be
that spoken language processing is naturally a multisensory               biased to acquire certain types of information better than
phenomenon, pointing out that infants appear to use visual                others. Even so, whether people are able to learn patterns
speech cues early in life to help perceive speech.                        when cross-categorical dependencies are employed is a less
Furthermore, when one sensory modality is insufficient for                explored issue. Conway and Christiansen (2006) showed
perceiving a speech element, the other modality can be                    that when learning two separate sets of regularities
recruited: for example, phonemes that are auditorily similar              concurrently, participants demonstrated learning only when
tend to be visually distinct in terms of facial and mouth                 the two sets of stimuli were in different sensory modalities
movements. The importance of multisensory processing in                   or perceptual categories. They argued that this demonstrates
speech perception is also seen in the well known McGurk                   that statistical learning relies on stimulus-specific rather
illusion (McGurk, 1976) in which participants see a video of
                                                                      3337

than abstract representations since no “mixing” of the             proposed a shallow integration model, as depicted in Figure
information occurred across sensory modalities. These last         2 (top). In this model, different modality features, such as
findings suggest that to some extent, information across           shape and color for vision, enter onto different featural
sensory modalities is not easily integrated during statistical     nodes. These nodes feed input into a central processing
learning, raising doubts as to a completely domain-general         mechanism where the various input is integrated, producing
view of statistical learning.                                      an overall sensory experience. Importantly, in the shallow
                                                                   model the sensory features do not load onto a modality-
      Reconceptualizing Modality Differences                       specific node before moving to the central processing
The previously reviewed findings raise difficulties with           mechanism. Rather, various visual features, such as shape
adopting a purely domain-general view of statistical               and color, and auditory features such as pitch and tone all
learning. However, perhaps the problem lies in the                 interact once reaching the central processing mechanism.
inadequacy of using a strict dichotomous classification of         Thus, modalities are initially percept specific, but become
either purely domain-general versus purely domain-specific         integrated at a higher level of processing.
(illustrations of each are depicted in Figure 1) models. In a        In addition, as an alternative to the domain-specific view,
domain-general model, all input types and modalities are           which proposes that all sensory modalities are completely
treated equally, offering complete integration across              isolated from each other, McNorgan et al. (2011) proposed a
perceptual categories and sensory modalities. On the other         deep integration model (Figure 2, bottom). In this model,
hand, in a domain-specific model, no integration occurs at         an additional level of nodes is introduced. Sensory input
all between specific sensory modalities or perceptual              enters and is loaded onto a featural node as before, then
categories. Although there may be some theoretical                 passes onto a modality-specific sensory node, such as
usefulness out of depicting these views, sensory integration       vision, before entering the central processing mechanism.
is likely more complex than either model would imply.              As an example, according to this model, once a tone of a
                                                                   particular pitch is perceived, it loads onto the pitch node,
                                                                   and then is integrated with phonology and other auditory
                                                                   features before entering the central processor. Here the
                                                                   auditory information can be further integrated with
                                                                   information from other sensory modalities.
Figure 1. Domain-general model (top) versus domain-specific
model (bottom) of sensory integration.
   Cree and McRae (2003) investigated a similar problem in
the psycholinguistic literature regarding semantic
categorization. These authors reconceptualized the
previously debated question as to whether semantic
categorization is stored in a domain- or knowledge-specific        Figure 2. Shallow integration model (top) and deep integration
                                                                   model (bottom), adapted from McNorgan et al. (2011).
manner, by statistically analyzing a large corpus of nouns
according to various theoretical categorizational constructs,
such as concept familiarity, word frequency, and visual                                The Present Study
complexity, among others. From their analyses, they found          We believe that the perspectives offered from these shallow
that semantic categorization can actually be conceptualized        and deep integration models can provide insight into better
as a combination of all of the proposed constructs. Thus,          understanding multisensory statistical learning. The purpose
they suggested a reconceptualization of the traditional            of the present study is to begin to tease apart which of these
domain-general/domain-specific division, into one that is          models might offer the most explanatory power for
more integrative (McNorgan, Reid, & McRae, 2011).                  multisensory/multi-categorical processing in statistical
   As a variation of the domain-general view, which                learning. The present experiments employ an artificial
suggests that all sensory modalities are processed within a        grammar learning (AGL) paradigm, a common paradigm
single cognitive mechanism, McNorgan et al. (2011)                 used to test such learning (Perruchet & Pacton, 2006; Reber,
                                                               3338

1967; Seger, 1994). The traditional AGL paradigm exploits          Stimulus Materials For the learning task, we used an
the probability between different inputs by using a finite         artificial grammar consisting of three visual elements and
state grammar. Traditionally, these inputs consist of various      three auditory elements. The visual elements were abstract
elements in a single modality or perceptual category. Thus,        black shapes that were difficult to verbally label. The
a particular input sequence may be a series of pictures,           auditory elements were three tones generated using
tones, or letters, the order of each element being determined      Audacity software having frequencies of 210, 286, and
by the grammatical rules. Our paradigm differed from the           389Hz. These frequencies were used because they neither
traditional in that instead of using inputs from a single          conform to standard musical notes nor have standard
perceptual category, we used elements from multiple                musical intervals between them (Conway & Christiansen,
domains, such that both within-categorical and cross-              2005).
categorical associations were present. Other studies                  We used an artificial grammar with constrained
(Robinson & Sloutsky, 2007) that have used inputs from             probabilities to generate the input sequences (see Table 1).
multiple domains have bound them in such a way that when           To generate a sequence from such a grammar, one randomly
an element from one perceptual category (e.g. a visual             picks a starting element on the left (A-1, V-2, A-3, V-4, A-
element) appeared, it always co-occurred with an element           5, or V6) and then uses the listed probability to generate the
from a different category (e.g. an auditory element). In           next item. For instance, if V-2 is the starting element, it can
contrast, we treated all sensory category inputs as individual     be followed by either A-3 or V-4; if A-3 is the element
units of the grammar. Thus, in Experiment 1, participants          occurring next, it can be followed by either V-4 or A-5.
were exposed to a learning phase in which they heard tones         Thus, V-2, A-3, A-5 is an example of a short three-item
interspersed with pictures that appeared on a screen (see          input sequence that can be generated by this grammar.
Figure 3). Each auditory element could be followed by a               In general, the grammar specifies that each auditory
visual or auditory element, and vice versa, creating a unique      element has .5 probability of being followed by one other
grammar consisting of three independent visual and three           auditory element and a .5 probability of being followed by a
individual auditory elements. Importantly, because the             visual element. Likewise, each visual element can be
learning phase consisted of both within-categorical and            followed half of the time by one other visual element, and
cross-categorical associations, we could test to what extent       half of the time by a single auditory element. Thus, each
participants can acquire each, which may help us distinguish       element of the grammar could be followed by two other
between the four possible models of multisensory                   elements, one of the same modality, and one from the other
integration discussed above. In Experiment 1, we employed          modality. For Experiment 1 the within-categorical items
two sets of stimuli from two different sensory modalities          were also within-modal (e.g., auditory-auditory and visual-
(visual shapes and auditory tones); in Experiment 2, we            visual), and the cross-categorical items were also cross-
employed two categories of auditory stimuli (tones and             modal (e.g., auditory-visual or visual-auditory). Two types
nonwords).                                                         of ungrammatical items were also generated, within-modal
                                                                   violations and cross-modal violations. To create within-
                                                                   modal violation items, all within-modal dependencies were
                                                                   altered so that they violated the grammar; however, all
                                                                   cross-modal dependences remained grammatical. For cross-
                                                                   modal violation items, all cross-modal dependencies did not
                                                                   conform to the grammar; however, the within-modal
                                                                   dependencies remained grammatical.
                                                                   Table 1: The probabilities used to formulate grammatical
                                                                   sequences for the learning phase and test items, which
Figure 3: Example of a possible input sequence used in the         consisted of visual (“V”) and auditory (“A”) elements.
present study.
                                                                              A-1    V-2    A-3     V-4    A-5      V-6
                        Experiment 1                                   A-1       0     .5      .5     0       0       0
                                                                       V-2       0      0      .5     .5      0       0
Method                                                                 A-3       0      0      0      .5      .5      0
Participants Fifteen undergraduate students from Saint                 V-4       0      0      0      0       .5      .5
Louis University participated in the study. All participants
received credit toward partial fulfillment of an                       A-5      .5      0      0      0       0       .5
undergraduate course as compensation for their time. All               V-6      .5     .5      0      0       0       0
participants reported being native speakers of English with
vision and hearing at normal or corrected to normal levels.        Procedure All participants completed two phases of the
                                                                   task: a learning phase and a test phase. In the learning phase,
                                                                   participants were directed to put on a pair of headphones,
                                                               3339

and pay attention to the pictures that flashed on the screen as         In other words, participants could reliably recognize a
well as any sounds they heard through the headphones.                grammatical item as grammatical and could detect within-
Participants were exposed to a continuous 7-8 minute                 modal violations. However, they were unable to detect
sequence of pictures and tones that coincided with the               statistical violations that occurred between two elements
grammar. In the second phase of the experiment,                      from two different modalities. These results indicate that
participants observed novel six-item sequences and had to            learning statistical associations between two elements may
determine if each item was grammatical (i.e., it “followed           be more difficult when it takes place across two modalities
the rules” of the sequences they heard during the learning           compared to when it occurs within the same modality.
phase) or ungrammatical (i.e., it “did not follow the rules”).       Because no cross-modal integration was seen in Experiment
Participants were given 20 novel grammatical test items, 10          1, we can conclude that the domain-general modal is not an
ungrammatical cross-modal violation items, and 10                    accurate depiction of the type of processing taking place in
ungrammatical within-modal violation items, in random                multisensory statistical learning.
order. Participants made their responses by pressing one of
two buttons on a button box, one signifying grammatical              Experiment 2
items, the other signifying ungrammatical items. For each               The results of Experiment 1 show that participants may be
participant, the auditory and visual tokens were randomly            unable to use knowledge gained through statistical learning
assigned to the elements in the grammar; thus, for one               to identify sequences that contain a cross-categorical
participant, A-1 might be the 210 Hz tone, but for another           violation. However, Experiment 1 tells us only how
participant, A-1 might be the 389 Hz tone.                           information is integrated between sensory modalities, but
                                                                     nothing about how information is integrated within a single
Results and Discussion                                               modality. Experiment 2 was conducted to further investigate
The present study serves as an initial test of the domain-           to what extent different features from a single modality are
general and domain-specific models of sensory integration.           integrated and learned, in order to test the shallow
If people process statistical information domain-generally,          integration model of statistical learning.
we expect to see no difference between performance in
detecting within-modal and cross-modal violations. Under
                                                                     Method
this view, what is important is that there exists a violation to
                                                                     Participants Participants in this study were fifteen
the grammatical regularities, and participants should
                                                                     undergraduate students from Saint Louis University. As in
therefore be able to detect such violations, regardless if it is
                                                                     Experiment 1, all participants received credit toward partial
a cross-modal violation (e.g., detecting that A-1, V-4 is an
                                                                     fulfillment of an undergraduate course as compensation for
illegal transition). However, if statistical learning is domain-
                                                                     their time. All participants reported being native speakers
specific, with learning focused solely on transitions within a
                                                                     of English with vision and hearing at normal or corrected to
sensory modality, then it might be expected that participants
                                                                     normal levels.
should fail to identify cross-modal violations.
   Table 2 lists percent correct judgments for each of the
                                                                     Stimulus Materials For Experiment 2, the stimulus
three item types (grammatical, ungrammatical within-modal
                                                                     materials were two different types of auditory stimuli. The
violations, and ungrammatical cross-modal violations). A
                                                                     same three tones used in Experiment 1 were used in this
series of single sample t-tests were run comparing the group
                                                                     experiment with the addition of two tones, at frequencies
means to chance performance (50%). A group mean
                                                                     245 and 333 Hz, to give a total set of five tones. As in
significantly higher than chance would signify learning.
                                                                     Experiment 1, the two additional tones did not conform to
                                                                     standard musical notes or contain intervals of any standard
Table 2: Mean performance for Experiments 1 and 2.
                                                                     musical scale. In addition, five nonsense syllables were
Values presented are percentage correct for each condition.
                                                                     used for the second stimulus type: “vot,” “pel,” “dak,” “jic,”
                                                                     and “rud” (from Gómez, 2002). For each participant, three
Group                        Mean (SD)
                                                                     of the tones and three nonsense syllables were randomly
                      Gram          Within-Cat      Cross-Cat
                                                                     selected and mapped onto the sequences. Thus, each
                                                                     participant received the same sequences (generated from the
Experiment 1          59.35(11.3)* 65.3(13.0)*     50.7(17.5)
                                                                     grammar in Table 1), but the actual tones and syllables used
                                                                     differed across participants.
Experiment 2          60.65(9.4)*   78.7(14.6)*    51.3(22.3)
                                                                        The grammar used for constructing the learning and test
                                                                     items was the same as in Experiment 1. The learning
   As can be seen from Table 2, learning occurred for the            sequence and test items used were nearly identical, except
grammatical items (t = 3.19, p < .01) and the within-modal           that two items from the list containing within-categorical
violation items (t = 4.56, p < .001). However, no learning           violations and two containing cross-categorical violations
was seen for the cross-modal violation items (t = 0.15, p >          were modified slightly. The test phase again consisted of
.5).                                                                 three types of items: grammatical, ungrammatical within-
                                                                 3340

category violations, and ungrammatical cross-category              and cross-category violations may be due to a tendency to
violations.                                                        focus first on within-category patterns, which may be
                                                                   adaptive. That is, it may be more useful to learn within-
Procedure The procedure was identical to the one                   category associations at the expense of cross-category ones,
undergone by the participants in Experiment 1.                     assuming that only a limited amount of cognitive resources
                                                                   are available to detect violations. The reasons for this are
Results and Discussion                                             currently unexplored, though several possible explanations
If cross-categorical violations are easier to identify when        exist. It is a possible that it is more cognitively efficient to
presented within a single sensory modality, we would               look for patterns in stimuli that are more similar before
expect to see improved performance on the cross-categorical        trying to find rules in patterns that exist across domains.
violations in Experiment 2, because the violations span            Perhaps participants would have shown learning if they had
perceptual categories but are within the same sensory              greater exposure to the cross-categorical patterns in the
modality (e.g., tone-syllable or syllable-tone). This finding      learning phase, which would support this claim. It is also
would provide evidence in support of the shallow                   possible that within-category associations are encountered
integration model. On the other hand, if cross-categorical         more frequently or are more informative, though this
violations are equally difficult to identify regardless of         possibility seems less likely given the infant literature
whether they are presented in a single or multiple sensory         showing that learning is enhanced when infants are given
modality, we should see no evidence of learning for the            stimuli in multiple modalities (Lewkowitcz, 2004).
cross-categorical items. This scenario would provide further          The two studies presented here provide initial evidence in
support for domain-specific processing in statistical              support of a domain-specific model of multisensory
learning.                                                          integration, suggesting that people have difficulty
   To test these possible outcomes, a series of t-tests were       integrating sensory input across perceptual domains.
run on the data to ascertain if learning was greater than          However, this finding is preliminary. Interestingly, this
chance levels for the three types of test items. The means for     conclusion does not correspond to the conclusions in
each item type can be seen in Table 2. As is evident,              McNorgan et al.’s (2011) initial test of their linguistic
learning was observed for the grammatical items (t = 4.384,        model, in which they determined that the deep model of
p < .001) and for the within-categorical violation items (t =      processing best accounts for linguistic categorization.
7.618, p < .001) but not for the cross-categorical violation       Several reasons for this discrepancy may exist. First, it is
items (t = 0.23, p > .8).                                          possible that statistical learning is a functionally different
   The data from Experiment 2 replicate and extend the             process than linguistic processing, at least as assessed by the
results seen in the previous experiment. Once again,               two different tasks used in our study and theirs. One major
learning was robust for grammatical items and                      difference between our statistical learning task and their
ungrammatical items when the grammatical violation was             linguistic task is that in the McNogran et al. (2011) study,
present between two units of the same feature type (i.e., two      participants did not actually perceive stimuli in different
tones or two syllables). However, when the violation               modalities. Instead, they were presented with words that
appeared between a tone and a syllable, participants were          theoretically appealed to different sensory modalities. If
unable to identify it as ungrammatical at levels above             processing operates differently in these two domains
chance. Thus, the difficulty seen in Experiment 1 for              (linguistic and statistical learning), it is not unreasonable to
individuals identifying grammatical violations in cross-           assume that a test of linguistic categorization would yield a
modal situations extends to instances where the grammatical        different pattern of results than a test of statistical learning.
elements are in the same sensory modality, but in different           A second explanation deals with the previously
perceptual categories.                                             mentioned issue of exposure time. It is possible that
                                                                   learning would have occurred if participants had been given
                    General Discussion                             more exposure to the cross-categorical dependencies in the
The present studies investigated categorical integration in a      learning phase. If this were the case, then the shallow and
statistical learning paradigm. Experiment 1 used visual and        deep integration models could be directly tested against
auditory elements in a single artificial grammar to                each other by integrating multiple features of each sensory
investigate within-modal and cross-modal processing.               modality into a single grammar. By varying the amount of
Experiment 2 investigated how learning takes place when            exposure time with such a grammar, it could be possible to
two distinct features within a single modality are employed.       determine whether learning associations across different
The findings were used to evaluate four models of                  sensory modalities differs in comparison to learning
multisensory integration, based on those recently applied to       associations across different perceptual categories within the
linguistic processing (McNorgan, Reid & McRae, 2011).              same modality.
   Taken together, the studies demonstrate that participants          An important issue for further study is how these
are capable of learning grammatical and within-categorical         processes work in infants and children, as it has implications
violations, but have difficulty with cross-categorical             for multisensory aspects of cognitive processing such as
violations. The discrepancy in performance between within-         speech perception. Since speech processing is one of many
                                                               3341

cognitive skills that is considered multisensory, especially       Emberson, L.L., Conway, C.M., & Christiansen, M.H. (in
for young infants (Rosenblum, 2008), it is necessary to              press). Timing is everything: Changes in presentation rate
determine if they are capable of detecting cross-category            have opposite effects on auditory and visual implicit
violations. Little is currently known about the                      statistical learning. Quarterly Journal of Experimental
developmental trajectory of multisensory learning in                 Psychology.
children. Other cognitive processes not systematically             Gómez, R.L. (2002). Variability and detection of invariant
studied in these experiments may also be involved, such as           structure. Psychological Science, 13, 431-436.
to what extent attention is specifically deployed in the           Gómez, R.L. (1997). Transfer and complexity in artificial
learning phase toward learning the within-modal versus the           grammar learning. Cognitive Psychology, 33, 154-207.
cross-modal associations. These are important issues for           Kim, R.S., Seitz, A.R. & Shams, L. (2008). Benefits of
future study.                                                        stimulus congruency for multisensory facilitation of
   In summary, the present experiments indicate that                 visual learning. PLoS One, 3(1), e1532.
statistical learning is a complex process with constraints         Leclercq, A. & Majerus, S. (2010). Serial order short term
present in categorization. Though people are capable of              memory predicts vocabulary development: Evidence from
correctly identifying grammatical information and within-            a longitudinal study. Developmental Psychology, 46 (2),
categorical violations, they have difficulty learning                417-427.
grammatical violations when the violation appears between          Lewkowicz, D.J. (2004). Serial order processing in human
elements from two different categories of information.               infants and the role of multisensory redundancy.
These categories may be different sense modalities, or               Cognitive Processes, 5, 113-122.
different features within the same modality. On the other          Manza, L & Reber, A.S. (1997). Representing artificial
hand, people are very skilled at identifying violations that         grammars: Transfer across stimulus forms and modalities.
occur within a single perceptual category. On the one hand           In D.C. Berry (Ed.), How implicit is implicit learning?
these findings would appear to suggest a purely domain-              (pp.73-106). New York, NY: Oxford University Press.
specific view of multisensory statistical learning, in which       McGurk, H. & MacDonald, J. W. (1976). Hearing lips and
sensory integration does not occur at all. On the other hand,        seeing voices. Nature, 2 64 , 746-748.
there may be other factors not explicitly explored in the          McNorgan, C., Reid, J. & McRae, K. (2011). Integrating
current experiment (e.g., exposure time, attention) that could       conceptual knowledge within and across representational
instead make cross-modal statistical learning more                   modalities. Cognition, 118, 211-233.
amenable.                                                          Perruchet, P. & Pacton, S. (2006). Implicit learning and
                                                                     statistical learning: One phenomenon, two approaches.
                        References                                   Trends in Cognitive Sciences, 10(5), 233-238.
Altmann, G.T.M., Dienes, Z., & Goode, A. (1995).                   Reber, A.S. (1967). Implicit learning of artificial grammars.
   Modality independence of implicitly learned grammatical           Journal of Verbal Learning and Verbal Behavior, 6, 855-
   knowledge. Journal of Experimental Psychology:                    863.
   Learning, Memory, and Cognition, 21, 899-912.                   Robinson, C.W. & Sloutsky, V.M. (2007). Visual statistical
Conway, C.M., Bauernschmidt, A., Huang, S.S., & Pisoni,              learning: Getting some help from the auditory modality.
   D.B. (2010). Implicit statistical learning in language            Paper session presented at the meeting of Cognitive
   processing: Word predictability is the key. Cognition,            Science Society, Nashville, TN.
   114, 356-371.                                                   Rosenblum, L.D. (2008). Speech perception as a
Conway, C.M., & Christiansen, M.H. (2005). Modality-                 multimodal phenomenon. Current Directions in
   constrained statistical learning of tactile, visual, and          Psychological Science, 17 (6), 405-409.
   auditory sequences. Journal of Experimental Psychology:         Seitz, A.R., Kim, R., Wassenhoven, V., & Shams, L.
   Learning, Memory, & Cognition, 31, 24-39.                         (2007). Simultaneous and independent acquisition of
Conway, C.M. & Christiansen, M.H. (2006). Statistical                multisensory and unisensory associations. Perception,
   learning within and between modalities: Pitting abstract          36(10), 1445-1453.
   against stimulus-specific representations. Psychological        Seger, C.A. (1994). Implicit learning. Psychological
   Science, 17, 905-912.                                             Bulletin, 115 (2), 163-196.
Conway, C.M., Pisoni, D.B., Anaya, E.M., Karpicke, J., &           Zacks, J.M. & Swallow, K.M. (2007). Event segmentation.
   Henning, S.C. (2011). Implicit sequence learning in deaf          Current Directions in Psychological Science, 16 (2), 80-
   children with cochlear implants. Developmental Science,           84.
   14, 69-82.
Cree, G.S. & McRae, K. (2003). Analyzing the factors
   underlying the structure and computation of the meaning
   chipmunk, cherry, chisel, cheese, and cello (And many
   other such concrete nouns). Journal of Experimental
   Psychology: General, 132 (2), 163-201.
                                                               3342

