UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Temporal Dynamics of Scan Patterns in Comprehension and Production
Permalink
https://escholarship.org/uc/item/1tz1j361
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Coco, Moreno I.
Keller, Frank
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

          Temporal Dynamics of Scan Patterns in Comprehension and Production
                                            Moreno I. Coco (M.I.Coco@sms.ed.ac.uk) and
                                                     Frank Keller (keller@inf.ed.ac.uk)
                                            Institute for Language, Cognition and Computation
                                              School of Informatics, University of Edinburgh
                                               10 Crichton Street, Edinburgh EH8 9AB, UK
                              Abstract                                  that visual responses during comprehension are launched af-
                                                                        ter the linguistic material is understood; whereas in produc-
   Speakers and listeners in a dialogue establish mutual under-         tion, visual responses are launched prior or during sentence
   standing by coordinating their linguistic responses. When a
   visual scene is present, scan patterns on that scene are also        generation.
   coordinated. However, it is an open question which linguis-             These results strongly suggest the existence of alignment
   tic and scene factors affect coordination. In this paper, we in-     mechanisms that underlie the coordination of comprehension
   vestigate the coordination of scan patterns during the compre-
   hension and generation of scene descriptions. We manipulate          and production processes. However, especially with respect
   the animacy of the subject and the number of visual referents        to the evidence for gaze coordination, it is unclear what the
   associated with it. By using Cross Recurrence Analysis, we           role og visual and linguistic information is, and whether the
   demonstrate that coordination emerges only during linguistic         characteristic lag underlying gaze coordination depends on
   processing, and that it is especially pronounced for inanimate
   unambiguous subjects. When the subject is referentially am-          such information.
   biguous (more than one visual object associated with it), scan          In Richardson et al. (2007), in fact, the visual informa-
   pattern variability increases to the extent that the animacy ef-     tion available to the participants is not naturalistically situated
   fect is neutralized.
                                                                        (i.e., six portait pictures of characters from TV serials), and
   Keywords: Scan patterns, situated language processing, cog-          the linguistic information used by the speaker to guide the
   nitive dynamics, coordination
                                                                        listener, besides referring to a depicted character, does not ac-
                                                                        tively interact with it. As a result of this, the gaze coordination
                          Introduction                                  obtained in the dialogue is achieved through a shallow pro-
When language is comprehended or produced in a visual                   cess of character identification: the speaker is talking about X
context, information about fixated objects has to be inte-              and the listener looks at X with a constant delay.
grated with the linguistic information that is concurrently             In this paper, we present a study in which we explicitly inves-
processed (e.g., Spivey-Knowlton et al. 2002); this integra-            tigate how linguistic and visual information interact to pro-
tion requires visual attention and sentence processing to be            duce coordinated scan patterns. We explore coordination at
synchronized temporally (e.g., Zelinsky and Murphy 2000).               different levels of granularity, from the macro-level of the
Language comprehension and language production, however,                whole trial down to the level of individual objects. Moreover,
differ in their temporal interaction with visual attention. In a        we test how coordination is influenced by the visual and lin-
comprehension task, visual attention is guided by linguistic            guistic referential information shared in comprehension and
information, and its main role is to anticipate which objects           production, focusing on the animacy of the subject of the sen-
the speech could refer to next (e.g., Altmann and Kamide                tence, shown to influence both linguistic and visual responses
1999). In a production task, instead, visual attention plays an         (Coco and Keller, 2010), and the number of targets (visual
active role in deciding which objects in the scene should be            referents associated with the subject).
mentioned in a sentence (e.g., Griffin and Bock 2000).                     Our main hypothesis is that the characteristic lag under-
   The relation between comprehension and production has                lying the scan pattern coordination between comprehension
been investigated mainly in the context of dialogue. A promi-           and production emerges only when sentence processing is ac-
nent account of how comprehension and production relate to              tively involved, and that it is directly influenced by the proper-
each other is the interactive alignment model (Pickering and            ties of the visual and linguistic information being processed.
Garrod, 2007); which assumes that successful dialogue leads             In particular, scan patterns are expected to show less coordi-
to aligned representations at every linguistic level, and that          nation on a single animate target, as the associated informa-
this alignment is supported by priming, i.e., the reuse of lin-         tion spans a wider range of contextual possibilities. In con-
guistic material.                                                       trast, the low linguistic relevance of an inanimate target, and
   Importantly, this process of alignment in dialogue has been          the referential ambiguity of multiple targets should force par-
observed to go beyond aligned linguistic representations; it            ticipants to depend more strongly on contextual scene infor-
also includes the gaze coordination of dialogue partners.               mation, thus triggering a higher degree of coordination.
Richardson et al. (2007) showed that the scan patterns of lis-
teners and speakers engaged in a dialogue about six charac-                                       Experiment
ters are coordinated. This coordination is subject to a char-           Our study aims to explore the role of referential factors in the
acteristic temporal lag, with the same character being fixated          temporal dynamics of scan pattern coordination between lan-
consistently later by listeners than by speakers. This confirms         guage comprehension and production during the description
                                                                    2302

of naturalistic scenes.
   Processing descriptions requires visual and linguistic ref-
erential information to be overtly integrated. When a descrip-
tion is produced, active processes of scene exploration inter-
act with the encoding of linguistic information; when such a
description is instead understood, its decoding is constrained
and modulated by the visual information available.
   The main goal of the current study is to test whether
the temporal dynamics of scan pattern coordination between
comprehension and production of scene descriptions differs
from that observed in dialogue. Additionally, we test whether
referential factors pertaining to the linguistic and visual infor-
mation processed modulate the associated pattern of coordi-
nated gazes.
                                                                       Figure 1: Example of experimental conditions and materials (scenes
Method                                                                 and sentences).
We quantify coordination by using eye-tracking data col-
lected in the two independent experiments (production and              Images were presented on a 21” multiscan monitor at a reso-
comprehension), which involve the same visual and linguis-             lution of 1024 x 768 pixels. Participants sat 60–70 cm from
tic stimuli.                                                           the computer screen, which subtend a region of approxi-
   In an eye-tracking language production experiment (Coco             mately 20 degrees of visual angle. Only the dominant eye
and Keller, 2010), we asked participants to describe a photo-          was tracked. In the description task, a target word appeared
realistic scene after being prompted with a target word, which         for 750 ms at the center of the screen, after which the scene
was either animate or inanimate (e.g., man or hat), and cor-           followed. A lapel microphone was used to record the descrip-
responded to either one, two or three visual objects depicted          tions generated. In the comprehension task, participants had
in the scene. The production data considerably varies in sen-          a scene preview of 1500 ms before the sentence was played.
tence and scan pattern complexity. Thus, in order to con-                 A nine points randomized calibration was carried out at the
trol this variability and have sentences with similar syntactic        beginning of each experiment, and repeated approximately
structures and controlled semantic factors, we select a subset         every 24 trials. Drift correction was performed before each
of 24 sentences (together with the associated scan patterns),          trial. Once every four trials, during the comprehension task, a
produced by different participants, to be used in the follow-up        yes/no comprehension question about the content of the scene
language comprehension experiment.                                     or the sentence was asked. Participants had to respond by
   We followed three criteria to select this subset: (1) the sen-      pressing a button on a control pad. In the description task,
tence is transitive and mentions only two visual referents,            there was no time limit for the trial, and to pass to the next
e.g., the WOMAN is playing the VIOLIN, making it possible              trial, participants pressed a button on the response pad. In the
to test coordination on a precise number of individual objects         comprehension task, the trial ended 1500 ms after the end of
(kept constant across the set), (2) the subject of the sentence        the sentence. Both experimental tasks were explained using
is either animate or inanimate, which allows us to observe             written instructions and took about 30 minutes to complete.
how the conceptual property of animacy modulates coordina-
tion, and (3) the target object associated with the subject is                                    Analysis
either unique (i.e., there is one corresponding visual object)         The temporal dynamics governing the interaction between
or referentially ambiguous (i.e., there are three correspond-          visual attention and language processing are different for
ing visual objects), to assess the role of ambiguity resolution.       comprehension and production. In comprehension, visual re-
Figure 1 depicts a set of example stimuli. The 24 sentences            sponses are linked to sentence processing only when the sen-
we selected represent a design with four conditions (six sen-          tence is listened to; in production, instead, visual responses
tences per condition), crossing the factors Animacy (animate           interact with sentence processing both prior and during the
or inanimate) and Number of Targets (one or three). These              mention of a visual object.
sentences were played to a different set of participants in an            A way to investigate temporal variability between two
indepedent language comprehension experiment while they                time-series while exploring the underlying regularity is Cross
viewed the associated scenes. For this purpose, the sentences          Recurrence Analysis (CRA, Marwan and Kurths 2002;
were recorded by a female native speaker of English.                   Richardson et al. 2007).
Procedure Forty-eight (24 per task) native speakers of En-             Nominal Cross Recurrence Analysis Conceptually, CRA
glish, all students of the University of Edinburgh, were each          compares two time series by calculating the degree of their re-
paid five pounds for taking part in the experiment. An Eye-            currence when delays are introduced with different levels of
Link II head-mounted eye-tracker was used to monitor par-              phase space embedding. From an original time-series X(t),
ticipants’ eye-movements with a sampling rate of 500 Hz.               delayed copies X(t + τ) are generated by introduction a lag
                                                                   2303

                                                                       however, we are interested in the agreement between the two
                                                                       scan patterns on a specific object k. This information is ob-
                                                                       tained by computing the φk coefficient, which increases with
                                                                       the frequency of matching looks on the same object (k − k)
                                                                       and away from this object (¬k − ¬k) between the two scan
                                                                       patterns. On the other hand, φk decreases with the frequency
                                                                       of mismatching objects (k − ¬k, and vice versa); refer to Dale
                                                                       et al. (2011), for more details.
                                                                       Regions of Analysis In order to capture how the temporal
                                                                       dynamics of coordination is influenced by the introduction of
                                                                       linguistic information, we conduct our analysis at three lev-
                                                                       els: global, phase, and object.
                                                                          In the global analysis, similar to Richardson et al. (2007),
                                                                       we look at the whole trial. At this macro-level, we observe
                                                                       how recurrence develops across different lags and measure
                                                                       the impact of subject animacy and visual referential ambigu-
Figure 2: The top of the figure shows a simplified example of how      ity on recurrence. If these two factors do not influence coor-
lags are introduced in the time series and cross-recurrence calcu-     dination, a similar amount of recurrence should result in all
lated. The bottom part shows how a contingency table mapping the
information of object co-occurrences between two scan patterns is      conditions.
created.                                                                  In the phase analysis, we compute recurrence separately
                                                                       before and during sentence processing, and explore the dis-
                                                                       tribution of optimal lags (i.e., the lags associated with maxi-
τ into the original time series. The different dimensions of           mal recurrence for each pair of scan patterns) associated with
phase space embedding are obtained by considering multi-               the visual objects describing the subject and object of the
ple lags X(t + mτ). The lag is introduced to compare one               sentence. Before sentence processing starts, we do not ex-
time series with the future or the past of itself, or to com-          pect any specific temporal correlation between comprehen-
pare it to another time series. The phase space consists of the        sion and production, as visual attention is not yet guided by
different intervals over which the delays are assigned. Over           linguistic information to the same target objects. However,
these time-delayed copies and across the different lags, re-           during production, in line with previous literature (Richard-
currence, i.e., a measure of similarity, is calculated.                son et al., 2007), we expect recurrence to increase when the
   Suppose we have scan-pattern data from two participants,            scan patterns of production are delayed with respect to the
each represented as a sequence of numbers (see Figure 2).              scan patterns of comprehension, i.e., when a positive lag is
Participant 1 was producing a sentence and participant 2               introduced.
was listening to it. If the two sequences are not shifted and             In the object analysis, we evaluate how recurrence (mea-
we measure their similarity by computing, for example, Eu-             sured as φk ) changes for the visual objects associated with
clidean distance, we obtain a distance of 9. If we shift the           the linguistic referents of the sentence (subject and object),
time series of participant 2 by moving his sequence forward            before and during sentence processing, across the different
by four time units, we observe increased similarity: the Eu-           conditions of Animacy and Number of Targets. Before pro-
clidean distance is now 3. The interpretation is that more time        duction, we expect higher recurrence on the second object, as
was needed by participant 2 to produce a sequence similar to           it usually represents the receiver of an action (for an animate
participant 1. Since our time series are scan patterns, i.e., se-      subject), or an object spatially related to the subject (if the
quences of fixated objects, we follow Dale et al. (2011) and           subject is inanimate). We hypothesize that in preparation for
adopt a categorical version of CRA, where recurrence is ob-            sentence processing, both in comprehension and in produc-
tained by means of contingency tables; refer to Figure 2 for           tion, visual attention explores the different possible events
an example. At each lag τ, we construct a contingency ta-              taking place in the scene that could be referred to linguisti-
ble CT, which is a square matrix with the objects of a given           cally. As animate actors are quickly spotted, visual attention
scene as its rows and columns. Each element of this matrix             focuses more on the receiver of the action. Similarly, in the
represents the number of times the pair of objects (i, j) co-          case of an inanimate subject, attention must be directed to
occurs between the two scan patterns x and y. More formally:           other inanimate objects that could be spatially related to the
               t=T −τ
CT i, j (τ) = ∑t=1    q(t), where T is the length of each scan         subject.
pattern and q(t) = 1 if x(t) = i and y(t + τ) = j, and q(t) = 0
otherwise.                                                             Inferential Analysis We use linear mixed effect models
   From CT, we can compute two measures of recurrence:                 (Baayen et al., 2008) to quantify the impact of Lags, Ani-
matching recurrence RR and object-specific recurrence φk .             macy, and Number of Targets on the amount of recurrence
Matching recurrence is computed along the diagonal of CT               observed. A linear mixed effect model is a multilevel exten-
by adding the frequencies of looks to the same objects. Often,         sion of linear regression, where the regression coefficients of
                                                                   2304

explanatory variables (fixed effects) on a dependent measure
are inferred with respect to random effects, usually related to
sampling variables, such as participants.
    We use and report estimates of LME coefficients for the
global and object analysis, where the dependent measures are
recurrence and φk . Our predictors are Lag, Number of Tar-
gets (one, three), Animacy (animate, inanimate), and for the
object analysis, we also include Object (first, second), a cate-
gorical variable indicating the visual objects referred to in the
sentence.1 The random effects are Participants, both in com-
prehension and production, and Scenes.
    Since our explanatory variables can be influenced by the
variability of scene configurations, we residualize our depen-
dent measures prior to the LME analysis, against three vari-
                                                                            Figure 3: CRA: Mean and confidence intervals of scan pattern recur-
ables (Clutter, Referents, and Area) related to each individ-               rence during the whole trial for the different lags (τ = ±50 ms from
ual scene. Clutter quantifies the visual density of the scene               −3500 ms to 3500 ms). Line density indicates the number of targets
(Rosenholtz et al., 2007), Referents describe the total number              (three: high density, one: low density), color indicates the animacy
of visual objects in a scene, and Area is the number of pixels              of the subject (red: animate, blue: inanimate).
occupied by the visual objects associated with the linguistic
referents of the sentence.
    All fixed factors were centered to reduce collinearity. The             animate ones (βInanimate = 0.036; p = 0.07); and this effect
mixed models were built following a forward step-wise pro-                  reaches significance when there is only one visual target
cedure. We start with an empty model, then we add the ran-                  (βInanimate:Target−One = 0.3; p < 0.05)
dom effects. Once all random effects have been evaluated, we                    Animate objects are linked to a larger set of event relations
proceed by adding the predictors. They are added one at time                within a given scene compared to inanimate objects, which
and ordered by log-likelihood improvement of model fit; the                 instead are often contextualized by their spatial relation with
predictor that improves most model fit is added first. Every                another object. When interpreting the coordination of gazes
time we add a new parameter to the model (fixed or random),                 between comprehension and production, this implies that for
we compare its log-likelihood against the previous model. We                an inanimate single target, once sentence processing starts
retain the additional predictor if log-likelihood fit improves              and the subject is spelled out, it is much easier to guess which
significantly (p < 0.05). The final model is therefore the one              object is going to be mentioned next. In contrast, the compe-
that maximizes model fit with the minimal number of predic-                 tition generated by the visual ambiguity in the Three Targets
tors.                                                                       condition tends to increase variability of scan patterns, mak-
                                                                            ing responses in the animate and inanimate condition more
                     Results and Discussion                                 similar. Nevertheless, three animate referents attract more vi-
We present three analyses: (1) in the global analysis, we ex-               sual attention than three inanimate referents, especially when
plore how recurrence changes with lags for the whole trial in               linguistic information is not yet introduced; which explains
the different conditions; (2) in the phase analysis, we inves-              the positive interaction between Animate subject and Three
tigate changes in recurrence by examining before and during                 Targets (βAnimate:Target−Three = 0.3; p < 0.05).
sentence processing. We search for the lag maximizing recur-                    It is important to note that at the global level of analysis, we
rence, and observe whether it differs for the two visual objects            fail to find an effect of lag (βLag = −0.00005; p > 0.1). This
of the sentence; (3) in the object analysis, we explore how the             differs from the findings of Richardson et al.’s (2007) study,
experimental factors Animacy, Number of Targets, and Ob-                    which is based on trials that consist of dialogues. In a dia-
ject interact with recurrence before and during sentence pro-               logue, the speaker provides the listener with linguistic guid-
cessing.                                                                    ance throughout the whole trial; whereas in descriptions2 , the
                                                                            linguistic guidance to listeners (expected to improve gaze co-
Global: Recurrence for the Whole Trial In Figure 3, we                      ordination) is limited to when the description is actually men-
show mean and confidence intervals of recurrence calculated                 tioned. Thus, we expect that the characteristic lag observed by
on scan patterns generated during the whole trial across dif-               Richardson et al. (2007) should emerge only during sentence
ferent lags with maximum lag ±3500 ms. We observe differ-                   processing. To test this, we analyze what happens before and
ences in the magnitude and trend of recurrence across condi-                during sentence processing separately.
tions.
    In particular, sentences with inanimate subjects trigger a              Phase: Lag Distribution Before and During Processing
higher scan pattern recurrence compared to sentences with                   In Figure 4, we plot the frequency distribution of the lags
     1 If the sentence is the woman is playing the violin, then Object:     which give maximal recurrence, before and during sentence
first is the recurrence on WOMAN -L (we disambiguate multiple vi-
sual referent by their position in the scene), whereas the Object: sec-          2 Notice, our speakers and listeners do not interact, as they are
ond is the recurrence on VIOLIN.                                            tested in two independent experiments.
                                                                        2305

Figure 4: Frequency distribution of optimal lags: before (top panel)          Figure 5: φk coefficient of visual objects associated with the sentence
and during (bottom panel) sentence processing. The optimal lag is             (first, i.e., subject; second, i.e., object), during sentence processing.
the one that gives maximal scan pattern recurrence on the visual
referents associated to the sentence (first, i.e., subject; second, i.e.,
object).
                                                                              ing the activation of sentence processing mechanisms.
processing, on the visual referents associated with the sen-                  Object: Influence of Animacy and Number of Targets In
tence.                                                                        Figure 5, we show how the φk of the first and second object
   Before sentence processing, the introduction of lags im-                   changes across conditions, during sentence processing3 .
proves recurrence on both visual objects; nevertheless, this                      We observe a main effect of Lag, where the φk coeffi-
increase in recurrence does not relate to any specific direc-                 cient of both objects gains by a positive shift of production
tion of temporal shifts. This implies that at lag zero, produc-               with respect to comprehension (βLag = 0.0011; p < 0.05) This
tion and comprehension have highly dissimilar scan patterns,                  confirms that during sentence processing itself, the coordina-
but they tend to be more aligned when delays are introduced.                  tion of scan patterns in comprehension and production oc-
Probably, visual attention tends to converge on a similar set of              curs with a characteristic delay (Richardson et al., 2007).
objects when a certain time has elapsed in both processes of                  Moreover, we find an interaction between Lag and Object,
comprehension and production. When looking at the objects,                    such that the second object gains more by positive shifting
we find maximal recurrence more often in relation to the sec-                 (βLag:Object−Second = −0.0008; p < 0.0001). Once the subject
ond visual object (the sentence object). We argue that visual                 of the sentence, i.e., the first object, is identified, visual atten-
attention focuses more on the objects in the scene, which are                 tion focuses on the second object, which is the receiver of the
either receivers of actions, or are in a spatial relation to other            action, for animate subject, or on a spatially related object,
objects, as they carry important causal information to under-                 for inanimate subjects. It is also interesting to note that when
stand the event taking place in the scene.                                    the subject of the sentence is associated with a single inani-
                                                                              mate target, we observe substantial gains when shifting on the
   During sentence processing, we observe a clear trend of
                                                                              corresponding object, i.e., the first object, in both temporal di-
maximal recurrence for positive lags. In line with previous
                                                                              rections, with the highest peak found at positive lags. In order
literature (Richardson et al., 2007), a scan pattern generated
                                                                              to understand this result, it is important to remember that the
during description needs to be shifted forward with respect
                                                                              φk coefficient penalizes mismatches. So, φk is positive when
to the associated comprehension scan pattern, as visual ref-
                                                                              gazes are either both on the target object (e.g. violin,violin) or
erents are usually fixated before description in production,
                                                                              both on completely different objects (e.g. woman-L, woman-
but identified in comprehension after the associated linguistic
                                                                              R); φk is instead negative when there is a mismatch, i.e. one
referents have been listened to. It is important to notice how
                                                                              gaze on the target object, the other on a different object (e.g.
during sentence processing, recurrence on the first visual ob-
                                                                              violin,woman-L).
ject (the sentence subject) increases substantially already at
                                                                                  An inanimate object has a low linguistic relevance, hence
lag zero compared to before sentence processing. Naturally,
                                                                              there is a high chance that is unattended if visual attention is
since the sentence starts with the subject, visual attention is
                                                                              not directed towards it by a cue. So, the first positive peak
oriented immediately to the associated visual referent. More-
                                                                              observed at negative lags indicates that when the alignment
over, we find that increasing positive lags improve recurrence
                                                                              between comprehension and production widens, gazes tends
on this visual referent. A similar increase is seen also for the
                                                                              to be on completely different objects. However, at positive
second object, but it holds for both positive and negative lags.
                                                                              lags, we observe a second and highest peak, which proba-
Furthermore, in general, it is clear that the relative gain in
                                                                              bly reflects gaze agreement on the inanimate target object.
recurrence by shifting is higher during sentence processing
than before, for both objects. This points to the important role                  3 We focus on the during sentence processing phase, as the LME
played by lags in aligning comprehension and production dur-                  analysis in the before analysis failed to yield any significant results.
                                                                          2306

In fact, once the inanimate object has been mentioned, vi-           to have a more controlled and counterbalanced design both
sual attention needs to locate and retrieve information about        in terms of experimental conditions and data accuracy (e.g.,
it. This process generates a delay in comprehension, which is        equal numbers of speakers and listeners). Moreover, a coop-
reflected by the larger gain in recurrence when the production       erative task give us the possibility to explore how the interac-
scan patterns are shifted forward.                                   tion of different cognitive processes, e.g., motor actions and
                                                                     visual responses, modulates the cross-modal coordination be-
                     General Discussion                              tween comprehension and production.
The processes of language comprehension and production                  Overall, we have shown that scan pattern coordination is a
share cognitive mechanisms which are intimately connected.           key mechanism that enables the integration of comprehension
Research in dialogue has shown coordination between speak-           and production processes. Crucially, we demonstrated that
ers and listeners both in their linguistic and visual responses      there are important visual and linguistic factors which need
(Pickering and Garrod, 2007; Richardson et al., 2007). How-          to be accounted for in order to achieve a full understanding of
ever, previous work fails to identify the factors involved in        the cognitive dynamics underlying this integration.
the coordination of visual responses in production and com-
prehension, and the temporal dynamics underlying it.                                      Acknowledgments
    In this paper, we investigated the temporal aspects of scan      The support of the European Research Council under award
pattern coordination during the generation and comprehen-            number 203427 ”Synchronous Linguistic and Visual Process-
sion of scene descriptions. Descriptions, in contrast to dia-        ing” is gratefully acknowledged.
logues, allow us to pin down more precisely the influence of
shared referential information during the overt interaction be-                                References
tween visual and linguistic responses.                               Altmann, G. and Kamide, Y. (1999). Incremental interpre-
    In order to quantify the temporal dynamics underlying gaze          tation at verbs: restricting the domain of subsequent refer-
coordination, we used Cross Recurrence Analysis: a tech-                ence. Cognition, 73:247–264.
nique used to unravel recurring patterns between time series         Baayen, R., Davidson, D., and Bates, D. (2008). Mixed-
(Marwan and Kurths, 2002; Dale et al., 2011). In line with              effects modeling with crossed random effects for subjects
Richardson et al. (2007), we found substantial recurrence be-           and items. Journal of memory and language, 59:390–412.
tween scan patterns in production and comprehension, but we
also observed important differences across phases of analysis        Coco, M. and Keller, F. (2010). Sentence production in natu-
and across individual objects. These differences are modu-              ralistic scene with referential ambiguity. In R. Catrambone
lated by both the animacy of subject and the number of tar-             & S. Ohlsson (Eds.), Proceedings of the 32th Annual Con-
gets. In particular, we find that delays in production increase         ference of the Cognitive Science Society, Portland.
coordination with comprehension during sentence processing           Dale, R., Warlaumont, A., and Richardson, D. (2011). Nom-
(but not before), and also improve the agreement between                inal cross recurrence as a generalized lag sequential analy-
scan patterns on the visual object identifying the subject of           sis for behavioral streams. International Journal of Bifur-
the sentence. We argue that prior to the availability of lin-           cation and Chaos.
guistic information, visual attention focuses on objects which       Griffin, Z. and Bock, K. (2000). What the eyes say about
are either receivers of actions, or objects that are involved in        speaking. Psychological science, 11:274–279.
a spatial relation with the target; the subject is in focus only     Marwan, N. and Kurths, J. (2002). Nonlinear analysis of bi-
if it is explicitly mentioned.                                          variate data with cross recurrence plots. Physics Letters A,
    The number of targets corresponding to a certain object             302:299–307.
interacts with their animacy in several interesting ways. A          Pickering, M. and Garrod, S. (2007). Do people use lan-
single animate object in the scene generates more variabil-             guage production to make predictions during comprehen-
ity between the scan patterns, which manifests itself in the            sion? Trends in Cognitive Sciences, 11(3):105–110.
recurrence remaining zero at all lags. This is perhaps due to
                                                                     Richardson, D., Dale, R., and Kirkham, N. (2007). The art of
the larger amount of conceptual knowledge related to animate
                                                                        conversation is coordination: common ground and the cou-
objects, which offers participants a wider space of contextual
                                                                        pling of eye movements during dialogue. Psychological
relations within the scene. An inanimate single object, on the
                                                                        science, 18:407–413.
other hand, has a more limited contextual potential; therefore
coordination between scan patterns in production and com-            Rosenholtz, R., Li, Y., and Nakano, L. (2007). Measuring
prehension becomes easier, and is attained for positive lags.           visual clutter. Journal of Vision, 7:1–22.
When multiple visual objects are associated with the same            Spivey-Knowlton, M., Tanenhaus, M., Eberhard, K., and Se-
subject referent, the influence of its animacy is neutralized,          divy, J. (2002). Eye movements and spoken language com-
due to the ambiguity introduced.                                        prehension: Effects of syntactic context on syntactic ambi-
    In future work, we are planning to address some shortcom-           guity resolution. Cognitive Psychology, (45):447–481.
ings of the study presented here. In particular, we are plan-        Zelinsky, G., J. and Murphy, G. (2000). Synchronizing
ning a cooperative version of the description task, in which            visual and language processing. Psychological science,
speakers and listeners are simultaneously recorded and asked            11(2):125–131.
to interact. The co-presence of speaker and listener allow us
                                                                 2307

