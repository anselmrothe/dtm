UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Pseudo-Deterministic Model of Human Language Processing
Permalink
https://escholarship.org/uc/item/6b74h72k
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Ball, Jerry
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                   A Pseudo-Deterministic Model of Human Language Processing
                                          Jerry T. Ball (Jerry.Ball@mesa.afmc.af.mil)
                                          Air Force Research Laboratory, 6030 S. Kent Street
                                                            Mesa, AZ 85212 USA
                              Abstract                                  come next, rather than waiting until the next input is
                                                                        available before deciding on the current input.
   This paper proposes, empirically motivates and describes a
   pseudo-deterministic model of Human Language Processing                 To capture the interactive nature of HLP, we propose a
   (HLP) implemented in the ACT-R cognitive architecture                parallel, probabilistic mechanism for activating alternatives
   (Anderson, 2007). The model reflects the integration of a            in parallel and selecting the most highly activated
   highly parallel, probabilistic activation and selection              alternative. This parallel, probabilistic mechanism selects
   mechanism and non-monotonic context accommodation                    between competing alternatives, but does not build any
   mechanism (with limited parallelism) with what is otherwise          structure. At each choice point, the parallel, probabilistic
   a serial, deterministic processor. The overall effect is an HLP
   which presents the appearance and efficiency of deterministic
                                                                        mechanism uses all available information to select
   processing, despite the rampant ambiguity which makes truly          alternatives that are likely to be correct, allowing the serial
   deterministic processing impossible.                                 integration mechanism to be largely deterministic.
                                                                           To capture the incremental and immediate nature of HLP,
   Keywords: HLP; pseudo-deterministic; cognitively plausible;
   functional; non-monotonic; context accommodation
                                                                        we propose a serial, pseudo-deterministic processor that
                                                                        builds and integrates linguistic representations, relying on a
                           Introduction                                 non-monotonic mechanism of context accommodation with
                                                                        limited parallelism, which is part of normal processing, to
There is extensive psycholinguistic evidence that Human                 handle cases where some incompatibility that complicates
Language Processing (HLP) is essentially incremental and                integration manifests itself.
interactive (Just & Carpenter, 1987; Altmann & Steedman,                   The primary monotonic mechanisms for building
1988; Tanenhaus et al., 1995; Altmann, 1998; Gibson &                   structure within the serial mechanism include: 1) integration
Pearlmutter, 1998). Garden-path effects, although                       of the current input into an existing construction which
infrequent, strongly suggest that processing is serial and              predicts its occurrence (substitution); and 2) projection of a
incremental at the level of phrasal and clausal analysis                new construction and integration of the input into this
(Bever, 1970). Lower level word recognition processes                   construction (Ball, 2007a). For example, given the input
suggest parallel, activation-based mechanisms (McClelland               “the pilot”, the processing of “the” will lead to projection of
& Rumelhart, 1981; Paap et al., 1982). At the level of                  a nominal construction and integration of “the” as the
phrasal and clausal analysis, humans appear to pursue a                 specifier of the nominal. In addition, the prediction for a
single analysis which is only occasionally disrupted,                   head to occur will be established. (For a discussion of
requiring reanalysis. One of the great challenges of                    functional categories like specifier and head, see Ball,
psycholinguistic research is to explain how humans can                  2007b.) When “pilot” is subsequently processed, it is biased
process language effortlessly and accurately given the                  to be a noun and integrated as the head of the nominal
complexity and ambiguity that is attested (Crocker, 2005).              construction projected by “the”.
As Boden (2006, p. 407) notes, deterministic processing                    Besides predicting the occurrence of an upcoming
“would explain the introspective ease and speed of speech               linguistic element, projected constructions may predict the
understanding”. However, given the rampant ambiguity of                 preceding occurrence of an element. If this element is
natural language, a deterministic mechanism would need                  available in the current context, it can be integrated into the
access to the entire input before making a decision. Marcus             construction. For example, given “the pilot flew the
(1980) proposed a deterministic parser with a limited                   airplane”, the processing of “flew” can lead to projection of
lookahead capability to capture the trade-off between the               a declarative clause construction which predicts the
efficiency of human parsing and the limitations with respect            preceding occurrence of a subject. If a nominal is available
to garden-path inputs. However, there is considerable                   in the context (as in this example), it can be integrated as the
evidence that HLP is inconsistent with extensive lookahead,             subject of the declarative clause construction.
delay or underspecification—the primary serial mechanisms                  In addition to these monotonic mechanisms, a projected
for dealing with ambiguity without backtracking or                      construction may non-monotonically override an existing
reanalysis. According to Altmann & Mirkovic (2009, p.                   construction (akin to adjunction in Tree Adjoining
604), “The view we are left with is a comprehension system              Grammar, Joshi, 1987). For example, in the processing of
that is „maximally incremental‟; it develops the fullest                “the pilot light”, the incremental integration of “pilot” as the
interpretation of a sentence fragment at each moment of the             head of the nominal construction will subsequently be
fragment‟s unfolding”. Instead of lookahead, the HLP                    overridden by a construction in which “pilot” functions as a
engages in “thinkahead”, biasing and predicting what will               modifier and “light” functions as the head.
                                                                    495

        Theoretical Basis & Computational                           wh-questions beginning with “who”. Although this is
                     Implementation                                 possible, parallel projection of alternative structures must be
                                                                    highly constrained to avoid a proliferation of alternatives
The pseudo-deterministic model aligns with current                  within the serial processing mechanism which has limited
linguistic theory in Cognitive Grammar (Langacker, 1987,            capacity to maintain alternative structures in parallel.
1991), Sign-Based Construction Grammar (Sag, 2010) and                 The pseudo-deterministic model has been implemented
Conceptual Semantics (Jackendoff, 2002), and borrows                in the ACT-R cognitive architecture (Anderson, 2007).
ideas from Preference Semantics (Wilks, 1975) and Tree              ACT-R is a theory of human cognition implemented as a
Adjoining Grammar (Joshi, 1987). A key goal of the                  computational system with support for measuring cognitive
research is development of a functional model that adheres          processing time. ACT-R integrates a procedural memory
to well-established cognitive constraints. Such constraints         implemented as a production system with a declarative
have evolved to be largely functional in humans (Ball et al.,       memory (DM). DM consists of symbolic chunks of
2010). The model also borrows heavily from the                      declarative knowledge implemented in a frame notation (i.e.
comprehensive grammar of Huddleston & Pullum (2002,                 a collection of slot-value pairs) within an inheritance
2005) and the “Simpler Syntax” of Culicover & Jackendoff            hierarchy (single inheritance combined with default
(2005; Culicover, 2009). A key feature of the grammar of            inheritance). ACT-R is a hybrid system which combines a
Huddleston & Pullum (henceforth H&P) is the introduction            serial production execution mechanism with parallel,
of phrase internal grammatical functions like head,                 probabilistic mechanisms for production selection and DM
determiner (or specifier) and modifier. Lexical items and           chunk retrieval. Within the model, serial, incremental
phrases may have alternative functions in different                 processing and context accommodation are implemented in
grammatical contexts. For example, a prepositional phrase           ACT-R‟s procedural memory. Parallel, probabilistic
may function as a modifier (or adjunct) in one context (e.g.        processing is implemented within ACT-R‟s DM and uses
“He will eat dinner in a minute”, and as a verbal                   ACT-R‟s parallel spreading activation mechanism and DM
complement in a different context (e.g. “He put the book on         retrieval mechanism, to support probabilistic selection
the table”). Although the typical subject (a clause level           between competing alternatives. ACT-R‟s retrieval
grammatical function) is a noun phrase, various clausal             mechanism eliminates the need for a mechanism like mutual
forms can also function as subject (e.g. “That he likes you is      inhibition to support selection between competing
true”, “Going to the movies is fun”).                               alternatives (cf. Vosse & Kempen, 2000). Other than adding
   Differences from these grammatical treatments are                a collection of buffers to ACT-R to support language
largely motivated by constraints imposed by the incremental         processing by retaining the partial products of retrieval and
and interactive nature of HLP as reflected in the                   structure building, and improving the perceptual processing
computational implementation. For example, wh-words                 in ACT-R (Freiman & Ball, 2010), the computational
occurring at the beginning of a sentence are uniformly              implementation does not add any language-specific
assigned a wh-focus function that is distinct from the              mechanisms—although the collection of buffers and
subject function. In “Who is he talking to?”, “who”                 productions which reference them might be viewed as
functions as the wh-focus and “he” functions as the subject         constituting a language module in ACT-R.
of the wh-question construction that is projected during the           The computational implementation comprises ~700
processing of “who is…”. In addition, “who” is secondarily          productions and ~63,000 DM elements (part of speech and
bound to the object function of the locative construction           form specific lexical items) and is capable of processing a
projected during processing of the preposition “to”.                broad range of English language constructions
Likewise, in “Who is talking?”, “who” again functions as            (www.doublertheory.com/comp-grammer/comp-
the wh-focus, but in this case “who” is secondarily bound to        grammar.htm; Ball, Heiberg & Silber, 2007). The model
the subject function. In contrast, H&P treat “who” as the           accepts textual input from single words to entire documents.
subject in “Who is talking?” and as a pre-nucleus which is          On a 64-bit quad-core machine with 8 Gig RAM, the model
external to the main clause in “Who is he talking to?”.             incrementally processes ~285 words per minute (wpm) in
However, at the processing of “who” in an incremental               real time (~140 wpm in ACT-R cognitive processing time).
processor, it is not possible to determine which function
applies given the H&P grammar, whereas “who” is                      Parallel, Probabilistic Activation and Selection
uniformly treated as the wh-focus in the pseudo-
deterministic model. Further, the pseudo-deterministic              Based on the current input, current context and prior history
model projects a uniform wh-question construction with              of use, a collection of DM elements is activated via the
both a wh-focus and subject function (allowing the subject          parallel, spreading activation mechanism of ACT-R. The
to be bound to the wh-focus), whereas the grammar of H&P            selection mechanism is based on the retrieval mechanism of
needs two different representations: one with a clause              ACT-R. Retrieval occurs as a result of selection and
external pre-nucleus when the wh-word is not the subject,           execution of a production—only one production can be
and one that is a simple clause when the wh-word is the             executed at a time—whose right-hand side provides a
subject. An incremental processor would need to project             retrieval template that specifies which type of DM chunk is
both alternatives in parallel to be able to efficiently process     eligible to be retrieved. The single, most highly activated
                                                                496

DM chunk matching the retrieval template is retrieved.                       Serial, Pseudo-Deterministic Structure
Generally, the largest DM element matching the retrieval                    Building and Context Accommodation
template will be retrieved, be it a word, multi-unit word
(e.g. “a priori”, “none-the-less”), multi-word expression            The structure building mechanism involves the serial
(e.g. “pick up”, “go out”), or larger phrasal unit.                  execution of a sequence of productions that determine how
   To see how the spreading activation mechanism can bias            to integrate the current linguistic unit into an existing
retrieval, consider the processing of “the speed” vs. “to            representation and/or which kind of higher level linguistic
speed”. Since “speed” can be both a noun and a verb, we              structure to project. These productions execute one at a time
need some biasing mechanism to establish a context                   within ACT-R, which incorporates a serial bottleneck for
sensitive preference. In these examples, the word “the”              production execution.
establishes a bias for a noun to occur, and “to” establishes a          The structure building mechanism uses all available
bias for a verb to occur (despite the ambiguity of “to” itself).     information in deciding how to integrate the current
These biases are a weak form of prediction. They differ              linguistic input into the evolving representation. The
from the stronger predictions that result from projection of         mechanism is deterministic in that it builds a single
constructions from lexical items, although in both cases the         representation which is assumed to be correct, but it relies
prediction may not be realized. In addition to setting a bias        on the parallel, probabilistic mechanism to provide the
for a noun, “the” projects a nominal construction which              inputs to this structure building mechanism. In addition,
establishes a prediction for a head, but does not require that       structure building is subject to a mechanism of context
this head be a noun. If “the” is followed by “hiking”,               accommodation capable of making modest adjustments to
“hiking” will be identified as a present participle verb since       the      evolving     representation.     Although     context
there is no noun form for “hiking” in the mental lexicon.            accommodation is part of normal processing and does not
There are two likely ways of integrating “hiking” into the           involve backtracking or reanalysis, it is not, strictly
nominal construction projected by “the”: 1) “hiking” can be          speaking, deterministic, since it can modify an existing
integrated as the head as in “the hiking of Mt. Lemmon”, or
                                                                     representation and is therefore non-monotonic.
“hiking” can project a modifying structure and set up the
                                                                         Context accommodation makes use of the full context to
expectation for a head to be modified as in “the hiking
shoes”. Since it is not possible to know in advance which            make modest adjustments to the evolving representation or
structure will be needed, the model must chose one and be            to construe the current input in a way that allows for its
prepared to accommodate the alternative (accommodation               integration into the representation. It allows the processor to
may involve parallel projection of the alternative). Based on        adjust the evolving representation without lookahead,
history of use (derived from the Corpus of Contemporary              backtracking or reanalysis, and limits the need to carry
American English), “hiking” has a strong preference to               forward multiple representations in parallel or rely on delay
function as a nominal head, so the model initially treats            or underspecification in many cases.
“hiking” as the head and accommodates “shoes” in the same                We have already seen an example of accommodation via
way as noun-noun combinations (discussed below). This is             construal (e.g. “the hiking of Mt. Lemmon” where “hiking”
in contrast to adjectives which have a strong preference to          is construed objectively even though it is a present participle
function as modifiers in nominals. Adjectives project a              verb). As an example of accommodation via function
structure containing a pre-head modifying function and               shifting, consider the processing of “the airspeed
head, with the adjective integrated as the modifier and a            restriction”. When “airspeed” is processed, it is integrated as
prediction for a subsequent head to occur.                           the head of the nominal projected by “the”. When
   Although the parallel, probabilistic mechanism considers          “restriction” is subsequently processed, there is no
multiple alternatives in parallel, the output of this parallel       prediction for its occurrence. To accommodate “restriction”,
mechanism is a single linguistic unit. For motivation at the         “airspeed” must be shifted into a modifying function to
lexical level, consider the written input “car”. Although this       allow “restriction” to function as the head. This function
input may activate lots of words in memory, ultimately, the          shifting mechanism can apply iteratively as in the
single word “car” is brought into the focus of attention             processing of “the pressure valve adjustment screw” where
(retrieved from memory and put in the retrieval buffer in            “screw” is the ultimate head of the nominal, but “pressure”,
ACT-R terms). If instead, the input is “carpet” or                   “valve” and “adjustment” are all incrementally integrated as
“carpeting”, a single, but different, word enters the focus of       the head prior to the processing of “screw”. Note that at the
attention. If “car” were initially retrieved during the              end of processing it appears that “pressure”, “valve” and
processing of “car…” (perhaps more likely in the case of             “adjustment” were treated as modifiers all along, giving the
spoken input), then it is simply overridden in the focus of          appearance that these alternatives were carried along in
attention if the input turns out to be “carpet”. Likewise for        parallel with their treatment as heads.
“carpet…” if it turns out to be “carpeting”. The processing              At a lower level, there are accommodation mechanisms
of “carpeting” does not lead to “car”, “carp”, “pet”, and            for handling conflicts in the grammatical features associated
“carpet” all being available in the focus of attention along         with various lexical items. For example, the grammatical
with “carpeting” (although these words may all be activated          number feature singular is associated with “a” and the
in DM). The single word that is most consistent with the             number feature plural is associated with “few” and “pilots”.
input enters the focus of attention.                                 In “a few pilots”, the singular feature of “a” is overridden
                                                                 497

by the plural feature of “few” and “pilots” and the nominal         head. There are two mechanisms for achieving this within
is plural overall (Ball, 2010).                                     the constraints of ACT-R. The first approach involves
   The preceding text argued for a parallel mechanism for           parallel projection of the structure needed to support the
selecting between competing structures combined with a              accommodation at the time “airspeed” is processed. The
serial mechanism for building structure given the parallel          second approach involves projection of the needed structure
selection. The architectural mechanism which supports               at the processing of “restriction”. In the first approach, the
selection is ACT-R’s DM retrieval mechanism which                   processing of “airspeed” leads to its integration as the head
returns a single structure. However, is it always the case that     of the nominal projected by “the”. In parallel, a structure
the input to the serial, structure building mechanism is a          which supports both a pre-head modifier and head is
single structure? Just & Carpenter (1992) provide evidence          projected and made separately available. When “restriction”
that good readers (among CMU subjects) can maintain two             is processed, the initial integration of “airspeed” as the head
alternative (syntactic) representations of ambiguous inputs         of the nominal is overridden by this alternative structure.
in parallel during the processing of sentences which may            Within this structure, “airspeed” is shifted into the
contain a dispreferred reduced relative clause (e.g. “the           modifying function and “restriction” is integrated as the
experienced soldiers warned about the dangers conducted             head. In ACT-R, this is accomplished in a single
the midnight raid” vs. “the experienced soldiers warned             computational step via execution of a production which
about the dangers before the midnight raid”), whereas less          makes the needed adjustments. In the second approach,
good readers are limited to a single representation. So long        when “restriction” is processed in the context of “the
as the preferred representation at the verb (i.e., the main         airspeed”, a structure with a pre-head modifier function, in
verb reading) is ultimately correct, less good readers do well      addition to a head, is projected. “Restriction” is integrated
relative to good readers. But if the preferred representation       as the head of this structure and “airspeed” is shifted into
at the verb is incorrect for a given input, less good readers       the modifying function. This new structure then overrides
do significantly worse than good readers at the point of            “airspeed” as the head of the nominal. Within ACT-R, the
disambiguation (i.e. less good readers are garden-pathed).          second approach requires an additional computational step
However, according to the authors, “maintaining the                 relative to the first approach. It is not possible to project the
multiple representations of a syntactic ambiguity is so             needed structure—which requires creation or retrieval of a
demanding that it produces a performance deficit, which is          DM chunk—and integrate that structure into another
shown only by the good readers” (ibid, p. 131). Good                structure in a single procedural step. To avoid this extra
readers are slower on ambiguous inputs vs. unambiguous              computational step and bring the model into closer
inputs—e.g. “the soldiers warned...” vs. “the soldiers              alignment with adult human reading rates (Freiman & Ball,
spoke…”—relative to less good readers.                              2010), the model adopts the first approach. The rapidity
   Reduced relative clauses are special constructions which         with which humans process language (200-300 wpm for
have generated a large amount of psycholinguistic research.         fluent adult readers) suggests that humans can learn to
Bever‟s (1970) famous example of a garden-path “The                 buffer needed info for efficiency. However, the most
horse raced past the barn fell” stumps even good readers.           efficient processor would project just enough structure to
Garden-path effects are explained as a disruption of normal         handle the actual input—minimizing the need to create or
processing requiring introduction of reanalysis mechanisms.         retrieve, and maintain alternative structures.
Such disruption should not occur if competing alternatives             If the alternative structure that is projected by a noun
are available in parallel. Other types of garden-path inputs        supports both a pre- and post-head modifier, then post-head
exist. A classic example is “the old train the young” (Just &       modifiers can also be accommodated. For example, in “the
Carpenter, 1987). The garden-path effect after “train”              book on the table”, if integration of “book” as the head of
suggests that readers make a strong commitment to use of            the nominal projected by “the” occurs in parallel with
“train” as a noun and do not have parallel access to the            projection of a structure with a prediction for a post-head
strongly dispreferred verb use during normal processing of          modifier, then this structure can override the treatment of
this simple sentence. It is especially revealing that the           “book” as the head when a post-head modifier like “on the
garden-path effect occurs immediately after the processing          table” occurs. The primary alternative is to have the post-
of “train”, implying severe limits on parallel structures.          head modifier project the structure needed to accommodate
   However, there are examples of the need for parallelism          both the head and the post-head modifier, and then override
in structure building which have small but cumulative               the previous head. Within ACT-R, this latter approach
effects on normal processing (Freiman & Ball, 2010). Such           requires an extra computational step and is less efficient.
examples provide evidence for a mechanism like context                 As another example of the need for context
accommodation combined with a limited capacity to                   accommodation in an incremental HLP, consider the
maintain multiple structures in parallel for efficiency.            processing of ditransitive verb constructions. Given the
   We have already briefly discussed the example “the               input “he gave the…”, the incremental processor doesn‟t
airspeed restriction” where it was suggested that the               know if “the” is the first element of the indirect or direct
processing of “restriction” causes “airspeed” to be shifted         object. In “he gave the dog the bone”, “the” introduces the
into a modifying function to allow “restriction” to be the          indirect object, but in “he gave the bone to the dog”, it
                                                                498

introduces the direct object. How does the HLP proceed?              a model that predicted only one or the other of the two
Delay is not a generally viable processing strategy since the        primary alternatives. However, unlike a model where one
amount of delay is both indeterminate and indecisive as              alternative is selected and may turn out to be incorrect,
shown by:                                                            necessitating retraction of the alternative, there is no need to
                                                                     retract any structure when all three elements are
      1.  he gave the very old bone to the dog
                                                                     simultaneously predicted, although it is necessary to allow
      2.  he gave the verb old dog the bone
                                                                     for a prediction to be left unsatisfied and for the function of
      3.  he gave the very old dog collar to the boy
                                                                     the nominals to be accommodated given the actual input.
      4.  he gave the old dog on the front doorstep to me
                                                                        The processing of ditransitive verbs is complicated
In 1, the inanimacy of “bone”, the head of the nominal,              further within a relative clause construction which contains
suggests the direct object as does the occurrence of “to the         an implicit complement (either the object or indirect object)
dog” which is the prepositional form of the indirect object,         that is bound to the nominal head. Consider
called the recipient in the model. In 2, the animacy of “dog”
                                                                          5.   the booki that I gave the man obji
in the first nominal, and the inanimacy of “bone” in the
                                                                          6.   the mani that I gave iobji the book
second nominal suggest the indirect object followed by the
                                                                          7.   the mani that I gave the book to obji
direct object. Delaying until the head occurs would allow
the animacy of the head to positively influence the                  In 5, “book” is bound to the object of “gave” within the
integration of the nominal into the ditransitive construction        relative clause based on the inanimacy of “book”. In 6,
in these examples. However, in 3, the animacy of “dog” also          “man” is bound to the indirect object of “gave” based on the
suggests the indirect object, but “dog” turns out not to be the      animacy of “man”. Note that animacy is the determining
head. In 4, the animacy of “dog” which is the head, suggests         factor here. There is no structural distinction to support
the indirect object, but this turns out not to be the case given     these different bindings. These bindings are established at
the subsequent occurrence of the recipient “to me”. There            the processing of “gave” without delay when the ditransitive
are just too many alternatives for delay to work alone as an         structure is first projected. In 7, “man” is initially bound to
effective processing strategy. Although there are only two           the indirect object, but this initial binding must be adjusted
likely outcomes—indirect object followed by direct object            to reflect the subsequent occurrence of “to” which indicates
or direct object followed by recipient—which outcome is              a recipient phrase even though no object follows the
preferred varies with the current context and no alternative         preposition.
can be completely eliminated. And there is also a                       Things get even more interesting if we combine a
dispreferred third alternative in which the direct object            ditransitive verb construction with a wh-question and
occurs before the indirect object as in “he gave the bone the        passive construction. Consider
dog”. In the model, ditransitives are handled by projecting
                                                                          8.   whati could hej have been given iobjj obji
an argument structure from the ditransitive verb which
predicts a recipient in addition to an indirect and direct           In this case, neither the object nor indirect object of “given”
object (this might be viewed as a form of                            occurs in canonical position within the ditransitive verb
underspecification). Although it is not possible for all three       construction. In this example, the wh-focus “what” is bound
of these elements to occur together, it is also not possible to      to the object, and the subject “he” is bound to the indirect
know in advance which two of the three will be needed. So            object. Again, the inanimacy of “what” and the animacy of
long as the model can recover from an initial mistaken               “he” are the determining factors.
analysis without too high a cost, early integration is to be            As a final example, consider the processing of the
preferred. Currently, the model projects a nominal from              ambiguous word “to”. Since “to” can be both a preposition
“the” following the ditransitive verb and immediately                (e.g. “to the house”) and a special infinitive marker (e.g. “to
integrates the nominal as the indirect object of the verb.           speed”) it might seem reasonable to delay the processing of
Once the head of the nominal is processed, if the head is            “to” until after the processing of the subsequent word.
inanimate, the nominal is shifted to the direct object. If the       However, “to” provides the basis for biasing the subsequent
first nominal is followed by a second nominal, the second            word to be an infinitive verb form (e.g. “to speed” vs. “the
nominal is integrated as the direct object, shifting the             speed”) and if its processing is delayed completely there
current direct object into the indirect object, if necessary.        will be no bias. How should the HLP proceed? If the context
This argument shifting is in the spirit of “slot bumping” as         preceding “to” is sufficiently constraining, “to” can be
advocated by Yorick Wilks (p.c.). If the first nominal is            disambiguated immediately as when it occurs after a
followed by a recipient “to” phrase, the first nominal is            ditransitive verb (e.g. “He gave the bone to…”). Lacking
made the direct object, if need be. If the first nominal is          sufficient context, “to” can set a bias for an infinitive verb
inanimate and made the direct object and it is followed by a         form to follow even though the processing of “to” is itself
second nominal that is animate, the second nominal is                delayed until after the next word is processed. This is the
integrated as the indirect object. It is important to note that      default behavior of the model. However, the model also
the prediction of all three elements by the ditransitive verb        supports the recognition of multi-word units using a
supports accommodation at no additional expense relative to          perceptual span for word recognition that can overlap
                                                                 499

multiple words (Freiman & Ball, 2010). With this                       Ball, J., Freiman, M., Rodgers, S. & Myers, C. (2010). Toward a
perceptual span capability, an expression like “to speed” can            Functional Model of Human Language Processing. Proceedings
be recognized as a multi-word infinitival unit and the                   of the 32nd Annual Meeting of the Cognitive Science Society.
processing of “to” need not be delayed in this context.                Bever, T. (1970). The cognitive basis for linguistic structures. In J.
                                                                         Hayes (Ed.), Cognition and the development of language (pp.
Similarly, “to the” can be recognized as a prepositional                 279-362). New York: Wiley.
phrase lacking a nominal head. Although not typically                  Boden, M. (2006). Mind as Machine: A History of Cognitive
considered a grammatical unit in English, “to the” is                    Science, 2 vols. Oxford: Oxford University Press.
grammaticalized as a single word form in some romance                  Crocker, M. (2005). Rational models of comprehension:
languages and its frequent occurrence in English suggests                addressing the performance paradox. In A. Culter (Ed), Twenty-
unitization. The perceptual span is roughly equivalent to                First Century Psycholinguistics: Four Cornerstones. Hillsdale:
having a limited lookahead capability. Overall, the                      LEA.
processing of “to” encompasses a range of different                    Culicover, P. (2009). Natural Language Syntax. NY: Oxford.
mechanisms that collectively support its processing. Some              Culicover, P. & Jackendoff, R. (2005). Simpler Syntax. NY:
of these mechanisms are specific to “to”, and others are                 Oxford.
                                                                       Davies, M. (2011). Corpus of Contemporary American English
more general.
                                                                         (COCA). http://corpus.byu.edu/coca/
                                                                       Freiman, M. & Ball, J. (2010). Improving the Reading Rate of
                Summary & Conclusions                                    Double-R-Language. In D. D. Salvucci & G. Gunzelmann
This paper proposes, empirically motivates and describes                 (Eds.), Proceedings of the 10th International Conference on
the implementation of a pseudo-deterministic model of                    Cognitive Modeling (pp. 1-6). Philadelphia, PA: Drexel
HLP. The use of the term pseudo-deterministic reflects the               University.
                                                                       Gibson, E., & Pearlmutter, N. (1998). Constraints on sentence
integration of a parallel, probabilistic activation and
                                                                         comprehension. Trends in Cognitive Sciences, 2(7), 262-268.
selection mechanism, and non-monotonic context                         Huddleston, R. & Pullum, G. (2002). The Cambridge Grammar of
accommodation mechanism (with limited parallelism), with                 the English Language. NY: Cambridge University Press.
what is otherwise a serial, deterministic processor. The               Huddleston, R. & Pullum, G. (2005). A Student’s Introduction to
serial mechanism proceeds as though it were deterministic,               English Grammar. NY: Cambridge University Press.
but accommodates the changing context, as needed, without              Jackendoff, R. (2002). Foundations of Language, Brain, Meaning,
backtracking and with limited parallelism, delay and                     Grammar, Evolution. NY: Oxford.
underspecification. The overall effect is an HLP which                 Joshi, A. (1987). Introduction to Tree Adjoining Grammars. In A.
presents the appearance and efficiency of deterministic                  Manaster-Ramer (ed). Mathematics of Language. Amsterdam:
                                                                         John Benjamins.
processing, despite the rampant ambiguity which makes
                                                                       Just, M. & Carpenter, P. (1987). The Psychology of Reading and
truly deterministic processing impossible.                               Language Comprehension. Boston: Allyn and Bacon, Inc.
                                                                       Just, M. & Carpenter, P. (1992). A Capacity Theory of
                          References                                     Comprehension: Individual Differences in Working Memory.
Altmann, G. (1998). Ambiguity in sentence processing. Trends in          Psychological Review, 99 (1), 122-149.
   Cognitive Sciences, 2(4), 146-152.                                  Langacker, R. (1987, 1991). Foundations of Cognitive Grammar,
Altmann, G. & Mirkovic, J. (2009). Incrementality and Prediction         Vols 1 & 2. Stanford: Stanford University Press.
   in Human Sentence Processing. Cognitive Science, 222, 583-          Marcus, M. 1980. A Theory of Syntactic Recognition for Natural
   609.                                                                  Language. Cambridge, MA: The MIT Press.
Altmann, G., & Steedman, M. (1988). Interaction with context           McClelland, J., & Rumelhart, D. (1981). An interactive activation
   during human sentence processing. Cognition, 30, 191-238.             model of context effects in letter perception: I. An account of
Anderson, J. (2007). How Can the Human Mind Occur in the                 basic findings. Psychological Review, 88(5), 375-407.
                                                                       Paap, K., Newsome, S., McDonald, J., & Schvaneveldt, R. (1982).
   Physical Universe? NY: Oxford University Press.
                                                                         An Activation-Verification Model of Letter and Word
Ball, J. (2007a). Construction-Driven Language Processing. In S.
                                                                         Recognition: The Word-Superiority Effect. Psychological
   Vosniadou, D. Kayser & A. Protopapas (Eds.) Proceedings of
                                                                         Review, 89, 573-594.
   the 2nd European Cognitive Science Conference, 722-727. NY:
                                                                       Sag, I. (2010). Signed-Based Construction Grammar, An Informal
   LEA.
                                                                         Synopsis. In Boas, H. & Sag, I. (Eds.) Signed-Based
Ball, J. (2007b). A Bi-Polar Theory of Nominal and Clause
                                                                         Construction Grammar. Stanford: CSLI.
   Structure and Function. Annual Review of Cognitive Linguistics,     Tanenhaus, M., Spivey-Knowlton, M., Eberhard, K., & Sedivy, J.
   5, 27-54.                                                             (1995). Integration of visual and linguistic information in
Ball, J. (2010). Projecting grammatical features in nominals:            spoken language comprehension. Science, 268(5217),1632-
   Cognitive     Processing      Theory    and     Computational         1634.
   Implementation. Proceedings of the 19th Behavior                    Vosse, T. & Kempen, G. (2000). Syntactic structure assembly in
   Representation in Modeling and Simulation Conference.                 human parsing: a computational model based on competitive
Ball, J., Heiberg, A. & Silber, R. (2007). Toward a Large-Scale          inhibition and a lexicalist grammar. Cognition 75, 105-143.
   Model of Language Comprehension in ACT-R 6. In R. Lewis,            Wilks, Y. (1975). A Preferential Pattern-Seeking Semantics for
   T. Polk & J. Laird (Eds.) Proceedings of the 8th International        Natural Language Inference. Artificial Intelligence 6: pp 53-74.
   Conference on Cognitive Modeling. 173-179. NY: Psychology
   Press.
                                                                   500

