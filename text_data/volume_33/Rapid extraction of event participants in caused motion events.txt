UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Rapid extraction of event participants in caused motion events.
Permalink
https://escholarship.org/uc/item/1z6685vb
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Wilson, Frances
Papafraou, Anna
Bunger, Ann
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                               Powered by the California Digital Library
                                                                University of California

                Rapid Extraction of Event Participants in Caused Motion Events
                                          Frances Wilson (fwilson@psych.udel.edu)
                     Department of Psychology, 108 Wolf Hall, University of Delaware, Newark, DE 19716
                                      Anna Papafragou (papafragou@psych.udel.edu)
                     Department of Psychology, 108 Wolf Hall, University of Delaware, Newark, DE 19716
                                                 Ann Bunger (bunger@udel.edu)
                     Department of Psychology, 108 Wolf Hall, University of Delaware, Newark, DE 19716
                                        John Trueswell (trueswel@psych.upenn.edu)
              Department of Psychology, University of Pennsylvania, 3401 Walnut Street, Philadelphia, PA 19104
                           Abstract                                 extraction of individual event components is important for
                                                                    understanding how people process visual information.
  When viewing a complex event, it is necessary to identify
  and calculate the relationships between different entities in     Additionally, since these event roles correspond fairly
  the event. For example, when viewing a caused motion              straightforwardly to linguistic information (“thematic
  event (e.g. a man raking leaves into a basket.), people need      roles;” see Dowty, 1991; Koenig Mauner & Bienvenue,
  to identify the Agent (man), the affected object or Patient       2003; Henderson & Ferreira, 2004), the processes
  (leaves), the Instrument (rake) and the Goal (basket). In         underlying non-linguistic event apprehension can be
  this paper we explore how this process of event                   informative about theories of how people produce,
  apprehension proceeds using eye-tracking methodology.             understand and acquire language. However, the field has
  Our study indicates that viewers extract event components         only begun to investigate the question of how humans
  rapidly, but some components can be extracted faster than
                                                                    succeed in parsing ongoing events.
  others. Moreover, there is a structure to saccade patterns
  when participants are asked to identify specific event                 In an early study of event apprehension, Griffin and
  components. In caused motion events, attention is allocated       Bock (2000) examined eye-movements to a still image
  to the Patient during the early stages of processing even         depicting an event with two animate participants (e.g. a
  when the Patient is not the target. We discuss implications       woman shooting a man). When participants freely
  of this work for how people perceive complex events.              inspected the image, they showed a preference for fixating
  Keywords: spatial cognition; event perception; thematic           Patients over Agents after 1300ms of inspection. But
  roles; eye-tracking                                               when participants were instructed to find the event
                                                                    Patient, fixations to the Agent and Patient began to
                       Introduction                                 diverge early, after approximately 300ms. These findings
                                                                    suggest that Patients can be identified rapidly, and are
Perceiving and understanding events in the world is an              allocated attention after initial scene processing.
important part of human cognition. Visual input is highly                Webb, Knott and MacAskill (2010) extended Griffin
complex, and yet people are able to rapidly extract                 and Bock’s study to “reach-to-grasp” actions, using video
information about the basic level category of a scene (e.g.         presentation of a human agent reaching to grasp an
a highway scene) as well as objects within a scene (e.g.            inanimate object (e.g. a green building block). Unlike
Biederman, 1995; Oliva & Torralba, 2001; Oliva,                     Griffin and Bock, they found that participants made early
Torralba, Castelhano & Henderson, 2003; Potter, 1975).              fixations to human agents. However, as the authors
In addition, when we view a scene or event we need to               acknowledge, it is not clear whether these findings show
determine the relations that exist between different                an early preference for looks to Agents or simply to
elements in the scene or different event participants. For          moving, animate entities, which are known to attract
instance, when we see a man hitting a ball, we need to              attention (Abrams & Christ, 2003). Despite this
conceptualize the causer of the event (or Agent—here the            limitation, this study does show a temporal structure in
man) and the entity directly affected by the action (the            attention to event components, with attention starting with
Patient—here the ball). More complex representations of             the origin of the action (the Agent), then moving to the
the event may include the Instrument used for hitting and           anticipated location of the Patient. However, it is not clear
the Goal or destination of the moving ball. Identifying             whether this finding would generalize to events where
both the types of event components that viewers are able            there are no disparities of animacy and motion.
to extract from dynamic events and the time course of
                                                                1206

     Using a rapid presentation of scenes, Dobel,               this is the case, then we would expect participants to
Gumnior, Bölte and Zwitserlood (2007) showed that               saccade directly to the target event component, with no
information about the relationships between event               systematic pattern of prior fixations. Another possibility is
components can be extracted rapidly. In scenes that             that, even if extraction of event components is generally
depicted an Agent, a Patient and a Goal/Recipient (such         rapid, it might not be equally rapid for all event
as an archer shooting an arrow to a target), judgments          components. On the basis of Griffin and Bock’s (2000)
about the coherence of the scene were made accurately           data, which found that attention is directed towards the
even at very short presentations of, e.g. 100ms. At             Patient more than the Agent, we might expect the Patient
presentation durations of 250-300ms the Agents were             role to be easier to identify than other components, and
named more accurately than the Goals (approx. 75% vs.           see early fixations on the Patient in all conditions. This
60%), again suggesting that Agents may be privileged            possibility is supported by evidence from other domains.
over other event components. Patients were named less           Linguistic evidence suggests that different event
accurately, but it is possible that this was due to the         components are not accorded the same status (Koenig,
relatively small size of the Patients relative to the other     Mauner & Bienvenue, 2003). Verb arguments are
event components. Dobel and colleagues concluded that           typically considered to be part of the lexical entry for a
such rapid apprehension of scene coherence suggests that        verb, and thus obligatory, while adjuncts are optional.
roles within an event can be assigned without fixation on       Boland and Boehm-Jernigan (1998) provide evidence that
the relevant area of the scene. However, since the decision     arguments are read faster than adjuncts, suggesting that
about scene coherence was made after stimulus                   arguments and adjuncts are distinguished by the sentence
presentation, it is possible that subsequent processing         processor. Agents and Patients are usually encoded as
based on the representation of the scene in visual memory       verb arguments, while Instruments are typically accorded
allowed accurate judgements, rather than processing             adjunct status (Boland, 2005). The status of Goals with
during stimulus presentation.                                   respect to the argument/adjunct distinction is less clear:
                                                                while they are required by the subcategorization frames of
                     Current Study                              certain verbs (e.g. put), they show variability with respect
Here we report an eye-tracking experiment that examines         to the preposition used, in contrast to the prototypical
the relation between event components, and the role they        prepositional argument taken by dative verbs (e.g. show
play in building a representation of an event. Unlike prior     this to Simon) (Tutunjian & Boland, 2008). If the non-
studies that have used relatively simple events, often with     linguistic processing of event components reflects the way
only an Agent and a Patient, our study focuses on caused        in which they are encoded linguistically, then we might
motion events in which an animate Agent uses a tool or          expect that Patients are identified more easily than Goals,
body part (Instrument) to move an inanimate object              and Goals more easily than Instruments.
(Patient) towards an inanimate target or destination
(Goal). We adapted Griffin and Bock’s “Find the Patient”                                  Method
paradigm and asked viewers to rapidly identify and fixate
each of the four event components present in the event.         Participants
By examining the speed at which event components can
be identified and the pattern of fixations made before          Forty undergraduate students from the University of
fixating the target object, we hoped to determine the           Delaware participated for class credit (Mean age =19;1).
relationship between individual event components as
event representations are assembled.                            Materials
   We were particularly interested in comparing event role      Eighteen test pictures were created using clip art images.
apprehension for the three non-Agent roles (Patients,           The pictures depicted caused motion events, such as a
Goals and Instruments). (Agents in our study were always        man using a rake to rake leaves into a basket (e.g. Fig. 1).
animate and therefore conflated animacy and agency.)            The Agent of each action was always an adult human, and
Our study asked whether these event components can be           the pictures always included an object affected by the
identified by viewers equally rapidly and/or                    action (the Patient) (e.g. the leaves) and a Goal or
independently from one another. There are at least two          destination for the action (e.g. the basket). The Instrument
possibilities about how such event roles are extracted          used to perform the action was either a tool (such as a
from caused motion sequences. According to Dobel and            rake) or a body part (such as a foot used for kicking).
colleagues (2007), information about event roles can be
extracted in the earliest stages of scene presentation. If
                                                            1207

                                                                  were seated approximated 60cm from the screen. The
                                                                  experiment took approximately 5-10 minutes.
                                                                                             Results
                                                                  Coding
                                                                  In each scene, four Areas of Interest (AOIs) were defined
                                                                  (Agent, Patient, Instrument, Goal) using the Tobii Studio
                                                                  AOI tool. AOIs did not overlap. In cases where the Agent
                                                                  was holding an Instrument, the Agent AOI was defined as
                                                                  the area of the Agent’s torso and head, and the Instrument
                                                                  as the tool or Instrument itself, as well as the hand and
                                                                  wrist of the Agent. Trials with greater than 30% trackloss
                                                                  were excluded from the analysis (approx. 1.3%)
                 Figure 1 Example Test Item.                      Analysis
                                                                  Figures 2-5 show the proportion of fixations to each event
An additional set of 18 caused motion events were used as         component in each condition. In the Agent condition (Fig.
fillers. Filler items alternated with experimental items.         2), we see early looks to the Agent (at around 120ms) and
Two pictures depicting frogs were created for display             little consideration of other event components. In the
after each experimental item and filler to encourage              Patient condition (Fig. 3), looks to the Patient diverge
participants to make eye-movements around the screen.             early (at around 150ms) from looks to the Goal and
Participants were randomly assigned to one of two orders          Instrument, and later (at around 250ms) they diverge from
of the stimuli, one the reverse of the other.                     looks to the Agent. In the Goal condition (Fig. 4), looks to
                                                                  the Goal diverge at around 300ms. In the Instrument
Procedure                                                         condition (Fig. 5), we see an early peak of looks to the
Participants were told that they would see pictures               Patient before looks to the Instrument diverge (at around
depicting an action or event. Each participant was                250ms).
randomly assigned to one of four conditions. In the Agent            To assess the reliability of these findings, we calculated
condition, participants were told to look as quickly as           the proportion of looks to each event component during
possible at “the person or animal who was performing the          four 200ms time windows, starting from the onset of the
action,” and to press the space bar as soon as they were          stimulus. Because proportion data can sometimes violate
doing so. In the Instrument condition, participants were          assumptions of linear statistical models, we first
given the same instruction but told to look at “the tool or       transformed the proportion data to elogit values following
body part used to make the action.” In the Goal condition,        a procedure outlined in Barr (2008). The elogit data were
participants were told to look at “the goal or destination of     then analyzed using multi-level linear modelling with
the action,” and in the Patient condition, participants were      crossed random intercepts for subjects and items (see
instructed to look at “the object directly affected by the        Baayen, Davidson and Bates, 2008 for discussion). The
action.” Every participant saw a practice picture (an             model contained a single fixed effect of Condition with
archer firing an arrow at a target) in which the target item      four levels (Agent, Goal, Instrument and Patient search).
relevant to their condition was highlighted. Before each of       The dependent variable was elogit looking time to the
the 36 pictures (18 experimental items and 18 fillers),           target1 (i.e. Agent in the Agent condition, Patient in the
participants were instructed to fixate a cross located at the     Patient condition, etc.). The lme4 package in the statistical
top of the screen in the center, and to press the space bar       package R, which we used to conduct the analyses, shows
when they were fixating it. After each picture, participants      the estimates for each level of the fixed factor relative to a
viewed one of two pictures (randomly selected) depicting          base level and provides comparisons of each level of the
two frogs for 3000ms. Participants’ eye-movements were            factor to the base level. For example, using Agent as the
tracked using a Tobii T60 eye-tracker. At the start of the        base level, the model would give us the comparison
experiment, participants’ eye-movements were calibrated           between the Agent and the Goal, the Agent and the
using a five-point calibration procedure, in which they
followed a red dot which moved to the four corners of the         1
                                                                    Since looks to event components within a condition are
screen and then to the center of the screen. If calibration
                                                                  negatively correlated, and thus not independent, we
was incomplete, the procedure was repeated. Typically
                                                                  compared looks to specific event components across
participants required only one calibration. Participants
                                                                  conditions.
                                                              1208

Instrument, and the Agent and the Patient. However, we           conditions. In time window 2 (200-400ms), there were
were also interested in contrasts between the other levels       more looks to the target in the Agent condition than in all
of the Condition, e.g. between the Instrument and the            other conditions (Instrument: t=-2.131, p<0.05, Goal:
Goal. To obtain these contrasts we changed the base level        t=3.585, p<0.05, Patient: t=-2.131, p<0.05). After rotating
of the model. For example, changing the base level to the        the base level, both the Patient (t=-3.013, p<0.05) and
Goal, we obtained the contrast between the Goal and the          Goal (t=-2.151) conditions showed more looks to the
Instrument, the Goal and the Patient, and the Goal and the       target than the Instrument condition during time window
Agent. By rotating the base level to each of the four levels     2 (p<0.05). Together, these results suggest that
of the factor Condition we were able to obtain all possible      successfully finding an Agent occurred more quickly than
contrasts.                                                       finding any of the other event components; furthermore,
  In time window 1 (0-200ms), there were more looks to           finding a Goal or a Patient occurred more quickly than
the target in the Agent condition than in the Instrument         finding an Instrument. In the third (400-600ms) and fourth
condition (t=-2.339, p<0.05), but no other significant           (600-800ms) time windows, there were no significant
differences between looks to the target in the other             differences between conditions. Overall, these results
     Figure 2 Looks to event components in the Agent                  Figure 4: Looks to event components in the Goal
                        condition.                                                       condition.
    Figure 3: Looks to event components in the Patient             Figure 5: Looks to event components in the Instrument
                        condition.                                                       condition.
                                                             1209

suggest that event components can be identified rapidly,          condition are due to the relatively small sizes of each of
but point to asymmetries among different event roles.             these event components (3.5% and 3.6% of image area),
   Could these asymmetries be due to differences in size          which might have led participants to look around the
between AOIs corresponding to individual event                    scene to find the target. However, if this were the case,
components? To preserve scene plausibility, size of event         then we would expect to see more looks to the Instrument
components in our stimuli was not controlled for, and             in the Patient condition, which we do not. Additionally,
overall, Goals were larger than Agents, which were larger         we would not expect to see additional looks to the Patient
than both Instruments and Patients: paired t-tests                in the Goal condition. We consider plausible explanations
confirmed that there were significant differences in size         of such looks to the Patient below.
(as measured as a percentage of image area using the
Tobii Studio AOI tool) between Goal and Patient (t(17)=-                                  Discussion
6.77, p<0.0001), Goal and Instrument (t(17)=-6.14,
                                                                  This study sought to investigate the processing of event
p<0.0001), Goal and Agent (t(17)=-5.05, p<0.0001),
                                                                  components in a “Find the X” task. In contrast to previous
Instrument and Agent (t(17)=-2.160, p<0.05) and Patient
                                                                  work in this area, which has mostly investigated the
and Agent (t(17)=--3.41, p<0.01). Crucially, however,
                                                                  relation between Agents and Patients, we advanced the
there was no significant difference in size between the
                                                                  empirical domain of inquiry by examining the relations
Patient and Instrument (3.5% vs 3.6% of image area), so it
                                                                  between Patients, Goals and Instruments. Our study
does not seem likely that the difference in speed of
                                                                  reveals three major conclusions. Firstly, consistent with
identification between Patients and Instruments is due to
                                                                  the findings of Dobel et al. (2007), we observed that event
differences in area. Furthermore, although Goal AOIs
                                                                  components could be identified rapidly and accurately
were bigger, on average, than Patient AOIs, we do not see
                                                                  (although participants were only able to saccade directly
a difference in speed of identification between Goals and
                                                                  to the target in the Agent condition, where it is probable
Patients. Finally, and most importantly, the time taken to
                                                                  that participants were relying on animacy cues). Secondly,
fixate the Goal, Instrument or Agent did not correlate with
                                                                  we discovered asymmetries between event components:
AOI size. Only in the Patient condition was a significant
                                                                  not all event components were identified with equal
negative correlation observed (r=-.508, n=18, p<0.031),
                                                                  speed. Consistent with Griffin and Bock (2000), we found
indicating that smaller Patients were fixated slightly later.
                                                                  that Patients were identified particularly rapidly.
We discuss alternative explanations for the differences
                                                                  Furthermore, we found that Instruments were identified
between identification of event components in the general
                                                                  more slowly than either Patients and Goals. Our data
Discussion below.
                                                                  support the hypothesis that roles typically encoded as
   Our initial analysis indicated that the conditions
                                                                  arguments in language (e.g. Patients) are identified more
differed most in time window 2. To determine whether
                                                                  quickly than those typically identified as adjuncts (e.g.
there were early fixations on individual event
                                                                  Instruments). The fact that Goals are identified just as
components, we compared looks to each of the event
                                                                  quickly as Patients even though Goals are not prototypical
components across conditions in time window 2, using the
                                                                  arguments may be related to the high salience of Goals
same model selection procedure as in the previous
                                                                  (Lakusta & Landau, 2005; Papafragou, 2010). Although it
analysis. For Agents, Goals and Instruments, we found
                                                                  is not possible to draw firm conclusions about the relation
little variation in looks to the relevant component across
                                                                  between linguistic encoding and event components at this
conditions in which that component was not the target:
                                                                  stage, our data raise the possibility that the distinction in
Starting with Agents, looks to the Agent differed only
                                                                  language between arguments and adjuncts is a result of
between the Agent condition and each of the other
                                                                  prioritization of event components in non-linguistic
conditions (Goal, t=-10.551, Instrument, t=-9.113, Patient,
                                                                  processing.
t=-8.956, all p<0.05). Similarly, looks to the Goal differed
                                                                     A third, more tentative conclusion can be drawn
only between the Goal condition and each of the other
                                                                  regarding the role of Patients. The analysis of looks to the
conditions (Agent, t=-3.832, Instrument, t=-3.982, Patient,
                                                                  Patient component across conditions highlighted an
t=-3.755, all p<0.05). Finally, looks to the Instrument
                                                                  asymmetry between Patients and other event components.
differed only between the Instrument condition and each
                                                                  While there were no differences in looks to the Agent,
of the other conditions (Agent, t=-2.098, Goal, t=-2.144,
                                                                  Goal and Instrument in conditions in which each
Patient, t=-2.281, all p<0.05). However, there were more
                                                                  component was not the target, looks to the Patient varied
looks to the Patient in the Goal (t=4.669, p<0.05),
                                                                  across conditions. Unsurprisingly there were more looks
Instrument (t=7.327, p<0.05) and Patient (t=9.393,
                                                                  to the Patient in the Patient condition (i.e. when it was the
p<0.05) conditions than in the Agent condition. After
                                                                  target), but somewhat surprisingly, there were more looks
rotating the base level, we found that there were more
                                                                  to the Patient in the Goal condition compared to the Agent
looks to the Patient in the Instrument condition compared
                                                                  condition, and in the Instrument condition compared to
to the Goal condition (t= 2.672, p<0.05). One possibility
                                                                  the Goal condition. This result suggests that attention is
is that the increased looks to the Patient in the Instrument
                                                              1210

allocated to the Patient even when the Instrument is the         Dowty, D. (1991). Thematic proto-roles and argument
target. Why might this be so? One possibility is that the          selection. Language, 67, 547–619.
Patient is somehow more central to the event, and that           Griffin, Z., & Bock, K. (2000). What the eyes say about
identifying what has been affected by the action facilitates       speaking. Psychological Science, 11, 274–279
location of the Instrument. Furthermore, since the Patient       Henderson, J., & Ferreira, F. (eds.) (2004). The interface
is depicted as moving towards the Goal, allocation of              between language, vision and action: Eye movements
attention towards the Patient might facilitate calculation         and the visual world. New York: Psychology Press.
of the trajectory towards the Goal and identification of the     Koenig, J.-P., Mauner, G., & Bienvenue. (2003).
location of the Goal within the scene. Alternatively,              Arguments for adjuncts. Cognition, 89, 67–103.
increased looks to the Patient could be considered further       Lakusta, L., & Landau, B. (2005). Starting at the end: The
evidence for the distinction between arguments and                 importance of goals in spatial language. Cognition, 96,
adjuncts: participants may allocate attention to event             1–33.
components which are typically encoded as arguments              Oliva, A., & Torralba, A. (2001). Modeling the shape of
(such as Patients) before allocating attention to less             the scene: a holistic representation of the spatial
prototypical     arguments      (Goals)     and    adjuncts        envelope. International Journal in Computer Vision,
(Instruments). However, at this stage it is impossible to          42, 145–175.
draw firm conclusions about the precise nature of the role       Oliva, A., Torralba, A., Castelhano, M. S., & Henderson,
of Patients in the identification of other event                   J. M. (2003). Top-down control of visual attention in
components.                                                        object detection. Proceedings of the IEEE International
   To summarize, we have shown that event components               Conference on Image Processing, vol. I, 253–256.
can be rapidly and accurately identified in a scene.             Papafragou, A. (2010). Source-goal asymmetries in
However, different event components (Patient, Goal,                motion representation: Implications for language
Instrument) are not identified equally quickly, in a way           production and comprehension. Cognitive Science, 34,
that may be consistent with the linguistic distinction             1064–1092.
between arguments and adjuncts.                                  Potter, M. C. (1975). Meaning in visual search. Science,
                                                                   187, 965–966.
                   Acknowledgments                               Tutunjian, D., & Boland, J. E. (2008). Do we need a
                                                                   distinction between arguments and adjuncts? Evidence
 This research was partly supported by NIH/NICHD
                                                                   from psycholinguistic studies of comprehension.
Grant 3R01HD055498 to A.P. and J.T. Thanks to James
                                                                   Language and Linguistics Compass, 2, 641–646.
Delorme for assistance in data collection and Rick
                                                                 Webb, A., Knott, A., & MacAskill, M. R. (2010). Eye
Chalton for assistance in preparation of stimuli.
                                                                   movements during transtive action observation have
                                                                   sequential structure. Acta Psychologica, 133, 51–56.
                       References
Abrams, R., & Christ, S. (2003). Motion onset captures
   attention. Psychological Science, 14, 427–432.
Barr, D. J. (2008). Analyzing ”visual world” eyetracking
   data using multilevel logistic regression. Journal of
   Memory and Language, 59(4), 457–474.
Baayen, R. H., Davidson, D. J. & Bates, D. M. (2008),
  Mixed-effects modelling with crossed random effects
  for subjects and items. Journal of Memory and
  Language ,59(4), 390–412.
Biederman, I. (1995). Visual object recognition. In M.
   Kosslyn & D. N. Osherson, eds., An Invitation to
   Cognitive Science: Visual Cognition (2nd edition), vol.
   2.
Boland, J. E. (2005). Visual arguments. Cognition, 95,
   237–274.
Boland, J., & Boehm-Jernigan, H. (1998). Lexical
   attachments and prepositional phrase attachment.
   Journal of Memory and Language, 29, 684–719.
Dobel, C., Gumnior, H., Bölte, J., & Zwitserlood, P.
   (2007). Describing scenes hardly seen. Acta
   Psychologica, 12, 129–143.
                                                             1211

