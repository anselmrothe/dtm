UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Effects of information comprehensibility and argument type on lay recipients’ readiness
to defer to experts when deciding about scientific knowledge claims

Permalink
https://escholarship.org/uc/item/1jt439s0

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Bromme, Rainer
Scharrer, Lisa
Britt, M. Anne
et al.

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Effects of information comprehensibility and argument type on lay recipients’
readiness to defer to experts when deciding about scientific knowledge claims
Rainer Bromme (bromme@uni-muenster.de)
Institute for Psychology, University of Münster, Fliednerstrasse 21,
48149 Münster, Germany

Lisa Scharrer (lisa.scharrer@uni-muenster.de)
Institute for Psychology, University of Münster, Fliednerstrasse 21,
48149 Münster, Germany

M. Anne Britt (britt@niu.edu)
Psychology Department, Northern Illinois University, 363 Psychology-Math Building,
Dekalb, IL60115, USA

Marc Stadtler (stadtlm@uni-muenster.de)
Institute for Psychology, University of Münster, Fliednerstrasse 21,
48149 Münster, Germany

Abstract
The present study investigated whether laypersons are aware
of their own knowledge limitations when having to decide
about the acceptability of scientific knowledge claims.
Specifically, we tested whether laypeople are more prone to
discount their actual dependence on experts after having read
simplified science depictions. Lay recipients read scientific
arguments varying in comprehensibility and argument type
and thus in apparent easiness. We assessed participants’
inclination to rely on their own information evaluation rather
than to seek out expert advice when deciding about claim
acceptability. As expected, results showed lay recipients to be
more confident in their own information evaluation and less
inclined to turn to an expert for decision support after reading
easy compared to difficult depictions.
Keywords: knowledge evaluation; expertise; argument
comprehensibility; causal explanations; evidence

Introduction
Whether making up their mind about undergoing specific
medical treatment or judging if certain behaviors are
detrimental to the environment, laypeople frequently face
situations where they need to decide about the acceptability
of scientific knowledge claims. The ease of accessing
information on the Web has eliminated problems with
regards to the availability of science-related knowledge that
might act as a basis for an informed judgment. However, a
major challenge lies in the evaluation of this information,
i.e. its acceptability, usefulness and sufficiency for solving a
problem at hand (Bromme, Kienhues & Porsch, 2010).
The evaluation of scientific claims is particularly difficult
due to the complexity and tentativeness of science
knowledge, and it is therefore likely to be beyond
laypersons’ epistemic capabilities (Keil, 2008). Advances in
science and technology have led to an enormous growth of
knowledge. To manage this complexity, science knowledge

is organized into different disciplines represented by
specialized experts. Thus, throughout our whole lifetime we
remain laypersons who depend on advice of pertinent
experts regarding most topics. This uneven distribution of
knowledge in modern societies will be conceived in the
following as a ‘division of cognitive labor’ (Keil et al.,
2008). However, for the division of cognitive labor to
function successfully, laypeople must be aware of the
incompleteness and limitations of their own knowledge. In
other words, laypeople have to recognize that in certain
situations they are unable to make an informed decision
about the veracity of encountered information and instead
need to defer to an expert for advice.
The present study addresses the question of whether
laypeople are aware of the insufficiency of their own
knowledge and thus the necessity to rely on the division of
cognitive labor when having to come to an informed
decision about scientific knowledge claims. Specifically, it
was examined whether laypeople’s awareness of their own
limitations is decreased whenever scientific information is
presented in a way that makes the subject matter appear
fairly easy and uncomplicated.
Laypeople often encounter scientific information
especially prepared for their consumption, i.e. presented in a
simplified way to make the contents superficially
comprehensible for non-experts (Zimmerman et al., 2001).
However, if laypeople encounter such ‘easy’ texts, their
understanding may mislead them to judge the subject matter
as equally easy, and their mental representations of the
described phenomena formed by reading the information as
more complete and accurate than they actually are (cf.
Goldman & Bisanz, 2002). Such an impression may
manifest itself in the conviction that their knowledge and
skill does not differ meaningfully from that of an expert.
Consequentially, scientific messages that are easy to
understand might create the impression that laypeople are

2788

able to evaluate the viability of the provided information by
themselves and that deferring to an expert is an unnecessary
waste of time and energy.
The assumption that the ease of text understanding
influences readers’ confidence in their own evaluation is in
line with research on fluency. Fluency is defined as the
subjective experience of ease or difficulty when completing
a mental task, and it has been shown that fluency
experiences can serve as a basis for judgment of various
information- or task-features (Schwarz, 2004). For instance,
experienced fluency is generally connected with positive
judgments of truth and confidence in one’s own
performance (e.g. Reber & Schwarz, 1999; Alter,
Oppenheimer, Epley & Eyre, 2007). What we currently term
‘text easiness’ can actually be conceived as a type of
processing fluency. However, the influence of experienced
fluency on laypeople’s assessment of their own epistemic
capabilities in comparison to that of an expert has to our
knowledge not been investigated by previous fluency
research.

Perceived Easiness of Scientific Contents
Assuming that perceived easiness of information leads
laypeople to neglect their dependence on the division of
cognitive labor raises the question as to what characteristics
make scientific contents appear easy. We presume perceived
easiness to be influenced by at least two message attributes:
information comprehensibility and type of argument in
which information is presented to support a claim.
To date, the influence of comprehensibility and argument
type on laypeople’s readiness to evaluate science
information themselves rather than to rely on an expert
advisor has not been investigated directly. However, we
base our assumption of the impact of both factors on
previous theoretical considerations as well as empirical
findings which show comprehensibility and argument type
to affect the persuasiveness of arguments. Strong agreement
to a claim or a positive evaluation of provided arguments
should only occur if recipients feel that they are sufficiently
informed and qualified to form an opinion about the subject
matter. In contrast, if recipients do not feel competent to
assess the quality of provided information, they should be
more hesitant in their judgments and refrain from indicating
strong agreement or evaluations. Thus, previously obtained
effects of comprehensibility and argument type on
persuasiveness might at least partly result from an influence
of both factors on recipients’ readiness to make an own
decision about a claim or an argument.
Information Comprehensibility According to Chaiken and
Eagly (1976), recipients are more apt to accept claims
supported by comprehensible arguments for two reasons:
First, if the argument is not well understood recipients
receive lesser amounts of information in support of the
claim. Second, failing to understand might create feelings of
frustration among recipients, which then translate to the
claim intended to be supported. The resulting negative affect

makes it then less likely for recipients to accept the claim as
valid. This assumption has been confirmed by previous
research, which has shown comprehensible arguments to
cause stronger claim agreement among recipients compared
to arguments difficult or impossible to comprehend. This
research was mainly focused on arguments supporting a
moral claim and on arguments advertising the usefulness of
consumer products (Bradley & Meeds, 2004; Chaiken &
Eagly, 1976), but comparable findings have also been
yielded for scientific claims (Eagly, 1974). However, it
remains unclear whether the observed persuasive effect of
comprehensibility also extends to laypeople’s confidence in
their own information evaluations and thus on their reliance
on the division of cognitive labor.
Argument Type Previous research has differentiated
between two types of arguments that can support a causal
claim: ‘Explanations’ (also called ‘causal arguments’)
describe the mechanism underlying a claimed causal
connection (e.g. ‘Cholesterol increases the risk of stroke
because it blocks the blood vessels’). In contrast, ‘evidence’
(also termed ‘noncausal arguments’) supports the claim by
referring to statistical data (e.g. ‘Cholesterol increases the
risk of stroke because 74% of people suffering a stroke have
above-average cholesterol levels’) (Brem & Rips, 2000;
Sandoval & Cam, in press).
In spite of the prominent role evidence plays in empirical
science, previous literature suggests that laypeople prefer
causal arguments as epistemic justifications, possibly
because their evaluation is perceived as easier. According to
Keil (2010), individuals have a sophisticated sense for
causal relations and structure and seek out explanations.
These activities form the essence of individuals’ folk
science. Thus, laypeople may consider causal arguments as
more traceable and easier to evaluate than noncausal
arguments, since causal arguments more closely reflect the
kinds of epistemic justifications they consider in everyday
life. Consequentially, laypeople might be more prone to rely
on their own evaluations of causal arguments, whereas they
are more likely to appreciate the necessity of reverting to
experts if confronted with noncausal evidence. Laypeople
should then be more easily persuaded by causal than by
noncausal arguments. Findings by Slusher and Anderson
(1996) indeed confirm causal arguments to cause stronger
claim agreement than noncausal arguments. However, other
research comparing both argument types yielded different
results, indicating that evidence is perceived as better
argument support than explanations (Brem & Rips, 2000;
Sandoval & Cam, in press).
Hence, although theoretical considerations suggest a
persuasive advantage of causal over noncausal arguments
from a layperson’s point of view, previous research does not
consistently provide support for the assumption of causal
arguments being perceived as more traceable by laypeople
and more manageable to evaluate by themselves. A possible
explanation for the inconsistency of findings is that
argument type and comprehensibility might have been

2789

confounded in at least some studies. In cases where
noncausal arguments had been more comprehensible than
their causal counterparts, the perceived easiness of
comprehensible arguments might have outweighed the
easiness ascribed to causal arguments. In order to further
investigate whether laypeople are indeed more strongly
persuaded by causal arguments, it is necessary to assess the
influence of argument type independently from the
influence of argument comprehensibility. Moreover, and
similar to the state of affairs regarding comprehensibility, it
remains unclear whether argument type has an effect on
recipients’ confidence in their decision about information
acceptability. Thus, further research is needed to assess
whether and how argument type influences laypeople’s
readiness to rely on their own judgment rather than on the
division of cognitive labor.

The Present Research
The present study was aimed to investigate how the way
scientific information is presented influences laypeople’s
inclination to rely on their own evaluations of scientific
claims rather than to defer to an expert. We assumed that if
scientific information is presented in a way that makes it
difficult for laypeople to process, they are more likely to
realize that as non-experts they are in fact unable to
confidently decide whether the information poses a sound
argument to support a give claim.
In order to investigate this assumption, laypeople were
confronted with argumentative texts which provided support
for a causal claim and which were intended to vary in
perceived easiness. Perceived easiness was manipulated in
two ways. Firstly, the texts were either written to appear
comprehensible or clearly incomprehensible. Secondly, the
texts either supported the stated claim with an explanation
of the underlying causal mechanism (thus with information
tailored to laypersons’ familiar way of reasoning in folk
science) or with empirical evidence (thus with information
that should be less compatible with laypersons’ familiar way
of thinking).
We expected lay recipients to evaluate comprehensible
arguments as stronger (i.e. more supportive of the claim)
than incomprehensible arguments (H1) and causal
arguments as stronger than noncausal arguments (H2). We
furthermore assumed that laypeople agree more strongly to
a claim after reading comprehensible than incomprehensible
arguments (H3) and after reading causal arguments
compared to noncausal arguments (H4). With regards to
laypeople’s confidence in their own agreement decision, we
assumed that comprehensible arguments cause higher trust
in their own decision about the claim (H5) and conversely a
weaker desire to consult an expert for further decision
support than incomprehensible arguments (H6). Finally,
causal arguments should lead lay recipients to trust more
strongly in their own decision (H7) and to be less inclined to
consult an expert than noncausal arguments (H8).

Method
The study was conducted with a 2x2 repeated measures
design, the independent variables being argument
comprehensibility (comprehensible vs. incomprehensible)
and argument type (causal vs. noncausal). Each participant
was assigned to all experimental conditions in a randomized
order that varied between individuals. In each condition,
participants were asked to read an argument about a medical
topic. Thus, every recipient read four arguments in total: one
comprehensible causal, one comprehensible noncausal, one
incomprehensible causal and one incomprehensible
noncausal argument.
Eighty-eight undergraduates (52 female, mean age =
25.66 years, SD = 5.13) of different subjects at a German
university took part in the study and received 8 Euro for
their participation. To ensure participants’ lay status,
students of medicine, biology or related subjects and
students of empirical sciences, who can be assumed to be
particularly familiar with noncausal arguments, were
excluded from participation.

Materials
Expository texts about four medical issues were generated
(mean length = 80.5 words, SD = 16.46). The texts
contained concepts and relations that were derived from
real-world concepts but were imaginary to ensure that
readers were low in topic knowledge and had no strong
prior opinion about the issues. Each text consisted of an
argument that supported an issue-related causal claim (e.g.
‘A side-effect of Rethoxat is that it brings about asthma
attacks’). The claim was always stated at the beginning of
the argument, followed by information serving as claim
support. For each text, four variations were created,
analogous to the experimental conditions: In the causal
argument conditions, the claim was supported by an
explanation of the underlying mechanism and in the
noncausal argument conditions by statistical data.
Comprehensibility of both argument types was manipulated
by use of technical terms, repetition of important
information and inclusion/omission of unnecessary,
distracting detail. For instance, the sentence ‘After the intake
of Rethoxat, the agent is absorbed from the stomach into the
blood stream.’ from the comprehensible causal variation
was transformed to ‘After sublingual application of
Rethoxat, the verum is resorbed via the Tunica mucosa
gastrica into the sanguis’ in the incomprehensible causal
variation. However, comprehensibility manipulations were
only applied to the argument support, while the claim was
stated in the same wording across conditions.
Before reading each argument, participants were
confronted with a scenario in which a fictitious friend was
described as having a medical problem. The fictitious friend
was unsure whether a certain problem-related claim was
true or false and asked the participant about their opinion.
The arguments were presented as stemming from an online
source and were described as being authored by a medical

2790

expert in order to keep the social role ascribed to the source
constant between conditions.

Dependent Measures
Manipulation Check To assess whether comprehensibility
had been manipulated as intended, participants evaluated
each argument for perceived comprehensibility on a 1 to 7
scale (1: very incomprehensible, 7: very comprehensible).
Since comprehensibility might be interpreted differently by
different readers (Wiley, Griffin & Thiede, 2005),
participants were provided with a short definition of what
the experimenters meant by comprehensibility to ensure that
each participant judged the arguments by comparable
standards. This definition described information as
comprehensible when the contents are perceived as clear
and when readers feel able to discriminate essential from
less important parts and to evaluate information consistency.
Argument Strength Participants were furthermore asked to
rate the strength of each argument on a 1 to 7 scale (1: the
argument provides no support for the claim, 7: the argument
provides strong support for the claim).
Claim Agreement To assess whether argument reception
led to changes in participants’ claim acceptance, agreement
to each claim was assessed prior and subsequent to reading
the claim-supporting argument. Participants were asked to
indicate their agreement on a scale from 1 (I don’t agree at
all) to 7 (I totally agree).
Confidence in the Claim Agreement Decision
Participants’ readiness to decide about the claim was
indicated by two measures, each of which was collected
before and after participants read the argument.
(A) Trust in one’s own judgment of the claim correctness:
Before and after reading each argument, participants
indicated on a 1 to 7 scale how strongly they agreed to the
statement ‘I am confident in my own decision about whether
it is true that [claim statement inserted]’ (1: don’t agree, 7:
strongly agree).
(B) Desire to consult an expert for decision support:
Similarly, before and after argument reception, participants
were asked about their agreement to the statement ‘Before I
decide about whether it is true that [claim statement
inserted], I would like to seek further advice from an expert’
on a 1 to 7 scale (1: don’t agree, 7: strongly agree).

aforementioned variables. This was repeated four times, so
that each participant read one argument of each
experimental condition. After the described pre-and postmeasured were collected for all arguments, readers were
presented again with each argument and were asked to
evaluate its strength and comprehensibility. Participants
then completed a demographic questionnaire and were
finally debriefed about the fictitious nature of the presented
arguments.

Results
Table 1 shows the means and standard deviations of the
dependent measures for the different experimental
conditions. Medium to strong inter-correlations of the
dependent variables claim agreement, trust in own decision
and desire for expert advice show that all three measures are
significantly related but nevertheless present separate
constructs (Table 2).

Manipulation Check
A repeated measures ANOVA on comprehensibility ratings
with
the
within-subject-factors
comprehensibility
(comprehensible vs. incomprehensible) and argument type
(causal vs. noncausal) showed that as intended, arguments
designed as comprehensible were considered more
comprehensible than arguments designed to be
incomprehensible, F(1,87) = 744.05, p < .001, part. η2 = .90.
Since neither the main effect of argument type nor the
argument type*comprehensibility interaction was significant
(both F(1,87) < 1.90, ns), the manipulation check confirmed
comprehensibility to vary orthogonally to argument type.

Perceived Argument Strength
To test H1 (comprehensible arguments are perceived as
stronger than incomprehensible arguments) and H2 (causal
arguments are perceived as stronger than noncausal
arguments) we conducted a repeated measures ANOVA on
argument strength measures with comprehensibility and
argument type as within-subject-factors. As expected, lay
recipients judged comprehensible arguments as stronger
than incomprehensible arguments, F(1,87) = 11.41, p <
.001, part. η2 = .56. Furthermore, according to our
hypothesis, causal arguments were rated as stronger than
noncausal arguments, F(1,87) = 13.07, p = .001, part. η2 =
.13.

Procedure

Claim Agreement

Participants worked individually on a booklet which
contained the arguments and scales for collecting the
dependent measures. The booklet first presented participants
with a scenario in which the fictitious friend’s problem was
described. Pre-measures of participants’ claim agreement,
trust in their own judgment and desire to consult an expert
were collected. Participants then read the argument and
provided their answers to the post-measures of the

H3 (comprehensible arguments cause stronger claim
agreement than incomprehensible arguments) and H4
(causal arguments cause stronger claim agreement than
noncausal arguments) were tested by subjecting differencescores of pre-and post-measures of participants’ claim
agreement to a repeated measures ANOVA. Results showed
that in line with H3, participants’ agreement with the claim

2791

Table 1: Means and standard deviations (in brackets) for the dependent measures as a function of comprehensibility and type
of argument.
Argument condition
Compr. causal
Incompr. causal
Compr. noncausal
Incompr. noncausal

Comprehensibility

Argument
strength

6.07
(1.10)
2.14
(1.36)
6.14
(1.14)
1.92
(1.24)

5.85
(1.28)
3.93
(1.59)
5.16
(1.56)
3.50
(1.67)

Claim
agreement
pre
post
3.99
5.14
(1.08)
(1.22)
3.94
4.93
(1.01)
(1.16)
3.94
5.02
(0.99)
(1.15)
4.08
4.78
(0.91)
(1.26)

increased more strongly after reading comprehensible
compared to incomprehensible arguments, F(1,87) = 7.48, p
= .008, part. η2 = .08. In contrast to our expectations (H4),
the extent of agreement change did not differ between
argument types, F(1,87) = 2.624, ns.

Confidence in the Claim Agreement Decision
We had hypothesized laypeople to rely more readily on their
own decision about a claim after reading comprehensible
compared to incomprehensible arguments, indicated by a
higher trust in their own decision (H5) and a weaker desire
to consult an expert (H6). Conversely, causal arguments
should lead to higher levels of trust in one’s own decision
(H7) and to a weaker desire to consult an expert (H8)
compared to noncausal arguments. To test our hypotheses,
we conducted repeated measures ANOVAs on differencescores of pre-and post-ratings of trust in own decision and
desire to consult an expert.
(A) Trust in Own Agreement Decision Participants
showed a stronger increase in trust in their own decision
after they had read comprehensible compared to
incomprehensible arguments, F(1,87) = 13.271, p < .001,
part. η2 = .132, providing support for H5. Contrary to H7,
changes in trust did not differ between causal and noncausal
arguments, F(1,87) = 1.23, ns.
(B) Desire to Consult an Expert Results indicated that
laypeople‘s desire to seek out expert advice decreased
significantly stronger after reading comprehensible
arguments than after reading incomprehensible arguments,
(F(1,87) = 15.00, p < .001, part. η2 = .15), lending support

Trust in own
decision
pre
post
1.24
4.22
(0.87)
(1.87)
1.18
3.63
(0.70)
(2.03)
1.18
4.03
(0.56)
(1.85)
1.17
3.34
(0.55)
(1.93)

Desire for expert
advice
pre
post
6.65
5.72
(0.68)
(1.63)
6.55
6.16
(0.96)
(1.29)
6.77
6.00
(0.58)
(1.36)
6.55
6.25
(0.91)
(1.25)

to H6. H8 was not confirmed, since changes in desire for
expert advice did not differ between argument types, F(1,
87) = 1.08, ns.

Discussion
By confronting recipients with texts of varying easiness, the
present study investigated whether laypeople are aware of
the limitations of their own epistemic capabilities when
having to decide about scientific knowledge claims. We had
expected that laypeople would rely less on the division of
cognitive labor and thus agree more confidently and
strongly with information they consider easy than with
information that makes the subject matter appear difficult.
Results show that comprehensibility of scientific texts
clearly influences laypeople’s agreement to scientific
arguments and their reliance on the division of cognitive
labor. Participants perceived comprehensible arguments
as stronger and were more inclined to agree to the argument
claim when they received comprehensible compared to
incomprehensible information. Moreover, as we had
expected, laypeople were more confident in their agreement
decision after reading comprehensible arguments. They
showed higher levels of trust in their own decision about the
claim and perceived themselves less in need of additional
expert advice than after reading incomprehensible
arguments.
Findings with regards to argument type only partly confirm
our expectations: We found that recipients evaluated causal
arguments as stronger than noncausal arguments. This is in
line with previous research indicating that laypersons do not
evaluate arguments in the same way as experts, who regard

Table 2: Intercorrelation (Pearson’s r) of the pre/post difference-scores of claim agreement, trust in own decision and desire
for expert advice. All correlations are significant at a .05 level.
Argument condition
Compr. causal
Incompr. causal
Compr. noncausal
Incompr. noncausal

Claim agreement &
Trust in own decision
.496

.429
.511
.355

Claim agreement &
Desire for expert advice
-.225
-.250
-.454
-.241

2792

Trust in own decision &
Desire for expert advice
-.460
-.449
-.389
-.373

empirical evidence as the preferable form of claim support
and consider explanations unsubstantiated by data as
generally weak (Kuhn, 1991; Slusher & Anderson, 1996).
Furthermore, by holding comprehensibility constant
between both argument types, our results show that
laypeople’s epistemic preference for causal over noncausal
arguments is not due to a confounding with
comprehensibility.
However, the influence of argument type on argument
evaluation did not transmit to recipients’ claim agreement or
to their confidence in their claim agreement decision. We
assume that stronger and more consistent effects of
argument type might be found among a population outside
of the academic context, who should be even less familiar
with noncausal arguments than our present participants.
While we were careful to exclude students from empirical
sciences from our sample, their general academic
background might have provided our participants at least
with some experience in noncausal argumentation,
exceeding that of the ‘average layperson’.
The present results also indicate that laypeople are
generally aware of the necessity to rely on the division of
cognitive labor. Even when receiving easy texts,
participants’ ratings of their desire to ask an expert did not
average below 5 on a scale from 1 to 7 (with 7 indicating a
strong desire). However, the decreasing influence of
information easiness on the perceived need for expert advice
suggests that a too strong simplification of scientific
contents might mislead lay recipients to underestimate their
dependence on experts.
To summarize, our results confirm the assumption that
laypeople are more inclined to rely on their own evaluations
of scientific contents when they perceive the topic at hand
as easy, than when they perceive the issue as beyond their
own understanding. Moreover, it seems that whereas
comprehensibility has a strong influence on lay recipients’
impression of content easiness, the impact of argument type
is comparatively small.
The present findings suggest that caution should be taken
whenever scientific contents are communicated to
laypeople. Popularized science reports, i.e. science
depictions especially intended for public consumption, are
usually characterized by simplification in order to facilitate
the target audience’s content understanding (Goldman &
Bisanz, 2002; Zimmerman et al., 2001). However, our
findings indicate that such simplifications comprise the risk
of making scientific knowledge appear less complex and
easier to evaluate than it actually is. Therefore, popularized
science reports should not only inform laypeople about
scientific contents itself but in addition make recipients
aware of the fact that the content information presented is
generally not sufficient to allow confident evaluations of
related knowledge claims.

Acknowledgments
This research was supported by the Deutsche
Forschungsgemeinschaft (DFG), grant BR 1126/6-1.

References
Alter, A.L., Oppenheimer, D.M., Epley, N. & Eyre, R.N.
(2007). Overcoming intuition: Metacognitive difficulty
activates analytic reasoning. Journal of Experimental
Psychology: General, 136, 569-576.
Bradley, S. & Meeds, R. (2004).The effects of sentencelevel
context, prior word knowledge and need for cognition on
information processing of technical language in print ads.
Journal of Consumer Psychology,14, 291-302.
Brem, S.K. & Rips, L.J. (2000). Explanation and evidence
in informal argument. Cognitive Science, 24, 573-604.
Bromme, R., Kienhues, D. & Porsch, T. (2010). Who knows
what and who can we believe? Epistemological beliefs are
beliefs about knowledge (mostly) attained from others. In
L. Bendixen & F. Feucht (Eds.), Personal epistemology in
the classroom: Theory, research, and implications for
practice, Cambridge: University Press.
Chaiken, S. & Eagly, A.H. (1976). Communication
modality as a determinant of message persuasiveness and
message comprehensibility. Journal of Personality and
Social Psychology, 34, 606-614.
Eagly, A.H. (1974). Comprehensibility of persuasive
arguments as a determinant of opinion change. Journal of
Personality and Social Psychology, 29, 758-773.
Goldman, S.R., & Bisanz, G.L. (2002). Toward functional
analysis of scientific genres: Implications for
understanding and learning processes. In J. Otero, J.A.
Leon, & A.C. Graesser (Eds.), The psychology of science
text comprehension, Mahwah NJ: Erlbaum.
Keil, F. (2008) Getting to the truth: Grounding incomplete
knowledge. Brooklyn Law Review, 73, 1035-1052.
Keil, F.C. (2010). The feasibility of folk science. Cognitive
Science, 34, 826-862.
Keil, F.C., Stein, C., Webb, L., Billings, V.D. & Rozenblit,
L. (2008). Discerning the division of cognitive labour: An
emerging understanding of how knowledge is clustered in
other minds. Cognitive Science, 32, 259-300.
Kuhn, D. (1991). The skills of argument. Cambridge:
University Press.
Reber, R. & Schwarz, N. (1999). Effects of perceptual
fluency on judgments of truth. Consciousness and
Cognition, 8, 338-342.
Sandoval, W.A. & Çam, A. (in press). Elementary children's
judgments of causal justifications. Science Education.
Schwarz, N. (2004). Metacognitive experiences in consumer
judgment and decision making. Journal of Consumer
Psychology, 14, 332-348.
Slusher, M. & Anderson, C. (1996). Using causal persuasive
arguments to change beliefs and teach new information:
The mediating role of explanation availability and
evaluation bias in the acceptance of knowledge. Journal
of Educational Psychology, 88, 110-122.
Zimmerman, C., Bisanz, G., Bisanz, J., Klein, J. & Klein, P.
(2001). Science at the supermarket: A comparison of what
appears in the popular press, experts’ advice to readers,
and what students want to know. Public Understanding of
Science, 10, 37-58.

2793

