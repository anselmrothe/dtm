UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A value-relativistic decision theory predicts known biases in human preferences
Permalink
https://escholarship.org/uc/item/7b0356hw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Srivastava, Nisheeth
Schrater, Paul
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

   A value-relativistic decision theory predicts known biases in human preferences
                                            Nisheeth Srivastava (nsriva@cs.umn.edu)
                                        Department of Computer Science, 200 Union Street SE
                                                       Minneapolis, MN 55455 USA
                                               Paul R Schrater (schrater@umn.edu)
                                             Department of Psychology, 75 East River Road
                                                       Minneapolis, MN 55455 USA
                              Abstract                                 1953), are that option possibilities are represented as environ-
                                                                       mental states, value is assigned to these options in the form
   Traditional models of decision-making assume the existence
   of an external frame of reference for measuring the value of        of numerical reward, and the goal of the agent is assumed
   possible outcomes. We show that this fundamental assump-            to be the maximization of its long-term cumulative reward.
   tion prevents classical decision models from predicting realis-     These assumptions are foundational to both homo economi-
   tic decision-making behavior. Making an alternative relativis-
   tic assumption about the nature of reward leads us to formalize     cus (Persky, 1995) models of economic choice and reinforce-
   a rational agent as one which minimizes its internal decision-      ment learning (Barto & Sutton, 1998). In this paper, we ques-
   computational costs while retaining satisfactorily predictive       tion each of these three dogmas and replace them with alter-
   models of its external environment. In computational evalu-
   ation, our model replicates previously unexplained ‘irrational’     natives obtained from a relativistic view of both how agents
   behavior of human subjects.                                         evaluate possible outcomes and how they evaluate their own
   Keywords: Cognitive models; neural coding; decision theory;         existence as predictive agents.
   behavioral biases
                                                                          At a fundamental level, the assignment of reward values as-
                                                                       sumes the existence of some fixed reference against which the
                          Introduction                                 value of its actions can be measured. This simple assumption
Economists have used the terms ‘animal spirits’ and ‘cogni-            causes us to formulate rewards as absolute numeric quanti-
tive biases’ (Akerlof & Shiller, 2009) to explain the persis-          ties, with a “no reward” state as the origin. Furthermore, this
tence of behaviors incompatible with accepted definitions of           view renders us unable to consider any meaningful goal for
rationality. Consistent observation of such ‘predictably irra-         an agent other than maximal reward accumulation. That is, if
tional’ (Ariely, 2009) behavior in both controlled and uncon-          we detach the notion of value from the agent’s environment-
trolled settings has reduced confidence in the neo-classical           specific need at the moment of the decision and instead fix it
view of human decision-making as a rational enterprise.                with respect to some Platonic origin, we can no longer mean-
   Contemporary explanations for these biases typically draw           ingfully speak of satisfying needs, only of optimizing utility.
on evolutionary arguments (Gigerenzer & Goldstein, 1996),
                                                                          In this paper, we try to capture the notion of value as the
especially the idea of that deviations from traditional ratio-
                                                                       agent’s needs by making the valuation process relative to both
nality represent specialized adaptations to the social and en-
                                                                       the agent’s current policy and current set of options. This
vironmental conditions of mankind’s early history. Thus,
                                                                       changes the canonical decision modeling approach in three
while on one hand, rational models of decision-making lie
                                                                       ways: one, it captures the embodied view of cognition; two,
discredited through their inability to explain the existence of
                                                                       we discard the association of numerical rewards to particu-
cognitive biases, the prominent alternative approaches create
                                                                       lar outcomes - all rewards are relative comparisons of value;
heuristic-based theories that are limited in their ability to pro-
                                                                       three, decision-making is seen to be a process of identify-
duce generalizable causal explanations for decision-making
                                                                       ing outcomes from the agent’s current situation and evaluat-
processes. The absence of a realistic, principled theory of hu-
                                                                       ing those options relative to the agents understanding of what
man decision-making is deeply problematic, since models of
                                                                       has constituted the best policy for this situation, based on the
decision-making are central to the formulation of immensely
                                                                       agent’s past experience.
consequential social and economic policies.
   Given the continued failure of variants of existing theories           By formalizing these insights, we show that the assump-
to offer compelling explanations for how biological agents             tion of value relativity, while exotic at first sight, can be eas-
make decisions, we believe that it is necessary to re-evaluate         ily adapted into a tractable choice-learning algorithm. We
the foundational assumptions in these theories and find plau-          further show that the choice predictions of this algorithm pre-
sible alternatives. How does an agent represent its possi-             dict the choices of human subjects across different decision
ble options in an environment? How does it assign value                tasks that have heretofore been considered irrational. The
to various options? On what basis does it select between               unforced emergence of a number of previously unconnected
these options? The canonical responses to these questions,             cognitive biases from our decision model provides empirical
obtained through a history of research stretching from J S             support for its foundational premises. We conclude with a
Mill (Mill, 1874) to von Neumann (Neumann & Morgenstern,               brief discussion of some implications of our findings.
                                                                   1280

        Principles of self-motivated learning                        of reward unhesitatingly (and errantly!) being used in both
Any realistic model of decision-making must be consonant             the AI and reinforcement learning (Barto & Sutton, 1998) lit-
with the structure of human motivation, i.e., the intrinsic fac-     erature.
tors that affect an agent’s choice behavior. Building upon the          In our formulation of self-motivated learning, we retreat to
relativistic view of the sequential choice selection problem,        the pre-VNM state of understanding of preferences, by as-
we now develop a mathematical model of learning choice-              suming that agents can only adopt preferences for particular
selection that appears to be self-motivated and demonstrates         outcomes relative to others observed in the same context.
realistic learning behavior.
   We begin by obtaining alternatives to three assumptions           Cognitive efficiency
that underpin traditional decision theories - the ontological
                                                                     Basic rational choice theory assumes that rational agents at-
assumption of an agent-environment duality, the epistemo-
                                                                     tempt to maximize the reward that they can obtain through
logical assumption of absolute numerical utility values and
                                                                     their actions. However, this assumption has been shown by
the teleological assumption of utility maximization from our
                                                                     multiple behavioral studies to be unrealistic. The princi-
relativistic standpoint.
                                                                     pal alternative to this assumption is the bounded rationality
Embodied representation of preferences                               approach. However, traditional views of bounded rational-
The embodied and embedded view of cognition historically             ity (Rubinstein, 2003) continue to assume that agents attempt
arose as a response to the mainstream computational theory           to maximize reward under computational constraints. From a
of mind (CTM) that assumes that the mind literally is a digital      relativistic standpoint, environmental phenomena are judged
computer and that thought processes are therefore neural, rep-       to be valuable to the extent they have been judged valuable
resentational and computational. It suggests that rather than        in the past. Judging utility by whether an option has been
being an isolated observer and computer, the mind acts in in-        useful in the past as opposed to how useful it is removes the
separable conjunction with the environment to create mental          necessity to postulate Platonic rewards embedded in the envi-
processes (Brooks, 1991). Our relativistic view emphasizes           ronment. In our relativistic formulation, the relative value of
the absence of a unique privileged view of a decision event,         possible outcomes must emerge from the process of sequen-
and as such, rejects the presence of a disembodied observer.         tial choice selection itself.
The embodied view of cognition, therefore, lends itself better          In our formal model, described below, we postulate that
to our agent-environment description.                                humans are essentially searching for minimal-cost theories
                                                                     about how to choose high value options, where the cost is
Relative utility                                                     measured in terms of the complexity of encoding and storing
Traditional models of cognition have perpetually had an un-          the information needed to reliably make these decisions. We
easy relationship with quantitative theories of value. The re-       term this cost cognitive processing cost, which is equivalent
peated failures of neo-classical economic theories in modern         to the cost of accessing past beliefs in the agent’s memory.
times are traced by behavioral economists to the former’s fun-          In brief, rather than view humans and other natural
damental dependence on a model of reward/value.                      decision-making agents as reward maximizers, or even con-
   Almost all existing decision theories presuppose the exis-        strained reward maximizers, we view them as efficient need-
tence of state-specific quantified reward. This assumption ig-       satisficers. The expectation of efficiency allows us to pose
nores the failure of the persistent efforts made by early 20th       the optimal control and decision problems using standard op-
century psychologists towards finding tractable mappings be-         timization techniques, with the relevant quantities to be opti-
tween physical stimuli and the value judgments of human              mized possessing internal as opposed to external ontological
subjects. In fact, it was not until von Neumann and Mor-             significance.
genstern (Neumann & Morgenstern, 1953) showed that it is
possible, under a set of mathematical axioms (henceforth the         The decision model
VNM axioms) governing the nature of human preferences, to
obtain consistent additive values of relative expected utility       Informally, to make a sequence of decisions, the agent cy-
among various options that quantifications of human prefer-          cles between forming beliefs about the relative worth of op-
ences could be meaningfully addressed. The von Neumann               tions by accessing past experience, termed policies, making
program is fundamental to the development of reward-based            choices, experiencing outcomes and updating these policies
models of decision-making and planning in AI.                        to minimize processing costs for future decisions.
   However, two major problems have arisen in the course of             As we show in Figure 1 and discuss in greater detail in
the adaptation of the VNM approach to computational deci-            (Srivastava & Schrater, 2010), the formal structure of our
sion models. First, it has been established by multiple em-          model is homologous to the statistical minimum description
pirical studies that the VNM axioms do not apply to human            length principle, with the core premise that an agent tries to
preferences. Second, in adapting the VNM approach to com-            minimize its cognitive processing cost T while maintaining
putational models, the idea that the additive utilities obtained     a ‘satisficingly’ high level of predictive confidence C in the
are relative has been ignored, leading to absolute scalar values     quality of its choices. The self-motivated learning objective
                                                                 1281

    (a) A schematic of obtaining a good theory from data following     (b) A schematic of obtaining a good belief from environmental
    a minimum description length approach.                             stimuli using an evolutionary MDL principle
Figure 1: This graphic outlines the homologous nature of an evolutionarily optimal meta-cognitive decision strategy with
minimum description length principles.
is to minimize a function of the form,                                 accessing each policy to be unity, the total cost of memory
                                                                       access T becomes,
                    argmin            T                        (1)
                        x
                               Cnew   ≥ Cold .
                                                                                                  T=      ∑ 0 A−1 (xi ),                   (4)
                                                                                                        xi ∈M
where T and C are quantified below in terms of policies.                  Our measure of the agent’s confidence in its ability to pre-
   Let the discrete probability distribution x(s) represent an         dict its environment, C : x → [0, 1] captures the idea that con-
agent’s policy, viz., belief about the relative quality of out-        fidence grows when the policies have low uncertainty and low
comes s ∈ S available to it. The surprise experienced by an            surprise:
agent operating with a policy xa in comparison with policy xb                                      1        log |x| − H(x)
                                                                                            C=                               ,             (5)
can be quantified with an information divergence (Kullback                                       Cmax ∑memory R(x, xold )
& Leibler, 1951) of the form,
                                                                       where the numerator is a monotonically decreasing function
                               na             j                        of the Shannon entropy H(x) of the policy. Note that C is
                                            xa (s)
                R(xa , xb ) = ∑ xaj (s) log x j (s) .          (2)     normalized with respect to the greatest value it has previously
                              j=1            b                         been observed to achieve.
                                                                          Any algorithmic solution of our agent’s objective func-
   We propose that processing costs are determined by the              tion must solve three problems - one, specify a memory up-
cost of accessing a belief. Using information-theoretic ar-            date specifying how existing policies are integrated into the
guments, we suggest that the access cost of a belief is de-            agent’s current policy; two, specify an environmental up-
termined by its predictive exceptionality, which in turn can           date, which shows how the perceived goodness of various
be measured as a departure from the usual level of surprise            outcomes at the present moment, which we call reward-
that the agent experiences in making its predictions. We mea-          inference1 , are integrated into the agent’s current policy;
sure the informational exceptionality of a past policy xold (and       three, specify a combinatorial optimization algorithm spec-
hence the ease with which it will be available for recall to the       ifying which subset of existing policies the agent will recall
agent) as the deviation from the average surprise experienced          to form its new policy, such that the objective function we
by the agent R’:                                                       have defined above is satisfied. In (Srivastava & Schrater,
                                                                       2010), we present a direct policy search-based solution to all
                   A(xold ) = |R(x, xold ) − R|,               (3)     three problems for simple outcome spaces, resulting in a self-
                                                                       motivated learning algorithm for predicting choices made by
where x is the agent’s current policy.
                                                                       agents in sequential settings. The resultant algorithm outputs
   Given this measure of ease of memory access for each past
policy, a reasonable measure of the processing cost of se-                 1 Our model assumes that sensory data is encoded into the space
lecting a subset M’ out of the set M of all past policies is           of possible outcomes as a relative preference by existing neuronal
                                                                       processes. Thus, our usage of the term reward-inference accentuates
the inverse availability-weighted sum of the nominal cost of           the fact that it is obtained after perceptual processing of environmen-
accessing all policies in M’. Assuming the nominal cost of             tal stimuli.
                                                                   1282

beliefs corresponding to the relative preference for each of                 quence of the disproportionate weighting of low-probability
the possible outcomes in the agent’s decision context.                       outcomes in human subjects. This explanation was subse-
    While simply constructing a choice-learning algorithm ca-                quently amended in (Tversky & Kahneman, 1992) to restrict
pable of quantifying internal motivations would pass for an                  over-weighting only to ‘extreme’ low-probability events as
interesting theoretical exercise, in the next section, we present            opposed to all low probability events.
evidence below to show that our approach makes strong fal-
sifiable predictions about classes of behaviors in human sub-
jects that classical approaches are unable to explain.
              Irrational behavior is rational
Counter-examples to the expected utility axioms have a his-
tory nearly as old as rational choice theory itself. Deviations
from the predictions of expected utility theories, when con-
sistently observed in human subjects under controlled exper-
imental settings, have been defined as cognitive ‘biases’, im-
plying a somewhat paternalistic premise that people would
behave the way expected utility theory predicts if they were
unbiased (smart) enough. However, the epistemic value of
decision theories that are consistently mistaken cannot be rea-
sonably justified2 .
    While the weakness of existing neo-classical decision
                                                                                      (a) Results from experiments on human subjects
models have been critiqued exhaustively in the behavioral                             attempting to find subjects’ implicit certainty-
economics literature, incremental fixes to the basic frame-                           equivalence with respect to gains/losses and its de-
work and the use of ad hoc heuristics has created a frag-                             viation from mathematical expectation. Histori-
                                                                                      cally, this was the predominating motivation for
mented universe of predictive models, each successful at ex-                          the development of prospect theory.
plaining one specific set of cognitive biases. We believe that
a causally valid theory of decision-making must necessarily
present a unified explanation for multiple families of cogni-
tive biases.
    To demonstrate the plausibility of our self-motivated de-
cision model, we show how its predictions replicate biases
observed in two different cognitive domains and heretofore
explained separately using generalized utility theories in one
case and evolutionary heuristics in the other. Similar results
for other families of biases are described in a longer technical
report (Srivastava & Schrater, 2010), but are omitted in this
paper due to space constraints. We suggest that the unforced
emergence of multiple classes of cognitive biases from our
model provides support for its cognitive realism.
Risk aversion                                                                  (b) Results from simulation of prospect theory experiment using
                                                                               existential agents as subjects. The blue line represents the ide-
Kahneman and Tversky (Tversky & Kahneman, 1992) pro-                           alized expected value prediction while the red markers indicate
posed prospect theory largely to explain deviations from ex-                   average preference of 200 agents having experienced a history
                                                                               of repeated exposure to a choice selection task between a risky
pected value predictions in certainty-equivalence studies on                   gamble with a certain (x-axis) probability of succeeding and a
evaluations of risky prospects in human subjects. They ob-                     safe choice.
served that subjects consistently exhibited a four-fold pattern
of behavior when confronted with risk: risk seeking for gains                Figure 2: Existential learning generatively reproduces exper-
with low probability, risk aversion for gains with high prob-                imental results previously explained only empirically using
ability, risk seeking for losses with high probability, and risk             prospect theory.
aversion for losses with low probability. (Tversky & Kahne-
man, 1973) explain the emergence of this pattern as a conse-                    The experimental setup for their experiments is fairly
                                                                             straightforward: subjects are asked to select between a ‘safe’
     2 The dismissal of various cognitive phenomena as ‘biases’ is           gain/loss prospect of known value and one of unknown value
rather reminiscent of the construction of epicycles in Ptolemaic as-         determined as a Bernoulli choice between two known out-
tronomy - it is not the theory that does not fit the observations, it is
the observations that are so inconsiderate that they don’t obediently        comes. For example, a subject could be asked to choose be-
fit the theory!                                                              tween selecting a prospect that pays $0 with a probability of
                                                                         1283

0.9 and $50 with a probability of 0.1 and a set of prospects            all these biases is the tendency for subjects to prefer informa-
guaranteed to pay anywhere between $2 and $20 (say). The                tion that confirms their existing preconceptions/hypotheses
subjects were required to indicate their preference between             over objective evidence. Confirmation biases are generally
the risky and safe prospects for all the safe prospects pre-            explained using availability or priority heuristics in the biases
sented to them. The certainty equivalent value was estimated            and heuristics literature (Ayal & Hochman, 2009). Rational
as the midpoint between the lowest accepted and the high-               choice theories find it difficult to account for their presence.
est rejected value from among the safe prospects. Selections
where the certainty equivalent value exceeded the expected
value of the risky prospect ($5 in this case) were considered
risk-seeking, while those that were lower were counted as risk
averse.
   In order to simulate the experimental setup described in
(Tversky & Kahneman, 1992), we design our outcome space
to consist of two possible outcomes: select safe prospect or
select risky prospect. For every decision instance, the payoff
for the risky prospect is sampled from a Bernoulli distribution
appropriate for the gamble. For the gamble in the example
above, this means that the risky prospect will pay $0 in about
9 out of every 10 decision instances. The reward-inference                       (a) Existential agent evidencing confirmation bias
signal is constructed to assign a preference of 1 to the bet-
ter prospect (and 0 to the worse prospect) at every instantia-
tion. Thus, a choice between a gamble with a 0.1 probability
of paying off against a certain safe outcome is modeled as a
generative mechanism for reward-inference that reflects a se-
lection {0 1} biased towards the safe choice 90% of the time
and the alternate risky choice {1 0} 10% percent of the time.
   We provided each one of a population of 200 agents with a
series of 100 such reward-inference signals. A series is pre-
sumed to indicate the ‘learning’ phase for an agent with re-
spect to a particular choice problem involving risk evaluation.
At the end of a series, the agent is assumed to possess, in the                  (b) Percentage of high and low surprise instances
form of its final preference, an evaluative model for selecting                  active in agent’s salient set for runs of different
                                                                                 lengths.
between the prospects offered in the (Tversky & Kahneman,
1992) selection task. We modify the probability of winning
                                                                        Figure 3: Different flavors of confirmation bias exhibited by
or losing the gamble by modifying the Bernoulli distribution
                                                                        existential learning algorithm.
parameterizing the reward inference distribution.
   In Figure 2, we see that our simulation replicates results
that are qualitatively similar to the experimental results ob-             Figure 3(a) displays typical performance of an existential
tained from human subjects in (Tversky & Kahneman, 1992).               agent on a binary prediction task. Given consistent reward-
Remarkably, agents running our existential learning algo-               inference favoring one outcome (say 0, 1), the agent’s pref-
rithm consistently present the same four-fold pattern of risk           erence for this outcome increases, which is entirely rational.
aversion observed in human subjects. This leads us to hy-               Then, consistent reward-inference favoring the other outcome
pothesize that the biases documented by Kahneman and Tver-              1, 0 is provided, causing the agent to reverse its preference
sky, which have subsequently motivated the development of               (after a brief delay), which, again is entirely rational.
prospect theory and other generalized expected utility theo-               However, when the reward-inference is switched yet again
ries are, in fact, adaptive in nature rather than existing a priori     back to the original outcome, the agent does not switch, but
in human decision-makers. Our model produces, to the best               continues to confirm its recent preference for the other out-
of our knowledge, the first generative mechanism for esti-              come. This superficially irrational behavior follows naturally
mating and potentially quantifying Kahneman and Tversky’s               from the tendency of our agent to retain its existing theory if
four-fold pattern of risk aversion.                                     formulating a newer theory would cause its predictive confi-
                                                                        dence to drop.
Confirmation biases                                                        The first scientific evaluation of confirmation bias is his-
The term ‘confirmation bias’ often references biased hypoth-            torically assigned to Wason’s (Wason, 1960) rule-discovery
esis evaluation, differential memory recall, belief divergence,         experiments. However, Klayman and Ha (Klayman & Ha,
attitude polarization and other biases arising in different ex-         1987) proved that what Wason had actually shown was that
perimental contexts. The fundamental similarity shared by               human subjects prefer using positive test strategies, i.e., in-
                                                                    1284

stead of trying to find counter-examples to a hypothesis, they       environmental settings, where it replicates the predictions of
seek to validate it. Interpreting these findings in our frame-       classical rational choice models, as well as in atypical en-
work, observe that a disconfirming negative test strategy of         vironmental settings, where it faithfully replicates biases ob-
trying to rigorously disprove a held hypothesis would create         served in human subjects. As a consequence, our results show
several high surprise/regret decision instances for an existen-      that a number of important cognitive biases emerge as natural
tial agent.                                                          consequences of the way a metacognitive agent encodes in-
   Conversely, deploying positive test strategies would cre-         formation about the environment. However, our model is as
ate (given a predictable environment) low surprise/regret in-        yet unable to account for set size and framing effects, since
stances. Since part of the agent’s existential goal is to maxi-      it currently considers a particular embodied representation of
mize its expectation of future reward, and since this expec-         the agent-environment as persistent across choices. Extend-
tation, in the form of confidence, will vary inversely with          ing our model to capture these effects is an exciting direction
the cumulative surprise in the agent’s recalled history, it will     for future work, with cross-disciplinary implications.
strongly prefer making choices that lead to low surprise, and
hence will prospectively prefer positive test strategies. Figure                               Références
3(b) shows the existential agent’s preference for low surprise       Akerlof, G., & Shiller, R. (2009). Animal spirits: How hu-
decision instances.                                                     man psychology drives the economy, and why it matters for
   Very interestingly, we find that the agent’s preference for          global capitalism. Princeton University Press.
positive test strategies appears to emerge gradually as it be-       Ariely, D. (2009). Predictably irrational: The hidden forces
comes surer of its existing hypothesis. This corroborates               that shape our decisions. Harper Collins.
the information-theoretic intuition (Klayman & Ha, 1987)             Ayal, S., & Hochman, G. (2009). Ignorance or integration:
that such a preference arises as an information-processing re-          The cognitive processes underlying choice behavior. Jour-
sponse to environments where positive queries have higher               nal of Behavioral Decision Making, 22, 455-474.
informational content than negative queries.                         Barto, A., & Sutton, R. (1998). Reinforcement learning: an
                                                                        introduction. Univesity of Cambridge Press.
                          Discussion                                 Brooks, R. (1991). Intelligence without representation. Arti-
                                                                        ficial Intelligence, 47, 139-159.
In this work, we have showed how two different families of           Gigerenzer, G., & Goldstein, D. (1996). Reasoning the fast
cognitive biases can, in fact, be generated from a single causal        and frugal way: models of bounded rationality. Psycholog-
model of decision-making, merely by shifting the objective of           ical Review, 103(4), 650-669.
a classical bounded rational agent from resource-constrained         Klayman, J., & Ha, Y.-W. (1987). Confirmation, disconfir-
utility maximization to prediction-constrained cognitive ef-            mation and information in hypothesis testing. Psychologi-
fort minimization. This change in perspective, in turn, is ob-          cal Review, 94, 211-228.
tained from a relativized view of the nature of preferences,         Kullback, S., & Leibler, R. (1951). On information and suf-
arising from the intuition that, however an agent may be en-            ficiency. Annals of Mathematical Statistics, 22, 79-86.
gaged with its environment, it sees, from its own existentially      Mill, J. (1874). Essays on some unsettled questions of politi-
stationary vantage point, a set of options that it has seen in          cal economy, par 5.38.
the past, recalls its previous experience of choice selection        Neumann, J., & Morgenstern, O. (1953). Theory of games
amongst them, and uses its memory recall to make a new                  and economic behavior. Princeton University Press.
choice selection. Thus, the principal quantity of interest in        Persky, J. (1995). Retrospectives: The ethology of homo
decision-making becomes the cost of memory recall, optimiz-             economicus. The Journal of Economic Perspectives, 9(2),
ing which results in a novel rational decision theory.                  221-231.
   Note further that, by retaining a sense of optimality, we         Rubinstein, A. (2003). Modeling bounded rationality.
have essentially proposed a new way of defining rational                Prentice-Hall.
utility, which subsumes positive aspects of both the clas-           Srivastava, N., & Schrater, P. (2010). An evolutionarily moti-
sical expected utility paradigm (Neumann & Morgenstern,                 vated model of decision-making under uncertainty. Avail-
1953) and recent heuristic-based methods (Ayal & Hochman,               able at SSRN: http://ssrn.com/abstract=1687205.
2009) while avoiding their defects. Specifically, our model          Tversky, A., & Kahneman, D. (1973). Availability: a heuris-
retains the analytical tractability and causal interpretability         tic for judging frequency and probability. Cognitive Psy-
of the traditional expected utility/rational choice paradigm            chology, 5, 207-232.
while adapting the definition of rationality to confirm with         Tversky, A., & Kahneman, D. (1992). Advances in prospect
Gigerenzer’s (Gigerenzer & Goldstein, 1996) idea of ‘ecolog-            theory: Cumulative representation of uncertainty. Journal
ical rationality’. By adopting an embodied representation of            of Risk and Uncertainty, 5, 297-323.
the agent-environment interface, and an information-theoretic        Wason, P. (1960). On the failure to eliminate hypotheses
basis for defining costs, we are able to generalize our model’s         in a conceptual task. Quarterly Journal of Experimental
dependence across the ecology of different domains. This al-            Psychology, 12, 129-140.
lows our model to retain predictive accuracy both in typical
                                                                 1285

