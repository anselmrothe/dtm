UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Looking at Nothing Diminishes with Practice
Permalink
https://escholarship.org/uc/item/21m7h5xx
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Scholz, Agnes
Mehlhorn, Katja
Bocklisch, Franziska
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                                    Looking at Nothing Diminishes with Practice
                                   Agnes Scholz1 (agnes.scholz@psychologie.tu-chemnitz.de)
                                             Katja Mehlhorn2 (s.k.mehlhorn@rug.nl)
                          Franziska Bocklisch1 (franziska.bocklisch@psychologie.tu-chemnitz.de)
                                   Josef F. Krems1 (josef.krems@psychologie.tu-chemnitz.de)
                               1
                                 Department of Psychology, Chemnitz University of Technology, Germany
          2
            Dept. of Artificial Intelligence and Dept. of Experimental Psychology, University of Groningen, the Netherlands
                                Abstract                              information was presented compared to other areas on the
                                                                      screen.
   People fixate on blank locations if relevant visual stimuli
   previously occupied that location; the so-called ‘looking-at-         This so-called ‘looking-at-nothing’ behavior (Ferreira,
   nothing’ effect. While several theories have been proposed to      Apel, & Henderson, 2008) also occurs when the probed
   explain potential reasons for the phenomenon, no theory has        information is presented visually (Laeng & Teodorescu,
   attempted to predict the stability of this effect with practice.   2001; Renkewitz & Jahn, 2010; Spivey & Geng, 2001),
   We conducted an experiment in which participants listened to       when information is anticipated (Altmann & Kamide, 2007),
   four different sentences. Each sentence was associated with        in light and in complete darkness (Johansson, Holsanova &
   one of four areas on the screen and was presented 12 times.
   After every presentation participants heard a statement
                                                                      Holmqvist, 2006), and for simple (Brand & Stark, 1997) and
   probing one sentence, while the computer screen was blank.         more complex pictures (Johansson, Holsanova, &
   More fixations were found to be located in areas associated        Holmqvist, 2010).
   with the probed sentence than in other locations. Moreover,           Ferreira et al. (2008) assumes a memory representation of
   the more trials participants had completed, the less frequently    an object or event that integrates visual, auditory and spatial
   they exhibited looking-at-nothing behavior. Fixations on           information and leads to a corresponding visual, linguistic,
   blank locations seem to occur when an attempt is made to           spatial, and conceptual representation. When one part of this
   retrieve information associated with a spatial location as long
   as it is not strongly represented in memory.                       integrated memory representation is reactivated, other parts
                                                                      are retrieved, as well. This in turn causes gazing behavior
   Keywords: Eye tracking, practice, spatial cognition, mental        toward the location where the information was previously
   representation, working memory                                     presented. For example, seeing a table on a whiteboard leads
                                                                      to the activation of a visual as well as conceptual
                           Introduction                               representation of the figure. Additionally, spoken language
When processing information from the visual world, human              leads to the formation of a linguistic representation. The
cognition integrates visual and auditory input with abstract,         visual world leads to the activation of a spatial index
higher level mental representations (Huettig, Olivers, &              (Pylyshyn, 2001), which can be used later to direct our gaze
Hartsuiker, 2010). Reactivation of such a memory                      back to the area on a whiteboard, where the figure was
representation leads the gaze back to spatial locations or            previously presented.
areas that were previously occupied by relevant information.             Huettig et al. (2010) recently proposed a general
For example, when we mention something about a table                  framework to describe how linguistic and visual
presented on a whiteboard, we might point towards the                 representations are bound together in an integrated memory
whiteboard, even if the table is no longer there anymore.             representation. Their model, like that of Ferreira et al.
   Richardson and Spivey (2000) were among the first to               (2008), assumes the integration of information in a
show a close link between eye movements, auditory                     connected visual, linguistic, spatial, and conceptual
information processing and semantic information                       representation. It further includes ideas proposed by
processing, in an information-retrieval task. Participants            Altmann and Kamide (2007), Knoeferle and Krocker
were presented with a spinning cross in one of four equal-            (2007), and Spivey (2007). Here, we briefly introduce their
sized areas on a computer screen together with spoken                 framework. It is worthwhile to note that they include a
factual information. After four facts were presented,                 detailed description of how integrated memory
participants heard a statement probing one of the presented           representations can be linked to existing theories of long-
facts and had to judge the truth of the statement. During this        term and working memory (c.f., Baddeley, 2000). Huettig et
retrieval phase the computer screen was blank. Participants           al. (2010) propose that language–vision interactions are
fixated more in the critical area where the sought-after              based on long-term memory, where conceptual
                                                                      representations (e.g., the concept of a figure or of a
                                                                    1070

whiteboard) are derived from. Therefore, long-term memory        memory. With more practice, the strength with which
serves as a stable knowledge base. It is then working            retrieval-relevant information is represented in memory
memory that grounds cognition in space and time and leads        increases (e.g., Anderson & Schooler, 1991). If looking at
to the formation of short-term connections between objects       nothing increases with practice, then Huettig et al.’s
(e.g., spoken language, a figure, and a whiteboard).             assumptions would be supported. On the other hand, if
Contents of working memory are linked to contents of long-       looking at nothing decreases with practice, our findings
term memory via spatial indices. Because of this association     would support Spivey (2007) and conclude that looking at
working memory can instantiate a gaze back to the object.        nothing varies with the degree of relevant information
In describing connections between memory representations,        included in the mental representation.
Heuttig et al. (2010) assume that the stronger the association
between the linguistic and conceptual representations the                                 Experiment
higher “the probability of triggering a saccadic eye-            To test looking-at-nothing behavior under different levels of
movement” (p. 5).                                                practice we conducted an experiment in which participants
   Richardson, Altmann, Spivey, and Hoover (2009) share          were presented with four different sentences. Each sentence
Huettig at al.’s (2010) general idea of an integrated memory     described an artificial scene. The same set of four sentences
representation. In contrast, however, they suggest that only     was presented in each of 12 experimental trials. After every
sparse internal representations are built during the encoding    presentation trial a retrieval phase followed in which one of
of information. They assume that during information              the four sentences was probed. In every trial each sentence
retrieval, an eye movement can be launched to the                was associated with the same spatial location on a computer
associated area in order to gather more information. This        screen.
occurs when the spatial pointer (i.e., the visual part of the
integrated memory representation) does not include the           Method
searched information: “If the pointer’s tag does not include
the attribute, then the pointer’s address to the external        Participants. Eighteen students (14 female; age M = 22.8)
environment is the next obvious resource” (Spivey, 2007, p.      from Chemnitz University of Technology participated in the
298). The link between information sampling from the             experiment. All reported normal or corrected-to-normal
environment and eye movements can be understood as the           vision with contact lenses. All participants were native
covert orienting of visual–spatial attention (Hoffman, &         German speakers.
Subramaniam, 1995). Targeting a position makes it
necessary to allocate attention towards that place. Because it   Apparatus and material. Participants were seated in front
is impossible to make an eye movement without an                 of a computer screen at a distance of 630 mm and instructed
attentional movement (Shepherd, Findlay, & Hockey,               to position their head in a chin rest. The eye-tracker system
1986), attending to information stored in an integrated          SMI iView REDpt was used to sample data of the right eye
memory representation leads to eye movements towards             at 50Hz with a precision of 0.05°. Data were recorded with
associated spatial areas.                                        iView X 1.7 and analyzed with BeGaze 2.3 and MatLab
   Summarizing, we conclude that during the encoding of          7.0.1 software programs. Stimuli in the experiment were
information an integrated memory representation is formed        presented using E-Prime 2.0 on a 380-mm × 305-mm
from different modalities. However, theories diverge in          computer screen with a resolution of 800 × 600 pixels.
terms of how much information is included in the memory             The visual stimuli consisted of a grid dividing the screen
representation and how this in turn affects the looking-at-      into four equal-sized areas with a fixation cross at the center
nothing behavior. Ferreira et al. (2008) assume that the         of the grid. Each set of four sentences was associated with
probability of triggering an eye movement increases with         the same symbol – a black circle with a white loudspeaker
the strength of the association between the linguistic and       in it – which appeared in one of the four areas of the grid
conceptual representation. Consequently, one could predict       depending on the sentence that was presented.
that looking-at-nothing behavior becomes stronger with an           The auditory stimuli presented in the presentation trial
increasing association between these representations. Spivey     consisted of four prerecorded sentences each describing
(2007), on the other hand, proposes that looking at nothing      three attributes of an artificial scene (e.g., “There is a place
mainly occurs for the purposes of gathering information not      with a purple lighthouse, a sickle bay, and a wooden
yet included in the mental representation. In line with this     church.”). To test gaze behavior in the retrieval phase, we
one might conclude that looking at nothing diminishes as         generated 24 statements: A true and a false version for each
relevant information is included in the memory                   of the four statements multiplied by three attributes (The
representation.                                                  false statement probing the example sentence from above
   To test these assumptions we varied the degree to which       was “There is a place with a wooden cottage.”). Figure 1
information is included in memory representation. More           shows 1 of the 12 experimental trials.
precisely, we manipulated the degree of practice in a task,
where auditory information, which is associated with             Procedure. To mask study intentions, students were told
contents from a visual scene, has to be retrieved from           they were participating in a study concerning pupil dilation
                                                                 that involved solving a memory task. No instructions
                                                               1071

concerning gaze behavior were provided. The eye tracker          reaction times are prone to error through outliers (e.g., when
was calibrated using a 9-point calibration method. This          an investigator does not stop recording immediately upon a
procedure lasted between 5 and 10 min. Subsequently, the         participant’s response) we did not exclude outliers but used
12 experimental trials started. In each of the 12 trials, the    median reaction times for further analysis.
same four sentences were presented in random order. Every           To assess looking at nothing, gaze data from the
sentence always appeared with the symbol in the same area        beginning of the retrieval phase to a participant’s reply (i.e.,
on the screen with a presentation duration of 30 s.              analogous to response time) was analyzed. Four adjacent
                                                                 ‘areas of interest’ (AOIs) were defined corresponding to the
                                                                 four areas on the screen. Numbers of fixations in every AOI
                                                                 were counted per person and per trial. A fixation was
                                                                 defined as having a minimum duration of 100 ms and a
                                                                 maximum dispersion of 100 pixels (1.3° visual angle). The
                                                                 AOI associated with a probed sentence is called the ‘critical
                                                                 area’. Gaze behavior was analyzed, whereby trials were
                                                                 discarded in which tracking data was missing for >40% of
                                                                 the trial duration (8% of all trials). Missing tracking data
                                                                 was caused by blinks, lost pupil or corneal reflectance, or
                                                                 looking away from the screen.
                                                                    To test the independent variable practice, we aggregated
                                                                 the number of fixations in the AOIs as well as the
                                                                 performance data over sets of four experimental trials. This
                                                                 allowed us to compare three conditions of practice: block 1
        Figure 1: Example trial with the four experimental       (consisting of trials 1–4), block 2 (trials 5–8), and block 3
 sentences (presentation phase) and a statement probing the      (trials 9–12).
first sentence (retrieval phase). Original material in German.      Number of fixations and median reaction times were only
                                                                 analyzed for trials that were answered correctly.
After presentation of the fourth sentence within a trial, the
retrieval phase followed. Participants heard a statement,        Results
which referred to a fact from one of the four sentences, and     Performance measures. Overall, mean percentage of
judged it to be true or false. To observe participants’ gaze     correct responses to the statements was M = 87.8% (SD =
behavior, they were intentionally not instructed to reply as     20.8%), suggesting that the material was neither too difficult
soon as possible. Presentation of one statement lasted 4 s.      to memorize nor too easy to learn. A one-way repeated
Statements were randomly assigned to trials and participants     measures ANOVA revealed a significant effect for accuracy
with the restriction that every statement was probed once for    over the three blocks, F(2,34) = 11.04, p < .001, ηp2 = .40.
each participant. Participants had to answer the true or the     Bonferroni post-hoc tests showed an increase in
false version of a statement balanced across trials and          performance from the first to the second block, Mb1 = 73%
participants such that every participant was presented with      vs. Mb2 = 93%, p = .004, and from the first to the third
six true and six false statements. A true statement was          block, Mb1 = 73% vs. Mb3=97%, p =.005. There was no
recorded when participants responded verbally with ‘right’       significant change in performance from the second to the
and a false statement with ‘wrong’. Immediately following        third block, Mb2 = 93% vs. Mb3 = 97%, p = 1.00.
this response, the investigator pressed a key signaling the         The median reaction time to the statement in the retrieval
start of the next trial. In this way, participants were not      phase was 6206 ms (SD = 1617 ms). Over the three blocks
required to look at the keyboard (This procedure was chosen      of practice participants became faster in correctly
to prevent gazing away from the monitor towards the              responding, Greenhouse–Geisser-corrected F(1,48;34) =
keyboard, which could have led to loss in quality of eye-        9.61, p = .002, ηp2 = .36.
tracking data). After depressing the key, the investigator          Bonferroni post-hoc tests confirm a decrease in the
noted the particpant’s response on a sheet of paper. During      median reaction times from the first to the second block Mb1
the 12 experimental trials and their retrieval phases, gaze      = 7211 ms vs. Mb2 = 5798 ms, p = .016 and from the first to
data were recorded. Afterwards, participants filled out a        the third block, Mb1 = 7211 ms vs. Mb3=5608 ms, p = .009.
questionnaire which interrogated demographic variables and       Again, there is no difference between the second and the
the assumed goal of the study. Before leaving, participants      third block, Mb2 = 5798 ms vs. Mb3 = 5608 ms, p = 1.00.
were informed about the true nature of the study.                Response accuracy and median reaction times showed that
                                                                 the practice manipulation was successful. With more
Analysis. To assess participants’ performance, we collected      practice, participants answered correctly more often and
data on the accuracy of their responses and response times       replied more quickly to the statements.
(i.e., the time beginning with the retrieval phase and ending
with a participant’s reply as noted by the investigator). As
                                                               1072

Mean number of fixations.                                           the experiment. In block 1, the participant directs several
Exemplary gaze behavior of a typical participant. Figure 2          gazes to the critical area (Figure 2, top right). With
shows scan paths of a typical participant for the presentation      increasing practice, fewer fixations in the critical area are
and the retrieval phase of three trials, where the critical area    made (middle and bottom right).
was on the bottom right. Lines show saccades and circles
represent fixations with bigger circles indicating longer           Aggregated gaze behavior. Figure 3 shows the proportion of
fixations. Scan paths on the top left and right side of Figure      fixations in the critical area during the retrieval phase.
2 show a trial from block 1. In this trial, the sentence that       Proportions were aggregated for each block and across
was associated with the symbol in the bottom right area of          participants. Participants showing looking-at-nothing
the screen was probed for the first time.                           behavior should fixate in the critical area during the retrieval
                                                                    phase. To test this, for each block, we compared the
     Presentation phase                       Retrieval phase       proportion of fixations in the critical area with a chance
                              Block 1                               level of 25%. In block 1, the proportion of fixations in the
                                                                    critical area (37.2 %) is indeed above chance, tb1(17) = 2.09,
                                                                    p = .051, g = .99. In blocks 2 and 3 the proportion of
                                                                    fixations in the critical area were at chance levels, mean
                                                                    proportion block 2: 17.9 %, tb2(17) = –1.73, p = .102, g =
                                                                    .82; mean proportion block 3: 28.5 %, tb3(17) = 0.81, p =
                                                                    .426, g = .38. These results suggest that looking at nothing
                                                                    diminished from block 1 to block 2 and that the proportion
                                                                    of fixations did not vary meaningfully from chance in block
                              Block 2                               3.
                              Block 3
                                                                     Figure 3: Percentage of fixations in the critical area across
                                                                        blocks. Error bars represent standard error, dotted line
 Figure 2: Scan paths of one participant for a trial in block 1
                                                                                        indicates chance level.
     (top), a trial in block 2 (middle) and a trial in block 3
       (bottom) with the critical area at the bottom right.
     Left: presentation phase (scan paths of four sentence                                   Discussion
               presentations)1, right: retrieval phase.             Theories on the link between eye movements and auditory
                                                                    and semantic information processing (Huettig et al., 2010)
Scan paths on the left and right side in the middle of Figure       assume that during the encoding of information an
2 show a trial from block 2. In this trial, the sentence on the     integrated memory representation is formed from different
bottom right was probed for the second time. Scan paths on          modalities. However, these theories do not agree on how
the left and right side on the bottom of Figure 2 show gaze         much information is included in the memory representation.
behavior when the sentence was probed for the third time            Using the looking-at-nothing paradigm, we tried to shed
(block 3). Comparing scan paths from top to bottom on the           some light on this question.
left side of Figure 2, scan paths reveal that throughout the           Assuming an integrated memory representation as
experiment the participant kept on following the symbols            proposed by Ferreira et al. (2008), the probability of
during the presentation phase. In comparison, gaze behavior         triggering an eye movement during retrieval of information
in the retrieval phase (Figure 2, right) seems to change over       from memory will increase with the strength of the
                                                                    association between the different parts of the representation.
   1
     Longer fixations at the bottom right area are only shown by    Spivey (2007), on the other hand, proposed that only sparse
displayed data and not systematically. To control for gaze biases   internal representations are built during the encoding of
the critical area was randomized across trials.
                                                                  1073

information. Consequently, eye movements during memory            the cognitive system can use both. The question is, when do
retrieval occur mainly to gather information that is not yet      we rely on an internal memory representation and when on
included in the mental representation. According to Ferreira      an external memory store? Hoover and Richardson (2008)
et al. (2008), looking at nothing should increase with            and Johansson et al. (2010) suggest that looking at nothing
practice, while for Spivey (2007) the same behavior should        helps to relieve working memory when information is
diminish with practice.                                           retrieved from memory. For example, Johansson et al.
   Practice was induced by presenting participants with a set     (2010) presented participants with an auditory description of
of four sentences, 12 times. Each presentation phase was          a complex scene while participants had to fixate the center
followed by a retrieval phase where one sentence was              of a whiteboard. In a second condition they saw the picture
probed. To test whether the manipulation was successful,          of a complex scene but again had to fixate on the center of
we first checked if participants showed increasing                the picture’s scene. In both conditions, when they had to
performance in the retrieval task. Results show that over the     retell the information they had heard, and when they had to
three blocks, participants indeed replied with increasing         describe the visual scene, they drew the scene with their
accuracy and speed to the facts probing the presented             eyes on the whiteboard and did not maintain a central
sentences. Accuracy as well as response times revealed that       fixation. In contrast, in a study reported by Brand and Stark
the performance increase was stronger from the first to the       (1997), simple block patterns were used. During retrieval of
second block, than from the second to the third block. It         the block pattern, participants were allowed to look freely
seems that over the three blocks of practice memory               around the scene but kept a central fixation. Therefore,
associations for the sentences were strengthened leading to       Johansson et al. (2010) argue that looking-at-nothing
more correct and faster responses. Therefore, we conclude         behavior can relieve working memory load when task
that the practice manipulation was successful.                    demands (e.g., a complex scene description) require it.
   The question we wished to answer was how looking-at-              Applying the findings of Johansson et al. (2010) to our
nothing behavior would be affected by the content of the          results suggests that when memory load is high, looking at
memory representation. In block 1, participants looked more       nothing is shown. When memory load is low – because all
often to the critical area on the screen than a chance level of   relevant information has been learned – looking-at-nothing
25% would predict. In blocks 2 and 3 looking at nothing           behavior diminishes. Indeed, in block 1 of our study, when
diminished. In both blocks, fixations in the critical area did    the presented material was new to participants, looking at
not amount to more than that predicted by a chance level of       nothing was shown. Later, when the material was strongly
25%.                                                              represented in memory, looking at nothing diminished.
   Results of the first block replicated results of Richardson       Decreased looking-at-nothing behavior might also be
and Spivey (2000), which showed a close relationship              explained as the result of participants realizing over the
between gaze behavior and language processing. In block 1,        course of the experiment that the visual area they refixate on
information was not strongly represented in memory. Eye           no longer includes relevant information and therefore, this
movements were launched to the critical area on the screen        behavior becomes redundant. This implies that participants
in order to collect information from the visual scene. For        consciously control their gaze behavior. However, eye
blocks 2 and 3 we assumed that the looking-at-nothing             movements as described in the context of the looking-at-
behavior would become stronger or diminish, respectively.         nothing effect are a highly automatic and unconscious
Our results were not in line with the predictions of Huettig      behavior (Rayner, 2009). Furthermore, if change in gaze
et al. (2010), which stated that looking at nothing becomes       behavior were due to conscious control (i.e., participants
stronger as the association in memory is strengthened.            realize that during the retrieval phase, nothing is present
While performance improved over the three blocks, looking         anymore), we would then expect looking at nothing to
at nothing did not increase in strength. Our results seem to      diminish within the first block. Looking at data of the first
support the assumption of Spivey (2007) that looking-at-          four trials, we could not find such a tendency. Moreover, in
nothing behavior is executed to gather more information           the post-questionnaire participants did not report that they
from the environment. In blocks 2 and 3, the memory               controlled their gaze behavior.
representation might have included all relevant information.         We also realize that looking at nothing might not only
Thus, addressing an eye movement to the critical area on the      diminish because participants have learned the material, but
screen became ‘unnecessary’.                                      because they have given an automatic response to the
   We found that looking at nothing varies with the content       stimuli that does not include fixations to the critical area. To
of the memory representation. This supports the work of           rule out this alternative explanation one could present
Richardson et al. (2009), who assume the existence of an          participants with the same sentences throughout the course
internal memory story, whereby all relevant information is        of the experiment and sentences that change from trial to
stored in an integrated memory representation, and an             trial. If it is indeed the content of the integrated memory
external memory store (O’ Regan, 1992), which assumes             representation that is responsible for looking-at-nothing
only sparse memory representations and uses a spatial index       behavior, our results should be replicated in a way that
to address the visual world. Moreover, these are not              looking-at-nothing behavior diminishes for stable sentences
mutually exclusive abilities of the cognitive system. Instead,    and does not diminish for new sentences.
                                                                1074

  From the results of this study it can be concluded that       Hoover, M.A., & Richardson, D.C. (2008). When facts go
information is represented internally, and that under certain     down the rabbit hole: contrasting features and objecthood
conditions the external world is addressed in order to gather     as indexes to memory. Cognition, 108, 533–542.
more information (Spivey, 2007). We have further shown          Huettig, F., Olivers, C. N. L., & Hartsuiker, R. J. (2010).
that both ways of retrieving information are not necessarily      Looking, language, and memory: Bridging research from
mutually exclusive (Richardson et al., 2009). But, when is        the visual world and visual search paradigms. Acta
knowledge presented internally and when do we use an              Psychologica.        Advance        online       publication.
external memory store? We propose that working memory             doi:10.1016/j.actpsy.2010.07.013.
load may influence the decision to use either an internal or    Johansson, R., Holsanova, J., & Holmqvist, K. (2010). Eye
external memory store. However, a distinct boundary need          movements during mental imagery are not reenactments
not be imposed between these two modes of storage. Spivey         of perception. In S. Ohlsson & R. Catrambone (Eds.),
(2007) proposes that knowledge representations can be             Proceedings of the 32nd Annual Conference of the
described in a vague manner. That is, information can             Cognitive Science Society (pp. 1968-1973). Austin, TX:
belong to both internal and external storages. Bocklisch,         Cognitive Science Society.
Bocklisch, Baumann, Scholz, and Krems (2010) highlighted        Johansson, R., Holsanova, J., & Holmqvist, K. (2006).
a relationship between the concept of vagueness and               Pictures and spoken descriptions elicit similar eye
knowledge representations. This link could inform future          movements during mental imagery, both in light and in
research that tests the usefulness of this approach for the       complete darkness. Cognitive Science, 30, 1053–1079.
investigation of mental representations.                        Knoeferle, P., & Crocker, M. W. (2007). The influence of
                                                                  recent scene events on spoken comprehension: Evidence
                   Acknowledgments                                from eye movements. Journal of Memory and Language,
We would like to thank Nina Bär for helpful comments on           57(4), 519−543.
previous versions of this paper and Lars Eberspach for his      Laeng, B., & Teodorescu, D.S. (2002). Eye scanpaths
help in conducting the experiment.                                during visual imagery re-enact those of perception of the
                                                                  same visual scene. Cognitive Science, 26, 207–231.
                                                                O’Regan, J. K. (1992). Solving the ‘real’ mysteries of visual
                        References                                perception: The world as an outside memory. Canadian
Anderson, J. R., & Schooler, L. (1991). Reflections of the        Journal of Psychology, 46, 461−488.
  environment in memory. Psychological Science, 2, 396–         Pylyshyn, Z. (2001). Visual indexes, preconceptual objects,
  408.                                                            and situated vision. Cognition, 80, 127−158.
Altmann, G.T. (2004). Language-mediated eye movements           Rayner, K. (2009). The 35th Frederik Bartlett lecture: Eye
  in the absence of a visual world: the ‘blank screen             movements and attention in reading, scene perception and
  paradigm’. Cognition, 93, 79–87.                                visual search. The Quarterly Journal of Experimental
Altmann, G.T., & Kamide, Y. (2007). The real-time                 Psychology, 62 (8), 1457–1506.
  mediation of visual attention by language and world           Renkewitz, F. & Jahn, G. (2010). Tracking memory search
  knowledge: linking anticipatory (and other) eye                 for cue information. In A. Glöckner & C. Wittemann
  movements to linguistic processing. Journal of Memory           (Eds.), Foundations for tracing intuitions: Challenges,
  and Language, 57, 502–518.                                      findings and categorizations. New York: Psychology
Baddeley, A. (2000). The episodic buffer: A new                   Press.
  component of working memory? Trends in Cognitive              Richardson, D.C., Altmann, G.T.M., Spivey, M.J., &
  Sciences, 4, 417−423.                                           Hoover, M.A. (2009). Much ado about eye movements to
Bocklisch, F., Bocklisch, S.F., Baumann, M.R.K., Scholz,          nothing: a response to Ferreira et al.: Taking a new look at
  A., & Krems, J.F. (2010). The role of vagueness in the          looking at nothing. Trends in Cognitive Science, 13(6),
  numerical translation of verbal probabilities: A fuzzy          235−236.
  approach. In S. Ohlsson & R. Catrambone (Eds.),               Richardson, D.C., & Spivey, M.J. (2000). Representation,
  Proceedings of the 32nd Annual Conference of the                space and Hollywood Squares: looking at things that
  Cognitive Science Society (pp. 1974−1979). Austin, TX:          aren’t there anymore. Cognition, 76, 269–295.
  Cognitive Science Society.                                    Shepherd, M., Findlay, J. M. & Hockey, R. J.(1986). The
Brandt, S.A., & Stark, L.W. (1997). Spontaneous eye               relationship between eye movements and spatial attention.
  movements using visual imagery reflect the content of the       The Quarterly Journal of Experimental Psychology
  visual scene. Journal of Cognitive Neuroscience, 9,             Section A, 38(3), 475−491.
  27−38.                                                        Spivey, M. (2007). Uniting and Freeing the Mind. In: M.
Ferreira, F., Apel, J., & Henderson, J.M. (2008). Taking a        Spivey (Eds.), The continuity of mind. New York: Oxford
  new look at looking at nothing. Trends in Cognitive             University Press.
  Science, 12(11), 405−410.                                     Spivey, M.J, & Geng, J.J. (2001). Occulomotor mechanisms
Hoffman, J. E., & Subramaniam, B. (1995). The role of             activated by imagery and memory: eye movements to
  visual attention in saccadic eye movements. Perception &        absent objects. Psychological Research, 65, 235-241.
  Psychophysics, 57(6), 787−795.
                                                              1075

