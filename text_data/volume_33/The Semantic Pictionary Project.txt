UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Semantic Pictionary Project
Permalink
https://escholarship.org/uc/item/3zp031jv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Kievit-Kylar, Brent
Jones, Michael
Publication Date
2011-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                              The Semantic Pictionary Project
       Brent Kievit-Kylar (bkievitk@indiana.edu)                              Michael N. Jones (jonesmn@indiana.edu)
                  Cognitive Science Program                               Department of Psychological and Brain Sciences
       Indiana University, Bloomington, Indiana USA                          Indiana University, Bloomington, Indiana USA
                              Abstract                                 neuroimaging research demonstrating that when humans
   Here we describe the Semantic Pictionary Project—a set of
                                                                       process words (in isolation or in context) they automatically
   online games and tools designed to collect large amounts of         activate sensorimotor information about the perceptual
   structured data about the object characteristics and perceptual     features of the word’s referent, how it is commonly used,
   properties of word referents. The project hinges on the use of      and physical contexts in which it has been experienced (for
   encoding-decoding games and a set of creation tools to              a review, see Riordan & Jones, 2010). A large number of
   capture data using online crowdsourcing. We describe the            behavioral experiments also demonstrate convincing
   architecture of the basic tools behind the games, the structure     evidence that sensorimotor experience becomes an
   of the resulting data, and how this information may be
   integrated into existing statistical semantic models. We also       inseparable part of a word’s lexical representation, including
   describe two validations using data collected from one of the       information about object features (color, shape, motion,
   tools (2D Geon Pictionary) demonstrating typicality effects in      etc.). Perceptual information is an inherent part of the
   the metrics of raw Geon objects created by subjects, and            semantic organization of the human lexicon, but much of
   unique variance in the predictions of word pair metrics over        this information cannot be learned from statistics in a text
   currently used linguistic and property data.                        corpus—it must be learned from multisensory experience.
   Keywords:        Geon;     natural     language     processing;        Perceptually grounded SSMs are now emerging in the
   crowdsourcing; semantic space models; embodied cognition.           cognitive science literature (e.g., Andrews, Vigliocco, &
                                                                       Vinson, 2009; Recchia & Jones, 2010; Steyvers, 2010). As a
                          Introduction                                 proxy for sensorimotor perception, these new integrative
Humans learn about the meanings of words and larger                    models use norms of human-generated properties (e.g.,
discourse units from repeated experience with both                     McRae et al., 2005). These norms are collected by asking
linguistic and perceptual information. However, current                hundreds of subjects to produce the physical properties
models of lexical semantics focus only on learning from                (internal and external parts), appearance, sounds, smells,
linguistic structure using statistical abstraction algorithms.         tastes, functional properties, categorical membership, etc.
Part of the problem is the lack of realistic structured data           for concrete nouns and event verbs based on multisensory
containing information about the perceptual structure of               experience. A property vector for a word is then created by
word referents. Text is plentiful, but usable object structure         aggregating across subjects. For example, the property
data currently are not. Given the ideological movement                 <has_4_legs> will have a high probability for dog and cow,
towards models of embodied lexical representation, model               but a low probability for centipede, and a zero probability
development is currently being held up due to a lack of                for strawberry. However, <is_red> is a highly salient
structured human data containing configural object and                 property of strawberry and not for dog.
property information about concrete word referents. Here,                 The development of perceptually grounded SSMs is
we describe the NSF-funded Semantic Pictionary Project,                currently being held up by a lack of data. The overall goal of
an online approach to the problem of data capture that                 the Semantic Pictionary Project is to collect large amounts
makes use of the paradigms of crowdsourcing and online                 of object and property data online using a combination of
gaming to gather data containing the perceptual structure of           crowdsourcing and our new encoding-decoding games, and
word referents. The online games may be played at                      to make the large datasets available to researchers to
www.SemanticPictionary.org.                                            develop superior grounded semantic models.
    Statistical semantic models (SSMs; e.g., Landauer &
Dumais, 1997) have recently been attacked as implausible               The Semantic Pictionary Paradigm
cognitive models because they learn from only linguistic               The Semantic Pictionary paradigm is a two-stage task with
information and are not grounded in perception and action,             self-correction built in. In the first stage, subjects are
contrary to the literature on embodied cognition, and this             presented with a target word selected from the high-
limits their ability to account for human behavior on                  concreteness/early-AoA       nouns      from     the     MRC
semantic tasks (for a review of the debate, see de Vega,               Psycholinguistic Database. Subjects are then provided a tool
Graesser, & Glenberg, 2008). The inadequacy of SSMs as                 to make a representation of this noun, with the goal of
cognitive models punctuates the current movement in                    making a depiction such that another subject could guess
cognitive science towards models of embodied cognition.                what word is being represented (similar to the popular
There is a growing body of both behavioral and                         Pictionary game). That representation is then given to a
                                                                   2229

different subject to attempt to recover the initial label.         viewpoint variance, component connectivity, etc. that do not
Success at recovering the initial label is in indication of a      seem to be possible to mine from language (see Riordan &
valid and meaningful encoding by the first subject. The data       Jones, 2011). Property Pictionary capitalizes on verbal
created by this paradigm can then be used in various               feature generation to produce high-level descriptions of
modeling applications.                                             words including physical properties (internal and external
   Words can be encoded in a variety of ways. The goal is to       parts), appearance, sounds, smells, tastes, functional
build a symbolic representation of the word’s referent in a        properties, categorical membership, affordances, etc. not
constrained domain. Example domains could be other                 captured by the low-level Geon shape descriptions or the
words, physical shape, smell, or sound. In each domain, a          distributional structure of natural language.
specially constructed tool is used by subjects to generate the        In the following sections, we briefly describe the
feature set representing that word, and the feature set can        architectures of each of these GWAP tools as well as the
then be given to a different set of subjects to verify.            structure of the data they collect and how it may be
                                                                   integrated into existing statistical semantic models. Then we
Crowdsourcing                                                      turn to an analysis of data collected through the 2D Geon
Crowdsourcing is a paradigm that has recently emerged to           Pictionary game. We demonstrate that the information
use aggregate groups of humans to solve problems online            captured by the game can reproduce standard semantic
that are impossible for computers to currently solve.              typicality effects, and contains unique variance in semantic
Crowdsourcing takes advantage of crowd wisdom                      similarity used by humans but that is currently missing from
(Surowiecki, 2004) to capture data that only humans can            linguistic structure and verbal properties.
currently produce at a massive scale. GWAPs (“games with
a purpose”) take advantage of crowdsourcing and the                                   Property Pictionary
amount of human computation currently wasted on online             Property production norms have proven extremely valuable
games to capture data for practical purposes. For example,         in a variety of semantic experiments, and in cognitive
humans spend approximately 10 billion hours each year              models of semantic representation and processing.
playing solitaire online. Facebook’s Farmville game allows         However, these databases are currently limited to a few
users to grow virtual crops and form social relations with         hundred concepts. By taking lessons from McRae et al.’s
other players online—Farmville sees about 68 million users         (2005) original study and string normalizations, a
each day. GWAPs harness the power of human computation             crowdsourcing GWAP can potentially produce a database
for data labeling using an entertaining game. The original         like McRae’s spanning thousands of words in 1-2 years. In
GWAP was called the “ESP Game” (von Ahn, 2006; now                 addition, we will have “goodness of transmission” values
the “Google Image Labeler”). The ESP game used online              for features from the encoding/decoding paradigm that were
human computation to solve the problem of labeling images          not possible in McRae’s original lab-collected database.
and image components on the web. All of the Semantic               Verbally coded features contain perception and action
Pictionary GWAPs are available online and are also linked          information at a higher level than the Geon shape
to social media sites such as Facebook to collect massive          description, and both are needed to evaluate perceptual
amounts of structural data with crowdsourcing.                     integration in SSMs.
                                                                      In Property Pictionary, subjects are assigned to be
Semantic Pictionary Games                                          encoders or decoders. In the encoding phase, the subject is
There are two broad classes of data representation games we        presented with a target word (e.g., DOG) and is asked to
employ: Property Pictionary and Geon Pictionary. Property          generate N descriptive features such that a decoder could
Pictionary is a class of games in which the subject encodes        guess the target word from the features. Subjects gain points
the target as a set of constrained verbal features that            as encoders the more people who can correctly guess the
describe it. Property Pictionary can be thought of as an           target word from their feature encoding. When a certain
online crowdsourcing version of McRae et al.’s (2005)              number of words have been encoded, subjects then progress
feature generation task (originally collected in the               to the decoding phase, guessing the target word that is
laboratory), with the addition of a decoding phase in which        represented by the feature encoding produced by another
different subjects attempt to guess the target word given a        encoder for a different word. In this fashion, we are able to
generated feature vector. Geon Pictionary is purely                quantify the diagnosticity of produced features. An
nonverbal. When presented with a target word to encode,            encoding of DOG = [+has_wings, +is_made_of_metal, ...]
the subject uses an editor to create an object model the           will not only be very infrequent, but will also have a very
referent using a constrained set of Geons (Biederman, 1987)        low probability of anyone else guessing the target word
in either two- or three-dimensional space. The Geon object         given this encoded pattern.
constructed from a target word is then provided to different          We have conducted pilot tests of Property Pictionary
subjects to guess the target word given the image.                 using both traditional psychology subject pool players, and
   The two classes of games were selected to compliment            using subjects via Amazon’s Mechanical Turk
information learned well by corpus-based models. Geon              crowdsourcing site. In the pilot collection phase, we used
Pictionary collects information about object structure, color,     the same concrete nouns in McRae et al.’s (2005) original
                                                               2230

laboratory study, and built interactive checks at the input         tree-based version requires that geons be attached to one
phase that originally had taken a significant portion of time       another at specified attachment points to construct a
to manually recode after data collection in McRae et al.’s          hierarchical tree-based representation and phrase grammar.
norms. For example, if a subject typed in “has four legs” or        The ‘no-tree’ version is unconstrained with regards to
“is four legged” the input system would remap in real-time          attachment points between geons—this allows much faster
by suggesting the equivalent recoded label, e.g., “do you           production of images, but object similarities are reliant on
mean <has_4_legs> ?”                                                vector superposition since the object representation is flat
   The details of the Property Pictionary pilot norms have          rather than hierarchically structured. We next describe the
been described elsewhere (Recchia & Jones, 2011), so we             three-dimensional version of Geon Pictionary in detail, and
will just briefly summarize here. The online Property               then the restricted two-dimensional versions more briefly.
Pictionary version of the feature norms was remarkably well
correlated with the original McRae et al. (2005) laboratory-        Three-Dimensional Geon Pictionary
collected norms. The verbal features generated by our online        A final object generated with the 3D Geon Pictionary tool is
subjects were very similar to those generated by McRae et           a tree of Geon objects with properties and their connection
al.’s subjects in the laboratory setting. The correlations          or attachment constraints. Each Geon has the following
between words’ feature vectors in the online version and            properties:
McRae et al.’s original database produced a mean
correlation .83 (SD = .08). In addition, the semantic               Geon Type: Chosen from (cube, sphere, cyliner, cone,
similarity among words in each of the norms were highly             handle).
correlated. If one creates a word-by-word correlation matrix        Size: Scaling in the X, Y and Z axis in set increments (from
within each of the norms and then computes the correlations         50% to 350% of one unit in steps of 1%).
between rows of the two matrices, the mean correlation is
.96 (SD = .03). The online version of the norms also had            Rotation: Rotation around the X, Y and then Z planes in set
high similarities to other production characteristics of the        increments (from 0 to 6 radians in steps of .01 radians)
original norms; e.g., # of features, # of distinguishing            Color: Chosen from a reduced color set (original MSPaint)
features, # of visual-motor/forms, # of tactile features, etc.
The remainder of this paper will focus on validating the            The first Geon is set as the root of the model and each Geon
Geon Pictionary data.                                               added is then attached to the root at specified attachment
                                                                    points. An attachment point is defined as a pair of points,
                     Geon Pictionary                                one defining the location on the parent and one the location
Geon Pictionary games require the subject to produce an             on the child. The child is then moved such that these two
object image representing the referent of the target word           attachment points are aligned in the same three-dimensional
using a constrained set of components and attachments. If           point. The points defining potential attachments are the 27
given DOG as a target word, the subject essentially draws a         points formed by a bounding rectangle around the Geon (3
picture of a dog by selecting from a set of primitive geons,        potential values for the X, Y and Z axis).
adjusting shape, color, orientation, size, and attachment
structure of the components using our geon editor. This
image is then provided to a second subject to guess at what
target word the encoder is representing with the image. The
system is designed such that we maximize the potential
representable objects while at the same time having a
compact and constrained enough description that
meaningful comparisons can be made between objects. The
data structure of the resulting image is stored as a tree-based
representation of object configurations and properties, and
we have several similarity algorithms available to determine
the similarity among geon objects. The tree-based object is
represented as a phrase structure grammar, so the visual
object may be recoded to a text-based sentence. This allows
corpus-based models to integrate the statistical information
from the visual object while bypassing the problem of
providing the models with vision.
   The Semantic Pictionary website has two- and three-
dimensional versions of the Geon Pictionary game. The                    Figure 1. The build interface of the 3D Geon tool.
three-dimensional version is necessarily tree attachment
based (to preserve the object structure as viewpoint is                The basic web interface is shown in Figure 1. The 3D
rotated). The two-dimensional version has two versions. The         rendering is done with an in-lab developed 3D rendering
                                                                2231

tool so no external libraries are required (this greatly           tree structure requirement has been removed. Primitive
facilitates web distribution). The model can be rotated by         instances can be added to the scene in arbitrary locations.
dragging the mouse in the X or Y plane. Particular Geons           While this version makes it faster for the subject to produce
can be selected by clicking on them and deselected by a            an object, the resulting data structure is flat and requires
second click. The rendering window is also used in moving          different types of similarity algorithms to analyze.
Geons to new parent nodes. Controls allow the subject to
manipulate the color, scaling, rotation, and geon type of a
selected object or group of objects.
   Geons may be added to existing Geons (at default
connections points). Connected Geons can also manage
their attachment points. Since each Geon (except the root)
has exactly one parent, but may have multiple children, we
decided to show and let the subjects manipulate the
connection between the selected node and its parent.                   Figure 3. 2D Geon Pictionary click-and-drag interface.
Selecting appropriate attachment points is the most difficult
task for subjects and to facilitate this we have provided two
manipulation techniques. The connection can be modified                  Encoding, Decoding, and Extrapolation
by use of either radio buttons representing the connection in      For storage and transfer, models are encoded in a simple
the X, Y and Z axis, or by selecting the point by clicking on      shorthand coding. In this coding, key symbols are used to
the appropriate location on a 3D wireframe model of a cube         describe the tree structure and properties of instances. This
that shares its orientation with the Geon on the rendering         encoding is short and easy to transfer between systems. The
screen. Figure 2 shows a rendered object and the attachment        model is decomposed into a text-based encoding through a
point cubes.                                                       simple rule set. Each primitive instance can be decomposed
                                                                   into a sentence unit of the following form:
                                                                       [SENTENCE] = An [OBJECT] made up of a [ROOT
                                                                   OBJECT DESCRIPTION] [OBJECT DESCRIPTION] =
                                                                   [COLOR], [SCALE], [GEON] rotated [ROTATION] whose
                                                                   [CHILD ATTACHMENT POINT] is attached to the
                                                                   [PARENT ATTACHMENT POINT] of a [CHILD OBJECT
                                                                   DESCRIPTION] and a [CHILD OBJECT DESCRIPTION]
                                                                   ...
  Figure 2. A rendered object and attachment point cubes.                            A horse is made up of a brown, wide, Cube whose left,
                                                                                     top, front, is attached to the top, of a brown, narrow,
The web environment is written in php and provides three                             shallow, Cylinder whose right, top, front, is attached to
                                                                                     the top, of a brown, narrow, shallow, Cylinder whose
paths of interface, Amazon's Mechanical Turk, Facebook                               left, top, back, is attached to the top, of a brown, narrow,
application,      and       our      own      web      domain                        shallow, Cylinder whose right, top, back, is attached to
www.SemanticPictionary.org. The php code provides a                                  the top, of a brown, narrow, shallow, Cylinder whose
login system to manage users, a set of written and video                             right, bottom, is attached to the bottom, of a brown,
                                                                                     narrow, shallow, Cylinder whose center, is attached to
instructions on how to use the Geon tools, the actual                                the bottom, of a brown, wide, Sphere
building interface, the identification interface and a scoring
system.                                                            Figure 4. An example of a horse model converted to natural
                                                                                             text description.
Two-Dimensional Geon Pictionary
The two dimensional version of Geon Pictionary tool is             Vector Encoding of Object Structure
designed to have a very similar look and feel to its three         Though the models can be decomposed into natural
dimensional equivalent. There are two primary differences          language and read by any natural language engine, purpose
between these two tools. The first is that whereas the three       built translators for particular NLP models are likely to
dimensional system only allows subjects to select stepped          improve performance. We next describe an encoding
values for rotation and scale, the two dimensional system          algorithm for the BEAGLE semantic model (Jones &
allows arbitrary values. The connection interface for the two      Mewhort, 2007) to make use of the Geon models directly.
dimensional system also allows subjects to click and drag              BEAGLE uses a set of two holographic vectors to
Geons (and all descendents) and will automatically select          represent each word in a language. The first vector is the
the attachment point that would most closely represent the         environmental vector; this is the static representation of the
released location, which makes object production much              word in the universe (sampled from a Gaussian
faster. In addition to the tree-based version of the 2D game,      distribution). The second vector is the lexical vector, which
there is also a freeform no-tree version. In this version, the     stores the relational information learned by the system
                                                               2232

through interaction with the corpus. After learning, word           taken from a learned training run on a corpus). The vector
relations can be extracted though holographic operations on         representation for a given geon is simply the sum of the part
sets of vectors such as cosine for similarity. Algorithms may       vectors. The tree's holographic vector is then the root
then be applied to convert a model into a single holographic        instances holographic vector added to the holographic
vector usable by the BEAGLE model.                                  vector of its children with a present random permutation
   Each property value (color, scale, Geon type, rotation,          added at each level. As is shown in Figure 5, members of a
attachment points) is assigned a randomly generated                 semantic category that are rated as being more typical
permutation of dimension equivalent to the language model.          exemplars tend to look more like one another in their geon
After these are assigned, they will remain constant                 encodings as well. This effect is stable over all typicality
throughout all encodings. A primitive instance is then              bins (right panel), but also the individual categories (left
encoded as the point-wise sum of the relevant property              panel). These results suggest that at least part of typicality
vectors. Property vectors will be calculated in two different       structure can be encoded in how subjects describe word
ways depending on whether the property is continuous or             referents using our Geons, and this information would be
drawn from a small set. For those drawn from a small set            represented in our natural language or vector representations
such as Geon type, attachment point and possibly color, the         as unique variance to be used to enrich statistical semantic
property vector will simply be the natural language                 models that typically only have linguistic structure from
environmental vector for that word. This is useful since            which to make inferences.
those environmental vectors will already have relational
meaning from previous or post experience with
supplemental corpora (we would expect most of the color
names and many of the shape names to occur in common
English text).
   Those values from continuous sets such as scale and
rotation can be encoded with frequency-encoded vectors
where vector values are chosen from a distribution
reflecting the value of the property (higher values for
example, may shift a distribution). A model vector can then
be calculated from the vectors for each of its primitive
instances. To do this, each child is permuted by a static
random permutation and then added point-wise to its parent
representation.
  Information Structure in 2D Geon Pictionary
                                                                              Figure 5. Typicality effects in 2D Geon Pictionary
We assess the structure contained in 2D geon                               Pictionary
representations constructed by groups of subjects in two
tasks. In the first task, subjects were asked to generate geon      Predicting Word Pair Similarities
representations of the concrete nouns from Rosch’s (1975)           Using the same similarity metric applied to the 2D geon
study of semantic typicality. In studies of typicality effects,     representations, we computed the pairwise similarities
stimuli are normally words. Here, we evaluate the structure         between words from the McRae et al. (2005) norms
of the geon representations of those words using the above          (different group of subjects than produced the typicality
described similarity algorithm applied to the geons. In the         data). These pairwise similarities were then entered into a
second task, we had subjects produce geon representations           hierarchical regression to predict similarities between words
for words from the original McRae et al. (2005) norms, and          in WordNet using the JCN metric; JCN has been shown to
we assess the information contained in the geon                     give the best approximation to human judgments of
representations of those words compared to the McRae et al.         semantic similarity between words (Jones & Mewhort,
feature vectors and a corpus-based co-occurrence metric.            2007). Included in the regression was cosine similarity from
                                                                    the McRae norms and pointwise mutual information (PMI)
Semantic Typicality Effects                                         between the word pair in the TASA corpus.
Figure 5 shows the similarity structure among words from
Rosch’s (1975) high, medium, and low typicality                     Table 1. Hierarchical regression predicting WordNet pairs.
conditions. In verification experiments, subjects are
typically faster to verify that two high typicality exemplars                Model               R       FΔ           Partial R
are members of the same category (e.g., robin-sparrow)              PMI                        .158   377.11      .158
than medium (hawk-chicken) or low (penguin-ostrich)                 PMI + McRae                .344   1556.27     .096, .305
typicality exemplars. To compute similarity between geons
in Figure 5, each possible color, shape, rotation and scale is      PMI + McRae + Geon         .358   144.42      .096, .302, .084
assigned a random Gaussian vector (these values could be
                                                                                                                       all p < .001.
                                                                2233

       Figure 6. Similarity structure that is unique to the text, verbal feature, and geon object representations of words.
As Table 1 shows, there is a considerable amount of                                                 References
redundancy in the three variables when predicting variance              Andrews, M., Vigliocco, G., & Vinson, D. (2009). Integrating
in WordNet similarities. However, each also contains a               experiential and distributional data to learn semantic representations. Psyc
                                                                     Review, 116, 463-498.
significant portion of unique variance not accounted for by
                                                                        Biederman, I. (1987). Recognition-by-components: A theory of human
the others. We entered geon similarity to the regression             image understanding. Psychological Review, 94, 115-147.
equation as the last step to stack chance against it. However,          deVega, M., Graesser, A., & Glenberg, A. (2008). Symbols and
as Table 1 demonstrates, similarity between the geon                 Emboiment: Debates on Meaning and Cognition. NY: Oxford Press.
representations of the words predicts a significant portion of          Jones, M. N., & Mewhort, D. J. K. (2007). Representing word meaning
                                                                     and order information in a composite holographic lexicon. Psychological
variance that is not accounted for by the text-based or verbal       Review, 114, 1-37.
feature measures. Figure 6 shows this structure more                    Jones, M. N., & Recchia, G. (2010). You can’t wear a coat rack: A
clearly. The MDS plot is arranged so that proximities are            binding framework to avoid illusory feature migrations in perceptually
                                                                     grounded semantic models. Proceedings of the 32nd Annual Cognitive
based on similarity from the McRae et al. (2005) norms.
                                                                     Science Society.
The red lines show strong connections between items found               Landauer, T. K., & Dumais, S. T. (1997). A solution to Plato’s problem:
by their geon similarity that are not seen by the other              The latent semantic analysis theory of the acquisition, induction, and
metrics. Qualitatively, this includes a considerable amount          representation of knowledge. Psychological Review, 211-240.
                                                                        McRae, K., Cree, G. S., Seidenberg, M. S., & McNorgan, C. (2005).
of shape structure (e.g., the similarity between pizza and
                                                                     Semantic feature production norms for a large set of living and nonliving
coin), color (pickle-grasshopper) material (green plants and         things. Behavior Research Methods, Instruments, & Computers, 37, 547-
wood/metal), symmetry/asymmetry, internal consistency,               559.
etc. This information is important to human semantic                    Recchia, G., & Jones, M. N. (2011). Crowdsourcing large-scale
organization, but is neither learned by the text-based models        semantic feature norms. Paper presented at the Midwest Cognitive Science
                                                                     Conference, MSU.
nor is it well represented in standard verbal feature                   Riordan, B., & Jones, M. N. (2010). Redundancy in perceptual and
generation norms.                                                    linguistic experience: Comparing feature-based and distributional models
                                                                     of semantic representation. Topics in Cognitive Science.
                                                                        Rosch, E. H. (1975). Cognitive representations of semantic categories.
                    Acknowledgements                                 Journal of Experimental Psychology: General, 104, 192-233.
This research was supported by grants from Google                       Steyvers, M. (2010). Combining feature norms and text data with topic
Research and NSF BCS-1056744 to MNJ. We would like to                models. Acta Psychologica, 133, 234-243.
thank Ken McRae and Gabe Recchia for their guidance.                    Von Ahn, L. (2006). Games with a purpose. Computer.
                                                               2234

