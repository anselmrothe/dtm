UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Identifying Metaphoric Antonyms in a Corpus Analysis of Finance Articles
Permalink
https://escholarship.org/uc/item/93w9n56v
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Gerow, Aaron
Keane, Mark
Publication Date
2011-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

         Identifying Metaphoric Antonyms in a Corpus Analysis of Finance Articles
                                                     Aaron Gerow (gerowa@tcd.ie)
                                     School of Computer Science & Statistics, Trinity College Dublin
                                                      College Green, Dublin 2, Ireland
                                                 Mark T. Keane (mark.keane@ucd.ie)
                                 School of Computer Science & Informatics, University College Dublin
                                                          Belfield, Dublin 4, Ireland
                               Abstract                                  in almost all languages. Similar spatial metaphors, of the
                                                                         kind we examine here, seem to ground many stock-market
   Using a corpus of 17,000+ financial news reports (involving           reports. Accounts of index, stock-market, and share move-
   over 10M words), we perform an analysis of the argu-                  ments tend to converge around metaphors of rising and
   ment-distributions of the UP and DOWN verbs used to
                                                                         falling, attack and retreat, gain and loss. These concepts
   describe movements of indices, stocks and shares. In Study 1
   participants identified antonyms of these verbs in a free-re-         appear to be grounded by core metaphors, with an
   sponse task and a matching task from which the most                   antonymic relationship to one another, that could be glossed
   commonly identified antonyms were compiled. In Study 2, we            as GOOD IS UP and BAD IS DOWN. Lakoff and Johnson
   determined whether the argument-distributions for the verbs           (1980) have pointed to this UP-DOWN metaphor opposition
   in these antonym-pairs were sufficiently similar to predict the       as underlying accounts of wealth (WEALTH IS UP as in high
   most frequently-identified antonym. Cosine similarity correl-         class), the rise and fall of numbers (MORE IS UP; LESS IS
   ates moderately with the proportions of antonym-pairs identi-         DOWN) and changes in quantity (CHANGE IN QUANTITY
   fied by people (r = 0.31). More impressively, 87% of the time         IS WAR as in retreating profits and defensive trades).
   the most frequently-identified antonym is either the first- or
                                                                           In the present paper, we look at the distributive structure
   second-most similar pair in the set of alternatives. The implic-
   ations of these results for distributional approaches to determ-      of these verbs’ arguments to determine whether there is
   ining metaphoric knowledge are discussed.                             empirical support for metaphoric opposites. Specifically, we
                                                                         try to determine whether the antonyms identified by parti-
   Keywords: Metaphor; corpus analysis; word meaning;                    cipants in a psychological study can be shown to meaning-
   semantics; experimental linguistics; grounding.                       fully correspond to a computational analysis of the argu-
                                                                         ment-distributions in our corpus.
                           Introduction
In recent years, significant progress has been made in                                            The Corpus
deriving meaning from statistical analyses of distributions              In January, 2010, we carried out automated web searches
of words (Gerow & Keane, 2011a; Landauer & Dumais,                       that selected all articles referring to the three major world
1997; Michel et al., 2010; Turney & Pantel, 2010). This                  stock indices (Dow Jones, FTSE 100, and NIKKEI 225)
distributional approach to meaning takes the view that words             from three websites: the New York Times (NYT,
that occur in similar contexts tend to have similar meanings             www.nyt.com), the Financial Times (FT, www.ft.com) and
(cf. Wittgenstein, 1953) and that by analysing word usage we             the British Broadcasting Corporation (BBC, www.b-
get at their meaning. For example, the word co-occurrence                bc.co.uk). These searches harvested 17,713 articles
statistics derived in Latent Semantic Analysis (LSA) seem to             containing 10,418,266 words covering a 4-year period:
tell us about the structure of the lexicon, as they are good             January 1st, 2006 to January 1st, 2010. The by-source
predictors of reaction times in lexical decision tasks (Land-            breakdown was FT (13,286), NYT (2,425), and BBC
auer & Dumais, 1997). More generally, it has been suggested              (2,002). The by-year breakdown was 2006 (3,869), 2007
that significant insights into human culture and behaviour can           (4,704), 2008 (5,044), 2009 (3,960), and 2010 (136). The
be derived from analysing very large corpora, like the Google            corpus included editorials, market reports, popular pieces,
Books repository (Michel et al., 2010). In this paper, we apply          and technical exposés. These three resources were chosen
similar distributional analyses to understand metaphoric-                because they are in English and have a wide-circulation and
ally-structured knowledge underlying the antonyms between                online availability. The Financial Times made up the
“UP" and "DOWN” verbs from a corpus of financial news                    majority of the articles; however, the spread was actually
reports. (see Gerow & Keane, 2011b, for an analysis of meta-             much wider as many articles were syndicated from the
phor hierarchies in the same data.)                                      Associated Press, Reuters, Bloomberg News, and Agence
   Lakoff (1992; Lakoff & Johnson, 1980) have argued that                France-Presse. The uniqueness of the articles in the database
our understanding of many concepts, such as emotions and                 was ensured by keying them on their first 50 characters.
mental states, are grounded in a few ubiquitous metaphors.                  Once retrieved, the articles were stripped of HTML,
The spatial metaphors that structure emotional states –                  converted to UTF-8, and shallow-parsed to extract phrasal
HAPPINESS IS UP and SADNESS IS DOWN – are found                          structure using a modified version of the Apple Pie Parser
                                                                     3288

(Sekine, 1997). Each article was stored in a relational data-        automating the generation of semantically resolute phrases
base with sentential parses of embedded noun- and verb-              (Brown et al., 2005). Online lexicons, such as WordNet and
phrases. Sketch Engine was used to lemmatise and tag the             LSA, have been used to generate and resolve analogies by
corpus (Kilgarriff et al., 2004). Sketch Engine is a web-            modelling synonymy (Turney, 2006; Veale, 2004). Such
based, corpus-analysis tool that lemmatises and tags                 work approaches semantics, and specifically antonymy,
customised corpora with part-of-speech tags using the                between words and phrases, but avoids conceptual meta-
TreeTagger schema (Schmid, 1994). A lemma is a singular,             phors. Lakoff (1992) offers a cognitive theory of metaphor,
part-of-speech token (e.g., verb or noun) that includes all          one in which linguistic metaphors are related, but distinct,
tenses, declensions, and pluralizations of a given word. For         from the metaphoric concepts they structure. Deignan
example, the one verb lemma “fall” includes instances such
                                                                     (2005) offers a bridge between concept and language, by
as “fall”, “fell” and “falls”, whereas the noun lemma “fall”
                                                                     proposing a cline between metonymy (part-whole relation-
includes “a fall” and “three falls”. Sketch Engine provides
so-called “sketches” of individual lemmas. For example, the          ship) and metaphor. Deignan’s link from metonymy to
sketch for fall-n (the word “fall” as a noun) is different from      metaphor is a good example of a corpus-based approach to
the sketch for fall-v (“fall” as a verb.) With some lemmas,          metaphor because it preserves the cognitive structures
the differences marked by part-of-speech are large, such as          proposed by Lakoff, while making the link between
with store-n compared to store-v. These sketches facilitated         semantics (words) and metaphor (thought) explicit. Here,
the statistical analysis of the most common arguments of             we explore this link with regard to antonyms.
verbs. For example, one of the most common verbs in the                In this article, we report two studies examining these
corpus was “fall,” which took a range of arguments with              issues. Study 1 was a study of participants’ identification of
different frequencies (e.g., “DJI”, “stocks”, “unemploy-             antonyms in two distinct tasks: a free-generation task
ment”). Throughout this paper, when we refer verbs we take           (where one is given rise and asked for its opposite) and a
this to mean verb lemmas.                                            match-the-opposite task (where one is asked to match rise to
                                                                     its opposite in a set of words). The word-sets were drawn
   Table 1: The percentage of the argument-distributions of rise     from the above corpus and consisted of a set of positive, UP
            and fall for their 10 most frequent arguments.           verbs (e.g., rise, soar, rally) and more negative, DOWN
                                                                     verbs (e.g., fall, lose, dip; see Table 2). Study 2 examined
       Rise         % of Total          Fall          % of Total     the argument-distributions of the antonym-pairs chosen by
       (Arg)          (Freq)           (Arg)           (Freq)        participants in Study 1 to see if they were, in any way,
       index          7.39%            index           6.97%         predictive of the choices made. To anticipate our findings,
       share          5.67%             share          6.41%         we find that argument distributions correlate moderately
       point          4.83%             point          3.75%         with the frequencies of antonym choices made by people.
      percent         2.90%           percent          2.97%         Furthermore, in the majority of cases, the most similar
                                                                     distribution for an antonym pair corresponds to the pair
       price          2.43%             price          2.83%
                                                                     most-frequently chosen by people.
       stock          2.00%             stock          2.78%
       yield          1.90%             yield          1.77%                    Table 2: The UP and DOWN verb used in studies.
        cent          1.31%              cent          1.34%
       profit         0.91%            profit          1.34%                      UP-verbs                     DOWN-verbs
        rate          0.90%              rate          1.24%             occurrences (% corpus*)       occurrences (% corpus*)
                                                                             rise     29,261 (4.20%)      fall     39,230 (4.20%)
                    (Nrise = 39,261; Nfall = 39,230).
                                                                             gain     13,134 (1.40%)      lose     12,298 (1.30%)
                   Metaphoric Antonyms                                   increase     6,158 (0.67%)   decrease       123 (0.01%)
                                                                           climb      5,631 (0.60%)     tumble      2,135 (0.23%)
From a distributional perspective, the arguments of a verb
and its antonym (like rise and fall) should have a definite                 jump      4,960 (0.53%)       slip      3,336 (0.36%)
structure that identifies their relationship to one another.                rally     4,190 (0.45%)     retreat     1,474 (0.20%)
That is, the frequency distribution of the arguments taken by            advance      2,385 (0.26%)      slide      2,777 (0.30%)
rise should have a lot in common with the argument-distri-                 surge      2,313 (0.25%)     plunge      1,592 (0.17%)
bution of its antonym fall (see Table 1). Furthermore, if we
                                                                          recover     2,165 (0.23%)    worsen        500 (0.05%)
look at other less-strongly-paired antonyms, like rise-lower
or rise-decrease, then the similarity in their argument distri-              soar     1,649 (0.18%)   plummet        443 (0.05%)
butions should be less. Specifically, we should find that a              rebound      1,220 (0.13%)        dip      1,322 (0.14%)
computational measure of similarity, such as cosine simil-               alleviate     134 (0.01%)     decline      3,672 (0.39%)
arity, between the words’ argument-distributions should be                elevate       52 (0.01%)       drop       8,377 (0.90%)
predictive people’s choice of antonyms.
                                                                           strong      718 (0.07%)       weak       1222 (0.13%)
  Within a larger body of work on automated semantic
tagging and semantic parsing, some work has focused on                       ease     2,243 (0.35%)       sink      1,339 (0.14%)
                                                                 3289

 Table 3: The percentages of antonym-pairs identified in the two              Study 1: People’s Antonym Choices
  tasks (T1 and T2) of Study 1 and their cosine similarity scores
(Sim). Total % is the mean percent occurrence across both tasks;     In this study, participants were either given the positive, UP
  bold words were only generated in the free-response task (T1).     verbs or the negative, DOWN verbs and asked to perform
                                                                     two tasks on the set (a free-generation task, always followed
      Antonym pair                                                   by a match-the-opposite task). The measure was the
                          Task 1 % Task 2 % Total % Sim
   (prompt-response)                                                 frequency with which a particular pair was identified in
advance-climb                 7%         0%          4%      0.98    either task.
advance-leave                 7%         0%          4%      0.62
alleviate-worsen             40%         0%         20%      0.86     Method
climb-fall                   46%        17%         31%      0.98
                                                                      Participants Twelve students at University College Dublin
climb-plunge                  0%         8%          4%      0.97
                                                                               voluntarily took part in the study; five male and
decline-rise                 20%        33%         27%      0.93
decline-incline              30%         0%         13%      0.42              seven female. All were native English speakers.
drop-rise                    10%        42%         26%      0.99              Participants were assigned to one of the two condi-
drop-climb                    0%        25%         13%      0.98              tions; receiving either all UP verbs or DOWN
ease-hard                    29%         0%         14%      0.12              verbs as prompts in both tasks of the study.
ease-worsen                  14%         0%          7%      0.85
elevate-decrease              0%        10%          5%      0.88
                                                                      Materials The set of UP verbs and DOWN verbs shown in
elevate-fall                 18%        70%         44%      0.79              Table 2 were used as the materials.
exacerbate-alleviate         10%        75%         43%      0.87     Procedure Participants were given written and verbal
exacerbate-ease               0%        25%         13%      0.86               instructions indicating that they would be asked to
fall-gain                     0%         8%          4%      0.96               carry out two tasks that involved identifying “the
fall-increase                 0%         8%          4%      0.56               opposites of the presented words”. For the free-gen-
gain-lose                    33%        92%         63%      0.94               eration task (Task 1) they were read the list of
gain-slide                    0%         8%          4%      0.98               words, one-by-one, and asked to verbally respond to
increase-decrease           100%       100%        100%      0.92               these prompts. Responses were timed and recorded
increase-drop                 0%         8%          4%      0.58
                                                                                during the study and later transcribed by the experi-
jump-fall                    29%        33%         31%      0.98
jump-tumble                   0%        17%          8%      0.99
                                                                                menter. After Task 1 the experimenter presented the
lose-find                    17%         0%          8%      0.89
                                                                                second task. Note there were no constraints on the
lose-win                     17%        17%         17%      0.87               responses for the first part of the study.
plummet-jump                 50%         0%         25%      0.97                   For the match-the-opposite task (Task 2), parti-
plunge-elevate               10%        37%         23%      0.77               cipants were given a sheet of paper with two
plunge-fly                   20%         0%         10%      0.80               columns of words. The left column was the list of
plunge-rise                  10%        17%         13%      0.97               prompts from the Task 1, and the right column was
rally-fail                    7%         0%          4%      0.94               a list of potential opposites. Their job was to draw
rally-retreat                 7%        42%         24%      0.94               lines from the column of prompt-words on the left-
rebound-retreat               0%        17%          8%      0.95               hand side to their “best opposite” on the right-hand
rebound-slip                 20%        33%         27%      0.92
                                                                                side. Note, that they were instructed that they could
recover-decline               0%        29%         14%      0.87
recover-lose                  6%        15%         11%      0.84
                                                                                indicate more than one word if they were
retreat-advance              34%        67%         50%      0.92               considered tied for “best opposite”. When this task
rise-fall                    73%        42%         57%      0.99               was completed, the sheet was collected and parti-
rise-sink                    10%        25%         18%      0.95               cipants were debriefed on the rationale for the study.
sink-elevate                 10%         0%          5%      0.72
                                                                      Scoring Note that whether participants are given the UP or
sink-float                   40%         0%         20%      0.53
slide-climb                  10%        37%         23%      0.99
                                                                               DOWN verb-sets they tend to produce the same
slide-stable                  0%        20%         10%      0.05              pairs; that is, one could be given rise and produce
slip-advance                  0%        17%          8%      0.97              fall, the rise-fall antonym-pair or one could be
slip-slide                   10%         0%          5%      0.99              given fall and produce rise generating the same
soar-fall                    43%        17%         30%      0.95              rise-fall antonym-pair. As there were no clear
soar-plummet                  0%        33%         17%      0.97              differences in the pairs identified by participants
stable-dip                    0%         8%          4%      0.08              who were presented either all UP verbs or DOWN
stable-unstable              43%         0%         21%      0.85              verbs, the scoring was performed on the two condi-
surge-plunge                  7%        33%         20%      0.98              tions collapsed together. In scoring the data, we
surge-decrease               14%         0%          7%      0.76
                                                                               noted the frequency of a particular antonym-pair
tumble-climb                 20%        25%         23%      0.98
tumble-rebound                0%        33%         17%      0.93
                                                                               produced from a particular prompt (e.g., rise or fall)
volatile-stable              21%        69%         45%      0.95              as a proportion of the total number of presentations
volatile-strong              10%         0%          5%      0.92              of that prompt, in either the first or second task.
weak-strong                  93%       100%         96%      0.96
weak-stable                   0%        25%         13%      0.95
                                                                  3290

Results & Discussion                                                    predictable from the argument-distributions of the verbs . In
General Characteristics of the Data. In all, participants               the next study, we turn to this key issue. To reiterate our
                                                                        hypothesis, we expect that an empirical analysis of the
identified 114 unique antonym pairs to the 30 presented
                                                                        distributional similarity between verb-arguments will
words (combined UP- and DOWN-verbs). On average, a
                                                                        correlate to the the results of the study presented in this
given prompt-word gave rise to almost five alternative                  section.
antonym pairs (M = 4.8) with a range from 2 (for weak,
participants produced weak-strong and weak-stable) or 9                   Study 2: Similarity of Antonym Distributions
alternative pairs (e.g., elevate-drop, elevate-fall). On
average, in the free-generation task participants suggested             Study 1 gives us a set of human data on how people tend to
one antonym (M = 1.37) that was not in the opposing set                 identify antonyms, in this study we compare these identific-
used in the match-the-opposite task (e.g., when presented               ations to a corpus analysis of the argument distributions of
with stable several participants suggested unstable as the              the same words. Our hypothesis was that by taking a
antonym, but readily chose volatile as its antonym in the               distributive approach to knowledge, we might be able to
matching task). Overall, people vary significantly in the               identify antonyms by analysing the arguments they take.
antonyms identified for a prompt word. However, for a                   Study 1 provides a way of validating our computational
group of people, there is usually a clear most-fre-                     analysis of these words’ argument distributions.
quently-identified antonym. For instance, on average, 96%
of participants chose strong when prompted with weak or                 Method
weak when prompted with strong. Table 3 shows the overall               Materials All the same words used in Study 1 were used in
percentage for the top two most frequently identified                             this analysis. We also included the words generated
antonym-pairs for each prompt word. Note, that a conser-                          by the participants in Study 1 that were not in our
vative estimate of chance across both tasks would be close                        original material list.
to 5%. This chance-level computation is simply an observa-              Procedure Taking the 114 antonym pairs in Study 1, we
tion of all available choices in Task 2 along with those free-                    assembled them into a set of word-vectors by the
generation choices in Task 1 that were not available in Task                      frequency of their arguments given by Sketch
2. This means that the chance-level estimation of 5% is                           Engine (Kilgarriff, 2004). Each verb had anywhere
much more conservative because in Task 1, as the entire                           from 250 to 2,000 arguments in its vector (if a
English lexicon is available to the participant. Thus, though                     particular word was found in one vector of a pair,
some percentages are low, they are well above chance.                             but not in the other, it was given a frequency of
  The Free-Generation Task. A notable aspect of the data is                       zero2). We examined a number of similarity meas-
how different the percentages are for identified antonyms in                      ures including Euclidean distance, cosine simil-
the two tasks. The free-generation task allowed participants                      arity, and Kullback-Leibler divergence. We also
to name whatever antonym came to mind, some of which                              compared methods of cutting and smoothing the
were not included in the set for Task 2. However, if one                          tails of the distributions to mitigate the effects of
looks at the most-frequently-identified antonyms, there are                       low-frequency arguments. Markedly, the most
only five cases (out of 60) where “another” antonym was                           successful measure was cosine similarity, in which
identified frequently. This means that we can be confident                        the distribution’s tail was not cut or smoothed. This
that the match-the-opposite task was not overly constrained                       measure was applied to the vectors of all words in
in the choices given to participants.                                             each of the 114 antonym pairs and similarity scores
  The Match-the-Opposite Task. In this task, the choice of                        noted. Correlations were computed between this
antonym was restricted to the 15 contrasting words, with                          measure and the proportions for different antonym-
participants being given the option to choose more than one.
                                                                                  pairs in Task 1 and Task 2 separately, as well as the
This is a more constrained task in which to identify
antonyms and produced a generally clearer pattern                of               combined totals (see Table 3).
antonym-pair identification1. There are clear winners in
terms of favoured antonym pairs; notably, increase-de-                  Results & Discussion
crease (100%), elevate-fall (44%) and alleviate-exacerbate              Overall, the argument-distributions of the words provide a
(43%). Note that some of the low percentages occur because              moderately effective means for identifying the most-fre-
one of the words in the pair is used by another very                    quently-chosen antonym pairs.
dominant antonym; so, for example, the listings for fall-                 Correlations to All Antonym-Pairs. The Pearson correla-
gain and fall-increase are very low (4%; though below                   tions between the cosine similarity scores and the propor-
chance) because fall-rise (implicitly listed in rise-fall) has a        tions in each of the tasks and overall, reveal a moderate
high percentage (57%).                                                  correlation (r = 0.31) for Task-2 x Cosine-Similarity . The
  In itself, this data is interesting but does not answer the           other measures reveal low correlations for Task-1 x Cosine
posed question of whether these patterns of behaviour are
1                                                                       2
  By necessity when a word is generated in Task 1 but not present         Note, we also used 1 instead of 0, a technique that is sometimes
in Task 2, the percentage has to be 0 in Task 2 (as it was not used     used to control the effects of the tail of the distribution, but it did
as a word prompt).                                                      not produce notably different results to those reported.
                                                                    3291

Similarity (r = 0.10) and Total-% x Cosine Similarity (r =                               Acknowledgements
0.25). It is perhaps not surprising that the best correlation is
                                                                     This work was carried out as part of a self-funded MSc in
found in the more constrained task where people’s choice of          the Cognitive Science programme at the University College
antonym was more restricted. That such correlated regular-           Dublin by the first author. Thanks to Trinity College Dublin
ities could be found for data from a relatively small sample         and Prof. K. Ahmad for support and supervision of the first
(n = 12) is, we believe, very encouraging for the veracity of        author’s PhD during the preparation of this paper. Thanks to
this technique. However, the correlation only gives us a             K. Hadfield and four anonymous reviewers for valuable
general sense of the correspondence; the more demanding              suggestions.
question is whether the most-frequently-identified antonyms
specifically emerge from the computational analysis of                                        References
argument-distributions.
                                                                     Brown, J. C., Frishkoff, G. A., & Eskenazi, M. (2005).
   Identifying Most-Frequently-Identified Antonyms. Table 3
                                                                       Automatic questions generation for vocabulary assess-
shows the top-two most-frequently-identified antonyms for
                                                                       ment. In Proceedings of the conference on Human
a given prompt word in the UP- and DOWN-verb sets. In
                                                                       Language Technology and Empirical Methods in Natural
the column showing the cosine similar score (Sim) for an
                                                                       Language Processing (pp. 819-826).
antonym, when the score is shown in bold it indicates that
                                                                     Deignan, A. (2005). A corpus-linguistic perspective on the
this was the highest similarity score for all the alternative
                                                                       relationship between metonymy and metaphor. Style, 39
antonym-pairs in the set. So, in 60% of cases the most-fre-
                                                                       (1), 72-91.
quently identified antonym-pair was also the one with the
                                                                     Gerow, A. & Keane, M. T. (2011a). Mining the web for the
highest-similarity score in its set of antonym-pairs. If we
                                                                       “voice of the herd” to spot stock market bubbles. To
widen this assessment to accept the highest and second-
                                                                       appear in Proceedings of the 22nd International Joint
highest scored antonym pair, then 87% of the pairs that
                                                                       Conference on Artificial Intelligence.
emerge from the corpus analysis were identified as most-
                                                                     Gerow, A. & Keane, M. T. (2011b). Identifying metaphoric
frequent antonyms by participants. This is a very good
                                                                       antonyms in a corpus analysis of finance articles. To
correspondence between the predictions of the computa-
                                                                       appear in Proceedings of the 33rd Annual Meeting of the
tional measure and the results of the human data.
                                                                       Cognitive Science Society.
                                                                     Kilgarriff, A., Rychlý, P., Smrž, P., and Tugwell, D . (2004).
                    General Discussion                                 The sketch engine. In Proceedings of EU-RALEX (pp.
Metaphors, and their linguistic instantiations, structure not          105-116).
only the way we converse, but the way we think. In this              Lakoff, G. & Johnson, M. (1980). Metaphors we live by .
paper we have shown that a statistical analysis of the argu-           Chicago, IL: University of Chicago Press.
ment-distributions can be used to identify antonymic verb-           Lakoff, G. (1992). The contemporary theory of metaphor.
pairs – pairs that refer to opposing metaphors in our know-            In Andrew, Ortony (ed.) Metaphor and Thought 2nd
ledge (cf. Lakoff, 1992).                                              Edition . Cambridge: Cambridge University Press.
  The strongest antonyms identified by participants in Study         Landauer, T. K. & Dumais, S. T. (1991). A solution to
1 are shown to be predictable by looking at statistical regu-          Plato’s problem: The latent semantic analysis theory of
larities of word-usage in a corpus. In itself, this is an inter-       acquisition, induction, and representation of knowledge.
esting result, but it also lends support to an emerging body           Psychological Review, 104, 211-240.
of work on finding meaning behind word-use statistics (see           Michel, J.-B. et al. (2010). Quantitative analysis of culture
Turney & Pantel, 2010 for a survey). Specifically, vector              using millions of digitized books. ScienceExpress, 10
space models, a form of which we employed in Study 2 of                (1126).
this paper, have been used in computational research on              Schmid, G. (1994). TreeTagger ― a language independent
document summarisation, comparison, information extrac-                part-of-speech tagger. (http://www.ims.uni-stuttgart.de
tion, searching, and indexing. These models, have also                 /Tools/DecisionTreeTagger.html).
found cognitive relevance in analogy resolution, semantic            Sekine, S. (1997). The apple pie parser, v5.9. (http://nlp.c-
priming and comprehension, and word-sense disambigu-                   s.nyu.edu/app/).
ation. This growing body of work, as well as the current             Turney, P. D. (2006). Similarity of semantic relations.
paper, bridges a gap between words and meaning.                        Computational Linguistics, 32 (3), 379-416.
   In another paper, using the same corpus, we show that             Turney, P. D. & Pantel, P. (2010). From frequency to
metaphoric verbs, exhibit a partially-subsumptive hierarch-            meaning: Vector space models of semantics. Journal of
ical structure (Gerow & Keane, 2011b). Both papers show                Artificial Intelligence Research, 37, 141-188
that, in this financial domain, there are clear statistical regu-    Veale, T. (2004). WordNet sits the SAT: A knowledge-based
larities in word usage that can be used as pointers to the             approach to lexical analogy. In Proceedings of the 16th
underlying structure and organization of metaphors. We                 European Conference on Artificial Intelligence (pp. 606-
believe that this is an important finding. Indeed, both papers         612).
bridge a gap, analogous to the word-meaning gap, between
linguistic and conceptual metaphors.
                                                                 3292

