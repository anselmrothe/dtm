UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Discovering Inductive Biases in Categorization through Iterated Learning
Permalink
https://escholarship.org/uc/item/1gc7q7d2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Canini, Kevin
Griffiths, Thomas
Vanpaemel, Wolf
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

        Discovering Inductive Biases in Categorization through Iterated Learning
                                             Kevin R. Canini (kevin@cs.berkeley.edu)
                                       Thomas L. Griffiths (tom griffiths@berkeley.edu)
                                           University of California, Berkeley, CA 94720 USA
                                      Wolf Vanpaemel (wolf.vanpaemel@psy.kuleuven.be)
                                       Department of Psychology, University of Leuven, Belgium
                                             Michael L. Kalish (kalish@louisiana.edu)
                   Institute of Cognitive Science, University of Louisiana at Lafayette, Lafayette, LA 70504 USA
                              Abstract                                 more flexible, and can represent categories that consist of
   Progress in studying human categorization has typically in-         multiple clusters of stimuli spread out across a stimulus space
   volved comparing generalization judgments made by people to         (Nosofsky, 1998). Evaluating these models thus becomes a
   those made by models for a variety of training conditions. In       problem of determining the nature of human inductive biases.
   this paper, we explore an alternative method for understand-
   ing human category learning—iterated learning—which can                In this paper, we use a novel approach to evaluate different
   directly expose the inductive biases of human learners and cat-     models of category learning. Rather than studying the gen-
   egorization models. Using a variety of stimulus sets, we com-       eralizations people make with different training stimuli, we
   pare the results of iterated learning experiments with human
   learners to results from two prominent classes of computa-          use an experimental method designed to provide direct access
   tional models: prototype models and exemplar models. Our re-        to people’s and models’ inductive biases. In this experimen-
   sults indicate that human learning is not perfectly captured by     tal method, iterated learning, each participant is trained with
   either type of model, lending support to the theory that people
   use intermediate representations between these two extremes.        stimuli that are selected from the responses of the previous
   Keywords: categorization; inductive bias; iterated learning;        participant. This results in a sequence of category structures
   Bayesian methods                                                    each produced by learning from the previous structure. Math-
                                                                       ematical analysis of this process shows that as the sequence
                          Introduction                                 gets longer, the structures that emerge will be consistent with
The ability to learn new categories from examples is a basic           the inductive biases of the learners (Griffiths & Kalish, 2007).
component of human cognition, and one of the earliest to be            Intuitively, iterated learning magnifies the small effects that
studied by psychologists (Hull, 1920). This long history of            inductive biases have on people’s generalizations, until those
investigation has resulted in a number of computational mod-           biases are all that is reflected in the data. We use iterated
els of category learning, including approaches based on infer-         learning to expose the inductive biases of human learners
ring decision rules (Ashby & Gott, 1988), extracting proto-            and compare them to those of categorization models. Our
types (Reed, 1972), memorizing exemplars (Medin & Schaf-               work demonstrates that iterated learning complements tradi-
fer, 1978; Nosofsky, 1986), and combinations of these meth-            tional categorization experiments and provides a new dataset
ods (Nosofsky, Palmeri, & McKinley, 1994; Vanpaemel &                  against which computational models can be compared.
Storms, 2008). This proliferation of models has been com-
plemented by an empirical literature comparing the ability of                        Models of category learning
different models to account for human behavior. In a typical           A wide range of formal approaches have been used to model
experiment, participants are taught the category membership            human categorization. In this paper, we organize our analysis
of a set of training stimuli and then asked to generalize to a         around two of the most prominent models—prototype and ex-
set of test stimuli. Computational models are evaluated on             emplar models—illustrating how our approach can be used to
their ability to predict the resulting patterns of generalization.     evaluate categorization models by empirically exploring hu-
   Competing models of category learning are commonly pre-             man inductive biases. In future work, we hope to extend this
sented in terms of their different assumptions about people’s          analysis to incorporate a more extensive range of models.
mental representations of categories and the processes that
translate these representations into behavior. However, we             Prototype models
can also think about these models more abstractly: as meth-            Prototype models of categorization represent each category
ods of learning categories that have different inductive biases.       with a single point—the prototype—which captures the cen-
In machine learning, the inductive bias of a learner is defined        tral tendency of that category (Reed, 1972). The similarity
to be those factors other than the observed data that lead the         of a novel stimulus x to a category j is given by η j (x) =
learner to favor one hypothesis over another (Mitchell, 1997).         exp{−d(x, µ j )}, where µ j is the prototype of category j, and
Different models of category learning favor different kinds            d(·, ·) is some distance metric between stimuli. The distance
of hypotheses about the structure of categories. For exam-             metric can be chosen to be more sensitive to certain dimen-
ple, a prototype model favors hypotheses in which categories           sions, reflecting the fact that category members may have
are coherent groups of stimuli, while an exemplar model is             more or less variance along each dimension. Given a collec-
                                                                   1667

tion of observed category members, the probability of classi-
fying a novel object x under category j is calculated as
                                β j η j (x)γ
                    P( j|x) =                     ,          (1)
                              ∑ j0 β j0 η j0 (x)γ                          (a)             (b)            (c)              (d)
where β j is a response bias towards category j, and γ is a         Figure 1: Stimuli used in the experiment. (a) Shepard circles,
response scaling parameter.                                         (b) rectangles, (c) Cortese blobs, and (d) Shepard blobs.
Exemplar models
Exemplar models (Medin & Schaffer, 1978; Nosofsky, 1986)            ticipant or a learning model) are not directly specified by the
represent a category with all of its observed members. Rather       experimental design; rather, they are sampled from a previous
than calculating a single prototype for each category, exem-        learner’s generalization responses. The learners are arranged
plar models sum over all previously observed examples, the          into a chain, where the responses from the first learner are
exemplars. The similarity of a novel stimulus to category j is      used as training data for the second learner, and so on. Be-
given by η j (x) = ∑y∈ j exp{−d(x, y)}, where y is an exemplar      cause each learner’s responses depend only on the previous
belonging to category j, and d(·, ·) is again some suitable dis-    learner’s, the chain is formally a Markov process, and there-
tance metric between stimuli. Given a collection of categories      fore the responses will converge to a stationary distribution.
and observations, the probability of classifying a novel object        Griffiths and Kalish (2007) provided an analysis of iterated
x under category j is the same as in the prototype models,          learning under the assumption that learners use Bayesian in-
given by Equation 1.                                                ference, sampling hypotheses from the posterior distribution
                                                                    given by Bayes’ rule: P(h|d) ∝ P(h)P(d|h). In this case, the
Interpolating between prototypes and exemplars                      observed responses in the iterated learning chain will con-
Prototype and exemplar models can be viewed as opposite             verge to the prior distribution P(h), therefore allowing us to
ends of a spectrum of models which vary in the complexity of        directly expose the inductive biases of the learners in the form
their representations. Prototype models use the simplest rep-       of the prior over hypotheses.
resentation: a single point for each category, while exemplar
models use the most complex representation: all observed                       Exploring human inductive biases
category members. Recently, models have been developed              Using the iterated learning methodology, we performed a cat-
which interpolate between these extremes by grouping the            egorization experiment to explore the inductive biases of both
observed stimuli into clusters and representing each cluster        people and models and to create a new dataset which can be
using a single point. These models adopt a flexible represen-       used as a resource by other researchers.
tation where clusters are added as warranted by the data. Ex-
amples include SUSTAIN (Love, Medin, & Gureckis, 2004),             Method
the varying abstraction model (Vanpaemel & Storms, 2008),
                                                                    Participants The experimental participants included 640
the rational model of categorization (Anderson, 1991), and
                                                                    workers from Amazon Mechanical Turk, who received a pay-
the hierarchical Dirichlet process (Griffiths, Canini, Sanborn,
                                                                    ment of $0.50, and 160 students at the University of Cali-
& Navarro, 2007; Teh, Jordan, Beal, & Blei, 2006). Because
                                                                    fornia, Berkeley, who received course credit, for a total of
these models can behave like prototype models, exemplar
                                                                    800. The experiment had 16 conditions, resulting from the
models, or anything in-between, they can potentially explain
                                                                    combination of four stimulus sets and four initial category
experimental results that suggest that people use flexible rep-
                                                                    structures. The eight conditions with the Cortese blobs and
resentations to learn categories.
                                                                    Shepard circles were each replicated six times, and the eight
                     Iterated learning                              conditions with the other two stimulus sets were each repli-
                                                                    cated four times. Each replication of each condition consisted
The categorization models introduced in the previous section
                                                                    of an iterated learning chain of 10 generations. Each partic-
correspond to learners with different capabilities and pref-
                                                                    ipant was randomly assigned to a chain in their pool (either
erences for category representations. In categorization re-
                                                                    Mechanical Turk or Berkeley students), occupying the next
search, comparisons of different models typically proceed by
                                                                    available generation in the chain.
presenting each model (as well as human participants) with
a set of training data and comparing the generalization pre-        Stimuli The experiment involved four different sets of stim-
dictions made by the learners. While this method allows us          uli, each of which varied on two dimensions (see Figure 1).
to quantitatively measure the degree to which each model ex-        Two of the stimulus sets had separable dimensions, meaning
plains the human data, it does not directly expose the under-       the dimensions on which they varied are easily differentiated.
lying inductive biases of the learners. Iterated learning is an     These were rectangles that varied in their width and height,
experimental method designed to give a pure estimate of in-         and “Shepard circles” (Shepard, 1964): circles of a varying
ductive biases (Griffiths & Kalish, 2007).                          diameter with a radius drawn at a varying angle. The other
   The central concept of the iterated learning framework is        two stimulus sets had integral dimensions: their dimensions
that the training data given to a learner (either a human par-      are not readily apparent, leaving no preferred coordinate sys-
                                                                1668

                         (a) Shepard circles                                                     (b) Rectangles
                          (c) Cortese blobs                                                    (d) Shepard blobs
Figure 2: Samples of human data from the experiment. Each row is an iterated learning chain; two replications of each
condition are shown. Black vs. gray pixels indicate category membership, and each image is the generalization responses of
a single learner. Each learner learned from examples from the categories shown to the immediate left. In (a), the y-axis is the
circle’s diameter and the x-axis is the angle of its radius. In (b), the y-axis is the rectangle’s width and the x-axis is its height.
tems for these stimuli in psychological space. These were              did not have any contact with other learners from different
both amoeba-like shapes, one from Cortese and Dyre (1996)              generations. The training phase was organized into blocks
which we call “Cortese blobs”, and the other from Shepard              containing 32 trials each, with the order of presentation of
and Cermak (1973) which we call “Shepard blobs”. The                   the stimuli randomized within each block.
construction of both of these stimulus sets involves varying              If the participant correctly answered at least 22 of the 32
the amplitudes and phase-shifts of components of periodic,             training trials1 in any training block, they continued to the
trigonometric functions, which are then converted to closed            test phase. Otherwise, they completed another block of the
loops. For each stimulus set, we constructed an equal-spaced,          training phase. If after 20 blocks or 25 minutes, a participant
8-by-8 grid of stimuli and used these 64 to train and test the         had not yet reached the learning threshold, the experiment
human learners.                                                        was ended, and the data collected so far were not included
                                                                       in further analyses. There were 21 participants who reached
Procedure Each participant completed a training phase and              the maximum number of blocks and 16 who reached the time
a test phase. In the training phase, the participant was trained       limit without achieving the criterion. These participants were
to reproduce the category memberships of a random selec-               replaced by others to fill in their positions in the chains.
tion of 32 of the 64 stimuli. In the test phase, each participant
classified all 64 items in random order without feedback. In           Results
each training trial, the participant classified a single stimu-        No significant differences were found between the two partic-
lus from the training set with feedback. For first-generation          ipant pools, so their data were combined in all further analy-
learners, this feedback was based on one of four initial cate-         ses. Figure 2 shows two representative chains of 10 genera-
gory structures, which are shown in the first columns of Fig-          tions for each of the 16 conditions, with gray vs. black pixels
ure 2. Two of the initializations—the first and third distinct         indicating category membership.2 In each row, the first panel
ones—are simple linear boundaries compatible with a proto-             shows the initial category structure, and all other panels show
type model. The other two are discretized versions of cate-            the category assignments made by a learner in the test phase
gory structures described by McKinley and Nosofsky (1995).
                                                                           1 22/32 correct responses indicates with p < 0.05 that the re-
For the remaining generations, feedback was provided ac-
                                                                       sponses are not purely random, according to an exact Binomial test.
cording to the test phase responses of the participant in the              2 To promote further exploration of the results by other
previous generation. Participants were not made aware that             researchers, the full set of results is available online at
their test responses would be used in later generations and            http://cocosci.berkeley.edu/iteratedCatData/.
                                                                  1669

                                                           Prototype model                               Exemplar model
            Stimulus set     Dimensions   Distribution*    Covariance*       γ          ε      r*        c        γ        ε
           Shepard circles    Separable     Laplace        independent 1.3731       0.1516      1     0.8245 2.0678     0.1448
             Rectangles       Separable     Laplace        independent 0.9034       0.1662      1     0.9257 1.5144     0.1651
            Cortese blobs      Integral      Normal            full       0.6516    0.0434      2     0.3717 3.7737     0.0417
           Shepard blobs       Integral      Normal            full       1.0195    0.5093      2     0.8171 1.1993     0.3096
Table 1: The model parameters fit to the human data. * shows parameters fixed by the experimenter rather than fit to the data.
γ are response scaling parameters, ε are noise mixture parameters, r is the exponent of the distance metric, and c is specificity.
after being trained on the category structure to its left.            To evaluate whether human inductive biases are consistent
   Most of the Shepard circle chains converged to fairly sim-         with those of the categorization models, we performed the
ple structures using categorization boundaries aligned with           same iterated learning procedure using the models.
one of the dimensions. For the rectangles, people seem to
prefer three main types of category structures: one with a            Deriving the inductive biases of the models
category of items on or near the main diagonal (correspond-           We first set the various model parameters, fixing some based
ing to squares and square-like rectangles), one with a bound-         on the properties of the stimulus sets and fitting others to
ary between the categories along the main diagonal (corre-            the human data. The results of the experiment with human
sponding to wide vs. tall rectangles), and one with a category        learners using the rectangle stimulus set suggest that people
along the top and left borders (corresponding to very narrow          prefer an alternative set of dimensions: the logarithms of the
or very short rectangles). The Cortese blob chains seem to            area (width × height) and aspect ratio (width ÷ height) of
favor boundaries which are roughly aligned with the horizon-          the rectangles. These dimensions roughly correspond to the
tal axis, but with some variability in their curvature. The re-       main diagonals in the plots in Figure 2(b). Indeed, previous
sults for the Shepard blobs seem quite noisy. Perhaps people          work indicates that the logarithms of the area and aspect ratio
interpreted these stimuli in feature spaces which are rather          are more psychologically salient dimensions than width and
different from the dimensions we used to plot the results, or         height (Krantz & Tversky, 1975). Correspondingly, we per-
perhaps because these stimuli are difficult to interpret, peo-        formed the model fitting and subsequent analyses using this
ple’s inductive biases about them are very weak.                      alternative feature space for the rectangle stimulus set.
                                                                         For stimuli with separable dimensions, it is appropriate
Convergence analysis For all of the stimulus sets, the
                                                                      to use an `1 (city-block) distance metric, while for stimuli
chains appear to have converged to their stationary distribu-
                                                                      with integral dimensions, an `2 (Euclidean) distance metric
tions. To quantitatively verify this, we performed a clustering
                                                                      is appropriate (Shepard, 1964). Therefore, for the separable
analysis of the test phase data. The category structures from
                                                                      stimuli, the prototype model’s similarity function was cho-
each generation of each chain were clustered using the k-
                                                                      sen to be the product of Laplace distribution functions on
means algorithm, with the variation of information (VI) met-
                                                                      each dimension d: η j (x) = ∏d exp{−|xd − µ j,d |/b j,d }/2b j,d ,
ric (Meila, 2003) used as the distance function between pairs
                                                                      where µ j,d and b j,d are the parameters of the category pro-
of category structures. The VI metric is a measure of the dis-
                                                                      totype. This implies the distance function d(x, (µ j , b j )) =
tance between partitions, so it depends only on how stimuli
                                                                      ∑d (|xd − µ j,d |/b j,d − 2b j,d ). The prototype parameter µ j,d
are classified, and not the locations of those stimuli in the
                                                                      was set as the sample median of the observed values on di-
feature space. The VI metric is invariant to relabelings of the
                                                                      mension d, and we set b j,d = 1/N j ∑i |xi,d − µ j,d |, the aver-
categories, so two structures which are identical but switch
                                                                      age absolute difference between the category members and
the category labels would have a VI distance of zero.
                                                                      the median µ j,d . These correspond to maximum likelihood
   Clustering the results from all conditions and generations         parameters for the Laplace distribution. For the integral stim-
of human data, we found that using 10 clusters gave a rea-            uli, the prototype model’s similarity function was chosen to
sonable result. We used a χ2 test on the histograms of the            be the multivariate normal distribution, using the maximum
number of responses in each of the 10 clusters, comparing             likelihood estimates for the mean and covariance matrix pa-
across pairs of generations in all the chains. We found sta-          rameters. For all stimuli, we set the response biases β j = 12 .
tistically significant differences (p < 0.05) between the ini-           The distance function of the exemplar model was set to
tial category structures and all others, as well as between the       d(x, y) = c(∑d |xd − yd |r )1/r , with r = 1 for the separable
first generation of learners and each of the last two genera-         stimulus sets and r = 2 for the integral sets, corresponding
tions. This analysis suggests that the overall distribution of        to `1 and `2 distance metrics, respectively. The parameter c
responses has converged to the stationary distribution by the         is the model’s specificity—analogous to the variance-tuning
second generation. To be conservative, we used only the last          parameters in the prototype models—and was fit to the hu-
five generations of human data in our further evaluations.            man data separately for each stimulus set. The response bias
                                                                      β j was set to be 1/N j , the inverse of the number of cate-
 Comparing human and model inductive biases                           gory members, to remove the inherent bias of the exemplar
The experimental results described above give a picture of the        model to prefer categories with more observed members, a
inductive biases of human learners for various stimulus sets.         bias which is not present in the prototype model and would
                                                                  1670

                 (a) Prototype model: Shepard circles                             (b) Exemplar model: Shepard circles
                    (c) Prototype model: Rectangles                                  (d) Exemplar model: Rectangles
                  (e) Prototype model: Cortese blobs                                (f) Exemplar model: Cortese blobs
                  (g) Prototype model: Shepard blobs                               (h) Exemplar model: Shepard blobs
Figure 3: Fitted model simulations. The format is the same as Figure 2. One replication per condition and model is shown. The
rectangle stimuli were presented to the models using the alternative dimensions of log-area and log-aspect ratio, but the plots
above use height and width as the x and y axes.
otherwise introduce a confounding factor in their comparison.       additional clusters more or less likely. When α is large, more
   The response scaling parameter γ was fit to the human data       clusters are inferred, and in the limit α → ∞, each datapoint
separately for each stimulus set and each model. Addition-          is assigned to its own cluster. When α is small, fewer clusters
ally, we found that a certain proportion of the human learners      are inferred, and in the limit α → 0, only a single cluster is
appeared to be responding at random during the test phase, so       inferred. In this way, the DPMM generalizes both the pro-
all models were mixed with a noise component, from which            totype and exemplar models, depending on the choice of α
responses were assumed to be generated uniformly at ran-            (Sanborn, Griffiths, & Navarro, 2006). By specifying a prior
dom. Participants were probabilistically assigned to the noise      distribution, the value of α can be inferred from the observed
component using the expectation-maximization (EM) algo-             data rather than being set at a fixed value.
rithm, with the prior probability ε of noise component mem-            While the DPMM is a useful model of categorization
bership being fit to the data. The results of the model fitting     (Griffiths et al., 2007), it also provides us a way of analyzing
procedures are summarized in Table 1.                               the responses of human category learners and categorization
   The fitted models were run through the same iterated learn-      models by inspecting the inferred number of clusters in their
ing experimental framework as the human learners, with four         category structures. Using a Gibbs sampling procedure, we
replications of each condition. As with the human data, only        fit a DPMM to each set of responses from the human data
the last five generations of each chain were used for analysis.     and model results, collecting a set of samples from the poste-
A sample of the results is shown in Figure 3.                       rior distribution over the number of clusters and the value of
                                                                    α. The results of this analysis are summarized in Figure 4.
Evaluation of human and model results                                  For the Shepard circles, the prototype model seems to pro-
To quantitatively compare the human data to the model re-           vide a better fit to the human data, while for the Shepard
sults, we fit a Dirichlet process mixture model (DPMM)              blobs, the exemplar model is a better match. For the rectan-
(Ferguson, 1973) to each set of responses. The DPMM is a            gles, neither model seems to capture the inductive bias of hu-
model which probabilistically clusters a set of observed data,      man learners, and the results suggest that a model using inter-
where the number of clusters is inferred from the data rather       mediate representations might be a better fit. For the Cortese
than specified as a parameter. One of its hyperparameters, α,       blobs, the prototype model produces results which have more
indirectly controls the number of inferred clusters by making       clusters than either the human data or the exemplar results;
                                                                1671

        1                                     Exemplar                                            4
                                              Human(0+1+2)
                                              Human(0+1)                                         3.5
       0.8                                    Human(0)
                                                                                                  3
                                              Prototype
                                                                                                 2.5
                                                                                    # clusters
       0.6
   _                                                                                              2
       0.4                                                                                       1.5
                                                                                                  1
       0.2
                                                                                                 0.5
        0                                                                                         0
             Shepard circles    Rectangles   Cortese blobs   Shepard blobs                             Shepard circles   Rectangles   Cortese blobs   Shepard blobs
                               (a) Inferred α value                                                       (b) Inferred number of clusters per category
Figure 4: Evaluation results for the human data and model simulations. Error bars have length twice the standard error. The
bars labeled “Human(0+1+2)” reflect all the human data, “Human(0+1)” are participants assigned to the noise component of at
most one model, and “Human(0)” are those not assigned to the noise component of either model.
this can be explained by the relatively low response scaling                    Griffiths, T. L., Canini, K. R., Sanborn, A. N., & Navarro, D. J.
parameter that was fit for this stimulus set (see Table 1). A                     (2007). Unifying rational models of categorization via the hi-
                                                                                  erarchical Dirichlet process. In Proceedings of the 29th annual
more psychologically plausible feature space might improve                        conference of the cognitive science society (p. 323-328).
the modeling results for the Cortese blobs.                                     Griffiths, T. L., & Kalish, M. L. (2007). Language evolution by it-
                                                                                  erated learning with Bayesian agents. Cognitive Science: A Mul-
                                                                                  tidisciplinary Journal, 31(3), 441–480.
                Conclusions and future work                                     Hull, C. (1920). Quantitative aspects of the evolution of concepts.
                                                                                  Psychological Monographs, XXVIII(1).
As a whole, our results suggest that the human learners’ in-                    Krantz, D. H., & Tversky, A. (1975). Similarity of rectangles: An
ductive biases are not always consistent with those of proto-                     analysis of subjective dimensions. Journal of Mathematical Psy-
type or exemplar models, but can vary depending on the stim-                      chology, 12(1), 4–34.
                                                                                Love, B. C., Medin, D. L., & Gureckis, T. M. (2004). SUSTAIN:
uli. This supports the notion that models which use more flex-                    A network model of category learning. Psychological Review,
ible representations and can interpolate between the behavior                     111(2), 309-332.
of prototypes and exemplars provide a better explanation of                     McKinley, S. C., & Nosofsky, R. M. (1995). Investigations of ex-
                                                                                  emplar and decision bound models in large, ill-defined category
the variable nature of human categorization. However, per-                        structures. Journal of Experimental Psychology: Human Percep-
haps our most significant contribution is the creation of a new                   tion and Performance, 21(1), 128-148.
dataset for evaluating categorization models, which we hope                     Medin, D. L., & Schaffer, M. M. (1978). Context theory of classifi-
                                                                                  cation learning. Psychological Review, 85(3), 207-238.
will be subjected to further analyses by other researchers.                     Meila, M. (2003). Comparing clusterings by the variation of infor-
   In future work, we plan to conduct analyses using more                         mation. In B. Schlkopf & M. K. Warmuth (Eds.), Learning theory
psychologically plausible feature spaces for these stimuli,                       and kernel machines (Vol. 2777, p. 173-187). Springer.
                                                                                Mitchell, T. M. (1997). Machine learning. New York: McGraw
which can be obtained through multidimensional scaling                            Hill.
studies. We also plan to extend our analysis to include in-                     Nosofsky, R. M. (1986). Attention, similarity, and the identification-
termediate models of categorization mentioned earlier, which                      categorization relationship. Journal of Experimental Psychology:
                                                                                  General, 115, 39-57.
interpolate between prototypes and exemplars. Work by                           Nosofsky, R. M. (1998). Optimal performance and exemplar models
Griffiths et al. (2007) has shown that in traditional catego-                     of classification. In M. Oaksford & N. Chater (Eds.), Rational
rization studies, the hierarchical Dirichlet process is capable                   models of cognition (p. 218-247). Oxford University Press.
                                                                                Nosofsky, R. M., Palmeri, T. J., & McKinley, S. C. (1994). Rule-
of explaining human data that neither prototypes nor exem-                        plus-exception model of classification learning. Psychological
plars adequately model; we hope that these results can also be                    Review, 101(1), 53-79.
replicated using the iterated learning experimental method.                     Reed, S. K. (1972). Pattern recognition and categorization. Cogni-
                                                                                  tive Psychology, 3, 393-407.
Acknowledgements This work was supported by grants IIS-                         Sanborn, A. N., Griffiths, T. L., & Navarro, D. J. (2006). A more ra-
                                                                                  tional model of categorization. In Proceedings of the 28th annual
0845410 and BCS-0704034 from the National Science Foundation.                     conference of the cognitive science society.
                                                                                Shepard, R. N. (1964). Attention and the metric structure of the
                                References                                        stimulus space. Journal of Mathematical Psychology, 1(1), 54–
                                                                                  87.
Anderson, J. R. (1991). The adaptive nature of human categoriza-                Shepard, R. N., & Cermak, G. W. (1973). Perceptual-cognitive
  tion. Psychological Review, 98(3), 409-429.                                     explorations of a toroidal set of free-form stimuli. Cognitive Psy-
Ashby, F. G., & Gott, R. E. (1988). Decision rules in the perception              chology, 4(3), 351–377.
  and categorization of multidimensional stimuli. J. Experimental               Teh, Y. W., Jordan, M. I., Beal, M. J., & Blei, D. M. (2006). Hier-
  Psychology: Learning, Memory, and Cognition, 14(1), 33-53.                      archical Dirichlet processes. Journal of the American Statistical
Cortese, J., & Dyre, B. (1996). Perceptual similarity of shapes                   Association, 101(476), 1566-1581.
  generated from Fourier descriptors. J. Experimental Psychology:               Vanpaemel, W., & Storms, G. (2008). In search of abstraction:
  Humam Perception and Performance, 22(1), 133–43.                                The varying abstraction model of categorization. Psychonomic
Ferguson, T. S. (1973). A bayesian analysis of some nonparametric                 Bulletin & Review, 15(4), 732-749.
  problems. The Annals of Statistics, 1(2), 209–230.
                                                                             1672

