UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An online model of the acquisition of phonotactics within Optimality Theory
Permalink
https://escholarship.org/uc/item/59w5k7dr
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Giorgio, Magri
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

     An online model of the acquisition of phonotactics within Optimality Theory
                                               Giorgio Magri (magrigrg@gmail.com)
                                      Institut Jean Nicod, École Normale Supérieure, 29 rue d’Ulm
                                                            75005 Paris, France
                               Abstract                                 constraint ∗ D ORSAL assigns violations to dorsal consonants
                                                                        (i.e. it is violated by the candidates [kl] and [k]). Faithful-
   Within the mainstream phonological framework of Optimality
   Theory (OT), grammars are parameterized by how they pri-             ness constraints measure how much a candidate differs from
   oritize or rank a given set of constraints. OT online learning       the corresponding target. For instance, the constraint M AX
   consists of slight re-rankings triggered by exposure to a sin-       assigns a violation for every deleted target segment (i.e. it is
   gle piece of data at the time. This paper presents a new online
   model for the acquisition of phonotactics in OT. Convergence         violated by the candidate [k] but not by [kl] for the target /kl/).
   and correctness are analytically investigated and the proposed       Two or more constraints can conflict. For example, M AX
   model is shown to be superior to existing OT online models.          prefers the candidate [kl] over [t] as the production of the tar-
   Keywords: Language Acquisition; Phonotactics; Optimality             get /kl/, while ∗ D ORSAL prefers [t] over [kl]. Grammars dif-
   Theory; Online algorithms.                                           fer in how they prioritize or rank these constraints. And con-
                                                                        flicts among constraints are resolved by a grammar in favor
                 Description of the model                               of the constraint it top ranks, in the sense that a phonological
English speakers know that blik would be a possible word                target is mapped to the (provably unique) winner candidate
while bnik would not, despite the fact that both are unattested         that satisfies condition (2) for any other loser candidate.
in the English lexicon. The knowledge of this distinction be-
                                                                           (2)    Among those constraints that assign to the pair of the
tween licit vs. illicit sound combinations is called phonotac-
                                                                                  target and the winner a different number of violations
tics. In carefully controlled experimental conditions, one-
                                                                                  than to the pair of the target and the loser, the top
year olds already react differently to licit vs. illicit sound
                                                                                  ranked one assigns less violations to the former.
combinations. They thus display knowledge of phonotactics
at an early stage, when other linguistic abilities (most notably        These ideas are formalized in the mainstream phonological
morphology) are still lagging behind (Hayes, 2004). How is              framework of Optimality Theory (OT) developed by Prince
that possible? This paper tackles the problem of the acquisi-           and Smolensky (2004), that I assume in this paper. This
tion of phonotactics from a computational perspective.                  framework ties up well with the recent bloom of interest for
   The acquisition of phonotactics is gradual: the target adult         models based on orders and rankings in Machine Learning
grammar is approached through a path of conservative inter-             (see the 2009 NIPS Workshop on Learning with rankings).
mediate stages. This gradualness is illustrated in (1) with                At this early stage of research on the acquisition of phono-
some spontaneous productions of two children attempting to              tactics, it makes sense to keep the learning problem as simple
say clock(s), from McLeod, Doorn, and Reed (2001).                      as possible. I thus assume that the set of constraints is univer-
                                                                        sal, shared by both developing children and adults and thus
   (1) 2:3      2:5 2:6 2:8             2:8 2:10 2:11 3:1
                                                                        needs not be learned. For instance, the constraint ∗ D ORSAL
          t2k   l2k      dk fl2k        k2k k@l2:k kl2k kl2k
                                                                        is motivated both by the process of fronting in child phonol-
          t2k   l2k d2k Tl2k            k2k k2k kl2k kl2k
                                                                        ogy (/k/ → [t]) as well as by languages that lack velars entirely
               fl2kT kl2kT Tl2k         k2k k@l2k kl2ks
                                                                        (e.g. Tahitian). The constraint is available also to English
               kl2kT                           k@l2k k2k
                                                                        speakers, but low ranked. The typology of adult phonotactics
We see reduction of the target cluster /kl/ with sonority-driven        and the typology of child intermediate stages thus coincide,
preservation of the obstruent (/kl/ → [k]); we see reduction to         consisting of the collection of all possible rankings.
the fronted obstruent (/kl/ → [t]); etcetera. We need a compu-             The gradualness illustrated in (1) suggests a model
tationally sound model of the acquisition of phonotactics that          whereby the learner entertains a current hypothesis of the
is able to describe the observed gradualness.                           target phonotactics that gets updated over time based on ex-
   Assume that each attempted phonological form (say, the               posure to phonotactically licit adult forms, describing a path
cluster /kl/) comes with a preassigned set of candidate pro-            within the space of possible phonotactics. This intuition can
ductions (say, the cluster [kl] itself, the two singleton conso-        be formalized as follows. At every time t, the model main-
nants [k] and [l]; and variants thereof such as [f] or [t]). The        tains a current ranking, that represents its current hypothe-
relevant properties of a target phonological structure and a            sis. This current ranking is represented as a numerical vector
corresponding candidate are extracted by a set of phonologi-            θt = (θt1 , . . . , θtn ), where n is the number of constraints and θtk
cal constraints, that measure how that pair deviates from the           is the ranking value of constraint Ck at time t. Constraint Ch
ideal along various dimensions. There are two types of con-             is ranked above constraint Ck at time t iff θth > θtk . The ini-
straints. Markedness constraints measure how much a can-                tial ranking vector top ranks the markedness constraints, and
didate violates wellformedness conditions. For instance, the            thus corresponds to a smallest language. The current ranking
                                                                   2012

vector is updated over time as follows. The model receives a           contains a unique W, as in (7a); or else multiple W’s, say two
piece of data from the target adult phonotactics, say the word         as in (7b). The former case (7a) is simple: we know that the
clock. It thus infers that the target /kl/ should be faithfully        unique WPC must in the end be ranked above the LPCs, ir-
mapped to the winner candidate [kl]; see (Hayes, 2004) for             respectively of the rest of the data. The case (7b) is instead
discussion. The model then picks (at random or according               delicate: we don’t know which of the two WPCs needs in the
to some refined procedure) a non faithful candidate, say [t].          end to be ranked above the LPCs, as one of them might have
If the current ranking prefers the loser unfaithful candidate          to be ranked low, depending on the rest of the data.
[t] over the faithful winner candidate [kl] according to (2),                            ... Ch   ... Ck    ...  C`   ...
then the model updates its current ranking vector according                (7)   a.
                                                                                     
                                                                                        ... ... ...   W    ...   L   ...
                                                                                                                          
to the general scheme (3). For instance, if the target is /kl/ and                                                       
the current grammar prefers the unfaithful production [t] over                   b.     ...  W   ...  W    ...   L   ...
[kl], then the algorithm might demote ∗ D ORSAL (that prefers          According to Boersma’s re-ranking rule (6), WPCs get pro-
the loser) and promote M AX (that prefers the winner).                 moted by 1, both in the case of a simple ERC (7a) with a
   (3) a. Decrease the ranking value of loser-preferring con-          unique W and in the case of a challenging ERC (7b) with
            straints (LPCs), i.e. constraints that prefer the un-      multiple W’s. This does not look like a good idea though, as it
            faithful loser candidate over the faithful winner one;     does not capture the crucial difference between the two cases.
                                                                       Here is a more principled alternative. In the simple case (7a),
         b. increase the ranking value of winner-preferring con-
                                                                       the unique WPC can be confidently promoted by the same
            straints (WPCs), i.e.constraints that prefer the faith-
                                                                       amount LPCs are demoted, say 1. But in the challenging case
            ful winner candidate over the unfaithful loser one.
                                                                       (7b), we should be cautious and split our confidence between
What is relevant about loser and winner candidates for a given
                                                                       the two WPCs, promoting each one just by 1/2. As uncer-
target is which constraints are LPCs and which WPCs. The
                                                                       tainty scales with the total number w of WPCs, each WPC
relevant information can thus be summarized with a row of
                                                                       should be promoted just by 1/w in the general case, as in the
W ’s, L ’s and E ’s corresponding to WPCs, LPCs and even con-
                                                                       new cautious promotion/demotion re-ranking rule (8).
straints (that assign the same number of violations to winner
and loser), called an Elementary Ranking Condition (ERC).                  (8)   a. Demote each undominated LPC by 1;
                                                                               b. promote each WPC by 1/w.
              target,         ... Ch ... Ck ... C` ... 
   (4)  winner,  ⇒ . . . W . . . L . . . E . . .                         Under the plausible conjecture that actual language learn-
               loser                                                   ing strategies employed by humans have been selected
                                                                       by evolution because of their computational efficiency
Algorithms that fit into this broad scheme are called OT on-           and soundness, computational considerations gain currency
line models. They are very simple and widely assumed, thus             within cognitive science. From a computational perspective,
deserving a close investigation as the null hypothesis.                there are two basic desiderata on sound OT online models
   The core ingredient in the definition of OT online models           of the acquisition of phonotactics. One is convergence: the
are the details of the re-ranking rule (3) used to update the cur-     model needs to eventually entertain a hypothesis consistent
rent ranking vector. Two main options have been considered             with the target adult phonotactics, so that only a finite num-
in the literature. One option is (5), due to Tesar and Smolen-         ber of updates are performed. A convergent online model is
sky (1998). A LPC is undominated if it is ranked “too high”,           correct provided the corresponding final grammar entertained
namely above all WPCs. This update rule (5) demotes (un-               at convergence is not only consistent with the target adult lan-
dominated) LPCs but does not promote WPCs, whose rank-                 guage but also restrictive enough to capture the target phono-
ing values are not updated. The resulting OT online algorithm          tactics. This paper argues that the new re-ranking rule (8) is
is called (gradual) Constraint Demotion (CD).                          computationally superior to the existing rules (5) and (6). I
   (5)     a. Demote each undominated LPC by 1;                        show that the corresponding OT online model is convergent,
           b. but do nothing to the WPCs.                              contrary to the case of (6). Furthermore, I consider a very
                                                                       simple OT model for segmental phonotactics, and I sketch an
Boersma (1997) argues (withinin a framework slightly differ-           argument that the OT online model with the new re-ranking
ent from the one considered here) that promotion is needed,            rule (8) is always correct, contrary to the case of (5) and (6).
and thus considers the update rule (6). The resulting OT on-
line model is called Gradual Learning Algorithm (GLA).                                          Convergence
   (6)     a. Demote each (undominated?) LPCs by 1;                    Tesar and Smolensky (1998) proved convergence for their
                                                                       demotion-only re-ranking rule (5). But convergence for Boer-
           b. and promote each WPC by 1.
                                                                       sma’s promotion/demotion re-ranking rule (6) has remained
This paper argues that neither re-ranking rule (5) or (6) yields       an open issue, until Pater (2008) provided a counterexample.
a proper online model of the acquisition of phonotactics, and          It is thus currently an open problem whether convergent con-
defends a new update rule. To introduce the idea, let me dis-          straint promotion is possible at all. Theorem 1 settles the is-
tinguish two cases, depending on whether the current ERC               sue with a positive answer. A sketch of the proof follows.
                                                                   2013

Theorem 1 The OT online model with the new promo-                   The convergence theorem 1 now follows straightforwardly.
tion/demotion reranking rule (8) converges (provided the data       Fact 1 guarantees that the current ranking values cannot get
fed to the model are consistent with some OT grammar).             too small, namely cannot live in the shaded region in Fig.1a.
Tesar and Smolensky show that the current ranking values            And Fact 2 guarantees that the current ranking values cannot
in the case of their demotion-only re-ranking rule (5) are al-      get too large either, namely cannot live in the shaded region in
ways larger than a constant (that depends on the number n of        Fig.1b. Taken together, Facts 1 and 2 thus guarantee that the
constraints). In fact, as constraints are only demoted when         current ranking values must live in a bounded region, namely
needed (i.e. when undominated), they cannot be demoted              in the non-shaded region of Fig.1c. Furthermore, the algo-
too much. A careful look at their proof reveals that lower          rithm can only entertain ranking vectors in a lattice, namely
boundness of the current ranking values extends to any pro-         the dots in Fig.1d. Thus, the search space of the algorithm is
motion/demotion update rule that only demotes undominated           finite, as there is only a finite number of points in a bounded
LPCs. In particular, the following fact thus holds true.            lattice. As the algorithm cannot loop by Fact 3, finiteness of
                                                                    the search space entails convergence, namely ensures that the
Fact 1 The current ranking values entertained by the OT on-         algorithm can only perform a finite number of updates.
line model with the new promotion/demotion re-ranking rule
(8) cannot get smaller than a constant (provided the data fed                                          Correctness
to the model are consistent with some OT grammar).                 A crucial component of the acquisition of the target adult lan-
Having established that the current ranking values cannot get       guage is the acquisition of its segmental phonotactics, i.e. of
too small, we now ask whether they can get too large. This is       the inventory of licit segments and of their licit concatena-
precisely what happens when Boersma’s update rule (6) is run        tions. Some elementary examples of OT typologies for seg-
on Pater’s counterexample: the ranking values increase indef-       mental phonotactics are provided in (10) and (11).
initely. It turns out that that cannot happen with the new up-
                                                                                              t d th dh
                                                                                         
date rule (8). The reason is as follows. As we never promote          (10) a.
                                                                                                                                            
more than we demote, the sum of the promotion amounts and                                 F1 = I DENT [ VOICE ]        F2 = I DENT [ ASP ] 
the demotion amounts is always negative or null. Thus, the                        b.            M1 = *[+ VOICE ]         M2 = *[+ASP ]
sum of the current ranking values at any time is always equal                                          M1,2 = *[+VOICE , +ASP ]
                                                                                                                                            
to or smaller than the sum of the initial ranking values. As                             
                                                                      (11) a.                 ps bs pz bz
the single ranking values cannot become too small (by Fact                                                                                   
1) and as their sum cannot get too large, then the single rank-                           F1 = I DNT [ FRIC - VOI ] F2 = I DNT [ STP - VOI ] 
ing values cannot become too large either.                                        b.           M1 = *[+FRIC - VOI ] M2 = *[+STP - VOI ]
                                                                                                   M1,2 = AGREE [ STP - VOI , FRIC - VOI ]
                                                                                                                                             
Fact 2 The current ranking values entertained by the OT on-
line model with the new promotion/demotion re-ranking rule          The set of forms (10a) consists of obstruents described by
(8) cannot get larger than a constant (provided the data fed to     the features VOICE and ASPIRATION. The set of forms (11a)
the model are consistent with some OT grammar).                    consists of two adjacent obstruents, described by the fea-
                                                                    tures STOP - VOICING and FRICATIVE - VOICING. The con-
The sequence of ranking vectors entertained by the OT online
                                                                    straint sets (10b) and (11b) contain identity faithfulness con-
model with a demotion-only update rule such as (5) cannot
                                                                    straints F1 , F2 for the two features; markedness constraints
have the shape (9), whereby the same ranking vector θ is en-
                                                                    M1 , M2 that punish the marked value of the two features; and
tertained twice but with some other ranking vector θ0 6= θ en-
                                                                    a markedness constraint M1,2 that punishes certain marked
tertained in between. In fact, (9) would require some ranking
                                                                    combinations of values of the two features.
value to first decrease and then increase back to its original
                                                                       I now sketch a formal OT framework for segmental phono-
value, which is impossible if only demotion is performed.
                                                                    tactics that generalizes examples such as (10)-(11). The con-
   (9)   . . . −→ θ −→ . . . −→ θ0 −→ . . . −→ θ −→ . . .           struction starts with N partial binary phonological features
                                                                    ϕ1 , . . . , ϕi , . . . , ϕN , such as VOICE or ASPIRATION in (10).
Thus, demotion-only OT online models never loop back to             Each feature ϕi takes a phonological form and returns the
a ranking vector that had been previously deemed unsuitable         value 0 or 1, or else # in case it is undefined. Segmental
and thus updated. Fact 3 ensures that this property extends to      phonology is feature-based: a segment can be identified with
promotion-demotion update rules. The proof (postponed to            the corresponding N-tuple hx1 , . . . , xi , . . . , xN i of feature val-
the Appendix) rests on the following fact: the hypothesis that      ues xi ∈ {0, 1, #}. The set of segments is thus defined as some
the data be OT-consistent entails that the vectors of promotion     set of such N-tuples, as in (12). As it is usual in phonotac-
and demotion amounts are conically independent.                     tics, I assume no distinction between underlying and surface
Fact 3 The OT online model with the new promo-                      forms. Nonetheless, I will use the symbol x (or y) when a
tion/demotion re-ranking rule (8) cannot loop back to a rank-       form is construed as an underlying (or surface) form.
ing vector previously dismissed (provided the data fed to the                     set of under- = set of sur- ⊆ {0, 1, #}N
model are consistent with some OT grammar).                          (12)         lying forms           face forms
                                                                2014

                       Figure 1: Sketch of the proof of the convergence theorem 1 in the case with n = 2 constraints
a.                                    b.                               c.                                  d.
                                                                                                                     ◦       ◦      ◦
                                                                                                                     ◦       ◦      ◦
                                                                                                                     ◦       ◦      ◦
The set of candidates corresponding to an underlying form x               (16) a. µ = {h1, 1i, h0, 1i, h1, 0i}, µ = {h0, 0i, h0, 1i, h1, 0i}
is the set of all forms defined for the same features that x is de-                 µ = {h0, 0i, h1, 0i, h1, 1i}, µ = {h0, 0i, h0, 1i, h1, 1i}
fined for. Finally, the constraint set can contain three types of               b. µ = {h0, 0i}.
constraints, listed in (13). The faithfulness constraint Fi cor-
responding to feature ϕi is violated by an underlying form and          The following result starts the investigation of correctness of
a candidate that differ w.r.t. feature ϕi . The (simple) marked-        OT online models of the acquisition of phonotactics. The
ness constraint Mi corresponding to feature ϕi is violated by a         proof is only sketched here; see (Magri, 2011) for details and
form that has the marked value for feature ϕi . I assume w.l.g.         for extensions beyond the overly restrictive assumption (15).
that the marked value is always 1. Finally, the binary marked-          Theorem 2 Consider an OT typology (12)-(13) correspond-
                                µ
ness constraint (BMC) Mi, j corresponding to features ϕi and            ing to N features. Assume that feature interaction is limited
ϕ j and a markedness pattern µ is violated by a form whose              according to (15) and phonologically plausible according to
pair of values for features ϕi , ϕ j belongs to the designated set      (16).3 Then the OT online model with the new re-ranking rule
µ ⊆ {0, 1} × {0, 1} of marked combinations of feature values.           (8) is correct on any language and for any sequence of data
  (13)     Fi (x, y) = 1 ⇐⇒ xi 6= yi                                    fed to the algorithm. On the contrary, for both re-ranking
                                                                        rules (5) and (6), there exist languages for which the model is
           Mi (y) = 1 ⇐⇒ yi = 1 = the marked value
              µ                                                         incorrect for any sequence of data fed to the algorithm. 
           Mi, j (y) = 1 ⇐⇒ hyi , y j i ∈ µ = set of marked feature
                                              value combinations        Draw a circle for every feature and an edge between any two
                                                                        features that interact through a BMC. Suppose that the result-
There are sixteen possible markedness patterns µ and thus
                                                                        ing graph looks like (17): the features can be split into two
as many BMCs. Here are some examples: the markedness
                                                                        disjoint sets Φ0 and Φ00 with no interactions between them.
pattern (14a) corresponds to the “doubly marked” constraint
M1,2 in (10b); the markedness pattern (14b) corresponds to                (17)    ◦    block Φ0                 ◦
the “agreement” constraint M1,2 in (11b); the complementary                                                           block Φ00
                                                                                             ◦        ◦
pattern (14c) corresponds to an “OCP” constraint; and so on.
                                                                                  ◦          ◦                            ◦
  (14)      a. µ = {h1, 1i}                doubly marked constraint
                                                                        We intuitively expect that the “difficult” problem of correct-
            b. µ = {h0, 1i, h1, 0i}            agreement constraint     ness of the OT online model on the “large” original typology
            c. µ = {h0, 0i, h1, 1i}                  OCP constraint     with N features can be reduced to the two “simpler” problems
BMCs are important because they model feature interaction.              of correctness on the two “smaller” typologies corresponding
As the learning complexity intuitively depends on feature in-           to the two sets of features Φ0 , Φ00 . This intuition can indeed
teraction, we are led to the following question: which restric-         be formalized and shown to hold true.
tive assumptions on feature interaction guarantee correctness              By assumption (15) that feature interaction is limited, each
of OT online models? I assume that the amount of feature                feature interacts with at most another feature and the feature
interaction is limited. The case with no feature interaction is         interaction graph (17) thus consists of connected components
trivial. The simplest non-trivial case is thus that each feature        of cardinality at most 2. I thus need to prove Theorem 2 only
interacts with at most another feature, so that (15) holds.1            in the case with N = 2 features. To this end, let’s sort the
                                                                        languages into three types, based on what needs to be ranked
  (15)     The constraint set does not contain any two BMCs             above the faithfulness constraints. To start, let languages of
           that both target the same feature.                           type I be those languages that do not require any constraint
I also assume that the mode of feature interaction is phonolog-         to be ranked above the faithfulness constraints. It is easy to
ically plausible, in the sense that the constraint set contains         check that any OT online model is correct on such languages.
no BMCs with a phonologically implausible markedness pat-                  Next, let languages of type II be those languages that re-
tern, namely a markedness pattern that has cardinality 3, as in         quire markedness constraints to be ranked above faithfulness
(16a);2 or that only punishes forms unmarked w.r.t. the two             constraints, but do not require the two faithfulness constraints
features targeted by the BMC, as in (16b).                              to be ranked relative to each other. To illustrate, suppose that
    1 In fact, if there were two BMCs M and M targeting the same
                                                                        the BMC corresponds to the OCP markedness pattern (14c).
                                         i, j    i,k
feature ϕi , then ϕi would interact with two features ϕ j and ϕk .          3 A further technical assumption on the set of candidates is
    2 The markedness pattern of cardinality 4 yields a trivial BMC.     needed, omitted here for space; see (Magri, 2011) for details.
                                                                    2015

The corresponding typology contains language (18a), which                 Tesar and Smolensky’s demotion-only re-ranking rule (5)
is is of type II, as it corresponds to the ranking (18b). The             is never correct on this language: as the faithfulness con-
complete set of ERCs is (18c).4                                           straints F1 and F2 are never LPCs, they are never re-ranked
                                                F1 F2 M1 M2 M1,2        by demotion-only; there is thus no way that a demotion-only
                             M1,2                 W       L       W       re-ranking rule can rank one of them on top of the other. Con-
                          F1 F2
                                               
                                                     W      W    W     straint promotion is needed in order to move around F1 and F2
                   h0, 1i                        W W L W                too. But will an OT online model that performs promotion too
  (18) a. L =               b.              c.                       
                   h1, 0i     M1 M2            W
                                                        W        W     be able to converge to the correct relative ranking of F2 above
                                                     W       L W        F1 ? It can be shown that the first ERC in (20c) can trigger
                                                  W W W       L           at most one update, as it has a W corresponding to the BMC
A learning path using Boersma’s update rule (6) is (19).5 The             M1,2 whose column does not have any L’s. Thus, updates are
final ranking vector incorrectly ranks F1 above M1,2 , so that            triggered just by the 2nd and 3rd ERCs. As the former only
the model has failed to learn the target ranking (18b). It can            promotes F2 while the latter promotes both F1 and F2 , F2 will
be shownthat              fails
                  the model          any
                                 for            learning
                                                           path.
                                           possible                    raise faster and thus be ranked above F1 throughout learning,
        F1 0             1      2        3        4        5       6      thus allowing a model that performs constraint promotion to
        F2   0   1 2 3 4 5 6                                converge to the correct final ranking (20b). In the case with
              3  6  3  6  3  6 
  (19) M1  5 → 4 → 5 → 4 → 5 → 4 → 5                       N = 2 features, it can be shown that any language of type III
                       
        M2 5 
                      6 5 6 5 6 5                            that requires a faithfulness constraint to be ranked above the
       M1,2 5            5      5        5        5        5       5      other has more ERCs that push the former over the latter, thus
Crucially, it is impossible for F1 to get incorrectly ranked              allowing promotion/demotion re-ranking rules to converge to
above M1,2 in the case of the new re-ranking rule (8). Suppose            the correct ranking for any learning path.
by contradiction that it did. Suppose M1,2 , M1 and M2 start
out at 5 and F1 and F2 at 0, as in (19). As M1,2 is never a LPC,
                                                                                              Appendix: proof of Fact 3
its ranking value cannot decrease. In order for F1 to make it             For the sake of clarity, assume that the ERCs fed to the model
above M1,2 , its ranking value must thus increase to at least 5.          contain a unique LPC and that the initial ranking vector is the
The last update that brings F1 that high requires one of M1 or            null vector; the reasoning below trivially extends to the gen-
M2 (call it Mi ) to be a LPC and to be ranked even higher. Re-            eral case. The contribution of an input ERC a to the current
call that the sum of the ranking values cannot increase over              ranking vector according to the update rule (8) can be sum-
time. As the sum of the ranking values of M1,2 , F1 and Mi                marized by pairing it up with the corresponding update vector
is (almost) equal to the sum of the initial ranking values, the           a in (21): the entry corresponding to the LPC is −1; entries
sum of the ranking values of the two remaining constraints F2             corresponding to WPCs are 1/w, where w is the total number
and M j must be (almost) smaller than zero. And this is eas-              of WPCs in the ERC a; all other entries are 0. The total num-
ily shown to be impossible. A formalization of this heuristic             ber of possible input ERCs is always finite; call it m. Let ai
reasoning shows that the OT online model with the new re-                 be the update vector corresponding to the ith ERC.
ranking rule (8) is always correct on languages of type II.                                                       
                                                                                                                   a1
                                                                                                                                      1
   Finally, let languages of type III be the remaining lan-                                                                            w if ak = W
                                                                            (21) a = [a1 , . . . , an ] → a = ...  with ak= −1 if ak = L
                                                                                                                  
guages, i.e. those that require the faithfulness constraints
                                                                                                                                        0 otherwise
                                                                                                                                      
to be ranked relative to each other. To illustrate, suppose                                                        an
that the BMC corresponds to the Agree markedness pattern
                                                                          As updates consist of adding update vectors, the current rank-
(14b). The corresponding typology contains the language
                                                                          ing vector θt entertained by the model at some time t can
(20a). This language is of type III, as it corresponds to rank-
                                                                          be described as a combination (22) of the update vectors
ing (20b). The corresponding set of ERCs is (20c).6
                                                                          a1 , . . . , am , each multiplied by the number of updates αti trig-
                                                   F1 F2 M1 M2 M1,2     gered by the corresponding ith input ERC up to time t.
                                                  W      L      W
                   h1, 1i                                                   (22)        θt = αt1 a1 + . . . + αti ai + . . . + αtm am
  (20) a. L =               b. F2 M1,2 c.  W                  L     
                   h0, 0i
                            M2 M1
                                                    W W L L               As the coefficients αti are by definition non-negative, (22)
                                                                          says that the current ranking vector is a conic combination
                                  F1                                      of the update vectors. We thus need to study the conic geom-
    4 The first three ERCs in (18c) correspond to the underlying form
                                                                          etry of the update vectors, namely the properties of their conic
x = h0, 1i, the faithful winner-form y = h0, 1i and the three unfaith-
                                                                          combinations. Here is an important conic property: the up-
ful candidate losers h1, 1i, h0, 0i and h1, 0i. The bottom three rows     date vectors a1 , . . . , am are called conically independent pro-
are obtained analogously from the underlying/winner form h1, 0i.          vided that there are no coefficients α1 , . . . , αm that satisfy the
    5 Numbers above arrows specifie the row triggering the update.
    6 These are the ERCs corresponding to the winner/underlying
                                                                          conditions in (23): it is impossible to synthesize the null vec-
                                                                          tor as a conic combination of the update vectors, unless the
form h1, 1i, constructed as in footnote 4. The ERCs corresponding
to h0, 0i are omitted for space, as they do not contain any L.            non-negative coefficients are all null.
                                                                      2016

  (23)     a. α1 a1 + . . . αm am = 0;                                                        (26)    a. The ranking vectors at two times t and t 0 coincide;
           b. αi ≥ 0 for all i = 1, . . . , m;                                                        b. time t precedes time t 0 ;
           c. αi 6= 0 for some i = 1, . . . , m.                                                      c. a different ranking vector is entertained at some
                                                                                                          time in between t and t 0 .
Fact 4 guarantees conic independence of the update vectors.                                                                                                0
And Fact 5 in turn says that conic independence entails that                                Assumption (26a) that the ranking vectors θt and θt enter-
the algorithm cannot loop. Fact 3 follows straightforwardly.                                tained at times t and t 0 coincide, can be expressed as the iden-
                                                                                            tity (27a), using the general characterization (22) of the cur-
Fact 4 The update vectors (21) corresponding to ERCs con-
                                                                                            rent ranking vector. Assumption (26b) that time t 0 follows
sistent with some OT grammar are conically independent.                                                                                         0
                                                                                            time t entails that the number of updates αti triggered by the
Proof. A set of ERCs OT-consistent with the ranking C1                                     ith ERC up to time t 0 is larger than or equal to the number of
. . .  Cn can be stacked as in (24): there is a top block of                               updates αti triggered up to time t, as stated in (27b). Finally,
ERCs that start with a W; followed by a second block of ERCs                                assumption (26c) entails that some update has happened at
that start with an E followed by a W; etcetera, until a final dth                           some time in between t and t 0 , so that at least one of the coef-
block of ERCs that start with d − 1 E’s followed by a W.                                    ficients has increased from time t to time t 0 , as stated in (27c).
                                                                                                                                       0              0
                        W1
                            C     C2     ...     Cd−1    Cd       ...             Cn
                                                                                             (27)    a. αt1 a1 + . . . + αtm am = αt1 a1 + . . . + αtm am
                                                                                                            0
         1st block           |   ...    ...       ...    ... ... ...              ...                 b. αti ≥ αti for all i = 1, . . . , m
                        W                                                            
                                                                                                            0
                                                                                                      c. αti 6= αti for some i = 1, . . . , m
                        E        W
                                                                                      
                                                                                     
        2nd block       |         |    ...       ...    ... ... ... ... 
                        E        W                                                                                                      0
  (24)                                                                                                                            def.
             ..
                       
                                       ..
                                                                                      
                                                                                           Introducing the coefficients αi = αti − αti , conditions (27)
              .        
                                           .     ...    ... ... ... ...                  can be rewritten as in (28), which contradict the hypothesis
                       
                        E        E     −−         E      W
                                                                                      
                                                                                           that the update vectors a1 , . . . , am are conically independent.
         dth block           |     |               |       | ... ... ...
                             E    E     −−         E      W                                   (28)    a. α1 a1 + . . . + αm am = 0
As the mapping (21) from ERCs into update vectors replaces                                            b. αi ≥ 0 for all i = 1, . . . , m
W ’s with 1/w and E ’s with 0, the update vectors correspond-                                         c. αi 6= 0 for some i = 1, . . . , m
ing to the stack of ERCs (24) look like (25).
          1                1  0            0            0             0                              Acknowledgments
            w                 w                                                             I wish to thank A. Albright. This work was supported in part
                                     1              1             |             |
                 , . . . ,  ,  w  , . . . ,  w , . . . ,  0  , . . . ,  0        by a ‘Euryi’ grant from the ESF to P. Schlenker.
                                                         
  (25)                                                 1             1
                                                                  w               w
                                                                                                                         References
          |         {z          }|         {z         }         |        {z         }
                 1st block             2nd block                      dth block             Boersma, P. (1997). “How We Learn Variation, Optional-
                                                                                               ity and Probability”. In IFA Proceedings 21 (pp. 43–58).
Suppose that a conic combination of the vectors (25) yields                                    University of Amsterdam: Institute for Phonetic Sciences.
the null vector, namely that conditions (23a) and (23b) hold.                               Hayes, B. (2004). “Phonological Acquisition in Optimal-
The first component of the update vectors corresponding to                                     ity Theory: The Early Stages”. In R. Kager, J. Pater, &
the 1st block is positive while the first component of the re-                                 W. Zonneveld (Eds.), Constraints in Phonological Acquisi-
maining update vectors is null. In order for the first com-                                    tion (pp. 158–203). Cambridge University Press.
ponents to sum to zero, the nonnegative coefficients αi that                                Magri, G. (2011). “A computational investigation of OT on-
multiply the vectors corresponding to the 1st block must be                                    line models of the early stage of the acquisition of phono-
all null. As their coefficients are null, the vectors correspond-                              tactics. Part 2: correctness”. (Manuscript, IJN, ENS.)
ing to the 1st block can be ignored. By reasoning analogously                               McLeod, S., Doorn, J. van, & Reed, V. (2001). “Normal
for the second components, I conclude that also the coeffi-                                    acquisition of consonant clusters”. American Journal of
cients αi that multiply the vectors corresponding to the 2nd                                   Speech-Language Pathology, 10, 99–110.
block are all null. By repeating this reasoning d times, I con-                             Pater, J. (2008). “Gradual Learning and Convergence”. Lin-
clude that all the coefficients αi in the combination are null,                                guistic Inquiry, 39.2, 334–345.
contradicting condition (23c).                                                             Prince, A., & Smolensky, P. (2004). Optimality Theory: Con-
Fact 5 If the update vectors are conically independent, then                                   straint Interaction in Generative Grammar. Blackwell.
the OT online model can never loop back to a current ranking                                Tesar, B., & Smolensky, P. (1998). “Learnability in Optimal-
vector that it had previously dismissed.                                                      ity Theory”. Linguistic Inquiry, 29, 229–268.
Proof. Suppose by contradiction that the algorithm loops
back at time t 0 to a ranking vector that it had dismissed at
a previous time t, as stated in (26).
                                                                                        2017

