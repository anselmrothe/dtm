UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Role of Cross-cutting Systems of Categories in Category-based Induction
Permalink
https://escholarship.org/uc/item/7bj7r791
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Smith, Neil
Shafto, Patrick
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

     The Role of Cross-cutting Systems of Categories in Category-based Induction
                                              Neil A. Smith (neil.smith@louisville.edu)
                                       Department of Computer Engineering & Computer Science
                                                           University of Louisville
                                               Patrick Shafto (p.shafto@louisville.edu)
                                              Department of Psychological & Brain Sciences
                                                           University of Louisville
                               Abstract                                     In an attempt to explain this category-based induction, psy-
                                                                         chologists have developed computational models; however,
   Prediction is arguably the most fundamental problem that peo-         extant models have yet to account for the entirety of the char-
   ple face. Having discovered that some object possesses a par-
   ticular feature, how is it that people are able to accurately in-     acteristic phenomena. One reason may be that previous mod-
   fer that another object exhibits the property? Psychologists          els rely on a single kind of knowledge, but there is evidence
   have actively studied this reasoning process; yet, current mod-       that people use multiple kinds of knowledge to guide predic-
   els of induction cannot provide an explanation for the entirety
   of the related phenomena. One reason may be that current              tion (e.g. Ross and Murphy, 1999). For example, an attribute
   models fail to account for people’s ability to assess multiple        possessed by penguins and dolphins seems unlikely to be true
   categories when making an inference. Building on previous             of all birds because there is an alternative categorization that
   research (Shafto et al., 2006), we present a model of induc-
   tive reasoning based on cross-cutting knowledge representa-           would explain the shared property; namely, aquatic creatures.
   tion. We present an experiment that investigates the ability             Building off of work by Shafto et al. (2006), we propose
   of this model to account for known inductive phenomena. We
   show that a model which assesses multiple kinds of knowledge          a novel model of category-based induction based on cross-
   explains the flexibility of human inference, better than models       cutting categories. We contrast this model with a well-known
   relying on a single kind of knowledge.                                account of category-based induction, the feature-based induc-
   Keywords: Category-based induction; Bayesian model;                   tion model (FBIM; Sloman, 1993). We present an experiment
   Cross-categorization.                                                 comparing the performance of the model in predicting peo-
                                                                         ple’s inferences on a number of known phenomena. Finally,
                                                                         we conclude by discussing implications of the findings for
One of the most remarkable features of human reasoning is                categorization, inductive reasoning, and learning.
the ability to predict unobserved aspects of the world. For in-
stance, consider learning that mammals have sesamoid bones.                             Category-based Induction
Based on this knowledge, people reliably predict that wolves             Studies in category-based induction typically follow a
are more likely to have this property than are oxen (Sloman,             paradigm introduced by Rips (1975), in which participants
1993). What knowledge supports these systematic predic-                  are asked to rate the strength of arguments of the form:
tions?
   To understand the underlying knowledge, psychologists                                  Zebras have sesamoid bones
have studied people as they reason about novel properties                                 Hippos have sesamoid bones
(like “has sesamoid bones”). These efforts have uncovered
a variety of systematic patterns, which constrain models de-                          All mammals have sesamoid bones
scribing how knowledge supports inference. For instance,
Osherson et al. (1990) describe a “monotonicity” effect, that            The statements above the line indicate the premises of the
occurs when people are asked to reason about a novel prop-               argument, which are assumed to be true. The task is to as-
erty possessed by some object; for instance, consider learn-             sess the likelihood that the category below the line, the con-
ing that penguins have a novel property. When people are                 clusion, has the property. The most often-cited literature on
asked to predict whether another specimen or other speci-                category-based induction makes use of so-called blank prop-
mens, such as all birds, will have the property, the strength            erties, such as “secretes uric acid crystals” or “travels in
of their prediction depends on the number of examples that               groups”. The assumption in their use is that blank proper-
have the property. So, if told that both penguins and finches            ties carry minimal a priori knowledge to guide people’s in-
have the property, people tend to predict that all birds are             ferences. In this paper, we choose an even more generic at-
more likely to have it, than if only told about penguins. Inter-         tribute for our stimuli, namely, “Property X”. We use this
estingly, while this inference may appear to be quite tenable,           not simply for convenience, but because evidence has shown
observe that if the additional exemplar was changed from                 that the blank properties may be influential in people’s judge-
finches to dolphins, it would seem to temper a willingness               ment making. For example, when Heit and Rubenstein (1994)
to generalize the property to all birds, a phenomenon called             asked people to reason about an anatomical or physiologi-
“non-monotonicity”.                                                      cal property of animals (e.g. “secretes uric acid crystals”),
                                                                     1464

people made stronger inferences when the animals were tax-           Premise monotonicity. Argument strength will tend to
onomically related; however, when asked to reason about a            increase with the addition of a premise, such that this
behavioral property (e.g. “travels in groups”), people were          premise is chosen from the lowest-level category that in-
more confident when the animals shared an ecological niche.          cludes both the categories of the other premises, and the
Furthermore, we make use of a notation inspired by Tenen-                                                        X
                                                                     conclusion. To demonstrate: bats −−−−→ mammals and
baum, Kemp, and Shafto (2007), that denotes syllogisms,                                 X
                            prop
                                                                     bats,leopards −−−−→ mammals.
concisely as P1 , . . . Pn −−→C. Here, Pn represents the nth
premise, prop is the property used, and C denotes the con-           Non-monotonicity. Some arguments can be made weaker
clusion. Using this notation, the above argument would be            by adding a premise that converts them into mixed arguments.
                                                                                                                       X
                                 sesamoid bones
represented as: zebras,hippos −−−−−−−−→ mammals.                     For example, given the argument penguins −−−−→ dolphins,
                                                                     if one were to add finches as a premise it may reduce the
    Researchers studying category-based induction have iden-
                                                                     perceived strength of the argument.
tified a number of phenomena, which have been used as
benchmarks by which to compare the performance of models.            Premise-conclusion asymmetry. Originally discovered by
Osherson et al. (1990) identified arguments as one of three          Rips (1975), this phenomenon occurs when an argu-
types: general, specific, or mixed. The general class is said to     ment’s premise and conclusion categories are inverted. So,
be formed by those arguments, whose conclusion categories                     X                                            X
                                                                     bats −−−−→ leopards would become leopards −−−−→ bats.
properly include all of their premise categories. For exam-          It was found that the strength of each argument was not
ple, when reasoning about a blank property and given a con-          evenly rated.
clusion category of all dogs, having the premise categories
of german shepards and chiuauas would make the argument              Inclusion fallacy. A person commits an inclusion fallacy
a general one. An argument is specific, if any natural cate-         when they reason that an argument with a general conclu-
gory that properly includes one of the premise or conclusion         sion category, is more cogent than one whose conclusion cat-
categories, properly includes the others. To demonstrate, the        egory is more specific. This phenomenon is termed a fal-
previous example could be changed into a specific argument           lacy because it does not appear normatively rational. For
                                                                                                                      X
by replacing the category all dogs with dalmations. Finally,         example, observe the arguments: crows −−−−→ birds and
a mixed argument is any argument that is neither general nor                    X
                                                                     crows −−−−→ ostriches. Notice, birds is superordinate to os-
specific. For instance, an argument with premise categories          triches, yet, people tend to rate the former argument stronger.
of dolphins and octopuses, and having a conclusion category
of all mammals would be considered mixed.                            Premise-conclusion identity. Argument strength is abso-
                                                                     lute when the premise and conlcusion are identical. That is,
                                                                                                               X
Premise typicality. The more representative the premise              when the argument is of the form q −−−−→ q.
categories are of the conclusion category, the stronger the ar-
                                                                     Premise-conclusion inclusion. An argument whose
gument. Since eagles are a typical bird, relative to ostriches,
                          X                                          premise categories are superordinate to the conclu-
the argument eagles −−−−→ birds, is considered stronger than         sion category is absolute. For example, the argument
the argument would be with ostriches as its premise.                               X
                                                                      animals −−−−→ birds demonstrates this effect.
Premise diversity. Argument strength is thought to in-               Feature exclusion. Premises having no overlapping fea-
crease as the diversity between the premises increases. For          tures with the conclusion will have no effect on the per-
                                         X                           ceived cogency of the argument (Sloman, 1993). Observe
example, compare: sheep,dolphin −−−−→ mammals to the ar-
                               X                                                                             X
gument: sheep,leopards −−−−→ mammals. sheep and leop-                the following: leopards,monkeys −−−−→ sheep. When peo-
ards do not represent the variety of mammals well—as their           ple were asked to choose the stronger argument between
taxonomic relation is pronounced—thus, the former argu-              one like that above, and an argument whose second premise
ment appears to be weaker than the latter. Historically, diver-      included a less similar exemplar, such as dolphins, people
sity has been a principle in the philosophy of science, which        tended to choose the former as the stronger argument. This
essentially states that a more diverse range of evidence better      phenomenon demonstrates a boundary condition on the diver-
confirms a hypothesis than does the same amount of similar           sity principle; though an added premise may lead to more di-
evidence.                                                            verse evidence, if the additional premise shares fewer salient
                                                                     features with the conclusion, it will fail to strengthen the ar-
Conclusion specificity. In cases where the conclusion cat-           gument.
egory properly includes the premise categories, the argument         Inclusion similarity. The strength of an argument whose
with the more specific conclusion category will be considered        premise category includes the conclusion category will
                                       X
stronger. For example, finches −−−−→ birds is considered             vary depending upon the perceived similarity between the
stronger than the argument with animals as the conclusion            premise and conclusion categories (Sloman, 1993). Slo-
category.                                                            man (1993) demonstrates this effect with an argument sim-
                                                                 1465

                      X                                                                                            X
ilar to mammals −−−−→ bats, and asking subjects to compare           model, consider the argument: sheep −−−−→ mammals, the
                                          X                          first step in obtaining the argument strength is to encode the
against an argument, like animals −−−−→ leopards. Since,
leopards are more typical of the category mammals, people            premise and conclusion categories, for example:
tend judge the latter argument as stronger.
                                                                             F(sheep) = [ f1 (sheep) = “has hooves”, ...] = [1, ...]
Non-diversity. Some arguments with more diverse
premises might be judged weaker than those with more simi-
                                                            X            F(mammal) = [ f1 (mammal) = “is f urry”, ...] = [1, ...]
lar premises. Consider the arguments: leopards,seals −−−−→
                                        X
dolphins and leopards,jellyfish −−−−→ dolphins. While                The next step, in words, is to calculate the argument strength
leopards and seals are more similar than leopards and jelly-         that is expressed as the ratio in Equation 1. This is the pro-
fish, people tend to choose the first argument as the stronger       portion of features in F(mammals) that is also in F(sheep),
one. Note that this particular case cannot be attributed to a        so that the larger this proportion, the stronger the argument
feature exclusion effect, since salient features in the premise      is perceived. Since, the premise category sheep has a larger
categories are shared with those of the conclusion category          number of shared features with the conclusion category mam-
(e.g. seals, jellyfish and dolphins are all aquatic animals).        mals than, say, a premise category of bats, the former argu-
                                                                     ment will yield a higher rating than the latter.
         Models of category-based induction
                                                                        The FBIM can demonstrate many of the documented phe-
A number of models have been proposed to account for the             nomena; however, it is not without limitations. For instance,
observed phenomena (Osherson et al., 1990; Sloman, 1993;             Sloman ran correlations between his model and human judge-
Medin et al., 2003). These models differ in a number of ways,        ments, and found that in 3 out of 5 cases, Osherson et al.’s
including in the proposed reasoning mechanisms, and the un-          Similarity Coverage Model (SCM; 1990) had stronger fit—
derlying knowledge representations. Here we focus on the             although, he did provide a defense for this finding (Sloman,
model that provides the most complete account of the known           1993). Further, the basic FBIM cannot account for non-
phenomena within a fully specified computational model, the          monotonicity. 1
feature-based induction model (Sloman, 1993).
Feature-Based Induction Model (FBIM)                                 Induction by cross-categorization
The feature-based induction model (Sloman, 1993), while              Shafto et al. (2006) introduced CrossCat, a model of cross-
theoretically expressed as a connectionist network, relies           categorization. Given data, the model infers a partitioning of
on concepts of similarity and coverage to explain argument           features into different kinds, and, for each feature-kind, the
strength. Because it is a connectionist model, the FBIM does         model infers a categorization of the objects. This model dif-
not assume an overarching category structure. Rather, the no-        fers from previous models in that it considers multiple sys-
tions of similarity and coverage are in relation to the features     tems of categories to guide an inference, but maintains key
of the premise and conclusion categories—not the whole of            similarities to previous approaches. The FBIM considers the
each category. The features are formally represented by a            entire set of features of the premise and conclusion categories
vector, F, of numerical elements, fi , such that each value en-      when assessing argument strength. The SCM (Osherson et
codes the absence or presence of a particular feature as 0 or        al., 1990) relies on a taxonomy of categories that applies in
1. For example, the category, Robins would be encoded, as            all contexts. CrossCat strikes a balance between these ap-
F(Robins) = [ f1 (Robins)... fn (Robins)].                           proaches allowing flexible use of knowledge to guide infer-
   In this model, similarity can be thought of as a function on      ences like the FBIM, and allowing structured representations
feature matches and mismatches, and coverage as the extent           to guide inference like the SCM.
to which the premise features overlap those of the conclusion           CrossCat is formally defined as a model that takes as in-
features. For single premise arguments, the strength of the          put a list of features, F, a list of objects, O, and an O × F
argument can be expressed as                                         object-feature matrix, D. Each entry, (o, f ) ∈ D, encodes
                                                                     the value of feature f for object o. For example, given that
                             F(P1 ) · F(C)                           o1 =“crow” and f1 =“has a beak”, then D(o1 , f1 ) = 1. The
                         S=                                   (1)
                                |F(C)|2                              goal is to make inferences about two kinds of situations that
                                                                     correspond to specific and general arguments. We deal with
The numerator, F(P1 ) · F(C), yields a scalar that is given by       specific arguments first. For specific arguments, the goal is,
the dot product between the two vectors, and the term |F(C)|,        for a novel feature y, with some observed entries yobs and
returns the length of the vector. This can be thought of geo-        some unobserved entries yunobs , predict the unobserved en-
metrically, as the projection of the vector of premise features,     tries based on the observed data D and observed entries yobs .
F(P1 ), onto the vector of the conclusion features, F(C).            Under the model, this prediction is mediated by inferences
   This model can account for many of the documented phe-
nomena. For example, the FBIM inspired both the inclusion                1 An extended model to address this issue was proposed but not
similarity and feature exclusion effects. To demonstrate the         tested.
                                                                 1466

about the likely cross-categorized representations, r,                to be a priori independent, and for a given feature, values in
                                                                      different categories are independent. Thus, the probability of
         P(yunobs |D, yobs ) ∝ ∑ P(yunobs |r)P(r|D, yobs ).    (2)    D(o ∈ c, f ) depend only on the number of true and false val-
                                  r
                                                                      ues of the feature for those objects, and the parameters s and
That is, representations r, that are probable given the data          b,
provide the most weight when predicting yunobs .
                                                                                                Beta(#true + sb, # f alse + s(1 − b))
   These predictions rely on inferring likely cross-categorized         P(D(o ∈ c, f )|w, z) =
representations, r. Under the model, r is composed of two                                                Beta(sb, s(1 − b))
                                                                                                                                    (6)
parts: a vector z, of length F, where z f designates the kind k
                                                                      where s and b represent the strength (measured in number of
of feature f , and a set of vectors, {w}, where wk contains the
                                                                      prior observations) and balance (the expected proportion of
categories for kind k. Given a data set, D, the model infers
                                                                      true values), and Beta represents the Beta function.
likely combinations of z and {w}, by approximating the pos-
                                                                         We used Markov Chain Monte Carlo (MCMC) to gener-
terior probability of P(z, {w}|D, y). The model is specified
                                                                      ate predictions. The algorithm proposes moving features be-
generatively, by first choosing a partition of the features z,
                                                                      tween kinds, objects between categories, and changing the
then for each kind k ∈ z, choosing a categorization of the ob-
                                                                      values of s and b. In each iteration, the algorithm tends to
jects wk , and prior probabilities for each feature in that kind,
                                                                      prefer values that improve on the current state. Although
and then generating the data Dk that correspond to that kind.
                                                                      we believe roughly similar heuristics may be used by people,
In a departure from the Shafto et al. (2006) model, we in-
                                                                      we emphasize that our main claim is about the importance
clude hyperpriors on the strength s and balance b of feature
                                                                      of cross-cutting category structure, not the behavior of this
values. Following Kemp, Perfors, and Tenenbaum (2007), we
                                                                      particular inference algorithm.
assume an exponential distribution on the strength parameter,
                                                                         For specific arguments, the model predicts that, for a novel
providing a strong expectation that each feature’s value will
                                                                      property, objects in the same category for that property’s kind
tend to be the same within a category, and a uniform balance.
                                                                      will be more likely to have the same feature.
   Formally, given a data set, D, the model infers z, a parti-
                                                                         For the general arguments, the goal is, for a novel feature y,
tion of features into kinds, and {w}, where wk contains the
                                                                      with some observed entries yobs , predict the probability that
categories for kind k, subject to
                                                                      a general category—e.g. birds—has the property. This case
  P(z, {w}|D, s, b) ∝ P(z, {w}, D, s, b)                       (3)    is rather different because we need to predict, (a) whether
                                K
                                                                      the general category birds is sensible given the data, and (b)
                     = P(z) ∏ P(Dk |wk , s, b)P(wk )P(sk )P(bk )      whether each and every bird is likely to have the property
                               k=1                                    given the category exists. Formally,
                                                               (4)
                                                                       P(ygenExt |D, yobs ) ∝                                       (7)
where K is the number of feature-kinds in z, Dk is the por-
tion of D that must be explained by system k, and P(Dk |wk )
                                                                                           ∑P(ygenExt |birds ∈ r)P(birds ∈ r|D, yobs )
                                                                                            r
is the process that generates the data for each feature-kind.                                                                       (8)
The prior distribution on feature partitions, and the prior on
objects into categories are denoted by P(z) and P(wk ), respec-       where ygenExt represents the extension of the general cate-
tively. Finally, sk and bk represent hyperpriors on the feature       gory, and birds ∈ r indicates that the category birds exists in
values. To evaluate the posterior probability, we must specify        the representation r. Otherwise, the details are as described
each component of Equation 4.                                         above.
   Assignments of features to partitions z are evaluated via a
chinese restaurant process (CRP) prior                                                         Experiment
                                (                                     In our experiment, we investigate how people perceive the co-
                                      nk
                                          , if nk > 0                 gency of one argument, relative to another. That is, when peo-
    P(zi = k|z1 , ..., zi−1 ) = i−1+α                          (5)
                                      α                               ple are given two arguments and asked to judge which of the
                                    i−1+α , k is a new class.
                                                                      two is stronger, and by what magnitude. We compare the re-
This process depends on a parameter α, which controls the             sults of human judgements to CrossCat, the FBIM, and a con-
strength of the preference for a small number of partitions.          ventional infinite mixture model (IMM; Rasmussen, 2000).
As α → 0, the process tends to produce small numbers of cat-          The IMM differs from CrossCat in that it does not discover
egories. Throughout, we set this parameter to .5, a moderate          systems of categories, rather, it proposes a single clustering
preference for simpler structures. Assignments of objects to          of the objects using the entire set of features as a basis.
categories for each kind wk , are also evaluated via the CRP.
   In this paper, we consider only binary features, and we            Method
therefore choose a Beta-Bernoulli model evaluating the prob-          Participants: Fifteen subjects were recruited from the Uni-
abilities of feature values. For simplicity, a feature is assumed     versity of Louisville community, including both students and
                                                                  1467

  Phenomenon                  Stimuli                                                                 Human       IMM      CC    FBIM
  Typicality                  1. eagles− →birds vs. ostriches− →birds                                  3.43        .071   .099    .040
                              2. leopards−  →mammals vs. bats−  →mammals †                             .567       -.035   .228    .108
  Diversity                   3. sheep,dolphins−  →mammals vs. sheep,leopards−       →mammals           -1.7       .029   .193    .033
                              4. eagles,penguins−  →birds vs. eagles,owls−   →birds                    .833        .051   .025    .037
  Conclusion Specificity      5. finches− →birds vs. finches−→animals                                  4.37        .092   .649    .235
                              6. dolphins−  →mammals vs. dolphins−   →animals                          5.60        .118   .602    .152
  Premise Monotonicity        7. penguins,eagles−  →birds vs. penguins−  →birds                        4.50       -.039   .233    .038
                              8. bat,leopards− →mammals vs. bats−   →mammals                           3.90        .009   .217    .053
  Non-monotonicity            9. dolphins−  →mammals vs. dolphins,octopuses−      →mammals             4.43        .020   .041   -.019
                              10. penguins− →dolphins vs. penguins,finches−   →dolphins †              .033        .026   .033    .000
  Asymmetry                   11. leopards− →bats vs. bats− →leopards                                  .467        .011   .086    .113
                              12. eagles−→penguins vs. penguins−   →eagles                             .667        .011   .093    .012
  Feature Exclusion           15. leopards,sheep− →monkeys vs. leopards,ants−    →monkeys              3.40        .002   .037   -.016
                              16. leopards,monkeys− →sheep vs. leopards,dolphins−      →sheep          2.97        .953   .061   -.006
  Non-diversity               17. leopards,seals−→dolphins vs. leopards,jellyfish−   →dolphins         4.13        .020   .004   -.027
                                                   →owls vs. finches,bats−
                              18. finches,ostriches−                         →owls †                   .633       -.007   .049   -.010
                                          Table 1: Mean Predictions of Human and Models.
non-students. The students were offered course credit for par-        demonstrating asymmetry were marginal2 (p = .0625 for
ticipating.                                                           both). The second examples of typicality, non-monotonicity,
Design and Materials: The dataset used to make model com-             and non-diversity were not found to be significant. These
parisons was an object-feature matrix that was filled in by           stimuli are presented in Table 1, as number 2, number 10, and
two coders for an unrelated project. The matrix consisted of          number 18, respectively, and are denoted by †. Subject judge-
22 animals and 106 features, such that each entry (i, j) of the       ments for our first example of premise diversity (i.e. number
matrix contained a 1 or 0, indicating whether or not feature j        3 in Table 1) were not in the expected direction.
was true of animal i.                                                    We performed two runs of CrossCat (referenced in Table
   Printed surveys were created for this experiment that con-         1 as CC) and the IMM, each using 40 samples, for all of the
sisted of eighteen questions in total. The questions were for-        arguments. The results of these simulations were averaged
mulated to appear much like those, that elicited the docu-            and are reported in Table 1. For each question, we expected
mented phenomena in the subjects of Osherson et al. (1990)            a particular argument to be rated stronger than its alternate,
and Sloman (1993)—excluding premise-conclusion identity,              consistent with the induction phenomena. For each of the
premise-conclusion inclusion, inclusion similarity, and the in-       questions, the difference between the ratings of argument A
clusion fallacy. Each question consisted of two arguments,            and B was calculated and averaged across participants. These
designated A and B, and a line with eleven hatch marks. Be-           ratings were compared to the model predictions, which are
low the far-right hatch mark, a letter B was placed. Similarly,       reported as log(argstrong /argweak ). Here, argstrong is the argu-
below the far-left hatch mark the letter A was placed.                ment that we expected would have the stronger rating, sim-
Procedure: Subjects were handed a survey and a writing                ilarly argweak is the weaker rated argument. This measure
utensil. They were told that for each question they should            provides an intuitive way of demonstrating whether a partic-
read both of the arguments (i.e. A and B), and evaluate which         ular model was able to predict the outcome for each of our
one they believe to be stronger. Once they determined the             questions, showing positive values where the model was suc-
stronger argument, they were asked to indicate on the line            cessful and negative values where the algorithm failed. In
how much stronger they believed their choice to be, relative          Table 1, we report the results that are in the expected direc-
to the alternate. They were informed that argument strength           tion in bold font. For all, but one of the arguments found
began at the midpoint of the line and increased toward the            to be statistically significant, our model is consistent with
argument that they deemed stronger.                                   the induction phenomena; whereas, the IMM fails to predict
                                                                      the stronger argument in one of our cases—monotonicity—
                                                                      and the FBIM fails for four cases—non-monotonicity, fea-
Results                                                               ture exclusion, and non-diversity. For the remaining statis-
                                                                      tically significant argument, shown as number 3, in Table 1,
Participant ratings for all cases of the stimuli were tallied. An
                                                                          2 Osherson  et al. (1990) asked people to make judgements using
exact binomial sign test for each question, revealed that at
                                                                      the same paradigm that we employed, and also used a binomial sign
least one example for all cases was significant (p < .05), ex-        test of significance. Their cases of asymmetry yielded a nonsignifi-
cluding premise diversity and asymmetry. Both of the cases            cant difference in the predicted direction.
                                                                  1468

we predicted that this argument would demonstrate the diver-            We showed that our model is able to demonstrate many
sity phenomenon, as did CrossCat, the IMM, and the FBIM;             of the known phenomena that is associated with category-
however, subjects judged the argument with the less diverse          based induction. While we believe that our model is a step
premises to be stronger.                                             in the right direction, there are limitations. For instance,
   The FBIM cannot account for the non-monotonicity cases,           CrossCat only identifies category structures, and does not dis-
as its bounded by its mathematical definition. In words, any         cover other more richly-structured knowledge representations
added premise features can only lead to a stronger argument.         found in real-world domains, such as tree structures. Further,
However, given the context of penguins and dolphins, fea-            the model does not take into account the fact that features can
tures of finches do not seem applicable; yet the FBIM con-           sometimes be the cause of other features, and futher use that
siders those features, and any overlap between those features        knowledge to guide prediction. Both of these ideas represent
and the features of dolphins, leads to a stronger prediction.        important areas for future work.
   The FBIM can explain instances of the feature exclusion
phenomenon when there is no overlap between the diversi-                                       References
fying premise category, and the conclusion category. While           Heit, E., & Rubenstein, J. (1994). Similarity and property ef-
Sloman (1993) was able to demonstrate this effect using the            fects in inductive reasoning. Journal of Experimental Psy-
Osherson et al. (1990) dataset, our dataset possessed overlap-         chology: Learning, Memory, and Cognition, 20, 411–422.
ping features between ants and monkeys, and between dol-             Kemp, C., Perfors, A., & Tenebaum, J. B. (2007). Learning
phins and sheep. Thus, the FBIM made stronger predictions              overhypotheses with hierarchical bayesian models. Devel-
for the arguments having more diverse premises; whereas,               opmental Science, 10, 307–321.
subjects rated the less diverse arguments stronger.                  Medin, D. L., Coley, J. D., Storms, G., & Hayes, B. K.
   Finally, the FBIM fails to account for non-diversity when           (2003). A relevance theory of induction. Pyschonomic Bul-
the more diverse premise category shares salient features with         letin and Review, 100, 254–278.
the conclusion category, such as leopards,seals−→dolphins vs.        Osherson, D., Smith, E. E., Wilkie, O., & Shafir, E. (1990).
leopards,jellyfish−→dolphins. We predicted that despite the            Category-based induction. Pyschological Review, 75, 185–
more diverse premises, the argument with premise categories            200.
of leopards and seals would be rated stronger by subjects, and       Rasmussen, C. E. (2000). The infinite gaussian mixture
their ratings agreed with our intuition. CrossCat can give an          model. In In advances in neural information processing
account for the arguments for which other models of induc-             systems 12 (pp. 554–560). MIT Press.
tion fail to explain. CrossCat tends to apply those features         Rips, L. (1975). Inductive judgements about natural cate-
that are salient, given the context. So, for instance, in the          gories. Journal of Verbal Learning and Verbal Behavior,
context of penguins and finches, the likelihood of adding fea-         14, 665–681.
tures of dolphins is reduced, since features of birds are more       Ross, B. H., & Murphey, G. L. (1999). Food for thought:
salient.                                                               Cross-classification and category organization in a complex
                                                                       real-world domain. Cognitive Psychology, 38, 495–553.
                         Discussion                                  Shafto, P., & Coley, J. D. (2003). Development of catego-
                                                                       rization and reasoning in the natural world. novices to ex-
People are remarkable for their ability to accurately predict          perts, naı̈ve similarity to ecological knowledge. Journal of
unobserved aspects of the world. Research in category-based            Experimental Psychology: Learning, Memory, and Cogni-
induction seeks to explain people’s success. Though many               tion, 29, 307–321.
previous models of induction have been proposed, none ex-            Shafto, P., Kemp, C., Baraff, E., Coley, J. D., & Tenenbaum,
plain the extant phenomena. In this paper, we have presented           J. B. (2005). Context-sensitive reasoning. In Proceedings
a novel model of category-based induction, based on cross-             of the twenty-seventh annual conference of the cognitive
cutting categorization. We have shown that this model out              science society. Mahwah, NJ: Lawrence Erlbaum Asso-
performs two well-established models, the FBIM and IMM,                ciates.
accounting for the greatest number of documented phenom-             Shafto, P., Kemp, C., Mansinghka, V., Gordon, M., & Tenen-
ena.                                                                   baum, J. B. (2006). Learning cross-cutting systems of
   Previous approaches have explored the extremes of knowl-            categories. In Proceedings of the twenty-eighth annual
edge representation. Models such as the SCM (Osherson et               conference of the cognitive science society. Mahwah, NJ:
al., 1990) maintain a strict taxonomy that is applied across all       Lawrence Erlbaum Associates.
situations, and cannot explain phenomena that require more           Sloman, S. A. (1993). Feature-based induction. Cognitive
flexibility. Models such as the FBIM have no structured rep-           Psychology, 25, 231–280.
resentation, and therefore cannot discern predictive features        Tenenbaum, J. B., Kemp, C., & Shafto, P. (2007). Theory-
from those that are idiosyncratic. Our approach balances               based bayesian models of inductive reasoning. In E. Heit
these two extremes, maintaining a strong knowledge repre-              & A. Feeney (Eds.), Inductive reasoning. New York: Cam-
sentation, but allowing for potentially many sets of categories        bridge University Press.
that guide inference in different contexts.
                                                                 1469

