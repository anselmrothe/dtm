UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
From Data Streams to Information Flow: Information Exchange in Child-Parent Interaction
Permalink
https://escholarship.org/uc/item/063856ft
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Choi, Heeyoul
Yu, Chen
Smith, Linda B.
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

    From Data Streams to Information Flow: Information Exchange in Child-Parent
                                                                Interaction
                  Heeyoul Choi, Chen Yu, Linda B. Smith, and Olaf Sporns (chenyu@indiana.edu)
                                    Psychological and Brain Sciences, and Cognitive Science Program
                                       Indiana University, 1101 E. 10th St., Bloomington, IN 47405
                              Abstract                                   learning the relevant sensorimotor cues and thus may enable
   The goal of this paper is to enhance understanding of how
                                                                         us to see more clearly the strands that are more tightly
   bodily actions between two social partners are coordinated in         woven in the highly developed adult system.
   interpersonal interactions in naturalistic contexts. To this end,     The key idea of the present study is to apply information-
   we introduce information-theoretic measures as a new                  theoretic measures to understand the structure in the
   approach to capturing sensorimotor dynamics in child-parent           sensorimotor dynamics of the interaction. To this end, we
   social interaction. In particular, information flows were
   measured based on a set of variables extracted from                   conceptualize multimodal information flows between
   multimodal fine-grained behavioral data in social interactions        children and parents as those between senders and receivers
   wherein a child and a parent played with a set of novel toys.         in artificial communication systems (Shannon, 1948). More
   Our results showed that information-theoretic measures can            specifically, the child and the parent communicate with each
   indeed capture the inherent structure of perception and action        other using multiple communication channels such as gaze,
   dynamics and further information exchange patterns can be             pointing, speech, and hand movements. The specific goal
   used to predict successful learning through child-parent
                                                                         this study is to understand how information theoretic
   interactions. Moreover, those information flows between
   sensorimotor variables reveal a set of underlying perceptual          measures might be used to analyze the flow and information
   and motor patterns with cognitively plausible explanations. In        exchange within each participant and between participants.
   summary, the present study represents the first steps to              For example, within an individual, do behaviors such as
   connect information-theoretic measures as a mathematically            looking “send” information to the hands, in the sense of
   rigorous framework with embodied human communication                  signalling a reach? Across individuals, does a hand action
   and cognition.                                                        by one participant send information to the gaze of the other?
   Keywords: Embodied Cognition; Local Transfer Entropy;                 And, if we can measure information flow in these ways, can
   Information Theory; Word Learning; Social Interaction.                we also measure how it might change at different points in
                                                                         the interaction, for example, when an object is being
                          Introduction                                   named?
How do two interacting agents couple their activity? Some                Historically, information theory was developed to find
forms of human collaborative and coordinated behavior                    fundamental limits on compressing and reliably
(such as maintaining a conversation, or jointly solving a                communicating data within single transmission channels
complex problem) appear to happen effortlessly as if the                 (Shannon, 1948). Since its inception, information theory has
participants can read each other’s mind and understand each              found applications in many other areas, including statistical
other’s communicative intent. At an elementary level, inter-             inference, natural language processing, the evolution and
agent coordination depends on external (and observable)                  function of molecular codes, model selection in ecology,
behaviors by the participants where the behavior of one                  thermal physics and other forms of data analysis(de Ruyter
participant influences the behavior of the other. Past                   van Steveninck et al., 1997). Recently, information theory
research tells us that behaviors such as eye movements,                  has been applied in the context of embodied autonomous
head turns, and hand gestures are critical to this                       systems to help characterize the flow of information
coordination. However, very little is known about the real-              between (neural or algorithmic) control architectures, body
time dynamics of these behaviors in social interactions nor              and environment (Sporns & Lungarella, 2006).
about how they may be related to higher-order functions                  Despite the recent success of information-theoretic
such as making inferences about the goals and intentions of              measures in various scientific fields, these recent advances
other.                                                                   have not been systematically applied to human behavioral
Because so little is known about the real time dynamics of               data. Thus the present study seeks both to understand the
the sensory-motor behaviors on which social coordination                 sensorimotor dynamics of social interactions as information
rests, the present study takes a bottom-up approach,                     flow and to develop a mathematically rigorous framework
measuring multiple sensory streams – head and hand                       within which to do so.
movements as well as each participant’s view of the events
– and then attempts to determine the possible signatures of                      Experiment and Data Preprocessing
coordination in these behaviors. The social coupling of a                Figure 1 provides an overview of the approach. We
toddler and a parent is an appropriate first setting for this            measured multiple sensory streams with no prior
endeavor because the toddler as a developing system is just              expectations that they are independent or dependent. These
                                                                     868

Figure 1.Overview of our approach. Sensorimotor dynamics are analyzed based on the normalized transfer entropy around naming
moments. 1) Data: Multimodal time series were collected from child-parent interactions. 2) Symbolization and information-theoretic
measure: those continuous time series were converted into symbolic sequences and information flows between those sequences were
calculated. 3) Pattern Discovery: finally we analyzed information transfer patterns between the child and the parent and discovered
psychologically interesting patterns that can lead to smooth social interaction and learning.
continuous data streams are then subjected to a                           on heads, and audio recording of the parent’s speech. The
symbolization step that, in a mathematically defensible way,              head cameras captured the dynamic visual information from
partitions the continuous values into a set of discrete                   each participant’s first-person perspective.
categories. From these, we can further apply information-                 After these play trials, the child was tested to determine
theoretic measures by first grouping the temporal variables               whether the child had learned any of the object names. This
according to different categorical events in the interaction,             name-comprehension test was performed by the
and then measuring the information flow between and                       experimenter. On each trial, three objects were placed out of
within participants.                                                      reach of the child about 30 inches apart, one to the left of
Before we provide further details, we briefly review the                  the child, one in the middle and one to the right. Then the
experimental setup, the nature of the multimodal data and                 experimenter looked directly into the child’s eyes, said the
data processing. More details can be found in Yu, Smith,                  name of one of the objects and asked for it. Direction of the
Shen, Peirera, & Smith (2009) and Yu & Smith (under                       child's eye gaze was scored as indicating comprehension.
revision). In the experiment, the child and the parent sat                Each word was tested twice with a score ranging from 0, 1
opposite each other at a small table and the parent was                   to 2. The objects with score 0 or 2 are considered to be
instructed to interact naturally with the child, engaging the             unsuccessfully or successfully learned respectively.
child’s attention with the toys while naming them. The toys
and names were novel to the children. In total there were six             Data Preprocessing
objects with novel shapes and solid colors and 6 to-be-                   The data from head cameras, motion sensors and audio were
learned object names were artificial names (e.g. “bosa”,                  automatically annotated by various image and sensory
“dodi”). Children and parents played with three objects at a              processing tools developed in our previous work. Technical
time. Eight children between 18 to 24 months of age and                   detailed can be found in Yu, Smith, Shen, Pereira, and
their parents participated in the study.                                  Smith (2009).
There were two sessions of the study. In the free-play                    Video processing. The recording rate is 30 frames per
session, parents and children played with 3 objects for 4 1.5             second and the resolution of each image frame is 720x480.
minute play periods. Parents were asked to play naturally                 The image data is analyzed in two ways: (1) At the pixel
and if they named the objects, they had to use the names that             level, we use the saliency map model developed by Itti,
were provided by the experimenter and pre-taught to the                   Koch, and Niebur (1998)to measure which areas in an
parents. The novel aspect of the study was the multimodal                 image are most salient based on motion and intensity. (2) At
sensing equipment worn by the participants: two head-                     the object level, we automatically extract visual information,
mounted mini cameras that were placed on both the child’s                 such as the locations and sizes of objects, from sensory data
and the parent’s foreheads, motion tracking sensors placed                in each of the two cameras. The combination of using pre-
                                                                      869

defined simple visual objects and utilizing state-of-the-art        section provides some technical details in information
computer vision techniques results in high accuracy in              theoretic calculations.
visual data processing.                                             For example, in order to measure the potential information
Motion data processing. Two motion tracking sensors on              transferred by the child’s head movement to the child’s hand
participants' heads recorded 6 degrees of freedom of their          actions, let X be a symbol sequence representing the child’s
head movements at the frequency of 240 Hz. Raw motion               head movement and Y be a symbol sequence representing
data {x, y, z, h, p, r} from each sensor were grouped into          the child’s hand actions, the transfer entropy from Y to X
position {x, y, z} and orientation {h, p, r} groups, and then a     can be calculated through the following steps. First, let A be
motion detection program was developed and used to                  a set of the symbols used in sequence X, and p(x) be the
compute the magnitudes of both position movements and               probability mass function of symbol x. Entropy of sequence
orientation movements.                                              X is defined by
Speech processing. The parent's speech was recorded. The                             ! ! =    −            ! !   log  ! ! .
speech signals were processed and we counted a spoken
                                                                                                     !∈!
utterance sentence containing an object name as a naming            Next, we calculate conditional entropy, ! !|! ! , as the
moment for that object.                                             entropy in sequence X given its previous values of X:
     From Data Streams to Information Flow                                  ! !|! ! =    −                  ! !, ! !   log  ! !|! ! .
                                                                                                 !∈!,! ! ∈!
We begin with multiple streams of continuous data from              ! !|! !   can be viewed as the amount of information
sensorimotor child-parent interaction. Yet the goal is to           transferred from one’s previous state to its current state in
measure information exchange at the bit level. Thus, we             the same sequence/process.
need to convert continuous time series into streams of              Further, given two processes X and Y, free information of X
discrete states. From these, we can then form probabilistic         given Xp and Yp is defined by:
distributions of the states of each variable over time, and                ! !|! ! , ! !
apply information metrics to quantify the amount of
information in bits.                                                       =−                      ! !, ! ! , ! !   log  ! !|! ! , ! ! .
                                                                                 !∈!,! ! ∈!,! ! ∈!
Symbolization                                                       Free information captures the amount of information of X
Symbolization is the procedure in which a continuous                that is not transferred from ! ! as ! ! is given (Note in
data stream is converted a symbol sequence. As in the               information-theoretic measures, a variable with certainty
SAX algorithm (Lin, Keogh, Lonardi, & Chiu, 2003),                  doesn’t contain any information).
we used the distribution of piecewise aggregate                     Now that given conditional entropy and free information,
approximates (PAAs) and made a uniformly                            transfer entropy from Y to X is defined by
distributed symbol set based on the histogram of the                            !" !, ! = ! !|! ! − ! !|! ! , ! ! ,
PAAs. Compared with other approaches, SAX allows                    which is the information in current X coming from Y. Thus,
lower-bounding distance measures to be defined on the               by subtracting free information in X which has nothing to do
symbolic space that are identical with the original data            with Y (as ! ! is given), we can obtain the amount of
space. Thus, the information loss through this                      information actually transferred from Y to X.
                                                                    Finally, in practice, two additional steps were included to
symbolization and its potential effects on subsequent
                                                                    improve calculation accuracy. The first step was to
data processing is minimal. One open issue in this                  normalize transfer entropy from Y to X with respect to the
process is window size; it needs to be neither too small            total information in sequence X itself. In this way, we can
nor too large to capture the relevant dynamics of the               obtain the relative amount of information transferred by Y.
phenomena under study. Here we set the window size                  Moreover, we introduce shuffled transfer entropy TE(Ys,X)
to 300 msec (PAA=3), as most micro-level human                      as a bias term (Ys is a shuffled sequence of Y) to remove
behaviors, such as gaze fixations, happen at this timing            accidental information captured by the information between
scale.                                                              X and Ys, as Ys contains the same symbols as those in Y but
                                                                    those symbols are arranged in a randomly shuffled order. As
Transfer Entropy                                                    a result, the final form used in our study is called
With symbolic representations of various derived time series        normalized transfer entropy:
from multimodal child-parent communication, we can select
                                                                                                    !" !, ! − !" ! ! , !
two time series and measure transfer entropy as a way to                         !"# !, ! =                                     .
capture information transfer between the two underlying                                                      ! ! !!
processes that generate these two time series. Transfer
entropy was originally proposed by Marko (1973), and has                  Finding Cognitively Significant Events
been successfully applied to understand how much                    If these information theoretic measures capture the structure
information      flows     between      variables     (Massey,      in the parent-child interaction, then they should be revealing
1990;Schreiber, 2000; Gourevitch&Eggermont, 2007). This
                                                                870

about significant behavioral events in that interaction. The        matrices were computed and their MDS plots were shown in
naming of objects is known to a psychologically compelling          Figure 2, which reveals various patterns and dynamics
moment in parent and child interaction and one in which the         between five variable categories. In the following, we will
parent and child seem to tightly coordinate attention               further     quantify     those     patterns    with     cognitive
(Tomasello & Farrar, 1986). Accordingly, we grouped the             interpretations.
normalized transfer entropy sequence into three time periods
defined around naming events: 1) “during” moments
defined by the onset and offset of a naming event; 2)
“before” moments defined by 3 seconds prior to the onset of
a naming event to that onset; 3) “after” moments defined by
the offset of a naming event to 3 seconds after that offset.
In addition, we segregated those naming events into two
kinds, those that led to successful learning and those that did
not (as measured by the comprehension test after play).
Thus, the goal was to compare information transfer patterns
in successful learning with those in unsuccessful learning,
and at three particular (and critical) moments in the
interaction (before/during/after naming).
In the present paper, we selected a subset of sensorimotor
variables in the interaction, grouped them into 5 semantic
categories and reported information exchange patterns
between them: child’s perception, child’s head movements,
child’s holding action, parent’s head movements and
parent’s holding action. As shown in Figure 2, four
variables from the child’s perception (1-4) contain visual
information of named objects, such as its size, intensity
saliency, motion saliency, and its spatial location in the head
camera view. Four variables (17-20) from the child’s head
movements measures both orientational and positional
changes of the child’s head. Similarly, four variables from
the parent’s head movements (21-23) capture the dynamics
of the parent’s head. Additionally, variables 7 and 8 contain
the information on which objects held by either the child or
the parent.
The first questions we asked were whether the transfer
entropy measures captured the inherent structure of
perception versus action and of one participant versus the
other, and whether information transfer patterns in
successful learning differ with those in unsuccessful               Figure 2. MDS plots from 6 normalized transfer entropy matrices:
learning. To this end, we first calculated all of the transfer      (Left column) unsuccessful learning, (Right column) successful
                                                                    learning. (Top) before the naming moments, (Middle) during the
entropies between any pairs of two variables in the data set
                                                                    moments and (Bottom) after the moments. The red ellipses are for
which formed a transfer entropy matrix. Within this matrix,         child’s head movement group, the blue for parent’s head
each cell indicates the amount of information transferred           movements, and the green for child target object perception group.
from one variable to the other. We viewed this transfer             7 and 8 are child’s holding and parent’s holding actions,
entropy matrix as a similarity matrix and applied                   respectively. The ellipses show the 1.5σ(standard deviation of the
multidimensional scaling (MDS) to recover the structure             group) equidistance trace from the group centers.
between those variables based on their information
exchange. This data analysis procedure consists of two              Child Perception and Head Movements
steps. First, a normalized transfer entropy matrix was              From Figure 2, we observe that the distances from child’s
converted into a symmetric dissimilarity matrix. Next,              perception to two head movement groups are changing over
multidimensional scaling (MDS) equipped with the constant           time. In successful learning, the child’s perception (green) is
adding technique as in kernel Isomap (Choi & Choi, 2007)            closer to the parent’s head movement (blue) before the
was applied to the dissimilarity matrices.                          naming events. A closer distance in MDS indicates that two
Given we decompose and group temporal sequences into six            groups were closely tied as there were more information
groups       –      before/successful,       during/successful,     exchanges between the two groups. This suggests that the
after/successful, before/unsuccessful, during/unsuccessful,         child’s perception was strongly influenced by the parent’s
and after/successful, six normalized transfer entropy               head movements right before naming in successful learning.
                                                                871

One possible explanation is that in successful learning,          attention, were more influenced by the parent’s (but not the
parents either followed the child’s attention or successfully     child’s own) manual actions, which turned out to have
attracted the child’s attention. This close coupling between      negative effects on learning.
the parent’s head movements and the child’s perception            The bottom two plots in Figure 4 showed information
served a precursor for successful learning.                       exchanges between the parent’s head movements and hand
However, during the naming moments, the child’s                   actions from both participants. During naming moments,
perception cluster (green) moved toward the child’s head          there were more information flows between the parent’s
movement cluster (red), and then finally moved away from          head movements and manual actions in successful cases
both head movement clusters in Figure 2 with                      than those in unsuccessful cases. A direct coupling between
approximately equal distances to both, suggesting that the        the parent’s head movements with manual activities can be
child’s head movements were closely coupled with the              viewed as a metric of the parent’s engagement in interacting
child’s own perception when the child heard the target            with the child and in teaching object names.
object name in successful cases.
Figure 3. Closest distances between child’s perception and
heads movements: (Left) successful learning, (Right)
unsuccessful learning.
These distance patterns are quantified and summarized in
Figure 3. We calculated the distances between the groups
based on the closest distance between two member variables
of two groups, as a close distance between any variable pair
from the two groups indicates a link between two groups
through those two variables. As shown in Figure 3, the same       Figure 4. Closest distances between head and hand movements:
trend described in successful cases also appeared in              (Top Left) between child’s head movement and hand movements
unsuccessful cases but the pattern is much weaker than what       in successful learning, (Top Right) between child’s head
                                                                  movement and hand movements in unsuccessful learning, (Bottom
happened in successful moments.                                   Left) between parent’s head movement and hand movements in
                                                                  successful learning, and (Bottom Right) between parent’s head
Head Movements and Holding Actions                                movement and hand movements in unsuccessful learning.
Figure 4 (top) shows the distances between the child’s head
movements and both the child’s and the parent’s holding           Child Perception and Holding Actions
actions. In successful cases (left), both the child’s and the     Yu, Smith, Shen, Pereira, and Smith (2009) reported that
parent’s hand actions are directly linked to the child’s head     hand movements, especially the child’s hand movements,
movements only during naming moments but not before or            are dominant factors for child’s perception. However, it is
after naming, suggesting a coupling of the child’s head           not clear how their relations are measured in terms of
movements and manual actions from both participants at the        transfer entropy. As shown in Figure 5, the overall pattern
naming moments. A similar pattern also appeared in                between holding actions and child perception is that before
unsuccessful learning, suggesting that the pattern is             naming they are close, and then child perception moves
characteristic for naming moments, being successful or not.       away from holding actions during the naming moments and
Moreover, one noticeable difference between successful and        then returns back to hand actions after the naming moments.
unsuccessful learning is that the parent’s hand actions           Moreover, this trend is shown in both successful and
consistently exchanged more information with the child’s          unsuccessful learning cases. This is a rather unexpected
head movements during and after naming in unsuccessful            result as our previous studies (Yu, Smith & Pereira, 2008)
cases, compared with those information exchanges between          showed that the child’s holding actions during the naming
the child’s own holding actions and his own head                  moments can facilitate learning. Taken together with the
movements. This pattern suggests that the child’s head            results illustrated in Figures 3 and 4, one plausible
movements, as an indicator of the child’s sustained               explanation is that during those naming moments, the
                                                              872

child’s and the parent’s manual actions had direct effects (as       study represents our first steps to combine multimodal fine-
measured by transfer entropy) on both the child’s and the            grained behaviors and information-theoretic measures to
parent’s head movements which consequentially influenced             better understand coordinated behaviors.
the child’s perception. Thus, both the child’s and the
                                                                     Acknowledgments: We thank Charlotte Wozniak, Amanda
parent’s head movements played a role during the naming
                                                                     Favata, Alfredo Pereira, Amara Stuehling, and Andrew
moments as a link between the child’s perception and
                                                                     Filipowicz for data collection, and Thomas Smith for
manual actions. This additional involvement of head
                                                                     developing data management and preprocessing software.
movements may play a critical role in naming and therefore
                                                                     This research was supported by NSF BCS 0924248 and
learning. In contrast, right before and right after naming
                                                                     AFOSR FA9550-09-1-0665.
moments, head movements were not involved and therefore
there were more direct information exchanges between the                                        References
child’s perception and manual actions.
                                                                     Choi, H., & Choi, S. (2007). Robust kernel Isomap. Pattern
                                                                        Recognition, 40(3), 853–862.
                                                                     DeRuyter van Steveninck, R., Lewen, G. D., Strong, S. P.,
                                                                        &Koberle, R. (1997). Reproducibility and variability in
                                                                        neural spike trains. Science, 275:1805-1807.
                                                                     Gourevitch, B., & Eggermont, J. J. (2007). Evaluating
                                                                        information transfer between auditory cortical neurons.
                                                                        Journal of Neurophysiology, 97, 2533–2543.
                                                                     Itti, L., Koch, C., & Niebur, E. (1998). A model of saliency
                                                                        based visual attention for rapid scene analysis. IEEE
                                                                        Trans. Pattern Analysis and Machine Intelligence, 20(11),
                                                                        1254–1259.
Figure5. Closest distances between hands and child’s perception:
(Left) unsuccessful learning, (Right) successful learning.           Lin, J., Keogh, E., Lonardi, S., & Chiu, B. (2003).A
                                                                        symbolic representation of time series, with implications
                          Discussions                                   for streaming algorithms. In Proc. 8th ACM SIGMOD
                                                                        workshop on research issues in data mining and
The present study applied normalized transfer entropy                   knowledge discovery. San Diego, CA.
measures to child-parent interaction data to better                  Marko, H. (1973). The bidirectional communication theory-
understand sensorimotor dynamics in such multimodal                     a generalization of information theory. IEEE Trans. on
interaction. We analyzed information flows between various              Communications, COM-21(12), 1345–1351.
variables and reported how information is flowing in the             Massey, J. L. (1990). Causality, feedback and directed
child-parent interaction, especially around the naming                  information. In Proc. int’l. symp. on information theory
events. Indeed, those information flows between                         and its applications. Waikiki, Hawaii.
sensorimotor variables informatively reveal a set of                 Schreiber, T. (2000). Measuring information transfer.
underlying perceptual and motor patterns which shed light               Physical Review Letters, 85(2), 461–464.
on our understanding on real-time sensorimotor dynamics,             Shannon, C. E. (1948). A mathematical theory of
within one participant and between two social partners, that            communication. Bell System Technical Journal, 27, 379-
lead to smooth interaction and therefore successful learning.           423.
However, we also note that, in this present approach, there          Smith, L. B., Yu, C., & Pereira, A. F. (2010). Not your
are some issues that should be handled carefully. For                   mothers view: the dynamics of toddler visual experience.
example, there is a tendency to over-interpret directional              Developmental Science, 1–9.
information-theoretic measures, such as transfer entropy,            Sporns, O. and Lungarella, M. (2006). Evolving coordinated
because information flow itself is not causality (though it             behavior by maximizing information structure. In Rocha,
seems like causality). Experimental studies are needed to               L. et al. eds. Artificial Life X. Cambridge, MA: MIT Press.
determine the causal mechanisms through which variables              Tomasello, M. and Farrar, M. (1986). Joint attention and
exchange information.                                                   early language. Child Develop.,1454–1463.
A general goal of the present study has been exploring a             Yu, C., Smith, L. B. & Pereira, A. F. (2008). Grounding
new venue to introduce information theoretic measures to                Word Learning in Multimodal Sensorimotor Interaction.
social and behavioral studies. This approach has already                In B. C. Love, K. McRae, & V. M. Sloutsky (Eds.) Proc. of
been widely used in many other scientific fields and it                 the 30th annual conference of the cognitive science
allows the quantitative statistical analysis of many disparate          society. Austin, TX: Cognitive Science Society. 1017-
systems in a mathematically rigorous way which has special              1022.
merits to understand and ground high-level social                    Yu, C., Smith, L. B., Shen, H., Pereira, A. F., & Smith, T.
interaction at the sensorimotor level. In addition, it provides         G. (2009). Active information selection: Visual attention
a framework to study and compare seemingly different                    through the hands. IEEE Trans. on Autonomous Mental
systems using the same quantitative concepts. The present               Development, 2, 141–151.
                                                                 873

