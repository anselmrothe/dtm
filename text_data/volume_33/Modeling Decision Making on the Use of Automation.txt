UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Decision Making on the Use of Automation
Permalink
https://escholarship.org/uc/item/7n4494nk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Morita, Junya
Miwa, Kazuhisa
Maehigashi, Akihiro
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                           Modeling Decision Making on the Use of Automation
                                                    Junya Morita (j-morita@jaist.ac.jp)
                      School of Knowledge Science, Japan Advanced Institute of Science and Technology, Japan
                                                Kazuhisa Miwa (miwa@is.nagoya-u.ac.jp)
                 Akihiro Maehigashi (mhigashi@cog.human.nagoya-u.ac.jp), Hitoshi Terai (terai@is.nagoya-u.ac.jp)
                                   Graduate School of Information Science, Nagoya University, Japan
                                                  Kazuaki Kojima (koj@aoni.waseda.jp)
                                         Faculty of Human Sciences, Waseda University, Japan
                                                   Frank E. Ritter (frank.ritter@psu.edu)
                                   College of Information Sciences and Technology, Penn State, USA
                              Abstract                                    (2006) proposed the Extended Decision Field Theory (EDFT
                                                                          model; Figure 1). The model constructs belief of Ca and Cm
    This paper presents a cognitive model that simulates reliance
    on automation using a line-tracing task similar to driving            (Bca, Bcm) based on partially displayed these values. From
    where an operator has to track a moving line with a circle            the belief values, trust (T) and self-confidence (SC) are con-
    by pressing keys on a keyboard (manual control) or rely on            structed. Preference of automation (P) is determined by sub-
    automation (auto control). An operator can switch between
    auto and manual control during the task. The success proba-           tracting T from SC. If P exceeds an upper threshold (θ), then
    bilities of each control mode were systematically varied. An          the model turns the current control mode to auto. If P falls
    ACT-R model to perform this task was constructed by repre-            below a lower threshold (-θ), then the model turns the cur-
    senting reliance on the automation as production. The model
    performs this task through productions that manage the per-           rent control mode to manual. In every cycle, values of Bca,
    ceptual/motor modules. The utility values of these productions        Bcm, T, and SC are updated by differential equations. Al-
    are updated based on the rewards in every screen update. We           though this model clearly explains the reliance on automation
    also introduce a meta-level monitoring the internal state of the
    model. A preliminary run of this model simulated the overall          in dynamic situations, the model does not have any knowl-
    trends of the behavioral data, suggesting some validity of the        edge about tasks. It cannot interact with a task environment,
    assumptions made in our model.                                        and it provides no human performance predictions.
    Keywords: Automation; ACT-R; Trust.                                      This report describes a cognitive process model that in-
                                                                          teracts with a specific task environment where sequential
                           Introduction                                   decision-making is made. Especially, we extend our previ-
We unconsciously use automation systems like e-mail spam                  ous model (Morita et al., in-press) to improve its motor con-
filters, spell checkers, and electronic toll collection (ETC)             trol. To do this, we use ACT-R, a unified theory of cognition
systems. These systems save time and help us lead more ef-                (Anderson, 2007). The following subsection briefly shows
ficient lives. We, however, sometimes face difficult choices              features of this architecture relating to our model.
about whether to use these systems (Bainbridge, 1983). It has
                                                                          ACT-R
also been pointed out that human decision making using such
systems is not always optimal. For example, Parasuraman                   One of the most important assumptions of ACT-R is modular-
and Riley (1997) stated that there are two types of maladap-              ity of cognition. ACT-R is composed of several independent
tive choices of using automation: misuse, the over-reliance of            modules: goal, production, declarative, perceptual, and mo-
automation, and disuse, the underutilization of automation.               tor (Anderson, 2007). A goal module holds the current task
Some studies indicated that human users have an automa-                   goal and other task related information. A production mod-
tion bias towards misuse of automation systems (Bahner, Hu-               ule and a declarative module hold procedural and declarative
per, & Manzey, 2008; Singh, Molloy, & Parasuraman, 1997;                  knowledge respectively. Perceptual modules include a vision
Skita, Moiser, & Burdick, 2000). On the other hand, other                 and an audio module, which take information from an exter-
research indicated that human users have a manual bias, a                 nal environment. A motor module manipulates devices like
bias towards disuse of automation systems consistent with                 a keyboard or a mouse in an external environment. Modules
a need for control (Beck, McKinney, Dzindolet, & Pierce,                  other than the production module have buffers to hold tem-
2009; Dzindolet, Peterson, Pomranky, Pierce, & Beck, 2003;                porarily information called a chunk. A production module
Dzindolet, Pierce, Beck, & Dawe, 2002).                                   integrates the other modules by production rules, which con-
    Vries, Midden, and Bouwhuis (2003) experimentally re-                 sists of a condition/action pair that is used in sequence with
vealed that the reliance of automation is influenced by both              other productions to perform a task. Conditions and actions
the Capability of Manual control (Cm) and the Capability of               in production rules are specified with buffer contents of each
Auto controls (Ca). To explain these effects, Gao and Lee                 module.
                                                                     1971

Figure 1: The process of Extended Decision Field Theory                        Figure 2: The Line-tracing task environment
(Gao & Lee, 2006), modified and reproduced from the origi-
nal figure.                                                            The vehicle is controlled by commands of “left”,
                                                                    “straight”, or “right”. If the vehicle receives a left command,
                                                                    the vehicle moves 1 pixel left from the original position. The
   ACT-R also includes sub-symbolic cognitive processes. If         command is sampled at 48 Hz1 . Therefore, maximally, the
several rules match to buffer conditions, conflict resolution       vehicle can move 2 pixels per one pixel scroll of the line.
of production rules is made based on utility values assigned           A participant can chose manual or auto controls to send
to production rules. The learning of utility is controlled by       commands. In the manual control, participants use left and
equation 1:                                                         right arrow keys to send commands. If a participant’s finger
                                                                    is put on a right arrow key, the vehicle keeps receiving a right
            Ui (n) = Ui (n − 1) + α[Ri (n) −Ui (n − 1)]       (1)   command at every 20 ms until this key is released. In the
                                                                    auto control, participants monitor that the auto control moves
   α is the learning rate; Ri (n) is the reward value given to      the vehicle. The auto control tries to follow an optimal line
production i at time n. The learning occurs when a reward           presented as the green line in Figure 2. An optimal line is the
is triggered, and all productions that have fired since the last    shortest line to pass “goals” located on each corner. Figure
reward are updated. This learning is essentially same as the        2 shows goals as blue dots. If the center of the vehicle is off
process presented in the EDFT model using a basic reinforce-        the optimal line, the auto control system sends a command to
ment learning method.                                               correct the vehicle position. In our experiment presented in
   So far, ACT-R has been used to model many fields                 the next section, the optimal line and goals are not visible to
of human-machine interaction including driving (Salvucci,           participants.
2006), teleoperation (Ritter, Kukreja, & Amant, 2007), wa-             In both control modes, commands are not always success-
ter flow control (Lebiere, Gonzalez, & Warwick, 2009), and          fully sent to the vehicle. Failures occur at specified rates. In
air-traffic control tasks (Taatgen, 2005). The utility update       this study, Ca and Cm specify these rates. If Ca or Cm is low,
learning of this architecture also has been applied to strategy     the vehicle controlled by the corresponding mode is lagged,
selection (Lovett & Anderson, 1996). Therefore, we consider         and it becomes hard to follow the line. To conduct the task
that this architecture is suitable to construct a model of de-      successfully, participants need to select a suitable mode in
cision making on the use of automation. Through this mod-           each situation. The participants freely change between modes
eling, we try to find behavioral constraints in the model of        by pressing the spacebar.
decision making on the use of automation.
                                                                                               Experiments
                            The Task                                Before describing the model, we summarize here two experi-
To manipulate auto and manual performance in a dynamic              ments that examined the use of automation in this task (more
situation, and to understand how users change to use automa-        details are reported in Maehigashi et. al., in press) .
tion, we developed a simple tracking task, similar to driving.         In experiment 1, the baseline performance of the manual
We call this task the line-tracing task. Figure 2 shows the         and the auto controls were examined. The participants were
screenshot of the task environment. This environment was            required to control the vehicle using the manual control mode.
developed in Java.                                                  There were five conditions where Cm values were manipu-
   This task requires participants to control the horizontal po-    lated from 30% to 70%. Every participant experienced all
sition of the vehicle (red circle) to follow the black line that    the five conditions in random order. Each condition lasted
scrolls down at 24 pixels per second. The screen is updated         40 s. The performance of the experiment was compared to
every 40 ms. If the vehicle is not on the line, a warning is pre-
                                                                        1 If a key-press event is detected, a flag of sending commands is
sented outside of the window. The line is drawn by randomly
                                                                    on. This flag is off when a key-release event is detected. Therefore,
combining 48 pixels height line patterns of varied angles (30,      the manipulation of the command rate is not influenced by a key-
45, 90, 135, and 150 degrees).                                      repeat rate setting in an operating system.
                                                               1972

the auto-mode performance measured in the corresponding
Ca conditions. The results confirmed that the manual perfor-
mance is lower than the auto performance in each condition.
   Experiment 2 specified the ratio of automation use during
the task. The participants conducted the task with the auto
and manual control modes. They could freely change the
mode during the task. Combining five levels of Ca and Cm
values, 25 experimental conditions were prepared. Every par-
ticipant experienced all 25 conditions. As in experiment 1,
each condition lasted 40 seconds. The results of experiment
2 indicate that participants could adaptively select a suitable                  Figure 3: The basic cycle of the model.
mode in a given situation.
                            Model
Simulated task environment
The model presented here extends our previous model
(Morita et al., in-press) to become closer to the actual inter-
action with the task environment. The model interacts with a
simulated task environment developed in the ACT-R graphi-
cal user interface that is part of ACT-R 6 (Anderson, 2007).
The simulated environment is same as the original environ-
ment in the keyboard layout, the screen update rates, the line
scrolling speed, the vehicle size, the line width, and the screen
size. The auto control mode is also implemented with Com-
mon Lisp in the simulated task environment. However, unlike
the original environment, visible goal positions are set at each
corner to allow the model to perceive the path.
Process of the model                                                                  Figure 4: Time flow diagram.
The model uses the production, goal, vision and motor mod-
ules of ACT-R 6. Eleven production rules are included in the
model. These rules consist of a basic perception-action cycle.      ual mode, the ToAuto rule competes with the KeepM, ToLeft,
Figure 3 indicates this cycle, presenting the rules in boxes.       ToRight, LtoS, and RtoS rules. These five rules have differ-
The cycle consists of a perceptual (the top part of the figure)     ent conditions specifying the vehicle and the goal positions,
and motor process (the bottom part of the figure) similar to        and current move-commands (left, right, straight). The ac-
previous driving models in ACT-R (Salvucci, 2006; Ritter et         tion clauses of the ToLeft, ToRight, LtoS, RtoS rules send a
al., 2007).                                                         command to hold or release a key to the motor module2 . The
   In the perceptual process, the model picks visual informa-       KeepM rule does not have any action clauses relating the mo-
tion from a visual location buffer that holds location informa-     tor module. This rule just clears the goal buffer.
tion of objects in the environment. The FindVehicle rule finds         Figure 4 presents a time flow diagram showing the rela-
the horizontal position of the vehicle, and places it into the      tions between the screen updates of the environment and the
goal buffer. The FindGoal rule finds the horizontal position        model cycles. The environment regularly updates the screen
of the nearest goal position, and placed it into the goal buffer.   every 40 ms. Individual rule firings take 50 ms, but the cycle
The position information in the goal buffer is used in the sub-     of the model is not regulated. There are delays in the visual
sequent motor process. After the motor process, information         and motor processes. The process of the visual location mod-
in the goal buffer is cleared to begin the next cycle.              ule itself has no delay. However, encoding the location into
   The subsequent motor process depends on the current              the goal buffer lags 10 ms. from the actual environment. The
mode. In each mode, there is a rule to switch the current mode      delay of the motor control is larger than that of the percep-
(ToAuto / ToManual). These mode-switching rules send a              tual module. The ACT-R motor module needs preparation
command to release currently pressed keys to the motor mod-         and execution time, which depends on the status of the motor
ule. After finishing the key-release, the PressSpace rule sends     module. These delays disadvantage manual control compared
a motor command pressing the spacebar.                              to automatic control.
   The mode swiching rules compete with other rules in each             2 The default ACT-R implementation does not include key-press
condition. In the auto mode, the ToManual rule conflicts with       and key-release functions. We used a customised module in which
the KeepA rule that just clears the goal buffer. In the man-        the time parameter of key-punch is used.
                                                               1973

Learning and mode switching
The model adaptively learns to use a suitable mode in a given
situation. We used the default reinforcement-learning algo-
rithm in ACT-R 6 presented in section 1. The model re-
ceives rewards in every screen update. When the vehicle is off
the line, rules used in the previous screen receive no reward
(Ri(n) = 0). Otherwise, rules used in the previous screen re-
ceive positive rewards (Ri(n) = 10). This trigger corresponds
to the warning in the actual task (Figure 2).
   This study uses a small learning rate (α = .01) compared to
the default setting (α = .2) because the rewards are frequently
triggered during the task. The noise parameter added to the          Figure 5: Performance of the model and the data in the base-
utility values (egs) is also set to 1. The initial utility values    line simulation. Error bars represent the standard error of
of the mode switching rules (UToAuto and UToManual ) are set         means (SEM).
to 5, and the initial utility values of other rules are set to 10.
This setting corresponds to the cost of mode switching. The          competing production rules.
initial utility values will not change unless the vehicle moves
                                                                                              Simulations
off the line because positive rewards and the initial values of
utility are the same.                                                In this paper, we present two simulation experiments that sim-
   In ACT-R, strategy selection is often modeled by conflict         ulate the experiments presented in section 3.
resolutions based on utility values of rules (Lovett & Ander-
son, 1996). According to this paradigm, the mode-switching
                                                                     Baseline simulation
rules fire when its utility values exceed a utility value of a       First, we conducted a simulation of experiment 1 to confirm
competing rule. However, our task has differences from tasks         the correspondence of base performance of the auto and man-
used in the previous studies. As Figure 4 indicates the motor        ual modes.
actions have delays. There are time-gaps between rule firing         Method In experiment 1, the participants could not use the
and manual control execution. These gaps make rewarding              auto control mode (Data-Manual: n = 65). Similarly, we ran
difficult because the next cycle begins before the motor ac-         the model with the initial control mode as the manual, and
tion completes. In addition, the structures of conflict are not      removed the ToAuto rule from the model (Model-Manual:
the same between the manual and the auto control modes.              n = 100). We also compared baseline auto performance be-
The ToAuto rule conflicts with five rules in the manual mode.        tween the original environment (Java-Auto: n = 65) and the
On the other hand, the ToManual rule conflicts with only the         simulated environment (CL-Auto: n = 100).
KeepM rule in the auto mode.
   To solve this problem, we assumed meta-level decision             Results Figure 5 indicates the performances of the four
making in addition to the standard conflict resolution. The          conditions in each Ca/Cm level, showing the ratio of time that
following code indicates the conditions of the ToAuto rule.          the vehicle is on the line. From this figure, it can be observed
    =goal>                                                           that the performance of the all four lines increases with higher
        isa move-vehicle                                             Ca/Cm levels, consisting with the manipulations of capabil-
        - vehicle-loc nil                                            ity. In addition, we can confirm that the auto controls are bet-
        - goal-loc nil                                               ter than the manual controls in both the experiment data and
        - previous-rule to.auto                                      the simulation. This result indicates the manual disadvan-
        current-mode manual                                          tages in this task. Although the performance of the model is
        !eval! (<= *self-conf* *trust*)                              relatively lower than that of the data, the correlations between
The last line is an !eval! condition that has two global vari-       the experiment and the simulation are high [Auto: r2 = .994,
ables, *trust* and *self-conf*3 . The ToManual rule also has         p < .01. Manual: r2 = .997, p < .01].
a similar condition, “!eval! (>= *self-conf* *trust*).” The Lisp
                                                                     Simulation with two modes
function outside of the ACT-R model sets the utility values of
the KeepA and KeepM rules into *trust* and *self-conf* re-           This simulation is conducted to simulate experiment 2 that
spectively. By putting these conditions, ToManual fires only         specifies the automation use ratio.
when *self-conf* exceeds *trust*, and the utility values of          Method In experiment 2, the participant (n = 35) could use
the ToManual rule exceeds that of the KeepA rule. Similarly,         the auto control mode. They conducted the task in 25 con-
the ToAuto rule fires only when *trust* exceeds *self-conf*,         ditions where Ca and Cm levels were manipulated (5 levels
and the utility values of the ToAutol rule exceeds that of the       of Ca ranging from 30% to 70% v.s. 5 levels of Cm ranging
    3 ACT-R architecture provide the !eval! condition to allow the   from 30% to 70%). Similarly, the model conducted the task
modeler to add arbitrary conditions to a production rule.            choosing two modes of control in the 25 conditions (n = 50).
                                                                1974

               Figure 6: Performance of the simulation 2. Error bars represent the standard error of means (SEM).
              Figure 7: Auto use ratio of the simulation 2. Error bars represent the standard error of means (SEM).
In each condition, the model conducted the task for 40 sec-                                   Conclusion
onds. The initial mode was randomly set.
                                                                    This paper described an ACT-R model that simulates decision
Results Figure 6 presents the performance of the model and          making about the use of automation. The results of the sim-
the experimental data. Each of the five graphs indicates the        ulations show overall correspondence with the experimental
performance in each Cm level, and the horizontal axis of the        data, suggesting some validity of the assumptions made in our
each graph indicates Ca levels. The figure indicates an in-         model.
crease of the performance of the model and the experiment              We consider that this study is characterized as the con-
data with higher Ca and Cm levels. The correlations of the          nection of the cognitive process model (ACT-R) to an ab-
model and the data are high [r2 = .875, p < .01] although           stract model (EDFT). Figure 8 summarizes the process of
some differences between the model and the data can be ob-          our model in the framework of the EDFT model. Like the
served. For example, the model is lower than the data in com-       EDFT model, the utility module of ACT-R represents Belief
bination of the low Cm and the high Ca levels (e.g., Cm =           and Trust in automation systems. However, unlike the previ-
30/Ca = 70). Similarly, the performance of the model fell be-       ous model, our model has knowledge to execute a task and
low that of the data in combination of the high Cm and the          simulates performing the task. Our model also does not re-
low Ca level (e.g., Cm = 70/Ca = 30). These differences sug-        ceive Ca/Cm directly. Randomized course conditions influ-
gest some difference in automation use between the model            ence the performance (success/failure) of the task. Moreover,
and the experiment data.                                            complex perceptual/motor factors are involved in the manual
   Figure 7 indicates the auto use ratio in each Ca and Cm          mode performance. Therefore, the reliance of the automation
level, which represents how long the auto mode is used during       interacts with the performance of the task in our model. As
the task. Comparison of the five graphs reveals decreases of        Bainbridge (1983) implied, to understanding decision making
auto use ratio with increases of the Cm level. We can also see      about the use of automation, one needs to consider monitor-
an increase of the auto use ratio with increases of the Cm level    ing the performance of auto and manual performance. This
from each graph. The model shares these tendencies with             study is a first step to include performance factors into mod-
the data, and we obtained a significant correlation between         eling use of automation.
the data and the model [r2 = .784, p < .01]. These results             Our model is also different from previous models of strat-
suggest that the adaptive learning on the mode selection was        egy selection in ACT-R. Unlike the previous studies, our task
made in both the experiment and the simulation. The model           requires and uses a complex perceptual/motor process. In
is, however, less adaptive compared to the data. The auto           such a situation, rewarding behavior is not easy problem. We
use ratio of the model is lower in the low Cm levels such as        introduced a function to monitor self-confidence and trust to
Cm = 30, and the model’s lines is flatter than the data’s line      solve this problem. We consider that the conditions compar-
in Cm = 50.                                                         ing utility values represents a type of meta-cognitive decision
                                                                    making, monitoring the internal states of the model. This
                                                                    monitoring process is not straightforward, but it is influenced
                                                                    by noise (egs). We need to be careful about assuming this
                                                              1975

                                                                  Bainbridge, L. (1983). Ironies of automation. Automatica,
                                                                    19(6), 775–779.
                                                                  Beck, H. P., McKinney, J. B., Dzindolet, M. T., & Pierce,
                                                                    L. G. (2009). Effects of human-machine competition on in-
                                                                    tent errors in a target detection task. Human Factors, 51(4),
                                                                    477-486.
                                                                  Dzindolet, M. T., Peterson, S. A., Pomranky, R. A., Pierce,
                                                                    L. G., & Beck, H. P. (2003). The role of trust in automa-
                                                                    tion reliance. International Journal of Human-Computer
                                                                    Studies, 58(6), 697–718.
                                                                  Dzindolet, M. T., Pierce, L. G., Beck, H. P., & Dawe, L. A.
                                                                    (2002). The perceived utility of human and automated aids
                                                                    in a visual detection task. Human Factors, 44(1), 79–94.
       Figure 8: Correspondence with the EDFT model.              Gao, J., & Lee, J. D. (2006). Extending the decision field the-
                                                                    ory to model operators’ reliance on automation in supervi-
                                                                    sory control situations. IEEE Transactions on Systems Man
process, but we could not simulate overall trends of the ex-        and Cybernetics, 36(5), 943–959.
periment without this assumption. This suggests the default       Lebiere, C., Gonzalez, C., & Warwick, W. (2009). Conver-
sub-symbolic computation is not enough for explaining the           gence and constraints revealed in a qualitative model com-
use of this automation in this task.                                parison. Journal of Cognitive Engineering and Decision
   However, using an !eval! condition is not supported by           Making, 3(2), 131–135.
ACT-R theory. ACT-R is designed as a unified cognitive the-       Lovett, M. C., & Anderson, J. R. (1996). History of success
ory that combines sub models from various fields (Ander-            and current context in problem solving: Combined influ-
son, 2007). It is difficult to combine sub models using !eval!      ences on operator selection. Cognitive Psychology, 31(2),
conditions. Therefore, we need to consider other methods            168–217.
of modeling this mechanism, which can contribute the de-          Maehigashi, A., Miwa, K., Terai, H., Kojima, K., Morita, J.,
velopment of a unified theory of cognition, particulary meta-       & Hayashi, Y. (in-press). Experimental investigation about
cognition.                                                          misuse and disuse in human automation system interaction.
                                                                    In Hci international 2011.
   There are several other limitations of this study. Consid-
                                                                  Morita, J., Miwa, K., Maehigashi, A., Terai, H., Kojima, K.,
ering the result in Figure 7, we need to explore mechanisms
                                                                    & Ritter, F. E. (in-press). Modeling human-automation
that lead to more adaptive learning. We also need to conduct
                                                                    interaction in a unified cognitive architecture. In The 20th
analysis on more detailed behavior such as the frequency or
                                                                    behavior representation in modeling & simulation (brims)
timing of mode switching during the task. The task used in
                                                                    conference 2011.
this study is also relatively simple and artificial. Connecting
                                                                  Parasuraman, R., & Riley, V. (1997). Humans and automa-
to more complex tasks is required. The factors involved in au-
                                                                    tion: Use, misuse, disuse, abuse. Human Factors, 39(2),
tomation use are broad. In future work, we will explore other
                                                                    230–253.
factors of automation use, such as cognitive load, emotion,
                                                                  Ritter, F. E., Kukreja, U., & Amant, R. S. (2007). Including
mental models, and individual differences.
                                                                    a model of visual processing with a cognitive architecture
                    Acknowledgments                                 to model a simple teleoperation task. Journal of Cognitive
                                                                    Engineering and Decision Making, 1(2), 121–147.
This study is supported through the CREST program from            Salvucci, D. D. (2006). Modeling driver behavior in a cogni-
the Japan Science and Technology Agency (JST), and DTRA             tive architecture. Human Factors, 48, 362–380.
(HDTRA 09-1-0054). The authors wish to acknowledge the            Singh, I. L., Molloy, R., & Parasuraman, R. (1997).
helpful comments and suggestions made by Dan Bothell,               Automation-induced monitoring inefficiency: role of dis-
William Kennedy, Christian Lebiere, Walt Mankowski, Ling            play location. International Journal of Human-Computer
Rothlock, Matthew Walsh, and John Yen.                              Studies, 46(1), 17–30.
                                                                  Skita, L. J., Moiser, K., & Burdick, M. D. (2000). Ac-
                          References                                countability and automation bias. International Journal of
Anderson, J. R. (2007). How can the human mind occur                Human-Computer Studies, 52(4), 701–717.
   in the physical universe? New York: Oxford University          Vries, P. de, Midden, C., & Bouwhuis, D. (2003). The effects
   Press.                                                           of errors on system trust, self-confidence, and the alloca-
Bahner, J. E., Huper, A. D., & Manzey, D. (2008). Misuse            tion of control in route planning. International Journal of
   of automated decision aids: Complacency, automation bias         Human-Computer Studies, 58(6), 719–735.
   and the impact of training experience. International Jour-
   nal of Human-Computer Studies, 66(9), 688-699.
                                                             1976

