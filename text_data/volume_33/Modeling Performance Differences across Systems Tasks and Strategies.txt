UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Performance Differences across Systems, Tasks, and Strategies
Permalink
https://escholarship.org/uc/item/8vp93222
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Lee, Jessica
Billman, Dorrit
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

           Modeling Performance Differences across Systems, Tasks, and Strategies
                                                       Jessica Lee (jessica.c.lee@nasa.gov)
                               San Jose State University, NASA Ames Research Center, Mail Stop 262-4
                                                    Moffett Field, CA 943035-1000 USA
                                             Dorrit Billman (dorrit.billman@nasa.gov)
                               San Jose State University, NASA Ames Research Center, Mail Stop 262-4
                                                    Moffett Field, CA 943035-1000 USA
                               Abstract                                  constructing models is too high to justify the benefits of
                                                                         estimating performance times. CogTool (John et al., 2004;
   Understanding problem-solving strategies and how different            http://cogtool.hcii.cs.cmu.edu/) is an easy-to-use modeling
   tools support problem solving is an important but difficult           tool that supports a simplified modeling process, while
   problem in cognitive science. Cognitive modeling provides
   one way of understanding and predicting problem solving and
                                                                         drawing on a well-vetted cognitive architecture, ACT-R
   the impact of supporting software tools. Modeling typically           (Anderson & Lebeire, 1998). The research reported here
   requires tradeoffs between fidelity of result and difficulty of       investigates how and how well a simplified modeling
   model building. We used CogTool to explore how well a                 approach like that used by CogTool can predict performance
   limited modeling approach can predict performance                     times of complex problem-solving across systems, tasks,
   differences between two applications that support problem             and strategies. We develop a method, our modeling policy,
   solving, specifically, for planning attitude of the International     for modeling complex behavior using a coarse-level tool
   Space Station. We develop a modeling policy for modeling
   complex behavior using a coarse-level tool with reduced               with reduced expressive power. We evaluate the strengths
   expressive power; then we compare model predictions with              and weaknesses of this method by comparing model
   experimental data to assess its ability to identify performance       predictions with experimental data.
   differences across systems, tasks, and strategies.                       We first describe the work and tasks being modeled,
                                                                         planning by a NASA Mission Control group, Attitude
   Keywords: problem-solving, strategies, HCI, modeling.                 Determination and Control (ADCO). Next we describe
                                                                         CogTool and why we selected it. We lay out the highlights
                           Introduction                                  of our modeling process, and describe a modeling policy,
   Problem solving in the context of human-computer                      which we found helpful to consistently model a large and
interaction both provides a resource for developing and                  complex set of behaviors. We present results of comparing
testing cognitive models and generates complex situations                predicted and actual performance times. We conclude by
of practical importance (Gray, 2008). The value of modeling              discussing where and why modeling successes and failures
problem solving outcomes and strategies in HCI is                        occurred and what this suggests about using models to
particularly high because empirical data may be impossible               understand performance in complex HCI work.
to collect at the point it would be most valuable.
Specifically, a designer would like to know how design                           ADCO Planning Domain & Software
choices impact performance in advance of implementing a                  ADCO controls the attitude (yaw, pitch, & roll) of the ISS
design. Thus, when performance data has its highest value,               (International Space Station). The operators monitor and
it can only be generated by model, not observation.                      command attitude in real-time and also develop plans in
   The need to predict performance has motivated                         advance of real-time operations. ADCO plans specify the
development of several tools for HCI (Card, Moran, &                     high-level activities (e.g. docking a Soyuz) and the actions
Newell, 1980; John et al., 2004; Kieras, 2006; Patton &                  (e.g. changes in control, maneuvering to a new attitude) that
Gray, 2010). Most tools support model construction by                    are needed to carry out the activity. ADCO currently uses
providing a framework in which low-level component                       legacy software (hereinafter called LEGACY; see Figure 1),
actions can be combined to represent larger problem solving              which functions as a form-based text editor. Operators open
tasks. Such tools can vary in the granularity of the low-level           a file for each activity and type in the parameters for each
components it provides, in whether predictions are                       action within that activity. If an activity is rescheduled, the
stochastic or deterministic, and in the complexity of tasks              start and stop times of each action must be changed.
the tool can effectively model. Models also differ in whether               After analyzing needs (Billman et al., 2010), a new
the model generates alternative strategies (Smith et al.,                prototype planning application (hereinafter called NEW; see
2008) or more frequently, requires the modeler to specify                Figure 2) was designed. NEW provides better
the strategies to be modeled.                                            representations and operations, particularly for temporal
   In selecting a modeling approach there is typically a                 relations. NEW allows rescheduling an activity as a whole,
tradeoff between the fidelity of the resulting model and the             by sliding the activity in the timeline or by typing in new
complexity of building it. Often, the cost of learning and               start times in the editing panel.
                                                                     3489

      Figure 1. Screenshot of LEGACY system. Revision is done                 Figure 2. Screenshot of NEW system. Revision is done by
      in lower right panel, by typing values into text boxes. (The             dragging and dropping selected events on the timeline or
           attribute values shown do not reflect a real event.)                       by typing values in the panel on the right.
   The experimental data to which we compared model                    potential power of this modeling approach is that widgets
predictions was a subset of an extensive experiment in                 and transitions can be linked together to generate
which users performed a series of checking and editing tasks           predictions about complex sequences of behavior.
over two days, separated by one week. A between-subjects                 To build a model, a series of screenshots create a
experiment compared performance using the two systems; 7               storyboard of frames.          Each frame is overlaid with
engineering students participated in LEGACY and 8 in                   interactive widgets, and transitions representing user actions
NEW. We taught users about possible strategies to complete             link frames to represent moving from one state to another.
the tasks but left strategy choice open. In this paper, our            Each model represents a specific sequence of actions (such
experimental data draws from a particular set of editing               as a particular strategy on a particular task) that are
tasks performed on the second day after 7-12 cumulative                demonstrated by clicking through successive frames. Based
hours of practice on the system.                                       on the demonstration, CogTool constructs a Keystroke
   The particular set of interest consisted of 12 tasks,               Level Model of how a skilled user would execute the task
requiring users to shift the times of various events: 1) one           and it computes a predicted time. The resulting model built
action, 2) one activity, 3) a set of actions within one activity,      from demonstration can be modified by inserting additional
or 4) a set of actions that span activities. The first two             components such as “look-at” or “think”.
changes are common and the second two less so. We model                   While CogTool is capable of modeling unusual interfaces,
performance on these time-shift tasks. Solving a “shift”               its strength lies in prototyping standard widgets like menus,
problem requires the user to: 1) encode the problem; 2)                and buttons. For this experiment, constructing a model of
select the event(s) to change, as one set or in subgroups              LEGACY was very straightforward because the system
depending on problem and strategy; 3) mentally compute                 utilized only standard widgets. However, we encountered
the new start time; 4) set to this time. Steps 2-4 may iterate         many challenges in modeling NEW because it used complex
for subgroups. The user may check results or refer back to             interactions not directly supported by the CogTool library.
the problem description.
                                                                                             Modeling Policy
          Modeling Environment: CogTool                                Our goal was to build a set of models that are individually
Many tools have been developed to support modeling HCI                 accurate and collectively consistent, without excessive
tasks. One example is CogTool – a general purpose user                 tailoring. Because we are trying to show adequacy of a
interface prototyping tool that generates quantitative                 limited modeling approach, demonstrating accuracy and
predictions of human performance, specifically response                consistency is difficult for two reasons. First, CogTool
times of skilled performance. This paper is not an evaluation          generates a separate model for every combination of task
of CogTool, per se, but rather CogTool’s simplified                    and strategy, thus requiring a large set of models to cover
approach to modeling behavior. We selected CogTool                     the behavior of interest. Second, the interactions in NEW
because it provided a good balance between required                    cannot be modeled with CogTool widgets in a standard way.
modeling effort and fidelity of result. It aims for simplicity         This leaves room for case-by-case variation in how to
by providing prepackaged interactive widgets (i.e. buttons,            extend or apply CogTool. Consistency and low-tailorabilty
links) and transitions (i.e. click, hover) that connect between        are important and instrumental to validity. If individual
different states. It aims for validity by deriving the behavior        models are tailored for each circumstance they are unlikely
of each component from ACT-R at the perceptual,                        to generalize, to predict as well as post-dict, or to provide a
cognitive, and motor level to predict time on task. The                valid model.
                                                                   3490

   We formulated a modeling policy to help manage                      The components for standard interactions such as button
complexity, limit tailorability, and ensure consistency. The        presses have widgets provided and can be modeled easily.
policy characterizes what situations fall within the scope of       For nonstandard interactions, modelers need to provide a
modeling and how models should be constructed scope.                fixed model component for the interaction type. Further,
                                                                    the modeler should construct models from existing
Scope of Modeling                                                   components that are as similar as possible, to maximize
Users: Identifying what skill level the model represents is         consistency.      Here are two examples of rules for
important for interpreting and applying its predictions.            components in nonstandard interactions:
CogTool models the “skilled” user. To calibrate the models,            Motor. The NEW system supports a drag-and-drop
each author performed blocks of simple tasks to generate            interaction in which the entity is dragged along a timeline
various levels of skilled performance data. Comparing this          and dropped at a specific time. Because the end location is
data to CogTool’s predictions, the appropriate skill level          very specific, this task requires fine motor control. Through
emerges where users are making few errors and are familiar          the iterative modeling of experimenter-data on simple tasks,
with the system, but tasks require deliberation and are not         we developed a rule to model this end location as a very tiny
automatic. We found that performance of our participants on         widget; this was a modification made to the standard drag-
the last block of the second day aligned with skill level           and-drop model.
appropriate for CogTool.                                               Perceptual. While most drag-and-drop interactions
   Tasks: Understanding a model’s bounds in terms of task           involve dragging an entity and dropping it at a visible target
type and task complexity is important for deciding which            area, users in NEW have no visual cue for where to drop the
tasks to model. With its library of vetted widgets and              entity. They instead rely on a separate, dynamically
storyboard of discrete states, CogTool is best at modeling          updated numeric display that indicates their progress toward
tasks using discrete “button pressing” actions, though it can       the target. The standard drag-and-drop model was again
be manipulated to represent continuous actions. The task            modified to reflect this by inserting a “look-at” [time
complexity that CogTool can model is bounded by the                 display] transition between the drag and the drop
granularity of available widgets and transitions. In selecting      components.
tasks to model, we started with simple discrete tasks and              After the components have been specified, they can be
progressed toward continuous tasks of greater complexity.           composed into sequences predicting more complicated
   Strategies: A strategy is an ordered set of actions to           behavior.      Because CogTool components cannot be
accomplish a task. Depending on the task, the set of                composed in parallel, it is important to select tasks that do
strategies could range from a few to a very large number;           not require parallel actions, or have overlapping actions that
thus, it is important to establish the scope of strategies to       can be treated as sequential. In our case, even though drag-
model. A CogTool model represents a single strategy for a           and-drop entails simultaneously moving the mouse while
single task as demonstrated by the modeler. Hence,                  watching a target, the actions for this sequence could be
CogTool can model simple tasks with little strategy                 reasonably stretched out and treated sequentially.
variation, but any larger strategy space falls beyond                  When modeling strategies for simple tasks, select
CogTool’s scope of practical usage. Recognizing CogTool’s           strategies that are as general as feasible. This has the
limitations in representing strategy for complex tasks, we          advantage that the strategy will be maximally reusable over
chose to focus on strategies we observed participants using.        task variations. We applied this policy to simplify models
Cogtool only directly predicts response time, not reasoning,        for typing in start times, by relying on an average strategy.
decision making, or strategy selection. In many cases, users
shift to efficient strategies with practice. Thus, speed of use     Process for Adhering to Policy
may be a powerful predictor of strategy choice.                     We used a structured method of incrementally extending
   Environment: Characteristics of the system influence             and testing components. We verified the functionality of
what types of interactions need to be modeled. CogTool is           standard components in standard domains; we modeled new
good at modeling interactions in discrete and stable                interactions by first testing single components in simple
interfaces.     If users can change the display during              tasks and systematically incrementing the complexity of
interaction, modeling is more difficult; particularly,              tasks, strategies, and components; we adjusted internal
continuous change in the display is difficult for CogTool to        structure as needed. When comparing user data to model
model as it depends on a demonstration on a static display          predictions, we prioritized the model’s ability to predict
to capture and predict actions. We minimized this issue for         patterns of difficulty, not absolute times, because modeling
CogTool by modeling selected items in which the display             individual differences in CogTool increases complexity and
was not likely to vary across users or change within task.          requires tailoring individual models. Adhering to our
                                                                    modeling policy was critical for ensuring the validity and
Requirements on Model-Building                                      consistency of model components and their composition.
Our policy for model construction provides rules for                Further, this makes the resulting model set and its
breaking tasks down into component elements, and for how            predictions easier to understand.
elements should be composed to model tasks and strategies.
                                                                3491

      Figure 3. Times for users of NEW and LEGACY systems                   Figure 4. Times on four item types for users of NEW
            plotted against CogTool’s predicted times.                          plotted against CogTool’s predicted times.
                      Modeling Goals                               correlation (r=0.999) between CogTool’s predicted times
Guided by the modeling policy, we constructed models at            and the experimental data in performing activity shifts and
the system level, item level, and strategy level and               action shifts across systems. This affirms CogTool’s ability
compared them to experimental data. Generating models at           to post-dict dramatic differences between two systems both
these three levels of granularity provides insight into the        on an absolute and relative scale.
practical value of modeling at different stages of the design
process, and also provides a framework through which we                      Modeling Item Type Differences
can assess the strengths and weaknesses of the proposed            To determine CogTool’s ability to predict differences item
modeling policy. Furthermore, how useful a model is                types, we compared experimental data of four item types in
depends on how well the model represents behavior. Having          NEW to their corresponding models. These four types were
access to data from participants provides a way of assessing       shifting actions, activities, actions within an activity, and
the validity of models.                                            actions across activities. We modeled NEW because it is
                                                                   both of practical interest and of greater complexity. We
             Modeling System Differences                           used data from the four fastest errorless users on NEW.
To compare the NEW and LEGACY systems, we modeled                  (One outlying data point of 108s was dropped.)
the two most common editing tasks – shifting an activity             We created CogTool models for each type of item. Each
and shifting an action. We used data from skilled and              model used the strategy of the overall fastest user for the
errorless users, the four fastest participants on each system.     entire block; these strategies were commonly shared by
(One outlying data point of 140s was dropped.) We created          other fast users. The fastest strategy for each task happened
two CogTool models for NEW and two for LEGACY,                     to be selecting the entities and editing the start times by
modeling one activity shift item and one action shift item.        typing in the details pane. In line with the modeling policy,
The model for each condition used the most common                  we maintained consistency by modeling all time edits using
strategy.                                                          the backspace key followed by typing in digits.
   The predictions generated by the models were consistent            Average user performance was still highly correlated
with the user performance on NEW and LEGACY (Figure                with the models’ prediction times by item type (r=0.945)
3). NEW users (red & orange) were much faster than                 (see Figure 4). However, the order of difficulty was
LEGACY users (blue & green) in both shifting activities            imperfectly predicted. For frequent items, CogTool
and shifting actions and CogTool correctly predicted this.         correctly predicted that action shifts (users 13s (SE=1.8);
For NEW, activity shifts were slightly faster (users 13s           CogTool 11s) would take longer than activity shifts (users
(SE=1.8); CogTool 11s) than action shifts (users 16s               16s (SE=1.5); CogTool 14s). For the less typical items,
(SE=1.5); CogTool 14s). For LEGACY, activity shifts were           CogTool’s predictions were reversed (for actions: users 38s
dramatically longer (users 83s (SE=18.7); CogTool 85s)             (SE=4.5); CogTool 40s versus for activities: users 47s
than action shifts (users 28s (SE=4.8); CogTool 29s).              (SE=4.4); CogTool 36s).
   We were interested in CogTool’s ability to post-dict              Despite the switched order for two of the item types, the
overall performance difference between systems (though we          values generated by the four CogTool models were broadly
had just four points to compare). Overall, there was a high        consistent with the experimental values for the four types of
                                                               3492

  Figure 5. Left: Predicted choices: only fastest strategies chosen.
                                                                                  Figure 6. Average user times for strategy vs predicted time
 Right: Actual strategy choices. Circle size shows number of users.
                                                                         strategies that we had (incorrectly) expected would be used.
items. This shows that CogTool can do an adequate job of
                                                                         A total of 24 models were created, varying from 4 for the
predicting item type differences, especially for items that are
                                                                         simplest task to 9 for the most complex. We also tallied the
structurally very different from each other. The order
                                                                         overall frequency with which strategies were used.
reversal for two tasks indicates possible weaknesses in
                                                                            First, we wanted to see if CogTool could predict strategy
modeling complex tasks. Two limitations of CogTool
                                                                         selection. We took the strategy times generated by each
probably contribute to the failure to correctly predict the
                                                                         CogTool model and ordered them from fastest to slowest for
relative times of these two tasks. First, these tasks are more
                                                                         each item type. Because skilled users tend to shift toward
complex. As a result, there is greater variation in strategy
                                                                         faster times and CogTool can only predict time on task, we
even among skilled users, reducing the accuracy of
                                                                         expected that if CogTool is a good predictor of strategy
modeling item difficulty with a single strategy. Second,
                                                                         choice, most people would use strategies that CogTool rates
CogTool models are purely mechanical and do not represent
                                                                         as fast. For example, all users might select the fastest 2 or 3
cognitive differences.        In this case, shifting between
                                                                         strategies, as illustrated in the left panel of Figure 5.
activities is more cognitively taxing than shifting within an
                                                                         However, our findings showed that CogTool seldom
activity because there are more parts to keep track of.
                                                                         predicted the use of strategies. For every item type, the
CogTool could be tailored, post-hoc by increasing “think”
                                                                         strategies judged fastest by the CogTool model were not the
operators as needed, but this is inconsistent with our
                                                                         ones commonly used (Figure 5, right panel). For the
predictive modeling policy.
                                                                         simplest items, the strategies that CogTool predicts are least
                                                                         efficient are the ones most chosen. For the more complex
            Modeling Strategy Differences                                items, strategy choice is highly varied with little preference
Turning to a finer granularity of modeling, we were                      for strategies CogTool predicts to be fast.
interested in CogTool’s modeling of strategy. First, we                     Second, for those strategies that were used, how well did
wanted to see if CogTool could predict strategy choice,                  CogTool predict the time to use a given strategy? For each
from a collection of identified strategies. That is, is the              strategy used by any of the 8 NEW users, we found the
strategy that CogTool predicts to be most efficient, the                 average time and correlated the average data with the time
strategy preferred by fast, practiced users?                             predicted by the model. In comparing the times of strategies
   Second, we wanted to see how well CogTool could                       produced by users to analogous times predicted by
predict the actual times for those strategies. In order to               CogTool, the correlation is modest (r=0.546), as shown by
compare the efficacy of various strategies, we used data                 the wide scatter in Figure 6. (One dot may represent
from all eight NEW participants on each of the four items                different numbers of users.) One key aspect of poor
(representing the four item types). We removed data for                  prediction is that all drag and drop strategies are lower than
responses with errors, outlying times, or other irregularity             they should be.
(such as redoing).                                                                                 Discussion
   We then built models for each of these strategies using the
Modeling Policy. Because CogTool cannot generate                         Summary of Results
strategies, we created models post-hoc based on strategies               We modeled performance on planning tasks by users
chosen by users. For each type of item, we modeled every                 working with two very different planning systems: one a
strategy used to complete the item plus a few additional                 legacy system currently in use by a Mission Control group
                                                                     3493

and one a new system designed to match the work structure.          components will compose cleanly, without interaction, is
We compared CogTool models to experimental data at the              critical. Problems with drag & drop models may have
system, item, and strategy levels. The core strength of our         stemmed from interaction with other processes in the more
approach was that by selecting CogTool and following our            complex models. While a richer modeling space can
modeling policy, it was feasible to represent and get time          evaluate positive (e.g. parallel execution) and negative (e.g.,
predictions for a varied set of problem solving situations.         competition for WM) interaction among components (Gray
   The models could predict the large performance                   2008; Smith et al, 2008), these models target simpler
differences between the very different systems, which               behaviors and hence entail greater complexity in building up
provide different interfaces, interactions, and strategies. In      to models of problem solving behavior. 4) Modeling
addition, our models also provided reasonable correlations          human-computer, or human-automation, interaction requires
with data for different item types. It predicted simple             a good model of the device. The default model of
differences between items that had clearly different                responsiveness and precision of mouse movements may
interactions (activity vs action shifts), but was not as            have been inadequate.
successful in predicting item differences for more complex
items with overlapping strategies and characteristics. With         Value of HCI Modeling
respect to strategies, CogTool was not an adequate predictor        Modeling human-computer interaction provides both
of strategy choice selection nor did it do a good job of            practical results and a test-bed for evaluating and
predicting strategy times.                                          developing modeling methods. Behavior here is constrained
                                                                    by the affordances of the interface, while still exhibiting a
Value of Validation                                                 very rich range of problem solving phenomena.
Detailed validation of a model in a complex work domain is
difficult and rare (Gray, John, & Atwood, 1993). We                                     Acknowledgements
selected a challenging work environment, which required                Research was funded by the Human Research Program,
interaction forms not previously supported in CogTool. For                Space Human Factors Engineering Project, NASA.
our model development, we vetted new components in
simple models applied to one set of tasks and users (the                                      References
authors), and applied this to a different, complex set of tasks
                                                                    Anderson, J. R. & Lebiere, C. (1998). The Atomic Components of
and users (experiment subjects). Thus, we did not tailor the
                                                                       Thought, Hillsdale, NJ: Lawrence Erlbaum Associates.
models to the data we sought to predict. We succeeded in            Billman, D., Arsintescu, L., Feary, M., Lee, J., Smith, A., &
accurately modeling behavior at a coarse but not fine level.           Tiwary, R. (In Press). Benefits of Matching Domain Structure
   Successful prediction at a fine level would, indeed, be             for Planning Software: The Right Stuff. Paper presented at the
very useful from a practical perspective. It would be                  Proceedings of the ACM CHI Conference on Human Factors in
valuable to predict accurately and in advance what strategies          Computing Systems.
are optimal, as we could then have taught these to users, to        Card, S. K., Moran, T. P., & Newell, A. (1983). The psychology of
increase the likelihood that each system was being used to             human-computer interaction. Hillsdale, N.J.: L. Erlbaum
best advantage. With fine-grained accuracy, modeling                   Associates.
                                                                    Gray, W. D. (2008). Cognitive modeling for cognitive engineering.
could also be used to adjust design; for example, there are
                                                                       In R. Sun (Ed.), The Cambridge handbook of computational
tradeoffs in design of the timeline layout between precision           psychology. New York: Cambridge University Press.
and scale; accurate models would allow exploring design             Gray, W., John, B., & Atwood, M. (1993). Project Ernestine:
alternatives to find best configurations.                              Validating a GOMS analysis for predicting and explaining real-
                                                                       world task performance. Human Computer Interaction, 8(3),
Modeling Challenges                                                    237-309.
Our modeling policy highlighted several broad modeling              John, B. E., Prevas, K., Salvucci, D. D., & Koedinger, K. (2004).
                                                                       Predictive human performance modeling made easy. In
challenges. 1) Behavior-based models (such as CogTool)
                                                                       Proceedings of the SIGCHI conference on Human factors in
have difficulty modeling working memory burden,                        computing systems (pp. 455-462). Vienna, Austria: ACM.
presumably because this is least directly controlled by the         Kieras, D. (2006). A Guide to GOMS Model Usability Evaluation
task. Our problems differed in difficulty computing target             using GOMSL and GLEAN4. Retrieved January, 2011. from
times (add an hour vs 25 min), which affected component                University of Michigan. Electrical Engineering and Computer
times and whether users included checking operations.                  Science Department FTP site: ftp://www.eecs.umich.
Limited modeling of WM restricts the ability to distinguish            edu/people/kieras/GOMS/NGOMSL_Guide. Pdf
between systems that impose different working memory                Patton. E.W. & Gray, W.D. (2010). SANLab-CM: A tool for
burdens, a critical need for software supporting problem               incorporating stochastic operations into activity network
                                                                       modeling. Behavior Research Methods, 42, 877-883.
solving. 2) Assessing when a model of a component will
                                                                    Smith, M., Lewis, R., Howes, A., Chu, A., Green, C., & Vera, A.
compose cleanly in a larger model is difficult. Though our             (2008). More than 8,192 ways to skin a cat: Modeling behavior
drag & drop models fared well on our simple test-bed tasks,            in multidimensional strategy spaces. Paper presented at the
when this component was included in larger models, these               Proceedings of the 30th Annual Conference of the Cognitive
consistently underpredicted times. 3) Identifying when                 Science Society. Austin, TX: Cognitive Science Society.
                                                                3494

