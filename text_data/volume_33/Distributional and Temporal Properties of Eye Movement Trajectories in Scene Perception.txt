UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Distributional and Temporal Properties of Eye Movement Trajectories in Scene Perception
Permalink
https://escholarship.org/uc/item/4qw2x328
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Rhodes, Theo
Kello, Christopher
Kerster, Bryan
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

              Distributional and Temporal Properties of Eye Movement Trajectories
                                                         in Scene Perception
                                               Theo Rhodes (trhodes3@ucmerced.edu)
                                            Christopher T. Kello (ckello@ucmerced.edu)
                                               Bryan Kerster (bkerster@ucmerced.edu)
          Cognitive and Information Sciences, University of California Merced, 5200 North Lake Rd., Merced, CA 95343
                              Abstract                                   Sims et al., 2008). Various land and sea creatures have been
   Eye movements gather visual information from the
                                                                         tracked while foraging for food, and the lengths of paths
   environment for various purposes and goals. Spatial patterns          from one locale to the next are measured. The probability of
   of eye movements vary depending on the layout of visual               observing path length d often goes as P(d) ~ d-β, with β ~ 2.
   information, and intentions of the observer. However, despite            The precise formulation of the distribution is often a
   this variability, basic principles of visual information              matter of dispute, but they are generally agreed to be heavy-
   gathering may be reflected in lawful properties of eye                tailed. The Lévy distribution is part of a broader class of
   movement trajectories that hold across various stimulus and           heavy-tailed distributions that indicate multiplicative
   intentional conditions. Two experiments are presented
   analyzing eye movement trajectories during scene perception           interactions in generating the observed data (i.e. path
   across pictures with varying spatial frequency distributions          lengths in this case; Shlesinger, Zaslavsky & Klafter, 1993).
   (Expt 1), and across two different task conditions, "finding"         These results are relevant to eye movements because animal
   versus "counting" tasks (Expt 2). Results show that, in all           foraging and scene perception are both search behaviors.
   conditions, distributions of saccade amplitudes are heavy-            Indeed, even memory search has been shown to result in
   tailed and nearly identical in shape, and fixation fluctuation        heavy-tailed distributions of “path lengths”, i.e. time
   series are long-range correlated with nearly identical spectral
                                                                         intervals between recall events (Rhodes & Turvey, 2007).
   slopes. While a small effect of task intention was found, the
   broader conclusion is that eye movements during scene                    These results suggest that eye movement trajectories may
   perception exhibit general statistical characteristics that           also exhibit heavy-tailed path length distributions by virtue
   models have yet to address.                                           of being a kind of search behavior. Consistent with this
                                                                         hypothesis, Stephen and Mirman (2010) found that
   Keywords: Eye movements, scene perception, lognormal
   distributions, Lévy flights, 1/f scaling, long-range correlation.     distances between successive eye tracking samples were
                                                                         lognormally distributed in a “visual world paradigm” task
                          Introduction                                   (lognormal distributions are heavy-tailed and also associated
                                                                         with multiplicative interactions). This study alone, however,
Research on visual search and scene perception tends to                  leaves it unclear whether the observed lognormal
focus on the effects of stimulus factors on eye movements.               distributions were due to characteristics of the tasks or
For instance, the debate over parallel versus serial search              stimuli, such as their constrained, repetitive nature.
hinges on stimulus characteristics of targets, distractors, and             The second body of research to suggest general properties
the visual field (Triesman & Gelade, 1980). Models of scene              of eye movement trajectories concerns temporal correlations
perception relate the saliency of visual features and objects            in neural and behavioral activity. It turns that many different
in scenes to probabilities of eye fixations (Itti, Koch &                measures of both kinds of activities have been found to
Niebur, 1998).                                                           contain long-range correlations in their intrinsic fluctuations
   By contrast, the basic character of eye movements is                  (Kello et al., 2007). These correlations tend to follow a 1/f
mostly taken for granted in research on scene perception,                scaling relation, and 1/f scaling is also a kind of heavy-
i.e. there are saccades between fixations, and microsaccades             tailed distribution associated with multiplicative interactions
and other more fine-grained movements within fixations                   (Van Orden, Holden & Turvey, 2003). Any time series can
(Liversedge & Findlay, 2000). These categories are coarse                be expressed in the frequency domain as a set of sine waves
and describe little about the structure of eye movement                  of varying amplitudes (power) and frequencies (phase is
trajectories, beyond the fact that trajectories will string              discarded for this analysis). 1/f scaling describes a time
together periods of small-scale movements (fixations)                    series for which power is related to frequency as P ~ 1/fα,
interspersed with periods of large-scale movements                       where ideally α ~ 1.
(saccades and pursuits).                                                    Widespread findings of 1/f scaling, across modalities and
   One might assume that more quantitative statements                    levels of analysis, suggest that its origins are task-general
about eye movements during scene perception will depend                  and domain-general. 1/f scaling has also been found in eye
on particularities of scenes and intentions of observers.                movements, i.e. in fluctuations of repetitive target fixations
However, two bodies of research suggest otherwise. First, a              (Shelhamer, 2005), and in variations within and across
large body of research on foraging behaviors has shown that              standard visual search tasks (Aks, Zelinsky & Sprott, 2002).
search trajectories are nearly universally characterized by              However, as with heavy-tailed path lengths, these results on
heavy-tailed distributions of path segment lengths (e.g.,
                                                                     178

1/f scaling in eye movements may also be particular to the            10. The other task was a scene memory task whereby
repetitive, constrained nature of the tasks.                          participants were given 60 seconds to verbally describe each
                                                                      of six images after each one was presented (because image
            Scene Perception Experiments                              order was randomized, the memory task appeared randomly
   The aim of our study was to investigate whether heavy-             to participants). Each subject viewed all 30 images.
tailed distributions and long-range correlations are general
facts about the statistical structure of eye movement
trajectories. If so, then any theory or model of eye
movements would need to explain how this structure is
shaped to fit specific tasks and stimuli, while preserving its
general character across conditions.
   We chose to use scene perception as a general kind of
visual information gathering that goes beyond previously
used tasks. Most importantly, scene perception can unfold
over relatively long periods of time without experimental
intervention, and it embodies the kind of information
gathering that visual systems are constantly engaged in.
   We manipulated stimulus (Expt 1) and task (Expt 2)
conditions in order to test whether findings are restricted to
any particular conditions. Our basic dependent measure was
Euclidean distances between adjacent pairs of eye tracking
samples, which yields series of eye speed measurements.               Figure 1: Example visual search trajectory for an image of a
Speed series are appropriate for investigating general                             spiral staircase inside ancient ruins.
properties of eye movements because absolute position
information is not preserved.
Experiment 1 Methods
Stimuli. Two hundred and fifty images were selected from a
collection of National Geographic's Photo of the Day
website. All images were originally 1600x1200 pixels in
resolution, cropped to 1600x1100 to remove a watermark.
Images were all natural scenes, color and spanned a wide
range of content, including landscapes, action shots, close
ups of animals and people.
   To test whether the statistics of trajectories are affected by
stimulus factors, we categorized them according to their
spatial frequency distributions. Spectral analyses of spatial
frequencies in natural images have been shown to exhibit 1/f
scaling analogous to that in time series (Field, 1987). If
heavy tails in eye movement trajectories come from visually
searching over scenes with heavy-tailed spatial frequency               Figure 2: Example partial ISD time series (A) and saccade
distributions, then varying the latter should affect the                   amplitude series (B). The dashed line in A indicates
former. Ten images were chosen within each of three                        threshold, and B shows the lengths above threshold.
categories: Steep (α < -3), mid-range (-3 < α < -2.25) and
shallow (α > -2.25) scaling relations.                                Experiment 1 Results
   Subjects, Apparatus, and Task. Eleven University of                From the raw gaze position series (Figure 1), inter-sample
California Merced undergraduates participated in the                  distances (ISDs) were computed (Figure 2) and blinks and
experiment for course credit. Each participant was seated             measurement malfunctions were removed. As one would
approximately 36" in front of a 30" flat panel LCD monitor.           expect given the well known fixation and saccade structure
Participants viewed each of the thirty images in random               of human gaze trajectories (Henderson, 2003), ISD series
order for 45 seconds per image. Monocular gaze position               were characterized by clusters of low values (fixations)
was recorded at 500 Hz using an Eye Link II head mounted              interspersed with “bursts” of high values (saccades). Based
eye tracker (Figure 1).                                               on visual inspection, a threshold of 1.5 pixels was used to
   Subjects were instructed to view each image in the                 separate saccade speed “bursts” from fixation fluctuations
context of two tasks. One was a rating task whereby                   (increasing this threshold by a few pixels had no qualitative
participants were asked after each image to characterize the          effect on results). Each saccade length (i.e. amplitude) was
complexity and memorability of the image on a scale of 1 to
                                                                  179

                                                                   distributions. Thus there was absolutely no support for the
                                                                   exponential distribution without a heavy tail.
   Figure 3: Example below-threshold fixation time series.
measured as the distance from the first point over threshold
to the next point below threshold (Figure 2), and ISDs
below threshold were concatenated to yield fixation
fluctuations.
   Saccade amplitudes correspond to the path lengths of a
Lévy flight, so their distributions were examined. Fixation
ISDs corresponded to intrinsic fluctuations in speed (with
saccades removed), in that no experimental manipulations
were applied within trial series, i.e. for each given picture
(note that speed may be affected by the location of gaze on a        Figure 4: Aggregate saccade amplitude distributions from
given scene, but the experimenter does not directly                                        Experiment 1.
influence where to gaze). Thus their temporal correlations
were examined.                                                        Spectral analyses of fixation amplitude series resulted in
   Figure 4 shows saccade amplitude distributions in log-log       evidence for long-range correlations. Averaged spectra for
coordinates for steep, mid-range, and shallow stimulus             each condition are shown in Figure 5 in log-log coordinates.
conditions, aggregated over all trials and subjects. Multi-        1/f scaling appears as a negative linear relation in log-log
model inferdence (Burnham & Anderson, 2002;                        spectra, with a slope significantly less than zero. The figure
Wagenmakers & Farrell, 2004) was used to determine the             shows a 1/f scaling relation in the lower frequencies (where
statistical model most likely to generate these distributions.     most variation resides, despite appearances due to the
Four candidate statistical models were tested: exponential,        logarithmic scales), but it is difficult to distinguish long-
lognormal, gamma and Pareto distributions. Lognormal,              range from short-range correlation by visual inspection
gamma and Pareto distributions are heavy-tailed,                   (Wagenmakers, Farrell & Ratcliff, 2004).
suggestive of a complex, multiplicative process. The                  To distinguish between short-range and long-range
lognormal distribution is one of the simplest multiplicative       correlation, we applied a maximum likelihood method
distributions, the Pareto distribution represents an idealized     developed by Thornton and Gilden (2005; Torre &
power-law function, and the gamma distribution is a hybrid         Wagenmakers, 2009).
of power-law and exponential distributions, indicating a
truncated power-law. The lognormal distribution has all
power moments defined while the Pareto and gamma
distributions do not. For each candidate, the negative log-
likelihood (the function maximized in maximum likelihood
estimation) was calculated. Log-likelihoods were then used
to calculate Akaike's information criterion, which is a
measure of the information-theoretic distance between
candidate distributions and the distribution of the data. The
minimum AIC value indicates the most likely candidate
distribution given the data.
   AIC strongly supported the lognormal distribution for all
three condition aggregates. Aggregates were also created for
each image and each subject, and lognormal was supported
for 100% of the former, and 100% of the latter. Using
maximum likelihood estimation, we calculated the
parameters corresponding to the best fit lognormal
distribution. There were no significant effects of condition,       Figure 5: Averaged spectra for fixation fluctuation series in
image or their interaction (mean σ = 1.25). AIC analysis of               Experiment 1 (dark line is α = 1 reference point).
individual trials predominantly supported lognormal (60%)
with some support for gamma (38%) and pareto (2%)
                                                               180

The method differentiates between two qualitatively                 “find” task, participants searched for a small star embedded
different models of time series data. One is a 1/f scaling          in the image. In a “count” task, participants searched for all
model, which they expressed in terms of fractional                  objects of a given kind in order to count them.
Brownian motion plus white noise (fBmW). The other
model is short-range correlation model, which they express
as an autoregressive moving-average (ARMA), also with a
white noise term. Both models are thus specified by two
parameters, removing potential bias towards a model with
more free parameters. Given a predefined parameter space,
the maximum likelihood method chooses the model and pair
of parameter values most likely to generate fluctuations with
the spectral characteristics of an observed fluctuation series.
   A spectrum was computed for each of the individual peak
angle series, and averaged to form equivalent aggregates for
each condition, each image, and each subject. In all cases,
fBmW was supported over the ARMA model. The α
parameter estimates were also compared across conditions,
images, and subjects. There was no significant effect of
condition (mean α = 0.60, F(2,327) = 0.48).
Experiment 1 Discussion
These results provide broader evidence that heavy-tailed
distributions and long-range correlations are general
properties of eye movement trajectories. Previous studies
found heavy-tailed distributions for restricted sets of
artificial stimuli, under highly constrained task conditions,
and also long-range correlations in times to repeatedly
saccade between pairs of targets (Shelhamer, 2005).
Experiment 1 expanded upon these results using a wider
range of natural stimuli, a more natural scene perception
task, and a novel but simple threshold method for dividing
series of eye movement speeds into saccade amplitudes and
fixation fluctuations (above and below threshold).
   The AIC analysis of individual trials shows majority
support either for lognormal or gamma distributions. The
gamma distribution is sometimes characterized as a                   Figure 6: Example visual search trajectory for the find task
truncated power law, as it is essentially a power law                     (top) and counting items task (e.g. sheep; bottom).
distribution that tapers into an exponential distribution.
Lognormal distributions are also common in situations               Experiment 2 Methods
where heavy-tailed behavior is bounded, either in time or           Stimuli. Images were selected from the same collection as
magnitude. Given that eye-tracking is sharply bounded by            Experiment 1 with the additional criteria that they contain a
the dimensions of the screen, support for lognormal and             set of 40-100 enumerable objects. Example sets include
gamma may be convergent support for a truncated power               sheep, spots on a giraffe, and leaves floating in a lake. A
law (a task for future research).                                   total of 30 such images were selected. A second version of
   While heavy-tailed distributions and 1/f scaling held            each image was created by embedding a small, transparent
across images and participants, the task in Experiment 1 was        and textured star at a difficult-to-find location in the image.
homogeneous across trials. The effects of intention on scene        A group of volunteers provided feedback to calibrate the
perception are well-known and were first documented by              difficulty of locating stars, and star locations and
Yarbus (1967), who showed that trajectories over the same           transparencies were adjusted such that stars could be found
image were noticeably different depending on viewing                with 60 seconds approximately 50% of the time.
instructions. Yarbus' work was limited in scope, but more              Subjects, Apparatus, and Task. Sixteen University of
recent replications have lent some quantitative support to his      California Merced undergraduates participated in the
results (DeAngelus & Pelz, 2009). Thus different intentions         experiment for course credit. Participants were carefully
may result in different distributions and temporal properties.      screened for potential issues that might affect sampling rate,
   Experiment 2 was designed to test this possibility. We           such as eyeglasses or cosmetics. Each participant was seated
created two scene perception search tasks with the goal of          approximately 36" in front of a 30" flat panel LCD monitor.
generating highly distinct eye movement trajectories. In a          Participants viewed one set of 15 images in random order,
                                                                181

and were asked to either find the star, or count the instances     information of eye movement trajectories is distinct (a topic
of a given object. They then performed the other task on the       for future research), but eye movement speeds do not carry
other 15 images, also presented in random order. Task and          positional information and may thus exhibit the same
set order were counterbalanced, with four participants in          general properties found in Experiment 1.
each of the four possible combinations. Participants were             Saccade amplitudes and fixation fluctuations were
given 45 seconds for each image, and in the case of the find       constructed as in Experiment 1, and both series exhibited
task, were instructed to fixate and press a key should they        the same properties as in Experiment 1. Support for
locate the star before time was up. Monocular gaze position        lognormally distributed saccade amplitudes was strong at
was recorded at 500 Hz using an Eye Link II head mounted           both the aggregate and individual trial levels (Figure 7). In
eye tracker.                                                       particular, lognormal was supported for 86% of the find
                                                                   trials, 94% of the count trials, 100% of the participant
                                                                   aggregates, and 100% of the image aggregates, with the
                                                                   remaining trials in both cases showing support for a gamma
                                                                   distribution. Estimates of the lognormal shape parameter
                                                                   were slightly but reliably lower for the find task trials (mean
                                                                   σ = 1.25) compared with the count task trials (mean σ =
                                                                   1.26, p < 0.001).
                                                                      Also as in Experiment 1, spectral analysis was applied to
                                                                   each series of fixation ISDs from each trial. Spectra were
                                                                   averaged for find trials versus count trials (Figure 8), and
                                                                   the Thornton and Gilden (2005) method was used to test for
                                                                   long-range correlations (versus short-range or no
                                                                   correlations). We found strong evidence for the fBmW
                                                                   model in aggregate spectra for each condition, image, and
                                                                   subject. In all cases, fBmW was supported over the ARMA
                                                                   model. There were no significant differences in the long-
                                                                   range correlation parameter estimates (α = 0.80) between
  Figure 7: Aggregate saccade amplitude distributions from         task conditions.
                         Experiment 2.
                                                                   Experiment 2 Discussion
                                                                   The results of Experiment 2 were as unequivocal as
                                                                   Experiment 1: the properties of heavy-tailed distributions
                                                                   and long-range correlations remained, despite visible
                                                                   differences in the spatial layouts of eye movement
                                                                   trajectories. Task condition had a small but reliable effect on
                                                                   lognormal parameter estimates for saccade amplitude
                                                                   distributions, which indicates that task intentions can alter
                                                                   series of eye movement speeds, at least by slight quantities.
                                                                   There were also differences in lognormal and 1/f parameter
                                                                   estimates across experiments that appear to be at least partly
                                                                   due to methodological differences. The fact that results were
                                                                   otherwise so uniform across experiments provides further
                                                                   evidence for their generality.
                                                                                           Conclusions
                                                                      The finding that eye movement speeds during scene
 Figure 8: Averaged spectra for fixation fluctuation series in     perception have a common statistical structure may not
      Experiment 2 (dark line is α = 1 reference point).           seem very interesting at first, at least not to a cognitive
                                                                   scientist. All humans have oculomotor apparatus and control
Experiment 2 Results                                               systems, so one might expect these similarities to result in
The different task conditions had the desired effect of            common statistics of measures like speed that do not carry
evoking clearly distinct spatial patterns of eye fixations.        positional information. The present results, however, go
Figure 6 shows example trajectories for the find task (upper)      well beyond typical measures of central tendency and
versus the count task (lower). Based on visual inspection,         variance. Series of eye movement speeds were found to
the large majority of find trials were similarly distinct from     contain two different general properties in their saccade
the large majority of count trials. This means that positional     amplitudes versus fixation fluctuations. Both of these
                                                                   properties are power laws, at least within a given range of
                                                               182

scales. And both have been found in other studies of eye           Field, D. J. (1987). Relations between the statistics of
movements, as well as other studies of neural and                     natural images and the response profiles of cortical cells.
behavioral activities of many different kinds. Thus heavy-            Journal of the Optical Society A., 4, 2379–2394.
tailed distributions and long-range correlations appear to be      Henderson, J. M. (2003). Human gaze control during real-
common to eye movement trajectories.                                  world scene perception. Trends in Cognitive Sciences, 7,
   The implications of these results are yet to be explored.          498-504.
One might be able to formulate theories of search behaviors        Hills, T. T. (2006). Animal foraging and the evolution of
that provide a common basis for understanding searches                goal-directed cognition. Cognitive Science, 30, 3-41.
through habitats, visual fields, information networks (e.g.        Itti, L., Koch, C. & Niebur, E. (1998). A model of saliency-
world-wide web), and long-term memory (Hills, 2006). For              based visual attention for rapid scene analysis. IEEE
instance, current directions in foraging research include             Transactions on Pattern Analysis and Machine
complex diffusion and state-space models based on the                 Intelligence, 20, 1254-1259.
boundary conditions and constraints specific to search             Kello, C. T., Beltz, B., Holden, J. G. & Van Orden, G. C.
environments (Patterson et al., 2008). Similar models may             (2007). The emergent coordination of cognitive function.
prove fruitful in understanding visual search, especially             Journal of Experimental Psychology: General, 136, 551-
based on models of the environment such as saliency maps.             568.
   It is important to note that the above mentioned search         Liversedge, S. P. & Findlay, J. M. (2000). Saccadic eye
models are typically aimed at explaining path lengths                 movements and cognition. Trends in Cognitive Sciences,
(saccade amplitudes) as opposed to fixation fluctuations.             4, 6-14.
With regard to the latter, long-range correlations spanned         Patterson, T. A., Thomas, L., Wilcox, C., Ovaskainen, O., &
the many dozens of fixations (interspersed by saccades) that          Matthiopoulos, J. (2008). State–space models of
occur in 45 seconds of scene viewing. This finding is in the          individual animal movement. Trends in Ecology and
purview of scene perception models because its time scale             Evolution, 23, 87-94.
goes well beyond “low-level” mechanisms like image                 Rhodes, T. & Turvey, M. T. T. (2007). Human memory
stabilization, at least as they are currently formulated. Thus        retrieval as Lévy foraging. Physica A, 385, 255-260.
it will be a challenge to formalize models that guide eye          Shelhamer, M. (2005). Sequences of predictive saccades are
movements over varied scenes for varied purposes of                   correlated over a span of ~2s and produce a fractal time
information foraging, while also generating long-range                series. Journal of Neurophysiology, 93, 2002-2011.
correlations in the fluctuations of eye movement speeds.           Shlesinger, M. F., Zaslavsky, G. M. & Klafter, J. (1993).
   With regard to empirical directions, further statistical           Strange kinetics. Nature, 363, 31-37.
commonalities may be found in the spatial distributions of         Sims, D. W., Southall, E. J., Humphries, N. E., Hays, G. C.,
eye fixations that are more typically the focus of scene              Bradshaw, C. J. A., Pitchford, J. W., et al. (2008). Scaling
perception models (Henderson, 2003), and appear to be                 laws of marine predator search behavior. Nature, 451,
more greatly affected by stimulus and task factors.                   1098–1102.
Whatever the case, it will be informative to investigate how       Stephen, D. & Mirman, D. (2010). Interactions dominate the
models and theories of scene perception might address the             dynamics of visual cognition. Cognition, 115, 154-165.
present results.                                                   Thornton, T. L., & Gilden, D. L. (2005). Provenance of
                                                                      correlations in psychological data. Psychonomic Bulletin
                     Acknowledgments                                  & Review, 12, 409-441.
The authors would like to thank Michael Spivey and Teenie          Torre, K. & Wagenmakers, E-J. (2009). Theories and
Matlock for their helpful contributions. The work was                 models of 1/fβ noise in human movement science. Human
funded by NSF grants 08-42784 and 10-31903.                           Movement Science, 28, 297-318.
                                                                   Treisman, A. M., & Gelade, G. (1980). A feature-integration
                                                                      theory of attention. Cognitive Psychology, 12, 97–136.
                          References                               Van Orden, G. C., Holden, J. G., & Turvey, M. T. (2003).
Aks, D. J., Zelinsky, G., & Sprott, J. C. (2002). Memory              Self-organization of cognitive performance. Journal of
   across eye- movements: 1/f dynamic in visual search.               Experimental Psychology: General, 132, 331–350.
   Journal of Nonlinear Dynamics & the Life Sciences, 6, 1–        Wagenmakers, E.-J., & Farrell, S. (2004). AIC model
   25.                                                                selection using Akaike weights. Psychonomic Bulletin &
Burnham, K. P., & Anderson, D. R. (2002). Model                       Review, 11, 192-196.
   selection, and multimodel inference: A practical                Wagenmakers, E.-J., Farrell, S., & Ratcliff, R. (2004).
   information-theoretic approach. New York: Springer.                Estimation and interpretation of 1/f noise in human
Castelhano, M. S., Mack, M. L. & Henderson, J. M. (2009).             cognition. Psychonomic Bulletin & Review, 11, 579–615.
   Viewing task influences eye movement control during             Yarbus, A. L. (1967). Eye movements and vision (B. Haigh,
   active scene perception. Journal of Vision, 9, 1-15.               Trans.). New York: Plenum Press.
DeAngelus, M. & Pelz, J. B. (2009). Top-down control of
   eye movements: Yarbus revisited. Visual Cognition, 17,
   790-811.
                                                               183

