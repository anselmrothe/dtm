UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Multimodal Investigation of Recognition Performance for Target-Aligned but Irrelevant
Stimuli
Permalink
https://escholarship.org/uc/item/4ws7s3tz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Dewald, Andrew
Sinnett, Scott
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

     A Multimodal Investigation of Recognition Performance for Target-Aligned but
                                                        Irrelevant Stimuli
                                            Andrew D. Dewald (adewald@hawaii.edu)
                                   Department of Psychology, University of Hawaii at Manoa
                                                2530 Dole Street, Honolulu, HI 96822
                                                 Scott Sinnett (ssinnett@hawaii.edu)
                                   Department of Psychology, University of Hawaii at Manoa
                                                2530 Dole Street, Honolulu, HI 96822
                               Abstract                                 phenomenon termed the attentional blink (AB; see Shapiro,
                                                                        1992). However, when targets were presented across
   Overtly presented, but ignored visual and auditory stimuli           sensory modalities (that is, when first identifying a visual
   presented within the same sensory modality are inhibited in a        target and then an auditory target, or vice versa), typical AB
   later recognition task if previously presented synchronously
                                                                        effects were not observed. That is, participants were able to
   with an attended visual target (Tsushima, Sasaki & Watanabe,
   2006; Tsushima, Seitz & Watanabe, 2008; Dewald, Doumas               detect an auditory or visual target even when it was
   & Sinnett, 2010; Dewald & Sinnett, 2011). We extend these            immediately preceded by a target occurring in the other
   findings to conditions in which task irrelevant stimuli (written     modality (i.e., visually or auditorily respectively), whereas
   or spoken words) were presented in a separate sensory                they were unable to do so under unimodal presentations.
   modality than task-relevant targets (picture or sound                This finding suggests that attentional costs are reduced if a
   repetitions). A subsequent recognition task was given for the        difficult task is divided across sensory modalities.
   previously presented irrelevant stimuli (words). Words that              Further investigating this issue, Sinnett et al. (2006)
   had been simultaneously presented with a target in the               explored a multiple resource view of attention by means of
   previous repetition detection task were later recognized at
                                                                        an inattentional blindness (IB) paradigm. IB is a well-
   chance levels, demonstrating a bolstered recognition of task-
   irrelevant items (e.g. target-aligned words) when compared           studied phenomenon in attention research that illustrates a
   with performance under unimodal presentation.                        situation in which an individual fails to detect an explicitly
                                                                        presented event due to attention being directed elsewhere
   Key words: Attention, Multimodal Presentation, Recognition           (Mack & Rock, 1998; Simons & Chabris, 1999). The
                                                                        overwhelming conclusion of IB research is that if attention
                           Introduction                                 is deployed to a difficult or demanding primary task,
It has been demonstrated throughout cognitive psychology’s              information not relevant to the primary task goes
history that attention is a limited resource (Broadbent, 1954;          unprocessed, at least not to levels of explicit awareness. A
Cherry, 1953; James, 1890; Mack & Rock, 1998; Rees,                     curious finding by Sinnett et al. (2006), however, was that
Russell, Frith, & Driver, 1999; Sinnett, Costa & Soto-                  when irrelevant information was presented in a sensory
Faraco, 2006; Triesman, 1960). Interestingly, the capacity of           modality separate from the target information, levels of IB
the attentional system seems to be modulated if a difficult             was reduced for irrelevant items (i.e., performance
unisensory task is divided across multiple sensory                      improved when compared to unimodal presentations).
modalities (i.e., a multiple resources theory, see Wickens,                 Sinnett et al. (2006) utilized an IB paradigm (see also
1984). For instance, Sinnett et al. (2006) showed that under            Rees et al., 1999) incorporating multisensory presentations
multimodal presentations, inattentional blindness for words             in which participants detected immediate repetitions in a
was ameliorated (i.e., perception improved) when compared               stream of rapid serially presented items in either visual,
with unimodal conditions, regardless of the modality of                 auditory, or bimodal conditions. In the unimodal conditions
word presentation (see also Toro, Soto-Faraco, & Sinnett,               (visual only or auditory only streams) the primary task was
2005 for a similar example involving statistical learning).             to monitor either pictures (or sounds) presented
These findings seem to provide support for an attentional               simultaneously with written words (or spoken, respectively)
system that is segregated, such that each sensory modality              and detect immediate repetitions in either the word or the
has access to individualized attentional resources (see                 distractor stream. Immediately following this task, a
Wickens, 1984).                                                         surprise word recognition test was administered for
    Providing support for a multiple resource view, Duncan,             unattended words (after having attended to pictures or
Martens, and Ward, (1997) demonstrated that participants                sounds). In the crossmodal condition words were presented
had difficulty identifying target items presented 300 ms or             either visually or auditorily, with a distracting stream of
less after previous targets under unimodal presentations                either overlaid/superimposed sounds or pictures in the
(auditorily or visually), due to the well-documented                    opposite modality. Unimodal performance (both auditory
                                                                    1164

and visual) yielded high and comparable levels of IB.               inattentional blindness to include an additional analysis for
However, when attention was divided across modalities               items that had appeared simultaneously with targets in the
(that is, attending to visual pictures while ignoring spoken        separate task. When doing so, an inhibition for visually
words, or attending to sounds while ignoring written words),        presented words (explicitly presented) was observed. In an
participants performed significantly better in subsequent           ensuing investigation, the same IB paradigm was adapted to
word recognition tests for the unattended words. Thus,              auditory presentations in which spoken words were overtly
despite the accepted notion that attentional capacity is            presented at the same time as common everyday sounds,
limited, recognition performance for irrelevant stimuli can         with the primary task to detect target repetitions in the
often be improved as long as it had been presented in a             sound stream, and the secondary task to later recognize the
separate sensory modality (e.g., Duncan et al., 1997; Sinnett       previously ignored words (Dewald & Sinnett, submitted).
et al., 2006; Wickens, 1984).                                       Again, the findings demonstrated that akin to visually
    Although a plethora of scientific evidence suggests that        presented words, word recognition was inhibited for spoken
stimuli that receive attention are more efficiently processed       words that had previously been temporally aligned with
than stimuli that go unattended (Ahissar & Hochstein, 1993;         sound repetitions.
Mack & Rock, 1998; Sinnett et al, 2006; Spence & Squire,               In the present investigation, we extend these unimodal
2003) a number of investigations have demonstrated that             examples of inhibited performance for task irrelevant but
unattended information can nevertheless be processed and            target-aligned stimuli to multimodal presentations. As
affect behavior. However, the findings from these                   increased performance has been observed for such
investigations fail to yield a clear picture as to the degree to    presentations (see Duncan et al., 1997; Sinnett et al., 2006),
which unattended stimuli can influence behavioral                   we would expect that previously documented inhibition
processing. That is, the nature of these effects has ranged         might disappear, or perhaps even lead to enhanced
from facilitation to inhibition depending on whether the            recognition performance for task-irrelevant words, as long
unattended stimuli were presented above or below                    as they had previously been presented with a target
threshold. Moreover, a critical relationship between whether        repetition. To address this, we presented participants with
or not the irrelevant stimuli occur synchronously with a            multisensory visual and auditory streams (adapted from
relevant target has been recently uncovered.                        those used in the unimodal conditions in Dewald et al., 2010
    Watanabe, Náñez, and Sasaki (2001, see also Seitz &             and Dewald & Sinnett, 2011). Here, one of the streams
Watanabe, 2003; 2005) demonstrated significant perceptual           included spoken words with distracting pictures, and the
learning enhancements in the absence of focused attention           other had written words with distracting sounds. The task
for stimuli that were presented below the threshold from            was to respond to repetitions in the target stream (i.e.,
visual awareness (i.e. implicitly presented). However, when         sounds or pictures) and then to subsequently recognize as
using explicit stimuli, Tsushima and colleagues (Tsushima,          many words that had been previously presented (i.e.,
Sasaki & Watanabe, 2006; Tsushima, Seitz & Watanabe,                ignored) in the repetition detection task.
2008) demonstrated a later inhibition. Accordingly,
behavioral facilitation or inhibition appears to be partly                                     Method
dependent on whether or not stimulus presentation is sub- or
superthreshold. Critically, the facilitatory and inhibitory         Participants. Sixty participants (n=60) were recruited from
effects in both of these examples appear to be contingent on        the University of Hawai’i at Manoa in exchange for course
the temporal relationship between the irrelevant stimulus           credit. A total of 30 participants were used for each
and an attended target in a separate task. That is,                 condition (visual words and sounds or auditory words and
performance changes for irrelevant stimuli were observed            pictures). Participants were naïve to the experiment and had
only when temporally aligned with relevant stimuli (i.e.,           normal or corrected to normal vision and hearing. Written
task targets). For instance, Tsushima and colleagues                informed consent was obtained before participation in the
(Tsushima et al., 2006, 2008) demonstrated that the                 experiment occurred.
detection of ignored, but explicitly presented coherent
motion displays, is inhibited when the motion display is            Materials. The multimodal streams were concatenated using
temporally aligned with the presence of an attended task-           the same stimuli as used in the visual (Dewald et al., 2010)
relevant target in a simultaneously presented task. The same        and auditory (Dewald & Sinnett, 2011) experiments that
inhibition was not observed for non-aligned presentations,          previously showed inhibitory results. A total of 150 one to
and was further supported by functional magnetic resonance          two syllable, high-frequency English words (average length
imaging (fMRI) data showing an inhibition in brain activity         of 5 letters) were selected from the MRC psycholinguistic
in brain areas associated with processing motion direction          database (Wilson, 1988). The overall average frequency of
(Tsushima et al., 2006).                                            the 150 selected words was 120 per million, ranging
    We have recently published behavioral data also showing         between 28 and 686. The words were presented either
an inhibition for temporally aligned, but irrelevant stimuli        visually (Arial font at a size of 24 points) or auditorily. For
(Dewald et al., 2010). In this example we modified the              the auditory presentation, a native English speaker’s voice
paradigm utilized by Sinnett et al (2006) investigating             was recorded reading the list of selected words three times,
                                                                1165

after which three blind listeners chose the best exemplar of      surprise recognition test were words that had either been
each spoken word. In the event that the three exemplars of a      temporally aligned with the task-relevant target, (i.e., target-
specific word were chosen by the listener, a fourth listener      aligned), or had not been temporally aligned with the task-
was asked to decide which one was best. The selected              relevant target (i.e., non-aligned) in the previous repetition
recordings were edited using sound editing software so as to      detection task. The surprise word recognition tasks were
all contain the same length of presentation length (350 ms)       randomly presented by DMDX software, one at a time,
and average amplitude.                                            written in bold, capitalized letters in Arial font at a size of
    A total of 100 pictures were selected from the Snodgrass      24 points (see also Dewald et al., 2010; Dewald & Sinnett,
and Vanderwart (1980) picture database. The pictures (on          2011; Sinnett et al., 2006 for a similar design). An
average 5 to 10 cm’s) were randomly rotated +/-30 degrees         analogous version of the experiment was created where the
from upright so as to ensure task difficulty (see also Rees et    repeated targets were words rather than sounds. All word
al., 1999). A database of 100 familiar sounds were edited to      repetitions followed this design. Care was taken to ensure
350 ms and for average amplitude and served as the                that sound-word combinations did not have any semantic
auditory analog of the visual pictures in the visual stream.      relationship.
    The exact same stimuli and design to create streams were      Power analysis. An a priori power analysis indicated that a
used here as in Dewald et al. (2010, for visual stimuli) and      minimum of 10 subjects in each condition would yield a
Dewald & Sinnett (2011, for auditory stimuli). The 100            95% confidence for detecting a medium sized effect when
sounds/pictures were randomly separated into two equal            employing the traditional .05 criterion of statistical
groups, while the 150 words (both visual and auditory) were       significance. As we predict a possible amelioration of the
randomly divided into three equal groups (similar average         inhibition witnessed in Dewald et al (2010) and Dewald &
frequency). In each group of sounds/pictures, half (25) were      Sinnett (2011), it is important that there is sufficient power.
pre-selected and duplicated. These repeated sounds/pictures
acted as targets as each pair occurred in the auditory/visual                              Procedure
presentation as an immediate repetition. The remaining 25
sounds/pictures were also duplicated, but their positioning
in the stream never allowed for an immediate repetition.          Participants were randomly assigned and completed only
One hundred of the 150 words were overlaid/superimposed           one of the repetition detection tasks. That is, half of the
on each of the sounds/pictures, creating a block size of 100      participants were given the stream of visual words and
sound-word/picture-word items. Across two blocks of               auditory sounds, while the other half were given the stream
presentation, half of these words (i.e., 50) were target-         of visual pictures and auditory words. Importantly,
aligned with a sound/picture repetition while the other half      superimposed/overlaid irrelevant stimuli (visual or auditory
were non-aligned. Each block of 100 items was created in          words), were presented in a different sensory modality from
which the 25 sounds/pictures not immediately repeated in          the targets in the repetition detection task. The primary task
the first block now served as the sounds/pictures that were       of detecting immediate repetitions in either the sound or
immediately repeated, with the same 100 randomized words          picture stream was presented as follows, respectively: a
superimposed as in the first block (note, an                      visual–auditory condition with a visual word stream and an
overlaid/superimposed word was never repeated within a            auditory sound stream; and an auditory-visual condition
block). Therefore, across both blocks in each experiment,         with spoken words and visual pictures. Participants were
each sound/picture was played/displayed a total of four           required to detect immediate repetitions in either the sound
times (once as a repeat and then two other times as non-          (or picture) or the word stream.
repeats in the complementary block). The words were                  Participants were randomly assigned to either condition,
presented a total of two times throughout the experiment,         and then again randomly assigned to one of two attention
once in each block respectively.                                  conditions. One group was required to attend and respond to
    The same principle was used when making streams of            repetitions in the sound/picture stream (i.e., ignore the
items when the words (both written and spoken) were               words), while the other group was required to respond to
repeated (attending to words condition). As there were 150        immediate repetitions in the spoken/written word stream and
words and 100 sounds/pictures six different versions of the       ignore the sounds/pictures. Participants responded to
sound-word superimposed stimuli were created for use in           repetitions by pressing the ‘G’ key on the keyboard.
the attending to sounds condition as well as the attending to        Each item in the sound/picture-word presentation was
words condition.                                                  presented for 350 ms with a 150 ms inter-stimulus interval
    Participants were administered a surprise recognition test    (ISI; silence/blank screen) between each item for a stimulus
immediately following the repetition detection task. This         onset asynchrony (SOA) of 500 ms. A repeatable training
task consisted of 100 words from both the previously              block of eight trials was given before the experiment started.
heard/viewed stream (50) as well as never heard or seen           Immediately after the repetition detection task the surprise
before foil words (50). These words were used in a different      word recognition test was administered. Participants were
version of the experiment (fully randomized). The 50 non-         instructed to press the “V” key if they recognized the word
foil words (i.e., words that had been presented) in the           from the repetition detection task or instead the “B” key if
                                                                  they did not see/hear the word before.
                                                              1166

                           Results
Target detection accuracy in the primary task.
An analysis of the overall accuracy (for both experiments
and across all conditions) of the primary task of immediate
target repetition detection revealed that participants were
accurate at detecting target repetitions in the primary task,
(78% hit rate vs. 22% miss rate, t(59)= 21.09, p<.001).
Visual words and auditory sounds
Overall visual surprise recognition performance. The
results of the surprise recognition test were compared
between conditions (attending sounds vs. attending written
words), and also against chance levels. Overall recognition
performance was significantly better after attending to the       Figure 1. Recognition percentages for Target-Aligned (black bars)
written words when compared with after attending to the                and Non-Aligned (grey bars) words in the surprise word
                                                                   recognition test after attending to either the visual word stream
sounds (63.1% SE=2.57 vs. 53.7%, SE=1.40, t(29)=2.25,
                                                                                   (left) or the sound stream (right).
p<0.05). Additionally, recognition performance after
attending to the words was significantly better than chance
(t(29)=5.08 , p<0.001) while performance after attending to
                                                                 Visual pictures and auditory words
the picture stream was not (t(29)=1.14, p= 0.26).                Overall visual surprise recognition performance. The
                                                                 results of the surprise recognition test were analyzed in the
Target-aligned and non-aligned words. When attending to          same manner as above. Overall recognition performance
written words in the repetition task (rather than sounds),       was significantly better after attending to the spoken words
subsequent recognition for target-aligned as well as non-        when compared with after attending to the pictures (68.4%,
aligned words were both significantly better than chance         SE=2.08 vs. 52.6%, SE=3.47, t(29)=-4.97, p<0.01).
                                                                 Additionally, recognition performance after attending to the
performance (target-aligned: 66.0%, SE=2.68, t(14)= 5.97,
p<.001; non-aligned: 61.3%, SE=4.45, t(14)= 2.55, p<.005).       spoken words was significantly better than chance
Despite the 4.7% trend in the data for improved                  (t(29)=8.85, p<0.001) while performance after attending to
                                                                 the picture stream failed to be significantly better than
performance with target-aligned words, there was no
significant difference between target-aligned and non-           chance (t(29)=.754 p= 0.457).
aligned word recognition (t(14)= .804, p=.44; see Figure 1).
                                                                 Target-aligned and non-aligned words. When attending to
    Most importantly, the analysis of recognition
performance after attending to the sound stream confirmed        spoken words in the repetition task, ensuing recognition for
that participants were not better than chance at recognizing     target-aligned as well as non-aligned words was
                                                                 significantly better than chance performance (target-
non-aligned words (55.4%, SE=4.69, t(14)= 1.26, p=.228).
And critically, recognition performance was not                  aligned: 70.7%, SE=2.31, t(14)= 4.31, p<.001; non-aligned:
significantly different from chance for target-aligned words     65.5%, SE=3.54, t(14)= 8.95, p<.001). Again, despite the
                                                                 5.2% difference, there was no significant difference between
(51.0%, SE=4.18, t(14)= .197, p=.847; see Figure 1).
Furthermore, when compared to each other, recognition for        target-aligned and non-aligned word recognition
non-aligned words was not significantly different from           performance after attending to the words (t(14)= 1.04,
target-aligned words (t(14)= -.762, p=.459) .                    p=.316; see Figure 2).
                                                                     Recognition performance after attending to the picture
                                                                 stream showed that recognition of non-aligned words was
                                                                 not better than chance (52.8%, SE=5.39, t(14)= .539,
                                                                 p=.599). Moreover, analogous to the other condition (visual
                                                                 words and sounds), recognition for target-aligned words
                                                                 was not significantly different from chance (51.0%,
                                                                 SE=4.81, t(14)= .206, p=.840; see Figure 2). There were no
                                                                 significant differences when compared to each other (t(14)=
                                                                 .272, p=.790).
                                                             1167

                                                                            The present findings are of particular interest considering
                                                                        the recent documented inhibition observed for target-
                                                                        aligned, explicitly presented superthreshold stimuli in
                                                                        numerous investigations (Dewald et al., 2010; Dewald &
                                                                        Sinnett, submitted; Tsushima et al., 2006, 2008). Recall that
                                                                        Tsushima et al (2006) demonstrated that performance for
                                                                        superthreshold motions that were simultaneously presented
                                                                        with a task-target were later inhibited when compared to
                                                                        motions not presented with a task-target. This finding was
                                                                        further supported by word recognition performance in an
                                                                        inattentional blindness paradigm showing inhibition for
                                                                        previously aligned words in a repetition detection task; for
                                                                        both visual (Dewald et al., 2010) and auditory (Dewald &
                                                                        Sinnett, submitted) presentations. However, here, target-
 Figure 2. Recognition percentages for Target-Aligned (black bars)      aligned irrelevant stimuli were recognized no differently
      and Non-Aligned (grey bars) words in the surprise word            than non-aligned irrelevant stimuli in both experimental
  recognition test after attending to either the spoken word stream     conditions (Visual words: 55% Non-Aligned vs. 51%
                 (left) or the picture stream (right).                  Target-Aligned; Auditory Words: 52% Non-Aligned vs.
                                                                        51% Target-Aligned), suggesting that the previously
                             Discussion                                 observed inhibition seemingly disappears when attention is
                                                                        divided across sensory modalities. This could arise due
There are a number of key findings that merit discussion.               possibly to the existence of individualized attentional
First, we have replicated previous findings on inattentional            reservoirs for each sensory modality (see Wickens, 1984).
blindness under multimodal presentations, showing that                      Interestingly, recent research by Swallow and Jiang
performance after attending the distracting stream (either              (2010) suggests an “attentional boost” (i.e., facilitation) for
sounds or pictures) lead to the inability of participants to            simultaneously presented information in a dual-task
recognize previously presented words above chance levels.               paradigm (see also Lin et al., 2010). Although in their
This is a particularly relevant finding given that, in a                experiment, participants were required to divide their
virtually identical task, Sinnett et al. (2006) did find above          attention across both streams, rather than only pay attention
chance results for both of these multimodal conditions. It is           to one of the streams, our results are somewhat analogous to
difficult to speculate as to why we found contradicting                 this notion. It is perhaps possible that by dividing the task
results, although, it should be noted that under certain                across modalities, an analogous boost emerges.
conditions equivalent levels of IB were observed when                       To conclude, the findings presented here provide an
comparing unimodal to crossmodal conditions in Sinnett et               outcome that aligns with most literature regarding divided
al. (2006; see Experiment 2). Regardless of this difference,            attention across sensory modalities. That is, while
it is apparent that attending to the words resulted in                  attentional capacity is limited for stimulus processing within
enhanced word recognition levels. Furthermore, the present              the same sensory modality, tasks presented to different
experiment expands on Sinnett et al. by directly measuring              sensory modalities may in fact increase that capacity by
the fate of irrelevant stimuli presented simultaneously with            enabling access to individualized reservoirs (e.g., Duncan et
or without a task-relevant target.                                      al., 1997; Lavie, 2005; Sinnett et al., 2006; Wickens, 1984).
    Recall that Dewald et al (2010), showed support for a               It seems to be that the additional attentional resources were
possible inhibitory mechanism for overtly presented but                 directed towards irrelevant stimuli and therefore,
irrelevant visual information that appeared simultaneously              recognition of the irrelevant stimuli was enhanced, or at the
with an attended target within the same sensory modality                very least, not inhibited.
(recognition performance was 36%). Furthermore, Dewald
and Sinnett (submitted) extended this finding to auditory                                         References
presentations (recognition performance was 40%). In the
present study, the same inhibition was not observed.                    Ahissar, M., & Hochstein, S. (1993). Attentional control of
Instead, performance for irrelevant words simultaneously                          early perceptual learning. Proceedings of the
presented with an attended target in a separate modality                          National Academy of Science U.S.A, 90, 5718–
remained at chance levels (51% in both conditions). While a                       5722.
confirmatory analysis across experiments was done, indeed               Bright, P., Moss, H., & Tyler, L. K. (2004). Unitary vs
showing improved performance for multimodal conditions                            multiple semantics: PET studies of word and
when compared to unimodal conditions (both collapsed or                           picture processing. Brain and Language, 89, 417-
not across modalities), it should be acknowledged that the                        432.
unimodal experiments were conducted and reported                        Broadbent, D.E. (1958). Perception and communication.
separately making a direct comparison challenging.                                London: Pergamon Press.
                                                                    1168

Britten, K.H., Shalden, M.N., Newsome, W.T., & Movshon,           Seitz, A. R. & Watanabe, T. (2008). Is task-irrelevant
          J.A. (1992). The analysis of visual motion: A                     learning really task-irrelevant? PLoS ONE 3(11):
          comparison of neuronal and psychophysical                         e3792
          performance. Journal of Neuroscience, 12, 4745-         Sinnett, S., Costa, A., & Soto-Faraco, S. (2006).
          4765.                                                             Manipulating inattentional blindness within and
Cherry, E. C. (1953). Some experiments on the recognition                   across sensory modalities. Quarterly Journal of
          of speech, with one and two ears. Journal of the                  experimental Psychology, 59(8), 1425-1442
          Acoustical Society of America, 25, 975–979.             Snodgrass, J. G., & Vanderwart, M. (1980). A standardized
Dewald, A.D., Sinnett, S., & Doumas, L.A.A. (2010). The                     set of 260 pictures: Norms            for name
          inhibition and facilitation of stimuli can be                     agreement, image agreement, familiarity, and
          modulated by the focus of direct attention.                       visual complexity.          Journal of Experimental
          Proceedings of the Twenty-Eight Annual                            Psychology: Human Learning and Memory, 6, 1
          Conference of the Cognitive Psychology Society                    74–215.
Dewald, A.D., & Sinnett, S. (submitted). An inhibited             Spence, C., & Squire, S. (2003). Multisensory integration:
          recognition performance for explicitly presented                  Maintaining the perception of synchrony. Current
          target-aligned irrelevant stimuli in the auditory                 Biology, 13, R519-R521.
          modality. Proceedings of the Twenty-Ninth Annual        Spence, C., & Driver, J. (1998). Cross-modal links in spatial
          Conference of the Cognitive Psychology Society                    attention. Pilosophican Transactions of the Royal
Driver, J., & Spence, C. (2004). Crossmodal spatial                         Society :Biological Sciences, 352(1373), 1319-
          attention: Evidence from human performance.                       1331.
          In C. Spence & J. Driver (Eds.), Crossmodal space       Stroop, J. R. (1935). Studies of interference in seriail verbal
          and crossmodal attention. Oxford, UK: Oxford                      reactions. Journal of Experimental Psychology,
          University Press.                                                 18,643-662.
Fahle, M., & Poggio, T. (2002). Perceptual learning, The
          MIT Press.                                              Swallow K. M., & Jiang, Y. V. (2010). The attentional
Lin, J.Y., Pype, A.D., Murray, & Boynton, G.M. (2010).                      boost effect: Transient increases in attention to
          Enhanced memory for scenes presented at                           one task enhance performance in a second task.
          relevant points in time. PLoS Biol, 8(3), E1000337.               Cognition, 115, 118-132.
Lupker, S. J. (1984). Semantic priming without association:       Tshushima, Y., Sasaki, Y., & Watanabe, T. (2006). Greater
          A second look. Journal of Verbal Learning and                     disruption due to failure of inhibitory
          Verbal Behavior, 23, 709–733.                                     control on an ambiguous distractor. Science, 314,
Peterson, S.E., Fox, P.T., Posner, M.I., Mintun, M., &                      1786-1788.
          Raichle, M.E. (1989). Positron emission                 Tsushima, Y., Seitz, A. R., & Watanabe, T. (2008). Task-
          tomographic studies of the processing of single                   irrelevant learning occurs only       when the
          words. Journal of Cognitive                                       irrelevant feature is weak. Current Biology,18(12),
          Neuroscience,1(2), 153-170.                                       516-517.
Rees, G., Russell, C., Frith, C. D., & Driver, J. (1999).         Watanabe, T., Náñez,Y., & Sasak, S. (2001). Perceptual
          Inattentional blindness versus inattentional                      learning without perception. Nature, 413, 844–
          amnesia for fixated but ignored words. Science,                   848.
          286, 2504-2507.                                         Wilson, M. D. (1988). The MRC psycholinguistic database:
Roelfsema, P. R., van Ooyen, A., & Watanabe, T. (2009).                     Machine readable dictionary, version 2.
          Perceptual learning rules based on reinforces                     Behavioural Research Methods, Instruments and
          and attention. Trends in Cognitive Sciences, 14(2),               Computers, 20, 6-11.
          64-71.
Ruz, M. A., Worden, M. S., Tudela, P.O. & McCandliss, B.
          D. (2005). Innattentional amnesia to words in a
          high attentional load task. Journal of Cognitive
          Neuroscience,      17, 768-776.
Seitz, A. R., Kim, R., & Shams, L. (2006). Sound facilitates
          visual learning. Current Biology, 16, 1422-1427.
Seitz, A. R. & Watanabe, T. (2003). Psychophysics: Is
          subliminal learning really passive? Nature, 422,
          36.
Seitz, A. R. & Watanabe, T. (2005). A unified model for
          perceptual learning. Trends in Cognitive
          Science, 9 (7), 329-334.
                                                              1169

