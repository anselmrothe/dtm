UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Naive Inference viewed as Computation
Permalink
https://escholarship.org/uc/item/8582r0v9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Thorton, Chris
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                             Naı̈ve Inference viewed as Computation
                                                         Chris Thornton
                                                        COGS/Informatics
                                                       University of Sussex
                                                              Brighton
                                                             BN1 9QH
                                                                UK
                                                     c.thornton@sussex.ac.uk
                          Abstract                                     The problem particularly affects information embody-
                                                                    ing conditional cycles. Imagine we have boolean vari-
   Use of Bayesian models to explain both high- and low-            ables X, Y and Z representing basic features of the en-
   level aspects of cognitive function promises better con-
   nections between cognitive science and cognitive neu-            vironment (e.g., rain, mud and humidity). These are
   roscience. But standing in the way are fundamental               known to be conditionally related as follows: P (Y |X) =
   problems, such as the computational intractability of            0.8, P (Z|Y ) = 0.4, P (X|Z) = 0.6. Given P (X) = 1.0
   Bayesian inference, and the general difficulty of under-
   standing how Bayesian calculation can deal with struc-           (e.g., observed evidence of rain) what probability should
   tural representation. Getting around the problem of in-          we infer for Y ? Standard methods of probabilistic in-
   tractability seems to involve devising effective methods         ference cannot produce any answer. The existence of
   for approximating optimal inference. But there is the
   alternative of simplifying the interpretation of how in-         a cycle among the conditional relationships means the
   ference arises. While the process is normally taken to           model cannot be viewed as representing a joint distribu-
   involve calculations over an implied joint distribution, it      tion. Inference through marginalization is ruled out.
   is possible to view it more simply as data-driven appli-
   cation of conditional assertions. This naı̈ve interpreta-           One way around the problem is to take an approach
   tion has several advantages with regard to tractability          which dispenses with the underlying joint distribution
   and representation. The paper formalizes the model and           altogether. Instead of treating this as the key reference,
   demonstrates some of its virtues.
                                                                    we treat the probabilities the model asserts as fundamen-
                                                                    tal. Conditional values are not viewed as constraints on
                      Introduction                                  an implied joint distribution. Rather they are viewed as
Methods of probabilistic inference are increasingly under           mandating acts of inference. On this basis, P (X|Y ) le-
the spotlight as cognitive science moves towards greater            gitimates inference of an unconditional value of X when-
use of Bayesian approaches (e.g., Knill and Richards,               ever an unconditional value of Y is identified. Simulta-
1996; Chater et al. 2006). Strongly facilitating this trend         neous inferences for the same variable can be accommo-
are the ‘graphical models’ for performing inference with            dated by letting them contribute equally to the inferred
complex probabilistic information (e.g., Pearl, 1988).              value, subject to the constraint that probabilities sum to
Somewhat obstructing it is the knowledge that Bayesian              1. Inferred values are then obtained by normalized sum-
inference is computationally intractable (Cooper, 1990).            mation of products, much as in marginalization. The
For some, this intractability does not vitiate the explana-         regime accommodates cyclic conditionality. Application
tory value of Bayesian inference viewed as an optimal               to the case above, for example, produces a final inferred
solution for a cognitive or perceptual problem (e.g., An-           probability of 0.8 for variable Y .
derson, 1990). The point is made that such models can                  This regime, in which asserted probabilities are
be viewed as theories at a functional level of abstraction,         treated as inference mandates, can be viewed as a naı̈ve
e.g., the computational level of Marr’s scheme (Marr,               form of probabilistic inference (cf. Hansson et al. 2008)
1982). For others, the intractability issue is more con-            in which inference arises directly from the semantics of
cerning (e.g., Danks, 2008).                                        conditional assertions. Application of conditional proba-
   A more basic problem with Bayesian approaches re-                bilities to relevant unconditional values has the potential
lates to the constraints that methods of probabilistic              to identify new unconditional values. These can then be
inference place on source information. All standard                 the basis for production of further values, and so on, in
methods assume a probabilistic model that implicitly                a potentially infinite sequence. Naı̈ve inference becomes
represents an underlying joint distribution (Russell and            the behaviour of a data-driven machine — a naı̈ve infer-
Norvig, 2010). Inference is progressed through marginal-            ence machine as it will be called.
ization, i.e., constrained summations of values appearing              Is such a primitive procedure likely to have any use-
within this joint distribution. The difficulty is that the          ful application? There are various ways it might do so.
process is then infeasible with regard to probabilistic in-         Where there is a need to deal with probabilistic infor-
formation that does not properly represent a joint dis-             mation embodying cycles, standard forms of inference
tribution.                                                          cannot be used. Dealing with the situation without re-
                                                                366

quiring additional assumptions, naı̈ve inference may then                            Formalization
have a use as a least-commitment approach to inference          In this approach, probabilistic information is assumed
in the presence of conditional cycles.                          to take the form of probability values for random dis-
   The regime also makes connections with non-                  crete variables. Conventional notation is used. Thus
inferential models of mechanism. Accommodation of               P (X = Xi ) denotes the probability that random variable
cycles means that naı̈ve inference can exhibit looping.         X has value Xi . If X is boolean, P (X) is a shorthand
Naı̈ve inference machines have the potential for infinite       for P (X = true).
processing. In the case where extremal probabilities (1s           Given variables X and Y are both boolean, the condi-
and 0s) are deployed, the behaviour is that of a digital        tional expression P (X|Y ) expresses the probability that
device with iterative behaviour; a connection can then be       X is true given Y is true. In naı̈ve inference, this is
made between naı̈ve inference and computation. In fact,         understood to directly mandate acts of inference. Iden-
as Section 4 demonstrates, naı̈ve inference machines are        tification of an unconditional probability for Y , either
Turing equivalent: they can model any form of computa-          by assumption or (prior) inference, establishes the pos-
tional behaviour. This suggests the potential for expla-        sibility of inferring an unconditional value of X. Where
nations unifying modeling of inferential behaviour with         inference using multiple conditionals is legitimated, de-
modeling of computational behaviour.                            rived products are assumed to contribute equally to the
   An appealing application of naı̈ve inference is in con-      inferred value, subject to the constraint that probabili-
nection with conventional Bayesian accounts. A diffi-           ties in a distribution must sum to 1.
culty with these is the computational intractability of the        A probabilistic model is defined to be a set of condi-
process model. Some accounts cash this out by establish-        tional and unconditional probability values for random
ing the means by which processing is implemented (e.g.,         discrete variables. Letting M label such a model, PM (X)
Pouget et al. 2003; Körding and Wolpert, 2006). Others         is the unconditional probability of X in model M , and
reserve the right not to do so on grounds of explana-           PM (X|Y ) is the conditional probability of X given Y
tory abstraction (e.g., Chater and Oaksford, 2008b). In         in model M . Bold font is used to denote distributions.
general, there is a need to establish a better connection       Thus PM (X) is the distribution on variable X repre-
between the theoretical ideal of Bayesian inference, and        sented by model M . Given X is boolean, P (X) = 1
practical mechanisms by which it can be pursued.                becomes a shorthand for P(X) = h1, 0i.
   Naı̈ve inference cannot be viewed as approximating              Defining the unnormalized inferred probability for Xi
Bayesian inference. But since it treats the semantics of        in model M to be
the conditional probability assertion in the same way,                                    X
situations can arise in which both methods produce the                     PM (Xi ) =             PM (Xi |c)PM (c)     (1)
same result. There is then the potential to treat naı̈ve                               c∈C(Xi ,M)
inference as modeling the ‘bounded rationality’ (Simon,            the distribution inferred for X in model M is
1957) that ideal rationality must express in practice. In-
stead of approximating the Bayesian ideal, this intro-                      P′M (X) = α hPM (X1 ), ..., PM (Xn )i      (2)
duces a less sophisticated interpretation of what infer-
ence involves.                                                     In Eq. 1, C(x, M ) is the set of conditions that figure
                                                                in conditional probabilities asserted for values of X in
   Taking bounded rationality to be modeled by naı̈ve in-
                                                                model M , n is the number of values of X, and α is the
ference does achieve some of the benefits of approxima-
                                                                normalization function. The inference of Eq. 2 is taken
tion, however. The process model is no longer computa-
                                                                to be defined just in case the model provides evaluations
tionally intractable. There is also the prospect of better
                                                                for all conditions. That is to say, it is defined if the
connections with models of neural processing. Mediated
                                                                model provides unconditional values for all applicable
by simple operations of summation and normalization,
                                                                conditions.
the machinery of naı̈ve inference is likely to be more
                                                                   Building on this, we can define the complete set of in-
easily related to known functionalities of the brain (cf.
                                                                ferences that can be obtained through application of the
Dayan and Abbott, 2001)
                                                                inference step to an existing model. Termed a revision,
   The aim of the paper is to set out the proposed model        this is denoted by adding a prime to the model label.
of naı̈ve probabilistic inference in more detail, to for-       Thus M ′ denotes the naı̈ve-inferential revision of model
malize it mathematically, and to examine its potential          M:
uses. There are five main sections. The next section
(Section 2) formalizes the inference model. Section 3 ex-
amines the degree to which naı̈ve inference can emulate            M ′ = { P′M (X) | X ∈ M ∧ PM     ′
                                                                                                      (X) 6= PM (X)}   (3)
ideal Bayesian estimation. Section 4 explores the sense
in which naı̈ve inference machines are Turing equivalent.          Here, X ∈ M is true if and only if variable X features
Section 5 presents a summary.                                   in model M .
                                                            367

   Recursive evaluation of M ′ can then be the means of         (i.e. priors) is assumed to represent a joint distribu-
generating a sequence of inferential revisions of a partic-     tion. The process of inference involves determining un-
ular model. Mi , the i’th model in the sequence, must           observed values in this distribution. Where uncondi-
satisfy                                                         tional values are considered to constitute evidence, de-
                                                                rived values are posteriors. While the process is compu-
                   Mi = Mi−1′
                                   =⇒ Mi−1                      tationally intractable (Cooper, 1990), graphical models
                                                                such as (Pearl, 1988) are often effective. These allow
   where the ‘=⇒’ operator denotes imposition of Mt−1  ′        the process to be progressed in a way that maximally
                              ′
on Mt−1 . Specifically, M =⇒ M represents addition              exploits independence relationships for factorising cal-
of all unconditional values in M ′ to M , with preference       culations.
given to values of M ′ where both sets give values for             The naı̈ve model of inference relinquishes the assump-
the same variable. Letting M0 label the set of condi-           tion of an underlying joint distribution. Inference is
tional values in model M , and M0′ be the corresponding         taken to involve data-driven application of conditional
set of unconditional values, the sequence of revisions for      assertions. However, the two approaches place the same
model M then takes a well-defined form. This is denoted         interpretation on conditional assertions. In both inter-
N (M ):                                                         pretations, it is axiomatic that
                 N (M ) = ( M0′ , ..., Mn′ )                                        P (X) = P (X|Y )P (Y )
                                                                   given known values for P (Y ) and P (X|Y ). Inference
   N (M ) can also be viewed as labeling the naı̈ve infer-
                                                                mediated solely by this rule is thus progressed identically
ence machine defined by model M . The behaviour of
                                                                under naı̈ve and ideal protocols.
the machine is production of revisions. The output is
                                                                   This can be illustrated using the ‘sprinkler’ exam-
the revision sequence itself.
                                                                ple, a popular scenario for illustrating the behaviour of
   A simple illustration is provided by the model of Table      Bayesian inference using Bayesian networks (e.g., Pearl,
1.                                                              1988, p. 56). In this example, variable Rain represents
                                                                the occurrence of rain, variable Sprinkler represents a
       P (X = 1) = 1               P (X = 0) = 0
                                                                sprinkler being on overnight, and variable GrassW et
       P (X = 1|X = 1) = 0         P (X = 0|X = 1) = 1
                                                                representing the grass being wet. These are all boolean
       P (X = 1|X = 0) = 1         P (X = 0|X = 0) = 0
                                                                variables taking values T and F, representing true and
                                                                f alse respectively. Conditional and unconditional prob-
           Table 1: Naı̈ve-inferential oscillator               abilities for these variables are illustrated schematically
                                                                in Figure 1.
   In this probabilistic model, X is conditionally depen-
dent on itself, but with the conditioned value always be-            Sprinkler
ing the opposite of the conditioning value. Naı̈ve in-               Rain      T        F               Rain
ference then yields an infinite revision sequence within             F         0.4      0.6             T         F
which the value of X continually changes between its                 T         0.01     0.99            1         0
two values. Given shorthand representations for binary-
valued distributions, and vertical arrangement of the el-
                                                                               GrassWet
ements of the sequence, N (M ) evaluates as
                                                                               Rain     Sprinkler  T         F
                                                                             F        F          0         1
                              {P (X) = 1},
                          {P (X) = 0},                                       T        F          0.8       0.2
                                                                             F        T          0.9       0.1
               N (M ) =  {P (X) = 1},
                                             
                          {P (X) = 0},
                                             
                                                                              T        T          0.99      0.01
                               ...
                                                                Figure 1: Probabilistic model for Rain/Sprinkler/Grass
   This is the behaviour of the naı̈ve inference machine        example.
defined by the model of Table 1. The (infinite) sequence
of revisions generated is the output the machine pro-
                                                                   In this diagram, each variable is represented by a table.
duces.
                                                                Values of the variable correspond to columns, while rows
                                                                represent conditions. Where unconditional values are
   Emulation of ideal Bayesian inference                        given, they appear in the bottom row of a table. Thus,
In optimal Bayesian inference, a probabilistic model            the unconditional probability of Rain is here shown to
comprising conditional and unconditional probabilities          be 1. The conditional probability of GrassW et given
                                                            368

Rain = T and Sprinkler = F is 0.8, and so on. The val-          ucts of conditional and unconditional values in the usual
ues shown can be viewed as comprising a probabilistic           way. Naı̈ve inference can thus reproduce the effect pro-
model in the present sense of the term. They can also           vided variables are provided whose unconditional values
be regarded as comprising a probabilistic model in the          are those that would be obtained through application of
conventional sense of the term. Indeed, given the sim-          Bayes’ rule. On the assumption that such proxies are in-
plicity of the model guarantees conditional independence        troduced (or assumed to exist), naı̈ve inference then has
of GrassW et given Sprinkler and Rain, it also repre-           the potential to reproduce hypothesis-selection involving
sents a Bayesian network. On this view, the tables are          application of Bayes’ rule. On this basis, naı̈ve inference
the conditional probability tables (CPTs) of a standard         can reproduce the classic inferential scenario of Bayesian
Bayesian network.                                               estimation.
   Say we discover that P (Rain) = 1.0, and wish to infer
the effect on P (Sprinkler). We must decide whether we          Introducing a conditional cycle
wish to treat P (Rain) = 1.0 as the unconditional proba-        Naı̈ve inference has the advantage of being able to ac-
bility of Rain, or as observed evidence. This makes a dif-      commodate models representing conditional cycles. This
ference in the case of the Bayesian network: in one case        effect can be illustrated using a modification of the
the network will calculate new values for Sprinkler and         ‘sprinkler’ example. In the original example, there are
GrassW et through probabilistic inference. In the other,        no cycles among the conditions. The conditional struc-
priors for these two variables will become implicitly de-       ture takes the form of a directed acyclic graph (DAG), as
fined. Derived probabilities are the same however. The          required for a Bayesian network. Consider now the vari-
emerging prior (or inferred probability) for Sprinkler is       ation of Figure 2. Here variables Rain and GrassW et
P (Sprinker) = 0.01 and the emerging prior (or inferred         have the same conditional relationship. But we now have
probability) for GrassW et is P (GrassW et) = 0.802.            a Humidity variable, which is conditionally dependent on
   In this case, optimal Bayesian inference relies purely       GrassWet. This produces a conditional cycle in which
on derivation (and normalization) of products. There            GrassWet is made more probable by Rain, Humidity is
is no application of Bayes’ rule. Naı̈ve inference is then      made more probable by GrassWet, and Rain is made
able to emulate the process with the same result. Apply-        more probable by Humidity.
ing Eq. 2 to the model of Figure 1, the initial revision is
determined to contain P (Sprinkler) = 0.01. It will not                           Rain
contain a value for GrassW et however, since all the con-                         Humidity  T     F
                                                                                  T         0.6   0.4
ditions for that variable require unconditional values for                                  1     0
both Rain and Sprinkler. Establishment of an uncon-
ditional probability for Sprinker then prompts a second
revision comprising P (GrassW et) = 0.802.                           GrassWet                     Humidity
   The Bayesian network generates the same posterior                 Rain     T     F             GrassWet T     F
                                                                     T        0.8   0.2           T        0.4   0.6
value (or emergent prior) for GrassW et as does naı̈ve in-
ference. Indeed, given the assumption that Sprinkler is
summed-out in the Bayesian network before GrassW et,
the two regimes produce the derivations in the same               Figure 2: Model for Rain/Grass/Humidity example.
order. In simple cases like this, ideal Bayesian infer-
ence and naı̈ve inference can produce the same result.             This cycle violates the conditional-independence re-
The Bayesian network has a more extensive behavioural           quirements of the Bayesian network, and thus the as-
repertoire, of course. Utilizing Bayes’ rule for inverting      sumption of an underlying joint distribution. Standard
conditional probabilities, it could be the means of cal-        methods cannot be applied but the naı̈ve procedure is
culating an unconditional value for Rain given evidence         unaffected. Revisions are identified in the usual way.
involving GrassW et, for example.                               The presence of the cycle creates the potential for an in-
   The key difference between naı̈ve and Bayesian infer-        finite sequence. But in this case, inference rapidly con-
ence is that the former makes no direct use of Bayes’           verges on a particular set of unconditional values. Taking
rule for inverting conditional probabilities. However, this     M to be model of Figure 2, we obtain the following finite
does not necessarily mean that naı̈ve inference is unable       sequence:
to reproduce classical Bayesian hypothesis selection. In
this scenario, inference is used to determine the hypoth-
                                                                                                               
                                                                                        {P (Rain) = 1},
esis that optimally explains certain data, given priors on                             {P (GrassW et) = 0.8},  
the hypotheses and the data, and conditional values for
                                                                                                               
                                                                          N (M ) =     {P (Humidity) = 0.4},   
data given hypotheses (i.e., relevant likelihoods). The
                                                                                                               
                                                                                       {P (Rain) = 0.6},       
functionality applied, however, involves deriving prod-                                 {P (GrassW et) = 0.8},
                                                            369

   The original unconditional probability for Rain ap-            table specifies a single transition. For example, the first
pears here as the zeroth element of the sequence. Deriva-         entry, says that in state 0 reading symbol #, the ma-
tion of distributions by Eq. 2 then yields four revisions,        chine should write a 1, move right (R), and enter state
the last of which makes no changes to the model. Infer-           1. The symbol # represents an empty tape cell.
ence terminates at this point, with a final probability of
0.8 for GrassW et. This inferred value may be viewed                         State    Read               Write           Move      New state
as reflecting the cyclical dependency between the three                         0          #                    1           R             1
variables. Alternatively, the inferential process may be                        0          0                    1           R             1
viewed as a dynamic projection of the asserted condi-                           0          1                    0           L             0
tional relationships.                                                           1          #                   #            L             h
                                                                                1          0                    0           R             1
         Emulation of Turing Machines                                           1          1                    1           R             1
Attention now given turns to other interpretations that
can be applied to naı̈ve inference. This section exam-                          Table 2: Incrementing Turing Machine
ines the sense in which naı̈ve inference is Turing equiv-
alent. By showing that naı̈ve inference can model any                Running the machine with a tape representing a bi-
Turing-machine computation, the procedure is shown to             nary number has the effect of producing a binary num-
have computational power equivalent to that of a digital          ber on the tape that is one greater than the initial value.
computer, or any other device for effective computation.          Given an initial tape with contents [# # 1 1 #], and
   A Turing machine is defined in terms of a state-               initial read position at index 4 (i.e., over the final 1),
transition table, a ‘tape’ containing a sequence of sym-          the machine executes a series of transitions eventually
bols, and an initial tape position. In each cycle, the            producing the tape state [# 1 0 0 #].
machine reads the symbol from the current position on                 T0
                                                                                                                  S
the tape and responds by writing a symbol at that po-
                                                                      I  K    W # 1 0  R
                                                                      0  iii  # 1 0 0  I    T0 K    #    1    0   S R K   0  1 h
                                                                      0  iii  1 0 1 0  0    #  i    1    0    0   0 # ii  0  1 0
sition, moving the tape one position left or right, and               0  iii  0 0
                                                                                1
                                                                                  0
                                                                                  0
                                                                                    1
                                                                                    0
                                                                                       0
                                                                                       0
                                                                                            1
                                                                                            0
                                                                                               i
                                                                                               i
                                                                                                    0
                                                                                                    0
                                                                                                         1
                                                                                                         0
                                                                                                              0
                                                                                                              1
                                                                                                                  0
                                                                                                                  0
                                                                                                                    0
                                                                                                                    1
                                                                                                                      ii
                                                                                                                      ii
                                                                                                                          0
                                                                                                                          1
                                                                                                                             1
                                                                                                                             0
                                                                                                                               0
                                                                                                                               0
                                                                                       I    T1 K                  1 # ii  0  0 1
entering a new state. The behaviour of the machine is                 T1
                                                                      I  K    W # 1 0
                                                                                       1
                                                                                       1
                                                                                            #
                                                                                            1
                                                                                               i
                                                                                               i
                                                                                                    1
                                                                                                    0
                                                                                                         0
                                                                                                         1
                                                                                                              0
                                                                                                              0
                                                                                                                  1
                                                                                                                  1
                                                                                                                    0
                                                                                                                    1
                                                                                                                      ii
                                                                                                                      ii
                                                                                                                          0
                                                                                                                          0
                                                                                                                             1
                                                                                                                             1
                                                                                                                               0
                                                                                                                               0
the result of repeatedly applying such transitions, until             1  iii  # 1 0 0  1    0  i    0    0    1           1  0 0
                                                                      1  iii  1 0 1 0  I    T2 K
                                                                      1  iii  0 0 0 1  2    #  i    1    0    0
the halt state is reached. The final output obtained is                         1 0 0  2
                                                                                       2
                                                                                            1
                                                                                            0
                                                                                               i
                                                                                               i
                                                                                                    0
                                                                                                    0
                                                                                                         1
                                                                                                         0
                                                                                                              0
                                                                                                              1   M
                                                                                                                                 I
                                                                                                                                 M  I K    0 1 2 3 4
                                                                                       I    T3 K                  S R K   L  R   R  0 iii  0 1 0 0 0
the revised contents of the tape.                                     T2
                                                                      I
                                                                      2
                                                                         K
                                                                         iii
                                                                              W
                                                                              #
                                                                                #
                                                                                1
                                                                                  1
                                                                                  0
                                                                                    0
                                                                                    0
                                                                                       3
                                                                                       3
                                                                                            #
                                                                                            1
                                                                                               i
                                                                                               i
                                                                                                    1
                                                                                                    0
                                                                                                         0
                                                                                                         1
                                                                                                              0
                                                                                                              0
                                                                                                                  0
                                                                                                                  0
                                                                                                                    #
                                                                                                                    0
                                                                                                                      ii
                                                                                                                      ii
                                                                                                                          0
                                                                                                                          0
                                                                                                                             1
                                                                                                                             1
                                                                                                                                 R
                                                                                                                                 L
                                                                                                                                    1
                                                                                                                                    1
                                                                                                                                      iii
                                                                                                                                      iii
                                                                                                                                           0
                                                                                                                                           1
                                                                                                                                             0
                                                                                                                                             0
                                                                                                                                               1
                                                                                                                                               0
                                                                                                                                                 0
                                                                                                                                                 0
                                                                                                                                                   0
                                                                                                                                                   0
                                                                                                                  0 1 ii  1  0   R  2 iii  0 0 0 1 0
   To translate a Turing machine into an equivalent naı̈ve            2
                                                                      2
                                                                         iii
                                                                         iii
                                                                              1
                                                                              0
                                                                                0
                                                                                0
                                                                                0
                                                                                  1
                                                                                  0
                                                                                  1
                                                                                    0
                                                                                    1
                                                                                    0
                                                                                       3
                                                                                       I
                                                                                       4
                                                                                            0
                                                                                            T4
                                                                                            #
                                                                                               i
                                                                                               K
                                                                                               i
                                                                                                    0
                                                                                                    1
                                                                                                         0
                                                                                                         0
                                                                                                              1
                                                                                                              0
                                                                                                                  1
                                                                                                                  1
                                                                                                                    #
                                                                                                                    0
                                                                                                                      ii
                                                                                                                      ii
                                                                                                                          1
                                                                                                                          0
                                                                                                                             0
                                                                                                                             1
                                                                                                                                 L
                                                                                                                                 R
                                                                                                                                    2
                                                                                                                                    3
                                                                                                                                      iii
                                                                                                                                      iii
                                                                                                                                           0
                                                                                                                                           0
                                                                                                                                             1
                                                                                                                                             0
                                                                                                                                               0
                                                                                                                                               0
                                                                                                                                                 0
                                                                                                                                                 0
                                                                                                                                                   0
                                                                                                                                                   1
inference machine we can proceed as follows. For each                 T3
                                                                                       4
                                                                                       4
                                                                                            1
                                                                                            0
                                                                                               i
                                                                                               i
                                                                                                    0
                                                                                                    0
                                                                                                         1
                                                                                                         0
                                                                                                              0
                                                                                                              1
                                                                                                                  1 1 ii  0  1   L
                                                                                                                                 L
                                                                                                                                    3
                                                                                                                                    4
                                                                                                                                      iii
                                                                                                                                      iii
                                                                                                                                           0
                                                                                                                                           0
                                                                                                                                           0
                                                                                                                                             0
                                                                                                                                             0
                                                                                                                                             0
                                                                                                                                               1
                                                                                                                                               0
                                                                                                                                               0
                                                                                                                                                 0
                                                                                                                                                 1
                                                                                                                                                 1
                                                                                                                                                   0
                                                                                                                                                   0
                                                                                                                                                   0
cell of the Turing machine’s tape, we introduce a named               I
                                                                      3
                                                                      3
                                                                         K
                                                                         iii
                                                                         iii
                                                                              W
                                                                              #
                                                                              1
                                                                                #
                                                                                1
                                                                                0
                                                                                  1
                                                                                  0
                                                                                  1
                                                                                    0
                                                                                    0
                                                                                    0
                                                                                                                  W
variable whose values are the symbols used by the Turing              3  iii  0 0
                                                                                0
                                                                                  0
                                                                                  1
                                                                                    1
                                                                                    0  K
                                                                                                                  S
                                                                                                                  0
                                                                                                                    R
                                                                                                                    #
                                                                                                                      K
                                                                                                                      ii
                                                                                                                          #
                                                                                                                          0
                                                                                                                             1
                                                                                                                             1
                                                                                                                               0
                                                                                                                               0
                                                                                       K     i   ii  iii   iv
machine. We introduce variables to represent the current              T4
                                                                      I  K    W # 1 0
                                                                                       i
                                                                                       ii
                                                                                             0
                                                                                             0
                                                                                                 1
                                                                                                 0
                                                                                                     0
                                                                                                     1
                                                                                                           0
                                                                                                           0
                                                                                                                  0
                                                                                                                  0
                                                                                                                  1
                                                                                                                    0
                                                                                                                    1
                                                                                                                    #
                                                                                                                      ii
                                                                                                                      ii
                                                                                                                      ii
                                                                                                                          0
                                                                                                                          0
                                                                                                                          1
                                                                                                                             1
                                                                                                                             0
                                                                                                                             0
                                                                                                                               0
                                                                                                                               1
                                                                                                                               0
symbol read, and the current symbol to be written. We                 4
                                                                      4
                                                                         iii
                                                                         iii
                                                                              #
                                                                              1
                                                                                1
                                                                                0
                                                                                  0
                                                                                  1
                                                                                    0
                                                                                    0
                                                                                       iii
                                                                                       iv
                                                                                             0
                                                                                             1
                                                                                                 0
                                                                                                 0
                                                                                                     0
                                                                                                     0
                                                                                                           1
                                                                                                           0
                                                                                                                  1
                                                                                                                  1
                                                                                                                    0
                                                                                                                    1
                                                                                                                      ii
                                                                                                                      ii
                                                                                                                          0
                                                                                                                          0
                                                                                                                             0
                                                                                                                             1
                                                                                                                               1
                                                                                                                               0
                                                                      4  iii  0 0 0 1        1   0   0     0
also introduce variables to represent the current state,                        1 0 0
the current move, and the current tape position. Finally,
we establish a clocking variable that cycles through a se-        Figure 3: Naı̈ve inferential simulation of incrementing
quence of values representing the read/write/move cycle           Turing machine.
of execution. This functionality is achieved through use
of self-referential conditions, as in the model of Table 1.          The equivalent naı̈ve inference machine appears in Fig-
   Probabilities are extremal (i.e., 1s and 0s) in all cases.     ure 3. In this translation, variable R represents the cur-
Conditional values are configured so that values change           rent read, W the current write, S the current state and
in accordance with the transitions of the Turing machine.         M the current move. Variable I is the current tape in-
States of the clocking variable are referenced for pur-           dex and variable K is the three-phase clock. Variables
poses of sequencing the individual steps of each transi-          T 1, T 2, T 3 etc. represent the tape contents at positions
tion. Execution of the machine then produces extremal             1, 2, 3 etc. To correctly initialize the machine, we in-
distributions over variables that precisely replicate the         clude unconditional distributions which have the effect
read/write/move states of the Turing machine. Tape-               of setting the clock variable to phase 1, the tape posi-
cell variables are updated exactly as the Turing machine          tion variable to the appropriate index, and the tape vari-
updates its tape.                                                 ables to values corresponding to the initial contents of
   As an illustration, consider the Turing machine de-            the tape. The ensuing behaviour then perfectly emulates
fined by the state-transition table of Table 2. The func-         the original Turing machine, terminating once the halt
tion of this machine is to increment whatever binary              state is reached. Tape-state variables at that point cor-
number is represented on its tape. Each entry in the              rectly represent the final tape state of the corresponding
                                                              370

Turing machine.                                                      tic mind: where next?. In N. Chater and M. Oaks-
   This is not the only way to translate a Turing machine            ford (Eds.), The Probabilistic Mind: Prospects for
into an equivalent naı̈ve inference machine, of course.              Bayesian Cognitive Science (pp. 501-514). Oxford:
Neither is it claimed to be the best. The demonstration              Oxford University Press.
suffices, however, to show that the behaviour of a Tur-
                                                                 Chater, N. and Oaksford, M. (2008b). The probabilistic
ing machine can be obtained from naı̈ve inference. On
                                                                     mind: prospects for a bayesian cognitive science. In
this basis, computational behaviour is contained within
                                                                     N. Chater and M. Oaksford (Eds.), The Probabilistic
naı̈ve inference, and naı̈ve inference has the capacity to
                                                                     Mind: Prospects for Bayesian Cognitive Science (pp.
‘compute’ any computable function.
                                                                     1-32). Oxford: Oxford University Press.
   A better understanding is then obtained of the sense
in which naı̈ve inference addresses the problem of infer-        Chater, N., Tenenbaum, J. and Yuille, A. (2006). Proba-
ential intractability. The protocol does not invoke an               bilistic models of cognition: conceptual foundations.
intractable algorithm, due to the fact that it does not              Trends in Cognitive Sciences (Special issue on Prob-
invoke an algorithm of any sort. Rather, it invokes the              abilistic Models of Cognition), 10, No. 7 (pp. 287-
general concept of computation. Rather than solving the              291).
problem of intractability, then, naı̈ve inference provides
an interpretation in which the problem does not seem             Cooper, G. (1990). The computational complexity
to apply. A clearer understanding is also obtained of                of probabilistic inference using bayesian belief net-
behavioural possibilities. The demonstration that naı̈ve             works. Artificial Intelligence, 42 (pp. 393-405w).
inference is able to compute any function implies it can         Danks, D. (2008). In N. Chater and M. Oaksford (Eds.),
be the medium for representing any formal structure.                 The Probabilistic Mind: Prospects for Bayesian Cog-
On that basis, a naı̈ve inference machine can then be                nitive Science (pp. 59-75). Oxford: Oxford Univer-
the means of applying inferential processes to structural            sity Press.
representations.
                                                                 Dayan, P. and Abbott, L. (2001). Theoretical Neuro-
                       Discussion                                    science: Computational and Mathematical Modelling
The paper has proposed a ‘naı̈ve’ method of probabilis-              of Neural Systems. MIT Press.
tic inference that deals with the problem of conditional         Hansson, P., Juslin, P. and Winman, A. (2008). The
cycles. While it cannot be viewed as approximating                   naı̈ve intuitive statistician: organism—environment
Bayesian estimation, it does offer some of the advantages            relations from yet another angle. In N. Chater
of an approximation approach. It avoids the problem                  and M. Oaksford (Eds.), The Probabilistic Mind:
of intractability, by linking inference to computation in            Prospects for Bayesian Cognitive Science. Oxford:
general rather than to the action of a specific algorithm.           Oxford University Press.
There may then be implications for ‘the challenge of ap-
plying probabilistic methods over structured symbolic            Knill, D. and Richards, W. (Eds.) (1996). Perception as
representations’ (Chater and Oaksford, 2008a, p. 510).               Bayesian Inference. Cambridge University Press.
The present method addresses that challenge to some              Körding, K. and Wolpert, D. (2006). Bayesian decision
extent by demonstrating a way in which ‘it is possible to            theory in sensory motor control. Trends in Cognitive
integrate probability with logic’ (ibid.)                            Sciences, 10 (pp. 319-326).
   Naı̈ve inference offers a novel way to bridge the gap be-
tween the ideal of Baysian calculation and the realities of      Marr, D. (1982). Vision. New York: W.H. Freeman.
innately constrained behaviour. Whereas the tradition
                                                                 Pearl, J. (1988). Probabilistic Reasoning in Intelligent
of rational analysis involves modeling ‘cognitive abili-
                                                                     Systems: Networks of Plausible Inference. San Ma-
ties using sophisticated forms of probabilistic inference’
                                                                     teo: Morgan and Kaufman.
(Chater et al. 2006, p. 287), this approach allows them
to be modeled using naı̈ve forms. Rather than assuming           Pouget, A., Dayan, P. and Zemel, R. (2003). Inference
this necessarily involves applying some heuristic approx-            and computation with population codes. Annual Re-
imation of ideal Bayesian calculation, moreover, it can              view of Neuroscience, 26 (pp. 381-410).
be taken to involve a non-heuristic procedure operating
                                                                 Russell, S. and Norvig, P. (2010). Artificial Intelligence:
under a less sophisticated interpretation of inference.
                                                                     A Modern Approach (Third Edition). Boston: Pear-
                       References                                    son.
Anderson, J. (1990).          The Adaptive Character of          Simon, H. (1957). Models of Man, Social and Rational:
    Thought. Erlbaum.                                                Mathematical Essays on Rational Human Behavior
                                                                     in a Social Setting. New York: Wiley.
Chater, N. and Oaksford, M. (2008a). The probabilis-
                                                             371

