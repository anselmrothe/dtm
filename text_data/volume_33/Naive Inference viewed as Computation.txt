UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Naive Inference viewed as Computation

Permalink
https://escholarship.org/uc/item/8582r0v9

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Author
Thorton, Chris

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Naı̈ve Inference viewed as Computation
Chris Thornton
COGS/Informatics
University of Sussex
Brighton
BN1 9QH
UK
c.thornton@sussex.ac.uk
The problem particularly affects information embodying conditional cycles. Imagine we have boolean variables X, Y and Z representing basic features of the environment (e.g., rain, mud and humidity). These are
known to be conditionally related as follows: P (Y |X) =
0.8, P (Z|Y ) = 0.4, P (X|Z) = 0.6. Given P (X) = 1.0
(e.g., observed evidence of rain) what probability should
we infer for Y ? Standard methods of probabilistic inference cannot produce any answer. The existence of
a cycle among the conditional relationships means the
model cannot be viewed as representing a joint distribution. Inference through marginalization is ruled out.
One way around the problem is to take an approach
which dispenses with the underlying joint distribution
altogether. Instead of treating this as the key reference,
we treat the probabilities the model asserts as fundamental. Conditional values are not viewed as constraints on
an implied joint distribution. Rather they are viewed as
mandating acts of inference. On this basis, P (X|Y ) legitimates inference of an unconditional value of X whenever an unconditional value of Y is identified. Simultaneous inferences for the same variable can be accommodated by letting them contribute equally to the inferred
value, subject to the constraint that probabilities sum to
1. Inferred values are then obtained by normalized summation of products, much as in marginalization. The
regime accommodates cyclic conditionality. Application
to the case above, for example, produces a final inferred
probability of 0.8 for variable Y .
This regime, in which asserted probabilities are
treated as inference mandates, can be viewed as a naı̈ve
form of probabilistic inference (cf. Hansson et al. 2008)
in which inference arises directly from the semantics of
conditional assertions. Application of conditional probabilities to relevant unconditional values has the potential
to identify new unconditional values. These can then be
the basis for production of further values, and so on, in
a potentially infinite sequence. Naı̈ve inference becomes
the behaviour of a data-driven machine — a naı̈ve inference machine as it will be called.
Is such a primitive procedure likely to have any useful application? There are various ways it might do so.
Where there is a need to deal with probabilistic information embodying cycles, standard forms of inference
cannot be used. Dealing with the situation without re-

Abstract
Use of Bayesian models to explain both high- and lowlevel aspects of cognitive function promises better connections between cognitive science and cognitive neuroscience. But standing in the way are fundamental
problems, such as the computational intractability of
Bayesian inference, and the general difficulty of understanding how Bayesian calculation can deal with structural representation. Getting around the problem of intractability seems to involve devising effective methods
for approximating optimal inference. But there is the
alternative of simplifying the interpretation of how inference arises. While the process is normally taken to
involve calculations over an implied joint distribution, it
is possible to view it more simply as data-driven application of conditional assertions. This naı̈ve interpretation has several advantages with regard to tractability
and representation. The paper formalizes the model and
demonstrates some of its virtues.

Introduction
Methods of probabilistic inference are increasingly under
the spotlight as cognitive science moves towards greater
use of Bayesian approaches (e.g., Knill and Richards,
1996; Chater et al. 2006). Strongly facilitating this trend
are the ‘graphical models’ for performing inference with
complex probabilistic information (e.g., Pearl, 1988).
Somewhat obstructing it is the knowledge that Bayesian
inference is computationally intractable (Cooper, 1990).
For some, this intractability does not vitiate the explanatory value of Bayesian inference viewed as an optimal
solution for a cognitive or perceptual problem (e.g., Anderson, 1990). The point is made that such models can
be viewed as theories at a functional level of abstraction,
e.g., the computational level of Marr’s scheme (Marr,
1982). For others, the intractability issue is more concerning (e.g., Danks, 2008).
A more basic problem with Bayesian approaches relates to the constraints that methods of probabilistic
inference place on source information. All standard
methods assume a probabilistic model that implicitly
represents an underlying joint distribution (Russell and
Norvig, 2010). Inference is progressed through marginalization, i.e., constrained summations of values appearing
within this joint distribution. The difficulty is that the
process is then infeasible with regard to probabilistic information that does not properly represent a joint distribution.

366

Formalization

quiring additional assumptions, naı̈ve inference may then
have a use as a least-commitment approach to inference
in the presence of conditional cycles.
The regime also makes connections with noninferential models of mechanism. Accommodation of
cycles means that naı̈ve inference can exhibit looping.
Naı̈ve inference machines have the potential for infinite
processing. In the case where extremal probabilities (1s
and 0s) are deployed, the behaviour is that of a digital
device with iterative behaviour; a connection can then be
made between naı̈ve inference and computation. In fact,
as Section 4 demonstrates, naı̈ve inference machines are
Turing equivalent: they can model any form of computational behaviour. This suggests the potential for explanations unifying modeling of inferential behaviour with
modeling of computational behaviour.
An appealing application of naı̈ve inference is in connection with conventional Bayesian accounts. A difficulty with these is the computational intractability of the
process model. Some accounts cash this out by establishing the means by which processing is implemented (e.g.,
Pouget et al. 2003; Körding and Wolpert, 2006). Others
reserve the right not to do so on grounds of explanatory abstraction (e.g., Chater and Oaksford, 2008b). In
general, there is a need to establish a better connection
between the theoretical ideal of Bayesian inference, and
practical mechanisms by which it can be pursued.
Naı̈ve inference cannot be viewed as approximating
Bayesian inference. But since it treats the semantics of
the conditional probability assertion in the same way,
situations can arise in which both methods produce the
same result. There is then the potential to treat naı̈ve
inference as modeling the ‘bounded rationality’ (Simon,
1957) that ideal rationality must express in practice. Instead of approximating the Bayesian ideal, this introduces a less sophisticated interpretation of what inference involves.
Taking bounded rationality to be modeled by naı̈ve inference does achieve some of the benefits of approximation, however. The process model is no longer computationally intractable. There is also the prospect of better
connections with models of neural processing. Mediated
by simple operations of summation and normalization,
the machinery of naı̈ve inference is likely to be more
easily related to known functionalities of the brain (cf.
Dayan and Abbott, 2001)
The aim of the paper is to set out the proposed model
of naı̈ve probabilistic inference in more detail, to formalize it mathematically, and to examine its potential
uses. There are five main sections. The next section
(Section 2) formalizes the inference model. Section 3 examines the degree to which naı̈ve inference can emulate
ideal Bayesian estimation. Section 4 explores the sense
in which naı̈ve inference machines are Turing equivalent.
Section 5 presents a summary.

In this approach, probabilistic information is assumed
to take the form of probability values for random discrete variables. Conventional notation is used. Thus
P (X = Xi ) denotes the probability that random variable
X has value Xi . If X is boolean, P (X) is a shorthand
for P (X = true).
Given variables X and Y are both boolean, the conditional expression P (X|Y ) expresses the probability that
X is true given Y is true. In naı̈ve inference, this is
understood to directly mandate acts of inference. Identification of an unconditional probability for Y , either
by assumption or (prior) inference, establishes the possibility of inferring an unconditional value of X. Where
inference using multiple conditionals is legitimated, derived products are assumed to contribute equally to the
inferred value, subject to the constraint that probabilities in a distribution must sum to 1.
A probabilistic model is defined to be a set of conditional and unconditional probability values for random
discrete variables. Letting M label such a model, PM (X)
is the unconditional probability of X in model M , and
PM (X|Y ) is the conditional probability of X given Y
in model M . Bold font is used to denote distributions.
Thus PM (X) is the distribution on variable X represented by model M . Given X is boolean, P (X) = 1
becomes a shorthand for P(X) = h1, 0i.
Defining the unnormalized inferred probability for Xi
in model M to be
X
PM (Xi |c)PM (c)
(1)
PM (Xi ) =
c∈C(Xi ,M)

the distribution inferred for X in model M is
P′M (X) = α hPM (X1 ), ..., PM (Xn )i

(2)

In Eq. 1, C(x, M ) is the set of conditions that figure
in conditional probabilities asserted for values of X in
model M , n is the number of values of X, and α is the
normalization function. The inference of Eq. 2 is taken
to be defined just in case the model provides evaluations
for all conditions. That is to say, it is defined if the
model provides unconditional values for all applicable
conditions.
Building on this, we can define the complete set of inferences that can be obtained through application of the
inference step to an existing model. Termed a revision,
this is denoted by adding a prime to the model label.
Thus M ′ denotes the naı̈ve-inferential revision of model
M:
′
M ′ = { P′M (X) | X ∈ M ∧ PM
(X) 6= PM (X)}

(3)

Here, X ∈ M is true if and only if variable X features
in model M .

367

Recursive evaluation of M ′ can then be the means of
generating a sequence of inferential revisions of a particular model. Mi , the i’th model in the sequence, must
satisfy

(i.e. priors) is assumed to represent a joint distribution. The process of inference involves determining unobserved values in this distribution. Where unconditional values are considered to constitute evidence, derived values are posteriors. While the process is computationally intractable (Cooper, 1990), graphical models
such as (Pearl, 1988) are often effective. These allow
the process to be progressed in a way that maximally
exploits independence relationships for factorising calculations.
The naı̈ve model of inference relinquishes the assumption of an underlying joint distribution. Inference is
taken to involve data-driven application of conditional
assertions. However, the two approaches place the same
interpretation on conditional assertions. In both interpretations, it is axiomatic that

′
Mi = Mi−1
=⇒ Mi−1
′
where the ‘=⇒’ operator denotes imposition of Mt−1
′
on Mt−1 . Specifically, M =⇒ M represents addition
of all unconditional values in M ′ to M , with preference
given to values of M ′ where both sets give values for
the same variable. Letting M0 label the set of conditional values in model M , and M0′ be the corresponding
set of unconditional values, the sequence of revisions for
model M then takes a well-defined form. This is denoted
N (M ):

P (X) = P (X|Y )P (Y )

N (M ) = ( M0′ , ..., Mn′ )

given known values for P (Y ) and P (X|Y ). Inference
mediated solely by this rule is thus progressed identically
under naı̈ve and ideal protocols.
This can be illustrated using the ‘sprinkler’ example, a popular scenario for illustrating the behaviour of
Bayesian inference using Bayesian networks (e.g., Pearl,
1988, p. 56). In this example, variable Rain represents
the occurrence of rain, variable Sprinkler represents a
sprinkler being on overnight, and variable GrassW et
representing the grass being wet. These are all boolean
variables taking values T and F, representing true and
f alse respectively. Conditional and unconditional probabilities for these variables are illustrated schematically
in Figure 1.

N (M ) can also be viewed as labeling the naı̈ve inference machine defined by model M . The behaviour of
the machine is production of revisions. The output is
the revision sequence itself.
A simple illustration is provided by the model of Table
1.
P (X = 1) = 1
P (X = 1|X = 1) = 0
P (X = 1|X = 0) = 1

P (X = 0) = 0
P (X = 0|X = 1) = 1
P (X = 0|X = 0) = 0

Table 1: Naı̈ve-inferential oscillator
In this probabilistic model, X is conditionally dependent on itself, but with the conditioned value always being the opposite of the conditioning value. Naı̈ve inference then yields an infinite revision sequence within
which the value of X continually changes between its
two values. Given shorthand representations for binaryvalued distributions, and vertical arrangement of the elements of the sequence, N (M ) evaluates as


{P (X) = 1},
 {P (X) = 0},

N (M ) = 
 {P (X) = 1},
 {P (X) = 0},
...

Sprinkler
Rain
F
T

T
0.4
0.01

F
0.6
0.99

Rain
T

F

1

0

GrassWet








Rain
F
T

Sprinkler
F
F

T
0
0.8

F
1
0.2

F
T

T
T

0.9
0.99

0.1
0.01

Figure 1: Probabilistic model for Rain/Sprinkler/Grass
example.

This is the behaviour of the naı̈ve inference machine
defined by the model of Table 1. The (infinite) sequence
of revisions generated is the output the machine produces.

In this diagram, each variable is represented by a table.
Values of the variable correspond to columns, while rows
represent conditions. Where unconditional values are
given, they appear in the bottom row of a table. Thus,
the unconditional probability of Rain is here shown to
be 1. The conditional probability of GrassW et given

Emulation of ideal Bayesian inference
In optimal Bayesian inference, a probabilistic model
comprising conditional and unconditional probabilities

368

Rain = T and Sprinkler = F is 0.8, and so on. The values shown can be viewed as comprising a probabilistic
model in the present sense of the term. They can also
be regarded as comprising a probabilistic model in the
conventional sense of the term. Indeed, given the simplicity of the model guarantees conditional independence
of GrassW et given Sprinkler and Rain, it also represents a Bayesian network. On this view, the tables are
the conditional probability tables (CPTs) of a standard
Bayesian network.
Say we discover that P (Rain) = 1.0, and wish to infer
the effect on P (Sprinkler). We must decide whether we
wish to treat P (Rain) = 1.0 as the unconditional probability of Rain, or as observed evidence. This makes a difference in the case of the Bayesian network: in one case
the network will calculate new values for Sprinkler and
GrassW et through probabilistic inference. In the other,
priors for these two variables will become implicitly defined. Derived probabilities are the same however. The
emerging prior (or inferred probability) for Sprinkler is
P (Sprinker) = 0.01 and the emerging prior (or inferred
probability) for GrassW et is P (GrassW et) = 0.802.
In this case, optimal Bayesian inference relies purely
on derivation (and normalization) of products. There
is no application of Bayes’ rule. Naı̈ve inference is then
able to emulate the process with the same result. Applying Eq. 2 to the model of Figure 1, the initial revision is
determined to contain P (Sprinkler) = 0.01. It will not
contain a value for GrassW et however, since all the conditions for that variable require unconditional values for
both Rain and Sprinkler. Establishment of an unconditional probability for Sprinker then prompts a second
revision comprising P (GrassW et) = 0.802.
The Bayesian network generates the same posterior
value (or emergent prior) for GrassW et as does naı̈ve inference. Indeed, given the assumption that Sprinkler is
summed-out in the Bayesian network before GrassW et,
the two regimes produce the derivations in the same
order. In simple cases like this, ideal Bayesian inference and naı̈ve inference can produce the same result.
The Bayesian network has a more extensive behavioural
repertoire, of course. Utilizing Bayes’ rule for inverting
conditional probabilities, it could be the means of calculating an unconditional value for Rain given evidence
involving GrassW et, for example.
The key difference between naı̈ve and Bayesian inference is that the former makes no direct use of Bayes’
rule for inverting conditional probabilities. However, this
does not necessarily mean that naı̈ve inference is unable
to reproduce classical Bayesian hypothesis selection. In
this scenario, inference is used to determine the hypothesis that optimally explains certain data, given priors on
the hypotheses and the data, and conditional values for
data given hypotheses (i.e., relevant likelihoods). The
functionality applied, however, involves deriving prod-

ucts of conditional and unconditional values in the usual
way. Naı̈ve inference can thus reproduce the effect provided variables are provided whose unconditional values
are those that would be obtained through application of
Bayes’ rule. On the assumption that such proxies are introduced (or assumed to exist), naı̈ve inference then has
the potential to reproduce hypothesis-selection involving
application of Bayes’ rule. On this basis, naı̈ve inference
can reproduce the classic inferential scenario of Bayesian
estimation.

Introducing a conditional cycle
Naı̈ve inference has the advantage of being able to accommodate models representing conditional cycles. This
effect can be illustrated using a modification of the
‘sprinkler’ example. In the original example, there are
no cycles among the conditions. The conditional structure takes the form of a directed acyclic graph (DAG), as
required for a Bayesian network. Consider now the variation of Figure 2. Here variables Rain and GrassW et
have the same conditional relationship. But we now have
a Humidity variable, which is conditionally dependent on
GrassWet. This produces a conditional cycle in which
GrassWet is made more probable by Rain, Humidity is
made more probable by GrassWet, and Rain is made
more probable by Humidity.
Rain
Humidity
T

GrassWet
Rain
T

T
0.6
1

F
0.4
0

Humidity
T
0.8

F
0.2

GrassWet
T

T
0.4

F
0.6

Figure 2: Model for Rain/Grass/Humidity example.
This cycle violates the conditional-independence requirements of the Bayesian network, and thus the assumption of an underlying joint distribution. Standard
methods cannot be applied but the naı̈ve procedure is
unaffected. Revisions are identified in the usual way.
The presence of the cycle creates the potential for an infinite sequence. But in this case, inference rapidly converges on a particular set of unconditional values. Taking
M to be model of Figure 2, we obtain the following finite
sequence:




N (M ) = 



369

{P (Rain) = 1},
{P (GrassW et) = 0.8},
{P (Humidity) = 0.4},
{P (Rain) = 0.6},
{P (GrassW et) = 0.8},








The original unconditional probability for Rain appears here as the zeroth element of the sequence. Derivation of distributions by Eq. 2 then yields four revisions,
the last of which makes no changes to the model. Inference terminates at this point, with a final probability of
0.8 for GrassW et. This inferred value may be viewed
as reflecting the cyclical dependency between the three
variables. Alternatively, the inferential process may be
viewed as a dynamic projection of the asserted conditional relationships.

table specifies a single transition. For example, the first
entry, says that in state 0 reading symbol #, the machine should write a 1, move right (R), and enter state
1. The symbol # represents an empty tape cell.
State
0
0
0
1
1
1

Emulation of Turing Machines
Attention now given turns to other interpretations that
can be applied to naı̈ve inference. This section examines the sense in which naı̈ve inference is Turing equivalent. By showing that naı̈ve inference can model any
Turing-machine computation, the procedure is shown to
have computational power equivalent to that of a digital
computer, or any other device for effective computation.
A Turing machine is defined in terms of a statetransition table, a ‘tape’ containing a sequence of symbols, and an initial tape position. In each cycle, the
machine reads the symbol from the current position on
the tape and responds by writing a symbol at that position, moving the tape one position left or right, and
entering a new state. The behaviour of the machine is
the result of repeatedly applying such transitions, until
the halt state is reached. The final output obtained is
the revised contents of the tape.
To translate a Turing machine into an equivalent naı̈ve
inference machine we can proceed as follows. For each
cell of the Turing machine’s tape, we introduce a named
variable whose values are the symbols used by the Turing
machine. We introduce variables to represent the current
symbol read, and the current symbol to be written. We
also introduce variables to represent the current state,
the current move, and the current tape position. Finally,
we establish a clocking variable that cycles through a sequence of values representing the read/write/move cycle
of execution. This functionality is achieved through use
of self-referential conditions, as in the model of Table 1.
Probabilities are extremal (i.e., 1s and 0s) in all cases.
Conditional values are configured so that values change
in accordance with the transitions of the Turing machine.
States of the clocking variable are referenced for purposes of sequencing the individual steps of each transition. Execution of the machine then produces extremal
distributions over variables that precisely replicate the
read/write/move states of the Turing machine. Tapecell variables are updated exactly as the Turing machine
updates its tape.
As an illustration, consider the Turing machine defined by the state-transition table of Table 2. The function of this machine is to increment whatever binary
number is represented on its tape. Each entry in the

Read
#
0
1
#
0
1

Write
1
1
0
#
0
1

Move
R
R
L
L
R
R

New state
1
1
0
h
1
1

Table 2: Incrementing Turing Machine
Running the machine with a tape representing a binary number has the effect of producing a binary number on the tape that is one greater than the initial value.
Given an initial tape with contents [# # 1 1 #], and
initial read position at index 4 (i.e., over the final 1),
the machine executes a series of transitions eventually
producing the tape state [# 1 0 0 #].
T0
I
0
0

K
iii
iii

W
#
1

#
1
0

1
0
1

0
0
0

0

iii

0

0
1

0
0

1
0

T1

R
I

T0

K

#

1

0

0
0

#
1

i
i

1
0

0
1

0
0

0
I
1

0
T1
#

i
K
i

0

0

1

1

0

0

I
1

K
iii

W
#

#
1

1
0

0
0

1
1

1
0

i
i

0
0

1
0

0
1

1
1

iii
iii

1
0

0
0
1

1
0
0

0
1
0

I
2
2

T2
#
1

K
i
i

1
0

0
1

0
0

2
I

0
T3

i
K

0

0

1

3
3
3

#
1
0

i
i
i

1
0
0

0
1
0

0
0
1

I
4

T4
#

K
i

1

0

0

4

1

i

0

1

0

4

0

i

0

0

1

T2
I
2

K
iii

W
#

#
1

1
0

0
0

2
2

iii
iii

1
0

0
0

1
0

0
1

0

1

0

T3
I

K

W

#

1

0

3
3
3

iii
iii
iii

#
1
0

1
0
0

0
1
0

0
0
1

0

1

0

S
S
0

R
#

K
ii

0
0

1
1

h
0

0
0

0
1

ii
ii

0
1

1
0

0
0

1
1
1

#
0
1

ii
ii
ii

0
0
0

0
1
1

1
0
0

1

0

0

I
M

M

I

K

0

1

2

3

4

S
0

R
#

K
ii

L
0

R
1

R
R

0
1

iii
iii

0
0

1
0

0
1

0
0

0
0

0
0
1

0
1
#

ii
ii
ii

0
1
1

1
0
0

L
R
L

1
2
2

iii
iii
iii

1
0
0

0
0
1

0
0
0

0
1
0

0
0
0

1
1

0
1

ii
ii

0
0

1
1

R
L

3
3

iii
iii

0
0

0
0

0
1

0
0

1
0

L

4

iii

0
0

0
0

0
0

1
1

0
0

W

K

i

ii

iii

iv

S
0
0

R
#
0

K
ii
ii

#
0
0

1
1
1

0
0
0

0
0

1
0

0
1

0
0

0
1

1
#

ii
ii

0
1

0
0

1
0

0
1

0
0

0
0

1
0

1
1

0
1

ii
ii

0
0

0
1

1
0

1

0

0

0

K

T4
I

K

W

#

1

0

i
ii

4
4

iii
iii

#
1

1
0

0
1

0
0

iii
iv

4

iii

0

0
1

0
0

1
0

Figure 3: Naı̈ve inferential simulation of incrementing
Turing machine.
The equivalent naı̈ve inference machine appears in Figure 3. In this translation, variable R represents the current read, W the current write, S the current state and
M the current move. Variable I is the current tape index and variable K is the three-phase clock. Variables
T 1, T 2, T 3 etc. represent the tape contents at positions
1, 2, 3 etc. To correctly initialize the machine, we include unconditional distributions which have the effect
of setting the clock variable to phase 1, the tape position variable to the appropriate index, and the tape variables to values corresponding to the initial contents of
the tape. The ensuing behaviour then perfectly emulates
the original Turing machine, terminating once the halt
state is reached. Tape-state variables at that point correctly represent the final tape state of the corresponding

370

Turing machine.
This is not the only way to translate a Turing machine
into an equivalent naı̈ve inference machine, of course.
Neither is it claimed to be the best. The demonstration
suffices, however, to show that the behaviour of a Turing machine can be obtained from naı̈ve inference. On
this basis, computational behaviour is contained within
naı̈ve inference, and naı̈ve inference has the capacity to
‘compute’ any computable function.
A better understanding is then obtained of the sense
in which naı̈ve inference addresses the problem of inferential intractability. The protocol does not invoke an
intractable algorithm, due to the fact that it does not
invoke an algorithm of any sort. Rather, it invokes the
general concept of computation. Rather than solving the
problem of intractability, then, naı̈ve inference provides
an interpretation in which the problem does not seem
to apply. A clearer understanding is also obtained of
behavioural possibilities. The demonstration that naı̈ve
inference is able to compute any function implies it can
be the medium for representing any formal structure.
On that basis, a naı̈ve inference machine can then be
the means of applying inferential processes to structural
representations.

tic mind: where next?. In N. Chater and M. Oaksford (Eds.), The Probabilistic Mind: Prospects for
Bayesian Cognitive Science (pp. 501-514). Oxford:
Oxford University Press.
Chater, N. and Oaksford, M. (2008b). The probabilistic
mind: prospects for a bayesian cognitive science. In
N. Chater and M. Oaksford (Eds.), The Probabilistic
Mind: Prospects for Bayesian Cognitive Science (pp.
1-32). Oxford: Oxford University Press.
Chater, N., Tenenbaum, J. and Yuille, A. (2006). Probabilistic models of cognition: conceptual foundations.
Trends in Cognitive Sciences (Special issue on Probabilistic Models of Cognition), 10, No. 7 (pp. 287291).
Cooper, G. (1990). The computational complexity
of probabilistic inference using bayesian belief networks. Artificial Intelligence, 42 (pp. 393-405w).
Danks, D. (2008). In N. Chater and M. Oaksford (Eds.),
The Probabilistic Mind: Prospects for Bayesian Cognitive Science (pp. 59-75). Oxford: Oxford University Press.
Dayan, P. and Abbott, L. (2001). Theoretical Neuroscience: Computational and Mathematical Modelling
of Neural Systems. MIT Press.

Discussion
The paper has proposed a ‘naı̈ve’ method of probabilistic inference that deals with the problem of conditional
cycles. While it cannot be viewed as approximating
Bayesian estimation, it does offer some of the advantages
of an approximation approach. It avoids the problem
of intractability, by linking inference to computation in
general rather than to the action of a specific algorithm.
There may then be implications for ‘the challenge of applying probabilistic methods over structured symbolic
representations’ (Chater and Oaksford, 2008a, p. 510).
The present method addresses that challenge to some
extent by demonstrating a way in which ‘it is possible to
integrate probability with logic’ (ibid.)
Naı̈ve inference offers a novel way to bridge the gap between the ideal of Baysian calculation and the realities of
innately constrained behaviour. Whereas the tradition
of rational analysis involves modeling ‘cognitive abilities using sophisticated forms of probabilistic inference’
(Chater et al. 2006, p. 287), this approach allows them
to be modeled using naı̈ve forms. Rather than assuming
this necessarily involves applying some heuristic approximation of ideal Bayesian calculation, moreover, it can
be taken to involve a non-heuristic procedure operating
under a less sophisticated interpretation of inference.

Hansson, P., Juslin, P. and Winman, A. (2008). The
naı̈ve intuitive statistician: organism—environment
relations from yet another angle. In N. Chater
and M. Oaksford (Eds.), The Probabilistic Mind:
Prospects for Bayesian Cognitive Science. Oxford:
Oxford University Press.
Knill, D. and Richards, W. (Eds.) (1996). Perception as
Bayesian Inference. Cambridge University Press.
Körding, K. and Wolpert, D. (2006). Bayesian decision
theory in sensory motor control. Trends in Cognitive
Sciences, 10 (pp. 319-326).
Marr, D. (1982). Vision. New York: W.H. Freeman.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent
Systems: Networks of Plausible Inference. San Mateo: Morgan and Kaufman.
Pouget, A., Dayan, P. and Zemel, R. (2003). Inference
and computation with population codes. Annual Review of Neuroscience, 26 (pp. 381-410).
Russell, S. and Norvig, P. (2010). Artificial Intelligence:
A Modern Approach (Third Edition). Boston: Pearson.

References
Anderson, J. (1990).
Thought. Erlbaum.

The Adaptive Character of

Simon, H. (1957). Models of Man, Social and Rational:
Mathematical Essays on Rational Human Behavior
in a Social Setting. New York: Wiley.

Chater, N. and Oaksford, M. (2008a). The probabilis-

371

