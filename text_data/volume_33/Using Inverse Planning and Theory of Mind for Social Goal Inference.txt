UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Using Inverse Planning and Theory of Mind for Social Goal Inference
Permalink
https://escholarship.org/uc/item/7f34d3pz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Tauber, Sean
Steyvers, Mark
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

             Using Inverse Planning and Theory of Mind for Social Goal Inference
                                                 Sean Tauber (sean.tauber@uci.edu)
                                              Mark Steyvers (mark.steyvers@uci.edu)
                                   Department of Cognitive Sciences, University of California, Irvine
                                                            Irvine, CA 92697 USA
                              Abstract                                     play an interesting role in our ability to engage in social
                                                                           interaction. For instance, we have to keep track of the
Previous research shows that people assign latent goals or
intentions to simple animated agents based on the motion behavior          information that individuals know or do not know and
of these agents. We propose that human observers can infer that an         combine this with contextual information in order to
animated agent has a partial state of belief about its environment         understand the intentions of others. Others have argued that
and that observers use this information – in combination with the          ToM is much too complex to understand in terms of simply
agent's observable behavior – to infer its goals. We conducted an          having or lacking the ability to represent other's beliefs and
experiment that showed that observers used line-of-sight cues – an         that evidence about the limitations in adult's ToM abilities
agent's orientation relative to various objects in the environment,        may provide insight about the cognitive process(es)
and the presence or absence of visual obstructions – to determine          involved in ToM (Samson & Apperly, 2010). These
the content of an agent's state of belief about the location of            limitations in adults are only beginning to be explored and
objects. Our results are consistent with the hypothesis that human         may lead us to a better understanding of the process or
observers use line-of-sight cues to assign belief states to agents and     processes that underlie the phenomenon that has been
that these belief states can be used to interpret agent behavior. We       referred to broadly as ToM.
found that observer models that incorporated inferences about
agents’ beliefs outperformed an all-knowing observer model in
describing human responses. Additionally, we found that human              The perception of animacy
responses were most consistent with the behavior of a model that           Studying ToM and social goal inference in realistic social
incorporates information about both orientation and line-of-sight          contexts is a difficult undertaking with many uncontrollable
obstructions.                                                              variables. It is therefore useful to develop controlled
                                                                           experiments that allow us to simulate social interactions that
   Keywords: Theory of Mind; ToM; belief states; states of                 are tractable. Heider and Simmel (1944) were the first to
   belief; goal inference; social goal inference; inverse planning;        demonstrate that humans perceived simple two-dimensional
   perceived animacy.                                                      shapes that were animated on a screen as having latent
                                                                           motives, goals and intentions. The motion of these shapes
                          Introduction                                     was designed by an animator – the shapes were not real
Imagine that you are standing across the street from a bank                agents and did not have real latent intentions. Nevertheless,
right before closing time. Suddenly, a car pulls up and four               human observers perceive these shapes as agents with
bank robbers get out of the car and charge into the bank. A                ―minds.‖ This phenomenon is sometimes referred to as the
minute later, another car pulls up and a man jumps out of                  perception of animacy (for a technical description see
the car and runs towards the bank entrance. What is he                     Feldman and Tremoulet, 2008)
doing? Maybe he is trying to stop the robbery or help the                    Modern research that employed the perceived animacy
hostages; or maybe he is rushing to cash a paycheck before                 phenomenon showed that not only did human observers
the bank closes. As it stands, we are missing a key piece of               perceive that the agents had goals; they also appeared to
information that would help us understand the man’s                        perceive that the agents made inferences about the goals of
intentions – whether or not he knows that the robbers are in               other agents (Baker, Goodman, & Tenenbaum, 2008; Baker,
the bank. We are often able to make inferences about the                   Saxe, & Tenenbaum, 2009; Ullman et al., 2010). These
intentions of others based on the context of the situation and             studies showed that not only can people perceive these
their behavior but, as our example shows, sometimes we                     shapes as agents with minds, but they can also perceive
also need to know something about a person’s state of belief               them as agents who can reason about the minds of other
about the world in order to interpret their actions with any               agents.
amount of certainty.
                                                                           Inverse planning
Theory of Mind                                                             Baker, et al. (2008, 2009) showed that a Bayesian inverse
Much research on Theory of Mind (ToM) has focused on the                   planning process provided inferences about the latent goals
ability (or inability) of animals and human children to                    of animated agents that were more similar to human
represent others as having states of belief about the                      inferences than a simple cue-based model. In general, the
environment that are different from their own. The general                 idea of an inverse planning process is that humans have
assumption is that most human adults have this ability                     access to a generative process in which an agent's behaviors
(Premack & Woodroof, 1978; Doherty, 2008). ToM can                         can be generated rationally based on the state of the
                                                                       2480

environment, their own goals, and their inferences about the        The Challenge of modeling ToM
goals of other agents. Humans infer the goals of another            It is challenging to design ToM experiments that involve the
agent by inverting this generative process to infer an agent's      dynamic interaction of multiple agents and are rich enough
goals from its observed behaviors. It is important to note          for observers to perceive the agents as having goals,
that in the aforementioned experiments, the inverse planning        preferences and states of belief, yet remain tractable for the
model assumed (and the human observers were instructed)             application of computational modeling.
that the agents had complete knowledge of the environment              Previous inverse planning research used a Markov
including the position of the other agent(s). This was              Decision Process (MDP) to model continuous agent
potentially important for the inferences that humans made           behavior as a function of its goals and the state of the
because they could assume that an agent had the same                environment (Baker, et al., 2008, 2009). One way to extend
knowledge about the other agent’s behavior as they had.             this framework to account for agents having states of belief
   In our experiment, we eliminate this assumption so that          is to use Partially Observable Markov Decision Process
even though human observers have complete knowledge of              (POMDP). Both MDPs and POMDPs are complex models
the environment, they have the opportunity to take into             of sequentially dependent agent behavior. Because we were
consideration that the agents have incomplete knowledge of          more interested in the role of belief states than in action
the environment.                                                    planning, we chose to simplify the generative action process
                                                                    in such a way that we could avoid modeling sequentially
States of belief                                                    dependent action information. Specifically, we decided to
As demonstrated in our bank robbery example, agents often           reduce agent action sequences down to a single discrete
have incomplete or false beliefs about the state of the             multi-choice decision. The hope was that we would better
environment and this can affect human judgments about the           be able to isolate the effects of the belief state inference
goals of these agents. Our objective for the current study          process on observers' judgments from the effects of the
was to build on the inverse planning and perceived animacy          inverse action planning process.
literature to include situations in which humans would                 Another issue that arises when attempting to isolate the
assign relative or incomplete states of belief to animated          effect of different variables in this type of framework is the
agents and combine this information with the agents’                confounding of goals and priorities. Once an observer has
observable behavior when inferring their goals. In order to         inferred that an agent has a certain belief state and observes
create the perception that agents had different states of           the agent's behavior in light of that belief, the observer can
knowledge about the environment we instructed observers             attempt to use this information to infer the agent's goal.
to assume that agents did not know the location of other            When there are multiple objects in the environment
agents or objects in the environment unless they ―saw‖              however, the agent may have multiple goals – some of
them. We predicted that the perception that agents did or did       which may be more important than others. An observer may
not ―see‖ portions of the environment would be mediated by          not be able to infer a unique set of goals/priorities to explain
the presence or absence of obstructions (such as walls and          an agent's behavior. We address this issue with our Cops
doors) and by orientation cues that would allow observers to        and Robbers paradigm by assuming that most people assign
perceive that the agent was ―looking‖ in a certain direction.       the same constant set of goals and priorities to specific agent
Taken together, we refer to these as line-of-sight cues.            types. Instead of asking observers to infer an unknown
   The usefulness of orientation cues was inspired by               agent's multiple goals and the priority of these goals, we ask
previous research that indicated that these cues influence the      observers to identify the type of agent they are observing –
way observers perceive the intentions of agents in perceived        cop or robber. We eliminate the confounding of goals and
animacy experiments (Gao, Newman, & Scholl, 2009). In               priorities by assuming that cops always want to get the
our case, we hypothesized that observers interpreted the            robber (primary goal), and robbers want to stay away from
orientation of an agent as the direction in which it was            the cop (primary goal) and get the loot (secondary goal).
looking. In order for an agent to ―see‖ another agent or
object in the environment it must have oriented towards that                                Experiment
agent or object and there must not have been any
                                                                    We designed an experiment that used perceived animacy to
obstructions (closed doors) blocking the line of sight. We
                                                                    simulate social interactions in which observers would
predicted that if these two conditions were met then an
                                                                    potentially use line-of-sight cues to track an agent's state of
observer would represent the agent as knowing with
                                                                    belief about the environment and combine this information
certainty the location of the other agent or object. If the two
                                                                    with the agent's motion behavior in order to infer the
conditions were not met – either the agent did not look
                                                                    identity of the agent. The idea was that, given the same
towards the other agent or object; or it did look but there
                                                                    motion behavior, different line-of -sight cues would affect
was an obstruction blocking the line of sight – then an
                                                                    observers' perception of agents' states of belief, which
observer would represent the agent as not knowing with
                                                                    would in turn affect their inferences about the agents'
certainty the location of the other agent or object.
                                                                    identities.
                                                                       Human participants performed a task in which they
                                                                    observed the interactions of two animated agents and had to
                                                                2481

determine the identity of a particular agent based on its
behavior and the state of the environment. We told
participants that one agent was a cop and the other was a
robber but they did not know which agent was which on
each of the trials. We also told participants that the agents’
knowledge of the environment depended on what the agents
could or could not see.
  We varied the relative motion and orientation of one of
the agents with respect to the other agent and the loot; and
we varied the positions of the second agent and the loot, as
well as whether there were visual obstructions (walls)
between the agents and/or between the agents and the loot.
Method
Participants Participants were 28 undergraduate students
from The University of California, Irvine that each received
partial course credit for their involvement in our experiment.
Stimuli The stimuli consisted of 128 brief animations in
which there was an active agent (blue triangle), a static
agent (green triangle) and a static object called the loot (a
red square). For each trial the static objects were in one of
32 possible configurations (figure 1-a) and the active agent
had one of four possible motion sequences (figure 1-b).
Participants were instructed that the interior (gray) doors in
the environment blocked the sight of the agents when they
were closed, but that they always opened when an agent
moved towards them.
Procedure Participants were provided with a background
story for the experiment in which they were told that there          Figure 1. Stimuli: a) shows the four possible positions
were two agents – a cop and a robber. The cop was trying to          for the loot (red square) and static agent (green
catch the robber and the robber was trying to get the loot           triangle) – which was oriented either towards (as
without being caught by the cop. It was not known which              shown) or away from the center room; b) each row
agent was the cop and which was the robber. The                      demonstrates one of the four possible motion
experimental task was to identify the moving agent as either         sequences for the active agent (blue triangle) – the
the cop or the robber for each animation. On each trial              three columns depict the active agent’s starting
participants watched the animation and were presented with           position, orientation behavior, and motion behavior; c)
a choice about the moving (blue) agent’s identity. The               A complete example trial as seen by a human observer
options were ―Cop‖, ―Robber‖ and ―Don’t Know.‖ The                   at 3 different points in time. The blue agent moves
order of the trials was randomized for each participant and          from the left-most room into the intersection, ―looks‖
the order of the options was randomized for each participant         down towards the green agent, and then moves away
on each trial.                                                       from the green agent and towards the loot (which is
                                                                     behind a closed door). Gray doors always opened as
Empirical Results                                                    agent approached them—they obstructed line-of-sight
A comparison of several key trials (Fig. 2) demonstrates the         but not motion.
relative impact of motion, orientation, and visible
obstructions on human judgments and model predictions.             when the active agent had a clear line-of-sight to the other
We will first outline the results of the human judgments           agent and then moved away from it (fig. 2-b-3). When there
before moving on to the model predictions.                         was no line-of-sight because of non-orientation (fig. 2-b-1)
Figure 2-a demonstrates the effect of a wall between the           or the presence of a wall between the agents (fig. 2-b-2)
agents in a trial where the active agent moved towards the         human responses were more uncertain.
other agent. Humans overwhelmingly gave cop responses
when there was no wall between the agents (fig. 2-a-2),            Computational Theory
whereas the presence of a wall resulted in uncertainty in the      Graphical models1 are a useful way to describe the
human responses (fig. 2-a-1).                                      generative process by which human participants respond to
  Figure 2-b demonstrates the effect of walls and
orientation in a trial where the active agent moved away              1
                                                                        For an introduction to graphical model notation, see Koller,
from the other agent. Humans gave mostly robber responses
                                                                   Friedman, Getoor, and Taskar (2007).
                                                               2482

experimental stimuli. We develop four graphical models of
observer behavior and compare the predictions of these
models to the human response data.
   We assume that observers use an inverse planning process
that reverses an action-planning model to infer the identity
of an agent from observations of its actions.
   In order to model the agent’s goal driven behavior as a
single multi-choice decision, we separate each trial into two
distinct phases. The information gathering phase consists of
the agent moving into the center of the maze and its
orientation behavior. All of our models assume that this
sequence of behavior is not generated by the agent’s goal-
directed action planning process, but rather by a random
information gathering process. This random process allows
an observer to infer the agent’s state of belief, but does not
provide any evidence about the agent’s identity. The
decision phase consists of the agent’s movement in one of
the three directions. Our models assume that this behavior
results from the agent’s goal-directed action planning
process and therefore provides evidence about the agent’s
identity. These assumptions allow us to model the agent’s
belief formation and action planning as two separate
processes.
Generative model (agent's perspective) In each trial, the
active agent makes a sequence of observations about the
location of objects in the environment. Figure 3-a is a
graphical model representing the agent’s theory about how
these observations are formed from the true locations of
objects in the environment, whether or not the agent
oriented towards each location and the location of doors
   . From the agent's perspective, the true state         of the
objects is unobserved and the other variables are observed.
   Step one: belief inference In the first step, the agent has a
prior belief that there is equal probability that each of the          Figure 2. Example trials with human results (H) and
objects is in each of the rooms. The agent then uses the               model comparisons (LS, PR, XV and AK). For each
belief model (fig. 3-a) to update the probability that each            example trial: The agent always enters the center room
object is in each room based on its sequence of                        from the left (indicated by arrow); first frame shows
observations, orientations, and its knowledge of the position          direction agent oriented after reaching center
of walls. We refer to the posterior distribution of        as the      (information gathering phase); second frame shows
agent's belief state about the location of object . For                agent motion (decision phase).
example, (           |        ) is the agent’s belief that the
other agent (object          ) is in location four. Applying         priority       for that object of primary, secondary or
Bayes’ rule gives the posterior probability (from the agent's        unimportant. There were two agent types (cop and robber)
perspective) that object       is in location      (Eq. 1). This     and we assumed a constant configuration of goals and
posterior distribution is proportional to the likelihood of the      priorities for each type. Based on its goals, priorities, and
observations , given that was the true location of object            belief state, the agent chooses an action as a sample from
  , multiplied by the prior probability that object was in           a distribution that is proportional to the expected utility of
location .                                                           the actions (eq. 2).
       (        |        )                                                                         (              )
                                                                           (        |      )                                (2)
         ∏ ( |                   ) (          )         (1)                                    ∑ (                  )
   Step two: action planning The belief state that the agent         Inverse model (observer's perspective) Figure 3-c depicts
inferred in step one becomes an observed variable in the             the inverse planning model from the perspective of the
action planning model (fig. 3-b). The model assumes that             observer.
the agent has a goal       with respect to each object and a
                                                                 2483

                                                                      an agent to ―see‖ an object it must orient towards the object
                                                                      and there must not be a closed door in front of the object.
                                                                      Proximity (PR) model This observer does not require
                                                                      orientation for the formation of belief states. It assumes that
                                                                      an agent can ―see‖ an object if it is in an adjacent room and
                                                                      not behind a closed door even if the agent does not orient
                                                                      towards the object.
                                                                      X-ray vision (XV) model This observer assumes that an
                                                                      agent’s belief about the location of objects is a function of
                                                                      its orientation only. For an agent to ―see‖ an object it must
                                                                      orient towards the object – closed doors do not block its
                                                                      line-of sight.
                                                                      All-knowing (AK) model This model corresponds to an
     Figure 3. a) Belief model, b) generative action model            observer that has no ToM. The observer represents the agent
     (agent’s perspective), c) inverse-planning model                 as having the same belief state about the environment that it
     (observer’s perspective). Shaded nodes are observed              has – in this case, complete and correct knowledge of the
     variables and unshaded nodes are unobserved                      environment. It implements only steps two and three of the
     variables.                                                       inverse model where the agent's belief state is equal to the
                                                                      actual state of the environment.
   Step one: belief inference The observer knows the true
state of the environment and infers the agent's belief state          Model Comparison
using a version of eq. 1 where            is replaced with   . We     Figure 4 shows the negative log-likelihood of model
use to represent the agent's belief state as inferred by the          predictions for each participant based on a cross validation
observer. We do not provide the graphical model for this              analysis. We used the responses from all but one participant
step because it is identical to fig. 3-a with the exception that      to optimize a single parameter ( ) that relates to the
     is replaced with       .                                         response mechanism for each of the four observer models.
   Step two: type inference In the second step (fig. 3-c) the         We then used this learned parameter value when predicting
variables that are known to the observer are the agent's              the responses of the participant that was held out of the
belief state       from step one and its action . The observer’s      training data. We did this for every participant. The line-of-
inference about the agent’s type is represented by the                sight model made the best predictions for every participant,
posterior joint distribution (           |     ).                     followed by the proximity model, x-ray model and finally
                                                                      the all-knowing model.
       (       |     )      ( |        ) ( | ) ( )         (3)        Qualitative model comparison Figure 2 provides a
                                                                      comparison of model behavior and human judgments in
   Step three: response The observer chooses a response               several illustrative conditions. All of the models tended to
(“cop”, “robber”, or “don’t know”) based on the posterior             correspond to the human responses on trials in which the
probability of the agent’s type .                                     active agent had a clear line-of-sight to the other agent (figs.
                                                                      2-a-2 & 2-b-3). When there was not a clear line of sight
   See the online appendix2 for a more detailed description           between the agent and the objects, the LS model, and to
of the computational theory and modeling – including a                some extent the PR model, tended to perform better than the
description of the agent's utility function and the observer
response model.
Modeling
We developed four observer models based on the inverse
planning framework—the first model provides a full
description of our hypothesis about the mechanism by
which human observers assign belief states to agents. Each
of the last three models is a version of the full model in
which we remove one of the constraints on belief inference.
Line-of-sight (LS) model This observer assumes that an
agent’s belief about the location of objects is a function of
its orientation and the presence or absence of visual
obstructions (doors) between the agent and the objects. For
   2
     https://webfiles.uci.edu/stauber/Tauber_Steyvers_CogSci2011_
Appendix.pdf                                                              Figure 4. Negative log-likelihood of model predictions.
                                                                  2484

AK and XV models.                                                     agents had complete knowledge of the environment (all-
  Figure 2-a demonstrates the effect of a closed versus open          knowing model).
door between the agents when the target agent is                        Our assumptions about the independence of the
approaching the other agent. The LS and PR models, along              information gathering and decision phases simplified the
with the humans, tended to respond with more uncertainty              model process. However, it is reasonable to argue that in
when there was a closed door (fig. 2-a-1) than the AK and             more realistic situations the information gathering process
XV models did. When there was an open door (fig. 2-a-2),              would depend on the agent’s goals and priorities. In this
the humans and all of the models gave predominantly cop               case an agent’s information gathering behavior depends on
responses.                                                            where it has already looked, what it saw, and what its goals
  Figure 2-b shows the effects of orientation and doors on            are.
human and model behavior when the target agent moves                    Finally, there is a growing body of empirical evidence
away from the other agent. When there is an open door but             suggesting that ToM abilities may involve a combination of
no orientation (fig. 2-b-1) the LS model and humans are               processes that are each used more or less effectively by
uncertain, and the other three models give primarily robber           human children and adults in different situations (Samson &
responses. When the target agent orients towards the other            Apperly, 2010). A new direction for future research is the
agent but there is a closed door between them, the humans,            development of a computational description of the cognitive
LS and PR model responded with uncertainty. The AK and                process(es) involved in ToM that accounts for the wide
XV models gave robber responses. When the target agent                range of failures and successes on ToM tasks by children
oriented towards the other agent and there was an open door           and adults described in the empirical literature.
between them, the humans and all of the models gave
primarily robber responses.                                                                   References
                                                                      Baker, C. L., Goodman, N. D., & Tenenbaum, J. B. (2008).
                          Discussion                                    Theory-based social goal inference. In Proceedings of the
  We propose that observing an agent's actions in the                   Thirtieth Annual Conference of the Cognitive Science
context of the true state of its environment does not always            Society (pp. 1447-1452).
provide enough information for an observer to infer its               Baker, C.L., Saxe, R., & Tenenbaum, J.B. (2009). Action
goals. Often, an observer needs to know something about                 understanding as inverse planning. Cognition, 113, 329-
the agent's state of belief in order to interpret its actions. We       349.
designed an experiment where observers watched a series of            Doherty, M. J. (2008). Theory of mind: how children
animations – in each of which it appeared that an agent                 understand others’ thoughts and feelings. Hove, UK:
moved in a certain direction in order to achieve its goals.             Psychology Press.
Even though there were sets of multiple trials that had               Feldman, J., and Tremoulet, P. D. (2008). The attribution of
equivalent environmental states and agent actions, observers            mental architecture from motion: towards a computational
interpreted the agents' actions differently depending on what           theory. Technical Report RuCCS TR-87, Department of
they thought the agent knew about the environment at the                Psychology, Rutgers University.
time that it made its decision.                                       Gao, T., Newman, G. E., & Scholl, B. J. (2009). The
  Our results are consistent with the hypothesis that human             psychophysics of chasing: A case study in the perception
observers infer an agent's belief state by using information            of animacy. Cognitive Psychology, 59(3), 154-179.
about whether it has a clear line-of-sight to relevant aspects        Heider, F., & Simmel, M. A. (1944). An experimental study
of the environment; and that these inferred belief states               of apparent behavior. American Journal of Psychology,
affect observers' interpretations of the agent's behavior.              57, 243-249.
  We developed four graphical models that each make                   Koller, D., Friedman, N., Getoor, L., and Taskar, B. (2007).
predictions about the structure of the process that humans              Graphical models in a nutshell. In L. Getoor & B. Taskar
use to infer the identity of agents in our experiment. We               (Eds.), Introduction to Statistical Relational Learning.
found that observer models that incorporated inferences                 Cambridge, MA: MIT Press.
about agents’ beliefs outperformed an all-knowing observer            Premack, D. and Woodruff, G. (1978). Does the chimpanzee
model in describing human responses. Additionally, we                   have a theory of mind? The Behavioral and Brain
found that all human responses were most consistent with                Sciences, 4:515–526.
the predictions of a line-of-sight model that required agents         Samson, D., and Apperly, I. A. (2010). There is more to
to both orient and have an obstruction-free line of sight               mind reading than having theory of mind concepts: New
towards a location in order to observe it. The                          directions in theory of mind research. Infant and Child
correspondence between model predictions and human data                 Development, 19, 443-454.
was progressively worse when we 1) assumed agent's                    Ullman, T.D., Baker, C.L., Macindoe, O., Evans, O.,
observed adjacent locations without orienting towards them              Goodman, N.D., & Tenenbaum, J.B. (2010). Help or
(proximity model); 2) assumed visual obstructions did not               hinder:     Bayesian      models       of     social  goal
impede observations (x-ray vision model); 3) assumed                    inference. Advances in Neural Information Processing
                                                                        Systems (Vol. 22, pp. 1874-1882).
                                                                  2485

