UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Category Identification Using Sparse Instance Representation
Permalink
https://escholarship.org/uc/item/9dg1f13m
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Zhang, Shunan
Lee, Michael
Yu, Meng
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

     Modeling Category Identification Using Sparse Instance Representation
                                        Shunan Zhang                                   Meng Yu
                                       Michael D. Lee                                  Jack Xin
                                 {szhang, mdlee} @uci.edu                      {myu3, jack.xin} @uci.edu
                            Department of Cognitive Sciences                    Department of Mathematics
                              University of California, Irvine                University of California, Irvine
                            Abstract                                      The difference between identification and category
                                                                      identification is that the former is about instances, and
   We study the problem of category identification, which             not their categorical structure. The difference between
   involves making inferences about category membership               category identification and categorization is much more
   (e.g., a ‘cat’) given a set of features (e.g., has a tail, has     subtle. The key issue, as described by Kemp et al. (2010,
   four legs). We note that this problem is closely related
   to classification problems in machine learning, for which          p. 230) relates to the sorts of features used to present the
   standard methods exist, and new methods continue to be             stimulus. In categorization, features are presented at the
   developed. Using a large database of associations of fea-          level of instances (e.g., Jack the cat has a tail). In cate-
   tures to animal stimuli, made by different people, we test         gory identification, features are presented at the level of
   several standard benchmark methods, including nearest              categories (e.g., has a tail). Intuitively, categorization is
   neighbor, decision tree, and logistic regression methods.
   We also apply a new classifier, developed for image pro-           about deciding whether a stimulus belongs to a family,
   cessing, which we call Sparse Instance Representation.             whereas category identification is about which family of
   We show that it is the best-performed, especially when             stimuli as a whole is being described.
   constrained in a novel psychologically interpretable way.              It is clear that category identification is an important
   We conclude that our results argue for sparse exemplar-
   based representations of category structures.                      capability, because it allows us to think about stimuli de-
                                                                      scribed by features in terms of their category member-
   Keywords: category identification, sparse representation,          ship. Nestled between identification and categorization,
   machine learning, category learning, exemplar represen-
   tation                                                             category identification blends psychologically interest-
                                                                      ing aspects of both. It maintains the focus on differences
                                                                      and individual instances inherent in identification, while
                                                                      incorporating the focus on sameness and coherence of
                 Category Identification                              conceptual structure inherent in categorization. In partic-
Suppose your friend tells you they are thinking of a par-             ular, category identification offers an interesting window
ticular animal, asks you what type it is, and starts listing          onto the structure of mental representations, since it in-
its features: it has a tail, has four legs, lives inside, and         volves the relationship between categories and features,
so on. You are now facing a category identification prob-             and so requires the representation of both what makes
lem, which requires you to infer the category of a given              stimuli different, and what makes them the same.
instance of that category (Kemp, Chang, & Lombardi,                       In this paper, we use existing data relating stimuli to
2010). In other words, when your friend describes the                 features that can be interpreted in terms of category iden-
features, you are being asked to identify a cat.                      tification. We explore a number of models of these data
   Category identification is clearly closely related to two          based on classification approaches from machine learn-
other cognitive capabilities. One of these is identifica-             ing. We consider a benchmark set of standard classifiers,
tion, which is the problem of inferring which of a set                as well as a new method developed in the image pro-
of instances is being presented, such as recognizing Jack             cessing literature, which we call Sparse Instance Repre-
the cat among a group of individual cats. Identification              sentation, that makes interesting, and psychologically in-
has been widely studied in various subfields of the cog-              terpretable, representational assumptions. We show that
nitive sciences, including psychology (Nosofsky, 1986),               one variant of Sparse Instance Representation is the best-
machine learning and statistics (Bunge & Fitzpatrick,                 performed model of the data, and, based on the results,
1993), and linguistics and philosophy (Michie, Spiegel-               we draw some conclusions about the way people may
halter, & Taylor, 1994). The other related cognitive abil-            represent categories.
ity is categorization, which is problem of inferring the
category membership of presented stimuli, such as de-                                             Data
ciding whether something is a cat or a dog. This has also             Our data come from the Leuven Natural Concept
been widely studied, especially in cognitive psychology               Database (DeDeyne et al., 2008). As summarized by
(e.g., Nosofsky, 1986; Kruschke, 1992; Love, Medin, &                 Storms, Navarro, and Lee (2010), this database involves
Gureckis, 2004)                                                       more than 400 stimulus words, distributed over 16 se-
                                                                  2574

                                                                0.18
                                                                                                   Participant 1
                             P1    P2    P3    P4               0.16                               Participant 2
                                                                                                   Participant 3
           is mammal         1      1     1     1               0.14                               Participant 4
           can fly           0      0     0     0               0.12
                                                                 0.1
           is small          1      1     1     1
                                                                0.08
           has small ears    0      0     1     0
                                                                0.06
           has pointy ears   0      1     1     1
                                                                0.04
           has large eyes    0      0     0     1               0.02
           has round eyes    1      1     0     0                  0
                                                                               Mammal       Bird          Fish   Insect  Reptile
           is hairy          1      1     0     1
           is friendly       0      0     1     1
                                                                Figure 1: Feature-judgment discrepancy for each partic-
           live alone        0      1     1     0
                                                                ipants, on each animal, grouped by animal family.
  Table 1: Examples of feature applicability judgments.
                                                                difficult to distinguish reptiles and amphibians. We com-
mantic categories: two food categories (fruits and veg-         bined the amphibian family and the reptile family, so that
etables), two activity categories (professions and sports),     we had 30 animals from the mammal family, 30 for birds,
six animal categories (amphibians, birds, fish, insects,        23 for fish, 26 for insects and 20 for amphibians and rep-
mammals, and reptiles), and six artifact categories (mu-        tiles.
sical instruments, tools, vehicles, clothing, kitchen uten-
sils, and weapons). For every stimulus word, the                Interpretation as Category Identification Data
database contains data for a large number of variables,         In this paper, we treat the exemplar by feature judgments
including typicality ratings, goodness ratings, goodness        of each of the four participants as providing data relevant
rank order, exemplar generation frequencies, exemplar           to category identification. This is certainly not the only
associative strength, category associative strength, es-        way these data could be interpreted, but we think it is a
timated age of acquisition, word frequency, familiarity         reasonable interpretation. The participant is being asked
ratings, imageability ratings, and pairwise similarity rat-     to decide whether or not each of a large list of features
ings.                                                           applies to a word describing a category. Thus, we can use
                                                                the set of features a participant assigned to a word—“can
Exemplar by Feature Data                                        fly”, “is small”, and so on—as the input to a category
In addition, the database incorporates a large feature gen-     identification problem, where the task is to identify the
eration study, in which 1003 student participants (about        category associated with that list of features.
half participating for course credit, and half paid the              A challenge for the four participants in doing this task
equivalent of $10 per hour) wrote down around 10 fea-           is that many of the category-level features in the Leu-
tures for 6–10 stimuli. Features were generated for each        ven set do not have clear answers. This intuition is made
of the stimulus words by at least 20 participants. Af-          more concrete by the example in Table 1, which shows
ter tallying generation frequencies, all features that were     the feature judgments for the stimulus word “cat” made
generated at least four times were selected. These fea-         by all four participants for some selected features. The
tures were rated for their importance in defining the dif-      first two features—“can fly” and “is small”—are good
ferent categories to which the corresponding stimulus           examples of the features where participants give unani-
words belonged.                                                 mous assessments. Cats as a category cannot fly, and are
   Most importantly for our modeling, the stimuli and           small.
features were combined in a feature verification task, in            But the remaining features in Table 1 focus on the fea-
which four participants (two students, two adults with          tures where there are reasonable differences in the as-
university degrees, paid the equivalent of $10 per hour,        sessments of the participants. Whether a cat “is short
and not including any of the authors of this paper) judged      haired”, “is friendly”, “lives alone”, and so on, is less
whether or not each of the features belonged to each of         clear. The differences in individual assessments high-
the stimuli. This resulted in two large exemplar by fea-        lighted in Table 1 are evident throughout the data. Fig-
ture applicability matrices for each participant, one for       ure 1 shows, for each participant and each animal, the
the animal domain, with 129 animal stimulus words and           proportion of features for which that participant was dif-
765 animal features, and the other for the artifact do-         ferent from all others. It is clear that these differences
main, with 166 artifact stimulus words and 1295 artifact        occur for all animals and all participants.
features. The subset of the database we use involve the
four exemplar by feature matrices for the animal domain.                    Machine Learning Classifiers
Originally, DeDeyne et al. (2008) categorized the animal        The psychological problem of category identification
into six families (mammals, birds, fish, insects, reptiles,     bears a close formal relationship with supervised classi-
amphibians), but also pointed out that people found it          fication methods developed in machine learning. In gen-
                                                            2575

eral, supervised classifiers are algorithmic procedures for      ing a feature at each step, trying to split the data into sub-
assigning a new case into one of a set of pre-defined            sets that belong to the same class. Different criteria for
classes, on the basis of observed attributes (Duda, Hart,        splitting are available, and we used information gain in
& Stork, 2000). Typically, the input to a classifier is a        our implementation (Bishop, 2006).
vector of features, and the output is the indicator of the
                                                                 Sparse multinomial logistic regression (SMLR)
assigned class, or the probability of assignment to each
                                                                 Multinomial logistic regression is a multi-class general-
class.
                                                                 ization of standard binary logistic regression. It gener-
   Thus, it is straightforward to map classifiers to the psy-    ates the logistic distribution of multiple classes using a
chological task of category identification. The problem          linear combination of per-class weights on each of the
is one of taking a set of features—has a tail, has four          dimensions of the input. We employed a multinomial
legs, lives inside, and so on—and mapping them to a cat-         logistic regression method that enforces sparsity using
egory like ‘cat’. This is exactly the psychological prob-        a l1 regularization (Krishnapuram, Figueiredo, Carin, &
lem of category identification. It is also straightforward       Hartemink, 2005), and the implementation was done us-
to use the Leuven dataset to evaluate different classifiers      ing the Princeton Multi-Voxel Pattern Analysis Toolbox
with a standard machine learning methodology. Specif-            (MVPA)1 . The output is a set of probabilities of mem-
ically, we split the exemplar by feature matrices for the        bership of 129 classes. The test sample is then assigned
four participants into training and test sets in a four-fold,    to the class with the highest probability.
leave-one-out, cross-validation. This means, in each val-
idation, we train the classifier using data from three par-      Sparse Instance Representation
ticipants, so that it can learn which features are associ-
ated with each animal, and then test on the data from the        In machine learning, sparse representation has proven
participant left out, so that it has to classify a presented     to be a powerful tool for representing high-dimensional
set of features as one of the animals.                           input with high fidelity (Bruckstein, Donoho, & Elad,
   We believe this link of theory and methods could con-         2009). Some methods, such as SMLR discussed above,
stitute one useful starting point for understanding how          implement sparsity by selecting only a small subset of
people do category induction. It provides set of sophis-         features for classification. Other methods select a small
ticated methods for doing the task, and a natural way            number of observations, rather than features. In Sup-
of evaluating them as benchmarks. It is also possible            port Vector Machine (Vapnik, 1995), for example, only a
to identify psychological assumptions implicit in many           small subset of relevant training samples are selected to
of these methods—such as the nature of the representa-           characterize the decision boundary between classes.
tional assumptions they make—to help guide psycholog-               A new and interesting machine learning method, de-
ical theorizing and model building.                              veloped in the image classification literature, uses the
   We used versions of three standard machine learning           second approach (Wright, Yang, Ganesh, Shankar Sastry,
methods—nearest neighbor, decision trees, and multino-           & Ma, 2009). We call this new method Sparse Instance
                                                                 Representation (SIR), because it represents test samples
mial regression—which we describe only briefly, since
they are well documented in the literature (e.g., Bishop,        in terms of a small number of the training samples them-
2006).                                                           selves. Specifically, the test samples are represented as
                                                                 a linear combination of just a few training samples from
Benchmark Methods                                                the same class. This representation is naturally sparse,
                                                                 involving only a small fraction of the overall input. In-
1-nearest-neighbor (1NN) 1-nearest-neighbor (1NN)                stead of using sparsity to identify a relevant model or rel-
assigns the test sample to the same class as its closest         evant features that can later be used for classifying all test
training sample in the feature space. We implemented             samples, it uses the sparse representation of each individ-
two versions of 1NN. In the first version, we combined           ual test sample directly for classification. In this sense,
the three training matrices to be one with dimension of          it can be considered a generalization of nearest neighbor
764 features by 387 animal instances, with 3 instances           approaches. While SIR has been successful in the image
for each animal that come from different training matri-         applications for which it was developed, we believe ours
ces. In the second version, we found the nearest neighbor        is the first attempt to apply it to a cognitive problem.
of the test sample in each of the training matrices sepa-
rately, and took the majority vote for classification. In        Mathematical framework Mathematically, in a typ-
both versions, distance between two feature vectors are          ical SIR formulation, a dictionary D is constructed as
calculated using the l1 norm.                                    D = [d1 , d2, ..., dn], where each di ∈ Rm is a feature vec-
                                                                 tor of the ith instance. D is an over-complete dictionary if
Decision tree (DT) Decision tree methods classify the            the number of instances n is much larger than the dimen-
test sample based on a learned tree-structure model.             sion of the feature vector m. To reconstruct an instance
Each interior node corresponds to one of the features,           in terms of its feature vector y, SIR uses the equation
branching to different paths based on the value of the cur-      y = Dθ, where a regularization is enforced on θ, such that
rent feature. Each leaf represents a decision class given        only a small number of instances from the dictionary D
the values of the input features represented by the corre-
sponding path. The algorithm works top-down by choos-                1 Available from http://www.pni.princeton.edu/mvpa
                                                             2576

are selected to describe y. A test sample is assigned to the
class with the smallest residual in presenting y as a linear                      Table 2: Cross-validation results.
combination using all instances from the corresponding
class.                                                                                                    Accuracy
                                                                      Method
   For our data, the dictionary D is a m × n matrix with 0-                               Test 1   Test 2   Test 3 Test 4     Ave
1 entries, where m = 764 is the total number of features              1NN V1               .605     .674     .605    .612     .624
and n = no × n p is the total number of instances from all            1NN V2               .628     .682     .643    .674     .657
training matrices, where no = 129 is the number of in-                DT                   .388     .558     .543    .426     .480
stances for an individual training matrix, and n p = 3 is             SMLR                 .612       –      .775    .411     .599
the number of training matrices. Thus, each class (cate-              SIR                  .659     .729     .744    .605     .684
gory) has n p instances, in the form of three feature vec-            NonNeg SIR           .760     .760     .783    .659     .740
tors (columns) in D. A test sample is in the form of a
feature vector y of the size m × 1.
   By re-aligning the dictionary matrix D, columns are
grouped by animal. Thus D can be rewritten as D =                   where θk has size n p × 1. Its elements are n p linear
[D1 , D2, ..., Dno ], where each Dk , k = 1, 2, ..., no, has di-    weights of the n p instances of the kth animal, features
mension m × n p . For a given test sample with feature              of one instance thus receive the same weight. Finally,
vector y, SIR assumes that y can be expressed by a linear           the test sample is identified by
combination of columns in subset Dk0 that is of the same
                                                                                        Index(y) = arg min rk (y)             (5)
class as y.                                                                                               k
                              np
                         y = ∑ θik0 Dik0 ,                   (1)    Non-Negative Variant A novel and psychologically
                             i=1                                    interpretable variant of SIR places a non-negative con-
                                                                    straint on the linear expression weights in θ. Therefore,
where Dik0 is the ith column of Dk0 . Since the class mem-
                                                                    the l1 regularized unconstrained convex optimization in
bership of y is yet unknown, it is necessary to consider            Equation 3 becomes a non-negative penalized l1 regular-
global linear combination of all the columns in D, thus             ized unconstrained convex optimization:
                                 no n p                                                      1
                     y = Dθ =    ∑ ∑ θik Dik .               (2)            θ∗ = arg min ky − Dθk22 + µ kθk1 , θ ≥ 0.         (6)
                                                                                         θ 2
                                k=1 i=1
                                                                    The natural psychological interpretation is that this con-
However, only those instances from the same class (e.g.
                                                                    straint forces representations that include only instances
k0 ) of y are highly relevant, whereas the features of other
                                                                    that provide evidence for a category identification deci-
instances are much less relevant. In theory, only n p fea-
                                                                    sion.
ture vectors of training samples that belong to k0 con-
tribute to the expression of y, which means globally the
                                                                                                 Results
linear expression weights in θ are sparse.
   The convex objective function is                                 We used the Split Bregman method (Goldstein & Osher,
                                                                    2009) to solve the optimization task, both without and
                  θ∗ = arg min kθk1 , y = Dθ.                       with non-negative restriction.2 We describe overall per-
                            θ                                       formance of the classifiers, then focus on the details of
                                                                    the SIR classifier.
where kθk1 denotes the l1 norm of θ. However, based
on the data, m > n for the dimension of matrix D. This              Accuracy
means the dictionary D is non-overcomplete, because the             We measured the performance of each method using ac-
equation y = Dθ is overdetermined, where the number                 curacy, which is simply the proportion of correctly clas-
of equations is larger than the number of unknown vari-             sified animals. Table 2 details the accuracies for all of
ables. In this case, the equation usually does not hold.            the classifiers on each of the four cross-validations, as
Instead, we place it in the objective function by incor-            well as average accuracy.3 It is clear that SIR outper-
porating a trade-off parameter µ, where µ can be tuned              formed the other benchmark methods, especially with
for speed of convergence, we fixed µ value in this study.           the inclusion of the non-negativity constraint. Nearest
Thus the objective becomes,                                         neighbor classifiers were the next best performed, fol-
                                                                    lowed by sparse multinomial logistic regression, and de-
                            1
             θ∗ = arg min ky − Dθk22 + µ kθk1 .              (3)    cision trees.
                         θ 2                                           We think the variation in accuracy across the cross-
                                                                    validations may be interpretable in terms of individual
Decision criterion After obtaining the sparse solution
θ∗ , we calculate the residuals                                         2 A technical note regarding details of implementation is
                                                                    available at http://www.socsci.uci.edu/∼szhang/research.htm
            rk (y) = ky − Dk θk k22 , k = 1, 2, ..., no,     (4)        3 Note that SMLR did not converge on Test 2.
                                                                2577

  0.5
    0
−0.5
               tiger                                     tiger                               tiger
  0.5
             l                                     r
         me                                   sa
                                                 u
      ca                                    o            n wolf
          lio
              n                         din          lio                                         fox
    0
                           orc                                                    ge                         co
                                                                                    ck                         d
                               a                                                       o
−0.5
               tiger                                     tiger                               tiger
  0.5
    0
−0.5
               tiger                                     tiger                               tiger
Figure 2: Weights on all instances in the training data learned for ‘tiger’, using (upper panel) no regularization, (middle
panel) sparse regularization, and (lower panel) non-negative sparse regularization, colored by participant.
differences in representation. Classification accuracy              zontal axis). For each test category and a potential cate-
was almost always lowest when the feature assignments               gory, we summed the estimated weights of all 3 instances
of participant 4 were used for testing. Referring back to           of the potential category, resulting in a weight-sum asso-
the individual differences in agreement in Figure 1, we             ciated with the specific pair. For each pair, values across
note that participant 4 shows more discrepancy in their             tests are further summed to yield the value shown.
representations of animals.                                            Clearly, the sparse weights are generally assigned to
                                                                    instances from the correct category, illustrated by over-
Selected Instances                                                  all larger values along the diagonal, whereas instances
Figure 2 gives an example of the instance-based repre-              from wrong categories received much lower weights, il-
sentations used by SIR, for the example ‘tiger’. Each               lustrated by the shaded areas off the diagonal. Another
panel shows the weights for all of the animals for the              interesting pattern is shown by the five squares along the
three training participants concatenated together. The top          diagonal, each containing all pairs within an animal fam-
panel shows the case when no regularization is used. The            ily (mammal, bird, fish, insect and reptile). This illus-
middle panel shows the case when sparse regularization              trates the within-category similarity in weighting that re-
is used. The bottom panel shows the case when the non-              flects the natural conceptual structure.
negativity constraint is placed on sparse regularization.
   To give some intuitions about the instances selected                                     Discussion
by the regularization processes, the middle panel labels
a number of animals besides tiger that receive significant          The critical representational assumption of SIR is that
positive or negative weights. For example, the third par-           sparsity in enforced in terms of instances. All features
ticipant, to the right, uses both ‘fox’ and ‘cod’ as well as        from the same instance receive the same weight, but dif-
‘tiger’ in their representation, with fox features contribut-       ferent instances receive different weights. The insight
ing positive evidence and cod features negative evidence.           is that, although features are naturally very high dimen-
In the non-negative regularization, only fox continues to           sional, instances belonging to the same class lie approxi-
contribute. The other participants use other animals to             mately in low-dimensional feature subspaces. If a collec-
represent tiger, again showing individual differences, but          tion of representative samples can be found, it is possible
use animals that are easily interpreted in terms of the ev-         to represent a typical sample with respect to the basis
idence their features provide for identification.                   they form.
   Another analysis is presented in Figure 3, which                    The decision-making assumptions of SIR are simple,
shows the weight distribution across all pairs of a test            and assume a linear combination of the basis instances in
category (vertical axis) and any potential category (hori-          doing category identification. One potentially important
                                                                2578

                                                                          modeling of signals and images. SIAM Review, 51,
                                                                          34–81.
Mammal
                                                                    Bunge, J., & Fitzpatrick, M. (1993). Estimating the num-
                                                                          ber of species: A review. Journal of the American
                                                                          Statistical Association, 88, 364–373.
                                                                    DeDeyne, S., Verheyen, S., Ameel, E., Vanpaemel, W.,
    Bird
                                                                          Dry, M., & Voorspoels, W. (2008). Exemplar by
                                                                          feature applicability matrices and other Dutch nor-
  Insect
                                                                          mative data for semantic concepts. Behavior Re-
                                                                          search Methods, 40, 213–231.
    Fish
                                                                    Duda, R. O., Hart, P. E., & Stork, D. G. (2000). Pattern
                                                                          classification. Wiley.
 Reptile
                                                                    Goldstein, T., & Osher, S. (2009). The split Bregman al-
                  Mammal       Bird    Insect     Fish  Reptile
                                                                          gorithm for l1 regularized problems. SIAM Journal
                                                                          of Imaging Science, 2, 323–343.
         Figure 3: Overall weight distribution for SIR.             Kemp, C., Chang, K. M., & Lombardi, L. (2010). Cate-
                                                                          gory and feature identification. Acta Psychologica,
                                                                          133, 216–233.
contribution we have made is to identify a non-negativity           Krishnapuram, B., Figueiredo, M., Carin, L., &
constraint on the weights as leading to better SIR perfor-                Hartemink, A. (2005). Sparse multinomial logis-
mance on category identification data. This focus on in-                  tic regression: Fast algorithms and generalization
stances that are evidence for a category mirrors findings
                                                                          bounds. IEEE Transactions on Pattern Analysis
in the similarity modeling literature that emphasize the
role of positively weighted common features in stimulus                   and Machine Intelligence, 27, 957-968.
representation (e.g., Navarro & Lee, 2004).                         Kruschke, J. K. (1992). ALCOVE: An exemplar-based
    Thus, the superior performance of SIR in our evalu-                   connectionist model of category learning. Psycho-
ations support the idea that people represent stimuli in                  logical Review, 99, 22–44.
terms of sparse sets of the relevant instances. This is             Love, B. C., Medin, D. L., & Gureckis, T. (2004). SUS-
a natural extension of prominent and successful exem-                     TAIN: A network model of category learning. Psy-
plar theories of concept representation (Nosofsky, 1986).                 chological Review, 111, 309–332.
It assumes that specific stimuli are the basis of concept           Michie, D., Spiegelhalter, D. J., & Taylor, C. C. (1994).
representation, but implies that relatively few key stim-                 Machine Learning, Neural and Statistical Classi-
uli are used. This is what is done—by various specific
                                                                          fication. Prentice Hall.
mechanisms–by a number of existing models of cate-
gory learning, including the original ALCOVE model                  Navarro, D. J., & Lee, M. D. (2004). Common and dis-
(Kruschke, 1992), SUSTAIN (Love et al., 2004), and                        tinctive features in stimulus similarity: A modified
the Varying Abstraction Model (Vanpaemel & Storms,                        versionof the contrast model. Psychonomic Bul-
2008). Useful next steps are to apply these sorts of psy-                 letin & Review, 11(6), 961–974.
chological models to account for the category identifi-             Nosofsky, R. M. (1986). Attention, similarity and the
cation behavior, and to explore their formal relationship                 identification-categorization relationship. Journal
to machine learning methods like SIR, and related case-                   of Experimental psychology: General, 115, 39-57.
based reasoning systems (e.g., Aamodt & Plaza, 1994).               Storms, G., Navarro, D. J., & Lee, M. D. (2010). Intro-
                                                                          duction to the special issue on formal modeling of
                     Acknowledgments                                      semantic concepts. Acta Psychologica, 133, 213–
We thank Max Welling and Qiang Liu, and members of                        315.
the Memory and Decision-making Laboratory at UCI.                   Vanpaemel, W., & Storms, G. (2008). In search of ab-
                                                                          straction: The varying abstraction model of cate-
                         References                                       gorization. Psychonomic Bulletin & Review, 15,
Aamodt, A., & Plaza, E. (1994). Case-based reason-                        732–749.
          ing: Foundational issues, methodological varia-           Vapnik, V. (1995). The nature of statistical learning
          tions, and system approaches. Artificial Intelli-               theory. Springer-Verlag.
          gence Communications 7, 1, 39–52.                         Wright, J., Yang, A. Y., Ganesh, A., Shankar Sastry, S.,
Bishop, C. M. (2006). Pattern recognition and machine                     & Ma, Y. (2009). Robust face recognition via
          learning. Springer.                                             sparse representation. IEEE Transactions on Pat-
Bruckstein, A., Donoho, D. L., & Elad, M. (2009). From                    tern Analysis and Machine Intelligence, 31, 210–
          sparse solutions of systems of equations to sparse              227.
                                                                2579

