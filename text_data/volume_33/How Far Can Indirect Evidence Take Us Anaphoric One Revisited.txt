UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How Far Can Indirect Evidence Take Us? Anaphoric One Revisited
Permalink
https://escholarship.org/uc/item/8wc5w9d2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Pearl, Lisa
Mis, Benjamin
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

              How Far Can Indirect Evidence Take Us? Anaphoric One Revisited
                                                     Lisa S. Pearl (lpearl@uci.edu)
                                                      Department of Cognitive Sciences
                                                          3151 Social Science Plaza
                                                               Irvine, CA 92697
                                                     Benjamin Mis (bmis@uci.edu)
                                                      Department of Cognitive Sciences
                                                          3151 Social Science Plaza
                                                                Irvine, CA USA
                              Abstract                                            syntactic antecedent of one = “red bottle”
                                                                                  semantic referent of one = RED BOTTLE
   A controversial claim in linguistics is that children face an in-
   duction problem, which is often used to motivate the need for              The original proposal for learning anaphoric one required
   Universal Grammar. English anaphoric one has been argued
   to present this kind of induction problem. While the original           children to have innate domain-specific knowledge about the
   solution was that children have innate domain-specific knowl-           structure of language, as part of the child’s Universal Gram-
   edge about the structure of language, more recent studies have          mar (Baker, 1978). However, more recent studies have sug-
   suggested alternative solutions involving domain-specific in-
   put restrictions coupled with domain-general learning abilities.        gested alternative solutions involving innate domain-general
   We consider whether indirect evidence coming from a broader             learning abilities coupled with input restrictions that arise
   input set could obviate the need for such input restrictions. We        from domain-specific learning constraints (Foraker et al.,
   present an online Bayesian learner that uses this broader input
   set, and discover it can indeed reproduce the correct learning          2009; Pearl & Lidz, 2009; Regier & Gahl, 2004).
   behavior for anaphoric one, given child-directed speech. We                Here, we consider whether indirect evidence leveraged
   discuss what is required for acquisition success, and how this          from a broader input set could lead children to the correct
   impacts the larger debate about Universal Grammar.
                                                                           knowledge for anaphoric one. If so, we can then refine the
   Keywords: anaphoric one; acquisition; Bayesian learning;
   domain-general; domain-specific; indirect evidence; input re-           current views on what is required for successful acquisition -
   strictions; language; online probabilistic learning; poverty of         and specifically, whether it is (i) domain-specific or domain-
   the stimulus; Universal Grammar                                         general, and (ii) innate or derivable.
                                                                              We first discuss adult and child knowledge of anaphoric
   Induction problems in language acquisition                              one, and then review previous proposals for how to learn this
One of the most controversial claims in developmental and                  from the available input. We then motivate why a child might
theoretical linguistics is that children learning their native lan-        view a broader input set as informative for anaphoric one.
guage face an induction problem, sometimes called “Poverty                 Following this, we present an online Bayesian learner that
of the Stimulus” (Chomsky, 1980; Crain, 1991). Simply put,                 uses this broader data set, and find that our learner is indeed
this is the claim that the data in children’s input are insuffi-           capable of reproducing the behavior associated with correct
cient to identify the correct language knowledge as quickly                knowledge of anaphoric one without imposing any domain-
as children seem to.                                                       specific input restrictions. We conclude with discussion of
   If this is true, then children must bring something to the              what is required for acquisition success, and how this impacts
language acquisition problem - and the nature of this “some-               the larger debate about Universal Grammar.
thing” is often debated. Is it domain-specific or domain-
general? Is it something derivable from prior experience or                                  English anaphoric one
something necessarily innate? These questions are impor-                   Adult knowledge
tant, as induction problems in language acquisition are of-
                                                                           The adult representation of English anaphoric one has both
ten used to motivate innate, domain-specific knowledge about
                                                                           a syntactic and semantic component. In order to interpret an
language (Universal Grammar (Chomsky, 1965)).
                                                                           utterance like (1), the listener must first identify the syntactic
   The potential induction problem presented by English
                                                                           antecedent of one, i.e., what string one is replacing. In (1),
anaphoric one (1) has received considerable recent attention
                                                                           adults interpret one’s antecedent as “red bottle”, so the utter-
(e.g., Foraker, Regier, Khetarpal, Perfors, and Tenenbaum
                                                                           ance is equivalent to “Look - a red bottle! Oh, look - another
(2009); Lidz, Waxman, and Freedman (2003); Pearl and Lidz
                                                                           red bottle!”
(2009); Regier and Gahl (2004)).
                                                                              Then, the listener uses this syntactic antecedent to identify
   (1) Anaphoric one                                                       the semantic referent of one, e.g., what object in the world
   Situation: Two red bottles are present.                                 one is referring to. Given the syntactic antecedent “red bot-
   Utterance: “Look - a red bottle! Oh, look - another one!”               tle”, adults interpret the referent of one as a bottle that is red
   Interpretation of one:                                                  (RED BOTTLE), as opposed to just any bottle (BOTTLE). Ac-
                                                                       879

cording to standard linguistic practice, the string “red bottle”              that there is also ambiguity with respect to the semantic ref-
has the structure in (2), while “a red bottle” has the structure              erent (e.g., RED BOTTLE vs. any BOTTLE). Examples (6) and
in (3):                                                                       (7) demonstrate two kinds of ambiguous data.
    (2)        [N 0 red [N 0 [N 0 bottle]]                                       (6) Syntactic (Syn) Ambiguity
    (3) [NP a [N 0 red [N 0 [N 0 bottle]]]                                       Situation: There are two bottles present.
                                                                                 Utterance: “Look, a bottle! Oh look - another one!”
    The syntactic category N0 can only contain nouns (e.g.,
“bottle”), and the category NP contains any noun phrase (e.g.,                   (7) Semantic and Syntactic (Sem-Syn) Ambiguity
“a red bottle”). The syntactic category N’ is larger than N0 but                 Situation: There are two red bottles present.
smaller than NP, and can contain both nouns (e.g., “bottle”)                     Utterance: “Look, a red bottle! Oh look - another one!”
and noun+modifier strings (e.g. “red bottle”). Note that the
                                                                                 Syn ambiguous data do not clearly indicate the category of
string “bottle” can be labeled both as syntactic category N’
                                                                              one, even though the semantic referent is clear. In (6), the
(4a) and syntactic category N0 (4b).1
                                                                              semantic referent must be BOTTLE since the antecedent can
    (4a) [N 0 [N 0 bottle]]                                                   only be “bottle”. But, is the syntactic structure [N 0 [N 0 bottle]]
    (4b)      [N 0 bottle]                                                    or just [N 0 bottle]? Notably, if the child held the mistaken
                                                                              hypothesis that one was category N0 , this data point would
    Linguistic theory posits that anaphoric elements only have
                                                                              not conflict with that hypothesis since it is compatible with
antecedents of the same syntactic category. Since one’s an-
                                                                              the structure being [N 0 bottle].
tecedent can be “red bottle”, then one should be category N’
                                                                                 Sem-Syn ambiguous data are unclear about both the ref-
in these cases. Notably, if the syntactic category of one were
                                                                              erent and the category of one. In (7), if the child held the
instead N0 , one could not have “red bottle” as its antecedent;
                                                                              mistaken hypothesis that the referent is simply BOTTLE (un-
instead, it could only have noun-only strings like “bottle”, and
                                                                              like the adult interpretation of RED BOTTLE), this would not
we could not get the interpretation that we do for (1).
                                                                              be disproven by this data point - there is in fact another bot-
    One way to represent adult knowledge is (5):
                                                                              tle present. This data point is ambiguous syntactically for the
    (5) Adult anaphoric one knowledge in utterances like                      same reason Syn data like (6) are: if the referent is BOTTLE,
        “Look - a red bottle! Do you see another one?”                        then the antecedent is “bottle”, which is either N0 or N’.
    (a) Syntactic structure: category N’                                         Fortunately, there are some unambiguous data available
    (b) Semantic referent: The mentioned property (“red”) is                  like (8), but these require a very specific conjunction of situ-
        relevant for determining the referent of one.                         ation and utterance.
Child knowledge                                                                  (8) Unambiguous (Unamb) data
                                                                                 Situation: Both a red bottle and a purple bottle are present.
Behavioral evidence from Lidz et al. (2003) (henceforth                          Utterance: “Look - a red bottle! There doesn’t seem to be
LWF) suggests that young children also have this same in-                                     another one here, though.”
terpretation for utterances like (1). LWF examined the look-
ing behavior of 18-month-olds when hearing an utterance like                     In (8), if the child mistakenly believes the referent is just
“Look, a red bottle! Do you see another one?”. The 18-                        BOTTLE ,   then the antecedent of one is “bottle” and it’s sur-
month-olds demonstrated a significant preference for looking                  prising that the speaker would claim there’s not “another bot-
at the bottle that was red (as compared to a bottle that was                  tle here”, since another bottle is clearly present. Thus, this
some other color). LWF interpreted this to mean that by 18                    data point unambiguously indicates that the property “red” is
months, children have acquired the same representation for                    important, so the semantic referent is RED BOTTLE. The cor-
anaphoric one that adults have.                                               responding syntactic antecedent is “red bottle”, which has the
                                                                              syntactic structure [N 0 red [N 0 [N 0 bottle]]] and indicates one’s
                    Learning anaphoric one                                    category is N’.
                                                                                 Unfortunately, unambiguous data comprise only a small
The learning problem
                                                                              fraction of children’s input - LWF discovered that a mere
Learning the correct representation for anaphoric one is diffi-               0.25% of child-directed anaphoric one utterances were un-
cult because many anaphoric one data are ambiguous with re-                   ambiguous data. For this reason, the debate has arisen about
spect to what syntactic category one is, even if children know                how children might solve this acquisition problem as rapidly
that the choice is between N’ and N0 . Moreover, as we saw                    as they do.
in (2), sometimes there is more than one N’ antecedent to
choose from (e.g., “red bottle” vs. “bottle”), which means                    Innate, domain-specific knowledge
     1 We
                                                                              An early proposal (Baker, 1978) (henceforth Baker) assumed
           note that the actual labels themselves are immaterial. It is
only relevant that these structural levels are distinguished in this way,     that only unambiguous data were informative. Given the
i.e., that “red bottle” and “bottle” are the same label (N’ here), while      sparsity of these data, it was proposed that children possess
“bottle” can also be labeled with a smaller category label (N0 here).         domain-specific knowledge about the structure of language -
                                                                          880

in particular, children innately know that anaphoric elements           (9) “Look at the cute penguin. I want to hug it/him/her.”
(like one) cannot be syntactic category N0 . Instead, children          ≈ “Look at the cute penguin. I want to hug the cute penguin.”
automatically rule out that possibility from their hypothesis
space, and simply know that one is category N’.                         Here, the antecedent of the pronoun it/him/her is the NP
                                                                     “the cute penguin”:
Domain-general learning abilities +
                                                                        (10) [NP the [N 0 cute [N 0 [N 0 penguin]]]]
domain-specific input restrictions
Regier and Gahl (2004) (henceforth R&G) noted that Sem-                 In fact, it turns out that one can also have an NP antecedent:
Syn data like (7) could be leveraged to learn the correct rep-          (11) “Look! A red bottle. I want one.”
resentation for anaphoric one. Specifically, a learner with             ≈ “Look! A red bottle. I want a red bottle.”
domain-general statistical learning abilities could track how
often a property that was mentioned was important for the               So, the issue of one’s syntactic category only occurs when
referent to have (e.g., when “red” was mentioned, was the            one is being used in a syntactic environment that indicates it
referent just a BOTTLE or specifically a RED BOTTLE?). If            is smaller than NP (examples of this <NP environment are in
the referent had that property (e.g., was a RED BOTTLE), this        (1), (6), (7), and (8)). Notably, one shares some semantic and
meant that the syntactic antecedent of one would be an N’            syntactic distribution properties with other pronouns.
string (e.g., “red bottle”) and implicated one’s category as N’.        Following R&G’s idea, a learner could track how often a
The R&G data set consisted of both unambiguous data and              property mentioned in the potential antecedent (e.g., “red” in
Sem-Syn ambiguous data, and their online Bayesian learner            “a red bottle” in (11)) is important for the referent to have.
was able to learn the correct interpretation for anaphoric one.      Crucially, we can apply this not only to data points where
No innate, domain-specific knowledge was required.                   one is <NP ((6) and (8)), but also to data points where pro-
    Pearl and Lidz (2009) (henceforth P&L) noted that if the         nouns are used anaphorically and in an NP syntactic environ-
child had to learn the syntactic category of one, an equal-          ment ((9) and (11)). When the potential antecedent mentions
opportunity (EO) learner would view Syn ambiguous data               a property and the pronoun is used as an NP, the antecedent
like (6) as informative. Unfortunately, Syn ambiguous data           is necessarily also an NP, and necessarily includes the men-
far outnumber the Sem-Syn ambiguous and unambiguous                  tioned property (e.g., “a red bottle”). Data points like (9) and
data combined (about 20 to 1 in their corpus analysis), and          (11) are thus unambiguous both syntactically (category=NP)
in fact lead a probabilistic learner of the kind R&G propose         and semantically (the referent must have the mentioned prop-
to the wrong syntactic category for one (i.e., one=N0 ). Thus,       erty). We will refer to them as unambiguous NP (Unamb
R&G’s Bayesian learner would have to explicitly filter out the       NP) data points, and these are the additional data points our
Syn ambiguous data. P&L suggested that this kind of filter           learner (henceforth the P&M learner) will learn from.
is domain-specific, since it involves ignoring a specific kind          Like the R&G and P&L learners, our learner differs from
of linguistic data, though they speculate how this restriction       the Baker learner by learning from data besides the unam-
could be derived from domain-general learning preferences.           biguous <NP data. However, our learner differs from the
    Foraker et al. (2009) (henceforth F&al) focused on iden-         learners in R&G and P&L by learning from data containing
tifying the syntactic category of one, applying an ideal             anaphoric elements besides one.2 Table 1 shows which learn-
Bayesian learner to the syntactic input alone. Their learner         ers use which data.
employed subtle conceptual knowledge to identify the likely
syntactic category for one (specifically, a syntactic comple-                        Table 1: Data sets used by learners.
ment is “conceptually evoked by its head noun” and indicates
the noun string is N0 , while a modifier is not and indicates
                                                                       Data type              Example       Learners
the noun string is N’). While there were not many informa-
                                                                       Unamb <NP              (8)           Baker, R&G, P&L’s EO, P&M
tive one data points in their data, their ideal learner was able
                                                                       Sem-Syn Ambig          (7)           R&G, P&L’s EO, P&M
to learn that one was category N’. Their learner required a
                                                                       Syn Ambig              (6)           P&L’s EO, P&M
domain-specific input restriction to syntactic data as well as
                                                                       Unamb NP               (9), (11)     P&M
domain-specific knowledge about the subtle distinction be-
tween complements and modifiers, and their implications for
syntactic categories.
                                                                     Information in the data
         A broader view of informative data
Instead of restricting the input set, we consider expanding it       Figure 1 represents the information dependencies in any data
beyond unambiguous (8), Sem-Syn ambiguous (7), and Syn               point where a pronoun is used anaphorically and there is a
ambiguous (6) data. Consider that there are other anaphoric          potential antecedent that has been mentioned recently.
elements in the language besides one, such as pronouns like              2 Our learner also differs from the F&al learner by leveraging
it, him, her, etc. These pronouns are category NP, since they        both syntactic and semantic information, instead of just syntactic
replace an entire noun phrase (NP) when they are used (9):           information.
                                                                 881

   !"#$%&'()*&+,#-,).))                   *'""#+,)'(01#).)!"&+&'+)
       (*+&,-.&"()&/#01(-/)                 (*+&,-.$#23("&#$(-4&
                                                                            actual antecedent string ∈ {“red bottle”, “bottle”, etc.}
                                                                            object referred to ∈ {has property, does not have property}
      23432356789)756356)                   :;568<67<)=:8>3)
    !"#;("26&>($8#$()?&                      !"#$#%$&%'()&                  The data types used by the different learners have the ob-
    !"#;("26&=>;#"2.$2?&             56$2.787&7.2(9#"6&#:&;"#$#%$&       servable values in Table 2.
    @$2(7()($2&'2"=$9&            @$2(7()($2&'2"=$9&    56$2.787&
    =$71%)('&;"#;("26?&           =$71%)('&>#)=D("?&    ($<="#$>($2&
                                                                                   Table 2: Data types and observable values.
                                                                           Data type          PropMent        Pronoun    SynEnv     Obj
                                                                           Unamb <NP          Yes                   one     <NP     has prop
                    @72%.1&.$2(7()($2&'2"=$9&                              Sem-Syn Ambig      Yes                   one     <NP     has prop
                                                           A/'("<()&
                                                                           Syn Ambig          No                    one     <NP     N/A
                        A/B(72&"(:(""()&2#&                C.2($2&         Unamb NP           Yes          it, one, etc.      NP    has prop
       Figure 1: Information dependencies in data points.                   The online probabilistic learning framework
                                                                         Important quantities
   Under S YNTACTIC U SAGE, we can observe which pro-                    The two components of the correct representation for
noun is used (e.g., it, one, etc.). The syntactic category de-           anaphoric one are (a) that a property mentioned in the po-
pends on which pronoun is used (e.g., NP, N’, or N0 for                  tential antecedent is important for the referent of one to have,
one). We can observe the syntactic environment in which                  and (b) that one is category N’ when it is not an NP. These
the pronoun is used, which depends on the syntactic cate-                correspond to “property important?” and “syntactic category
gory (e.g., “another one” indicates a syntactic environment              of pronoun” in Figure 1. We represent the probability of the
of <NP, which means the category is N’ or N0 ). The syn-                 former as pI and the probability of the latter as pN 0 .
tactic category also determines whether the antecedent string               We follow the update methods in P&L, and use equation
can contain a modifier (e.g., category N0 cannot, since it only          (12) adapted from Chew (1971), which assumes p comes
allows bare nouns like “bottle”).                                        from a binomial distribution and the beta distribution is used
   Under R EFERENTIAL I NTENT, we can observe whether                    to estimate the prior:
the potential antecedent mentioned a property or not (e.g., “a
red bottle” vs. “a bottle”). If a property was mentioned, it is a                                α + datax
                                                                                       px =                      ,α = β = 1          (12)
latent variable whether the mentioned property was important                                 α + β + totaldatax
for the referent of the pronoun to have. This then determines
                                                                            α and β represent a very weak prior when set to 1. datax
whether the antecedent string must include that property (e.g.,
                                                                         represents how many informative data points indicative of
it must if the property is important).
                                                                         x have been observed, while totaldatax represents the total
   Both the antecedent string variables determine the con-
                                                                         number of potential x data points observed. After every in-
tent of the actual antecedent string (e.g., if both a modifier
                                                                         formative data point, datax and totaldatax are updated as in
and a property must be included, the antecedent would be
                                                                         (13), and then px is updated using equation (12). The vari-
“red bottle” rather than simply “bottle”). Finally, the an-
                                                                         able φx indicates the probability that the current data point is
tecedent string determines what object is being referred to,
                                                                         an example of an x data point. For unambiguous data, φx = 1;
and whether that object has the mentioned property (e.g.,
                                                                         for ambiguous data φX < 1.
whether it’s a RED BOTTLE when the previous context was
“a red bottle”). This is observable (e.g., we can see if the
bottle that one refers to is in fact red).                                                       datax = datax + φx                 (13a)
   These variables can take on the following values:                                    totaldatax = totaldatax + 1                 (13b)
    R EFERENTIAL I NTENT                                                    pI is updated for Unambiguous <NP data, Sem-Syn Am-
   property mentioned? ∈ {Yes, No}                                       biguous data, and Unambiguous NP data. pN 0 is updated for
   property important? ∈ {Yes, No}                                       Unambiguous <NP data, Sem-Syn Ambiguous data, and Syn
   antecedent string includes property? ∈ {Yes, No}                      Ambiguous data.
    S YNTACTIC U SAGE                                                       The value of φx depends on data type. We can derive the
   pronoun used ∈ {one, it, him, her, etc.}                              value of φI by using the information dependencies in Figure
                                                                         1, and the basic Bayes equation. φI uses equation (14), which
   syntactic category of pronoun ∈ {NP, N’, N0 }
                                                                         includes π (what pronoun was mentioned), σ (what the syn-
   syntactic environment ∈ {NP, <NP}
                                                                         tactic environment is), µ (whether the previous context men-
   antecedent string includes modifier? ∈ {Yes, No}
                                                                         tioned a property), ω (whether the object has the mentioned
    C OMBINED                                                            property), and I (the property is important):
                                                                     882

                                                                                    where
                                         p(π, σ, ω|I, µ = yes) ∗ pI                                                     n
   φI = p(I|π, σ, µ = yes, ω) =                                        (14)                             ρ4 =    pN 0 ∗ n+m                       (20a)
                                             p(π, σ, ω|µ = yes)
                                                                                                        ρ5 =     1 − pN 0                        (20b)
    Unambiguous <NP and Unambiguous NP data have φI =1,
which is intuitively satisfying since they unambiguously in-                        The quantities in (19) intuitively correspond to representa-
dicate that the property is important for the referent to have.                  tions for anaphoric one when no property is mentioned in the
Sem-Syn ambiguous data have φI calculated as in (15):                            previous context. For ρ4 , the syntactic category is N’ (pN 0 )
                                                                                                                           n
                                                                                 and the N’ string uses only a noun ( n+m      ). For ρ5 , the syntac-
                                                                                                    0
                                                                                 tic category is N (1-pN 0 ).
                                          ρ1
                            φI =                                       (15)
                                    ρ1 + ρ2 + ρ3
                                                                                 Learner input sets & parameter values
where                                                                            To gauge the frequency of the different data types in child-
                                            m                                    directed input, we conducted a corpus analysis of 17,521
                  ρ1 =             pN 0 ∗ n+m  ∗ pI                   (16a)
                                                                                 child-directed utterances in the Brown-Eve corpus from
                  ρ2 =      pN 0 ∗    n
                                    n+m   ∗ (1 − pI ) ∗ 1t            (16b)      CHILDES (MacWhinney, 2000). Following P&L, we posit
                  ρ3 =      (1 − pN 0 ) ∗ (1 − pI ) ∗ 1t              (16c)      that the anaphoric one learning period begins at 14 months
                                                                                 and that children hear approximately 1,000,000 sentences
    In (16), m and n refer to how often N’ strings are observed                  from birth until 18 months. We can then use the data fre-
to contain modifiers (m) (e.g., “red bottle), as opposed to                      quencies in the Brown-Eve corpus to estimate the expected
containing only nouns (n) (e.g., “bottle”). These help deter-                    distribution of pronoun data between 14 and 18 months. Ta-
mine the probability of observing an N’ string with a mod-                       ble 3 shows the input sets used to test the different learning
ifier (16a), as compared to an N’ string without one (16b).                      proposals for anaphoric one.
Parameter t indicates how many property types there are in
the learner’s hypothesis space, which determines how suspi-
cious a coincidence it is that the object just happens to have                      Table 3: Input sets for different anaphoric one proposals
the mentioned property.
    The quantities in (16) correlate with anaphoric one repre-                            Data type    Baker    R&G, P&L          P&L’s EO       P&M
                                                                                      Unamb <NP             0                0              0         0
sentations. For ρ1 , the syntactic category is N’ (pN 0 ), a mod-                  Syn-Sem Ambig            0             242            242        242
                    m
ifier is used ( n+m    ), and the property is important (pI ). For                       Syn Ambig          0                0         2743       2743
ρ2 , the syntactic category is N’ (pN 0 ), a modifier is not used                        Unamb NP           0                0              0     3073
    n                                                                                Uninformative     36500           36258          33515      30442
( n+m  ), the property is not important (1- pI ), and the object
has the mentioned property by chance ( 1t ). For ρ3 , the syn-
tactic category is N0 (1-pN 0 ), the property is not important (1-                  For the free parameters in the model, we will follow the
pI ), and the object has the mentioned property by chance ( 1t ).                corpus-based estimate P&L used for m and n: m = 1 and n =
    The value of φN 0 also depends on data type. We derive the                   3. We will also follow an estimate P&L used for t: t = 5.
value of φN 0 similarly (though not identically) to φI :                         Measures of success
                                           p(π, µ, ω|N 0 , σ =< NP) ∗ pN 0
                                                                                 In addition to measuring pI and pN 0 at the end of the learn-
   φN 0 = p(N 0 |π, σ =< NP, µ, ω) =                                             ing period, a good metric of acquisition success is how likely
                                                p(π, µ, ω|σ =< NP)
                                                                        (17)     the learner is to produce the infant looking behavior in the
                                                                                 LWF experiment (e.g., “Look - a red bottle! Do you see an-
    Unambiguous <NP data have φI =1, which is again intu-                        other one?”). Specifically, we can calculate the probability
itively satisfying since they unambiguously indicate that the                    (pbeh ) of the learner looking at the referent that has the men-
category is N’ when the syntactic environment is <NP. Sem-                       tioned property (e.g., the RED referent given that “red” was
Syn ambiguous data have φN 0 as in (18):                                         mentioned) when given a choice between two referents.
                                             ρ1 + ρ2                                 pbeh = p(ω = hasproperty|π = one, σ =< NP, µ = yes)           (21)
                      φN 0 Sem−Syn =                                   (18)
                                         ρ1 + ρ2 + ρ3
                                                                                 This works out to
where ρ1 , ρ2 , and ρ3 are the same as in (16). Equation (18)
is intuitively satisfying as only ρ1 and ρ2 are representations                                                ρ1 + ρ2 + ρ3
                                                                                                     pbeh =                                       (22)
with syntactic category N’.                                                                                 ρ1 + 2 ∗ ρ2 + 2 ∗ ρ3
    Syn Ambiguous data have φN 0 as the following:
                                                                                 where ρ1 , ρ2 , and ρ3 are defined as in (16), m = 1, n = 3,
                                             ρ4                                  and t = 2. As before, these quantities intuitively correspond
                             φN 0 Syn =                                (19)
                                          ρ4 + ρ5                                to the different outcomes. The numerator represents all the
                                                                             883

outcomes where the learner looks to the correct object (ρ1 , ρ2      This is domain-specific knowledge, though it could be de-
and ρ3 looking at the RED bottle), while the denominator in-         rived through innate domain-general statistical learning abil-
cludes the two additional outcomes where the learner looks to        ities applied to the input. The child can then track how of-
the incorrect object (ρ2 and ρ3 looking at the non-RED bottle).      ten a mentioned property is important for a referent to have
                                                                     by using these same domain-general abilities. In the second
             Results & General discussion                            learning stage, the learner uses these domain-general abilities
Table 4 shows the results of the learning simulations over the       coupled with domain-specific knowledge that allows comple-
different input sets, with averages over 1000 runs reported          ments and modifiers to be distinguished in the syntactic input
and standard deviations in parentheses.                              (F&al). This domain-specific knowledge could be innate (as
                                                                     part of Universal Grammar), or perhaps derived somehow.
                                                                        To conclude, we find that indirect evidence can be lever-
              Table 4: Probabilities after learning                  aged effectively by an online probabilistic learner in order
                                                                     to produce behavior consistent with infant anaphoric one be-
  Prob    Baker        R&G, P&L       P&L’s EO         P&M           havior, even if the learner does not achieve the adult rep-
  pN 0    .50 (<.01)   .97 (<.01)      .17 (.02)     .37 (.04)       resentation. Though this learning step does not require in-
  pI      .50 (<.01)   .95 (<.01)      .02 (.01)    >.99 (<.01)
  pbeh    .53 (<.01)   .93 (<.01)     .50 (<.01)    >.99 (<.01)      nate domain-specific knowledge, a second step that allows
                                                                     the learner to achieve the adult representation might. We be-
                                                                     lieve this general approach of looking at broader input sets for
   Interestingly, while the P&M learner has a lower probabil-        learning linguistic phenomena may be fruitful for identifying
ity for one as N’ in general (pN 0 = .37), it has an extremely       what is and is not necessarily part of Universal Grammar.
high probability of reproducing infant behavior and interpret-
ing one correctly in the LWF scenario (pbeh > .99). This is                              Acknowledgements
because the learner believes the mentioned property is impor-        We are very grateful to Vance Chung and Erika Webb for
tant (pI > .99). If the property is important, the antecedent        their assistance with the corpus analysis, and the Computa-
must contain the modifier (e.g., be “red bottle” as opposed to       tion of Language laboratory at UC Irvine for helpful discus-
“bottle”) - which means the learner will choose the correct          sion. In addition, this research was supported by NSF grant
referent even if the learner generally thinks one is N0 . That       BCS-0843896 to LP.
is, infants could produce adult-like behavior in this context
without having adult-like representations of anaphoric one.                                   References
   We note that this result is due to the input set the P&M          Baker, C. L. (1978). Introduction to generative transforma-
learner is using - the learners using restricted input sets be-         tional syntax. Englewood Cliffs, NJ: Prentice Hall.
have exactly as previous studies found. Learning from unam-          Chew, V. (1971). Point estimation of the parameter of the
biguous data alone does not work (Baker), though including              binomial distribution. American Statistician, 25(5), 47–50.
Sem-Syn ambiguous data will lead to the correct representa-          Chomsky, N. (1965). Aspects of the theory of syntax. Cam-
tion and the correct behavior (R&G, P&L). Additionally in-              bridge: The MIT Press.
cluding Syn ambiguous data (P&L’s EO) leads to the incor-            Chomsky, N. (1980). Rules and representations. Oxford:
rect representation and chance looking behavior. Expanding              Basil Blackwell.
to unambiguous NP data (P&M) doesn’t solve the incorrect             Crain, S. (1991). Language acquisition in the absence of
category problem for one, but it turns out this isn’t always            experience. Behavioral and Brain Sciences, 14, 597–612.
necessary to interpret one correctly in context.                     Foraker, S., Regier, T., Khetarpal, N., Perfors, A., & Tenen-
   This suggests that while children must eventually learn that         baum, J. (2009). Indirect evidence and the poverty of the
one is N’, they do not need to do so by 18 months. This                 stimulus: The case of anaphoric one. Cognitive Science,
may allow them time to develop the ability to make the sub-             33, 287–300.
tle conceptual distinctions F&al’s learner uses to leverage the      Lidz, J., Waxman, S., & Freedman, J. (2003). What infants
syntactic distribution of one and converge on one as N’. This           know about syntax but couldn’t have learned: experimental
leads to a more complex acquisition trajectory. Initially, chil-        evidence for syntactic structure at 18 months. Cognition,
dren could use a broader input set (like the P&M learner) and           89, B65–B73.
learn the correct interpretation for one in most contexts, even      MacWhinney, B. (2000). The childes project: Tools for ana-
if they believe one is usually N0 . Later, children could be            lyzing talk. Mahwah, NJ: Lawrence Erlbaum Associates.
sophisticated enough to leverage the information in the syn-         Pearl, L., & Lidz, J. (2009). When domain-general learning
tactic distribution and identify one as definitively N’.                fails and when it succeeds: Identifying the contribution of
   The knowledge needed for acquisition success would then              domain-specificity. Language Learning and Development,
include both domain-specific and domain-general compo-                  5(4), 235–265.
nents. To identify the broader data set the P&M learner used,        Regier, T., & Gahl, S. (2004). Learning the unlearnable: The
the child needs to recognize that one is similar to other pro-          role of missing evidence. Cognition, 93, 147–155.
nouns (i.e., it is anaphoric and has syntactic antecedents).
                                                                 884

