UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Encoding word-order and semantic information using modular neural networks

Permalink
https://escholarship.org/uc/item/32m745gw

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Cabana, Alvaro
Valle-Lisboa, Juan
Mizraji, Eduardo

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Encoding word-order and semantic information using modular neural
networks
Alvaro Cabana
Sección Biofı́sica, Facultad de Ciencias, Universidad de la República

Juan Valle-Lisboa
Sección Biofı́sica, Facultad de Ciencias, Universidad de la República

Eduardo Mizraji
Sección Biofı́sica, Facultad de Ciencias, Universidad de la República
Abstract: Vector space models have been successfully used for lexical semantic representation. Some of these models
rely on distributional properties of words in large corpora, and have been contrasted with human performance on
semantic similarity and priming in lexical decision tasks. Neural network models of lexical representation have been
classically of reduced size due to computational limitations. Recently, associative memory models have been related
to semantic space models such as LSA and Bayesian classificators. Our goal is to build lexical representations that
include semantic and word-order information by using context-dependent neural networks. The model integrates
word-order and semantic information in a way reminiscent of the BEAGLE model. In this work we train a multimodular neural network on a large corpus, and use it to account for reaction times in lexical priming studies.

1813

