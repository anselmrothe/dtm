UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Impedance Effects of Visual and Spatial Content upon Language-to-Logic Translation
Accuracy
Permalink
https://escholarship.org/uc/item/3p552481
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Barker-Plummer, Dave
Dale, Robert
Cox, Richard
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                               Impedance Effects of Visual and Spatial Content
                                upon Language-to-Logic Translation Accuracy
                                              Dave Barker-Plummer (dbp@stanford.edu)
                                                           CSLI, Stanford University
                                                       Stanford, California, 94305, USA
                 Robert Dale (Robert.Dale@mq.edu.au)                            Richard Cox (rcox@inf.ed.ac.uk)
          Centre for Language Technology, Macquarie University              School of Informatics, University of Edinburgh
                         Sydney, NSW 2109, Australia                                   Edinburgh, EH8 9AB, UK
                               Abstract                                   gate the factors which might make learning in these areas dif-
                                                                          ficult (see e.g., (Barker-Plummer, Cox, Dale & Etchemendy
   There is a body of work that suggests that those elements of
   the cognitive architecture responsible for processing, on the          (2008), Cox, Dale, Barker-Plummer & Etchemendy, (2008)).
   one hand, visual information (essentially visual properties of            Our study extends the field in two ways: by separately an-
   objects), and, on the other hand, spatial information (spatial re-     alyzing the effects of two kinds of visual information (ob-
   lationships between objects), may compete with each other for
   resources. In this paper, we explore whether and to what de-           ject size and object shape) which are usually treated together,
   gree the processing of visual and spatial information interferes       and by examining how those visual factors interact with each
   with the task of translation from natural language into logic, a       other and with spatial information.
   skill that students often find difficult to master. Using a large
   corpus of student data, we determine correlations between dif-
   ficulty and the particular properties used in the sentences, with        Background: Human Visuospatial Processing
   implications for pedagogical design.
   Keywords: first-order logic, logic teaching and learning, visu-        Baddeley’s (2007) model of working memory contains a vi-
   ospatial reasoning, visuospatial working memory, educational           suospatial sketchpad (VSSP), a phonological loop (for speech
   data mining, instructional design, visual impedance                    processing), plus an episodic buffer for holding and inte-
                                                                          grating diverse types of information. Attentional resources
                           Introduction                                   and rehearsal across the three working memory modalities is
There is widespread agreement that the human visuospatial                 managed by a central executive. The VSSP partitions visu-
cognitive system consists of two dissociated but not entirely             ospatial working memory into two components: memory for
independent subsystems: one for processing visual informa-                spatial location and an object-based short-term memory. The
tion (e.g. object size, shape) and another for processing spa-            VSSP is proposed as a storage system capable of integrating
tial information (e.g. the locations of objects with respect              visual and spatial information (Baddeley, 2007; Baddeley &
to each other). There is also the suggestion in the litera-               Hitch, 1974; Logie,1995; Logie & van der Meulen, 2009).
ture that these subsystems are used whether the information is               Recent evidence (Klauer & Zhao, 2004) provides support
perceived directly via external stimuli, or derived internally,           for dissociation between the visual and spatial subsystems
via mental imagery (Logie, 1995; Baddeley, 2007). Further                 and provides support for Logie’s (1995) model of the VSSP.
research suggests that particular combinations of visual and              That model proposes a visual cache (for storing features such
spatial information are more or less easily integrated dur-               as shape, size, and colour) and an ‘inner scribe’ that deals
ing cognitive processing, as evidenced by impeded perfor-                 with spatial and movement information.
mance on reasoning and text comprehension tasks (Schuler,                    Baddeley (2007) assumes that visuospatial information
Scheiter & Gerjets, 2009). It seems that differences in the               “may be encoded in the sketchpad either through perception,
types of source information can lead to competition for cog-              from long term memory (LTM), or via a combination of both”
nitive resources in working memory, which in turn leads to                (p. 93). The VSSP, then, provides “a way of integrating visu-
poorer performance. These effects have been shown to occur                ospatial information from multiple sources” (p.101).
whether information is presented as external stimuli, or as the              Short term memory for objects encodes features such as
result of mental imagery, and independently of the modality               shape, size, orientation and texture. The visual system seems
in which the information is presented.                                    to readily combine and encode several features of any partic-
   Against this background, we investigate whether visual or              ular object (e.g.size and shape, shape and texture) as easily
spatial impedance effects are observed in a linguistically ori-           as a single feature of an object. The capacity limitation for
ented cognitive task in which students translate natural lan-             objects in short-term memory (STM) seems to be more for
guage (NL) sentences into first-order logic (FOL). The ability            the number of objects than for the number of features per
to perform this task is a key skill in learning formal logic and          object. Baddeley (2007) suggests that, for most people, the
related fields, such as mathematics, which require the formal-            optimal number-of-objects versus number-of-features trade-
ization of informally presented information. The work de-                 off in short-term memory seems to be 16 features distributed
scribed here is part of an ongoing project in which we investi-           over 4 objects
                                                                      3259

   Schuler et al. (2009) review research suggesting that writ-             Tasks of this kind have high ecological validity, since they
ten stimuli (text) may be processed in the VSSP in addition to         arise in the sciences and in mathematics when information is
auditory and phonological processing if it contains spatial in-        translated into formal notations. The data we use in this study
formation and/or information about visual features of objects          is collected from students participating in tasks designed for
(e.g. De Beni, Pazzaglia, Gyselink & Meneghetti, 2005).                instruction of this key skill. A more detailed understanding
                                                                       of the cognitive processes in this task therefore has the po-
   Although the visual and spatial cognitive subsystems are
                                                                       tential to inform the design of instructional materials in these
dissociated to some extent, they are not completely indepen-
                                                                       important subjects.
dent, as evidenced by the fact that some combinations of in-
formation are more efficiently processed than others. Schuler                                      The Corpus
et al. (2009) showed subjects coloured drawings of fish ac-
                                                                       In order to investigate the presence of visual and spatial
companied either by written spatial information (The pectoral
                                                                       impedance effects, we data-mined a large-scale educational
fin lies between the two dorsal fins) or written visual infor-
                                                                       corpus in the area of logic teaching (Barker-Plummer, Dale,
mation (The pectoral fin has the same light brown color as
                                                                       & Cox, 2011). The corpus consists of student-generated so-
the dorsal fins). In one condition of the experiment, subjects
                                                                       lutions to exercises in Language, Proof and Logic (LPL; Bar-
were presented with the visual or spatial information aurally
                                                                       wise, Etchemendy, Allwein, Barker-Plummer & Liu, 1999),
(spoken), and in another, subjects read the text. Learners
                                                                       a courseware package consisting of a textbook together with
given text with spatial content showed worse recall than those
                                                                       desktop applications which students use to complete exer-
given visual text content, irrespective of presentation modal-
                                                                       cises.1 The book offers an introductory course in formal logic
ity (written or spoken).
                                                                       for early undergraduates. Students may submit answers to
   Knauff & Johnson-Laird (2002) used as stimuli relational            489 of LPL’s 748 exercises2 to The Grade Grinder (GG), a
terms of the form The hat is above the cup, The cup is above           robust automated assessment system that has assessed more
the fork, Does it follow that the hat is above the fork? The           than 2 million submissions of work by more than 55,000 in-
stimuli were varied according to information type. Examples            dividual students in the period 2001–10; this population is
of the kind just given are visuospatial (above–below), while           drawn from approximately a hundred institutions in more
pure-visual examples used terms such as cleaner–dirtier and            than a dozen countries.
pure-spatial examples used terms such as north–south. A                    One type of exercise in LPL involves translating natural
control condition employed relations such as better–worse.             language (NL) sentences into first-order logic (FOL). The
It was found that visual relational terms were associated with         corpus contains a total of 275 sentences which students are
longer reaction times (RT) in subjects’ reasoning compared             asked to translate and submit to the Grade Grinder. Most of
to control relations. Visuospatial relations produced faster           these sentences refer to a blocks world of objects arrayed on
RTs than control relations, with spatial-only relations produc-        a checkerboard. The objects may have visual properties such
ing the fastest RTs. There was no difference in error rates            as shape (cubes, tetrahedra, dodecahedra) and/or size (small,
across the four conditions defined in terms of correct assess-         medium, large). They may also have spatial relationships
ment of the truth of conclusions to valid and invalid infer-           with other objects on the grid (in front of, between). The re-
ences. Knauff & Johnson-Laird (2002) conclude that “. . . the          maining sentences involve completely different vocabularies
principal effect is that visual relations slow down reasoning,         involving either numbers, or people and their pets. The Grade
relative to the other three relations” (p 368). Those authors          Grinder considers a translation for a sentence to be correct if
termed the effect that they observed ‘visual impedance’, and           it is provably equivalent to a reference solution.3
concluded that irrelevant visual detail can impede reasoning.              From the 275 sentences we identified a subset of 129 sen-
For Knauff & Johnson-Laird (2002), ‘irrelevant visual detail’          tences for study, omitting those that included references to
seems to means visual attributes of objects that do not assist         temporal information and other semantic phenomena that
the reasoner in building spatial mental models.                        were idiosyncratic with respect to our current investigation.
   It is interesting to note that the Schuler et al. (2009) study      In contrast with earlier studies, we investigate the effect of
demonstrated what might be termed ‘spatial impedance’, in              size and shape information separately. While these are both
contrast to Knauff & Johnson-Laird’s (2002) reported visual            types of visual information, shape information is discrete,
impedance effect. However, the two studies differed substan-           while size information is generally considered scalar. So we
tially in at least two ways: first in terms of task (recall of         partitioned these sentences into eight categories according to
information vs reasoning with information) and, secondly, in           whether size, shape and spatial information are present in the
terms of cognitive source (perception vs mental imagery).              sentence (Figure 1). In that figure we refer to the type of sen-
                                                                       tence in row 6 as 101, meaning that the sentences in this class
   In this paper we explore the effects of visual and spatial text
                                                                           1 See http://lpl.stanford.edu.
content in a different kind of task, that of translating natural           2 The other exercises require that students submit their answers
language sentences into first-order logic. Our aim is to deter-        on paper to their instructors.
mine whether there is evidence of visual or spatial impedance              3 There are infinitely many correct answers for any sentence, so a
effects in this domain.                                                theorem prover is employed to determine equivalence.
                                                                   3260

        Type      n   Example NL sentence in category                     the truth of their sentences, providing a way for students to
        000      10   Max is a student, not a pet
        001      15   At least one of A, C, and E is a cube               test their solution.5 Students can determine whether a trans-
        010      15   B is larger than both A and E                       lation is incorrect if they can build a world in which the NL
        011      25   Everything smaller than A is a cube                 sentence has a different truth-value from the candidate FOL
        100      18   C is in back of A but in front of E
        101      24   B is not to the left of a cube                      translation, but they cannot definitively check whether a so-
        110       6   Either E is not large or it is in back of A         lution is correct. Sentences which contain no size, shape or
        111      16   B is to the right of a large cube                   spatial information cannot be checked for error in this way,
                                                                          and we would therefore expect the error rate for these sen-
Figure 1: Examples of sentences in each of the eight cate-                tences to be higher than that of the other, testable, classes.
gories. Type indicates the presence or absence of spatial, size           This class is also notable for the relatively small number of
and shape information respectively (so, 111 means all three               subjects translating these sentences.
are present). n refers to the number of sentences in the cate-               Given the different levels of error across the eight sentence
gory.                                                                     types shown in Figure 2, we examined the effect of member-
                                                                          ship in each of the eight sets using pincorr as a dependent
       Type     pincorr    SD      Mean no. trans.             SD         variable. Of course, it may not be the particular combinations
       000          .25    .15               6226.80      4902.77
       001          .09    .07             13173.87      10944.13         of visual and spatial information that result in different levels
       010          .15    .19             18488.27       9578.00         of difficulty; other possibilities, for example, are the readabil-
       011          .26    .21             10680.08       6277.08         ity and informational complexity of the sentences. Below, we
       100          .19    .22             19009.44       7915.24
       101          .23    .15               9689.00      6232.25         describe two separate analyses which control for these possi-
       110          .29    .24             15255.33       8883.13         bilities using covariates in our analyses. In the first we con-
       111          .20    .14             10170.25       8627.53         trol for differences in readability across sentence classes us-
                                                                          ing the Flesch readability index (Talburt, 1986) as a surrogate
Figure 2: Proportion of submitted student translations that               for sentence comprehension difficulty. In the second we use
were incorrect (pincorr) for each category of sentence with               the presence of a binary predicate in the sentence as a surro-
standard deviations (SD), together with the average number                gate for informational complexity.
of translations considered and standard deviations.
                                                                                                      Analyses
contain spatial information (indicated by the leading digit)              Readability as a covariate
and shape information (indicated by the last digit). In the text          A three-way analysis of covariance (ANCOVA) was per-
we refer to this class as space+shape sentences.                          formed. Each of the three factors (size, shape and spatial
                                                                          information) had two levels (present/absent). This analysis
                              Method                                      used the Flesch readability index as a covariate in order to
Measuring Problem Difficulty                                              control for the readability of the sentences. The interaction
                                                                          plot is represented by both graphs in Figure 3.
Our measure of the difficulty of the translation task for a par-             In order to further elucidate the components of the interac-
ticular sentence is the proportion of the initial attempts at             tion, the three-way ANCOVA was partitioned into two sepa-
translation that are in error, which we label pincorr. Pin-               rate, two-factor ANCOVAs.
corr values range from 0–1, with smaller values indicating                   The first analysis was conducted upon sentences that do
fewer errors. Figure 2 shows the pincorr values for each of               not contain spatial information (i.e. the first four rows of Fig-
the sets of sentences, and the average (mean, standard devia-             ure 1) and the second on those that contain spatial information
tion) number of subjects contributing to these values.4                   (i.e. the lower four rows of Figure 1).
   Note that pincorr is the proportion of initial attempts by a              The two-way interaction graph for non-spatial sentences is
subject that are in error. The Grade Grinder places no limit              shown in the upper graph of Figure 3.
on the number of times that an exercise may be attempted,
and the corpus contains many attempts by the same subject                 Informational complexity as a covariate
at translating the same sentence. These translation attempts              Spatial information in the LPL blocks language concerns rela-
are presumably revised on the basis of GG’s feedback on ear-              tions between objects. For example, one object may be to the
lier attempts, so we calculated the translation error rates by            left of, or it may adjoin, another object. The spatial language
considering only the initial submission of a sentence by an               also contains one ternary relation, between. By contrast, vi-
individual student.                                                       sual information in the language predominately concerns the
   The pincorr value for the class with no size, shape and spa-           properties of objects. An object may be a cube (shape) or
tial information (row 1 of the table) must be treated with some           small (size). Relations, such as smaller (size) and same shape
caution. The LPL package includes desktop software which                  (shape), do occur in the language. However, the spatial frag-
enables students to build ‘worlds’ in which they can evaluate             ment of the language is exclusively relational, and this offers
    4 The tasks completed vary by subjects represented in the corpus.         5 These worlds are displayed in a graphical modality.
                                                                      3261

Figure 3: ANCOVA 3-way interaction plot showing sen-                 Figure 4: ANCOVA 3-way interaction plot showing sen-
tences referring only to object shape and size (upper figure)        tences referring only to object shape and size (upper fig-
and sentences referring to spatial location of objects as well       ure) and sentences referring to spatial location of objects and
as shape and size (lower figure). The Flesch index of read-          shape and size (lower figure). For each sentence in each group
ability was included as a covariate in the analysis; the plotted     the presence of higher arity (binary) predicates was included
values are adjusted means and differ from those in Figure 2.         as a categorical covariate.
an alternative explanation of variance in difficulty between
spatial and visual sentences.                                           In order to determine whether the effect that we observed
   The distinction between the predominantly relational and          was due to increased complexity of FOL sentence rather than
predominantly property fragments of the language is a dif-           visual/spatial impedance, we repeated the analyses using a
ference of informational complexity. We use the presence of          binary covariate indicating, for each sentence in every group,
a binary predicate as a proxy for this difference. Sentences         whether or not it contains a binary predicate.
containing one ore more binary relations (pincorr: M = .235,
SD = .211) are significantly more difficult to translate (t =           A three-way ANCOVA analysis was performed. The three-
−2.36, p = .02) than sentences that contain no binary pred-          way interaction plot is represented by both graphs of Fig-
icates (pincorr: M = .166, SD = .118), and the eight groups          ure 4. The three-way analysis was partitioned into two two-
differ in terms of the number of binary-predicate-containing         way analyses. For non-spatial sentences, the two-way inter-
sentences they include.                                              action graph is shown as the upper graph in Figure 4.
                                                                 3262

             Type     pincorr (Flesch)    pincorr (Arity)                   • In the first analysis, with Flesch as a covariate, the trans-
              000           .26                 .30
              001           .08                 .14                            lation difficulty ordering is space+shape < size+shape <
              010           .18                 .15                            space+size. In the second analysis with arity as the covari-
              011           .24                 .29                            ate, the relative difficulty of size+shape and space+size are
              100           .22                 .16
              101           .22                 .21                            switched.
              110           .30                 .25
              111           .21                 .16                            A striking effect was that, whereas sentences containing
                                                                            references to shape but not to either size or spatial information
Figure 5: Summary adjusted pincorr 3-way interaction                        were the least error-prone to translate (M=.09, SD=.07, row
means, for each covariate.                                                  2 in Figure 2), when spatial information is added, the com-
                                                                            bination of spatial and shape information (M=.23, SD=.15,
                                                                            row 6 in Figure 2) significantly increases difficulty (t = -3.42,
   A second two-factor ANCOVA was performed on sen-                         p = .002). In sentences without spatial information, combin-
tences that contained size and/or shape information together                ing size information with shape information (M=.26, SD=.21,
with spatial information (the lower four rows of Figure 1).                 row 4 in Figure 2) significantly increases difficulty (t = -
                                                                            3.12, p = .003) compared to only shape information (M=.09,
                              Results                                       SD=.07, row 2 in Figure 2).
The results of both analyses, controlling readability and in-
formational complexity, agree on the following:                                                        Discussion
                                                                            The interaction of visual and spatial features of sentences af-
• The three-way ANCOVAs interaction effects were signif-                    fects sentence translation difficulty with effects that are sim-
   icant (Flesch: F(1,120)=5.51, p = .02, Arity: F(1,120) =                 ilar when controlling for each of two potential confounding
   10.72, p =.001). This indicates that the effects of size and             factors, readability and informational complexity.
   shape information upon translation difficulty differ at dif-                Taken together, the results suggest that the easiest-to-
   ferent levels of the spatial factor.                                     translate sentence types are those that contain just one vi-
                                                                            sual or spatial type of information, with a relative difficulty
• The two-way ANCOVAs with shape and size as indepen-                       of shape < size < space.
   dent variables for sentences with no spatial information                    Contrary to Schuler et al. (2009) we did not find a simple
   (upper four rows of Figure 1, upper graphs in Figure 3 and               negative effect of combining spatial information with visual
   Figure 4) revealed no main effect of size or shape, but a sig-           information in a sentence. Rather, the type of visual informa-
   nificant size-by-shape interaction (Flesch: F(1,60) = 6.66,              tion seems to make a difference: our results suggest that spa-
   p = .012, Arity: F(1,60) = 13.4, p = .001).                              tial information plus size information tends to produce more
                                                                            difficult-to-translate sentences than spatial information com-
• The two-way ANCOVAs with shape and size as indepen-
                                                                            bined with shape information.
   dent variables for sentences with spatial information (lower
                                                                               This suggests that research on visuospatial reasoning and
   four rows of Figure 1, lower graphs in Figure 3 and Fig-
                                                                            visuospatial working memory needs to distinguish between
   ure 4) showed no significant main effects or interactions.
                                                                            subtypes of visual information. Visual features such as size,
   Figure 5 shows the pincorr values from the ANCOVAs with                  shape and perhaps color, may differ in terms of the demands
each of the covariates. Considering these adjusted pincorr                  they place (singly and in combination) upon working mem-
means, and writing ‘<’ to mean ‘easier to translate’, we can                ory.
sum up the trends as follows:                                                  A surprising finding is that the size+spatial and
                                                                            shape+spatial classes both have higher pincorr values than
• Both of the analyses show that sentences involving only                   that for the size+shape+space class. This result challenges
   one type of information have lower values than sentences                 theories which suggest that impedance effects result from
   involving any combination of information types. Among                    competition for cognitive resources, since this would suggest
   these homogeneous sentences, shape < size < space.                       that impedance effects observed in sentences containing two
                                                                            types of information should not be reduced by the addition of
• Sentences involving all three information types6 are shown                a third type of information (or of more visual information if
   by both analyses to be the next hardest sentences to trans-              space and shape are to be considered as one type).
   late, i.e. they are more difficult to translate than homo-                  Our study is closest in kind to that reported in Knauff &
   geneous sentences, but easier than any pairwise combina-                 Johnson-Laird (2002). In both studies, information is pre-
   tions.                                                                   sented in the form of sentences to be read, and these sentences
                                                                            contain different information types. However, our tasks vary
    6 We consider visual(size) and visual(shape) to be different infor-
                                                                            in the number of types of information to be processed, in con-
mation types. They are subcategories of visual information which
differ, inter alia, in terms of whether they are discrete properties        trast to the tasks in Knauff & Johnson-Laird, which are each
(shape) or scalar (size).                                                   homogeneous. The implications of our findings for Knauff &
                                                                        3263

Johnson-Laird’s (2002) ‘visual-imagery impedance’ hypoth-                ral Language into Logic. CSLI Technical Report, Stanford
esis are not clear. In particular, their hypothesis makes use of         University.
the notion of ‘irrelevant visual detail’, referring to those vi-        Barwise, J., Etchemendy, J., Allwein, G., Barker-Plummer,
sual attributes of objects that do not assist with the building of       D. & Liu, A. (1999) Language, Proof and Logic. CSLI
spatial mental models. In our task, shape, size or spatial infor-        Publications and University of Chicago Press.
mation about objects—if mentioned in a sentence—is always               Blazhenkova, O. & Kozhevnikov, M. (2009) The new
relevant to the task of NL to FOL translation.                           object-spatial-verbal cognitive style model: Theory and
   The results have implications for logic teaching. Instruc-            measurement. Applied Cognitive Psychology, 23, 638-663.
tors, when creating sentences for NL to FOL translation ex-             Cox, R., Dale, R. Etchemendy, J., & Barker-Plummer, D.,
ercises designed to teach logical connectives, quantifiers, and          (2008) Graphical Revelations: Comparing student Trans-
concepts like implicature, will be better equipped for the prin-         lation Errors in Graphics and Logic. In J. Howse, J. Lee
cipled design of learning exercises. They could, for example,            and G. Stapleton (eds), Proceedings of the 5th Interna-
consider introducing sentences that refer only to object shape,          tional Conference on the Theory and Application of Dia-
then later challenge students with sentences that describe ob-           grams (Diagrams 2008). Springer.
jects in terms of, say, spatial position and size, at a stage when      De Beni, R., Pazzaglia, F., Gyselink, V. & Meneghetti, C.
the student is more practiced and confident.                             (2005) Visuospatial working memory and mental represen-
                                                                         tation of spatial descriptions. European Journal of Cogni-
   In further work we propose to address individual differ-              tive Psychology, 17(1), 77–95.
ences in cognitive processing of various forms of informa-              Johnson-Laird, P. N. (1983). Mental models: Towards a
tion. In earlier work we have demonstrated individual dif-               cognitive science of language, inference and conscious-
ferences between students in multimodal (graphical and sen-              ness. Harvard University Press, Cambridge, MA.
tential) logic learning contexts (e.g. Stenning, Cox, & Ober-           Kintsch, W. (1991) A theory of discourse comprehension:
lander, 1995). Students’ analytical reasoning performance on             Implications for a tutor for word algebra problems. In M.
constraint-satisfaction problems was shown to predict their              Carretero, M. Pope, R-J. Simons & J.I. Pozo, Learning and
propensity to develop flat versus ‘nested’ (broken-into-cases)           instruction: Volume 3, A publication of the European As-
styles of logical proof. Stenning et al. (1995) concluded that           sociation for Research on Learning & Instruction, Oxford:
‘verbaliser/visualiser’ conceptions of learning style are too            Pergamon Press.
simplistic: rather than preferring visual or verbal reasoning           Klauer, K.C. & Zhao, Z. (2004) Double dissociations in vi-
contexts, Stenning et al., (1995) found that students differed           sual and spatial short-term memory. Journal of Experimen-
more in their tendency to stay in one modality (graphical or             tal Psychology: General, 133, 355–381.
sentential) as opposed to switching between modalities. More            Knauff, M. & Johnson-Laird, P.N. (2002) Visual imagery
recently, Blazhenkova & Kozhevnikov (2009) have proposed                 can impede reasoning. Memory & Cognition, 30(3), 363–
a three-dimensional cognitive style model in which people                371.
are held to differ in their learning style preferences for ma-          Logie, R.H (1995) Visuo-spatial working memory, Hove,
terial containing object imagery, spatial imagery and verbal             UK: Lawrence Erlbaum Associates.
content. Exploiting the very large number of student submis-            Logie, R.H. & van der Meulen, M. (2009) Fragmenting
sions in our corpus, we plan next to study whether we can                and integrating working memory. In J.R. Brockmole (Ed.)
identify sub-groups of students who respond exceptionally to             The visual world in memory, Hove, UK: Psychology Press,
particular information-type configurations. The aim is to sta-           Taylor & Francis Group.
tistically identify such student clusters and to establish which        Schuler, A., Scheiter, K., & Gerjets, P. (2009) Does spa-
current individual difference theory the cluster patterns sup-           tial verbal information interfere with picture processing in
port.                                                                    working memory? The role of the visuo-spatial sketchpad
                                                                         in multimedia learning. In S. Ohlsson & R. Catrambone
                          References                                     (Eds.) Proceedings of the 32nd Annual Meeting of the Cog-
                                                                         nitive Science Society (pp 2828–2833), Cognitive Science
  Baddeley, A. & Hitch, G.J. (1974) Working memory. In G.                Society.
   Bower (Ed.), The psychology of learning and motivation,              Stenning, K., Cox, R. & Oberlander, J. (1995) Contrasting
   (Volume 8, pp. 47–90). New York: Academic Press.                      the cognitive effects of graphical and sentential logic teach-
  Baddeley, A. (2007), Working memory, thought, and action.,             ing: Reasoning, representation and individual differences.
   Oxford University Press.                                              Language and Cognitive Processes, 10(3/4), 333 – 354.
  Barker-Plummer, D., Cox, R., Dale, R. & Etchemendy, J.                Talburt, J., (1986) The Flesch Index: An Easily Pro-
   (2008) An Empirical Study of Errors in Translating Natural            grammable Readability Analysis Algorithm. Proceedings
   Language into Logic. In Proceedings of the 30th Annual                of the 4th Annual International Conference on Systems
   Meeting of the Cognitive Science Society (CogSci 2008).               Documentation. (pp. 114-122). New York, NY: ACM.
  Barker-Plummer, D., Dale, R., & Cox, R. (2011) The Grade
   Grinder Corpus Release 1.0: Student Translations of Natu-
                                                                   3264

