UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Categorizing Emotion in Spoken Language: An Analysis of Semantic and Prosodic
Contributions to Emotional Communication
Permalink
https://escholarship.org/uc/item/94k9r7mj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Fitzpatrick, Janine
Logan, John
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

  Categorizing Emotion in Spoken Language: An Analysis of Semantic and Prosodic
                                   Contributions to Emotional Communication
                                      Janine K. Fitzpatrick (jfitzpat@connect.carleton.ca)
                                            Institute of Cognitive Science, Carleton University
                                                                Ottawa, ON
                                               John Logan (john_logan@carleton.ca)
                         Institute of Cognitive Science and Department of Psychology, Carleton University
                                                                Ottawa, ON
                              Abstract                                  individuals with psychopathic characteristics, a group
                                                                        known to have deficits in processing emotion (e.g., Blair,
   The current study aimed to replicate and expand upon
   research conducted by Bagley, Abramowitz and Kosson                  Mitchell, & Blair, 2005).
   (2009) to examine categorization of emotional sentences                  The aim of the current study was to replicate and expand
   among non-psychopathic individuals. 36 monolingual                   upon research by Bagley, Abramowitz and Kosson (2009),
   English-speaking undergraduate participants categorized              who investigated emotional language processing in
   spoken English sentences (produced with neutral prosody but          individuals with primary and secondary psychopathy
   containing semantic cues to emotion) and French sentences            compared to individuals without psychopathy. Their
   (produced with appropriate prosody but with no semantic              experimental design involved isolating the semantic and
   cues to emotion) into one of five emotion categories:                prosodic cues present in spoken language by presenting
   happiness, sadness, anger, fear, or neutral. By isolating the
                                                                        monolingual English listeners with English sentences
   semantic and prosodic information available to listeners, we
   determined that categorization accuracy was higher among             spoken neutrally (i.e., semantic cues present but minimal
   sentences expressing anger in the prosodic condition.                prosodic cues) and Bulgarian sentences spoken with
   Accuracy was higher among sentences expressing all other             appropriate prosody (i.e., prosodic cues present but minimal
   emotions in the semantic condition. Overall, the lowest              semantic cues). These two conditions will be referred to as
   categorization accuracy was found for sentences expressing           the ‘semantic’ and ‘prosodic’ conditions, respectively. The
   fear in the prosodic condition. Across all emotion categories        vocal affect identification task included sentences
   and both presentation conditions, reaction time was longest          corresponding to the following emotional categories:
   for sentences expressing fear in the prosodic condition.             happiness, sadness, anger, surprise and neutral content.
   Although all participants in the current study had normative
                                                                        Fearful sentences were not included in their study. Because
   scores on the Self-Report Psychopathy Scale, those with
   relatively high scores displayed lower categorization accuracy       clear deficits have been found among individuals with
   for semantic sentences expressing happiness, anger and fear          psychopathy when identifying fear from verbal cues (see
   than lower-scoring participants. An extension of the current         Blair et al., 2002; Blair, Budhani, Colledge, & Scott, 2005),
   study comparing this normative sample to a group of                  the inclusion of this emotion category is a natural next step
   individuals with psychopathy will need to account for                in this research. Among non-psychopathic individuals,
   possible     implications    of     subclinical    psychopathic      Bagley et al. found that categorization accuracy was higher
   characteristics on vocal affect categorization accuracy.             in the semantic condition for sentences expressing
   Keywords: emotion; language processing; psychopathy;                 happiness, sadness, and surprise, while neutral sentences
   SRP-III.                                                             and those expressing anger displayed higher categorization
                                                                        accuracy in the prosodic condition. Psychopathic individuals
We are able to identify the emotional content of spoken                 classified sentences less accurately than non-psychopathic
language based on two types of cues: semantic cues, the                 individuals in the semantic condition, while differences in
content and meaning of what is being said, and prosodic                 classification in the prosodic condition approached
cues, the patterns of pitch, amplitude and duration of speech           significance. Further, participants with middle scores on the
associated with particular emotions. The current study was              PCL-R (Psychopathy Checklist-Revised, an instrument
conducted to investigate the contributions of semantic and              designed to assess psychopathy; Hare, 2003) were less
prosodic information towards listeners’ ability to identify             accurate at identifying happiness in the semantic condition.
the emotions expressed in spoken sentences. Currently, little           The authors propose that even subclinical levels of
is known about emotion categorization in the broader field              psychopathic characteristics may interfere with an
of cognitive science; the present study was designed to add             individual’s ability to process semantic cues for happiness,
to the relatively limited knowledge in this area. In addition,          while deficits in processing prosodic cues may only be
the emotion categorization data collected in the present                found in individuals with the full psychopathy syndrome.
study will provide a normative comparison to data from
                                                                    762

    Bagley et al. (2009) examined how the accuracy of                                          Method
emotion identification from prosodic cues in Bulgarian; the       Participants
prosodic condition in the current study was comprised of
                                                                  Forty-five Carleton University undergraduate students
French sentences. It is important to determine whether the
                                                                  participated in this study, 19 males and 26 females.
prosodic cues from another language would yield similar
                                                                  Participant age ranged from 18-35 years (Mage = 20.2 years,
results of identification accuracy among monolingual
                                                                  SD = 3.0). Participants were recruited through an online
English speakers. Further, although all participants included
                                                                  database run by the Carleton University Psychology
in the present study scored within the normative range of
                                                                  Department and received course credit for their participation
Self-Report Psychopathy Scale (SRP-III; Williams, Paulhus,
                                                                  in the study. 92% of participants were monolingual English
& Hare, 2007), we investigated whether participants’
                                                                  speakers, while the remaining 8% were native English
accuracy at identifying emotions correlated with their score
                                                                  speakers who spoke a second language other than French.
on the SRP-III. We also added a measure of reaction time
                                                                  All participants had little to no proficiency in French
(RT) to examine its relationship with categorization
                                                                  comprehension and production, as measured by a Language
accuracy.
                                                                  Experience Questionnaire in which participants described
    Also of interest was whether the discrepancy between
                                                                  their exposure to the French language over their lifetimes.
identification of fearful sentences is as marked between
                                                                  In addition, participants completed the Self-Report
psychopathic and nonpsychopathic individuals as it is for
                                                                  Psychopathy Scale (SRP-III, Williams, Paulhus, & Hare,
identification of other emotions. In a systematic review of
                                                                  2007) to ensure they represented a sample of non-
empirical literature concerning emotion recognition from
                                                                  psychopaths. Both the Language Experience Questionnaire
spoken language, Scherer, Johnstone and Klasmeyer (2003)
                                                                  and the SRP-III were presented via computer.
found that the acoustic cues reported to be associated with
fear are unclear. A variety of acoustic parameters (such as
number and duration of pauses and F0 range) indicate              Materials and Design
inconsistent empirical findings for recognition of fearful        The experimental stimuli were comprised of 93 sentences
utterances. Many prosodic cues depend on speaker-specific         recorded by four speakers. All sentences were recorded
factors such as age and gender, but the results for fear          using Praat software (Boersma & Weenick, 2010) using a
indicate more variability across findings than any other          headset microphone in a sound attenuated booth. The
emotion category included in the review. Scherer et al.’s         sentences represented five different emotion categories:
results, together with the results of a pilot version of the      happiness (e.g.: All my wishes came true that day), sadness
current study in which non-psychopathic listeners also            (e.g.: I had no money to buy Christmas gifts), anger (e.g.:
displayed lower categorization accuracy for sentences             He just smashed my new car), fear (e.g.: I hope they don’t
expressing fear presented in the prosodic condition, suggest      find me here), and neutral (e.g.: It’s time to fill the bird
that people may generally find it more difficult to recognize     feeder). Fluently bilingual speakers, two males and two
fear in language without a semantic context than other            females, recorded the sentences in English and French using
emotions.                                                         written scripts. They recorded English sentences with
    The central hypotheses of the current study were as           neutral prosody and French sentences with prosody
follows: First, based on the findings from Bagley et al.          appropriate to the emotion the sentences conveyed.
(2009), we hypothesized that categorization accuracy would        Listeners who do not understand spoken French should not
be significantly higher for sentences expressing happiness        be able to understand what is being said in the French
and sadness presented in the semantic condition, and for          sentences, and so they would need to rely on the non-
sentences expressing anger in the prosodic condition. We          semantic cues to determine the emotion being conveyed by
predicted that categorization accuracy would be lower for         the speaker. Thus, there were two conditions for listeners:
sentences expressing fear than all other sentences,               the English sentences comprised the semantic condition, in
particularly in the prosodic condition. Second, we                which only the content of the sentences was available to
hypothesized that participants with higher scores on the          listeners, while the French sentences comprised the prosodic
SRP-III would display significantly lower categorization          condition, in which listeners only had access to prosodic
accuracy among sentences expressing fear in both semantic         factors such as pitch contour and speech rate.
and prosodic conditions than lower-scoring participants.              The experimental task was conducted using a 5
Finally, we hypothesized that reaction time would display         (emotion) x 4 (speakers) x 2 (conditions: semantic vs.
an inverse relationship with categorization accuracy: RT          prosodic) repeated measures design. Participants were
would be longer in the prosodic condition, particularly for       presented with four sentence lists counterbalanced by affect
sentences expressing fear, than the semantic condition. RT        category and speaker, with each list containing all 93
would also be longer among participants with higher scores        sentences presented in random order. Two of the four lists
on the SRP-III than lower-scoring participants.                   were presented in the prosodic condition, and two in the
                                                                  semantic condition; both lists in each language were
                                                                  presented together so that participants heard all the
                                                                  sentences in one condition followed by all the sentences in
                                                                  the other. In total, each participant heard 372 sentences.
                                                              763

Procedure                                                                condition in which they were presented (semantic or
Participants listened to the sentences, presented via                    prosodic). Generally, participants were better at categorizing
headphones, and indicated the affect category to which they              the emotion of the sentences they heard in the semantic
thought the sentence belonged using a scale presented on the             (English) condition than the prosodic (French) condition.
computer screen in which a number on the keyboard                        All means reported represent the mean proportion of
corresponded with a particular emotion. After categorizing               accurate responses. Only the sentences conveying anger
the sentence, participants rated the degree to which they                were more accurately categorized in the prosodic condition
thought the sentence conveyed the emotion they had                       (Mprosodic = .75, SD = .16; Msemantic = .68, SD = .24).
indicated, referred to as the ‘quality’ of the sentence, on a 7-         Sentences conveying fear showed the largest discrepancy
point Likert scale (1 = low quality, 4 = moderate quality, 7 =           between categorization accuracy in the semantic and
high quality).                                                           prosodic conditions (Msemantic = .74, SD = .21; Mprosodic = .23,
    All participants completed a 10-sentence practice block              SD = .17).
to familiarize themselves with the scales used in the task                                0.90
and to adjust the volume of the auditory stimuli. The
                                                                                          0.80
sentences presented during the practice block were not used
during the experimental task. Participants were then                                      0.70
                                                                          Mean Accuracy
presented all sentences from the four lists, taking a 5-minute                            0.60
break after completing the second list. All of the sentences                              0.50
in the first two lists were presented in the same condition,                              0.40                                                  Semantic
and the sentences in the third and fourth list were presented                             0.30
in the other language (e.g.: lists 1 and 2 were semantic, lists                                                                                 Prosodic
                                                                                          0.20
3 and 4 were prosodic). This ensured that participants
                                                                                          0.10
completed the semantic and prosodic conditions of the task
without interruption. Sentences in each list were presented                               0.00
in a different randomized order to each participant.                                             Happiness Sadness    Anger    Fear   Neutral
                                                                                                                     Emotion
                            Results                                      Figure 1. Mean accuracy for sentence categorization by
SRP-III results were analyzed before proceeding with                     emotion in semantic and prosodic conditions. Error bars
analysis of the experimental task data. The mean overall                 represent ±1 standard error of the mean.
score for all males was 160, SD = 27, and the mean overall
score for females was 135, SD = 20. One male participant                 The relationship between sex and categorization accuracy of
and one female participant scored above the high normative               sentences in all emotions and conditions was not significant.
cutoff of two standard deviations above their gender’s                   A repeated-measures analysis of variance (ANOVA) was
mean; their experimental data were excluded from further                 conducted to determine the effects of the sentences’
analyses. Among the remaining 43 participants, the mean                  intended emotion and condition on categorization accuracy.
overall score for males was 157, SD = 24, and the mean                   Significance was set at p = .05 for all tests. The results
overall score for females was 133, SD = 18. Male scores                  indicate significant main effects of both emotion and
ranged from 98 to 194, and female scores ranged from 103                 condition on categorization accuracy, F (2.77, 97.09) =
to 171.                                                                  23.59 and F (1, 35) = 26.43, respectively. Contrasts
    Overall, the mean proportion categorization accuracy                 revealed that categorization accuracy for sentences
was .58 across all emotion categories, SD = .16. This is                 expressing happiness, F (1, 35) = 5.11, r = .36, and
significantly higher than chance levels of accuracy, χ2 (4, n            sentences expressing fear, F (1, 35) = 59.58, r = .79, were
= 43) = 431.51, p = .00. An accuracy cutoff criterion was set            significantly lower than accuracy of neutral sentences.
at .40, twice the level of chance. Data from seven                       Sentences in the prosodic condition, F (1, 35) = 26.43, r =
participants whose overall accuracy was less than .40 were               .66, displayed significantly lower mean accuracy than
excluded from further analysis. Further, seven sentences                 sentences in the semantic condition.
were removed from the final data set because they displayed                  There was a significant interaction between emotion and
a mean categorization accuracy of more than two standard                 condition on accuracy, F (4, 140) = 43.82. To further
deviations below the means of their respective emotion and               investigate this interaction, contrasts were performed to
condition groups. One sentence in each emotion category                  compare all emotion categories to their baseline (neutral)
was removed from the semantic condition, and a sentence                  and sentences in the prosodic condition to those in the
expressing happiness and one expressing sadness were                     semantic condition. The contrasts revealed significant
removed from the prosodic condition. Among remaining                     interactions when comparing sentences expressing anger, F
participants and sentences, mean categorization accuracy                 (1, 35) = 24.00, r = .64; and fear, F (1, 35) = 46.85, r = .76,
was .64, SD = .11. Figure 1 displays the mean proportion of              to neutral sentences. These effects reflect that, compared to
sentences accurately categorized by participants as a                    neutral sentences, categorization accuracy of sentences
function of the emotion expressed by the sentence and the
                                                                   764

expressing sadness, anger and fear was significantly
                                                                                               5500
affected by whether the sentence was presented in the
semantic or prosodic condition. This may be due to the fact                                    5000
that sentences expressing anger were the only ones that
                                                                              Median RT (ms)
displayed higher categorization accuracy in the prosodic                                       4500
condition than the semantic condition, and because the
difference in accuracy between semantic and prosodic                                           4000
conditions among the sentences expressing fear was the                                                                                                 Semantic
                                                                                               3500
most dramatic among all emotion categories.
    Tables 1 and 2 display confusion data for categorization                                                                                           Prosodic
                                                                                               3000
patterns in semantic and prosodic conditions.
                                                                                               2500
Table 1                                                                                               Happiness Sadness    Anger    Fear    Neutral
Confusion matrix of categorization in semantic condition
                                                                                                                          Emotion
                            Identified Emotion (%)
  Intended                                                                   Figure 2. Mean reaction time (in ms) of accurately
  Emotion     Happiness    Sadness     Anger         Fear    Neutral         categorized sentences by emotion in semantic and prosodic
 Happiness          70.4        5.0       1.7          0.2      22.7         conditions. Error bars represent ±1 standard error of the
 Sadness             1.7       77.3       3.2          5.7      12.1         mean.
 Anger               0.7       20.2      66.0          4.2       8.8
                                                                             The relationship between SRP-III score and total
 Fear                0.7       10.6       3.3         73.7      11.8
                                                                             categorization accuracy approached significance, r = -.30, p
 Neutral             2.7       14.7       4.4          1.4      76.9         = .08. A median split was performed on SRP-III scores to
                                                                             divide male (Mdn = 158) and female (Mdn = 129)
Table 2                                                                      participants into high and low-scoring groups. Table 3
Confusion matrix of categorization in prosodic condition                     displays mean categorization accuracy of high and low
                            Identified Emotion (%)                           SRP-III scoring participants by emotion and condition.
  Intended
  Emotion     Happiness    Sadness     Anger         Fear    Neutral         Table 3
 Happiness          51.9        7.6       9.5          5.1      25.7         Mean categorization accuracy of high and low SRP-III
 Sadness             3.3       59.8       3.6          6.0      26.7         participants by emotion and condition (SD)
 Anger               6.1        3.1      75.3          6.8       8.6           Condition                           Low (n = 18)            High (n = 18)
 Fear                8.0       17.4      28.0         22.7      23.7           Semantic
 Neutral             8.0       22.0       4.7          2.6      62.4             Happiness **                      .85 (.23)               .58 (.31)
                                                                                 Sadness                           .82 (.14)               .75 (.17)
In both semantic and prosodic conditions, sentences                              Anger **                          .79 (.17)               .56 (.24)
expressing happiness, sadness and fear were most often                           Fear **                           .84 (.16)               .64 (.22)
mistakenly categorized as neutral sentences. In the prosodic                     Neutral                           .83 (.22)               .74 (.20)
condition, the confusion distribution for sentences depicting
fear was also spread more evenly across sentences depicting                   Prosodic
anger and sadness than distributions for other emotions.                        Happiness       .54 (.16)                                  .50 (.17)
     Figure 2 displays mean reaction time (RT) among                            Sadness         .63 (.20)                                  .55 (.22)
accurately categorized sentences by emotion and condition.                      Anger           .77 (.14)                                  .73 (.17)
RT measurement started at the onset of the sentence                             Fear            .28 (.17)                                  .18 (.16)
presentation. Because sentences were not of uniform length                      Neutral         .63 (.22)                                  .63 (.20)
within presentation condition, and because the same                          Note. ** p < .01 for low and high                              SRP-III group
sentence differed in length between presentation conditions,                 comparisons.
it is difficult to draw meaningful conclusions by comparing
RT alone within or between presentation conditions.                          High-scoring participants displayed significantly lower
Nonetheless, we can examine the degree to which broad RT                     categorization accuracy for sentences expressing happiness,
patterns reflect categorization accuracy across emotions and                 anger and fear in the semantic condition than low-scoring
presentation conditions. RT is longest among sentences                       participants. The difference between mean accuracy for
expressing fear in the prosodic condition (M = 5246, SD =                    sentences expressing fear in the prosodic condition was not
1189), coinciding with a lowered categorization accuracy                     significant between high and low-scoring participants. As
for fear compared to all other sentences in both conditions.                 Table 1 shows, a significant relationship was found between
No significant relationships were found between sex or                       SRP-III score and categorization accuracy of sentences
SRP-III score and RT for any emotion or condition.                           expressing fear in the semantic condition, r = -.36, p = .03.
                                                                       765

Because males and females were grouped into high and low-          relatively high and low SRP-III scores will need to be taken
score categories based on different median scores,                 into account when comparing normative accuracy levels
regression analyses were performed to determine the                between normative and psychopathic populations.
relationship between SRP-III category (high or low), sex           Vassileva, Kosson, Abramowitz, and Conrod (2005)
and categorization accuracy (see Table 4).                         describe two distinct subgroups of psychopathy: primary
                                                                   psychopathy, characterized by higher scores on
Table 4                                                            interpersonal and affective items on the PCL-R (Hare, 2003)
Categorization accuracy for all sentences by SRP-III score         and the Interpersonal Measure of Psychopathy (IM-P, an
and sex                                                            additional measure of the personality core of psychopathy;
                                           95% CI                  Kosson, Stuerwalk, Forth, & Kirkhart, 1997); and secondary
  Variable         B (SE)       OR         Lower      Upper        psychopathy, characterized by higher scores on the
  Constant         .33 (.03)    1.39                               antisocial items on the PCL-R and increased severity of
  SRP-III          .43 (.04)    1.54**     1.43       1.66         alcohol and drug dependence. Kosson et al. (2009) treated
  Sex              .07 (.04)    1.08       1.00       1.16         psychopathy as a heterogeneous construct and examined
Note. OR = odds ratio; CI = confidence interval. ** p < .01.       differences between primary and secondary psychopaths in
                                                                   vocal affect recognition; results from the current study
When controlling for the influence of sex, SRP-III score is a      indicate that ‘normative’ individuals may need to be treated
significant predictor of overall categorization accuracy, with     as a heterogeneous group as well. Subclinical levels of
low scoring participants 1.5 times more likely to respond          psychopathic characteristics may be implicated in
correctly than high scoring participants. Sex was not found        difficulties in emotional sentence processing, and research
to be a significant predictor of categorization accuracy when      designed to compare categorization differences between
controlling for SRP-III score.                                     psychopathic and non-psychopathic individuals will need to
                                                                   this relationship into account.
                           Discussion                                   Several theories have emerged concerning emotional
                                                                   response and regulation among psychopathic individuals.
The accuracy results generally support our hypotheses:
                                                                   The dysfunctional fear hypothesis suggests that individuals
Categorization accuracy was higher in the semantic
                                                                   with psychopathy show less aversive reactions to
condition for all emotion categories except for sentences
                                                                   punishment than non-psychopathic individuals (see Blair et
expressing anger, which were more accurately categorized
                                                                   al., 2005). Lykken (1957) demonstrated that psychopathic
in the prosodic condition. Scherer et al. (2003) describe
                                                                   individuals demonstrated less avoidance of punished
several acoustic parameters associated with utterances
                                                                   responses (a harmless but painful electric shock) in a maze-
expressing anger (compared to neutral utterances), including
                                                                   learning task and less galvanic skin response reactivity to a
increased F0 mean and range, higher mean voice source
                                                                   conditioned stimulus associated with shock than controls.
intensity (dB), and increased frequency of accented
                                                                   These results may provide some rationale concerning
syllables. Detailed analysis of acoustic profiles of each
                                                                   psychopathic individuals’ impairment of fear recognition; if
sentence used in the present study was conducted as part of
                                                                   they are less adept at learning and responding to fear
a separate project and will not be discussed further.
                                                                   responses on their own, they may also be less likely to
    Categorization accuracy was significantly lower among
                                                                   recognize signals of fear in others.
sentences expressing fear in the prosodic condition than all
                                                                       The current experimental task relies upon discrimination
other sentences. This is in accordance with our hypotheses
                                                                   instead of recognition of emotions, thereby reducing its
as well as Bagley et al.’s (2009) results. Participants with
                                                                   ecological validity. One risk of isolating semantic and
higher SRP-III scores displayed significantly lower
                                                                   prosodic cues is the potential use of response bias in the face
accuracy than low-scoring participants when identifying
                                                                   of ambiguity, as discussed by Johnstone and Scherer (2000):
fear in sentences presented in the semantic condition, but
                                                                   When presented with ambiguous cues in experimental
not the prosodic condition. However, because overall
                                                                   stimuli, participants may be more likely favour one response
accuracy for sentences expressing fear in the prosodic
                                                                   over another. This preference may reflect a response
condition was significantly lower than all other sentences,
                                                                   heuristic not otherwise utilized during emotional processing
group comparisons between high and low-scoring
                                                                   in a natural setting. After examining response data, we
participants in this category are likely not as meaningful as
                                                                   excluded several sentences from analysis because they
group comparisons for other emotions. All participants were
                                                                   displayed significantly lower categorization accuracy than
deemed to be non-psychopathic based on their scores. An
                                                                   the other sentences in their emotion category. Among the
extension of this study will examine accuracy data among
                                                                   excluded sentences, several were semantically ambiguous
individuals with psychopathy; data indicating that a
                                                                   and/or context-specific (e.g.: Use your signal when you’re
normative population displays lower categorization
                                                                   switching lanes! was intended to express anger, but when
accuracy for prosodic sentences expressing fear will be
                                                                   heard in the semantic condition with neutral prosody it
useful when interpreting the results of the individuals with
                                                                   could easily be interpreted as a neutral sentence). Indeed,
psychopathy.        However,        discrepancies     between
                                                                   many of these semantically ambiguous sentences received
categorization accuracy among subclinical individuals with
                                                               766

more neutral categorizations than sentences with clearer             In addition to the theoretical benefits of exploring the
meaning. The degree to which each sentence accurately                categorization of emotions, the present work also has
reflects its intended emotion can be drawn from further              clinical implications. By studying categorization data from a
examination of confusion data, which will be helpful when            clinically psychopathic population, we may learn more
deciding which sentences to use in future iterations of this         about the nature of the deficits associated with emotional
study.                                                               processing in psychopathic individuals.
    The stimuli used in the present study were intended to
simulate emotion in speech. Although obtaining voice                                     Acknowledgments
samples from professional or lay actors has been the
preferred method in the field, Scherer (2003) suggests that          We are indebted to David Kosson for the stimuli used in this
actors may miss the more subtle cues of natural emotional            study, and to Erin Debodt for her help with designing and
speech in favour of obvious, stereotypical ones. Scherer et          running the experimental task.
al. (2003) describe the push and pull effects inherent in the
expression of emotion: Push effects are physiological                                         References
changes that characterize emotional responses in speech
                                                                     Bagley, A. D., Abramowitz, C.S., & Kosson, D.S. (2009).
production, while pull effects reflect the notion that
                                                                         Vocal affect recognition and psychopathy: Converging
vocalization is often regulated and monitored in order to fit
                                                                         findings across traditional and cluster analytic
into conventional expression norms. For example, in social
                                                                         approaches to assessing the construct. Journal of
groups in which expression of anger is deemed unattractive,
                                                                         Abnormal Psychology, 118 (2), 388-398.
pull effects would cause the inhibition of some of the
                                                                     Blair, R.J.R., Budhani, S., Colledge, E., & Scott, S. (2005).
characteristic cues of anger expression in order to better fit
                                                                         Deafness to fear in boys with psychopathic tendencies.
convention. Thus, while the use of actor portrayals may
                                                                         Journal of Child Psychology and Psychiatry, 46 (3),
exaggerate certain cues of emotion expression and provide
                                                                         327-336.
‘stereotypical’ voice samples, it is presumed that pull effects
                                                                     Blair, J., Mitchell, D., & Blair, K. (2005). The psychopath:
will be less influential in the simulated setting than in
                                                                         Emotion and the brain. Oxford: Blackwell Publishing.
samples derived from natural vocal expression and induced
                                                                     Blair, R.J.R., Mitchell, D.G.V., Richell, R.A., Kelly, S., &
emotions.
                                                                         Leonard, A. (2002). Turning a deaf ear to fear: Impaired
    In the semantic condition of encoding, actors were told
                                                                         recognition of vocal affect in psychopathic individuals.
to speak in a neutral voice in order to minimize any prosodic
                                                                         Journal of Abnormal Psychology, 111 (4), 682-686.
cues available for interpretation by the listeners. It is nearly
                                                                     Boersma, P., & Weenick, D. (2010). Praat: Doing phonetics
impossible to ensure the actor’s voice is completely neutral.
                                                                         by computer (Version 5.2.05) [Computer program].
Researchers wishing to further study the disparate
                                                                         Retrieved from http://www.praat.org/
contributions of semantic and prosodic information to
                                                                     Hare, R. D. (2003). The Hare Psychopathy Checklist –
emotional speech processing should examine the relative
                                                                         Revised, 2nd Edition. Toronto: Multi-Health Systems.
advantages and drawbacks of natural vs. synthetic speech
                                                                     Johnstone, T., & Scherer, K. R. (2000). Vocal
samples (see Scherer, 2003).
                                                                         communication of emotion. In M. Lewis and J. Haviland
    Because sentence length was not standardized across
                                                                         (Eds.), The Handbook of Emotion. New York: Guilford.
speaker, emotion and condition, it is difficult to interpret the
                                                                     Kosson, D. S., Stuerwald, B. L., Forth, A. E., & Kirkhart, K.
results of RT analysis. In order to effectively compare RT to
                                                                         J. (1997). A new method for assessing the interpersonal
accuracy data, alternative strategies for dealing with this
                                                                         behavior of psychopathic individuals: Preliminary
variability in sentence duration would need to be adopted.
                                                                         validation studies. Psychological Assessment, 9, 89-101.
Further analysis can be conducted by removing individual
                                                                     Lykken, D. T. (1957). A study of anxiety in the sociopathic
sentence length from each RT value to determine whether
                                                                         personality. Journal of Abnormal and Social
observed patterns still hold.
                                                                         Psychology, 55, 6-10.
    The present study was conducted to examine the effects
                                                                     Scherer, K. R., Johnstone, T., & Klasmeyer, G. (2003).
of isolating semantic and prosodic speech cues on emotional
                                                                         Vocal expression of emotion. In R. J. Davidson, K. R.
language processing among a normative sample of listeners.
                                                                         Scherer, and H. Goldsmith (Eds.), Handbook of the
The results indicate that semantic cues may be more heavily
                                                                         Affective Sciences. New York and Oxford: Oxford
implicated in categorization accuracy for sentences
                                                                         University Press.
expressing happiness, sadness and fear, while listeners may
                                                                     Vassileva, J., Kosson, D. S., Abramowitz, C., & Conrod, P.
use more prosodic cues to identify sentences expressing
                                                                         (2005). Psychopathy versus psychopathies               in
anger. In a broad sense, the present study is an example of
                                                                         classification of criminal offenders. Legal and
extending categorization research beyond the categorization
                                                                         Criminological Psychology, 10, 27-43.
of physical objects into more abstract types of events.
                                                                     Williams, K., Paulhus D., & Hare, R.D. (2007). Capturing
Emotion research is an area that cognitive science has
                                                                         the four-factor structure of psychopathy in college
tended to avoid. By employing empirical methods in the
                                                                         students via self-report. Journal of Personality
study of emotion, this lack of attention can be remediated.
                                                                         Assessment, 88 (2), 205-219.
                                                                 767

