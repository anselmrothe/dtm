UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cued multimodal learning in infancy: a neuro-computational model
Permalink
https://escholarship.org/uc/item/5z0406h9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Hannagan, Thomas
Wu, Rachel
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                Cued multimodal learning in infancy: a neuro-computational model
                                         Thomas Hannagan (thom.hannagan@gmail.com)
                               Laboratoire de Psychologie Cognitive, CNRS and Aix-Marseille University
                                               3, place Victor Hugo, 13331 Marseille, France
                                                     Rachel Wu (r.wu@bbk.ac.uk)
       Centre for Brain and Cognitive Development, Department of Psychological Sciences, Birkbeck, University of London
                                                   Malet Street, London, WC1E 7HX, UK
	  
                              Abstract                                  flashing squares that shifted attention to the target location, Square
                                                                        condition) shifted infants’ attention to one of the two identical
     We introduce a connectionist model of cued multimodal              events on every trial. For the social cue, a face appeared, spoke to
     learning in infants. Its architecture is inspired by
     computational studies coming both from the fields of infant        the infant, and turned to one of the lower corners containing an
     habituation and of visual attention. The model embodies in its     object. For the non-social cue, a red flashing square wrapped
     simplest form the notion that the attentional system involves      around the target frame appeared and disappeared at a regular
     competitive networks (Lee et al., 1999). Using this model, we      interval (i.e., flashed continuously) without a central stimulus
     reproduce infant behavioral results from Wu and Kirkham            throughout the familiarization trial. In the No Cue condition, the
     (2010), which found different learning effects with social,
     non-social, and no attentional cueing. We show that these          two objects appeared without any attentional cues. During the test
     learning differences can be explained by the amount of             trials, only the four blank frames were displayed on the screen
     information let through from non-cued locations. We discuss        while one of the sounds played. Infants were shown four blocks of
     these results and future lines of research on this                 stimuli. The main finding of W&K was that by 8 months of age,
     computational work.                                                different cues produced different learning effects: social cues
     Keywords: Connectionism; multimodal learning; cognitive            produced specific spatial learning of audio-visual events (i.e.,
     development; attentional cueing.                                   infants looked where cued multimodal events had played during
                                                                        test trials) by the second half of the experimental session (Blocks
                           Introduction                                 3-4), while non-social cues produced only general spatial learning
     In a busy multimodal world, infants must parse useful              (i.e., infants looked only at cued locations regardless of multimodal
information from a swirl of perceptual events. One way to               information) throughout all four blocks. Without any cues, infants
accomplish this is relying on attention cues to guide them to           did not display any learning (i.e., looked equally to all locations)
relevant learning events. Many attention cues can guide infants’        throughout all four blocks.
attention, but which ones help infants learn what to learn?
                                                                           The purpose of this article is to characterize the neural
     Recent work has shown that following social cues can shape         mechanisms at work in infants when they are performing this task
learning: Some studies have focused on word mapping (e.g., Gliga        (where the presence and type of cue produced different types of
& Csibra, 2009; Houston-Price, Plunkett, & Duffy, 2006; Pruden,         learning), without losing the interaction between infants and their
Hirsh-Pasek, Golinkoff, & Hennon, 2006; Yu, Smith, & Pereira,           environment throughout the task. In other words, the model’s
2008) and learning phonological patterns (Goldstein & Schwade,          outputs (where it is going to “look”) should determine its next
2008; Thiessen, Hill, & Saffran, 2005). For example, 15-month-          inputs (what it will “see” next).
olds are able to follow a turning face to an object, and then map a
spoken word onto that object rather than a non-cued object                 Previous computational work has dealt with isolated aspects of
(Houston-Price, Plunkett, & Duffy, 2006).                               the paradigm used in W&K. The HAB model (Sirois & Mareschal,
                                                                        2004) can successfully account for robust non-linearities in infant
     Wu and Kirkham (2010) – hereafter W&K – measured gaze              preferential looking data, using two interacting auto-associator
behavior when infants were presented with dynamic audio-visual          networks that learn under opposite principles. However, HAB
events (i.e., cats moving to a bloop sound and dogs moving to a         neither incorporates multimodal learning nor attentional cueing,
boing sound) in white frames in the corners of a black background.      and its outputs do not determine its inputs. On the other hand,
An object’s appearance in a spatial location consistently predicted     Mozer and Sitton (1998) proposed a computational model of visual
a location-specific sound. On every familiarization trial, infants      attention that embodies the notion of an attentional “spotlight” and
were shown identical audio-visual events in two diagonally              accounts for several cueing effects. In order to prevent interference
opposite corners of the screen (i.e., two valid binding locations).     when multiple objects are processed in a single hierarchical
To test the effects of attentional cueing on audio-visual learning,     network, the authors used a winner-take-all network (WTA) that
either a social cue (i.e., a central turning face that used infant-     ‘attended’ to one input region while filtering the others.
directed speech, Social Cue condition) or non-social cue (i.e., red     Importantly, the amount of information filtered in unattended
                                                                                                                                            1	  
	  
                                                                    2377

regions was critical to determine attentional shifts. However,                representations and the representational changes elicited by
explaining the differences between social and non-social cues in a            moving stimuli were not thought to be essential in the simulated
multimodal learning paradigm such as used in W&K was beyond                   experiment. Rather, our computational model focuses on
the scope of this model, since it was trained exclusively in the              understanding which information is being sent forward to
visual modality.                                                              associative structures, and on testing the nature of the attentional
                                                                              mechanisms involved.
     In an attempt to bridge this gap between the two fields we
introduce a neuro-computational model that generates a proper
sequence of saccades to learn from cued multimodal events. The
main challenge in this endeavour was to connect different
computational models without producing an intractable model.
                                   Model
     	  The model (illustrated in Figure 1) is essentially an adaptation
of Sirois and Mareschal's architecture for infant habituation (Sirois
& Mareschal, 2004), combined with Mozer and Sitton's model of
visual attention (Mozer & Sitton, 1998). However, the model
departs from the former in that it is capable of multimodal learning
among distractors, and from the latter in that the WTA network is
thought to model overt rather than covert attentional shifts. One
novel and critical feature of the model is that it is wired in a
feedback loop, whereby its last output determines its current
inputs. In this way, we can attempt to simulate the processes taking
place in the infant's brain as the sequence of visual and audio
events unfolds during training and test trials. Figure 1 illustrates
the W&K experiment and the proposed model, which we now
describe in detail.
     Simulations begin with the presentation of one of two possible
multimodal pairs at the model's input level. In W&K, the target
events consisted of identical toy animals (cats or dogs) that moved
synchronously at diagonally opposite corners of the screen, while
accompanied by a repetitive sound. In the model, these inputs are
simplified as patterns of activations distributed over visual and
auditory units that remain clamped throughout the trial. There are
five sets of N visual input units, each corresponding to an Area of
Interest (AOI hereafter) in W&K’s eye-tracking study, and a single
set of N auditory units (N = 4 in the figure and the simulations).
The pattern of activation attributed to the cat toy is presented both
                                                                                                                                                   	  
in the bottom left and top right visual banks, while another pattern
in the center corresponds to the face cue, which in the Social Cue
condition was presented with the target events during training. The           Figure 1:	  A rchitecture of the model. Two auto-associator networks
activation pattern corresponding to the sound is presented in the             are trained to store (left network, Hopfield Network [HN]) or
auditory input bank.                                                          suppress (right network, Novelty Detector [ND]) the activation
                                                                              pattern elicited by some attended part of a multimodal input event
     Next, it is important to motivate these input assumptions. In            (filtered input level). The states to which these networks converge
many computational studies of multimodal learning (Althaus &                  are fed into a winner-take-all network of location units (WTA
Mareschal, in press; Mayor & Plunkett, 2010), input patterns are              network, upper network). The winning unit determines the next
derived from actual pixilated images and Mel-scale filtered voices,           saccade of the model: which object will be attended to and which
whereas our inputs are simple arbitrary patterns in the spirit of the         one will be filtered.
HAB model (Sirois & Mareschal, 2004). In addition (and at odds
with the dynamical nature of the actual stimuli), our input patterns             Indeed, not all visual inputs are forwarded to the associative
are randomly generated only once at the beginning of the                      networks: we assume that some attentional filtering is exerted by
simulation, and they remain clamped for every trial. These choices            the WTA network (dynamics explained in the next section). Every
were made considering that the actual similarity between                      time a saccade is made, this filtering lets information about the
                                                                                                                                                 2	  
	  
                                                                          2378

attended AOI pass through undisturbed, whereas in other AOIs                phenomenon of inhibition of return that can last for several
only a fraction of the activation is forwarded. This filtering              seconds (Klein, 2000), we suppress activation in the winning unit
mechanism and the WTA network that produces it come from                    until the next saccade is made, which favors foraging of the visual
Mozer and Sitton's model of visual attention (Mozer and Sitton,             scene.
1998), except for the default amount of filtering exerted on
unattended regions which was of 90% in Mozer and Sitton,                                                 Simulations
compared to 50% in our model. This difference reflects the fact
that attentional systems are subject to cortical maturation (Johnson,       Procedure
1990), although its precise value was arbitrary and needs to be                The simulations procedure followed the paradigm used in
investigated further. The filter only operates on visual inputs, and it     W&K. After checking that each sub-network (HN, ND and WTA)
is initialized in a state that depends on the cue and target condition.     was operational, 20 models were generated, similar to the average
At the beginning of a trial, central patterns are less likely to be         number of infants in each of the three conditions. Models were
filtered, following experimental data showing that babies are more          generated at random and thus differed in their input representations
likely to look at the center (because of the attention getter that was      and initial connection weights. Each model was trained over four
just presented centrally). Filtered and unfiltered inputs are then          familiarization blocks, where one block contained six trials of
forwarded to the auto-associator networks.                                  target events (three trials per event type). Target events were
                                                                            randomized, but the same target could not be presented for more
     Auditory and visual patterns then arrive in the core of the model,     than two trials in a row. A trial was limited to 10 cycles, during
which consists of two auto-associator networks: the Hopfield                any of which the connection weights in HN and ND were updated.
network (HN in Figure 1) and the novelty detector (ND in Figure             Testing took place at the end of each block, and consisted of two
1). This dual system comes from the HAB model (Sirois and                   trials, where the auditory pattern for each target event was
Mareschal, 2004), and like HAB, this is the only part of our model          presented alone for 10 cycles. Mean proportional looking times
that learns by modifying connection weights during every cycle in           and standard errors were then calculated from output saccades to
each trial of the training phases. HN and ND are fully connected            the five AOIs.
networks of 6N units each, with small connection weights initially
generated at random. Each network is presented with full auditory              We simulated 4 cueing conditions: No Cue (50% filter), Square
and filtered visual patterns. However, the networks differ in the           Cue (70% filter), Social Cue (90% filter), and Social Cue (70%
associative learning rule they use: whereas HN uses Hebbian                 filter). In all conditions, the information from the attended location
learning to strengthen connections between active units, ND uses            was entirely sent forward. However, in the No Cue condition,
anti-Hebbian learning to decrease these same connections. Over              models were initialized with unattended filters set to 50%, meaning
the course of training, HN comes to memorize the patterns it was            that only 50% of activation from unattended locations could
exposed to by virtue of repeated auto-associations between                  propagate to the associative systems. By contrast, Social Cue and
coactive parts, so much so that eventually presentation of a part           Square Cue conditions had more stringent filters for unattended
(for instance the audio part) is sufficient to retrieve the entire          locations (either 70% or 90% depending on the cue and the
trained pattern. Meanwhile ND progressively learns to suppress the          hypothesis being tested), meaning that less information from these
activation elicited by the patterns it is being trained with, so that       locations was let through. The Social Cue (70%) condition acted as
eventually trained patterns are perfectly suppressed and new                a control for our hypothesis that social cueing increases attentional
patterns produce large activities; they are, in this sense, detected.       filtering. If the improvement in learning observed for the Social
Finally, HN and ND do not gate each other's inputs and outputs, as          Cue 90% relative to the Square Cue condition was not due to the
they do in HAB, but rather the visual units in each network sends           increased filter but rather to the central presence of a visual
their activation forward to the WTA network.                                stimulus, then the same improvement should be expected when the
                                                                            filter is lowered down to 70%, which was used for the Square Cue
     The WTA network (Figure 1, top network) is the structure of the        condition. Apart from the manipulation of this single parameter for
model that determines where it will "look" next. It is a standard           the purposes of hypothesis testing, exactly the same set of
WTA network (as in Mozer and Sitton, 1998) of five units, one for           parameters was used for all models and for all conditions (an
each AOI. WTA units increase their own activity by way of auto-             exhaustive list of equations and simulation parameters is not
excitation, and also receive activation from units of the same AOI          specified here for lack of space, but is available upon request to the
in HN and ND. Critically, WTA units are wired so as to compete              first author).
with one another via inhibitory connections. The net effect of this
entire set-up is that the unit that receives the most input will build      Results
activation faster and win the competition, by which we mean that
                                                                               We now report simulated mean percent looking time, as well as
its activity crosses a .95 threshold and triggers an ocular saccade to
                                                                            standard errors for the model. For each test trial (10 cycles), we
the corresponding AOI. Triggering a saccade in the model means
                                                                            calculated the proportion of cycles where the model attended to
changing the filter's values so as to change the flow of information
                                                                            each AOI, and averaged on all networks and all trials. We believe
from input to auto-associator networks. Consistent with the
                                                                            this is sufficient for the purpose of showing that the model exhibits
                                                                                                                                                 3	  
	  
                                                                        2379

a pattern of results consistent with the differences observed in            Figure 2, middle, black bars were superior to white bars), while
W&K with or without cues, and between types of cues.                        disregarding the multimodal information (black bars are of equal
                                                                            height). By contrast, “deep learning” was observed in the Social
Cued versus non-cued learning                                               Cue condition, but only in the last two blocks, where infants
     Over the four blocks in W&K’s No Cue condition, infants were           looked significantly more at the correct cued location than at any
equally likely to look at all locations when presented with the             other peripheral location (in Figure 2, bottom, the correct black bar
auditory cue. In particular, the authors failed to find any significant     is higher than the incorrect black bar and both white bars).
advantage of lower locations (labeled “cued” in Figure 2, for
consistency with other conditions) over upper locations (labeled            Table 1: Proportional looking times (Means and SE) for
“non-cued”) that could have accounted for a bias in the other               Infants and Model in the simulated conditions.
conditions. This finding is mirrored in our simulations, where cued
and non-cued locations are indistinguishable. However, the model                  Condition                     Infants         Model
was slightly more likely to look at the center than at any other                                                Mean (SE)       Mean (SE)
locations.                                                                        No Cue (50%)
                                                                                  Cued, correct                 0.21 (.03)      0.14(0.04)
     By contrast, when multimodal training events were cued in                    Non cued, correct             0.18 (.02)      0.22(0.05)
W&K’s study, infants looked significantly more at cued locations                  Cued, incorrect               0.17 (.02)      0.18(0.04)
(in the Square condition) or cued correct locations (in the Social                Non Cued, incorrect           0.22 (.03)      0.18(0.04)
condition, last two blocks) during test trials. The middle right and              Central                       0.23 (.03)      0.27(0.05)
bottom right graphs in Figure 2 show the same advantage in the                    Square Cue (70%)
model for cued locations over non-cued locations.                                 Cued, correct                 0.23 (.03)      0.31 (.04)
                                                                                  Non cued, correct             0.15 (.03)      0.11 (.02)
                                                                                  Cued, incorrect               0.26 (.03)      0.33 (.04)
                                                                                  Non Cued, incorrect           0.18 (.03)      0.11 (.03)
                                                                                  Central                       0.19 (.03)      0.14 (.03)
                                                                                  Social Cue (90%)
                                                                                  Blocks 1 & 2
                                                                                  Cued, correct                 0.15 (.03)      0.24 (.02)
                                                                                  Non cued, correct             0.18 (.03)      0.14 (.02)
                                                                                  Cued, incorrect               0.25 (.03)      0.23 (.02)
                                                                                  Non Cued, incorrect           0.16 (.03)      0.06 (.02)
                                                                                  Central                       0.25 (.03)      0.33 (.03)
                                                                                  Blocks 3 & 4
                                                                                  Cued, correct                 0.26 (.04)      0.26 (.03)
                                                                                  Non cued, correct             0.11 (.02)      0.10 (.02)
                                                                                  Cued, incorrect               0.17 (.03)      0.20 (.02)
                                                                                  Non Cued, incorrect           0.14 (.03)      0.13 (.02)
                                                                                  Central                       0.32 (.04)      0.32 (.03)
                                                                                  Social Cue (70%)
                                                                                  Blocks 1 & 2
                                                                                  Cued, correct                 -               0.19 (.04)
                                                                                  Non cued, correct             -               0.16 (.03)
	                                                                                Cued, incorrect               -               0.17 (.04)
                                                                                  Non Cued, incorrect           -               0.14 (.02)
Figure 2: Mean proportional looking times for the model (right)                   Central                       -               0.33 (.04)
and for infants (center), with the corresponding typical stimuli                  Blocks 3 & 4
used in each experiment during training (left screenshots, note that              Cued, correct                 -               0.15 (.04)
no visual stimuli were provided during test) in No Cue, Square
                                                                                  Non cued, correct             -               0.14 (.03)
                                                                                  Cued, incorrect               -               0.18 (.04)
Cue, and Social Cue conditions (resp. top, middle and bottom
                                                                                  Non Cued, incorrect           -               0.15 (.03)
panels). Figure adapted from Wu & Kirkham (2010).	  
                                                                                  Central                       -               0.37 (.04)
Differences between cues
     The main finding from W&K was that different cues produced                The “Social 90%” entry in Table 1 is divided in Blocks 1&2 and
different types of learning. What we might call “shallow learning”          Blocks 3&4, to be compared to the block analysis carried out in
was observed in the Square Cue condition, where infants looked              W&K. We see that the model can reproduce the same late but deep
preferentially at locations that had been cued during training (in          learning effect: it is more likely to look at the correct cued location
                                                                                                                                                  4	  
	  
                                                                        2380

only in the last two blocks, thereby showing a learning curve. The         Explaining social cues versus square cues
agreement between infants and the model on Blocks 3&4 is                      We have tested the hypothesis that the superior learning
illustrated in Figure 2, bottom panel. However, note that in the first     observed with social cues resulted from a kind of narrowing of the
two blocks, the model exhibits the same pattern of results as in the       infant’s receptive fields. While maintaining the original cueing
Square Cue condition (preferential looking to both cued locations,         mechanism, this narrowing was modeled by more stringent filters
in equal proportion), whereas infants tended to look at cued               for every other location than the fixated and the cued locations
incorrect locations.                                                       (that could possibly differ). Instead of the usual 50%, only 30%
                                                                           activation would be forwarded in the Square Cue 70% condition,
     This behavior can be contrasted with the looking times observed
                                                                           against 10% in the Social Cue 90% condition.
in the “Social Cue 70%” condition, which was a control for our
hypothesis that social cueing increases attentional filtering (as             The net effect of this assumption is to minimize interference in
shown in Table 1, these simulations do not have a counterpart in           HN: the network is equally biased to attend to the cued locations in
infant data). Table 1 shows that no preference for cued object             the Square Cue and the Social Cue conditions (as in W&K) during
locations was apparent in the Social Cue 70% condition, and cued           familiarization, but only in the latter can it associate precisely the
locations were only marginally superior to non-cued locations.             cued visual information to the auditory patterns during test. In the
This suggests that the improvement in learning observed for the            former condition, the unfiltered activation that comes from the
Social Cue 90% condition relative to the Square Cue 70%                    non-cued location gets involved in the association, so that during
condition was due to the increased filter, rather than the presence        test trials, part of the activation pattern for the non-cued correct
of a central stimulus.                                                     location is retrieved, which disturbs the WTA network.
                      General Discussion                                   Role of different parts of the model in this account
     Although a true understanding of this model can only be                  In this account, it would appear that the best part is played by
achieved through a detailed enquiry into training saccades and the         the HN network, while ND appears to have no explanatory power.
mechanisms behind them, here we wish to provide the reader with            This is not so, but the role of the ND is obscured by the fact that in
elements of explanation that might shed some light on our main             this model ND is much more active in early phases of training.
results.                                                                   When training begins, ND has not yet learned how to suppress
                                                                           activation for training input patterns. Thus, through ND every
Explaining the impact of cueing                                            unfiltered piece of information can contribute to the competition in
     Cueing in the model is achieved by letting through more               the WTA. As training unfolds, however, ND learns to suppress
activation from the location that is being cued, than would                activation for known patterns, thereby ensuring that unfiltered
normally be allowed. That is, if the model is “looking”, say, at the       information cannot use this path anymore to drive the model’s
upper right location while the lower right location is cued, 70%           output. This difference between early and late training might be the
activation from the lower right is forwarded to the associative areas      reason for the learning effect observed in the Social Cue 90%
rather than the usual 50% when there is no cue.                            condition, although this cannot explain why the same effect was
                                                                           not found in the Square condition.
     This simple mechanism means first, that in the auto-associator
networks, some learning will occur for cued locations even if the          Size of auditory input
model actually never “looks” at them, and second, that the model              One unexpected clue to understanding the network that might be
in fact will be biased to look at these cued locations. This is            of significance is the size of the auditory input pattern. The tuning
because the increase of activity drives the HN auto-associator into        phase of the network revealed that large auditory formats were
a state that resembles more and more the cued location, so that the        detrimental to the model’s learning capacity, while the best
corresponding unit in the WTA network would be fed more                    performance was obtained when it was equal to N (the size of one
activation and would tend to win the competition more often. As            set of visual units). The reason for this is as follows. Auto-
training proceeds, these two effects reinforce each other and help         associator networks are known to be very sensitive to the
the model associate auditory patterns to cued objects, which               correlation between the patterns to be stored, and this is especially
explains how it is able to account for experimental differences            true of the kind of Hebbian learning rule used in HAB and in this
between cued and non-cued conditions. However this mechanism               model. When the patterns of activity that are to be memorized are
alone cannot explain why the model fails to distinguish between            too close from one another, as they are when the auditory units
cued correct and cued incorrect locations in the Square condition          vastly outnumber the set of active visual units, interference occurs,
and succeeds only in the last two blocks of the Social condition.          and the network can converge to wild configuration states, often
Instead, with only this mechanism, the model treats all cues               called “spurious attractors” (Hopfield et al., 1983). Therefore,
equally.                                                                   limiting auditory inputs to the same format as a single visual
                                                                           location makes multimodal patterns more different to one another
                                                                           and makes for better learning. It would be interesting to investigate
                                                                           how this prediction of the network could be tested in the lab.
                                                                                                                                                5	  
	  
                                                                       2381

                           Conclusion                                        Houston-Price, C., Plunkett, K., & Duffy, H. (2006). The use of
                                                                          social and salience cues in early word learning. Journal of
     We have presented a neuro-computational model that builds on
                                                                          Experimental Child Psychology, 95(1), 27-55.
two successful predecessors coming from different fields of
                                                                             Johnson, M. H. (1990). Cortical maturation and the development
cognitive science. The model can account for new infant data
                                                                          of visual attention in early infancy. Journal of Cognitive
involving cued multimodal learning in the presence of distractors.
                                                                          Neuroscience, 2, 81- 95.
In particular, we have found a candidate mechanism that might
                                                                             King, A. J., Schnupp, J.W.H., Carlile, S., Smith, A. L., &
underlie largely observed differences between social and non-
                                                                          Thompson, I. D. (1996). The development of topographically-
social cues in infancy. This mechanism holds that infants make use
                                                                          aligned maps of visual and auditory space in the superior
of more stringent attentional filters when they are exposed to social
                                                                          colliculus. In B. E. Stein, M. Narita and T. Bando eds):
cues than to non-social cues.
                                                                          Extrageniculostriate Mechanisms of Visually Guided Orientation
                                                                          Behavior., Progress in Brain Research, 112, pp. 335-50.
                             Prospects
                                                                             Klein, R. M. (2000). Inhibition of return. Trends in Cognitive
     Future research should aim to better understand how the              Sciences, 4(4), 138-147.
network behaves, presumably by tracking down the evolution of                Lee, D. K., Itti, L., Koch, C. & Braun, J. (1999). Attention
proportional looking times as training unfolds, and by lesioning          activates winner-take-all competition among visual filters, Nature
parts of the network one at a time to assess whether and how its          Neuroscience, 2(4), pp. 375-81.
behavior is affected. In the long term, the model could also be              Levy, W. B., Hocking, A. B., & Wu, X. (2005). Interpreting
improved by strengthening its links to the brain. For instance,           hippocampal function as recoding and forecasting. Neural
Sirois and Mareschal related HN and ND to the cortex and the              Networks, 18(9), 1242-1264.
hippocampus, respectively, and the model might be improved by                Mayor, J., & Plunkett, K. (2010). A neuro-computational
reinstating the interaction that was originally present between these     account of taxonomic responding and fast mapping in early word
two systems in HAB. More generally, the cortex, hippocampus,              learning. Psychological Review, 117, 1-31.
and superior colliculus all perform more than one function that              McClelland, J. L., McNaughton, B. L., & O'Reilly R. C. (1995).
might well be relevant in this model, for instance coding for             Why there are complementary learning systems in the
auditory maps in the case of the colliculus (King et al,, 1996), or       hippocampus and neocortex: insights from the successes and
input recoding (Levy et al., 2005), and interleaved learning              failures of connectionist models of learning and memory.
(McClelland et al., 1995) in the case of the hippocampus. A model         Psychological Review, 102, 419–457.
that could recode input patterns for better storage and present them         Mozer, M. C., & Sitton, M. (1998). Computational modeling of
repeatedly to the infant during less active periods could offer new       spatial attention. In H. Pashler (Ed.), Attention (pp. 341-393). East
perspectives into how infants succeed universally in learning what        Sussex: Psychology Press Ltd.
to learn.                                                                    Pruden, S. M., Hirsh-Pasek, K., Golinkoff, R. M., & Hennon, E.
                                                                          A. (2006). The birth of words: Ten-month-olds learn words
                      Acknowledgments                                     through perceptual salience. Child Development, 77(2), 266-280.
     We thank Natasha Kirkham, Denis Mareschal, Jochen Triesch,              Sirois, S., & Mareschal, D. (2004). An interacting systems
Michael Thomas, Chen Yu, Shohei Hidaka, Eddy Davelaar,                    model of infant habituation. Journal of Cognitive Neuroscience,
Sylvain Sirois, Dan Yurovsky, Bruno Laeng, Nadja Althaus, and             16, 1352-1362.
Jonathan Grainger for their comments on this work. Presentation of           Thiessen, E. D., Hill, E. A., & Saffran, J. R. (2005). Infant-
this proceeding was supported by the British Academy Overseas             directed speech facilitates word segmentation. Infancy, 7(1), 53-71.
Conference Grant awarded to RW.                                              Wu, R., & Kirkham, N. Z. (2010). No two cues are alike: Depth
                                                                          of learning is dependent on what orients attention. Journal of
                            References                                    Experimental Child Psychology, 107, 118-136.
     Althaus, N. and Mareschal, D. (in press). Early language as
multimodal learning. Proceedings of the 12th Neural Computation
and Psychology Workshop.
     Gliga, T., & Csibra, G. (2009). One-year-old infants appreciate
the referential nature of deictic gestures and words. Psychological
Science, 20(3), 347-353.
     Goldstein, M. H., & Schwade, J. A. (2008). Social feedback to
infants' babbling facilitates rapid phonological learning.
Psychological Science, 19(5), 515-523.
     Hopfield, J. J., Feinstein D. I., & Palmer R, G. (1983).
'Unlearning' has a stabilizing effect in collective memories. Nature,
304(5922), 158–159.
                                                                                                                                             6	  
	  
                                                                      2382

