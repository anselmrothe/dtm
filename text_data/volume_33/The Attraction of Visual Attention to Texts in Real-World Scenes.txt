UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Attraction of Visual Attention to Texts in Real-World Scenes
Permalink
https://escholarship.org/uc/item/9cn7h1bs
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Wang, Hsueh-Cheng
Pomplun, Marc
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

                  The Attraction of Visual Attention to Texts in Real-World Scenes
                                         Hsueh-Cheng Wang (hchengwang@gmail.com)
                                                Marc Pomplun (marc@cs.umb.edu)
                              Department of Computer Science, University of Massachusetts at Boston,
                                           100 Morrissey Boulevard, Boston, MA 02125 USA
                             Abstract                                  likely to be fixated in a natural search task based on the
   Intuitively, it seems plausible that in real-world scenes,
                                                                       expected location of the target.
   attention is disproportionately attracted by texts. The present       The goal of the present study was to investigate the
   study tested this hypothesis and examined some of the               contribution of low-level visual saliency and high-level
   underlying factors. Texts in real-world scenes were compared        features to the ability of texts to attract attention in real-
   with paired control regions of similar size, eccentricity, and      world scene viewing. To test if texts are more attractive than
   low-level visual saliency. The greater fixation probability and     other scene objects, an eye-tracking database of scene
   shorter minimum fixation distance of texts showed their             viewing by Judd, Ehinger, Durand, and Torralba (2009) was
   higher attractiveness. These results might be caused by the
   prominent locations or special visual features of text. In
                                                                       re-analyzed in Experiment 1.
   another experiment, texts were removed from the scenes, and
   the results indicated that the locations that used to contain          Experiment 1: Reanalysis of Previous Data
   texts did draw more attention than controls. Finally, texts
   were placed in unexpected positions in front of homogeneous
   and inhomogeneous backgrounds. These unconstrained texts
                                                                       Method
   were found more attractive than controls, with background
   noise reducing this difference, which indicates that the              Participants. Judd and colleagues (2009) collected eye
   attraction by specific visual features of text was superior to      tracking data of 15 viewers. These viewers were males and
   typical saliency.                                                   females between the ages of 18 and 35. Two of the viewers
   Keywords: real-world scenes; scene syntax; text; eye
   movements; visual attention; LabelMe.
                                                                       were researchers on their project and the others were naive
                                                                       viewers.
                          Introduction                                    Apparatus. All viewers sat at a distance of
                                                                       approximately two feet from a 19-inch computer screen of
When inspecting real-world scenes, human observers                     resolution 12801024 in a dark room and used a chin rest to
continually shift their gaze to retrieve information.                  stabilize their head. An eye tracker with the sampling rate of
Important pieces of information could be, for instance,                240 Hz recorded their eye movements on a separate
depictions of objects (e.g., cars, monitors, or printers) or           computer.
texts, which could be shown on depictions of signs, banners,              Procedure. All participants freely viewed each image for
license plates, and other objects. Observers’ attention has            3 seconds, separated by 1 second of viewing a gray screen.
been found to be biased toward visually salient locations,             To ensure high-quality tracking results, camera calibration
e.g., high-contrast areas, during scene viewing or search (Itti        was checked every 50 images. All images were divided into
& Koch, 2001). Torralba, Oliva, Castelhano, and Henderson              two sessions of 500 randomly ordered images. Each session
(2006) suggested that scene context, i.e., the combination of          was done on average at one week apart. After every 100
objects that have been associated over time and are capable            images being presented, participants were asked to indicate
of priming each other to facilitate object and scene                   which images they had seen before to motivate them to pay
categorization, predicts the image regions likely to be                attention to the images
fixated. Võ and Henderson (2009) claimed that scene                       Stimuli. There were 1003 images in the database by Judd
syntax, i.e., the position of objects within the specific              et al. (2009), and these images included both outdoor and
structure of scene elements, influences eye movement                   indoor scenes. Some of these images were selected from the
behavior during real-world scene viewing.                              LabelMe database (see below).
  It is still an open question whether texts in real-world                Analysis. To identify and localize text in real-world
scenes attract more attention than comparable regions and              scene stimuli, we used the freely available LabelMe image
why this would be the case. It is possible that low-level              dataset (Russell, Torralba, Murphy & Freeman, 2008)
visual saliency attracts attention, i.e., that texts are more          containing a large number of scene images that were
attractive because they typically carry higher saliency – as           manually segmented into annotated objects. The locations of
computed along the lines of Itti and Koch (2001) - or                  objects are provided as coordinates of polygon corners and
luminance contrast. Moreover, it is also possible that the             are labeled by English words or phrases. Out of the 1003
positions of texts are more predictable in the scene context           images we selected 57 images containing 240 text-related
to contain important information, for example, texts on                labels and 93 images containing non-text objects. The text-
street signs. Such an effect would be in line with the model           related labels included terms such as ‘text’, ‘banner’, or
by Torralba et al. (2006), which predicts the image regions
                                                                   2733

‘license plate’. For the non-text objects, we excluded objects
with text-related labels or background labels, e.g., ‘floor’,
‘ceiling’, ‘wall’, ‘sky’, ‘crosswalk’, ‘ground’, ‘road’, ‘sea’,
‘sidewalk’, ‘building’, or ‘tree’. The label 'face' was also
excluded since faces have been shown to be particularly
attractive (see Judd et al., 2009, for a review). There were
1620 non-text objects in the final selection. The resolution
of these images was adjusted to 1024768 pixels, and the
coordinates of all objects were updated accordingly.
    The raw eye movement data was smoothed using a
computer program developed by Judd et al. (2009) that
calculates the running average over the last 8 data points
(i.e., over a 33.3 ms window). A velocity threshold of 6               Figure 1. Texts (yellow polygons) and their paired control
degrees per second was used for saccade detection.                       regions (green polygons) in one of the scene stimuli.
Fixations shorter than 50 ms were discarded (see Judd et al.,
2009).
                                                                        Table 1: Average characteristics of text objects, non-text
   It is known that eccentricity (the distance between the                            objects, and control regions.
center of an object to the center of the screen) and size
(number of pixels) of an object might influence eye
                                                                                               Size     Ecc.      Sal.   LumC.
movement measures. Observers show a tendency to fixate
                                                                      Experiment 1
near the center of the screen when viewing scenes on
                                                                        Text                   2631     283      0.41      40
computer monitors (Tatler, 2007). Larger objects tend to be
                                                                        Non-Text               2828     292      0.41      40
fixated more frequently since the landing probability
                                                                        Con. Region            2631     283      0.37      46
increases with larger area. Low-level visual features such as
                                                                      Experiment 2
saliency and luminance contrast were computed. Saliency
                                                                        Erased Text            2631     283      0.43      21
was calculated by the freely available computer software
                                                                        Non-Text               2676     293      0.41      24
“Saliency Map Algorithm” using the standard Itti, Koch,
                                                                        Con. Region            2631     283      0.37      36
and Niebur (1998) saliency map based on color, intensity,
                                                                      Experiment 3
orientation, and contrast. The average saliency value of
pixels inside an object boundary was used to represent                  UncText H B            2351     288      0.20      10
object saliency. Luminance contrast was defined as the                  UncText INH B          2723     281      0.39      55
gray-level standard deviation of pixels enclosed in an                  UncText H              2351     288      0.24      34
                                                                        UncText INH            2723     281      0.40      57
object. On average, text objects occupied 1.43% of the area
                                                                        Non-Text H             2670     301      0.27      34
in a 1024×768 pixel display.
   To derive compatible control objects, non-text objects               Non-Text INH           2746     284      0.41      57
were binned by eccentricity (smaller than 200, between 200              Con. Region H          2351     287      0.28      40
and 300, and greater than 300) and size (smaller than 1650,             Con. Region INH        2723     281      0.41      55
between 1650 and 5600, and greater than 5600). These
ranges of eccentricity and size were selected to roughly               In order to measure the attraction of visual attention, two
include the same number of objects in each interval. Each           object-based eye movement measures were taken: fixation
text object was paired with one non-text object within the          probability (the probability of a fixation to land inside a text
same size and eccentricity interval and matched in terms of         or non-text object or a control region during a trial) and
saliency and luminance contrast as closely as possible. A           minimum fixation distance (the shortest Euclidean distance
text object and its non-text match were typically selected          from the center of the object to any fixation during a trial).
from different images.                                              If an object had higher fixation probability or shorter
   Additionally, for each text object a control region in the       minimum fixation distance, the object was considered more
same scene was set up that matched its counterpart exactly          attractive. If there was no fixation landing inside an object
in its shape and size and had similar eccentricity (Ecc.),          boundary, its fixation probability was 0 regardless of how
saliency (Sal.), and luminance contrast (LumC.) (see Figure         close a fixation approached the object. Minimum fixation
1). The control regions could enclose non-text objects or           distance was measured to overcome this drawback and
backgrounds but did not intersect with any text objects. The        provide convergent evidence for any attractiveness results.
characteristics of text objects, non-text objects, and control
regions (Con. Region) are summarized in Table 1.
                                                                2734

                                                                                  Experiment 2: Erased Text
Results and Discussion
                                                                    To test whether the locations of text placement contribute to
Fixation probability and minimum fixation distance of texts,        the attractiveness of texts, in Experiment 2 we “erased” the
non-texts and control regions are shown in Figure 2. The            text parts from text objects and examined whether the
fixation probability of texts was significantly higher than the     observers’ attention was still biased toward these objects.
one of non-text objects and control regions, both Fs(1; 14) >       The text removal sometimes causes strong oddness, e.g., for
76.85, ps < 0.001. Minimum fixation distance of texts was           a stop sign, but sometimes does not, such as for a billboard.
shorter than the one of non-text objects and control regions,       This oddness is due to viewers expecting text in that
both Fs(1; 14) > 46.53, ps < 0.001. Both results were               location, which might possibly attract more attention.
consistent and suggested that texts were more attractive than
both non-text objects and control regions. In addition, non-
text objects had higher fixation probability and shorter            Method
minimum fixation distance than control regions, both Fs(1;
14) > 45.15, ps < 0.001. The results might be caused by
                                                                       Participants. Fifteen participants performed this
control regions not having an obvious boundary like texts
                                                                    experiment. All were students at the University of
and non-text objects.
                                                                    Massachusetts Boston, aged between 19 to 40 years old, and
                                                                    had normal or corrected-to-normal vision. Each participant
                                                                    received 10 dollars for participation in a half-hour session.
                                                                       Apparatus. Eye movements were recorded using an SR
                                                                    Research EyeLink-II system with a sampling frequency of
                                                                    500 Hz. After calibration, the average error of visual angle
                                                                    in this system is 0.5˚. Stimuli were presented on a 19-inch
                                                                    Dell P992 monitor with a refresh rate of 85 Hz and a screen
                                                                    resolution of 1024×768 pixels. Participants’ responses were
                                                                    entered using a game-pad.
                                                                       Procedure. After participants read the instructions, a
                                                                    standard 9-point grid calibration (and validation) was
                                                                    completed. Following two practice trials, participants
                                                                    viewed 130 stimuli in random order. They were instructed
                                                                    to freely inspect the scene. At the start of each trial, a drift
                                                                    calibration screen appeared, and participants were instructed
                                                                    to look at the calibration dot that appeared in the center of
                                                                    the screen. After subjects had passed the drift correction, the
                                                                    stimuli were presented. Following a ten-second presentation
Figure 2. Fixation probability and minimum fixation
                                                                    of each scene, the stimulus disappeared and the calibration
distance of texts, non-texts, and control regions. In this chart
                                                                    dot appeared again. In some cases, calibration and
and all following ones, error bars are based on 95%
                                                                    validation were performed once again to increase eye-
confidence intervals.
                                                                    tracking accuracy.
   The observed effect might be caused by low-level visual             Stimuli. The same 57 images and 240 text regions used
saliency as computed by the Saliency Map Model (Itti &              in Experiment 1 were employed in Experiment 2. However,
                                                                    in Experiment 2, the “text parts” in text objects were
Koch, 1998), high-level features (expected locations), or
                                                                    removed manually by replacing them with the background
maybe unique visual features of texts. Texts, like faces,
                                                                    color of the texts as shown in Figure 3. This removal led to
might have their unique visual features that are unrelated to
                                                                    a reduction in average luminance contrast from 40 to 21 (see
typical low-level visual saliency so that human observers
                                                                    Table 1). Nonetheless, the average saliency was not affected
develop "text detectors" during everyday scene viewing.
                                                                    by this text removal, due to the computation of saliency
The selected controls ruled out the first hypothesis of low-
level visual saliency. We will test how expected locations          being based on center-surround differences in color,
                                                                    intensity, and orientation. Note that luminance contrast was
affect eye movements in Experiment 2, and the influence of
                                                                    computed exclusively within an object, but saliency was
unique visual features of texts on attention will be examined
in Experiment 3.                                                    calculated according to the whole image, and the neighbor
                                                                    regions of an object were taken into account. Therefore, a
                                                                    stop sign might still be salient without the text “stop”
                                                                    because of the color difference between the sign and its
                                                                    surroundings but its luminance contrast is reduced since
                                                                    there is no contrast inside the sign.
                                                                2735

                                                                     unique visual features of text by adding visual noise, and we
                                                                     expected to find less attraction of attention by texts in front
                                                                     of such inhomogeneous background.
Figure 3. Erased texts and their paired control regions in a
scene.
   Analysis. The raw eye movement data were parsed using
the standard EyeLink algorithm. Eye fixation data were
analyzed separately for the first 3 seconds and for the entire
10-second viewing duration. Since this study did not
involve any post-presentation questions, the first 3 seconds
of viewing should be comparable with the total 3 seconds of
viewing in Experiment 1. As described in Experiment 1,
non-text objects and control regions were chosen based on
similar size, eccentricity, saliency, and luminance contrast
(see Table 1). Since saliency and luminance contrast were            Figure 4. Fixation probability of texts in Experiment 1,
positively correlated, r = 0.34, luminance contrast of control       erased texts in Experiment 2, and non-texts and control
regions (36) was higher than that of removed-text regions            regions in both experiments.
(21).
Results and Discussion
As shown in Figure 4, for 3-second viewing in Experiment
2, fixation probability for erased texts dropped compared to
text objects in Experiment 1, F(1; 28) = 35.82, p < 0.001,
for between-subject ANOVA. Minimum fixation distance
for erased texts was significantly longer in Experiment 2
than for texts in Experiment 1, F(1; 28) = 10.53, p < 0.01
(see Figure 5). These results might be caused by the
reduction of saliency and luminance contrast that
accompanied the erasure of text.
   During 3- and 10-second viewing, erased texts had
slightly higher fixation probability than non-text objects, but
this difference was not statistically significant, all Fs < 1, ps
> 0.33. However, minimum fixation distance for missing
texts was shorter than for non-text objects during 3-second
viewing, F(1; 14) = 25.57, p < 0.001, and 10-second
viewing, F(1; 14) = 14.43, p < 0.01, showing that the typical
locations of text still matter even when they do not contain
any text. This result indicates that part of the attractiveness
of texts derives from their prominent, expected locations in         Figure 5. Minimum fixation distance of texts in Experiment
typical real-world images. To test how the unique visual             1, erased texts in Experiment 2, and non-texts and control
features of texts attract attention without the effects of           regions in both experiments.
expected locations, Experiment 3 dissociated texts from
their typical locations and placed them in front of
homogeneous or inhomogeneous background. The purpose
of using inhomogeneous backgrounds was to reduce the
                                                                 2736

         Experiment 3: Unconstrained Text
Experiment 3 “moved” the text parts to unexpected
locations and placed them on high or low luminance
contrast backgrounds. This design eliminated the influence
of expected locations and tested how the unique visual
features of text affected eye movements.
Method
   Participants. An additional 15 students from the
University of Massachusetts at Boston participated in this      Figure 6. Unconstrained texts (yellow polygons) in front of
experiment. None of them had participated in Experiment 2.      homogeneous (right) and inhomogeneous backgrounds (left)
   Apparatus. Eye movements were recorded using an SR           and their paired control regions (green polygons) in one of
Research EyeLink Remote system. Other settings were the         the scene stimuli.
same as in Experiment 2.
   Procedure. The procedure was identical to Experiment 2.
   Stimuli. To extract the “text part” of a text object, the    Results and Discussion
difference in each of the RGB color components of every
pixel in each text object between Experiments 1 and 2 were      As shown in Figure 7, the fixation probability of
calculated. These patterns of color differences were            unconstrained texts in front of homogeneous background
recreated in other, randomly chosen scenes and placed in        was higher than for non-texts and control regions during 3-
positions where the original size and eccentricity were         second viewing, both Fs(1; 14) > 34.98, ps < 0.001. The
maintained (see Figure 6). These unconstrained texts were       unconstrained texts in front of homogeneous background
prevented from overlapping with regions currently or            (mean fixation probability: 0.18) were as attractive as texts
previously occupied by texts. There were a total of 240         in Experiment 1 (mean fixation probability: 0.18) located in
unconstrained text objects. Half of them were placed on         expected positions, F = 0.01, p > 0.9. For unconstrained
homogeneous background, i.e., regions with the lowest           texts in front of inhomogeneous background, the fixation
luminance contrast of all possible locations before placing     probability was still significantly higher than for non-texts
the text parts, while the others were placed on                 and control regions, both Fs(1; 14) > 14.76, ps < 0.01, but
inhomogeneous background, i.e., those areas with the            the difference was not as large as for unconstrained texts in
highest luminance contrast. To prevent an unconstrained         front of homogeneous background. Although saliency (0.40)
text from being placed on a computationally inhomogeneous       and luminance contrast (57) of inhomogeneous background
but visually homogeneous background, e.g., half black and       were higher than the ones of homogeneous background
half white, the luminance contrast of a candidate region was    (0.24 and 34, respectively), this result suggests that
calculated using 1010 pixels windows covering the              inhomogeneous background caused noise that interfered
candidate region.                                               with identifying the distinctive visual features of texts. For
   As discussed above, inhomogeneous backgrounds might          10-second viewing, the fixation probability for
cause visual noise that interferes with the unique visual       unconstrained texts in front of both homogeneous and
features of texts and thereby reduces the attraction of the     inhomogeneous background as well as for their control
viewers’ attention by such features. Table 1 shows the          regions increased. These results were identical to 3-second
characteristics of the unconstrained text in front of           viewing.
homogeneous background before (UncText H B) and after              For minimum fixation distance, the trends were similar to
(UncText H) the text parts were placed as well as the           fixation probability; unconstrained texts in front of
unconstrained texts in front of inhomogeneous background        homogeneous and inhomogeneous background received
before (UncText INH B) and after (UncText INH) the text         shorter distances and can therefore be considered more
parts were placed.                                              attractive (see Figure 8). Minimum fixation distance of
   Analysis. The analyses were identical to Experiment 2.       unconstrained texts in front of homogeneous background
Both 3- and 10-second viewing durations were analyzed for       was significantly higher than that of their associated non-
unconstrained texts in front of homogeneous and                 text objects and control regions, both Fs(1; 14) > 7.66, ps <
inhomogeneous backgrounds. Each unconstrained text was          0.05. However, the corresponding comparisons for
paired with a non-text object and a control region using the    inhomogeneous background failed to reach significance. For
same methods applied in Experiments 1 and 2. Table 1 lists      10-second viewing, minimum fixation distances of all
the characteristics of paired non-text objects and control      categories were reduced and the results were similar to what
regions.                                                        was found during 3-second viewing.
                                                            2737

                                                                   Torralba et al. (2006). Second, and most importantly, it
                                                                   demonstrates that this factor does not only apply to search
                                                                   tasks but that expected locations play a role even in a free
                                                                   viewing task. By presenting the unique visual features of
                                                                   text in unexpected locations and in both fully visible and
                                                                   degraded variants, the results of Experiment 3 indicated that
                                                                   the specific visual features of texts were superior to typical
                                                                   saliency, and their influence on attention was reduced by the
                                                                   noise caused by inhomogeneous background. We conclude
                                                                   that both low- and high-level features contribute to the
                                                                   ability of texts to attract a disproportionate amount of visual
                                                                   attention in real-world scenes. However, the results obtained
                                                                   in Experiment 3 might also be caused by the replacement of
                                                                   texts inducing semantic or syntactic violation. To further
                                                                   investigate the special visual features of texts, the next step
                                                                   in this line of research could be an experiment that places
                                                                   non-text objects in unexpected locations. In addition, it is
                                                                   important to investigate the contribution of informativeness
Figure 7. Fixation probability of unconstrained texts in front     to the ability of texts to attract attention. Such experiments
of homogeneous (H) and inhomogeneous (INH) background,             could present, for instance, non-English texts, such as
and the corresponding non-text objects and control regions.        Chinese characters, to native English speakers as subjects.
                                                                                        Acknowledgments
                                                                   Parts of the data were presented at the European Conference
                                                                   on Visual Perception (ECVP 2010). Thanks to Melissa Võ
                                                                   for helpful comments on an earlier version of the article.
                                                                   Preparation of the article was supported by Grant
                                                                   R15EY017988 from the National Eye Institute to Marc
                                                                   Pomplun.
                                                                                             References
                                                                   Itti, L, Koch, C., & Niebur, E. (1998). A Model of Saliency-
                                                                      Based Visual Attention for Rapid Scene Analysis. IEEE
                                                                      Trans Pattern Analysis and Machine Intelligence 20 (11):
                                                                      1254-1259.
                                                                   Itti, L., & Koch, C. (2001). Computational Modeling of
                                                                      Visual Attention. Nature Reviews Neuroscience.
                                                                      2(3):194-203.
Figure 8. Minimum fixation distance of unconstrained texts         Judd, T., Ehinger, K., Durand, F., & Torralba, A. (2009).
in front of homogeneous (H) and inhomogeneous (INH)                   Learning to predict where humans look, IEEE
background, non-text objects, and control regions.                    International Conference on Computer Vision (ICCV).
                                                                   Russell, B. C., Torralba, A., Murphy, K. P., & Freeman, W.
                   General Discussion                                 T. (2008). LabelMe: a database and web-based tool for
                                                                      image annotation, International journal of computer
In Experiment 1, we found that text objects were more                 vision, 77, 1-3, 157-173.
attractive than non-text objects and control regions of            Tatler, B. W. (2007). The central fixation bias in scene
similar size, eccentricity, saliency, and luminance contrast.         viewing: Selecting an optimal viewing position
Since we controlled for the typical saliency computed by              independently of motor biases and image feature
color, intensity, orientation, and contrast, the results might        distributions. Journal of Vision, 7(14):4, 1-17.
be caused by high-level features (expected locations),             Torralba, A., Oliva, A., Catelhano, M., & Henderson, J.M.
special visual features of text, or both. Experiment 2 further        (2006). Contextual guidance of eye movements and
investigated the attraction of attention by high-level features,      attention in real-world scenes: The role of global features
and the results suggested that eye fixations were influenced          in object search. Psychological Review, 113, 766-786.
by expected locations that might possibly be more                  Võ, M. L.-H., & Henderson, J. M. (2009). Does gravity
informative. This finding has important implications for our          matter? Effects of semantic and syntactic inconsistencies
understanding of attention in real-world scenes. First, it            on the allocation of attention during scene perception.
supports the concept of “contextual guidance” found by                Journal of Vision, 9(3):24, 1-15.
                                                               2738

