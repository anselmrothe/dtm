UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Effects of speaker gaze on spoken language comprehension: task matters
Permalink
https://escholarship.org/uc/item/80q806kh
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Kreysa, Helene
Knoeferle, Pia
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

        Effects of speaker gaze on spoken language comprehension: Task matters
                                          Helene Kreysa (hkreysa@cit-ec.uni-bielefeld.de)
                                          Pia Knoeferle (knoeferl@cit-ec.uni-bielefeld.de)
                                            Cognitive Interaction Technology Excellence Cluster
                                               Bielefeld University, 33615 Bielefeld, Germany
                              Abstract                                     to listeners, because speakers discussing entities in the visual
                                                                           world robustly gaze at the objects they are about to mention
   Listeners can use speakers’ gaze to anticipate upcoming refer-
   ents. We examined whether this listener benefit is affected by          (Griffin & Bock, 2000). Several studies have examined gaze
   different comprehension subtasks. A video-taped speaker re-             effects by overlaying a moving cursor on a display, thus repre-
   ferred to depicted characters, using either a subject-verb-object       senting the speaker’s gaze to objects without actually depict-
   or a non-canonical object-verb-subject German sentence. She
   shifted gaze once from the pre-verbal to the post-verbal refer-         ing the speaker (e.g., Brennan, Chen, Dickinson, Neider, &
   ent, a behavior that could allow listeners to anticipate which          Zelinsky, 2008; Carletta et al., 2010; Kreysa, 2009). Listen-
   character would be mentioned next. We recorded participants’            ers can exploit such symbolic gaze cursors in all sorts of tasks.
   eye movements to the characters during comprehension, as
   well as post-sentence verification times on whether a sub-              In collaborative visual search, participants detected the target
   sequent schematic depiction correctly highlighted the patient           faster when a gaze cursor depicted their interlocutor’s focus
   (Experiment 1) or the thematic role relations of the sentence           of attention than when they were provided with no partner in-
   (Experiment 2). Sentence structure affected response times
   only when verifying thematic roles. The eye movement data               formation, only voice, or even both cursor and voice (Brennan
   also showed reliable differences between tasks, regarding ef-           et al., 2008). Similarly, a dynamic gaze cursor proved helpful
   fects of sentence structure and their modulation by speaker             in detecting bugs in computer programs (Stein & Brennan,
   gaze. We argue that processing accounts of situated compre-
   hension must consider task effects on the allocation of visual          2004).
   attention.                                                                 Other studies have included a real or video-taped speaker
   Keywords: spoken sentence comprehension; task effects;                  (e.g., Hanna & Brennan, 2007; Nappa & Arnold, 2009;
   speaker gaze; syntactic structuring; eye tracking                       Nappa, Wessel, McEldoon, Gleitman, & Trueswell, 2009).
                                                                           Using a collaborative task, Hanna and Brennan (2007)
           Attention modulation across tasks                               showed that seeing a speaker attending to the object she was
When interacting with the immediate visual environment, we                 about to mention led listeners to shift attention to the cor-
can pay attention to all sorts of things: people around us, what           responding object in their own workspace even before the
somebody says, signs that tell us what to do or where impor-               speaker mentioned it. Similarly, in a sentence verification
tant information is located. Intuitively, these cues affect our            task, listeners were able to use the gaze of a robot speaker
visual attention in diverse tasks: while we drive, as we pre-              to anticipate a linguistically ambiguous referent (Staudte &
pare dinner, while we map-read our way to the city sights. In-             Crocker, 2009). In sum, speaker gaze – whether seen di-
deed, low-level visual cues have been shown to guide a per-                rectly or represented by a gaze cursor – allows listeners to
ceiver’s visual attention and improve performance across a                 anticipate what a speaker will refer to, and can rapidly benefit
range of cognitive tasks. In problem solving, pulsing lines                performance in comprehension, visual search, collaboration,
can lead participants to focus on important areas in a dia-                problem solving, and spatial referencing.
gram, facilitating the solution of insight problems (Grant &
Spivey, 2003). In language production, arrows pointing to                  Task effects: Visual attention & language processing
referents affected the produced sentence structure (Tomlin,                However, the impressive range of tasks across which visual
1995), as did brief screen flashes (Gleitman, January, Nappa,              context cues can influence cognitive processes does not mean
& Trueswell, 2007). In a change detection task, participants               that the allocation of visual attention is task-independent.
were faster to detect changes to objects when these were lo-               From the very early days of research on eye movements it
cated in the direction of someone else’s gaze than when they               has been known that images are scanned with different sac-
weren’t (Langton, O’Donnell, Riby, & Ballantyne, 2006). In                 cade sequences as a function of task: Participants were more
fact, eye gaze stimuli are known to exert a strong pressure to             likely to fixate on the faces of people in a painting when
shift attention in the direction of the gaze (e.g., Ricciardelli,          asked to determine their ages than when estimating their ma-
Bricolo, Aglioti, & Chelazzi, 2002).                                       terial wealth (Yarbus, 1967; Tatler, Wade, Kwan, Findlay, &
   In addition to these low-level and largely static cues, dy-             Velichkovsky, 2010). More recently, task (visual search vs.
namic changes in visual context also affect the perceiver’s                memorization) has been shown to affect which image areas
attention and behavior. One such cue is the shifting focus                 are inspected (Castelhano, Mack, & Henderson, 2009).
of another person’s gaze. Speaker gaze1 can be informative                    Task effects on gaze behavior have also been reported
    1 We use ‘speaker gaze’ in a wide sense, as a cue to the direction     in language processing, particularly in language production.
of attention. In many cases, this explicitly includes head movements.      Thus, a speaker’s fixation pattern depends among other things
                                                                       1557

on whether s/he is inspecting an object or preparing to name         case marking, world knowledge, and factors such as intona-
it (Meyer, Sleiderink, & Levelt, 1998), producing an active          tion or visual context can modulate this time course (Kamide,
versus a passive description (Griffin & Bock, 2000), telling         Scheepers, & Altmann, 2003; Knoeferle et al., 2005; We-
the time in an analogue versus digital format (Bock, Irwin,          ber, Grice, & Crocker, 2006). In the present study, when the
Davidson, & Levelt, 2003), or speaking about visible ver-            sentence continues with beglückwünscht (“congratulate”) and
sus remembered objects (Meyer, van der Meulen, & Brooks,             the NP2 determiner den/ der, neither linguistic information
2004). Moreover, eye movements are affected by the process-          nor world knowledge reveals which of the two other depicted
ing of linguistic information in language-based tasks (e.g.,         characters (the millionaire or the saxophone player) will be
reading and object recognition), but not in non-linguistic           referred to post-verbally. Thus, while the sentence is struc-
tasks (e.g., visual search) (Rayner & Raney, 1996; Zelinsky          turally unambiguous, there is a temporary referential ambi-
& Murphy, 2000). Clearly, the instructions given to partici-         guity at the verb.
pants can affect the interpretation of eye movement data (see
Knoeferle, Crocker, Scheepers, & Pickering, 2005, p.109).
   Within the domain of spoken language comprehension and
“visual world” studies – in which participants’ fixations of
objects are monitored as they listen to a related sentence – two
typical tasks are acting-out (e.g., Spivey, Tanenhaus, Eber-
hard, & Sedivy, 2002) and passive listening (e.g., Altmann
& Kamide, 1999). Descriptive comparisons of fixation pat-
terns between different studies suggest no obvious task-based
discrepancies in the time course with which comprehenders
inspect and anticipate objects. But direct and controlled ma-
nipulations of task across otherwise similar visual world stud-
ies are, to the best of our knowledge, lacking. As a result, the
potential effects of more subtle variations of comprehension-
related tasks are not explicitly considered in existing accounts
of situated comprehension (Altmann & Kamide, 2007; Knoe-
ferle & Crocker, 2006) and associated computational models
(Mayberry, Crocker, & Knoeferle, 2009). The linking hy-              Figure 1: Screen displays: (a) Example of still from the videos
potheses between visual attention and language comprehen-            used in Experiments 1 and 2; (b) Template for patient verification
                                                                     (Exp. 1): Does the circled character correspond to the patient of the
sion that underlie these accounts also don’t take potential top-     sentence?; (c) Template for verifying role relations (Exp. 2): Does
down task effects into account.                                      the arrow reflect the thematic roles of the sentence?
Task and speaker gaze effects: The present studies
Two eye-tracking experiments connected these separate                Table 1: Overview of the experimental conditions (Congruency is
                                                                     excluded here). The English translation of the SVO sentence is “the
strands of research: the use of dynamic speaker gaze in on-          waiter congratulates the millionaire”, while the OVS sentence im-
line sentence processing, and variations in the comprehension        plies that the waiter is being congratulated by the millionaire.
task (for further details, see Kreysa & Knoeferle, 2011). In           Condition            Picture           Sentence
both experiments, people watched videos of a speaker pro-              OVS & NoGaze         a                 Den                 Kellner
ducing German subject-verb-object (SVO) and object-verb-                                                      beglückwünscht        der
subject (OVS) sentences about characters on a screen. Fol-                                                    Millionär.
lowing each video, participants were instructed to verify spe-         OVS & Gaze           b                 Den                 Kellner
                                                                                                              beglückwünscht        der
cific aspects of the sentence: In Experiment 1, the task was                                                  Millionär.
to identify the patient, while Experiment 2 required partici-          SVO & NoGaze         c                 Der                 Kellner
pants to verify thematic role relations, a task which arguably                                                beglückwünscht        den
subsumes the patient identification task.                                                                     Millionär.
   Consider an example: A speaker looks at a computer dis-             SVO & Gaze           d                 Der                 Kellner
play that shows a waiter, a millionaire, and a saxophone                                                      beglückwünscht        den
                                                                                                              Millionär.
player (Fig. 1a). As soon as she begins her sentence with Der/
Den Kellner (“the waiter”), case marking identifies the first
noun phrase (NP1) as either the subject (Der, Table 1, c & d)           However, if the speaker now shifts gaze from the refer-
or the object (Den, Table 1, a & b). In German, both subject-        ent of the NP1 to the post-verbal referent, the direction of
and object-initial main clauses are grammatical, but the for-        her gaze could allow the listener to anticipate the latter even
mer are canonical while the latter are not. Understanding an         before hearing the NP2. If speaker gaze in a setup such as
object- (vs. subject-)initial sentence has been shown to slow        Figure 1a is used to anticipate post-verbal referents, listeners
comprehension (as reflected by eye movements), although              should begin to fixate this “target” referent shortly after the
                                                                 1558

speaker begins to gaze at it, and more often than when the            always looked at the character she was mentioning. Thus,
display doesn’t show the speaker. Such speaker-gaze based             shortly after uttering the verb, her gaze shifted from the NP1
anticipation could either be independent of, or modulated by,         referent to the NP2 referent. A second pretest ensured that
syntactic structuring and thematic interpretation. If it is inde-     this gaze shift was easy to see (98% correct; detection latency
pendent of sentence structuring, then post-verbal referent an-        M = 498 ms, SD = 386).
ticipation should occur to the same extent and with the same             The design included three within-subject factors (Table 1):
time course for both SVO and OVS sentences. Alternatively,            Gaze (speaker vs. not), Structure (SVO vs. OVS), and Con-
if speaker gaze effects on referent anticipation interact with        gruency between the sentence content and a post-sentence re-
syntactic structuring, then we should see differences in the          sponse template (see Procedure). The display versions and
time course and/ or extent to which a listener inspects the           sentence manipulations were allocated such that each sen-
target referent for OVS relative to SVO sentences. If such ef-        tence role (agent or patient) was equally distributed across
fects are long-lasting, they could also affect the post-sentence      screen positions over the course of the experiment. In addi-
verification response latencies.                                      tion, the NP2 referent appeared on the same side of the screen
   Crucially, all or none of these speaker gaze effects on a          equally often, so that the speaker shifted her gaze to the right
listener’s visual attention could vary as a function of the two       just as frequently as to the left. The 24 experimental items
different comprehension tasks: patient verification (Exp. 1)          were supplemented by 48 fillers with different sentence struc-
and role relations verification (Exp. 2). Observing similar           tures and images. The speaker was visible on 50% of trials.
speaker gaze effects across these two tasks would suggest that
the use of speaker gaze is independent of subtle task differ-
ences. Alternatively, people’s eye gaze and verification times
may be affected by the different aspects of comprehension
that each verification task focuses on. If so, we should see
differences in speaker gaze effects and sentence structure ef-
fects as a function of task.
                   Experiments 1 and 2
Methods
Participants Thirty-two Bielefeld University students took
                                                                      Figure 2: Eyetracking setup: Participants watched the video on the
part in Experiment 1 (15 male; 3 replacements), and a further         screen, then pressed a button in response to the template.
32 participated in Experiment 2 (5 male). All were native
German speakers with normal or corrected-to-normal vision.
                                                                      Procedure We monitored eye movements using an Eye-
All gave informed consent.
                                                                      link 1000 desktop head-stabilized tracker (SR Research), and
Materials and Design We created 72 characters in the                  recorded post-sentence verification latencies (see Fig. 2 for
virtual world SecondLife, and 48 critical sentences (NP1-             the experimental setup). On Gaze trials, participants saw
VERB-NP2-PP). We grouped the characters into 24 triplets,             the speaker talking about the SecondLife characters on the
and took a snapshot of them. Each snapshot was paired with            screen. On NoGaze trials, the same video was shown, but the
two German sentences (SVO and OVS) to create 24 items.                speaker was occluded behind a grey bar. Thus, only the static
Each sentence described a transitive action between the cen-          screen with the three characters was visible (see Table 1, a
tral character (e.g., the waiter) and one of the two outer char-      & c). Immediately following the end of each video, partici-
acters (e.g., the millionaire; Table 1). None of the nouns in         pants saw a template like Figures 1b or 1c. Their task was to
the sentence were semantically associated, nor was there a se-        press a button depending on whether the template accurately
mantic connection with the verb. Actions were not depicted.           depicted the sentence content (‘yes’ vs. ‘no’). For Experi-
A naming pretest ensured all characters were recognizable.            ment 1, the template represented the character who had been
   We recorded two videos for each item, showing the speaker          mentioned in the patient role in the sentence (see Fig. 1b).
producing the sentences about the characters. She was seated          For a video such as Figure 1a and the sentence Den Kellner
to the right of a 20” Apple iMac 8.1 screen, which displayed          beglückwünscht der Millionär (“The waiter is congratulated
the SecondLife triplet. A Canon PowerShot G10 camera was              by the millionaire”, OVS), the correct response to the tem-
positioned in such a way that both screen and speaker were            plate in Figure 1b is ‘yes’: The position of the waiter (i.e., the
visible in the recording. Videos began with the speaker look-         middle character) is circled. In Experiment 2, participants
ing at the camera and smiling briefly. She then inspected all         verified whether the arrow on the template correctly depicted
three characters in a fixed order, so that participants could         who-does-what-to-whom in the sentence (Fig. 1c). Thus, for
establish what a gaze to each of them looked like. Finally,           the same sentence, Figure 1a followed by Figure 1c would
her gaze returned to the central character, who was always            also require a ‘yes’ response, because the arrow points from
the referent of the NP1. She then began producing the sen-            the position of the millionaire on the right (the agent of the
tence, which had been read out to her previously. The speaker         sentence) to the waiter (the patient) in the middle.
                                                                  1559

Eye movement analysis For the eye movement analyses,                 tions fixate the target character to the same extent.
we selected two critical time windows during the video. The
first (“SHIFT”) comprised all fixations that began be- tween
the speaker’s gaze shift and the onset of the NP2. The second
time window (“NP2”) comprised all fixations starting during
the NP2. The x-y coordinates of participants’ fixations were
assigned to four areas of interest: NP1 referent, target (= NP2
referent), competitor (= the non-mentioned character), and
the area around the speaker. The main dependent variable was
the number of fixations to the target, i.e., the referent of the
NP2. Log-linear models were used for the inferential analy-
sis, combining characteristics of a standard cross-tabulation
chi-square test with those of ANOVA. They included the fac-
tors Gaze (Gaze vs. NoGaze), Structure (SVO vs. OVS),
                                                                     Figure 4: Time course of participants’ fixations to the target char-
and either participants (N = 32) or items (N = 24). Finally, a       acter (the NP2 referent) in ms from speaker gaze shift, depending on
model including Experiment as a factor allowed us to assess          structure and gaze (Exp. 1). The mean on- and offset of the NP2 are
the generalizability of effects across tasks.                        marked as vertical lines.
Results Experiment 1 (Verifying the patient)                            Analyses for the SHIFT time window confirmed that par-
                                                                     ticipants were more likely to inspect the target character when
Response time results Response times were measured                   they could see the speaker (35%) than when they could not
from the onset of the verification template until partic-            (26%; ps < .05, Fig. 3). An effect of Sentence Structure fur-
ipants’ button press (96% accuracy). A 2*2*2 (Struc-                 ther revealed that people fixated the target character more of-
ture*Gaze*Congruency) repeated-measures Anova on log-                ten in the SVO (36%) than OVS conditions (25%; ps < .05).
transformed response times revealed faster responses to              The main effect of Speaker Gaze was also present in the NP2
matching than mismatching templates (ps < .001). Neither             time window (ps < .001). When the speaker was present,
Structure nor Gaze had any effect.                                   participants fixated the target character more (55%) than in
Eye movement results Figure 3 shows proportions of fix-              her absence (43%). The Structure effect from the previous
ations in all interest areas, for the Gaze vs. NoGaze condi-         time window carried through too: Participants looked at the
tions during the SHIFT time window. Generally, participants          target character more while hearing an SVO sentence (54%)
still tended to fixate on the NP1 referent, who had just been        than during OVS (45%; ps < .001). There was no reliable
mentioned. However, in the Gaze condition, fixations to the          interaction of Gaze and Structure in either time window.
as-yet-unmentioned NP2 referent increased shortly after the
                                                                     Results Experiment 2 (Verifying role relations)
speaker shifted her gaze. Note that the speaker herself was
rarely fixated at all.                                               Response time results Participants’ responses to the who-
                                                                     does-what-to-whom template were 96% accurate. Just as in
                                                                     Experiment 1, matching templates elicited faster responses
                                                                     than mismatches (ps < .001), and Speaker Gaze had no reli-
                                                                     able effect on response times. Unlike for the patient verifica-
                                                                     tion task, however, role relations verification led to a signif-
                                                                     icant main effect of Sentence Structure (ps < .05), such that
                                                                     SVO sentences elicited faster responses than OVS (71 ms).
                                                                     Eye movement results Figure 5 shows proportions of fixa-
                                                                     tions in all interest areas for the Gaze vs. NoGaze conditions
                                                                     during the SHIFT time window. Figure 6 presents the time
Figure 3: Distribution of fixations beginning in the SHIFT time      course of participants’ fixations to the target character. As in
window across areas of interest, by speaker visibility (Exp. 1).     Experiment 1, these began to increase almost as soon as the
                                                                     speaker shifted her gaze, well before this character was men-
   Figure 4 presents the time course of participants’ fixations      tioned (and earlier than when no speaker gaze was available).
to the target character only, from the onset of the speaker’s        At the end of the sentence, the gaze pattern also differed from
gaze shift, as a function of structure and gaze. Like Figure 3,      Experiment 1 (Fig. 4): There, participants in the SVO condi-
it shows an earlier rise of looks to the target character in the     tion predominantly fixated the sentence-final patient, whereas
Gaze than in the NoGaze conditions, for both sentence struc-         this was not the case for Experiment 2 (Fig. 4).
tures. This begins about 500 ms after speaker gaze shift, and           During the SHIFT time window, log-linear analyses con-
well before the onset of the NP2. Only much later, roughly           firmed an effect of Gaze on fixations to the target charac-
at the offset of the NP2, do participants in the NoGaze condi-       ter: Just like in the patient verification task, participants were
                                                                 1560

                                                                        ification task varied as a function of subtle task differences.
                                                                        To this end, we recorded participants’ gaze as they listened to
                                                                        NP1-VERB-NP2 sentences mentioning two out of three char-
                                                                        acters on a computer screen. On half the trials, they saw a
                                                                        speaker shifting gaze at the verb from the NP1 referent to the
                                                                        NP2 referent. Subsequently, participants verified whether a
                                                                        circled character corresponded to the patient of the sentence
                                                                        (Exp. 1), or whether an arrow between two characters cor-
                                                                        rectly depicted their thematic role relations (Exp. 2; note that
                                                                        this task requires having identified the patient correctly).
Figure 5: Distribution of fixations in the SHIFT time window               As expected, response latencies in both experiments were
across interest areas, depending on speaker visibility (Exp. 2).        shorter when the template matched (vs. mismatched) the
                                                                        video in the to-be-verified aspects. However, sentence struc-
                                                                        ture affected response times only when people judged the-
more likely to fixate the target when they could (vs. couldn’t)         matic role relations, but not when they verified the identity
see the speaker (39% vs. 27%; ps < .001). Sentence Struc-               of the sentential patient. This suggests that the thematic role
ture also had a significant effect in the SHIFT window, al-             task may have required more in-depth syntactic processing.
though unlike in Experiment 1, participants fixated the target          The moment-by-moment allocation of visual attention sup-
character more often when hearing an OVS relative to an SVO             ports this conclusion: While sentence structure reliably af-
sentence (35% vs. 30%; ps < .05). Finally, also unlike Exper-           fected anticipatory eye movements to the post-verbal referent
iment 1, the interaction of Gaze and Structure was significant          in both experiments, its effect differed between the two asso-
(ps < .05): The facilitative effect of Gaze was considerably            ciated tasks. Patient verification led to more target fixations
larger for subject- than object-initial sentences, as can be seen       during SVO than OVS sentences, while this pattern flipped
in Figure 6. In the NP2 time window, the only reliable effect           for thematic role verification. This may be due to task differ-
was one of Gaze (ps < .001), with participants fixating the             ences in the informativity of the gaze shift: For patient veri-
target character more often with (63%) than without (47%)               fication, only gaze shifts in SVO sentences are task-relevant
the speaker.                                                            (the patient is already uniquely identified in OVS sentences).
                                                                        In contrast, for thematic role verification, the gaze shift is in-
                                                                        formative in both sentence structures, since this task relies on
                                                                        identifying two characters. In addition, it seems possible that
                                                                        during normal sentence processing (i.e., in Exp. 2), there may
                                                                        be a tendency to fixate the agent while hearing the verb. In
                                                                        contrast, if the task is explicitly to identify the patient (Exp.
                                                                        1), an efficient strategy would be to locate this character as
                                                                        early as possible and pay less attention to the remainder of
                                                                        the sentence.
                                                                           Importantly, while the availability of speaker gaze led to
                                                                        substantially earlier anticipation of the NP2 character across
                                                                        the board, this benefit was also modulated by sentence struc-
Figure 6: Time course of participants’ fixations to the target char-    ture – the greatest facilitation occurred for canonical SVO
acter, depending on structure and gaze (Exp. 2). The mean on- and       sentences in the role verification task. Task differences be-
offset of the NP2 are marked as vertical lines.
                                                                        came even more obvious later in SVO sentences, when it was
                                                                        advantageous for listeners who had to verify the patient to
   In cross-experiment analyses, the factor Experiment had              maintain fixation on the NP2 referent. It seems then that task
no reliable effect on response latencies. Crucially however,            can critically affect syntactically-driven eye movements in
it affected fixation patterns: During the SHIFT time window,            online spoken language comprehension. In sum, to accurately
participants were more likely to fixate the N2 referent in Ex-          account for effects of visual context (e.g., speaker gaze) and
periment 2 than in Experiment 1 (ps < .05). Structure inter-            syntactic structure on the deployment of visual attention, pro-
acted with Experiment, with increased fixations to the NP2              cessing accounts of situated language comprehension must
referent when hearing an SVO sentence in Experiment 1, but              include a model of task constraints.
when hearing an OVS sentence in Experiment 2 (relative to
the respective other structure, ps < .001).                                                  Acknowledgments
                     General Discussion                                 This research was funded by the Cognitive Interaction Tech-
We assessed whether speaker gaze effects on both response               nology Excellence Center (German research foundation,
latencies and visual attention during comprehension for a ver-          DFG). We thank Eva Mende, Linda Krull, Anne Kaestner,
                                                                    1561

Lydia Diegmann, and Eva Nunnemann for their assistance                (2006). Gaze cues influence the allocation of attention in
with preparing the stimulus materials and/ or collecting data.        natural scene viewing. Quarterly Journal of Experimental
                                                                      Psychology, 59, 2056-2064.
                         References                                 Mayberry, M., Crocker, M. W., & Knoeferle, P. (2009).
                                                                      Learning to attend: A connectionist model of situated lan-
Altmann, G. T. M., & Kamide, Y. (1999). Incremental in-
                                                                      guage comprehension. Cognitive Science, 33, 449–496.
  terpretation at verbs: restricting the domain of subsequent
                                                                    Meyer, A. S., Sleiderink, A. M., & Levelt, W. J. M. (1998).
  reference. Cognition, 73, 247–264.
                                                                      Viewing and naming objects: Eye-movements during noun
Altmann, G. T. M., & Kamide, Y. (2007). The real-time me-
                                                                      phrase production. Cognition, 66, B25–B33.
  diation of visual attention by language and world knowl-
                                                                    Meyer, A. S., van der Meulen, F., & Brooks, A. (2004). Eye
  edge: Linking anticipatory (and other) eye movements to
                                                                      movements during speech planning: Talking about present
  linguistic processing. JML, 57, 502-518.
                                                                      and remembered objects. Visual Cognition, 11, 553-576.
Bock, K., Irwin, D., Davidson, D., & Levelt, W. (2003).
                                                                    Nappa, R., & Arnold, J. (2009). Paying attention to intention:
  Minding the clock. JML, 48, 653–685.
                                                                      Effects of intention (but not egocentric attention) on pro-
Brennan, S., Chen, X., Dickinson, C., Neider, M., & Zelinsky,
                                                                      noun resolution. In Proceedings of the CUNY Conference.
  G. (2008). Coordinating cognition: The costs and benefits
                                                                    Nappa, R., Wessel, A., McEldoon, K., Gleitman, L., &
  of shared gaze during collaborative search. Cognition, 106,
                                                                      Trueswell, J. (2009). Use of speaker’s gaze and syntax
  1465-1477.
                                                                      in verb learning. Language Learning and Development, 5,
Carletta, J., Hill, R., Nicol, C., Taylor, T., de Ruiter, J., &
                                                                      1–32.
  Bard, E. (2010). Eyetracking for two-person tasks with ma-
                                                                    Rayner, K., & Raney, G. E. (1996). Eye-movement control
  nipulation of a virtual world. Behavior Research Methods,
                                                                      in reading and visual search: Effects of word frequency.
  42, 254-265.
                                                                      Psychonomic Bulletin & Review, 3, 245–248.
Castelhano, M., Mack, M., & Henderson, J. (2009). Viewing           Ricciardelli, P., Bricolo, E., Aglioti, S., & Chelazzi, L.
  task influences eye movement control during active scene            (2002). My eyes want to look where your eyes are look-
  perception. Journal of Vision, 9, 115.                              ing: Exploring the tendency to imitate another individual’s
Gleitman, L., January, D., Nappa, R., & Trueswell, J. (2007).         gaze. NeuroReport, 13, 2259-2264.
  On the ”give” and ”take” between event apprehension and           Spivey, M. J., Tanenhaus, M. K., Eberhard, K. M., & Sedivy,
  utterance formulation. JML, 57, 544-569.                            J. C. (2002). Eye-movements and spoken language com-
Grant, E., & Spivey, M. J. (2003). Eye movements                      prehension: Effects of visual context on syntactic ambigu-
  and problem solving: Guiding attention guides thought.              ity resolution. Cognitive Psychology, 45, 447–481.
  Psychological Science, 14, 462-466.                               Staudte, M., & Crocker, M. (2009). The effect of robot gaze
Griffin, Z., & Bock, K. (2000). What the eyes say about               on processing robot utterances. In N. Taatgen & H. van
  speaking. Psychological Science, 11, 274–279.                       Rijn (Eds.), Proceedings of the 31st Annual Meeting of the
Hanna, J., & Brennan, S. (2007). Speakers’ eye gaze dis-              Cognitive Science Society (pp. 431–436). Cognitive Sci-
  ambiguates referring expressions early during face-to-face          ence Society, Inc.
  conversation. JML, 57, 596–615.                                   Stein, R., & Brennan, S. (2004). Another person’s eye gaze as
Kamide, Y., Scheepers, C., & Altmann, G. (2003). Inte-                a cue in solving programming problems. In Proceedings of
  gration of syntactic and semantic information in predictive         the 6th International Conference on Multimodal Interface
  processing: Cross-linguistic evidence from German and               (p. 9-15). Penn State University.
  English. Journal of Psycholinguistic Research, 32, 37–55.         Tatler, B., Wade, N., Kwan, H., Findlay, J., & Velichkovsky,
Knoeferle, P., & Crocker, M. W. (2006). The coordinated               B.     (2010).     Yarbus, eye movements, and vision.
  interplay of scene, utterance, and world knowledge: Evi-            i-Perception, 1, 7-27.
  dence from eye tracking. Cognitive Science, 30, 481–529.          Tomlin, R. S. (1995). Focal attention, voice, and word or-
Knoeferle, P., Crocker, M. W., Scheepers, C., & Pickering,            der. In P. A. Dowing & M. Noonan (Eds.), Word Order in
  M. J. (2005). The influence of the immediate visual context         Discourse (p. 517-552). Amsterdam: John Benjamins.
  on incremental thematic role-assignment: Evidence from            Weber, A., Grice, M., & Crocker, M. W. (2006). The role of
  eye-movements in depicted events. Cognition, 95, 95–127.            prosody in the interpretation of structural ambiguities: A
Kreysa, H.       (2009).    Coordinating speech-related eye           study of anticipatory eye movements. Cognition, 99, B63-
  movements between comprehension and production. Un-                 B72.
  published doctoral dissertation, Edinburgh University, UK.        Yarbus, A. L. (1967). Eye movements and vision. New York:
Kreysa, H., & Knoeferle, P. (2011). Peripheral speaker                Plenum Press.
  gaze facilitates spoken language comprehension: Syntac-           Zelinsky, G. J., & Murphy, G. L. (2000). Synchronizing
  tic structuring and thematic role assignment in German.             visual and language processing: An effect of object name
  In Proceedings of the European Conference on Cognitive              length on eye movements. Psychological Science, 11, 125–
  Science in Sofia.                                                   131.
Langton, S., O’Donnell, C., Riby, D., & Ballantyne, C.
                                                                1562

