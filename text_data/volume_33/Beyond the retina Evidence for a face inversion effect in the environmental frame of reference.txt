UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Beyond the retina: Evidence for a face inversion effect in the environmental frame of
reference
Permalink
https://escholarship.org/uc/item/170723j0
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Davidenko, Nicolas
Flusberg, Stephen
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                      University of California

                                                       Beyond the retina:
        Evidence for a face inversion effect in the environmental frame of reference
                                          Nicolas Davidenko (ndaviden@stanford.edu)
                                           Stephen J. Flusberg (sflus@stanford.edu)
                                            Stanford University, Department of Psychology
                                Jordan Hall, 450 Serra Mall, Building 420, Stanford, CA 94305 USA
                            Abstract                                  frames). In a typical laboratory study, therefore, several
                                                                      reference frames are conflated. This begs the question: in
   Across a wide range of face perception tasks, observers show       relation to which reference frame(s) does the face inversion
   drastically worse performance when faces are oriented
   upside-down versus upright. However, the meaning of                effect occur?
   orientation must be established in relation to a particular           There is reason to believe that both retinal and
   frame of reference. In relation to which reference frame(s)        environmental reference frames matter in visual information
   does the face inversion effect occur? Here we describe a           processing. Irvin Rock (1973) conducted a series of
   simple, novel method for investigating potentially                 pioneering experiments on object form perception,
   independent effects of retinal and environmental reference         demonstrating that both retinal and environmental reference
   frames on face processing. Participants performed one of two
                                                                      frames impact participants’ memory for and interpretation
   face-processing tasks (emotional expression classification and
   recognition memory) as they lay horizontally, which served to      of novel objects under certain circumstances.              More
   disassociate the retinal and environmental reference frames.       recently, researchers have shown that our ability to perceive
   In both experiments we found a large effect of retinal             the stability of human body postures as well as the direction
   orientation on performance and a small but reliable effect of      of bodily motion depends on both retinal and environmental
   environmental orientation. In a follow-up control study, we        cues (Chang, Harris & Troje, 2010; Lopez et al., 2009).
   consider an alternative explanation based on our experimental      Finally, research on spatial cognition has found that people
   setup. We argue that environmental orientation influences
   face processing, which is revealed when retinal orientation is
                                                                      are sensitive to a variety of spatial reference frames and
   kept constant.                                                     flexibly adopt multiple different frames for representing the
                                                                      environment as they perform different tasks and
   Keywords: face perception, reference frames, face inversion        communicate with others (Tversky, Lee, & Mainwaring,
   effect, embodiment
                                                                      1999).
                                                                         However, to date there is no evidence that multiple frames
                          Background                                  of reference play a role in face processing. In fact, Rock
   Over 50 years of research has demonstrated that                    (1973) himself suggested that because faces are familiar
orientation dramatically affects the visual processing of             objects that have an intrinsic spatial structure (i.e. a top and
faces; across a wide range of perception and memory tasks,            bottom), their environmental orientation should not affect
observers show markedly worse performance when faces                  how we perceive them. Recent research seems to support
are presented upside-down compared to upright (Yin, 1969).            this view that face orientation effects are restricted to the
This face inversion effect is perhaps most famously                   retinal frame of reference (Troje, 2003; Chang et al., 2010).
illustrated by the classic Thatcher Illusion (Thompson,               In one experiment (Troje, 2003), participants had to indicate
1980); a picture of the former prime minister that appears            whether or not a face image displayed on a computer screen
normal when presented upside-down is revealed to be a                 was the same face they had seen moments before. The
disturbing grotesque of inverted features when rotated                images could be oriented upright on the screen or rotated by
upright. The dramatic effect of inversion on face perception          90º. The participant’s head was orientated upright in the
sets faces apart from other objects and has led many                  room for half of the trials and rotated by 90º in the other half
researchers to consider faces a special visual category               of the trials. The results indicated that performance was
(Rhodes et al., 1993; Farah et al., 1998).                            fastest and most accurate when the orientation of the face
   Notice, though, that the meaning of orientation (i.e. what         image matched the orientation of the participant’s retinal
counts as upright or upside-down) must be established in              frame, regardless of the environmental orientation of the
relation to a particular frame of reference. The vast majority        image and the participant.
of experiments examining orientation effects in visual                   Troje’s (2003) experiment (and related work; see Rock,
perception have participants seated in front of a computer            1973) was designed to pit the retinal frame against the
screen. A face image displayed on the monitor might be                environmental frame to see which one mattered more for
upright with respect to the participant’s retina (retinal             face processing. However, it is possible that both reference
frame), but it would also be upright with respect to the              frames affect face processing, but by pitting the two against
computer screen itself, the room the computer is situated in,         one another the relatively large retinal frame effect masked
and even the directional pull of gravity (environmental
                                                                  435

the ability to detect any effect of the environmental frame.              Procedure. The classification task was programmed in
Here we describe a novel, simple method for investigating                 Matlab using Psychophysics Toolbox 3. Data was collected
potentially independent effects of retinal and environmental              on a 15” Macbook Pro. The background of the display was
reference frames in face perception. Participants performed               black, and on each trial a single face image was presented at
one of two face-processing tasks as they lay horizontally,                the center of the display, preceded by a 100ms inter-trial
thereby disassociating the retinal and environmental                      interval (ITI).     Participants were asked to judge the
orientation of the stimuli (see figure 1). In this position,              emotional expression of each presented face as “happy,”
faces presented upright and upside-down in the retinal frame              “sad,” or “angry” as quickly and as accurately as possible by
are both rotated by 90º in the environmental frame, while                 pressing a number on a keypad corresponding to each
faces presented upright and upside-down in the                            expression.      Images remained on the screen until
environmental frame are both rotated by 90º in the retinal                participants provided a response. The keypad was held in
frame. This allows us to measure face inversion effects in                the left hand while three digits of the right hand were used
each reference frame while keeping the orientation in the                 to make the response. There was no fixation cross and
alternative frame constant.                                               participants were free to move their eyes to inspect the
                                                                          stimuli before responding. Participants first completed
                                                                          several practice trials while seated upright at a desk in order
                                                                          to familiarize them with the task.
                                                                             They were then randomly assigned to lie down on their
                                                                          right or left side on a padded bench to begin the
                                                                          experimental task. A pole-mounted head and chin rest with
                                                                          head-strap was constructed in-house to maintain
                                                                          participants’ heads fixed horizontally in the room as they
                                                                          completed the task (see figure 2). The computer was placed
                                                                          on a flat horizontal surface next to the bench and the screen
                                                                          was positioned approximately 33 cm from the face of the
                                                                          participant. At this distance, the face stimuli subtended
   Figure 1: Schematic diagram of the possible image orientations         approximately 5 º by 7º of visual angle. The experimental
   when the observer is lying on his right side. Face images that are     room was brightly lit.
  retinally up (RU) and retinally down (RD) are both rotated by 90º          We presented participants with Mooney faces in random
 in the environmental frame, while images that are environmentally        order with each face in one of 4 possible orientations – up,
up (EU) and environmentally down (ED) are both rotated by 90º in          down, right, and left on the screen (see Figure 1). After
                           the retinal frame.                             completing a block of 48 trials while lying on one side, the
                                                                          participant switched to lying on their other side and
                          Experiment 1                                    completed another block of 48 trials. The first block
    In relation to which reference frame(s) does the face                 consisted of the 48 original Mooney images while the
inversion effect occur? In Experiment 1, we investigated                  second block consisted of the 48 mirror-reversed images,
this question by having participants classify the emotional               each appearing in a randomly selected orientation. No
expression of Mooney faces (Mooney & Ferguson, 1951)                      feedback was given to participants.
while they lay on their sides. Mooney faces are two-toned
images used in many experimental studies of face
processing because they are difficult to perceive when
upside-down and elicit a notoriously large inversion effect
(see Figure 3).
Methods
Participants. 56 individuals from the Stanford community
were recruited to participate in this study in exchange for                     Figure 2: Pole-mounted horizontal chin-rest used in all
payment or class credit.                                                           experiments. Response pad used in Experiment 1.
Stimuli. Mooney faces were generated by blurring gray-                    Results
scale photographs and reducing them to two tones (see                     Data from 6 of 56 participants were excluded in analysis
Figure 3A). We selected 48 faces that could be easily                     because they either failed to perform above chance levels
identified as happy (16), sad (16), or angry (16) when                    (n=1) or their reaction times were more than 3 standard
upright. We then mirror-reversed each of these images to                  deviations above the group median (n=5). There were 8
create two sets of 48 faces for a total of 96 face images.                distinct types of trials (2 body positions X 4 image
                                                                          orientations). Because there was neither a main effect of
                                                                          body position (F(1,49)= 1.40, p>0.2) nor an interaction
                                                                      436

between body position and image orientation (F(1,49) =                 another causes the large retinal effect to mask the
1.59, p>0.2), we collapsed each participant’s data across the          environmental effect.
two body positions and refer to the 4 image orientation                   It is also possible that the environmental inversion effect
conditions as “retinally up” (RU), “retinally down” (RD),              observed in Experiment 1 may be a result of the specific
“environmentally up” (EU) and “environmentally down”                   task we used: a difficult, emotional expression classification
(ED). A retinal face inversion effect would manifest as                task of degraded face stimuli that recruits online face
better performance in RU versus RD trials. An                          processing mechanisms. The literature on face processing
environmental face inversion effect would manifest as better           has established inversion effects in a wide range of
performance in EU trials as compared to ED trials.                     perception and memory tasks. Can environmental
   Performance in all image orientations was significantly             orientation also influence how we store faces in memory, or
above 33% chance (ts(49)>16, p<10-20). As expected, we                 are these effects limited to specific online perceptual tasks?
observed a large retinal inversion effect, with more accurate
performance (0.94 vs. 0.70) and faster reaction times on                                       Experiment 2
correct trials (917ms vs. 1160ms) for RU versus RD faces                  The results of Experiment 1 demonstrated that both retinal
(t(49)= 15.6, p<10-19 for accuracy; t(49)=-9.3, p<10-11 for            and environmental reference frames affect online processing
reaction time; see Figure 3B,C). Intriguingly, we also found           in an emotional expression classification task of Mooney
a reliable effect of environmental orientation. Responses              faces. In Experiment 2, we asked if these effects would
were consistently more accurate (0.843 vs. 0.796) and faster           extend to a very different type of task with a very different
(1039ms vs. 1084ms) for EU vs. ED faces (t(49)= -2.4,                  set of face stimuli: recognition memory for gray-scale face
p=0.02 for both measures).                                             images.
                                                                       Methods
                                                                       Participants 26 individuals from the Stanford community
                                                                       were recruited to participate in this study in exchange for
                                                                       payment or class credit.
                                                                       Stimuli & Procedure 192 front-view, gray-scale
                                                                       photographs of Caucasian males were selected from the
                                                                       FERET database (Phillips et al., 1998). Stimuli were
                                                                       cropped using an oval shape to remove hair and clothing
                                                                       around each face and normalized for size, brightness, and
                                                                       contrast (see Figure 4A).
                                                                          We used the same apparatus and setup as in Experiment
                                                                       1. The experiment was programmed in Matlab using the
                                                                       Psychophysics Toolbox. Participants completed study/test
                                                                       blocks while lying on either side, for a total of 8 study/test
                                                                       blocks (2 body positions X 4 image orientations).
                                                                          During each study block, a sequence of 12 different faces
    Figure 3: Sample stimuli and performance on the emotional          was presented 4 times (each sequence in a new random
   expression classification task in Experiment 1 for retinally up     order). All faces in each study block were displayed at one
 (RU), down (RD), environmentally up (EU) and down (ED) faces.         given orientation (all up, all down, all left, or all right on the
             Error bars denote between-subjects SEM.                   screen). Each face image remained on the screen for 900ms
                                                                       and there was a 100ms ISI between faces. The background
Discussion                                                             of the display was black.
   The results of Experiment 1 support previous work                      A test block immediately followed each study block. A
demonstrating a large face inversion effect in the retinal             face was presented centrally in the same orientation as the
frame of reference. However, the results also support the              faces in the preceding study block. Participants held a
existence of a novel environmental inversion effect in the             computer mouse in their right hand and indicated whether
perception of faces. Despite the fact that faces in the EU and         the face on the screen was one they had just studied (“old”;
ED orientations were both rotated by 90º in the retinal                left mouse click) or one they had never seen before (“new”;
frame, there was a small but significant advantage for                 right mouse click). Each test block thus consisted of 24
classifying the faces’ expressions when they were EU                   trials: the 12 old faces interspersed with 12 new faces.
(upright in the environmental reference frame) versus ED               Participants completed 4 study/test blocks while lying in
(upside-down in the environmental reference frame). It is              one body position (one block at each orientation), and
possible that earlier research on this topic (e.g. Troje, 2003)        another 4 study/test blocks while lying in the other position.
found no evidence of an environmental inversion effect in              The order of positions and blocks was randomized across
faces because pitting the two reference frames against one             participants.
                                                                   437

Results                                                                   However, this interpretation of the results depends on the
   Data from 1 participant was excluded in analysis because            reliability of our experimental apparatus and design. In our
she failed to perform above chance level on the recognition            experiments, participants were lying down horizontally in
task. As in Experiment 1, there was neither a main effect of           order to disassociate the retinal and environmental frames of
body position (F(1,24)=0.35, p>0.5) nor an interaction                 reference, but this disassociation is only valid if both EU
between body position and image orientation (F(1,24)=                  and ED images were precisely at 90º in the retinal frame. If
1.34, p>0.1). We therefore collapsed each participant’s data           participants’ heads or eyes were slightly rotated towards
across the two body sides and refer to 4 image orientations            environmentally up, this asymmetry may have contributed
as “retinally up” (RU), “retinally down” (RD),                         to the effects we have found.
“environmentally up” (EU) and “environmentally down”                      In fact, there are at least two reasons an asymmetry might
(ED).                                                                  exist in our experimental setup. First, physiologists have
   We measured participants’ ability to discriminate old               identified a phenomenon known as ocular counter-roll
from new faces (d’) as well as their reaction time on correct          (OCR; see Sares et al., 2007), in which people’s eyes rotate
trials. As expected, we found a large retinal inversion effect,        slightly in the opposite direction of their head tilt. For
with better discrimination (d’ = 1.47 vs. 0.64) and faster             example, when a person tilts their head clockwise, the eyes
reaction times (976ms vs. 1112ms) for RU compared to RD                respond by exerting a small counter-roll of several degrees
faces (t(24)=5.44, p<0.0001 for d’, and t(24)=-3.49,                   counter-clockwise. Second, while participants were strapped
p=0.002 for reaction time). In addition, we found a reliable           into our horizontally leveled head and chin rest, they were
environmental inversion effect in recognition memory of                still able to shift their heads a few degrees and may have
faces: EU faces were recognized better than ED faces (d’ =             unwittingly tilted their heads when performing the task.
1.00 vs. 0.76; t(24)=3.0, p<0.007). This effect could not be           Could these factors have contributed to better performance
attributed to a speed-accuracy trade-off; in fact, reaction            for EU versus ED faces? To address this possibility, in
time on correct trials was (non-significantly) faster for EU           Experiment 3 we measured the exact position of
(1052ms) vs. ED (1096ms) faces (p=0.3; see Figure 4B,C).               participants’ eyes as they sat upright or lay in our
                                                                       experimental apparatus, and constructed stimuli to
                                                                       counteract any resulting asymmetries in retinal orientation.
                                                                                               Experiment 3
                                                                       Correcting for asymmetries in retinal orientation. In 13
                                                                       separate participants, we measured the eyes’ orientation
                                                                       when they lay in our experimental apparatus. We used a
                                                                       leveled high-resolution digital SLR camera to photograph
                                                                       participants’ irises while they were sitting upright and lying
                                                                       horizontally. Using Photoshop, two independent coders
                                                                       measured the angular disparity between the two pictures
                                                                       (i.e. how many degrees the sitting-up picture needed to be
                                                                       rotated so that it would be aligned with the lying-
                                                                       horizontally picture). These measurements produced an
                                                                       average OCR of approximately 4.2º (SD = 1.8º) in the
                                                                       direction opposite of head tilt. In other words, when subjects
                                                                       lay on their right, their eyes were rotated left by an average
                                                                       of 4.2º.
    Figure 5: Sample stimuli and performance on the recognition           Although this was a relatively small disparity consistent
  memory task in Experiment 2 for retinally up (RU), down (RD),        with previously published measurements (Sares et al.,
 environmentally up (EU) and down (ED) faces. Error bars denote        2007), the bias results in EU faces being on average more
                      between-subjects SEM.                            aligned with subjects’ retinal frame than ED faces.
                                                                       Specifically, when participants lay horizontally, EU faces
Discussion                                                             were rotated away from retinal upright by an average of
   The results of Experiment 2 suggest that environmental              85.8º, whereas ED faces were rotated by an average of
orientation can influence recognition memory for faces                 94.2º.      This asymmetry could potentially drive the
when retinal orientation is held constant. Participants had            differences in performance and reaction time observed in
better recognition memory performance when faces were                  Experiments 1 and 2. To correct for this asymmetry, in
presented       environmentally       upright    compared       to     Experiment 3 we rotated the face images by 5º in the
environmentally upside-down. Together with Experiment 1,               direction of OCR observed in our sample. This over-
these results suggest that face inversion effects in the               correction would ensure that any observed advantage in
environmental frame of reference generalize across very                processing EU faces could not be attributed to EU faces
different tasks utilizing very different face stimuli.
                                                                   438

being more aligned than ED faces with participants’ retinal        results in EU faces that are not truly upright in the
frame.                                                             environmental frame, but rather rotated by 5º. The
                                                                   misalignment between our EU stimuli and the
Methods                                                            environmental frame may have further weakened the
Participants. 43 individuals from the Stanford community           efficacy of our control experiment. In an ongoing study, we
were recruited to participate in this study in exchange for        are examining a different method of correcting for OCR that
payment or class credit. 39 of these completed Experiment          involves adjusting participants’ orientation (rather than the
3a (an abbreviated version of Experiment 1) and all 43             images) according to individual estimates of their OCR.
completed Experiment 3b (an abbreviated version of
Experiment 2).
Stimuli & Procedure. Experiments 3a and 3b were
identical to Experiments 1 and 2, except (1) faces appeared
in only EU and ED orientations (that is, we did not include
RU or RD trials), and images were rotated by 5º in the
direction opposite the participants’ body position, to correct
for the asymmetry described above. Participants first lay on
one randomly selected side and performed two study/test
blocks of the recognition memory task. They then switched
sides and performed two more such blocks. They then
completed one block of 48 emotional expression ratings of
Mooney faces, switched sides once more, and completed a
final block of expression ratings.
Results                                                             Figure 6: Results of Experiments 3a and b. A: percent correct and
                                                                       reaction time on the emotional expression classification task
   Data from 7 participants in Experiment 3a were excluded
                                                                      (Experiment 3a) for environmentally up (EU) and down (ED)
from analysis because their reaction times were more than 3           faces. B: discrimination performance and reaction time on the
standard deviations above the median, and data from 6                  recognition memory task (Experiment 3b). Error bars denote
participants in Experiment 3b were excluded because they                                  between-subjects SEM.
failed to perform above chance level on the recognition task.
Despite over-correcting for retinal asymmetry across EU
and ED image orientations, we found significant or trending                             General Discussion
effects in performance and reaction time similar to those of
Experiments 1 and 2. In Experiment 3a (expression                     In relation to which reference frame(s) does the face
classification of Mooney faces), proportion correct was            inversion effect occur?           We have presented several
0.826 on EU vs. 0.809 on ED trials (t(31)=1.18; p=0.12, 1-         experiments suggesting that independent face inversion
tail). Reaction time was 958ms vs. 978ms, respectively             effects occur in both the retinal and environmental reference
(t(31)= -1.43, p=0.08, 1-tail; see Figure 6A).                     frames.
   In Experiment 3b, we found a significant advantage in              In Experiment 1, participants classified the emotional
recognition memory for EU versus ED faces (Figure 6B).             expression of Mooney faces; in Experiment 2, participants
The average d’ across subjects was 1.01 for EU vs. 0.77 for        performed an old/new recognition task on novel face
ED faces (t(36)=2.79; p=0.004, 1-tail). Reaction time was          images. In both studies, we found a large effect of retinal
also faster for EU (1108ms) vs. ED (1181ms) faces (t(36)=          orientation on performance and a reliable (though smaller)
-2.42, p=0.01, 1-tail).                                            effect of environmental orientation. Specifically,
                                                                   participants in Experiment 1 were more accurate and faster
Discussion                                                         at judging emotional expressions of environmentally upright
                                                                   versus environmentally upside-down faces, even though
   The results of Experiment 3 suggest that OCR does not           faces in both conditions were rotated by 90º in the retinal
fully account for the results observed in Experiments 1 and        frame. Similarly, recognition performance in Experiment 2
2. Even after over-correcting for a 4.2º average asymmetry         was better for environmentally upright versus
in the retinal orientation of images, we again found reliable      environmentally upside-down faces. In Experiment 3, we
advantage in processing EU faces compared to ED faces,             ruled out an alternative explanation of our findings based on
although these effects in the expression classification task       the possibility that OCR or other experimental artifacts were
were only marginally significant. We attribute the noisier         causing environmentally upright face images to be slightly
results in Experiment 3a to the fact that we utilized a single     more aligned with participants’ retinal frame. We conclude
correction for OCR across all participants even though our         that there exists a reliable effect of environmental
measurements found this varied considerably from person to
person. In addition, rotating the image to correct for OCR
                                                               439

orientation on face processing that is revealed when retinal        Mooney CM, Ferguson GA (1951) A new closure test. Can
orientation is held constant.                                         J Psychol 5:129–133.
   However, as noted in the introduction, there are actually        Phillips, P. J., Wechsler, H., Huang, J., & Rauss, P. (1998).
many different environmental frames of reference, several             The FERET database and evaluation procedure for face
of which were conflated in our present set of experiments.            recognition algorithms. Image and Vision Computing
For example, a face image on a computer may be upright on             Journal. 16, 295–306.
the screen, upright in the room the computer is in, and             Rock, I. (1973). Orientation and form. New York, New
upright with respect to the directional pull of gravity. In our       York. Academic Press Inc.
setup, the room was brightly lit and participants had visual        Rhodes, G., Brake, S., & Atkinson, A. P. (1993). What's lost
access to objects and other features of the experiment room,          in inverted faces? Cognition, 47(1), 25-57.
which provided cues to environmental orientation in                 Sares, F., Granjon, L., Abdelrhani, B., & Boulinguez, P.
addition to the pull of gravity. Previous work has suggested          (2007). Analyzing head roll and eye torsion by means of
that it may be the gravitational orientation that matters most        offline image processing. Behavior Research Methods.
of all of the environmental cues (e.g. Chang et al., 2010),           39(3), 590-599.
but this may or may not be the case with face processing.           Thompson, P.(1980) Margaret Thatcher: a new illusion.
Future work will try to disentangle these different                   Perception 9 483-4.
environmental reference frames in order to determine which          Troje, N. F. (2003). Reference frames for orientation
one(s) play a role in face processing.                                anisotropies in face recognition and biological-motion
   What mechanisms might underlie an environmental                    perception. Perception, 32(2), 201-210.
inversion effect in face processing? One possibility is that        Tversky, B. Lee, P. U., and Mainwaring, S. (1999). Why
we learn through experience that faces tend to be upright in          speakers mix perspectives. Journal of Spatial Cognition
the world regardless of our own body’s position when we               and Computation, 1, 399-412.
observe them. For example, we may lie sideways when                 Yin RK. (1969). Looking at upside-down faces. Journal of
watching television, but nevertheless faces and other images          Experimental Psychology. 81:141–145.
on the screen remain upright in relation to the television, the
room, and gravity. We propose that this contextual
information present in our everyday experience affects our
ability to process faces when we see their regular upright
context (EU) versus an upside-down context (ED). Indeed,
Rock’s (1973) early work on novel shape perception
suggests that how we experience and categorize objects
during learning affects which reference frames matter later
for recognition performance. Further research is currently
underway in the lab to explore this possibility.
                    Acknowledgments
The authors would like to Jason Loftus for help with data
collection and Harry Bahlman for engineering our
experimental apparatus. We would like to thank Nathan
Witthoft for bringing to our attention the potential effect of
OCR. We would also like to thank Alexia Toskos Dils, Jon
Winawer, Daniel Sternberg and Lera Boroditsky for helpful
discussions throughout the design and execution of these
studies. This work was supported by NRSA Award 018279
to ND.
                         References
Chang, D. H. F., Harris, L. R., & Troje, N. F. (2010).
   Frames of reference for biological motion and face
   perception. Journal of Vision, 10 (Jun 28).
Farah, M. J., Wilson, K. D., Drain, M., & Tanaka, J. N.
   (1998). What is "special" about face perception?
   Psychological Review, 105(3), 482-498.
Lopez, C., Bachofner, C., Mercier, M., Blanke, O. (2009).
   Gravity and observer's body orientation influence the
   visual perception of human body postures. Journal of
   Vision. 9(5):1, 1-14
                                                                440

