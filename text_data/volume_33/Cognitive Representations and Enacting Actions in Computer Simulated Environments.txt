UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cognitive Representations and Enacting Actions in Computer Simulated Environments

Permalink
https://escholarship.org/uc/item/1tm631hn

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Pierce, Devin
Lu, Shulan
Harter, Derek
et al.

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Cognitive Representations and Enacting Actions in Computer Simulated
Environments
Devin R. Pierce (dpierce@cp.tamu-comerce.edu)
Department of Psychology, Texas A&M University - Commerce
Commerce, TX 75429 USA

Shulan Lu (Shulan_Lu@tamu-commerce.edu)
Department of Psychology, Texas A&M University - Commerce
Commerce, TX 75429 USA

Derek Harter (Derek_Harter@tamu-commerce.edu)
Department of Computer Science, Texas A&M University - Commerce
Commerce, TX 75429 USA

Pratyush Kotturu (pratyush@pratyush.in)
Department of Psychology & Department of Computer Science, Texas A&M University - Commerce
Commerce, TX 75429 USA

Paweena Kosito (tuktika@hotmail.com)
Department of Psychology, Texas A&M University - Commerce
Commerce, TX 75429 USA

Abstract

Introduction

Computer-simulated training environments are frequently
used for having people perform behaviors that pose a risk of
injury in the real world. The success of such training
applications is likely to be impacted by the degree to which
they evoke presence. In the current work, we examined
whether adding auditory components to a computer-simulated
environment might increase presence, thereby leading risktaking behaviors to be more consistent with performance in
an equivalent real environment. In Experiment 1, participants
first observed a human or an avatar perform several cuts on a
vegetable and then pause. Participants then used a mouse
cursor to indicate where they wanted to see the next cut
performed. Compared to participants coordinating actions on
behalf of the human, those coordinating actions on behalf of
the avatar chose cut locations that had a greater likelihood of
producing injury. In Experiment 2, we added an auditory
component associated with the expression of pain to the
computer-simulated environment and found that participants
chose cut locations that were comparable to those in the real
environment. This curb in risk-taking was not found in
Experiment 3, which used a generic sound associated with the
cutting task but not associated with pain. This indicates that
the effect found in Experiment 2 was not simply due to
directing attention to risky portions of the event. These results
suggests that adding auditory components to computersimulated environments involving risk-taking behaviors may
be useful. However, more research is needed in order to
effectively select and use auditory components most
appropriately.

It is well known that computer-simulated environments can
provide a safe setting for humans to perform tasks that carry
a risk of injury in real environments. They have been used
in a number of significant ways, such as improving medical
students' ability to perform surgery (Calatayud, Arora,
Aggarwal, Kruglikova, Schulz, Funch-Jensen, &
Grantcharov, 2010) and even teaching children to avoid
danger while crossing the street (Clancy, Rucklidge, &
Owen, 2006). These examples illustrate the importance of
exploring methods that may enhance the effectiveness of
computer-simulated training environments. One factor that
is particularly important for the success of such
environments is their ability to evoke presence, where
people act and respond realistically, even though they are
engaging and perceiving the task through computer
mediated platforms (Sanchez-Vives & Slater, 2005; Slater,
Lotto, Arnold, Sanchez-Vives, 2009). In accordance,
finding ways to increase presence is one approach to
facilitate the effectiveness of training in computer-simulated
environments.
Studies suggest that computer-simulated environments
involving physical risk can evoke presence; however, they
are oftentimes limited by the fact that no comparisons were
made to an equivalent real environment condition. For
example, research has shown that observing a virtual fire
beneath one's virtual body leads people to raise their real
arms as if avoiding harm (Gamberini, Cottone, Spagnolli, et
al. 2003); observing one's virtual body stabbed with a knife
leads to increased physiological arousal (Hägni, Eng, HeppReymond, Holper, Keisker, Ewa, et al,, 2008); and being

Keywords: Human-computer interaction; presence; pain;
virtual human

856

asked to inflict pain upon a virtual character can lead some
people to withdraw early from a study (Slater, Antley,
Davison, Swapp, Guger, Barker, et al., 2006) In such
scenarios, it is easy to see that it is not feasible to carry out
parallel real-world conditions for obvious ethical reasons.
This not only makes it difficult to determine just how
realistic their behavior was, but it also presents difficulties
when trying to explore methods that could increase presence
in scenarios involving risk of injury.
In a recent study, we developed a method that allowed us
examine how people coordinate cutting actions in real and
computer-simulated environments (Pierce, Lu, & Harter,
2009). Participants first observed a either a human or avatar
perform two cuts on a vegetable and then pause, as if
deciding where to make the next cut. A mouse cursor then
appeared at the knife’s location and participants moved it to
where they wanted to see the next cut made. Results
showed that there was no difference in the amount of time
spent completing the task or the velocity that people moved
the cursor to indicate their desired cut location. This
indicates that the computer simulated environment
successfully evoked some level of presence. However,
results also revealed that when coordinating actions on
behalf of the virtual human, people had a greater tendency
to choose cut locations that would more likely result in
injury.
In the current experiments, we extend our previous
research by examining whether providing auditory
component to a computer-simulated environment might
increase presence and thus mitigating the risk taking
tendencies mentioned above. We adopted the general
methodology as in our previous work just mentioned.
Experiment 1 was a replication study and was used to assess
baseline performances in the real environment. We
replicated the previous finding, in that those coordinating
actions on behalf of the avatar chose cut locations that had a
greater likelihood of producing injury. Two subsequent
experiments were then conducted in which we simply added
two different auditory components
to the simulated
environment. In Experiment 2, we choose to use a sound
that was associated with the expression of pain that could
result from cutting one's self. Experiment 3, in contrast,
used a more generic sound associated with the cutting task
but not directly associated pain.

either an avatar in a medium fidelity environment or a
human in a real environment. The avatar/actor, holding a
piece of food with one hand, performed several cuts on it
and then paused as if deciding where to make the next cut.
Participants then used a mouse cursor to indicate where they
wanted to see the next cut performed. Given that different
input devices can significantly influence how motor-based
tasks are performed (MacKenzie & Jusoh, 2001;
MacKenzie, Kauppinen, & Silfverberg, 2001; MacKenzie,
Sellen, & Buxton, 1991), participants in both environments
enacted actions using a standard computer mouse.

Method
Participants. Fifty-two undergraduates were recruited from
the Texas A&M University – Commerce.
Materials and Design. The experimental stimuli consisted
of a movie involving a human and a parallel simulation
involving an avatar to accompany our two between-subjects
conditions: human enacting actions and avatar enacting
actions (see Figure 1).

Figure 1: Snapshot taken from simulated environment at the
point where the avatar paused.
For the stimulus movie, a male actor used a knife to slice
a cucumber into pieces. He also performed non-risky
entrance events that preceded the risky culinary activity
(moving lettuce to a plate). The movie was recorded with a
Sony digital camcorder and filmed from a fixed position that
was over and behind the actor’s shoulder. Furthermore, to
reduce the possibility of drawing attention to certain
features of the movies, it was made in one take, without the
use of zooms, cuts, or pans.
The movie served as a model for which a medium fidelity
simulation was created, using the Alice 2.0 programming
environment (Conway et al., 2000). Each event being
simulated was approximately the same length as in real
environments. Cutting speeds were determined to be
comparable between the movie and its simulated version. A
sample simulation and movie was also created for a practice

Experiment 1
Experiment 1 was designed to fulfill two purposes. First, it
served as a replication of our previous work, which
demonstrated that people are more likely carry out actions in
a manner that could result in injury to an avatar in a
computer simulated environment than a human in a real
environment. Second, it served to assess baseline
performance in the real environment, so that comparisons
can be made with participants in subsequent experiments
where we added auditory cues to the simulated environment
associated with pain (Experiment 2) and not directly
associated with pain (Experiment 3). Participants observed

857

trial, where non-risky actions were enacted (moving cookies
to a tray).

Results & Discussion
As illustrated in Fig 2, an independent samples t-test
revealed a significant effect of task environment on the
injury index, t (50) = 2.28, p < .05, indicating that
participants chose cut locations much closer to the avatar’s
non-cutting hand (M = .35; SE 3.17) than the human’s noncutting hand (M = 10.85; SE = 3.34). This data replicates
our previous finding with a new group of participants.
Furthermore, it provides baseline performance for those in
the human enacting actions condition, which can be
compared to those in the simulated environment receiving a
sound associated with the experience of pain (Experiment 2)
or a sound that is not directly related with the experience of
pain (Experiment 3).

Procedure. Participants were randomly assigned to one of
the two conditions and then escorted to a desk equipped
with a computer mouse and 17 in. monitor. The mouse was
aligned horizontally on the desk corresponding to where the
second cut was presented on the monitor. An outline was
also drawn around the mouse at this location, which served
as the designated starting position for each trial. Participants
were instructed to leave their right hand on the mouse
throughout the experiment and to keep it at the starting
position until the experiment prompted for a response.

Mean Values on Injury Index

Before the experimental trial, they were informed of the
following: (1) they would observe several cuts made on a
cucumber; (2) the computer would pause; (3) a cursor would
appear where the knife is located; (4) they should move the
cursor as quickly as possible to where they would like to see
the next cut made; and (5) then they should click the mouse.
On experimental trials, the cursor appeared along the x-axis
where the knife was located and along the y-axis at the base
of the food being cut. Participants were given one practice
trial (indicating with a mouse cursor where they wanted a
cookie to be placed) followed by one experimental trial.
The x, y screen coordinates of mouse movement were
recorded every 10ms, starting at the time that the cursor
appeared and stopping at the time at which participants
clicked the mouse. E-prime 2.0 (Schneider, Eschman, &
Zuccolotto 2007) was used to control the presentation of the
stimuli and for the collection of data. The simulation and
movie was presented at a resolution of 1024 x 768 and at an
average frame rate of 32 frames per second for the
simulation and 30 frames per second for the movie. This
experiment took approximately 5 minutes to complete.

16
14
12
10
8
6
4
2
0
-2
-4
-6
-8
RE

SE

SE (ouch) SE (cutting)

Task Environment

Figure 2: Performance in each condition (RE = real
environment & SE = simulated environment). Error bars
represent standard errors of the means.

Injury Index. This measure was created to indicate how
much injury the human or avatar would likely incur if the
cut location chosen by the participant were actually
performed. To calculate the index, the x pixel location that
was just to the right of the left index finger was subtracted
from the x pixel coordinate corresponding to the location of
the desired cut. It was reasoned that since the knife
remained perpendicular to the object for each cut,
participants might infer that subsequent cuts would be made
the same way. Operating under this assumption, the left
index finger would become increasingly injured as the
participant moved the desired cut location further to the left
of the x pixel coordinate located just to the right of the left
index finger (see Figure 1). Smaller values on this index are
indicative of greater potential for injury. For example, a
score of zero on the injury index would indicate that users
suggested the cut location right at the finger tip, whereas a
score of negative 5 would indicate that the suggested cut
locations passed the finger tip and thus brought injury to the
avatar.

Experiment 2
Experiment 1 showed that people decided to perform cutting
actions at location that had a greater potential for injury
when coordinating actions in a computer simulated
environment than in a real environment. In Experiment 2,
we used the same methodology as in Experiment 1, with the
exception that we added a voice to the simulated
environment saying “ouch” each time the avatar made a cut.
The aim of this experiment is to see whether a providing a
sound component directly related to the human expression
of pain could increase presence and reduce the risk taking
that was found in Experiment 1.

Method
Participants & Design. Whereas the human enacting
actions condition was comprised of those from Experiment
1, data from a new group of 22 participants was used for the
avatar enacting actions condition. The new participants
recruited for this between-subjects study were drawn from
the same participant pool as described in Experiment 1.

858

Materials. The materials were identical to those used in
Experiment 1, with the exception that a voice saying "ouch"
was heard each time the avatar performed a cut. This was
achieved by performing a series of audio/videos editing.
First, the cucumber simulation and the audio file were
imported into video and audio tracks using Cubase, which is
a professional music production software program. Third,
the audio track was edited so that the voice saying "ouch"
was synchronized to the cutting actions in the simulation,
followed by the creation of a modified audio file. Fourth,
the cucumber simulation and modified audio file were
imported into VirtualDub and then combined into a single
audio/video file.

Procedure. The procedure was identical to that described in
Experiment 1.
Data Analysis. The data analysis was identical to that
described in Experiment 1.

Results & Discussion
As illustrated in Fig 2, an independent samples t-test
revealed a significant effect of task environment on the
injury index, t(50) = 2.08, p < .05, indicating that
participants chose cut locations much closer to the avatar’s
non-cutting hand (M = -1.88; SE = 5.13) than the human’s
non-cutting hand (M = 10.85; SE = 3.34). This result
indicate that at least in our experimental set-up, the cutting
sound did not curb risk-taking.

Procedure. The procedure was identical to that in
Experiment 1.

General Discussion

Data Analysis. The data analysis was identical to that in
Experiment 1.

The current findings suggest that adding the dimension of
sound to computer-simulated environments, can lead risktaking behaviors to be more comparable to how they occur
in a parallel real environment. This is consistent with the
body of research regarding presence and provides support
that sound can be a cost-efficient way to increase a
computer-simulated environment's ability to evoke
presence. However, it appears that not all sounds are equal
and effective, as we only found that the sound expressing
pain curbed risk-taking.
It is tempting to speculate why the sound component
expressing human pain was effective for reducing risktaking. Recent research has demonstrated that simply
hearing a word associated with pain can trigger activity in
ACC and insula (Richter, Eck, Straube, Miltner, & Weiss,
2010). A number of studies have implicated these cortical
areas as being involved not only with the experiencing pain
first-hand, but also when perceiving other humans in pain
(see Decety & Grezes, 2006). However, these areas appear
to be less involved in situations where mediated
representations of humans are in painful situations (Gu and
Han, 2007). It is thus possible that people may embody
pain less extensively in computer-simulated environments
and that this contributed to participants being riskier in our
initial computer-simulated condition where no sound was
provided. The pain-related word may have in turn reduced
risk taking because it facilitated the environment's capacity
to evoke an embodied experience, which some believe is an
important aspect of presence (e.g., Biocca, Harms, &
Burgoon, 2003; Schubert, Friedman, Regenbrecht, 1999).
The current work is by no means free of limitations. First,
we only used two different sounds ("ouch" & "knife
cutting") within one particular setting (i.e., cutting
vegetable). There are a range of possibilities regarding the
use of sounds and how they might be implemented in
different scenarios, as well as, a variety of different
computer simulated environments. This raises an important
concern regarding how future research is needed to help
better understand how to approach selecting and using
auditory cues appropriately for different training scenarios

Results & Discussion
As illustrated in Fig 2, an independent samples t-test
revealed no effect of task environment on the injury index, t
(46) = .17, p = .87, indicating that participants chose cut
locations that were a comparable distance from the avatar’s
non-cutting hand (M = 9.82; SE =5.24) and the human’s
non-cutting hand (M = 10.85; SE = 3.34). These results
indicate that using a pain-related word as an auditory cue
could curb risk taking and make performance comparable to
those in the a parallel real environment.

Experiment 3
Experiment 2 provided some evidence that adding an
auditory cue signaling pain can lead people to choose cut
locations that were comparable to those in the real
environment. In Experiment 3, we used the same
methodology as in the previous experiments, with the
exception that we added the actual cutting sound while
preparing cucumber to the simulated environment each time
the virtual character made a cut.

Method
Participants & Design. Whereas the human enacting
actions condition was comprised of those from Experiment
1, data from a new group of 26 participants was used for the
avatar enacting actions condition. The new participants
recruited for this between-subjects study were drawn from
the same participant pool as described in Experiment 1.
Materials. The materials were identical to those used in
Experiment 1, with the exception that participants heard a
cutting sound each time the avatar made a cut. The
audio/visual editing method was the same as described in
Experiment 2.

859

involving risk. Second, participants only received one
critical trial. It is an open question as to whether receiving
multiple trials with an auditory cue might at some point lose
its effectiveness.

World Conference on Innovative Virtual Reality. New
York, NY: ASME Publishing.
Richter, M., Eck, J., Straube, T., Miltner, W. R., Weiss, T.
(2010). Do words hurt? Brain activation during the
processing of pain-related words. Pain, 148, 198–205.
Sanchez-Vives, M., & Slater, M. (2005). From presence to
consciousness through virtual reality. Nature Reviews
Neuroscience, 6, 332-339.
Schneider, W., Eschman, A., & Zuccolotto, A. (2007). EPrime 2 reference guide. Pittsburgh, PA: Psychology
Software Tools Inc.
Schubert, T.W., Friedman, F., & Regenbrecht, H.T.
(1999). Embodied presence in virtual environments. In:
Paton R, Neilson I (Eds.). Visual representations and
interpretations. Springer-Verlag, London, pp. 268–278.
Slater, M., Antley, A., Davison, A., Swapp, D., Guger, C.,
Barker, C., et al. (2006). A virtual reprise of the Stanley
Milgram obedience experiments. PLoS ONE, 1(1), e39.
Slater, M., Lotto, B., Arnold, M. M., & Sanchez-Vives, M.
V. (2009). How we experience immersive virtual
environments: the concept of presence and its
measurement. Anuario de Psicologia, 40, 193-210.

Acknowledgments
This research was supported by grants from the National
Science Foundation (IIS 0742109 and IIS 0916749) and
Texas A & M University-Commerce Faculty Research
Enhancement Program. Any opinions, findings, and
conclusions or recommendations expressed in this material
do not necessarily reflect the views of the National Science
Foundation. We would like to thank Lakshmi Pydikondal
afor building the simulated environments, as well as, Rachel
Bailey and Heather Grimes for helping with data collection.
References
Biocca, F., Harms, C., Burgoon, J. K. (2003). Toward a
more robust theory and measure of social presence: review
and suggested criteria. Presence 12(5), 456–480.
Clancy, T. A., Rucklidge, J. J., & Owen, D. (2006). Road
crossing safety in virtual reality: a comparison of
adolescents with and without ADHD. Journal of Clinical
Child and Adolescent Psychology, 35, 203-215.
Conway, M., Audia, S., Burnette, T., Cosgrove, D.,
Christiansen, K., Deline, R., et al. (2000). Alice: lessons
learned from building a 3D system for novices. Proc.
CHI, pp. 486–493.
Gamberini, L., Cottone, P., Spagnolli, A., Varotto, D.,
Mantovani, G. (2003). Responding to a fire emergency in
a virtual environment: different patterns of action for
different situations. Ergonomics, 46 (8), 842–858.
Gu, X., & Han, S. (2007). Attention and reality constraints
on the neural processes of empathy for pain. NeuroImage,
36, 256–267.
Hägni, K., Eng, K., Hepp-Reymond, M. C., Holper, L.,
Keisker, B., Siekierka, E., et al (2008). Observing virtual
arms that you imagine are yours increases the galvanic
skin response to an unexpected threat. PLoS ONE, 3(8),
e3082.
MacKenzie, I. S., & Jusoh, S. (2001). An evaluation of two
input devices for remote pointing. Proceedings of the 8th
IFIP International Conference on Engineering for
Human-Computer Interaction (pp. 235-249). Heidelberg,
Germany: Springer-Verlag.
MacKenzie, I. S., Kauppinen, T., & Silfverberg, M. (2001).
Accuracy measures for evaluating computer pointing
devices. Proceedings of the ACM Conference on Human
Factors in Computing Systems (pp. 9-16). New
York, NY: ACM Press.
MacKenzie, I. S., Sellen, A., & Buxton, W. (1991). A
comparison of input devices in elemental pointing and
dragging tasks. Proceedings of the ACM Conference on
Human Factors in Computing Systems (pp. 161-166).
New York, NY: ACM Press.
Pierce, D., Lu, S., & Harter, D., 2009. Enacting actions in
simulated environments. Proceedings of the Inaugural

860

