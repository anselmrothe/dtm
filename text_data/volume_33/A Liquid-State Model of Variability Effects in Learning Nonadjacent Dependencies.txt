UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Liquid-State Model of Variability Effects in Learning Nonadjacent Dependencies
Permalink
https://escholarship.org/uc/item/0rt2d1b4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Fitz, Hartmut
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

A Liquid-State Model of Variability Effects in Learning Nonadjacent Dependencies
                                             Hartmut Fitz (hartmut.fitz@gmail.com)
                              Center for Language and Cognition Groningen, University of Groningen
                                 Oude Kijk in ’t Jatstraat 26, 9712 EK Groningen, the Netherlands
                             Abstract
                                                                                                                         90 100
  Language acquisition involves learning nonadjacent dependen-
  cies that can exist between words in a sentence. Several ar-
                                                                                                                         80
                                                                              Correct (%)
  tificial grammar learning studies have shown that the human
  ability to detect dependencies between A and B in sequences                                                            70
  AXB is influenced by the amount of variation in the X element.
  This paper presents a model of statistical learning that displays                                                      60
  similar behavior on this task and generalizes in a human-like
                                                                                                                         50
  way. The model was also used to predict human behavior for
  increased distance and more variation in dependencies. We                                                              40
  compare this model-based approach with the standard invari-                                                                                   variability
                                                                                                                                    1   2               6         12        24
  ance account of the variability effect.
  Keywords: Language acquisition; statistical learning; vari-                                                                                       Variability
  ability; nonlocal dependencies; liquid-state machines.
                                                                            Figure 1: The variability effect in learning nonadjacent de-
                         Introduction                                       pendencies (data reproduced from Onnis et al. 2003).
Sentences in natural language are not just sequences of in-
dependent words. Dependencies can hold between immedi-                      results of this experiment are depicted in Figure 1. In condi-
ately adjacent words or between words at a distance. Lan-                   tions of high variability (12 and 24), dependency learning was
guage acquisition involves learning which dependencies are                  significantly better than for medium variability (6). The high-
syntactically required to form grammatical sentences. We                    est accuracy was observed when there was no variation in the
call a sequence of words in which the final element depends                 middle element (1). Manipulating the amount of variability
on the identity of the initial element a frame. Frames are                  in the fillers resulted in a U-shaped behavioral pattern.
quite common in natural language. In tense morphology, in-                     The experiment was designed to exclude surface distribu-
flectional morphemes depend on the subject auxiliary, e.g.,                 tional properties as explanatory factors. In all variability con-
in ‘X is VERB-ing Y’. The category VERB is highly vari-                     ditions, for example, each A..B frame occurred the same num-
able whereas the frame itself is rigid and highly frequent.                 ber of times in training, ruling out a frequency-based account
Nonlocal dependencies are also created by noun-verb number                  of the variability effect. Other statistical cues such as type fre-
agreement, e.g., in ‘the Xs on the table are Y’ where depen-                quency and forward transitional probabilities were similarly
dent elements (plural marker and auxiliary) can be separated                uninformative (see Figure 2). This suggests that mechanisms
by prepositional phrases or relative clauses. Furthermore, it
has been argued that frequent three-word frames such as ‘You
                                                                                                                                                     AXB frequency
                                                                                            Value according to measure
                                                                                                                                                ●
                                                                                                                              1.0
X it’ may enable children to induce word categories X and                                                                                            AX transitional probability
thus solve the bootstrapping problem (Mintz, 2003), in par-                                                                   0.8                    XB transitional probability
                                                                                                                                                ●    Type/token ratio
ticular if frame elements are function words (Leibbrandt &
                                                                                                                              0.6
Powers, 2010). In all these examples, patterns of highly in-
variant nonadjacent words are separated by highly variable                                                                    0.4
                                                                                                                                    ●
lexical material (fillers).                                                                                                   0.2           ●                                    ●
   In the artificial grammar learning paradigm (AGL) several                                                                                              ●
                                                                                                                                                          ●        ●
                                                                                                                                                                       ●
                                                                                                                              0.0   ●       ●                                    ●
recent studies have investigated how the learning of nonadja-
cent dependencies is modulated by the amount of variation in                                                                        1   2                 6        12         24
the middle slot (Gómez, 2002; Gómez & Maye, 2005; Onnis                                                                                           Variability
et al., 2003, 2004). These studies found a variability effect
in adults and children, and across modalities. In Onnis et                   Figure 2: Statistical cues do not explain variability effects.
al. (2003), for instance, adult subjects were exposed to 432
nonce word strings of the form Ai X j Bi where i ∈ {1, 2, 3}                of statistical learning which rely on frequency and N-gram
and X j was drawn from sets of various sizes (1, 2, 6, 12, or               information may not be able to account for the learning of
24). Subsequently, subjects had to judge the grammaticality                 nonadjacent dependencies in humans. The only information
of strings that were in the training set (e.g., A1 X4 B1 ) and of           that was useful in this task was the identity of the frame initial
strings in which dependencies were violated in that the final               elements. Learners had to attend to these elements and ignore
element did not match the initial element (e.g., A2 X9 B3 ). The            the ‘noise’ in the middle position. Why did this strategy work
                                                                      897

better in some conditions than in others? Onnis et al. (2003)              model with a working memory of past inputs that is degrad-
argued that learners attempt to seek invariance in the input.              ing over time (similar to the context layer of an SRN, see
When variability is high, dependencies stand out as invariant              Elman, 1990).
against the fillers and get noticed. When there is no varia-                  A liquid state is a vector of liquid-size in which each po-
tion in fillers, fillers stand out against the variable frames and         sition corresponds to the activation value of one unit in the
attention focuses on dependencies in these frames. In condi-               reservoir. During processing the liquid state is updated ac-
tions of medium variability, neither frames nor fillers attract            cording to the formula
special attention leading to poorer performance. Hence, the
                                                                                             z(t + 1) = σ(wliq z(t) + win x)           (1)
authors explained the U-shaped behavior by means of an at-
tentional mechanism that tries to detect figure-ground rela-               where z(t) is the liquid state at time t, wliq is the connection
tionships in the input. While this explanation works to ac-                matrix of the liquid, win is the connection matrix from the
count for the big picture, some more fine-grained aspects of               input units to the liquid, x is the current input, and σ is the
the data are left unexplained. For low variability (2), for ex-            activation function of units in the liquid (in our implementa-
ample, the difference in the number of frames and fillers is               tion tanh). The liquid consisted of 60 units and connectivity
smaller than for variability 6, and yet performance was better.            was set to 10%. To make the liquid state-forgetting (Jaeger,
Secondly, no significant difference between variabilities 12               2001), the spectral radius of wliq was clamped to 0.9 and the
and 24 was found, although the invariance account predicts                 connection matrix was scaled accordingly.
that more variation in fillers should facilitate learning here.               Input to the model was encoded using ten units. Each sym-
Thus the postulated attentional mechanism may not fully ex-                bol in the language was represented by five randomly chosen
plain behavioral differences between conditions.                           units of the input layer. These were switched to 1, the rest
   In this paper we present a connectionist model that repli-              to 0. The same distributed encoding was used to represent
cates human performance on the dependency learning (and                    target symbols at the output layer. The model’s output was
generalization) task. The model suggests an alternative, simi-             decoded by mapping the five most active units to 1, the others
larity-based explanation of the variability effect that does not           to 0. To predict a target element correctly, the decoded output
involve the role of attention. Differences in model behavior               pattern had to match the target’s encoding exactly. Thus, the
resulted from the nature of information states induced by the              model was not guaranteed to predict elements of the appro-
input stream: variability in the fillers exerted two opposing              priate class (A, X or B) in each position. It had to learn word
forces which conspired to produce the U-shaped pattern in a                classes and positional information from the input.
single-route mechanism. The model allowed us to make pre-                     A sequence of inputs to an LSM induces a diverse range of
cise, quantitative predictions when the number of frames and               nonlinear dynamics in the liquid. In order to compute with
the dependency distance were increased. We conclude with a                 an LSM, a set of linear output units is calibrated to map the
discussion of our approach.                                                internal dynamics to a stable, desired output. Calibration (or
                                                                           training) can be achieved by adjusting wout , the weights from
                  The liquid-state framework                               the input and liquid to the output layer, using multiple linear
                                                                           regression
Liquid-state machines (LSM for short) are recurrent neural
networks which are modelled on the information process-                                          wout = (St S)−1 St T                  (2)
ing characteristics of the cerebellum (Maass et al., 2002).                where S is the collection of internal states during the pre-
Their defining characteristic is a sparsely and randomly con-              sentation of an input sequence (and St its transpose), and T
nected reservoir of neuron-like units (liquid) which turns a               is the matrix of targets that the model is intended to pro-
time-varying input signal into a spatio-temporal pattern of                duce. In other words, to train an LSM an input sequence is
activations (Figure 3). Recurrence in the liquid equips the                passed through the liquid once and subsequently the read-out
                                                                           weights are adapted such that the sum of squared residuals is
                                                                           minimized at the output layer. All other weights in the model,
         Input                                       Output
                                                                           most importantly the liquid itself, remain unchanged. Regres-
                                                                           sion training boils down to matrix inversion which is cheap
                                                                           to compute. To avoid singularity a small amount of Gaussian
                                                                           noise (µ = 0, σ2 = 0.001) was added to each bit of an input
                                                                           pattern. This proved sufficient to ensure that the inverse (of
                                                                           St S) always existed.
                 Liquid                                                       LSMs have previously been used in natural language pro-
                                                                           cessing tasks, e.g., in speech recognition (Triefenbach et
                                                                           al., 2011), grammar learning (Tong et al., 2007; Frank &
                                                                           Čerňanský, 2008) and reading time prediction (Frank & Bod,
                                                                           2011). We present the first application of these models that
Figure 3: Schematic representation of a liquid-state machine.              aims at explaining a particular psycholinguistic phenomenon.
                                                                     898

                                                   Learning and generalization                           familiar frames with novel X elements (e.g., A2 X31 B2 ). On
The model was trained on artificial languages similar to those                                           this task, the model again closely matched human behavior
used in the AGL studies—three frames A..B interspersed with                                              for zero and high variability, although it did not generalize
X elements drawn from sets of various sizes (1, 2, 6, 12 and
24). For each level of variability, all grammatical strings were
                                                                                                                                                  100
generated, they were concatenated in randomized order, and
                                                                                                           Constituents correctly predicted (%)
these blocks were repeatedly presented to the model for a to-                                                                                     80
                                                                                                                                                                                                ●
                                                                                                                                                        ●
tal of 432 strings. To mimic the 750ms pause between items
in the human experiments, each string AXB was followed by                                                                                         60
an end-of-sentence marker P. As in the AGL studies, the
                                                                                                                                                  40
model received the training set as one continuous input stream                                                                                                                          Human
                                                                                                                                                                                    ●   Model
without being reset between items. The test procedure dif-                                                                                        20
                                                                                                                                                            ●
fered from the human task of judging the grammaticality of
strings. The model rather had to predict the next element in a                                                                                      0
test sequence, and was evaluated on how well it predicted the                                                                                           1   2        6         12               24
dependent elements (Bs). The test set consisted of all string                                                                                                    Variability
types that the model had encountered in training. Individual
differences in human subjects were simulated by randomiz-                                                Figure 5: U-shaped performance for strings with novel fillers
ing the distributed input representations between model runs.                                            X (human data not available for variability 6 and 12).
This also minimized the risk of observing behavior that was
an artefact of a particular encoding. Results were averaged                                              nearly as well as humans for medium variability (Figure 5).
over 12 model subjects as in the AGL experiments.                                                        In both test conditions—trained and novel fillers—the model
   After training, the model was ‘well-behaved’ in that it had                                           amplified human differences between variabilities but showed
learned the transitional probabilities for both A and X ele-                                             considerable qualitative similarities with the data.
ments in each variability condition. This indicates that the
                                                                                                         Robustness
training procedure was adequate to track adjacency informa-
tion in the input. Predicting the B elements in trained items,                                           Neural network models are often sensitive to small changes in
the model displayed a U-shaped curve which was qualita-                                                  parameters, initialization, and training conditions. We found
tively similar to human subjects (Figure 4), although perfor-                                            that the LSM was very consistent in its behavior. Changes in
mance was substantially better in high variability conditions                                            the language encoding, liquid size, percentage connectivity,
(12 and 24) and worse for variability 6. Overall, though, the                                            spectral radius, and amount of noise did not essentially alter
                                                                                                         the model’s U-shaped behavior, although, of course, perfor-
                                                                                                         mance was closer to the human data in some settings than
                                         100                                                  ●
                                               ●                             ●
                                                                                                         in others. In similar vein, varying the total number of cy-
  Constituents correctly predicted (%)
                                         80
                                                                                                         cles through randomized blocks of stimuli or the time-scale
                                                         ●                                               of updating the liquid did not lead to a qualitative change in
                                         60                                                              behavior. It was almost impossible to erase the characteris-
                                                                                                         tic differences except when the liquid was so small that the
                                         40
                                                                   ●
                                                                                      Human
                                                                                                         model did not learn dependencies above 10% in any condi-
                                                                                  ●   Model
                                         20
                                                                                                         tion. This suggests that the LSM had a strong architectural
                                                                                                         propensity to differentially respond to relevant information
                                           0                                                             depending on the amount of variation in the input.
                                               1         2         6         12               24
                                                               Variability
                                                                                                                                                            Model analysis
                                                                                                         The critical information that was used to train the LSM was
Figure 4: The model showed U-shaped performance similar                                                  contained in the states of the liquid while the input sequence
to humans when tested on trained strings AXB.                                                            was passed through it. If inputs were sufficiently similar they
                                                                                                         caused the liquid to assume similar states and eventually got
model matched the human data on how dependency learning                                                  mapped to the same output; if inputs were sufficiently dis-
is influenced by filler variability quite well.                                                          similar the liquid separated them at the output. To analyze
   Onnis et al. (2004) investigated whether there was also a                                             the model’s behavior, internal states were recorded during
variability effect when subjects had to generalize to novel                                              the input phase, a principal components analysis was con-
items. Tested strings now contained fillers X that did not oc-                                           ducted, and the liquid was visualized by projection into a
cur in training. The model’s ability to generalize was mea-                                              two-dimensional principal subspace. After presentation of an
sured in a similar way, by testing on 6 strings composed of                                              X element, the liquid entered a state from which a dependent
                                                                                                   899

 element had to be predicted (B-state for short). For zero vari-                                 three predictions that were then tested experimentally. For
 ability, variation in B-states derived entirely from distinct A                                 zero variability, prediction accuracy should drop when there
 elements whereas in the other conditions also differences in                                    is only one cycle through the training set. Now there is only
 X elements added variation. As variability increased from 1                                     a single data point in the circular region of Figure 6 (left) to
 to 24, the regions from which identical B elements had to be                                    which the model is adapted in training, and B-states induced
 predicted increased in size because distinct X elements sent                                    in testing are not entirely congruent. High variability condi-
 the liquid into distinct states. This steady increase in state dis-                             tions, on the other hand, should be less affected by the num-
 persion was measured as the average Euclidean distance of a                                     ber of cycles. This was confirmed in that accuracy in the zero
 B-state region from its centroid. At the same time, increasing                                  variability condition dropped to 0% and remained above 90%
 variation in X elements provided more and more distinct data                                    for variability 24. Secondly, imposing a large amount of noise
 points in each such region. Thus, variability had two oppo-                                     on the liquid’s internal states should increase the area of B-
 site effects on the information states that the model used to                                   state regions in training and thus make the model more fault-
 predict B elements. B-state regions that mapped to identical                                    tolerant. In conditions of medium variability, this should im-
 dependencies grew larger and simultaneously became filled                                       prove prediction success, and indeed the model reached al-
 more densely with relevant training data (see Figure 6). When                                   most 100% accuracy on trained items for variability 6. And
 combined, these two forces—dispersion and density—could                                         third, the model should also achieve very high accuracy when
 explain U-shaped performance.                                                                   variability is increased to 48 because the critical B-state re-
    Since trained B-states resulted from a continuous stream of                                  gion should become even more densely filled with training
 input sentences, and tested B-states from presenting a single                                   data than for variability 24. This prediction was confirmed as
 test sentence, the former always deviated slightly from the lat-                                well, the model reached above 90% accuracy on both trained
 ter. In testing, the model could correctly predict a dependent                                  and novel items when variability was increased to 48.
 element if the corresponding B-state was sufficiently close to                                     Apart from these factors, the choice of learning algorithm
 a B-state that the model had assumed in training. For zero                                      can have a strong influence on neural network behavior. Thus,
                                                                                                 it is possible that the reported results were mainly due to
Second principal component
                             zero           medium                      high                     regression training. To determine the role that the training
                                    +                    +                         +             regime played in creating the observed behavior, we com-
                                        +      +
                                                                           +                     pared the LSM with a feed-forward network. This network
                                                                                       +
                                                   +                                             had the liquid replaced by a non-recurrent hidden layer but
                                                                +                      +
                                training
                                                                                                 was identical otherwise. Without recurrence, the model did
                              + testing                   +                    +                 not implement a working memory and hence could not pre-
                                                                                                 dict dependent elements above chance. Nonetheless, if re-
                                            First principal component                            gression training played a crucial role we would also expect
                                                                                                 to witness similar U-shaped accuracy in the feed-forward net-
 Figure 6: B-states in training (dots) and testing (crosses) for                                 work (relative to chance level performance which was iden-
 three levels of variability; simplified depiction.                                              tical in all conditions). We found that this was not the case;
                                                                                                 model performance peaked for variability 6, and was lowest
 variability, B-states clustered in a small region of state space                                for variability 24. For novel items, there was a steady decline
 that contained many data points because there were 144 cy-                                      in accuracy from zero to high variability. This control experi-
 cles through the training set in this condition (Figure 6, left).                               ment suggests that the effect of differences in filler variability
 B-states in testing mostly fell into this region (and the model                                 on dependency learning was caused by the properties of the
 made a correct prediction) due to the lack of variation in the                                  liquid and not by the training algorithm that was used.
 X element. For high variability, B-states spanned a larger re-
 gion of state space, with distinct data points deriving from all                                                    Novel predictions
 trained items with a different X element. As a consequence,                                     Frames in natural language can be more diverse than in the
 the training algorithm adapted the entire region of state space                                 AGL experiments, and dependencies can be separated by
 to map onto the same B element (Figure 6, right). This made                                     more than one word. We therefore tested the model in condi-
 the model highly robust for variability 24, especially in the                                   tions of increased frame variability and dependency distance.
 generalization task with novel X elements. When variabil-
 ity was medium (Figure 6, center), states that mapped to the                                    Increased frame variability
 same B were scattered in isolated clusters across state space                                   According to the standard explanation of the variability ef-
 (one for each distinct X element) and these clusters each con-                                  fect, learners seek to identify invariance in the input (Onnis
 tained less data points than in the zero variability condition.                                 et al., 2003, 2004). When variability in X is high, the frames
 When B-states in testing fell outside these regions, the model                                  A..B stand out as invariant against the X elements. When vari-
 could not interpolate the dependent element as in the high                                      ability in X is zero, the focus shifts on the variation in frame
 variability condition, and hence accuracy was lower.                                            dependencies. In conditions of medium variability, the num-
    To verify that this was the correct analysis, we derived                                     ber of frames and fillers is similar, which makes it difficult
                                                                                           900

for the learner to detect dependencies and this results in lower
performance. To assess this account in the model, the number                                                                              100   ●
                                                                                                                                                ●
                                                                                                                                                                                  ●
                                                                                                                                                                                  ●
                                                                                                                                                                                                  ●
                                                                                                                                                                                                  ●
                                                                                                   Constituents correctly predicted (%)
                                                                                                                                                               ●
of A..B frames in the language was doubled. If the invariance
                                                                                                                                          80
account is correct, we should observe improved performance                                                                                            ●
for variabilities 1 and 2 because the frame-to-filler ratio in-                                                                           60         ●
creases. For variability 6, we should observe a drop in perfor-
mance because having the same number of different frames                                                                                  40
                                                                                                                                                                ●
                                                                                                                                                                         ●   Trained, normal distance
                                                                                                                                                                         ●   Trained, double distance
and fillers in the input should mask frame invariance. For                                                                                                                   Novel, double distance
                                                                                                                                          20
high variability 12 and 24, we should also observe a drop in
performance because the difference in the number of frames                                                                                  0
and fillers is less distinct. Figure 7 shows the model’s learn-
                                                                                                                                                1    2         6                 12               24
ing behavior for six frames compared to the results of Fig-                                                                                                Variability
ure 4 for three frames. For high variability (12 and 24) there
                                                                                                Figure 8: Learning and generalization for increased depen-
                                                                                                dency distance.
                                         100   ●                     ●
                                                                                     ●
  Constituents correctly predicted (%)
                                         80
                                                   ●
                                                                                                frames or fillers in the input language. This variation helped
                                         60
                                                                                                the model to better predict dependencies for variability 6 in a
                                                                                                way similar to the effect of adding noise to the liquid in the
                                         40
                                                           ●
                                                                                                control condition described in the analysis section.
                                                                          ●   3 Frames
                                                                              6 Frames
                                         20                                                                                                         General discussion
                                           0
                                                                                                Several recent AGL studies have shown that the learning
                                                                                                of nonadjacent dependencies is modulated by the amount
                                               1   2       6         12              24
                                                       Variability
                                                                                                of variation in the filler elements (Gómez, 2002; Gómez &
                                                                                                Maye, 2005; Onnis et al., 2003, 2004). The U-shaped pattern
Figure 7: Performance increased for medium variability when                                     found in these studies can not easily be explained by recourse
the number of frames was doubled.                                                               to distributional properties of the language input and is diffi-
                                                                                                cult to reconcile with many findings indicating that the human
was no performance difference and for medium variability (6)                                    language system is remarkably sensitive to transitional prob-
performance improved considerably. In the zero and low vari-                                    abilities (e.g., Saffran et al., 1996). In particular, these results
ability conditions (1 and 2), the model performed worse than                                    pose a challenge for statistical models of language learning
before. Thus, the U-shaped pattern persisted when depen-                                        that exploit adjacency and frequency information.
dencies in the language were more complex and the results                                          To account for this data we used a liquid-state model which
suggest that the behavior of the LSM was not in accordance                                      is a sparsely connected, recurrent network that computes over
with the predictions of the invariance account.                                                 transient states. LSMs implement a working memory to de-
                                                                                                tect temporal contingencies and can be trained efficiently by
Increased dependency distance                                                                   linear regression. This allowed us to study the model’s behav-
In a third experiment, the model was used to investigate per-                                   ior after exposure to the same small number of training items
formance for increased distance between nonadjacent ele-                                        as in the AGL studies. The LSM was trained off-line after
ments. The input language consisted of ‘sentences’ AXY B,                                       the entire input sequence had been presented. This procedure
where the filler chunks XY were again drawn from sets of                                        may not be not faithful to the human experiments where im-
cardinalities 1, 2, 6, 12 or 24. The invariance account does                                    plicit expectations about upcoming words might be formed
not make predictions for increased distance since it does not                                   during the input phase already. However, it was shown that
specify the role of working memory in learning nonlocal de-                                     the training regime was not critically responsible for the ob-
pendencies. In the model, U-shaped behavior persisted for                                       served U-shaped behavior. It remains to be tested whether the
trained items, and to some extent also for novel filler chunks                                  model displays similar behavior when the read-out weights
(Figure 8). Compared to Figure 5, however, increasing the                                       are adjusted incrementally (e.g., using perceptron learning).
distance led to a breakdown in generalization. A novel com-                                        The liquid-state approach provides a generic neuro-com-
bination of two fillers caused the model to enter regions of                                    putational framework for sequential processing and cognitive
state space that could not reliably be mapped to dependent                                      modelling more broadly. The liquid is general purpose and
targets by the read-out units. As in the previous experiment                                    can be used to model an indefinite number of cognitive tasks
of increased frame variation, the most pronounced difference                                    (even in parallel). Connectivity in the liquid is not altered
occurred for variability 6. In both these experiments, there                                    during learning and hence these models make very modest as-
was more variation in B-states resulting from either more                                       sumptions about the nature of mental representations. Inputs
                                                                                          901

which are sufficiently distinct are separated by the liquid, in-       therefore intend to assess this similarity-based, liquid-state
puts which are sufficiently similar are mapped to similar out-         model account in AGL behavioral experiments.
put. In such a system, differential behavior results from the
input stream filtered through the architecture of the model,                                Acknowledgments
rather than the observable symbolic properties of the input            Thanks to Stefan Frank and Morten Christiansen for helpful
itself. That is to say, variability in the input generates statis-     comments and discussion.
tically relevant information in the liquid—such as the density
and dispersion of information states—that is not measurable                                     References
in the input stream in terms of transitional probabilities, N-         Elman, J. (1990). Finding structure in time. Cognitive Sci-
gram frequency or the type-token ratio. The explanation we               ence, 14, 179–211.
propose for the variability effect is based on these properties        Frank, S., & Bod, R. (2011). Insensitivity of the human
of information states. It is a hallmark of neural network mod-           sentence-processing system to hierarchical structure. Psy-
els that they represent inputs as a graded pattern of activation         chological Science. (In press)
distributed over a set of units. In the LSM, differences and           Frank, S., & Čerňanský, M. (2008). Generalization and sys-
similarities between such patterns were picked up by the re-             tematicity in echo state networks. In Proceedings of the
gression used to calibrate the read-out weights. This enabled            30th Annual Conference of the Cognitive Science Society
the model to categorize novel stimuli based on their repre-              (pp. 733–738). Austin, TX: Cognitive Science Society.
sentational similarity with trained items. When variability in         Gómez, R. (2002). Variability and detection of invariant
fillers was zero, representations of test stimuli were highly            structure. Psychological Science, 13, 601–617.
similar to those of trained items because they fell into a small       Gómez, R., & Maye, J. (2005). The developmental trajectory
region of state space that was densely populated by train-               of nonadjacent dependency learning. Infancy, 7, 183–206.
ing data. When variability was high, a large region of state           Jaeger, H. (2001). The “echo state” approach to analys-
space was adapted to map to the same dependency in training              ing and training recurrent neural networks (Tech. Rep.
which again caused high similarity between trained and tested            No. 148). German National Research Center for Informa-
items. For medium variability, similarity was lower because              tion Technology.
the state space got partitioned into smaller, separate regions.        Leibbrandt, R., & Powers, D. (2010). Frequent frames as
When representations of test items fell outside these regions            cues to part-of-speech in Dutch: Why filler frequency mat-
the model produced errors in predicting dependencies.                    ters. In Proceedings of the 32nd Annual Conference of the
                                                                         Cognitive Science Society (pp. 2680–2686). Austin, TX:
    This similarity-based account differs from the invariance
                                                                         Cognitive Science Society.
account proposed in Onnis et al. (2003). Whereas the latter
                                                                       Maass, W., Natschläger, T., & Markram, H. (2002). Real-
argues that differential learning can be explained by a mecha-
                                                                         time computing without stable states: A new framework for
nism of attentional shift that seeks to find stable patterns in a
                                                                         neural computation based on perturbations. Neural Com-
noisy stream, the account proposed here is based on similari-
                                                                         putation, 14, 2531–2560.
ties between information states in the learner’s working mem-
                                                                       Mintz, T. (2003). Frequent frames as a cue for grammatical
ory which are induced by training and test stimuli. The model
                                                                         categories in child directed speech. Cognition, 90, 91–117.
suggests that this might be an alternative, more parsimonious
                                                                       Onnis, L., Christiansen, M., Chater, N., & Gómez, R. (2003).
explanation of the variability effect. Both accounts, however,
                                                                         Reduction of uncertainty in human sequential learning: Ev-
are not mutually exclusive although some of the model pre-
                                                                         idence from artificial grammar learning. In Proceedings of
dictions were not in line with the invariance account. At-
                                                                         the 25th Annual Conference of the Cognitive Science Soci-
tention as well as representations in working memory might
                                                                         ety (pp. 887–891). Mahwah, NJ: Lawrence Erlbaum.
play a role in learning nonadjacent dependencies, especially
                                                                       Onnis, L., Monaghan, P., Christiansen, M., & Chater, N.
in the implicit learning paradigm in which all of the data on
                                                                         (2004). Variability is the spice of learning, and a crucial
the variability effect have been gathered.
                                                                         ingredient for detecting and generalising nonadjacent de-
    We also used the LSM to obtain novel predictions for con-            pendencies. In Proceedings of the 26th Annual Conference
ditions in which there were more frames in the language                  of the Cognitive Science Society. Mahwah, NJ: Lawrence
(six instead of three) and a larger distance between depen-              Erlbaum.
dencies (two fillers instead of one). It was found that the            Saffran, J., Aslin, R., & Newport, E. (1996). Statistical learn-
model displayed a similar U-shaped pattern, but shifted to-              ing by 8-month-old infants. Science, 274, 1926–1928.
wards lower variabilities. The most pronounced difference              Tong, M., Bickett, A., Christiansen, E., & Cottrell, G. (2007).
occurred for medium variability where the model’s perfor-                Learning grammatical structure with echo state networks.
mance improved significantly compared to the standard con-               Neural Networks, 20, 424–432.
dition (three frames, one filler). These precise, quantitative         Triefenbach, F., Jalalvand, A., Schrauwen, B., & Martens,
predictions suggest a straightforward test of whether process-           J.-P. (2011). Phoneme recognition with large hierarchi-
ing in the model adequately captures the implicit learning               cal reservoirs. In Neural Information Processing Systems
of nonadjacent dependencies in humans. In future work we                 (NIPS 2010). (In press)
                                                                   902

