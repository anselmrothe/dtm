UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Why Neurons Cannot be Detectors: Shifting Paradigms from Sherlock Holmes to Elvis
Presley?
Permalink
https://escholarship.org/uc/item/5dr367b8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Salay, Nancy
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

   Why Neurons Cannot be Detectors: Shifting Paradigms from Sherlock Holmes to
                                                             Elvis Presley?
                                                  Nancy A. Salay (salay@queensu.ca)
                                     Department of Philosophy/School of Computing, Watson Hall 310
                                                     Kingston, ON, K7L 3N6 CANADA
                                Abstract                                 community. I present here just two examples of this
                                                                         practice in order to focus this discussion1:
   The practice of treating neurons as detectors is ubiquitous in
   the neuro-science community and in AI as well, in the context                  1. ―… the key claim of localist coding schemes is
   of neural networks. But there are a growing number of                      that a given unit (neuron) codes for one familiar thing
   cognitive scientists who think that the representational                   (and does not directly contribute to the representation
   paradigm is ill-suited to this level of explanation. In this               of anything else), and that it is possible to interpret the
   paper, I rehearse William Ramsey‘s powerful critique of                    output of a single unit in a neural network.‖ (Bowers,
   neural-detector attribution, focusing on his argument that                 2009, p. 223)
   Dretske-style information theoretic accounts of representation
   fail to justify the practice. I then take this conclusion a step
                                                                                  2. ―These investigators report the discovery of
   further by arguing that not only does this particular                      number-encoding neurons in the lateral prefrontal
   justification fail, none at all are possible. The conclusion that          cortex of the macaque brain. ... this work opens up the
   we need to let go of the representational paradigm is not a                exciting possibility of studying the cerebral bases of
   negative one though, I shall claim, because it liberates us                elementary arithmetic at the single-cell level.‖
   from the kind of misguided thinking that leads to theoretical              (Dehaene, 2002, p. 1652)
   dead-ends. Once we see this, we are free to investigate new,          Unfortunately, because the practice is so ubiquitous and
   more fruitful, paradigms.
                                                                         unchallenged in the field of neuroscience, there aren‘t many
   Keywords: representation; neurons; detectors; information             actual justifications to assess. As Ramsey points out,
   theory; Dretske; interaction theory.                                           ... researchers often skip the question of whether
                                                                              neural receptors function as representations and
                           Introduction                                       instead ask about how the representational encoding is
The practice of treating neurons as detectors is ubiquitous in                done. That is, researchers often begin with the
the neuro-science community and in AI as well, in the                         assumption that neurons function as representations,
context of neural networks. But there are a growing number                    and then explore, for example, whether the encoding is
of cognitive scientists who think that the representational                   in single cell ‗grandmother‘ representations or instead
paradigm is ill-suited to this level of explanation. With this                distributed across a population of neurons. (2003, p.
paper, I will add my voice to these ranks. In section one, I                  127)
will rehearse William Ramsey‘s powerful critique of neural-              I won‘t rehearse here Ramsey‘s speculations for why there
detector attribution, focusing on his argument that Dretske-             has been so little written about this central topic, although
style information theoretic accounts of representation fail to           his diagnosis is spot on; instead, I will skip to his decision to
justify the practice. In section two, I take this conclusion a           focus the critique on Fred Dretske‘s information theoretic
step further by arguing that not only does this particular               account of representation, since, he concludes, this is the
justification fail, none at all are possible. The conclusion             most robust, well-defended account that comes the closest to
that we need to let go of the representational paradigm is not           offering an explicit justification for the practice:
a negative one though, I shall claim, because it liberates us                     ... his theory seems clearly motivated by examples
from the kind of misguided thinking that leads to theoretical                 of the very notion of representation we are trying to
dead-ends. Once we see this, we are free to investigate new,                  explicate, and many have appealed to Dretske as a
more fruitful, paradigms. In the final section, I briefly                     way of defending receptor-style representations. What
discuss one of the more promising ones.                                       is more, because Dretske‘s account of content is so
                                                                              closely intertwined with an account of what it is for
               Section I: Ramsey’s Critique                                   something to function as a representation, we see that
By explicitly addressing the question of what justifies                       he is, indeed, worried about providing a solution to
neural-level detector attributions, Ramsey brings to the fore                 what I have been calling the functional specification
a discussion sorely lacking in the cognitive science                          challenge. Thus, if anybody has given a carefully
                                                                              worked-out philosophical explication and defence of
                                                                              the receptor notion ... it is Dretske. (ibid., p. 131)
                                                                         1
                                                                           I do not intend to single these out as particularly egregious cases
                                                                         or so on in any way – there are literally hundreds of others I could
                                                                         have chosen, but a choice had to be made.
                                                                     2217

         On Dretske‘s account, what makes some internal             Again, the idea is that it is in virtue of the information
    state X a primitive representation or detector of some          carried by the causal co-relation between magnetesomes and
    class of things or actions Y is that it meets the               anaerobic water that, through natural selection,
    following three conditions:                                     magnetesomes developed the functional role they did,
         1. The presence/absence of X covaries with the             within the context of anaerobic bacteria. This, according to
    presence/absence of members of Y;                               Dretske, is what justifies our treatment of them as anaerobic
         2. The co-variance is under-written by a nomic             water detectors.
    causal relation, that is, the presence/absence of                  But, Ramsey argues, this is much too quick. How do we
    members of Y cause or are a necessary part of the               know that it is in virtue of the information the causal
    cause of the presence/absence of X; and,                        relations carry that they were selected for? In order to get to
         3. The functional role of X, within the system             that conclusion, Ramsey argues, we need a much more
    within which it arises, is to carry information about the       ontologically-loaded notion of information than is
    presence/absence of members of Y. (Dretske, 1988)               warranted, one in which information itself can play a causal
Condition 3 ultimately does the work of justifying our              role: ―… many writers—including Dretske—appear to reify
treatment of X as a representation, since lots of states meet       information with expressions like ‗information flow‘ and
both conditions 1 and 2 alone, but do not function to carry         ‗information carrying‘ ….‖(2003, p. 135) But we have no
information about and, consequently, represent anything.            independent justification for treating information in this
For example, the presence of large electrical fields is             way. From an ontologically Spartan vantage point,
causally necessary for the presence of lightning, but               information is just what can be learned about the causal
lightning does not represent electrical fields. Now the trick,      history of some object or system: ―Talk about information
of course, to developing a fully naturalistic account of            carrying can be understood as simply a way of saying that
representation, is to explain how condition 3 can come              nomic relations between states of affairs allows us to use
about without appealing to the existence of some intentional        these states of affairs to discover things.‖ (Ramsey, 2003, p.
system in which X functions to carry information. Dretske           135) Indeed, as Ramsey points out, these states of affairs
follows teleological-functionalists such as Millikan in             need not even be directly causally related to one another in
arguing that such functional roles are established as a result      order for there to exist an information relation between
of natural selection or, in some contexts, in the course of the     them. If A is larger than B, and B is larger than C, then A
development of learning mechanisms. Here is an excerpt              ‗carries‘ information about C, since knowing something
from Dretske on how he sees such functional information-            about A, say that it has length X, allows one to deduce
carrying roles being established:                                   something about C, say that it has length < X. In other
    Suppose an animal – call it Buster – is so wired that it        words, ―being an information carrier is nothing more than
    can see nearby Os.... Because Os are dangerous to               being a thing that stands in some sort of relation to
    animals like Buster, it quickly learns to avoid them.           something else, such that the former can be exploited to gain
    Learning to avoid Os is a process in which an internal          knowledge about the latter.‖ (2003, p. 135) In this unreified
    sign of O, an internal signal carrying the information          sense, information abounds.
    that an O is present, is made into a cause (a triggering           But although information abounds, it doesn‘t follow that
    cause) of whatever movements constitute avoidance.              all or indeed any of this information is in fact used. Two
    ... As a result of the learning of the sort just described,     things might be causally related, let‘s say the presence of A
    Buster‘s internal circuitry has been reconfigured so as         causes some process to occur in B, but the fact that B‘s
    to give an information-bearing element a control                activity carries information about the presence of A may
    function.‖ (1994, p. 69)                                        play no role at all in this causal transaction, not even in an
According to Dretske, it is in virtue of the information            account of the evolutionary history of the development of
carried by the causal co-relation between the presence of Os        this causal relationship. For example, if I squirt a drop of
and the internal O signal that the internal O signal gets its       water onto a small sample of salt, the salt will begin to
role. Here is another of Dretske‘s examples, one that               dissolve. The salt‘s activity, the dissolving, is an indication
Ramsey highlights, of the same sort of process, but one that        that a liquid is present, that is, I could discover from its
develops as a result of evolutionary pressures:                     present state that a liquid is present and I could also
    … the magnetesomes in anaerobic bacteria indicate               discover, with the right equipment, exactly when in the
    the direction of magnetic North, which also happens to          history of this sample the liquid was introduced; but, of
    correlate with deeper, anaerobic water. Through a               course, the dissolving will continue on whether or not I
    process of natural selection, these magnetesomes come           actually attempt to deduce this information.
    to be wired to the bacteria‘s navigational system                  Likewise, Ramsey points out, in the examples Dretske
    because of their nomic link to anaerobic water. They            uses to support his case, in none of them is it clear that it is
    are thus given the functional role of indicating the            in virtue of the information that the underlying physical
    direction of anaerobic water and, according to Dretske,         causal relations carry that it is selected for:
    thereby become anaerobic water representations.                     For instance, the iron deposits that serve as
    (Ramsey, 2003, p. 132)                                              magnetesomes in anaerobic bacteria are wired to the
                                                                2218

     bacteria‘s propulsion devices because of the way they                detectors – is just to confuse levels of explanation. In order
     reliably respond to anaerobic conditions. We need                    to perform this kind of reduction, we need a theory that
     some further reason, however, for thinking they are                  allows us to bridge between the levels. This theory will
     recruited into service because of the information that               explain how the more abstract, higher-level concept of
     results from this relation. There is really no sense in              representation is instantiated at the neural level.
     which the bacteria‘s flagellum (their propellers)                       Of course, finding strong co-relations between neural
     exploit the informational content carried by the                     activity and states of affairs in the world in conjunction with
     magnetesomes: no sense in which they use the                         a solid information theoretic account of representation is
     magnetosomes to discover something about anaerobic                   supposed to play exactly this bridging role. Indeed, it‘s
     conditions. It is one thing to serve as a causal mediator            because of a sensitivity to this abstractness of the concept of
     between A (anaerobic conditions) and B (directional                  representation that researchers are typically careful to call
     propulsion), it is an entirely different thing to serve as           neurons detectors, primitive representations, rather than full-
     an informer about A for B. (2003, p. 137)                            blown ones. But, as we saw in the previous section,
   Ultimately, Dretske‘s account fails, then, because of the              Ramsey‘s arguments undermine the justificatory support
untenable, but critical for his view, distinction between the             that information theoretic accounts give to treating neurons
physical and informational features of causal relations; to               as detectors. Consequently, there is reason to be suspicious
get the teleological story off the ground, the informational              of the current scaffolding holding together the neural-
relations need to play a causal role in the account. At the               representational hierarchy. My aim here is not to critique
least, this assumption is as non-naturalistic as the very                 this Marr-inspired levels approach to cognitive inquiry,
notion of intentionality it was invoked to demystify. At the              (although I do think it biases us towards a particular view of
worst, it is an ontological load too heavy to bear. Without               what could count as a cognitive process); rather, I want to
it, however, the support for condition 3 is removed and,                  accept this way of dividing the theoretical labour and argue
unless condition 3 is met, we aren‘t justified in treating                that a further explanatory distinction we ought to make
causal relations as representation relations. We‘re back at               serves to limit the kinds of concepts we can use to theorise
square one.                                                               at the various levels. As a consequence, we will see that
                                                                          concepts such as detector can never be applied at the
  Section II: No Justifications are Forthcoming.                          implementation level, no matter how much bridging we do.
In this section, I want to argue for the following stronger                  To begin the deconstruction, we need to introduce a new
claim: not only do Dretske-style accounts fail to justify the             kind of distinction, one that tracks the degree of context a
practice of neural-detector attribution, but no such                      given concept includes. Being a distinction of degree, we
justification is in the cards at all.                                     shouldn‘t expect too many instances at either end of the
   Now I‘m certainly not making a novel claim when I say                  continuum; most concepts will fall somewhere along the
that, conceptually-speaking, representation and neuron are                middle, perhaps closer to one side or the other, of what I‘ll
concepts appropriate to different levels of explanation:                  be calling the individual/collective continuum to indicate
within the cognitive science community, David Marr‘s tri-                 concepts that pick out kinds in virtue of their context-free
level hypothesis2 has been widely accepted and used to                    features, on the one hand, and concepts that pick out kinds
justify division of labour3. In the context of this sort of level         in virtue of their context-dependent features on the other.
distinction, we could say that using the concept of a                     What it is to be an instance of a strongly individual concept
representation, which is a concept proper to either the                   will depend mostly upon the local, non-relational, properties
computational or the algorithmic level of explanation, in                 its instances have. The concept hydrogen, for example, is
order to pick out kinds at the implementation level – this is             highly individual, in this sense, because to be an instance of
what we are doing after all when we treat neurons as                      it is to meet a set of conditions that can be specified in a
                                                                          generally context-free way, e.g. being an atom with one
2                                                                         proton in its nucleus. What it is to be an instance of a
   Marr (1982) describes a framework for the theoretical task of
explaining visual processing, which we can extend to cognition in         strongly collective concept, on the other hand, will depend
general, in which the following three levels of explanation are           mostly upon the system-level, relational, properties its
distinguished:       at the highest level of abstraction, the             instances have. For example, the concept worker ant lies
computational level, we describe the general function of the system       closer to the collective side of the continuum since, while
under investigation; at a middle level, the algorithmic level, we         there are certainly some individual features that worker ants
describe the processes or mechanisms that make this activity              exhibit, e.g. being female, having a certain body size, and so
possible; and, at the lowest level, the level of implementation, we       on, it is not possible for an ant to be a worker ant unless
describe how the ‗hardware‘ performs these actions.                       there is an ant colony within which it can function in that
3
  Griffiths et al., (2010) for example, are quite explicit that their
                                                                          way; a lone ant, outside of its colony context, is no longer a
theories apply to the function level of explanation only: ― ...
probabilistic models of cognition pursue a top-down or ‗function-         worker ant, since part of what it is to be a worker ant is to
first‘ strategy, beginning with abstract principles that allow agents     play a certain role within a larger system. Thus, certain
to solve problems posed by the world – the functions that minds           concepts can be applied to individuals without appeal to the
perform – and then attempting to reduce these principles to               broader system within which those individuals are found,
psychological and neural processes.‖ (Griffiths et. al, 2010, p. 357)
                                                                      2219

while others cannot be so applied — they necessarily                       which encodes a full-scale model of our surroundings
involve some relational attributes.                                        is misguided. Animate vision, Ballard argues, neither
   Now, the concept of being a detector is clearly a                       needs nor can afford to create and sustain such a
collective concept. To see this, consider the following                    model.      Instead, we constantly saccade around,
example. We might want to call a magnetised metal rod a                    picking up only such fragments of information as we
metal detector in virtue of the causal relations that exist                need to support specific actions, and re-visiting the
between it and instances of metal – metallic objects within a              scene again and again rather than relying on some
certain distance will, quite literally, be drawn towards the               internally represented surrogate. (ibid., p. 8-9)
rod. But, as we saw in the previous section, such a rod is no             Clark‘s context-based distinction between explanations
more a metal detector than the magnetesomes in anaerobic               complements the dichotomy between individual and
bacteria are anaerobic water detectors. A magnetised metal             collective concepts I have been developing: individual-level
rod can only have the functional role to detect metals within          concepts are best explicated with homuncular explanations,
a context within which it is used in this capacity. This is            while more collective concepts can only be fully
because to be a detector is to play a particular role in a             characterised with interactive explanations, since only the
system, namely, to carry information about the                         latter will draw the relevant aspects of context into the
presence/absence of members of a certain class. To notice              description.
this is just to acknowledge that there are certain features of            An example will help make clear how I see the
the concept of being a detector that cannot be explicated by           homuncular/interactive and the individual/collective divides
appeal to the purely individual features of an object acting           working together in explanations. Take the concept of an
in this capacity, since it‘s the playing of a certain role, and        automobile. As with many concepts, there are both
this is a relational attribute, that is essential to being an          individual and collective aspects to it. From Wikipedia, for
instance of the concept.                                               example, we get this definition:
   A final distinction will help tie this discussion back to               An automobile, motor car, or car is a wheeled motor
levels of explanation. Andy Clark (1996)4 convincingly                     vehicle used for transporting passengers, which also
argues that, in cognitive science, we ought to be                          carries its own engine or motor. Most definitions of
distinguishing between three different classes of                          the term specify that automobiles are designed to run
explanations, where each is differentiated according to how                primarily on roads, to have seating for one to eight
much context is included in it. For the sake of symmetry                   people, to typically have four wheels, and to be
and because I don‘t want to get side-tracked here by                       constructed principally for the transport of people
controversies over emergence, I will ignore Clark‘s third                  rather than goods. (http://www.wikipedia.org/)
category of emergent explanation and focus only on the first              If we focus on defining an automobile in terms of its role
two: homuncular and interactive explanations.                          of transporting passengers, for example, then we will also
   We provide an homuncular explanation when we theorise               need to explain the contexts within which there are
about an individual by ―adverting to the capacities and roles          passengers waiting to be transported; there can be no
of its components, and the way they interrelate.‖ (ibid. p. 5)         transporting role in the absence of passengers 5. This kind of
For example, when we describe how a machine works by                   explanation counts as interactive since it includes the larger
appealing to its sub-components, we are giving a                       environment within which automobiles function and seeks
homuncular explanation of it. We provide an interactive                to explain its relational features. On the other hand, if we
explanation when we include the role of the environment in             zero in on what the components of a motor vehicle are,
our account of how some system functions in that                       asking how each functions, what its individual features are,
environment.          Clark cites Ballard‘s approach to                and so on, we will be providing a homuncular explanation.
understanding vision as an animate process as a good                   Each of these explanations will deepen our understanding of
example of interactive explanation. In contrast to the                 the car concept because each will explain a different aspect
traditional homuncular treatment of vision ―as the task of             of it; such explanations are, thus, not incompatible.
building a detailed representation of a 3D world on the basis             But we have to be careful; it‘s easy to apply the wrong
of what is essentially a body of 2D data,‖ (ibid. p. 7)                type of explanation to a concept, as we do when we give a
Ballard                                                                homuncular explanation to a collective concept and vice
    depicts the goal of vision as the production of                    versa. To see how quickly this confusion can occur, let‘s
    successful actions within an environment context,                  look more closely at the homuncular description of
    keeping computational costs as low as possible. ...                automobile. Being homuncular, it will focus on car
    Thus, according to Ballard, the idea of a component                components and on how the various mechanisms function to
                                                                       bring about system-level activity such as acceleration,
4                                                                      deceleration, and so on. But note that a concept like
  Craver and Bechtel (2007) also do an excellent job of clarifying
some of the level confusions that abound in the debate between         acceleration is a collective concept, since it applies only to
bottom-up and top-down causation. Much of what they say is
                                                                       5
mirrored in what Clark says and what I am arguing for here, but to       Of course, absence here cannot mean that there just don‘t happen
make those connections explicit would take more space than I have      to be passengers here at this time; rather, it means that the kind
room for so I leave that to another paper.                             passenger just doesn‘t exist in this context.
                                                                   2220

the car as a whole and involves relational attributes such as      some causal regularity. Such an account would be viciously
the property of increase in speed relative to a frame of           circular since the very reason we are appealing to the
reference. Thus, although we could pick out the engine as a        supposed detection capacities of neurons is to explain how
mechanism that plays a role in the car‘s capacity for              the larger system, the human cognitive agent, manages to
acceleration, we will need to be careful that we don‘t             represent.
erroneously, or sloppily, treat the engine as the car‘s               Stated thus, this result might seem hopelessly depressing,
accelerator. The engine itself doesn‘t do any accelerating at      but I think it is cause for optimism: clearly seeing the
all, it doesn‘t even move, even though its activity, in            circularity of our current thinking ought to liberate us once
conjunction with the movement of the wheels, the amount            and for all from whatever reductive attractions it holds. In
of friction between the tires and the road, and so on, results     the next section I will sketch what I see is the way forward.
in the car‘s acceleration. In other words, its actions are
necessary for acceleration, but the engine itself does not                      Section III: A Paradigm Shift
accelerate. The mistake we make, if we take the engine to          Ramsey‘s arguments uncover some very deep-seated
be the car‘s accelerator, is to give a homuncular explanation      assumptions about representation that we, perhaps because
to a collective concept: no amount of component activity           we are paradigm examples of information-using systems, all
could ever give account of the relational attributes of such a     seem to share. These biases lead us to read more into causal
concept. Thus, homuncular explanations are good for                relations than are justified – co-relation between two states
explicating the individual (aspects of) concepts and               of affairs is not enough to warrant the assumption that
interactive explanations are required for providing an             information transfer plays a role in the underlying causal
account of the collective (aspects of) concepts.                   transaction, even when there is a story to tell about how
   We now have the terminology we need to clearly identify         having and using the relevant information would have
the problem with treating neurons as detectors. The concept        bestowed selectional advantage on the system within which
of being a detector is a collective concept and, as such,          such states exist.
requires explication in interactive terms. When we appeal             When we analyse our theoretical approach further, we
to the detecting capacity of our neurons in the course of          find that it is underwritten by a confused understanding of
explaining the representational capacities of human                the relation between concepts and explanations, that our
cognitive agents, however, we are giving a homuncular              (natural) reductive impulse to prefer homuncular
account, since neurons are components of this larger system.       explanations draws us to look inward when we are
But, since the concept we are trying to explicate is a             explaining intentional capacities when we should be looking
collective one, this can‘t possibly be right. Supposing that       outward for interactive explanations instead.
our capacity to model objects in our environment is                   Interaction theorists, and dynamic systems theorists in
explained by the capacity of our neurons to do exactly that        general, have begun developing precisely these kinds of
is like pointing to a car‘s engine and saying ―there, that‘s       interactive explanations. (Freeman, 2000; Keijzer, 1998;
where the acceleration is happening.‖ As we just saw,              Kirsch, 1990; Thelen, Schöner, Scheier, Smith, 2001).
although car engines play a role in acceleration, to fully         Among these, Fred Keijzer‘s is particularly noteworthy
explicate the concept we need to look beyond the car‘s             since he has attempted to give at least the beginning of an
components to the general environment within which                 account of the kind of higher-level, off-line behaviour –
acceleration becomes possible. In a precisely analogous            planning, remembering, and so on – that interactionist
way, we shouldn‘t look inwards for detectors; we need to           accounts with their emphasis on system-environment
think more broadly about what contextual attributes make           interactions, have had a hard time explaining. What‘s
the role of detection possible.                                    particularly exciting about his idea is that it draws its
   But, someone might counter, why couldn‘t the neuronal           inspiration from the field of genetics, an area in which a
level really be the locus of detection in the human cognitive      paradigm-shift away from representation-based models is
system? If we suppose that there is a larger system, perhaps       already yielding fruitful new insights. On this new view,
a network of neurons, within which neurons function as                 Genes do not instruct the cytoplasm, they rely on the
detectors, we are giving an interactive explanation of the             intrinsic disposition of cytoplasmic processes to
capacity.                                                              generate spatial and temporal structure. As Gottlieb
   Unfortunately, this won‘t work: if we suppose that                  puts it, genes are a part of a complex but highly
neurons function to carry information about whatever it is             coordinated system of regulatory dynamics that
they detect within the context of a larger system, then we             operate simultaneously at multiple scales, extending
will need to explain how this larger system has the capacity           from genes to chromosomes, to the cell's nucleus,
for using the information the neurons carry. Otherwise,                cytoplasm, tissues and up to the whole organism
we‘ll be back to square one, as we were at the end of section          (Gottlieb, 1992, p.142). (Keijzer, 1998, pp. 286-87)
one. But to suppose that something is capable of using             If we are to progress in our understanding of cognition,
information is just another way of saying that it has              Keijzer argues, we need to similarly replace our homuncular
intentional capacities, that it has the ability to extract a       treatment of behaviour as ultimately driven by internal
representation of an actual or possible state of affairs from      representations, implemented by neurons, by an interactive
                                                               2221

theory of how the different scalar levels of activity within        Clark, A. (1996). Happy couplings: emergence and.
and without a cognitive agent influence and direct one                explanatory interlock. In M. Boden (Ed.), The Philosophy
another to produce behaviour. On such an account, we are              of Artificial Life. Oxford: Oxford University Press.
free to understand the function of neurons in entirely novel        Clark, A. (2002). Is seeing all it seems? Action, reason, and
ways. Keijzer describes one possibility like this:                    the grand illusion. Journal of Consciousness Studies,
     In behavioral explanations based on representational             9(5/6).
     specification the activity of neurons is interpreted as        Craver, C., & Bechtel, W. (2007). Top-down causation
     an input-output device which receives and sends                  without top-down causes. Biology and Philosophy, 22:
     information. However, neurons can also easily be                 547–563.
     interpreted as oscillatory units (Alexander & Globus,          Dehaene, S. (2002). Single-Neuron Arithmetic. Science,
     1996). Given this interpretation, the total nervous              New Series, Vol. 297, No. 5587, 1652-1653.
     system forms a larger oscillatory network, the                 Dretske, F. (1988). Explaining Behavior. Cambridge: MIT
     behavior of which depends on the characteristics of its          Press.
     components and their connections. As the nervous               Dretske, F. (1994). The Explanatory Role of Information,
     system is an organ that extends itself over the scale of         Phil. Trans. R. Soc. Lond. A, 349, 59-70.
     the total body of an organism, and because the                 Fodor, J. (1990). Information and representation. In P.
     connections between neurons allow very swift                     Hanson (Ed.), Information, Language, and Cognition.
     interactions across this network, it forms a means for           Vancouver: University of British Columbia Press.
     dynamical patterns to organize themselves very fast            Freeman, W., & Skarda, C. (1990). Representations: who
     (starting at tens of milliseconds) at the bodily scale. In       needs them? In J. McGaugh, N. Weinberger and G. Lynch
     turn, the neural dynamics is tied to a musculo-skeletal          (Eds.), Brain Organization and Memory: Cells, Systems
     system capable of initiating environmental changes at            and Circuits. Oxford: Oxford University Press, pp. 375–
     the bodily scale. The bodily dynamics in turn                    380.
     influences      dynamical     relations     within     the     Freeman, W. (2000). How Brains Make Up Their Minds.
     environment. (1998, p. 279)                                      New York: Columbia University Press.
   Whether or not this is ultimately the right way of thinking      Griffiths, T. L., Chater, N., Kemp, C., Perfors, A.,
about neurons is beside the point of this paper; I present it         Tenenbaum, J. (2010). Probabilistic models of cognition:
here simply as an example of the theoretical possibilities            exploring representations and inductive biases. Trends in
open to us.                                                           Cognitive Sciences 14, 357–364.
   I‘ll leave the final word to Walter Freeman, a                   Keijzer, F. (1998). Doing without representations which
neuroscientist who claims that he was able to make headway            specify what to do. Philosophical Psychology, II(3), 269-
in interpreting his own data only once he let go of his basic         302.
assumption that neurons function as detectors:                      Keijzer, F. (2002). Representation in dynamical and
      For more than 10 years we tried to say that each                embodied cognition. Cognitive Systems Research, 3, 275–
     spatial pattern was like a snapshot, that each burst             288.
     served to represent the odorant with which we                  Kelso, J. A. S. (1995). Dynamic Patterns: The Self-
     correlated it, and that the pattern was like a search            Organization of Brain and Behaviour. Cambridge: MIT
     image that served to symbolize the presence or                   Press.
     absence of the odorant that the system was looking             Kirsh, D. (1990). When is information explicitly
     for. But such interpretations were misleading. They              represented? In P. Hanson (Ed.), Information, Language,
     encouraged us to view neural activity as a function of           and Cognition. Vancouver: University of British
     the features and causal impact of stimuli on the                 Columbia Press.
     organism and to look for a reflection of the                   Marr, D. (1982). Vision. A Computational Investigation into
     environment within by correlating features of the                the Human Representation and Processing of Visual
     stimuli with neural activity. This was a mistake. After          Information. New York: W.H. Freeman.
     years of sifting through our data, we identified the           Ramsey, W. (2003). Are receptors representations? Journal
     problem: it was the concept of representation.                   of Experimental & Theoretical Artificial Intelligence,
     (Freeman & Skarda, 1990, p.376)                                  15:2, 125-141.
                                                                    Thelen, E., Schöner, G., Scheier, C., Smith, L. (2001). The
                          References                                  dynamics of embodiment: A field theory of infant
Bowers, Jeffrey S. (2009). On the biological plausibility of          perseverative reaching. Behavioral and Brain Sciences,
   grandmother cells: implications for neural network                 24, 1–86.
   theories in psychology and neuroscience. Psychological
   Review, Vol. 116(1), 220-51.
Clark, A. & Toribio, J. (1994). Doing without representing?
   Synthese, 101, 401–431.
                                                                2222

