UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Turn-boundary projection: Looking ahead
Permalink
https://escholarship.org/uc/item/5xn4q9g5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Tice, Marisa
Henetz, Tania
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                    Turn-boundary projection: Looking ahead
                 Marisa Tice (middyp@stanford.edu)                          Tania Henetz (thenetz@stanford.edu)
                  Margaret Jacks Hall, Stanford University                        Jordan Hall, Stanford University
                        Stanford, CA 94305-2150 USA                               Stanford, CA 94305-2150 USA
                               Abstract                                 2006, but see Gravano & Hirschberg, 2011). Addressing turn
                                                                        projection experimentally, de Ruiter and colleagues (2006)
   Coordinating with others is hard; and yet we accomplish this
   every day when we take turns in a conversation. How do we do         asked Dutch speakers to listen to fragments of spontaneous
   this? The present study introduces a new method of measuring         speech and press a button at the moment they anticipated the
   turn-boundary projection that enables researchers to achieve         speaker would be finished speaking. The stimuli were manip-
   more valid, flexible, and temporally informative data on online
   turn projection: tracking an observer’s gaze from the current        ulated phonetically, controlling for potential projection cues
   speaker to the next speaker. In this preliminary investigation,      such as intonation, lexicosyntactic information, and rhythm.
   participants consistently looked at the current speaker during       Their results suggest that speakers rely primarily on lexical
   their turn. Additionally, they looked to the next speaker before
   her turn began, and sometimes even before the current speaker        information (which also provides syntactic cues) to identify
   finished speaking. This suggests that observer gaze is closely       upcoming turn-end boundaries.
   aligned with perceptual processes of turn-boundary projection,
   and thus may equip the field with the tools to explore how we           The experimental approach introduced by de Ruiter et al.
   manage to take turns.                                                (2006) is an significant step forward in research on boundary
   Keywords: Turn-taking; Social cognition; Eye tracking; Co-           projection, but there is still much to be addressed. Specifi-
   ordination; Timing; Conversation; Interaction
                                                                        cally, we do not know how to account for boundary projec-
                                                                        tion as the turn is unfolding. Listeners have access to only
                          Introduction                                  that information which has already been spoken, and so their
Interacting with others requires us to make a number of com-            use of cues may differ over the course of a turn. For ex-
plex linguistic, social, and cognitive decisions. Despite this,         ample, it could be the case that listeners track intonation as
most conversations proceed smoothly, allowing us to take for            a primary cue to the beginning of a turn’s denouement, and
granted the intricate processes taking place in getting the tim-        then increase their reliance on lexical information to precisely
ing of our actions right on cue. Turn-taking during conversa-           identify the end of the upcoming syntactic clause. The infor-
tion is one phenomenon that exemplifies these issues. Intu-             mation that listeners use to track upcoming turn boundaries
itively we seem to wait for the current speaker to stop talk-           should reflect their integrated knowledge of all the cues avail-
ing before we start conjuring up a response, with each turn             able to them as the turn is unfolding.
preceded and followed by orderly pauses or ‘gaps’ in speak-
ing. But this is not the case: not only do we not ‘wait’, but              The button-press methodology gives us a single point in the
there are often no gaps between speakers at all! Speakers               turn at which to test a manipulation. It is incapable of track-
are extremely adept at taking turns efficiently, averaging 0.2-         ing listeners’ ongoing certainty level about upcoming turn-
0.4 second gaps in face-to-face conversation (Brady, 1968;              end boundaries; especially in cases where there is a possible,
Stivers et al., 2009) and 0.7 second gaps over the phone                or even probable, but not realized turn-end (e.g. “Did I ever
(Jaffe & Feldstein, 1970), often with less than 5% overlap              tell you about my Aunt Millie? She was a wild one.”). In
(Levinson, 1983). This general pattern has been observed                listening to this signal, participants in a button-press experi-
across many cultures, leading researchers to conclude that in-          ment are likely to enter their response after “Millie” or after
terlocutors adhere to standards of no-gap-no-overlap in trans-          “one.” In the case that they were not fooled by the first po-
ferring turns from one speaker to the next (de Ruiter et al.,           tential turn-end place, the single button press could not tell
2006; Sacks et al., 1974; Stivers et al., 2009). To accom-              us about their ongoing projection: how close they came to
plish this no-gap-no-overlap timing, listeners must be able to          thinking of it as a turn-end boundary, what cues were im-
actively project the end of the current speaker’s turn (here-           portant at the time, et cetera. The button-press also adds an
after, turn-end boundary), while simultaneously starting to             “input” requirement to the task, which might be sensitive to
plan their response.                                                    the task instructions. An ideal measure of anticipation would
   The prevailing method of investigating how projection                not require explicit instructions, easing the cognitive load on
takes place is to use corpora to identify linguistic cues that co-      participants that might arise from the specific task.
incide with turn-end boundaries (e.g. prosodic, syntactic, and             We propose a new method of investigating turn-projection
pragmatic boundaries; (Ford & Thompson, 1996; Caspers,                  behavior: tracking observer gaze. In the utterance about Aunt
2003)). But these cues often co-occur, making it difficult              Millie, gaze might reveal a robust effect of the initial proba-
to interpret relative cue importance. Additionally, some of             ble turn-end point: a gradient increase and then decrease in
these cues might come too late for listeners to make use of             transition-related looks as the utterance continues. Button-
them, for instance, lengthening of the final word in an utter-          pressing, in contrast, indicates the point in time when the ob-
ance happens nearly at the end of the turn (de Ruiter et al.,           server felt they had sufficient evidence to respond to an utter-
                                                                    838

ance1 , which is somewhat analogous to “jumping in” to actu-          Materials
ally take a turn. Producing a response is an essential behavior       To assess observer gaze as a measure of turn-boundary pro-
in conversation, but is not the same phenomenon as active             jection, we recorded the eye movements of participants as
turn-end boundary projection, which we may do at all times            they watched two short film clips of dialogue. To optimize
without ever intending to jump in. Tracking observer gaze             the ease of coding participants’ eye gaze, the video materi-
allows us to measure how listeners track upcoming bound-              als also needed to display each speaker in relatively isolated
aries without adding in the complexities of what is required          and static positions on screen. In this study we rely on the
to respond.                                                           film device known as the “split-screen” telephone conversa-
Observer gaze                                                         tion (see Figure 1). During a typical split-screen conversa-
                                                                      tion, the screen is partitioned to simultaneously show two or
During face-to-face conversation, listeners tend to look at the
                                                                      more speakers as they converse over the phone. This medium
current speaker. This behavior has been documented through
                                                                      satisfies the constraint of conversational interactivity required
naturalistic observation (Kendon, 1967) and replicated in the
                                                                      to expect turn-transitional looks, but also keeps the speakers
laboratory (Bavelas et al., 2002) and in studies of human-
                                                                      in distinct enough regions of the screen to make gaze coding
computer interaction (Jokinen et al., 2009). In each of these
                                                                      feasible. We chose two “split-screen” telephone conversa-
studies, eye gaze has been shown to be an effective turn-
                                                                      tions from the relatively recent film Mean Girls (Paramount
taking cue. Eye gaze has also been tied to predictive linguis-
                                                                      Pictures, 2004).
tic processes in other contexts (Brown-Schmidt & Tanenhaus,
2006; Griffin & Bock, 2000; Richardson & Dale, 2005). It
is possible, then, that when an ongoing conversation nears
a point of turn transition, third-party observers will look to
the next speaker anticipatorily as the current speaker’s turn
is coming to a close—that is, before the current speaker has
stopped speaking. Note that we don’t mean to suggest that
observer gaze plays the same role in face-to-face conversa-
tion as it would in our task, only that there is precedence for
this looking tendency.
   A third-party observer’s eye movements over the transition         Figure 1: Frame of a split-screen scene in the film Mean Girls.
period from current to next speaker could provide a continu-          Speaker 1 is on the left, Speaker 2 on the right.
ous and naturalistic measure of turn-end boundary projection.
This methodology retains the ability to control phonetic and
other linguistic factors in the presentation of video stimuli,        Procedure
while permitting the examination of non-linguistic factors in         Participants were asked to watch two short scenes from the
the accompanying visual scene. Furthermore, with minimal              film and then answer questions about each scene immediately
changes, it could lend itself well to developmental work since        after it finished playing. For the duration of the experiment,
eye-tracking is an effective online measure for young chil-           participants were seated at a small desk in front of a large
dren (Fernald et al., 2010; Gredebäck et al., 2009; Kidd et al.,     display screen. A small video camera was tucked beneath
2011).                                                                the screen, pointing upwards, toward the participant’s face
   This study is an initial investigation of observer gaze as         and was switched into recording mode for the duration of the
a measure of turn-boundary projection. If observer gaze is a          experiment. Audio was played aloud over the speakers of a
reliable measure of anticipatory turn-taking behavior, we may         laptop so that it could be captured by the video camera for
harness it to investigate the processes and cues used for online      later coding. No participant reported difficulty hearing the
turn projection. In this study, we ask the following questions:       stimuli.
(1) Do third-party observers reliably track current speakers             Participants were first asked about their familiarity with the
with their gaze? and (2) Do third-party observers anticipate          movie. More than half of the participants had seen the film at
transitions to the next speaker?                                      least once before (N=10). Regardless of familiarity with the
                                                                      film, each participant was briefly familiarized with the char-
                             Methods                                  acters featured in the clips. At the start of both trials, partici-
Participants                                                          pants were reminded that they would be asked about the clip
The seventeen participants in this study were all current mem-        after it was over. Then the experimenter asked the participant
bers of the Stanford Linguistics or Psychology Departments            to focus on a yellow star centered on the screen until the clip
(females = 9). The participants were volunteers who were not          began. After the clip was over, the experimenter and partic-
paid for their participation and were unaware of the purpose          ipant went through three comprehension questions verbally.
of the study.                                                         The entire experiment took less than five minutes for all par-
                                                                      ticipants. During debriefing, participants were asked if they
    1 Though in this case, the response is simple.                    guessed the purpose of the study. One participant reported
                                                                  839

awareness that we were measuring his looks to each speaker,                        (p<0.05). This is strong evidence that observers are looking
so these data were excluded from analyses.                                         at the current speakers during their turns, replicating previous
                                                                                   work by Bavelas, Coates, & Johnson (2002).
  Question                              Answer                                        This pattern also means that observers must be reliably
  1. Hello?                             I know your secret.                        shifting their gaze between speakers when the floor is trans-
  2. Secret? What are you saying about? Gretchen told me that you like A.S.        ferred. So do observers reliably anticipate the next speaker’s
  3. Is that bad?                       But if you like him, whatever.             turn with their gaze, as they do when participating in every-
  4. Really? You would do that? I mean  Oh no, trust me, I know exactly how to     day conversation? Figures 2b-f show the average gaze tra-
  nothing embarrassing though, right?   play it                                    jectories for each question-answer pair, and Figure 2g shows
  5. Aren’t you so mad at Gretchen for  No.                                        the trajectory averaged across Q-A pairs. The wide variation
  telling me?
                                                                                   in trajectories is partially due to shorter and longer questions
Table 1: Question-answer pairs included in the analyses drawn                      and answers, which include transitional gazes from previous
from the one-minute dialogue. See Figure 2 for individual gaze tra-                and following discourse.
jectories.                                                                            In each Q-A pair, observers’ gaze shifts from the person
                                                                                   asking the question (the Questioner) to the person responding
                                                                                   to the question (the Responder). Observers might do this by
Eye-gaze coding                                                                    shifting their gaze only after the Responder has begun speak-
Here we report eye gaze data from the first video clip (com-                       ing. Alternatively, they could anticipate the beginning of the
prehension score average: 95.8%). We omitted data from                             next turn so that observers are already looking at the Respon-
the second video before running any analyses. It included                          der as her turn begins. This would align with the listening be-
a shifting four-way screen split that made direction of gaze                       havior of interlocutors who are actually participating in con-
impossible to code reliably2 . There are 15 total transitions in                   versation.
the one-minute video clip. Before analyzing the data, we se-                          To compare the reaction or anticipation accounts, we first
lected all of the five question-answer pairs as the target of our                  identified critical time windows during the question-answer
analyses. Question-answer sequences present a reasonable                           sequence for statistical comparison. Since we know that ob-
example case for testing this method since they are reliable as                    servers reliably gaze at the current speaker during their turn,
adjacency pairs (i.e. they usually elicit a response), but still                   our windows of interest need to include the region between
provide a diverse sample of Speaker1-Speaker2 sequences.                           turns. One way to assess whether observers have shifted gaze
    The video recording of each participant’s gaze during the                      toward the Responder is to compare the proportion of looks
clip was analyzed by at least two coders: one of the authors                       to the Responder in the beginning of the gap with the propor-
and one trained coder naive to the purpose of the study. Di-                       tion at the end of the gap. To account for the planning and
rection of gaze was coded for each 50 ms interval of the one-                      execution of eye-movements, we extended this region by 200
minute film clip as ‘right’, ‘left’, ‘center’ and ‘not codeable’.                  ms on either side of the gap since the measurement reflects
These were recoded to numerical values for averaging across                        shifts that were planned before the change in gaze (Fischer
coders, replacing uncodeable values with the average of the                        & Ramsperger, 1984; Griffin & Bock, 2000). If observers
values directly preceding and directly following. Intercoder                       anticipate turn beginnings with their gaze, then their looks to
agreement was high (96%)3 .                                                        the Responder should increase between the window 200 ms
                                                                                   before the gap and 200 ms after the gap.
                                   Results
                                                                                      A visual analysis of the gaze trajectories in Figures 2b-f
Do observers look at the current speaker? Figure 2a displays
                                                                                   demonstrates that observers generally shift their gaze to the
the average gaze trajectory for all 16 participants across the
                                                                                   Responder before she begins speaking. Furthermore, some of
entire one-minute film clip. It is clear that observers reliably
                                                                                   these shifts are happening at the very beginning of the gap (or
look at the current speaker. This was confirmed by unpaired
                                                                                   even earlier), indicating that observers may also make antici-
Wilcoxon signed rank tests on the proportion of looks to the
                                                                                   patory looks to the next speaker while the current speaker is
current speaker during each turn in the minute-long dialogue.
                                                                                   finishing her turn.
While Speaker 1 was talking, observers were looking at her
79.6% of the time, and while Speaker 2 was talking, observers                         These general observations were confirmed by comparing
gazed at Speaker 1 only 25.2% of the time. When neither                            the average proportion of looks to the Responder in the 200
speaker was talking, gaze was divided between speakers, with                       ms window before and after the gap using paired Wilcoxon
58.1% looking to Speaker 1. Each of these differences is sig-                      signed rank tests. Since our hypothesis makes a strong di-
nificant overall (p<0.001) and for 15 of the 16 participants                       rectional prediction that looks to the Responder will increase
                                                                                   before that speaker’s turn, we report one-tailed p values. Av-
     2 Some participants also found the second clip confusing (com-
                                                                                   eraged across Q-A pairs, looks to the Responder increased
prehension score average = 87.5% overall, but only 72.2% for those
who had not seen the movie before).                                                from 24% in the 200 ms window before the gap to 66% in the
     3 91% of disagreements were between ‘center’/‘unclear’ and                    200 ms window after the gap (p=.03). This comparison was
‘right’/‘left’ codes (not ‘right’ vs. ‘left’).                                     significant at p=.03 for each of the five Q-A pairs except for
                                                                               840

Figure 2: Gaze trajectories averaged across participants for (a) the entire conversation, (b)-(f) each Q-A pair, and
(g) an average of the five Q-A pairs. In (a), each speaker turn is highlighted by light and dark shaded regions. Figures
(b)-(f) plot proportion of looks to the Responder at each 50 ms interval, with shading over the duration of the gap.
200 ms before and after the gap are lightly shaded, and indicate time windows on which analyses were made. In (g),
the gaze trajectory is for all five pairs. The gap in this figure has been collapsed into a single, average duration.
                                                            841

pair one, which was marginal (p=.07).                                    spectively). These questions contain little information, and
   These analyses suggest that observers do, indeed, antici-             we might suspect that the lower proportion of looks to the
pate the beginning of the Responder’s turn. However, there               Questioner is due to the observers’ preference for looking to
is still the question of whether the data show any evidence              the current speaker. Finally, the gap in Q-A pair five is ex-
that observers are not only anticipating the beginning of the            tremely long (949 ms), and observers appear to actually start
Responder’s turn, but also anticipating the end of the Ques-             looking back to the first speaker midway through the gap.
tioner’s turn. If observers are anticipating the end of the              This supports work showing that silences over a second may
Questioner’s turn, then we would expect looks to the Respon-             be perceived as “trouble” in a conversation (Jefferson, 1989;
der to increase within the first 200 ms of the inter-speaker             Brennan & Williams, 1995).
gap, since their eye movements must be planned in advance.                  We did not design or select our Q-A pairs to satisfy these
Since three of our Q-A pairs (one, two, and four) have gaps              properties and so the previous description is post hoc. But,
of length less than 200 ms, our previous analysis already pro-           the existence of these looking patterns increases our confi-
vides suggestive evidence that this anticipation is taking place         dence that observer gaze is a robust measure of online turn
(the difference between the pre- and post- gap windows was               projection. Observer gaze could be manipulated by control-
significant for pairs two and four, p=.03). For the two pairs            ling some of these properties, but it will take further research
with gaps longer than 200 ms, we can compare the first 200               to determine which ones are most important.
ms of the gap with the previous 200 ms. These Q-A pairs
do not provide evidence that observers anticipated the end of            Conversations on video
the Questioner’s turn: for pair five, the difference trends in           There are two issues one might have with our stimuli. The
the right direction (p=.09) and for pair three, the looks to the         first is that the video stimuli are from a scripted dialogue in
Responder actually decreased significantly, (p=.03).                     a film which is meant to be entertaining, and might conceiv-
                                                                         ably exaggerate conversational cues. In future versions of this
                           Discussion                                    work, we plan to replicate these effects without the “director”
In this preliminary analysis of observer gaze, we were inter-            effect of using a Hollywood film5 . We are in the process of
ested in two primary questions: (1) Do third-party observers             collecting naturalistic conversations between strangers, both
reliably track current speakers with their gaze? (2) Do third-           in split-screen and co-present conversational situations to use
party observers anticipate transitions to the next speaker?              as stimuli.
   Our analyses suggest that observers do reliably track cur-               Second, there is some concern about how to interpret look-
rent speakers with their gaze, and that they often do so before          ing behavior to a recorded conversation since, though ob-
the Responder begins talking, and even sometimes before the              server gaze is a passive and naturalistic behavior, it does not
Questioner finishes talking, though evidence for this is more            replicate exactly the experience of being a first-person in-
mixed. These preliminary data are promising given the lim-               teractant in a conversation. Not only may a third-party role
ited, naturalistic stimuli and the minimal task. Our result con-         affect participant engagement in unpredictable ways, but re-
firms previous work showing that listeners actively project              cent work has shown that interactive features of conversa-
upcoming turns, but it does not yet build on this methodology            tional gaze, such as mutual gaze, may affect what informa-
to investigate relatively untouched aspects of turn-boundary             tion speakers take away from the conversation (Richardson &
projection (e.g. continuous cue usage, developmental study,              Dale, 2005). This effect may extend to the information they
et cetera.) But, the methodology we demonstrate here may                 attend to in projecting upcoming turn-end boundaries. For-
bring these results sooner and more accurately than present              tunately, it is increasingly possible to measure observer gaze
button-pressing methodologies can.                                       in interactive first-person experiments thanks to developing
   There are hints in our present data that such insights can            technology in minimally intrusive eye-tracking systems.
be gained. The gaze patterns on a few Q-A pairs show de-                    On the other hand, since we know relatively little about
viations that we might have expected a priori, given previ-              how turn projection is accomplished, it may work to our ad-
ous research. Q-A pair four is structured analogously to the             vantage to leave the complicating factors of first-person dia-
“Aunt Millie” example above, since a number of cues (intona-             logue to future work. By this time, our methodology could
tional, syntactic, semantic, and more) could lead participants           be well-enough established to make firm predictions about
to ‘false alarm’ and project that the turn will end earlier than         gaze as a continuous measure of certainty about upcoming
it actually does. The resulting gaze behavior is exactly what            turn-end boundaries, and the anticipation of upcoming turn-
we expected: less than a second into the turn, observers start           beginnings. Finally, gaze measures may prove to be comple-
looking to the Responder, recovering as the Questioner (un-              mentary to button-pressing techniques, since each provides
expectedly) continues with her turn. Similarly, the questions
                                                                         develop the analytical tools to do so as we develop the method more
in pairs one and three could be interpreted as alternatives to           generally.
a full turn (i.e. a ritualized greeting and a backchannel4 , re-             5 We have collected a second version of this experiment in which
                                                                         observers are given no sound. Observers’ eye behavior did not repli-
    4 The analyses presented here do not include a way of separating     cate the findings reported here, suggesting that the source of these
these ‘false alarm’ instances from others, but we expect to further      effects was not the “Hollywood” visual effects and editing.
                                                                     842

distinctly different information, but measures behaviors that              in the turn-taking system in dutch. Journal of Phonet-
occur simultaneously in everyday conversation.                             ics, 31, 251–276.
                                                                    de Ruiter, J., Mitterer, H., & Enfield, N. (2006). Projecting
Future directions                                                          the end of a speaker’s turn: A cognitive cornerstone of
Observer gaze is a promising new methodology for pinning                   conversation. Language, 82, 515–535.
down the cognitive processes involved in turn-end boundary          Fernald, A., Thorpe, K., & Marchman, V. (2010). Blue car,
anticipation. One immediate goal for is to use the natural-                red car: Developing efciency in online interpretation
istic, spontaneous stimuli that we are currently collecting to             of adjectivenoun phrases. Cognitive Psychology, 60,
replicate the results of this experiment, while adding phonetic            190–217.
manipulations of the sort in de Ruiter et al. (2006). Following     Fischer, B., & Ramsperger, E. (1984). Human express sac-
much of the previous work on turn-taking, we have focused                  cades: extremely short reaction times of goal directed
on question-answer pairs (e.g. Stivers et al., 2009). Questions            eye movements. Experimental Brain Research, 57,
almost always elicit a response, which make them easier to                 191–195.
study than other turn-transitions. With this new methodology        Ford, C., & Thompson, S. (1996). Interactional units in con-
we intend to investigate a more diverse set of turn transitions            versation: Syntactic, intonational, and pragmatic re-
in upcoming work. Finally, the immediate application of ob-                sources for the management of turns. In E. A. Sche-
server gaze as studied here is for adult turn-taking behaviors.            gloff & S. A. Thompson (Eds.), Interaction and gram-
However, there are several other areas of study, such as child             mar. Cambridge, MA: Cambridge University Press.
development, second language acquisition, and cross-cultural        Gravano, A., & Hirschberg, J. (2011). Turn-taking cues
interaction, that could use this method for investigating turn-            in task-oriented dialogue. Computer Speech and Lan-
taking and other interactional and conversational phenomena.               guage, 25, 601–634.
   Observer gaze presents new opportunities to explore how          Gredebäck, G., Johnson, S., & Hofsten, C. von. (2009). Eye
we manage to coordinate with others in interaction—in this                 tracking in infancy research. Developmental Neuropsy-
case, taking turns in conversation. For decades, the study of              chology, 35, 1–19.
conversational timing and turn-taking has been held up for a        Griffin, Z., & Bock, K. (2000). What the eyes say about
lack of on-line processing measures. One of this method’s                  speaking. Psychological Science, 129, 177–192.
most promising features is that it measures a behavior that         Jaffe, S., & Feldstein, S. (1970). Rhythms of dialogue. New
participants already engage in spontaneously. By capturing                 York: New York: Academic Press.
this natural behavior in the lab, we may be able to elucidate       Jefferson, G. (1989). Preliminary notes on a possible met-
some of the mechanics of turn processing.                                  ric which provides for a ’standard maximum’ silence of
                                                                           approximately one second in conversation. In D. Roger
                    Acknowledgments                                        & P. Bull (Eds.), Conversation: an interdisciplinary
                                                                           perspective. England: Multilingual Matters Ltd.
This research was supported by an NSF Graduate Research
                                                                    Jokinen, K., Nishida, M., & Yamamoto, S. (2009). Eye-gaze
Fellowship to M.T. We thank Eve V. Clark, Herb H. Clark,
                                                                           experiments for conversation monitoring. In Proceed-
Paul Thibodeau, Chigusa Kurumada, Michael Frank, and
                                                                           ings of the 3rd international universal communication
Shawn Tice for their helpful comments, as well as the four
                                                                           symposium. New York, NY: ACM.
anonymous reviewers of our paper. We also thank our coders:
                                                                    Kendon, A. (1967). Some functions of gaze-direction in so-
Andy Lesser, Laura Yuen, and Armine Pilikian.
                                                                           cial interaction. Acta Psychologica, 26, 22–63.
                                                                    Kidd, C., White, K., & Aslin, R. (2011). Toddlers use speech
                          References
                                                                           disuencies to predict speakers’ referential intentions.
Bavelas, J., Coates, L., & Johnson, T. (2002). Listener re-                Developmental Science, 1–10.
        sponses as a collaborative process: The role of gaze.       Levinson, S. (1983). Pragmatics. Cambridge, MA: Cam-
        Journal of Communication, 52, 566–580.                             bridge University Press.
Brady, P. (1968). A statistical analysis of on-off patterns in      Richardson, D., & Dale, R. (2005). Looking to under-
        16 conversations. Bell System Technical Journal, 47,               stand: The coupling between speakers’ and listeners’
        73–91.                                                             eye movements and its relationship to discourse com-
Brennan, S., & Williams, M. (1995). The feeling of another’s               prehension. Cognitive Science, 29, 1045–1060.
        knowing: Prosody and filled pauses as cues to listeners     Sacks, H., Schegloff, E., & Jefferson, G. (1974). A simplest
        about the metacognitive states of speakers. Journal of             systematic for the organization of turn-taking for con-
        Memory and Language, 34, 383–398.                                  versation. Language, 50, 696–735.
Brown-Schmidt, S., & Tanenhaus, M. (2006). Watching the             Stivers, T., Enfield, N., Brown, P., Englert, C., Hayashi, M.,
        eyes when talking about size: An investigation of mes-             Heinemann, T., et al. (2009). Universals and cultural
        sage formulation and utterance planning. Journal of                variation in turn-taking in conversation. PNAS, 106,
        Memory and Language, 54, 592–609.                                  10587–10592.
Caspers, J. (2003). Local speech melody as a limiting factor
                                                                843

