UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The formation of context in artificial object recognition
Permalink
https://escholarship.org/uc/item/0mx007gz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Knittel, Anthony
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                  University of California

                          The formation of context in artificial object recognition
                                                Anthony Knittel (aek@cse.unsw.edu.au)
                                              University of New South Wales, Sydney, Australia
                               Abstract                                      Developing understanding of the manner in which context
                                                                          acts is essential for developing effective artificial systems,
    Context plays an important role in the recognition of objects,        and for understanding the manner in which important seman-
    allowing the general content of a scene to influence identifi-
    cation of individual parts. An autonomous learning system is          tic and visual processes operate.
    presented that examines processes involved in the formation              The manner in which context is formed, and how contex-
    of context between multiple co-occurring objects, under the           tual processes between semantic elements are activated is not
    task of identifying abstract objects in a scene. Learning is per-
    formed using a form of Learning Classifier System, that builds        well understood (Bar, 2004). An important aspect for study-
    representations of features autonomously under reinforcement.         ing this topic is to implement artificial learning processes that
    The feature identification system is used in combination with         capture the behaviour being studied, allowing examination of
    an associative network, used for finding co-occurrence rela-
    tionships for establishing context. Experiments show the in-          the process in detail and in an objective manner, to capture
    fluence of the associative network to resolve ambiguous obser-        properties essential to creating the observed behaviour. Arti-
    vations through the use of context. This approach involves the        ficial learning and applied models contribute to the develop-
    interaction of a reinforcement system, analogous to dopamin-
    ergic processes, with an associative system, based on associa-        ment of artificial systems for practical purposes, to take ad-
    tive Hebbian learning processes, and demonstrates the ability         vantage of aspects of human visual and semantic processes,
    of a recurrent associative network for establishing context re-       which are able to handle large amounts of knowledge in a fast
    lationships.
                                                                          and effective manner.
    Keywords: context; hebbian learning; reinforcement; object
    recognition                                                           Artificial implementations
                                                                          A range of approaches have been used to study recognition of
           Introduction: recognition of scenes                            objects in scenes. The most successful methods use a series
Recognition of objects in a scene requires the interaction of a           of processing steps including edge detection filters, transfor-
number of processes, such as identification of primitive fea-             mations and classifiers, such as (Mutch & Lowe, 2008). This
tures from sensory input, a general idea of the “gist” of the             approach is biologically inspired and makes use of statistical
scene and context of the observation, and influence from the              properties of the training data sets, however does not address
recognition of previously known objects in the observed en-               identification of multiple objects or contextual influences be-
vironment (Oliva & Torralba, 2007).                                       tween them.
    A review by Bar (2004) highlights a number of influen-                   A number of approaches have addressed the identification
tial factors in the role of context in interpreting an observed           of multiple objects in a scene and composition of objects from
object, including the role of co-occurring objects and scenes,            a hierarchical arrangement of parts (Zhu, Lin, Huang, Chen,
abstract properties of an object, as well as facilitation from vi-        & Yuille, 2008; Parikh, Zitnick, & Chen, 2009; Kokkinos &
sual interpretation of a scene at different spatial frequencies.          Yuille, 2009). These address factors such as the unsupervised
Bar (2007) proposes that multiple possible interpretations of             formation of hierarchical clusters, and the use of interaction
an object are activated, that a contextual frame is identified            between bottom-up and top-down processing, to aid identifi-
separately, before the combination of information allows the              cation.
scene and objects to be recognised. Oliva and Torralba (2007)                Recent deep learning (Bengio, 2009) methods provide a
have studied the properties of co-occurrence between com-                 means of identifying intermediate features in a neural net-
mon types of objects in a scene, and the manner in which the              work configuration, which have been used in object recogni-
presence of an object influences the likely presence of other             tion (Ranzato, Huang, Boureau, & LeCun, 2007), competitive
objects, and the relative areas they may occur. There are many            with state of the art image classifiers. This approach high-
factors involved, including semantic interpretation and visual            lights unsupervised identification of intermediate structures,
and spatial information, as well as other statistical properties          however does not allow interaction of context from a number
of observation. This may allow informed guesses about the                 of objects in a scene comparable with contextual processes in
presence and location of objects in a scene, as well as bias-             human cognition.
ing perceptual interpretation of individual objects (Oliva &                 Hoiem, Efros, and Hebert (2008) address the interaction
Torralba, 2007).                                                          between relative positions and sizes of objects in a scene,
    A study by Auckland, Cave, and Donnelly (2007) exam-                  and (Oliva & Torralba, 2006) address recognition of the “gist”
ined the role of the presence of non-target objects in a scene            of a scene based on global features, for use in aiding identifi-
on recognition of a target object. This showed improved iden-             cation of a scene.
tification of the target through a form of priming effect, , even            These address a number of factors involved in the role of
when other objects are not involved in the task.                          context in object recognition, however processes underlying
                                                                      3064

the development of features and development of contextual             also the likelihood that the rule will be maintained in the pop-
properties of learned features, such as contextual interactions       ulation.
between learned objects, requires further study.                         New rules are regularly created, either as copies of obser-
                                                                      vations, or as modifications of existing rules. Most LCS sys-
Ambiguous objects                                                     tems follow a genetic paradigm and use a genetic algorithm
An important topic in visual processing is the resolution of          to create new rules, based on combinations of pairs of other
ambiguous low-level observations, which require the interac-          rules. The population is maintained at a fixed or maximum
tion of high-level interpretations of the scene in order to be re-    size, so when new rules are added, the weakest rules are re-
solved effectively. Yuille and Kersten (2006) discuss the use         moved from the population.
of Bayesian inference to resolve ambiguous lower features,               There are a number of different implementations of LCS
by using potential high-level objects identified to verify low        systems, which handle the rule selection process, reinforce-
level features in a top-down manner.                                  ment and population selection processes in different ways.
   Implementation of an artificial learning system that cap-          XCS (Wilson, 1995) is currently the most established method,
tures the development of contextual information from obser-           and maintains rules according to the accuracy of predicting
vations, and is able to use such context to bias the interpreta-      future rewards received by a rule.
tion of features, offers insight into practical considerations of
such processes.                                                       Activation-Reinforcement based Classifier System
                                                                      ARCS (Knittel, 2010) is a form of Learning Classifier Sys-
Learning Classifier Systems                                           tem designed to maintain links with cognitive processes. Two
Learning Classifier Systems (LCS) (Bull & Kovacs, 2005) are           properties are maintained for each rule, a measure of acces-
machine learning systems related to Reinforcement Learning            sibility, based on the degree of reinforcement of the rule, and
(RL) (Sutton & Barto, 1998), which learn to recognise fea-            quality, representing the expected reward when a rule is used.
tures of the task autonomously, guided by external reinforce-         The accessibility property is based on an analogy with mem-
ment. The key difference between LCS systems and RL is                ory traces, which are strengthened through use (A. D. Bad-
that the representations used for learning incorporate a de-          deley, 1997), and decline either with time or as a result of
gree of generalisation, such that rules, or classifiers, devel-       competition with newer traces (A. Baddeley, Eysenck, & An-
oped by the system may be applicable for a wider range of             derson, 2009). The method of reinforcement is comparable
states (Drugowitsch, 2008). The reinforcement process used            to that used in ACT (Anderson, 1996). This approach has
by reinforcement systems is related to dopaminergic pro-              shown to be effective at balancing generalised and specialised
cesses in the brain, and provides a robust and flexible method        rules (Knittel, Bossomaier, & Snyder, 2007), and provides
of learning (Samson, Frank, & Fellous, 2010).                         closer comparison with cognitive processes than other LCS
   The representations used in LCS tend to capture abstract           systems.
concepts and symbols, related to perceptual observations, and            Effects of context can be incorporated by maintaining asso-
as such provides a higher level of abstraction than artificial        ciative relationships between objects observed, allowing the
neural networks, which model physical properties of individ-          context of observations to influence the weight of rules used
ual neurons. This allows a broader perspective of the pro-            in the system.
cesses being studied, and address properties that may require
a larger scale than that which can be captured in a model             Associative relationships
based on representation of individual neurons. LCS acts au-           There are a number of factors influencing context, however
tonomously, and is able to extract features relevant to the task      one common factor is based on the associative relationships
simply based on reinforcement received.                               between objects, resulting from co-occurrence relationships.
                                                                      This provides a priming effect, where the activation of an
General design of Learning Classifier Systems                         object or concept promotes the activation of associated ele-
Learning Classifier Systems are composed of a population of           ments (Auckland et al., 2007).
rules or classifiers, where each can be compared with the cur-           A number of models are available that study the forma-
rently observed environment, and propose an action that the           tion and activation of associative relationships. Anderson’s
system can perform, or an interpretation of the observation.          ACT(*/R) models are based on abstract concepts, where
The system is presented with an observation from the envi-            properties of interaction between concepts is identified from
ronment, and each of the rules is tested to see which match           behavioural studies (Anderson, 1996; Anderson et al., 2004).
and are relevant at the current time. From the set of matching        In this model a network is created with links between associ-
rules an action or classification is chosen, according to the         ated concepts, and when a concept is activated, the activation
relative weight of each rule.                                         is passed along weighted links, following a “leaky capacitor”
   When external reinforcement is received by the system, the         model.
rules which have recently acted receive a reward, which influ-           Another model that is used to capture associations is Heb-
ences the measure of expected reward for using the rule, and          bian learning, which is based on physiological properties of
                                                                  3065

the strengthening or weakening of synaptic connections be-           works act in this manner, however connections with Bayesian
tween neurons (Haykin, 1998). Connections between a pair             statistics are not clear.
of neurons are strengthened if they fire in a correlated manner,         Hebbian learning allows the formation of a network related
and weakened otherwise.                                              to Bayesian statistics. The use of a Hebbian network pro-
   Hebbian learning has been recognised as resulting in              vides a heuristic for evaluating the presence of ’x’ based on
weights based on the conditional probability of firing between       a range of other activations. It would be informative to ex-
neurons (O’Reilly, 2001), such as with the CPCA learning             amine further the similarities and differences between activa-
rule (O’Reilly & Munakata, 2000):                                    tions provided by such a network and known errors of human
                                                                     judgement, such as those described by (Kahneman, Slovic, &
              ∆wi j (t + 1) = ηy j (t)(xi (t) − wi j (t))     (1)    Tversky, 1982).
   Conditional probability and Bayesian statistics play an           Design of associative network
important role in studies of the recognition of objects in           Hebbian learning modeled on physiological behaviour can be
context (Torralba, 2003), as well as in general models of            detailed, such as the BCM learning rule (Cooper, 2004), how-
the composition of conceptual objects from related fea-              ever a number of simplified rules exist, such as the CPCA
tures (Tenenbaum, Griffiths, & Kemp, 2006).                          rule, given in Equation 1.
                                                                         This rule has been shown to converge on the conditional
Formation of context                                                 probability of activation of the pre-synaptic neuron, given
Existing learning models have addressed the role of context          activation of the post-synaptic neuron P(x|y), as no modifi-
in a number of ways. Hoiem et al. (2008) use the relative po-        cation takes place to the weight when firing is uncorrelated
sitions of objects in a 3D interpretation of the scene to bias       and the post-synaptic neuron is inactive. When construct-
recognition of objects, for example objects in appropriate po-       ing an associative network to reflect conditional probability,
sition and scale relative to other objects in the scene. Other       it is desirable to capture the reverse property, P(y|x). Hebbian
methods include training recognition of pre-defined contex-          learning theory indicates that the emphasis on post-synaptic
tual categories, which are then used to bias interpretation of       activation in the CPCA rule is not an essential property of
individual objects (Torralba, 2003; Torralba, Murphy, Free-          Hebbian learning. When describing the BCM theory, Cooper
man, & Rubin, 2003). Rabinovich, Vedaldi, Galleguillos,              (2004) states that “plasticity will occur only in synapses that
Wiewiora, and Belongie (2007) use a method where an image            are stimulated presynaptically”. This suggests that an alter-
is segmented, and each segment is biased to select a segment         native form emphasising the role of the presynaptic neuron
label that is consistent with other labels in the scene, trained     on synaptic weight changes is appropriate:
using labelled image datasets.
   Context can be loosely defined as a set of consistently co-                      ∆wi j (t + 1) = ηxi (t)(y j (t) − wi j (t))   (2)
occurring features or objects. As such, recognition of asso-
ciations between these features will form a kind of clique,              As a corollary to the conditional dependency measure
where consistent features of a context will be more strongly         reached through training of the CPCA rule (O’Reilly & Mu-
interconnected with each other than with other features. This        nakata, 2000), this training rule converges on the conditional
                                                                     probability P(y j |xi ).
property can be captured in a recurrent network of associ-
ations, where the activation of a number of features will                Nodes in the network represent objects in the environment.
strengthen other features in the same context. Assessment            Training of the network is performed by setting the nodes ac-
of the likelihood of co-occurrence of objects is typically ad-       tive representing objects present, and using the above rule to
dressed using Bayesian statistics, and an associative network        train connections. Weights are adjusted such that the sum of
should reflect this property.                                        weights output from each node sums to one.
                                                                         Evaluation of contextual bias results from activating ob-
   There are limitations with the use of a strictly Bayesian ap-
                                                                     served elements, and running a number of activation steps
proach. For example to evaluate the likelihood of the pres-
                                                                     until the network stabilises. Activation is based on a linear
ence of object ’x’ based on the presence of other objects,
                                                                     neuron model, using an additional inhibitory connection to
measurement of the conditional dependency of pairs such
                                                                     promote stability. Incorporating external activations, this pro-
as P(x|a) and P(x|b) is not sufficient to accurately resolve
                                                                     duces an update rule as follows:
P(x|abc), rather the joint distribution must be recorded in-
dependently. As the number of objects involved grows, the
                                                                                            y j = a j + ∑ xi wi j − εy j          (3)
quantity of statistical measurements required becomes in-                                               i
tractable, and approximate methods are needed, which allow
assumptions of the environment to simplify the task.                 Training an associative clique
   A recurrent network based on co-occurrence pairs provides         To demonstrate the behaviour of the associative network for
a means of approximation, and allows an assessment of the            identifying context, training is performed on a network of 15
activation of element ’x’ based on the activations of a number       elements using a generative model of co-occurrence between
of other elements in the network. Spreading activation net-          the elements, based on a model of co-location. Each of the
                                                                 3066

elements is specified to occur in each of 3 locations with a
given prior probability, and instances are created by selecting
a location and evaluating which elements occur according to
the specified probabilities.
   With training, the weights of the network are shown to con-
verge on the conditional probability values between elements,
roughly indicated by the weight of lines shown in Figure 1.
The presence of associative cliques can be seen between ele-
ments A-E and F-J.
Figure 1: Arrangement of associative network after training.
                                                                    Figure 2: Stable activation level of associative network. All
                                                                    include partial activation of elements E and H. 1. no other
   Behaviour of the network is tested by simulating activation
                                                                    activation, 2. single active (B) 3. two active (B,C) 4. three
of an ambiguous observation, represented as partial activation
                                                                    active, members of the other grouping (F,I,J).
of two elements that are possible interpretations, along with a
number of co-occurring elements. This is done by applying a
value of 0.6 to elements E and H, members of the two domi-
                                                                    and context. A second object is then created as a copy of
nant cliques. Results of activation for an ambiguous pair with
                                                                    the first, with a random collection of symbols altered, such
zero, one, two and three co-occurring elements are shown in
                                                                    that 20% of the representation is varied. The second object
Figure 2. Without contextual activations the ambiguous inter-
                                                                    is attached to a different location, such that it co-occurs with
pretations are not distinguished. With one or more parallel ac-
                                                                    a different set of objects. A third ambiguous object is con-
tivations the elements of the co-occurrence clique are clearly
                                                                    structed by changing each of the modified symbols in the sec-
identified, providing a preference for one of the ambiguous
                                                                    ond object to a third symbol, such that the ambiguous object
interpretations.
                                                                    is equally dissimilar to the first and second.
                      Implementation                                   When the ambiguous object is presented as a replacement
                                                                    to the first or second object, it is necessary for the system to
Object identification
                                                                    identify each of the other objects in the scene independently,
The task used for evaluation is an abstract form of object          and to use the presence of the objects identified to bias inter-
recognition using a generative model, where objects are rep-        pretation of the ambiguous target object.
resented as collections of features arranged in a two dimen-
sional space. This allows statistical properties of the environ-    Context effects with ARCS
ment presented to be controlled.
   Objects are constructed as a random arrangement of feature       Context effects can be incorporated with the ARCS classifier
symbols in a grid. Co-occurrence relationships are created          system, by training the associative network in parallel with
by defining a number of locations, as described previously.         the existing reinforcement process.
Scenes are produced by selecting a location, determining the           Rules are constructed as a two dimensional grid of sym-
objects present according to occurrence statistics, and render-     bols. Each rule is associated with a label indicating the object
ing the chosen objects onto a fixed size grid representing the      classification for the rule. When a state is presented, each
scene. Objects may be obscured by other objects rendered            rule is compared against the state, and a match value estab-
over top.                                                           lished by comparing the rule with each corresponding region
   The task used to perform training, is to identify the object     of the state. To evaluate the match value for each rule for the
at a specified location. Object boundaries are not given.           assigned target position, the best match value covering the
   To evaluate the use of context effects, ambiguous objects        target position is used.
are created, and the task is to identify which object the am-          To select the rule to act, the product of the match value
biguous element represents, based on the co-occurring ob-           with the expected reward of the rule is used. Without using
jects in the scene. To construct an ambiguous representation,       an associative bias, the rule to act is selected according to a
first an object is created and assigned to a specific location      Boltzmann distribution:
                                                                3067

                                eβqn mn
                        Pn =                                  (4)
                             ∑Jj=1 eβq j m j
   where Pn is the probability of choosing rule n, J represents
the set of matching rules, qn is the expected reward and mn
the match level for rule n.
   To introduce contextual bias, a fixed size associative net-
work is used according to the number of object classes
present. Training of the network is conducted after each clas-
sification step. When training with class labels provided, the
activation level of each class present is set to 1, and those
not present set to 0. A single step of the learning process
described in Equation 2 is conducted.
   Once the initial activation values for each class are estab-       Figure 3: Result of the use of associative bias. 1. bias in
lished, the activation process proceeds according to the up-          match condition towards rule consistent with context, 2. per-
date rule given in 3. The resulting activation levels for each        formance improvement for rule set consistent with object rep-
class are normalised, providing a relative value for each class.      resentation, 3. performance improvement for rule set with
This is used to modify the selection value for each rule as fol-      assymetric preference to one interpretation
lows:
                                                                         Results of the degree of bias and improved classification
                               eβqn mn bx
                       Pn =                                   (5)     rates on ambiguous elements are shown in Figure 3. The de-
                            ∑ j=1 eβq j m j by
                              J
                                                                      gree of bias variation provided to classifications consistent
   where bx is the associative bias for object x, where the           with the associative context is +0.5, for example a bias value
given rule is linked with object x.                                   of 0.7 vs 0.2, providing significant discrimination. The re-
   It would be possible to capture context using a rule-based         sult of classification of ambiguous elements without the use
system, for example using a rule specifying that if object A          of associative bias is at chance level, at 0.47%, for a rule
is present at the same time as object B, a particular classifica-     set consistent with the features present in the environment.
tion would be preferred; such an implementation would allow           With introduction of associative bias, allowing context to in-
suitable classification, however involves a design that implies       fluence identification, identification accuracy was increased
the solution, and is based on a discrete definition of context,       to 0.94%, an improvement of 0.47. With a rule set that has
requiring each combination of contextual features to be de-           developed in a manner that is preferential to one interpreta-
fined at the rule level. In contrast, the associative method          tion of an ambiguous element, the improvement is 0.25.
allows contextual effects between a range of elements to be              These figures show clear discrimination between interpre-
captured in the network, using a soft definition of context aris-     tations of ambiguous elements, as a result of bias introduced
ing from activation properties of the network.                        through association, with lesser improvement when assym-
                                                                      metric preference is given to one interpretation.
                            Results
Training is first conducted with object labels available for                        Discussion and Conclusions
each position, before evaluation is performed on observations         This system provides an autonomous method for studying
without labels. A number of training stages are used to sim-          processes involved in formation of concepts relevant to a
plify the learning process. First training is conducted on in-        task, guided by reinforcement from behaviour, in tandem with
dividual objects, where a single object is presented for each         the recognition of context through co-occurrence relation-
step. After 200,000 training steps, classification is performed       ships captured in an associative network. The development
with 100% accuracy on individually presented objects. The             of features autonomously according to reinforcement, acting
second training stage involves classification with multiple ob-       alongside formation of contextual associative links, provides
jects present, and introduces training of the associative net-        a novel means of studying formation of context, and the man-
work.                                                                 ner in which it can be used to influence a task.
   Observations are presented using a 30 x 30 grid of features,          The interaction of the two types of systems allows the
each object is constructed using on average 34 symbols, in-           use of a simplified associative implementation, acting in tan-
cluding white space. 4 locations are used to generate the en-         dem with the reinforcement based learning process, to allow
vironment, with 25 objects, as well as 2 ambiguous represen-          context identified between multiple elements to influence the
tations.                                                              recognition of objects being observed.
   Evaluation is performed by presentation of multiple objects           The reinforcement based system provides a useful platform
in a scene, including ambiguous objects, which require the            for examining practical considerations of such processes in an
use of context for identification.                                    objective, autonomous manner. Representation of context is
                                                                  3068

captured in attractor basins produced from associative links         and localization using sparse features with limited recep-
in a recurrent network. The advantages provided for the in-          tive fields. International Journal of Computer Vision, 80(1),
terpretation of objects, and the ability to identify context in      45–57.
an autonomous manner, highlight the applicability of a recur-       Oliva, A., & Torralba, A. (2006). Building the gist of a
rent associative network for addressing how context can be           scene: the role of global image features in recognition. In
formed and utilised.                                                 S. Martinez-Conde, S. Macknik, L. Martinez, J.-M. Alonso,
                                                                     & P. Tse (Eds.), Visual perception - fundamentals of aware-
                         References                                  ness: Multi-sensory integration and high-order perception
                                                                     (Vols. 155, Part 2, p. 23 - 36). Elsevier.
Anderson, J. R. (1996). The architecture of cognition. Cam-
                                                                    Oliva, A., & Torralba, A. (2007). The role of context in
  bridge, MA, USA: Harvard University Press.
                                                                     object recognition. Trends in Cognitive Sciences, 11(12),
Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S.,
                                                                     520–527.
  Lebiere, C., & Qin, Y. (2004). An integrated theory of
                                                                    O’Reilly, R. C. (2001). Generalization in interactive net-
  the mind. Psychological Review, 111(4), 1036–1060.
                                                                     works: The benefits of inhibitory competition and hebbian
Auckland, M., Cave, K., & Donnelly, N. (2007). Nontar-
                                                                     learning. Neural Computation, 13(6), 1199-1241.
  get objects can influence perceptual processes during object
                                                                    O’Reilly, R. C., & Munakata, Y. (2000). Computational
  recognition. Psychonomic bulletin & review, 14(2), 332.
                                                                     explorations in cognitive neuroscience: Understanding the
Baddeley, A., Eysenck, M. W., & Anderson, M. C. (2009).
                                                                     mind by simulating the brain (1st ed.). Cambridge, MA,
  Memory. Hove, UK: Psychology Press.
                                                                     USA: MIT Press.
Baddeley, A. D. (1997). Human memory: Theory and prac-
                                                                    Parikh, D., Zitnick, C., & Chen, T. (2009). Unsupervised
  tice. Hove, UK: Psychology Press.
                                                                     learning of hierarchical spatial structures in images. In
Bar, M. (2004). Visual objects in context. Nature Reviews
                                                                     IEEE conference on computer vision and pattern recogni-
  Neuroscience, 5(8), 617–629.
                                                                     tion (pp. 2743–2750).
Bar, M. (2007). The proactive brain: using analogies and            Rabinovich, A., Vedaldi, A., Galleguillos, C., Wiewiora, E.,
  associations to generate predictions. Trends in Cognitive          & Belongie, S. (2007, oct.). Objects in context. In IEEE
  Sciences, 11(7), 280–289.
                                                                     international conference on computer vision (p. 1 -8).
Bengio, Y. (2009, January). Learning deep architectures for         Ranzato, M., Huang, F. J., Boureau, Y.-L., & LeCun, Y.
  ai. Found. Trends Mach. Learn., 2, 1–127.                          (2007). Unsupervised learning of invariant feature hierar-
Bull, L., & Kovacs, T. (2005). Foundations of learning clas-         chies with applications to object recognition. In IEEE con-
  sifier systems. Berlin: Springer-Verlag.                           ference on computer vision and pattern recognition (p. 1
Cooper, L. (2004). Theory of cortical plasticity. Singapore:         -8).
  World Scientific Pub Co Inc.                                      Samson, R., Frank, M., & Fellous, J.-M. (2010). Com-
Drugowitsch, J. (2008). Design and analysis of Learn-                putational models of reinforcement learning: the role of
  ing Classifier Systems: A probabilistic approach. Berlin:          dopamine as a reward signal. Cognitive Neurodynamics,
  Springer.                                                          4, 91-105.
Haykin, S. (1998). Neural networks: A comprehensive foun-           Sutton, R., & Barto, A. (1998). Reinforcement learning: An
  dation (2nd ed.). Upper Saddle River, NJ, USA: Prentice            introduction. Cambridge, MA: MIT Press.
  Hall PTR.                                                         Tenenbaum, J. B., Griffiths, T. L., & Kemp, C. (2006).
Hoiem, D., Efros, A., & Hebert, M. (2008). Putting objects           Theory-based bayesian models of inductive learning and
  in perspective. International Journal of Computer Vision,          reasoning. Trends in Cognitive Sciences, 10(7), 309 - 318.
  80(1), 3–15.                                                      Torralba, A. (2003). Contextual priming for object detection.
Kahneman, D., Slovic, P., & Tversky, A. (1982). Judgment             International Journal of Computer Vision, 53, 169-191.
  under uncertainty: heuristics and biases. New York: Cam-          Torralba, A., Murphy, K., Freeman, W., & Rubin, M. (2003,
  bridge University Press.                                           oct.). Context-based vision system for place and object
Knittel, A. (2010). An activation reinforcement based clas-          recognition. In IEEE international conference on computer
  sifier system for balancing generalisation and specialisa-         vision (p. 273 -280 vol.1).
  tion (arcs). In Gecco ’10: Proceedings of the 12th annual         Wilson, S. W. (1995). Classifier fitness based on accuracy.
  conference on genetic and evolutionary computation (pp.            Evolutionary Computation, 3(2), 149-175.
  1871–1878). New York, NY, USA: ACM.                               Yuille, A., & Kersten, D. (2006). Vision as bayesian infer-
Knittel, A., Bossomaier, T., & Snyder, A. (2007). Concept ac-        ence: analysis by synthesis? Trends in Cognitive Sciences,
  cessibility as basis for evolutionary reinforcement learning       10(7), 301 - 308.
  of dots and boxes. In IEEE symposium on computational             Zhu, L., Lin, C., Huang, H., Chen, Y., & Yuille, A. (2008).
  intelligence and games.                                            Unsupervised structure learning: hierarchical recursive
Kokkinos, I., & Yuille, A. (2009). HOP: Hierarchical object          composition, suspicious coincidence and competitive ex-
  parsing. CVPR, 0, 802-809.                                         clusion. ECCV, 759–773.
Mutch, J., & Lowe, D. (2008). Object class recognition
                                                                3069

