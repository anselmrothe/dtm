UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A computational theory of human perceptual mapping
Permalink
https://escholarship.org/uc/item/2xs33177
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Yeap, Wai
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                          A computational theory of human perceptual mapping
                                                W. K. Yeap (wai.yeap@aut.ac.nz)
                                               Centre for Artificial Intelligence Research
                                          Auckland University of Technology, New Zealand
                             Abstract                                   However, these views need to be organized into a coherent
   This paper presents a new computational theory of how
                                                                        global map and a method has been suggested. It requires
   humans integrate successive views to form a perceptual map.          recognizing objects found in the selected views in all the in-
   Traditionally, this problem has been thought of as a                 between views that have not been selected. These objects
   straightforward integration problem whereby position of              allow one to triangulate one’s position in the map and add
   objects in one view is transformed to the next and combined.         new views to the map in their appropriate position. The
   However, this step creates a paradoxical situation in human          theory has been tested successfully with different
   perceptual mapping. On the one hand, the method requires             implementations on mobile robots and the resulting maps
   errors to be corrected and the map to be constantly updated,
   and yet, on the other hand, human perception and memory              produced were found to exhibit several interesting
   show a high tolerance for errors and little integration of           characteristics of a human perceptual map.
   successive views. A new theory is presented which argues
   that our perceptual map is computed by combining views only                           A Perceptual Paradox?
   at their limiting points. To do so, one must be able to
   recognize and track familiar objects across views. The theory
                                                                           Researchers who investigated how spatial memories are
   has been tested successfully on mobile robots and the lessons        organised often suggest the existence of a two-system
   learned are discussed.                                               model: an egocentric model and an allocentric model (Mou,
                                                                        McNamara, Valiquette & Rump, 2004; Burgess, 2006;
   Keywords: perceptual map; cognitive map; spatial layout;
   spatial cognition.
                                                                        Rump & McNamara, 2007). These two models are very
                                                                        different implementations of the same basic mathematical
                          Introduction                                  model described above and therefore have different costs
                                                                        associated with their use. In particular, the former keeps
   How do humans integrate successive views to form a                   track of the relationship between the self and all objects
perceptual map? The latter is a representation of the spatial           perceived. As one moves, one needs to constantly update all
layout of surfaces/objects perceived in one’s immediate                 objects position in memory with respect to the viewer’s new
surroundings. That we have such a map is evident in that we             position. The latter creates a global map of all objects
do not immediately forget what is out of sight when we turn             perceived using a frame of reference independent of the
or move forward (see Glennerster, Hansard & Fitzgibbon                  viewer’s position. These researchers claimed that the former
(p.205, 2009) for a similar argument). However, researchers             is best suited for organising information in a perceptual map
studying this problem from four different perspectives,                 while the latter is best for a cognitive map. However, little is
namely how we represent our environmental knowledge                     said about how information encoded in an egocentric
(i.e. a cognitive map (Tolman, 1948; O’Keefe & Nadel,                   perceptual map is transferred into an allocentric cognitive
1978)), what frame of references we use, how we see our                 map. If this is achieved via switching frame of reference,
world, and how robots create a map of their own world,                  then the process is straightforward and from a mathematical
have offered solutions which when taken together create a               standpoint, the two representations are considered
paradoxical situation. It is noted that because the problem             equivalent. In this case, a perceptual map is a subset of a
lends itself to a straightforward mathematical solution                 cognitive map and holds only the most recently perceived
whereby information in one view is transformed to their                 information.
respective positions in the next view, much of the current                 Researchers who investigated the nature of cognitive
studies implicitly or explicitly assume that a solution to this         maps from studying resident’s memory of their environment
problem would involve such a step. This step is problematic             (both adults and children) often emphasized that the map is
when used to explain how humans integrate their views and               fragmented, incomplete and imprecise (e.g. Lynch, 1960;
the lack of an alternative method has hampered progress.                Downs & Stea, 1973, Evans, 1980). This does not mean that
   In this paper, a new computational theory of human                   the map is devoid of metric information but rather, one’s
perceptual mapping is presented. It abandons the idea of                memory of such information is often found to be distorted
integrating successive views to form a perceptual map.                  systematically as a result of applying cognitive organizing
Instead, it argues that what is afforded in a view is an                principles (Tversky, 1992). Some well-known examples of
adequate description of the current spatial local environment           these distortions include the regularization of turns and
and hence it does not need to be updated until one moves                angles (Byrne, 1979), and over- and under- estimation of
out of it. Only then, another view is added to the map. As a            distances due to factors such as direction of travel (Lee,
result, the map is composed of views selected at different              1970), presence of barriers (Cohen & Weatherford, 1981),
times during one’s exploration of the environment.                      and others. More recent studies have also shown that metric
                                                                   429

knowledge could be learned very early in one’s exposure to          mathematical process used is aimed at producing an
a new environment (Ishikawa & Montello, 2006; Buchner &             accurate map.
Jansen-Osmann, 2008). In Ishikawa and Montello’s (2006)
study, they also found large individual differences. Most
participants either manifested accurate metric knowledge
from the first session or they didn’t, and knowledge of both
groups did not show much improvement in some subsequent
trials. Note that by accurate, it is meant that participants
could “estimate directions and distances, and draw sketch
maps more accurately after first exposure to the routes than
would be expected by pure chance alone” (p. 118). All these
observations on the nature of cognitive maps suggest that
one’s perceptual map should also be fragmented, incomplete
and imprecise.
                                                                           Figure 2. The test environment and the robot’s path
                                                                       If the perceptual map is necessary to be precise, it is
                                                                    surprising that our perceptual system has not evolved to
                                                                    support such computations. Take vision, for example. Our
                                                                    visual perception of the world is highly illusory (Hurlbert,
                                                                    1994; Snowden, 1999) and thus, unlike computer vision,
                                                                    what we get is not a true geometrical description of what is
                                                                    out there (Fermuller, Cheong & Aloimonos, 1997;
                                                                    Bridgeman & Hoover, 2008; Glennerster, Hansard &
                                                                    Fitzgibbon, 2009). We have high visual acuity only in the
                                                                    small foveal region of the retina and thus a large part of our
                    Figure 1. A distorted map                       input lacks clarity and detail. Our eyes need to make rapid
                                                                    movements (known as saccades) to bring different regions
   Yet, robotics researchers (e.g Thrun, 2008) who have             into the foveal. Experiments on whether humans integrate
been developing mapping algorithms using the                        successive views at the saccade level reveal that we fail to
transformation approach have shown that the map produced            notice many kinds of changes occurring between saccades.
must be as accurate as possible. Errors found in robot sensor       This phenomenon is known as “change blindness” (see
readings are known to seriously affect the map created.             reviews of such work in Irwin, 1996; Intraub, 1997; Irwin &
Figure 1 shows a typically distorted map computed by a              Zelinsky, 2002; Simos & Rensink, 2005) and it argues
mobile robot equipped with a laser sensor and without using         against the idea that successive views are integrated to form
any error correction procedure. The robot’s path is as shown        a single unified representation.
in Figure 2 and a rectangular shaped map should have been              The above studies, when taken together, raise serious
produced instead of the triangular one shown in Figure 1.           doubts as to the appropriateness of a transformational
With the map computed, one would have difficulties                  approach to human perceptual mapping.
orienting oneself and there is also a danger that one could
easily mistaken that one is returning to a familiar part of the          A Theory of Human Perceptual Mapping
environment. For example, at point C, the robot should be at           Logically, a perceptual map is a representation of the
point B in the physical space and the robot could thus be           environment, as it is perceived. Thus, its input is a sequence
mistaken that it is re-entering a familiar part of the              of views, each being an integrated representation of
environment. Robotics research thus tells us that errors            information delivered by all its sensors. For simplicity, one
cannot be left unchecked when using such a procedure to             could consider information from a single sensor and
compute a map. In short, the map computed needs to be               especially if it is the most important sensor. For humans,
precise. With hindsight, this is not surprising since the           this is vision. With vision, Yeap (1998) argued that the input
                                                                430

should be at the level of Marr’s (1982) 2½D sketch - a             that the position of these points is always identified
representation describing the shape and disposition of             accurately and thus the map produced will be rough and
surfaces relative to the viewer. Yeap and Jefferies (1999)         vary among different individuals. The latter is a point
further argued that one should made explicit representations       emphasized in Ishikawa and Montello’s (2006) study
of local environments in a perceptual map and that these           mentioned earlier.
representations are computed from integrating successive              A general algorithm for implementing this new theory can
views. The latter idea is again reminiscent of what was            now be specified. Let PM be the perceptual map, V0 be
discussed earlier and must now be discarded.                       one’s initial view, and R be some reference objects
   If a representation of one’s local environment is not           identified in V0. Initialise PM with V0. For each move
computed from integrating successive views, what could be          through the environment, do:
the alternative? In finding an answer, we make two
observations. First, observe that a view affords us more than         Move and update:
a description of the surfaces in front of us. It tells us what       1. Execute move instruction and get new view, Vn.
and where things are, where we can move to next, what                2. Search for the reference objects in Vn and remove from
events are unfolding, where there might be dangers, and                   R those that are not found.
others (Gibson, 1950). In short, a view is in fact a                 3. If R still contains a sufficient number of reference
significant representation of a local environment and it                  objects, go to step 1.
should be made explicit in the map as a description of a             4. Expand PM, create a new R and go to step 1
local environment rather than as some spatially organised
surfaces. Second, observe that the world we live in is                In summary, the theory specifies that what is made
relatively stable. That is, it does not change much when we        explicit in a perceptual map is an integrated global
blink our eyes or take a few steps forward. As such, there is      representation of views selected during a journey. This is
no immediate need to update the view in our perceptual map         because each of these views provides an adequate
as we move. For example, consider your first view of a             description of the spatial layout of the local environment
corridor when entering it and assume an exit can be seen at        experienced. The basic algorithm for implementing the
the other end. If you walk down this corridor to the exit,         theory involves recognising objects in the current view that
then the description of the corridor space afforded in the         were remembered in the perceptual map, and using them to
first view adequately describes the local environment you          triangulate position of unknown objects (including the self)
are going through. Updating this description to include, for       in the map. Compared to the traditional approach, this
example, a view of a room besides the corridor as you walk         approach offers a simpler and less computationally
past it will enrich the description, but is unnecessary if the     expensive method for computing a perceptual map.
room is not entered.
   The tricky part of the problem is: if one does not                          On Implementation and Results
constantly update the view in the map as one moves, how               Does the theory work? Can it produce a reasonably
does one know where one is in the map or that one is still in      accurate perceptual map? One way to test the theory is to
the current local environment? Also, when does one begin           implement it and as Marr (1982) argued, the significance of
to update the map and how? One possible solution is to keep        a computational theory is that its implementation can be
track of objects seen in the initial view in all subsequent        done independently. Hence, the theory was tested on a
views. If some could be found, one could triangulate one’s         different platform – a mobile robot equipped with a laser
position in the map and thus localising oneself. However, at       sensor1. The details of our implementations will be reported
some limiting points, one will not be able to do so and this       elsewhere. This section highlights some key aspects of the
is when one needs to expand the map to include a new view          implementation and the lessons learned so that in the next
(albeit, a new local environment). If the new view to be           section, the significance of the theory is discussed with a
added is selected at a point just before reaching a limiting       concrete example.
point, it could be added to the map using the same method             To begin with, the theory leaves open two key
of triangulation. From a human perceptual mapping                  implementation issues, namely how and what objects are
standpoint, this solution is attractive since humans have          selected for tracking across views, and how and when a new
developed powerful mechanisms for recognising objects.             view is added to the perceptual map. These issues would
   Two points regarding the application of this method are         depend on the kind of perceptual apparatus one has and
worth noting here. First, for this method to work, it is           one’s needs in dealing with the environment. For our robot,
important that one is able to track objects across successive      the following is implemented. Laser points in each view are
views and for human vision, the fact that there is significant     turned into lines denoting surfaces perceived. Any
overlap between views ensures that this could be done.             reasonably sized surfaces with at least an occluding edge are
Second, the accuracy of this method depends on how
accurately one can identify the position of the tracked               1
                                                                       In reality, the reverse is true. The perceptual mapping problem
objects in the map (or more precisely, the position of those       was first investigated by considering how a robot, although with a
points needed for triangulation). For humans, it is unlikely       different sensor, could solve a similar perceptual mapping
                                                                   problem. I refer to such robots as “albots” (Yeap, 2011).
                                                               431

tracked across views. The latter condition is imposed to
ensure a good reference point exists for calculating the
relative position of other surfaces in the map. Using laser,
one’s ability to perform recognition is limited. Thus, to
track these surfaces between views, we use the traditional
transformation method to locate them. To decide when to
add a new view, the robot first detects if it has exited the
local environment (by detecting that its current view has
less than two tracked surfaces). Then it adds its previous
view to the map (since with less than two tracked surfaces
in the current view, it cannot add the current view to the
map). When adding a new view, no attempt is made to
update overlapping surfaces between the two views. All
information in the perceptual map that occupies the same
area covered by the current view will be deleted and
replaced by what is in the view. The rationale here is that
details are unimportant as long the overall shape of the
environment is maintained.
            Figure 3. The perceptual map produced.
   The robot algorithm used in this implementation is:
   1. Execute move instruction and get a new view, Vn.
   2. If it is a turn instruction, use Vn to expand PM and                     Figure 4. A trace of the mapping process
       create a new R. Go to step 1.
   3. Search for the reference objects in Vn by                      Figure 3 shows the perceptual map produced as the robot
       transforming previous view to the new view using the       traversed the path through the environment in Figure 2. The
       mathematical transformation approach.                      dotted line indicates the approximate path of the robot.
   4. If less than two objects are found, use Vn-1 to expand      Points A (start) and B (end) should be the same points.
       PM and Vn to create a new R. To expand PM, one             Unlike the map as shown in Figure 1, this map preserves the
       replaces what is in front of the robot in PM with what     overall shape of the environment visited. Figure 4 (left
       is seen in Vn-1. Go to step 1.                             column) shows four consecutive steps of the robot. The
   5. Remove reference objects in R that are no longer in         right column shows the map expanded only ay the fourth
       view. Go to step 1.                                        step. The circle marks what information is missing in the
                                                                  map. Note that the position of the robot in the map (the little
                                                                  arrows) is estimated and it does not correspond to the exact
                                                                  position of the robot in the physical environment.
                                                              432

                         Discussion                                 information perceived. One fixates using the high visual
                                                                    acuity region, which provides detailed reference object
   The perceptual map shown in Figure 3 is imprecise and
                                                                    information. This aids later recognition and working out the
incomplete in the sense that it is not accurate in metric terms
                                                                    position of other objects in the perceptual map.
and has perceived surfaces missing. Yet, the overall shape
                                                                       Glennerster et al. (2009) provide an alternative
of the environment experienced is maintained (as compared
                                                                    explanation for the above observation to support their idea
with the map in Figure 1). The theory thus works, at least on
                                                                    that humans do not continuously integrate successive views
a mobile robot.
                                                                    into a precise integrated 3D model. The reason for the latter
   The present implementation, using a mobile robot with a
                                                                    is to explain an interesting finding from their experiments
perceptual system different from that of humans, shows that
                                                                    showing humans failure to notice the expansion of a room
one can select different kinds of information as a reference
                                                                    around them in an immersive virtual environment. To
object. This demonstrates the generality of this new
                                                                    account for their findings, they proposed that humans
approach. For humans, one expects a more complex method
                                                                    compute a view graph of their environment rather than a
to select the reference objects in view. For the robot using a
                                                                    precise 3D model. Each node in the graph is a stored
laser sensor, it is limited to selecting 2D line surfaces.
                                                                    snapshot of a scene and the link between them records the
Although the map computed by the robot is incomplete and
                                                                    motor output required to move between nodes. The view
imprecise, it is complete and precise in the sense that the
                                                                    graph idea is also popular for modeling animal spatial
overall shape of the environment is well preserved. This is
                                                                    behavior and for robots (e.g Scholkopf & Mallot, 1995).
partly due to the choice of information used as reference
                                                                    However, they noted the view graph idea does not explain
objects and partly due to the fact that the test environment is
                                                                    how different views are combined to form a consistent
indoors. Both conditions enable the robot to detect several
                                                                    representation, i.e. a perceptual map. They claimed that this
reference objects appearing directly in front of, and not far
                                                                    is an important and unsolved challenge. Interestingly, the
from, the robot. Consequently, the perceptual map is
                                                                    theory proposed here could be considered as view-based
expanded more frequently, producing a more complete map.
                                                                    since each local environment entered into the perceptual
Furthermore, occluding edges of the reference targets
                                                                    map is an individual view of the environment. However,
provide good reference points for relative positioning of
                                                                    each view is not captured as a node in a graph and there is
new information and the laser sensor provides accurate
                                                                    no encoding of instructions to move from one node to the
distance measurement of these points and especially if they
                                                                    other. This theory provides a possible mechanism for
are not too far away. Both conditions enable a fairly
                                                                    integrating views to build a global map.
accurate map to be computed. From a robotics perspective,
                                                                       That the perceptual map is not updated from each
the map computed is considered surprisingly accurate since
                                                                    successive view is strongly supported by the change
no error correction was done at the sensing level.
                                                                    blindness phenomenon. However, there is often a claim
   The perceptual map thus varies in details, both in terms of
                                                                    among these researchers that change blindness argues for a
precision and completeness due to how often the map is
                                                                    rethinking of how vision works and that no global map is
expanded and the accuracy of the information used for
                                                                    computed. As O’Regan (1992) puts it succinctly: “the
expanding the map. This variability can explain the
                                                                    outside world is considered as a kind of external memory
individual differences of human perceptual maps (Ishikawa
                                                                    store which can be accessed instantaneously by casting
and Montello, 2006). In an outdoor environment, it is likely
                                                                    one’s eyes to some location.” This theory provides an
that one selects reference objects consisting of large and
                                                                    alternative way in which a global map can be computed
easily visible distant objects. If so, one’s perceptual map
                                                                    without updating from each successive view and it is
might not be expanded that often and consequently, one can
                                                                    evidently clear that such a map is much needed in our
experience not remembering much even through one has
                                                                    interaction with the environment (Glennerster et al., 2009).
walked through a locally complex environment. In such
                                                                    The fact that the map is not constantly updated could also
cases, what is remembered can be the reference objects
                                                                    explain why our perception of the world is a stable one. If
themselves. This might explain the emergence of landmarks
                                                                    one were to use the transformation method, then the
in cognitive maps. The theory thus predicts some target
                                                                    locations of all the points in the map are constantly adjusted
features in one’s perceptual map will become landmarks in
                                                                    to accommodate what is in the current view. If one were to
one’s cognitive map under the circumstances described.
                                                                    trace the map computed at each step, one could see the
   The use of reference objects to expand a perceptual map
                                                                    shape of the map changes constantly as it adjusts the errors
has support in the literature on human vision. It has been
                                                                    in the map. This is not the case here. The local environment
reported that nearly all animals with good vision fixate on
                                                                    once perceived in a given view will not change until much
an object as they move, followed by some fast saccades that
                                                                    later. This gives the impression of having a very stable map
shift the direction of gaze (Carpenter, 1988; Land, 1999).
                                                                    (see Figure 4).
These studies focused on why we have saccades but for the
present study, it is the fixation of the eyes on an object that
is more revealing. Such a mechanism allows humans (and                                       Conclusion
animals) to locate and fixate on a reference object as they           A computational theory of human perceptual mapping is
move and then uses saccades to improve the quality of the           presented which shows how a perceptual map is computed
                                                                433

without integrating successive views. The theory is               Irwin, D.E. (1996). Integrating information across saccadic
supported by various accounts of how humans perceive their          eye movements. Current Directions in Psychological
world and in particular our lack of attention to changes and        Science, 5, 94-100
the illusory nature of our perception. The theory has             Irwin, D.E., & Zelinsky, G.J. (2002). Eye movements and
provided tentative account of various observations about            scene perception: Memory for things observed.
human spatial cognition and in particular how a stable world        Perception & Psychophysics, 64, 882-895
is perceived and how landmarks might emerge. The                  Ishikawa, T., & Montello, D.R. (2006). Spatial knowledge
implementation of the theory shows how the map computed             acquisition from direct experience in the environment:
is both imprecise and incomplete and yet still preserves a          Individual differences in the development of metric
good shape of the environment. The implementation also              knowledge and the integration of separately learned
shows how the theory could be implemented differently to            places. Cognitive Psychology, 52, 93-129
produce map with different precisions and details and this        Lee, T. (1970). Perceived distance as a function of direction
was offered as an explanation as to why individual                  in the city. Environment and Behavior, 2, 40-51
differences are observed.                                         Lund, M.F. (1999). Motion and vision: Why animals move
                                                                    their eyes. Journal of Comparative Physiology A, 185,
                   Acknowledgments                                  341-352
I would like to thank my students, Zati Hakim, Md. Zulfikar       Lynch, K. (1960). The image of the city. Cambridge, MA:
Hossain, and Thomas Brunner, who have collaborated on               MIT Press.
this project, and to the reviewers who have given valuable        Marr, D. (1982). Vision. San Francisco, CA: Freeman.
comments.                                                         Mou, W., McNamara, T.P., Valiquette, C.M., & Rump, B.
                                                                    (2004). Allocentric and egocentric updating of spatial
                                                                    memories. Journal of Experimental Psychology:
                        References                                  Learning, Memory, and Cognition, 30, 142-57
Bridgeman, B. & Hoover, M. (2008). Processing spatial             O’Keefe, J., & Nadel, L. (1978). The hippocampus as a
   layout by perception and sensorimotor interaction.               cognitive map. Oxford: Clarendon Press
   Quarterly Journal of Experimental Psychology, 61, 851-         O’Regan, J.K. (1992). Solving the “real” mysteries of visual
   859                                                              perception: The world as an outside memory. Canadian
Buchner, S., & Jansen-Osmann, P. (2008). Is route learning          Journal of Psychology, 46, 461-488
   more than serial learning? Spatial Cognition and               Rump, B., & McNamara, T.P. (2007). Updating in models
   Computation, 8, 289-305                                          of spatial memory. In Barkowsky, T.; Knauff, M.;
Burgess, N. (2006). Spatial memory: How egocentric and              Ligozat, G.; and Montello, D.R. eds. Spatial Cognition V
   allocentric combine. Trends in Cognitive Sciences,               Reasoning, Action, Interaction. Berlin, Heidelberg.:
Byrne, R.W. (1979). Memory for urban geography.                     Springer.
   Quarterly Journal of Experimental Psychology, 31, 147-         Scholkipf, B., & and Mallot, H.A. (1995). View-based
   154                                                              cognitive mapping and path planning. Adaptive Behavior,
Carpenter, R.H.S. (1988). Movements of the eyes. London:            3, 311-348
   Pion Ltd.                                                      Simons, D.J., & Rensink, R.A. (2005). Change blindness:
Cohen, R. & Weatherford, D.L. (1981). The effect of                 Past, present, and future. Trends in Cognitive Sciences, 9,
   barriers on spatial representations. Child Development,          16-20
   52, 1087-1090                                                  Snowden, R.J. (1999). Visual perception: Here’s mud in
Downs, R.M., & Stea, D. (1973). Image and environment:              your mind’s eye. Current Biology, 9, R336-R337
   Cognitive mapping and spatial behaviour. Chicago:              Tolman, E.C. (1948) Cognitive maps in rats and men.
   Aldine.                                                          Psychological Review, 55, 189-208
Evans,      G.W.     (1980).     Environmental     cognition.     Thrun, S. (2008). Simultaneous localization and mapping.
   Psychological Bulletin, 88, 259-287                              In M.E. Jefferies & W.K. Yeap (Eds.), Robotics and
Fermuller, C., Cheong, L.F., & Aloimonos, Y. (1997).                Cognitive Approaches to Spatial Mapping. Springer
   Visual space distortion. Biological Cybernetics, 77, 323-        Tracts in Advanced Robotics.
   337                                                            Tversky, B. (1992). Distortions in cognitive maps.
Glennerster, A., Hansard, M.E., & Fitzgibbon, A.W. (2009).          Geoforum, 23, 131-138
   View-based approaches to spatial representation in human       Yeap, W.K. (1988). Towards a computational theory of
   vision. In D. Cremers, B. Rosenhahn, A.L. Yuille, & F.R.         cognitive maps. Artificial Intelligence 34, 297-360
   Schmidt, (Eds.), Statistical and Geometrical Approaches        Yeap, W.K., & Jefferies, M.E (1999). Computing a
   to Visual Motion Analysis. Berlin: Springer-Verlag.              representation of the local environment. Artificial
Hurlbert, A.C. (1994). Knowing is seeing. Current Biology,          Intelligence 107, 265-301
   4, 423-426                                                     Yeap, W.K. (2011). How Albot0 finds its way home: A
Intraub, H. (1997). The representation of visual scenes.            novel approach to cognitive mapping using robots. Topics
   Trends in Cognitive Sciences, 1, 217-222                         in Cognitive Science, in press
                                                              434

