UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Classroom-based Experiments in Productive Failure
Permalink
https://escholarship.org/uc/item/7761h4h2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Kapur, Manu
Bielczyz, Katerine
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                             Classroom-based Experiments in Productive Failure
                                                   Manu Kapur & Katerine Bielaczyc
                                                  National Institute of Education, Singapore
                              Abstract                                    discovery learning compared with direct instruction (for
We present evidence from three quasi-experimental studies on              reviews, see Kirschner et al., 2006).
productive failure. In Experiment 1, students experienced either             However, we question whether there is little efficacy in
direct instruction (DI) or productive failure (PF), wherein they          having learners solve problems that target concepts they
were first asked to generate a quantitative index for variance before
receiving direct instruction on the concept. Experiment 2 examined
                                                                          have not learnt yet. To determine if there such an efficacy, a
if it was necessary for students to generate solutions or can these       stricter comparison for direct instruction would be to
solutions be simply given to the students to study and evaluate.          compare it with an approach where students first generate
Experiment 3 examined if it was necessary for students to generate        representations and methods on their own followed by direct
solutions before receiving the critical features of the targeted          instruction. As it can be expected, the generation process
concept, or would simply telling the critical features without any        will invariably lead to failure, that is, students are rarely
such generation work just as well. In Experiment 1, PF students           able to solve the problems and discover the canonical
performed on par with DI students on procedural fluency, and              solutions by themselves. Yet, this very process can be
significantly outperformed them on data analysis and conceptual           productive for learning provided direct instruction on the
insight items. In Experiment 2, only the effects on conceptual
insight and near transfer were significant. In Experiment 3, only
                                                                          targeted concepts is subsequently provided (Schwartz &
the effect on conceptual insight remained significant. Overall,           Martin, 2004). As a case in point, we present evidence from
these results challenge the claim that that direct instruction alone is   our research program on productive failure (Kapur, 2008).
the most effective approach for teaching novel concepts to
learners.                                                                            Designing for Productive Failure
                                                                          Productive failure focuses on engaging students in processes
                          Introduction                                    that serve two critical cognitive functions, which in turn,
Proponents of direct instruction bring to bear substantive                prepare students for subsequent direct instruction: a)
empirical evidence against un-guided or minimally-guided                  activating and differentiating prior knowledge in relation to
instruction to claim that there is little efficacy in having              the targeted concepts, and b) affording attention to critical
learners solve problems that target novel concepts, and that              features of the targeted concepts. PF comprises two
learners should receive direct instruction on the concepts                phases—a generation and exploration phase followed by a
before any problem solving (Kirschner, Sweller, & Clark,                  direct instruction phase. In the generation and exploration
2006). Kirschner et al. (2006) argued that “Controlled                    phase, the focus is on affording students the opportunity to
experiments almost uniformly indicate that when dealing                   leverage their formal as well as intuitive prior knowledge
with novel information, learners should be explicitly shown               and resources to generate a diversity of solutions for a
what to do and how to do it” (p. 79). Based on cognitive                  complex problem; a problem that targets concepts that they
load theory, commonly-cited problems with un-guided or                    have not yet learnt. Research suggests that students do have
minimally-guided instruction include increased working                    rich constructive resources (diSessa & Sherin, 2000) to
memory load that interferes with schema formation                         generate a variety of solutions for novel problems. At the
(Tuovinen & Sweller, 1999; Sweller, 1988), encoding of                    same time, research also suggests that one cannot expect
errors and misconceptions (Brown & Campione, 1994), lack                  students, who are novices to the target content, to somehow
of adequate practice and elaboration (Klahr & Nigam,                      generate or discover the canonical representations and
2004), as well as affective problems of frustration and de-               domain-specific methods for solving the problem (Kirschner
motivation (Hardiman et al., 1986).                                       et al., 2006).
   Klahr & Nigam’s (2004) often-cited study compared the                      However, the expectation for the generation and
relative effectiveness of discovery learning and direct                   exploration phase is not for students to be able to solve the
instruction approaches on learning the control of variable                problem successfully. Instead, it is to generate and explore
strategy (CVS) in scientific experimentation. On the                      the affordances and constraints of a diversity of solutions for
acquisition of basic CVS skill as well as ability to transfer             solving the problem. Our hypothesis is that this process both
the skill to evaluate the design of science experiments, their            activates and differentiates prior knowledge (as evidenced in
findings suggested that students in the direct instruction                the diversity of student-generated solutions). Furthermore, a
condition who were explicitly taught how to design un-                    comparison and contrast between the various solutions
confounded experiments outperformed their counterparts in                 affords opportunities to attend to critical features of the
the discovery learning condition who were simply left alone               targeted concept. Consequently, the generation and
to design experiments without any instructional structure or              exploration phase provides the necessary foundation for
feedback from the instructor. Further experiments by Klahr                developing deeper understanding of the canonical concept
and colleagues (e.g., Strand-Cary & Klahr, 2008), and                     during direct instruction (Kapur, 2009, 2010a/b; Schwartz &
others as well have largely bolstered the ineffectiveness of              Martin, 2004).
                                                                        2812

                            Purpose                                problems for homework, which the teacher marked and
                                                                   returned to the students, usually by the following period.
The purpose of this paper is to report three quasi-
                                                                      The PF condition differed from the DI condition in one
experimental studies that help unpack the efficacy of the
                                                                   important aspect. Instead of receiving direct instruction
productive failure (PF) effect. In Experiment 1, we compare
                                                                   upfront, students spent two periods working face-to-face in
PF with direct instruction (DI) to show that PF engenders
                                                                   triads to solve one of the data analysis problems on their
better prior knowledge differentiation (as evidenced in
                                                                   own. The data analysis problem presented a distribution of
student-generated solutions), and affords opportunities for
                                                                   goals scored each year by three soccer players over a
students to attend to critical features of the targeted concept.
                                                                   twenty-year period. Students were asked to design a
Experiment 2 tests whether prior knowledge differentiation
                                                                   quantitative index to determine the most consistent player.
can be engendered by simply giving student-generated
                                                                   During this generation phase, no instructional support or
solutions to the students to study and evaluate. Finally,
                                                                   scaffolds were provided. Following this, two periods were
Experiment 3 examines the extent to which attention to and
                                                                   spent on direct instruction where the teacher first
understanding of critical features is contingent upon having
                                                                   consolidated by comparing and contrasting student-
students go through the generation and exploration phase, or
                                                                   generated solutions with each other, and then explained the
could these critical features simply be told to students as
                                                                   canonical solution just like in the DI condition. Note that
part of direct instruction.
                                                                   because students in the PF condition spent the first two
                                                                   periods generating an index for variance, they solved fewer
                Experiment 1: PF vs. DI                            data analysis problems overall than their counterparts in the
Participants                                                       DI condition. To make this contrast even sharper, PF
                                                                   students did not receive any homework.
Participants were 74, ninth-grade mathematics students (14-
                                                                      After the second and fourth periods, students from all
15 year olds) from two intact classes in an all-boys public
                                                                   classes took a five-item, five-point (1=low to 5=high) Likert
school in Singapore. In all three experiments reported in this
paper, students were almost all of Chinese ethnicity.              scale engagement survey ( α = .79).
                                                                      Posttest All students took a five-item, paper and pencil
Research Design                                                    posttest ( α = .74) comprising:
                                                                   i. one item on procedural fluency (calculating SD for a
A quasi-experimental, pre-post design was used with one                 given dataset),
class (n = 39) assigned to the ‘Productive Failure’ (PF)           ii. two items on data analysis (comparing means and SDs of
condition, and the other class (n = 35) to the ‘Direct                  two samples; these items were isomorphic with the data
Instruction’ (DI) condition. Both classes were taught by the            analysis problems covered during instruction), and
same teacher.                                                      iii. two items on conceptual insight (required students to
   Pretest First, all students took a five-item paper and               evaluate sub-optimal solutions; one item dealing with
pencil pretest ( α = .75) on the concept of variance.                   sensitivity to ordering of data points, and another with
   Intervention Next, all classes participated in four, 55-             outliers)
minute periods of instruction on the concept as appropriate           Maximum score for each of the three types of items was
to their assigned condition.                                       10; two raters independently scored the items using a rubric
   In the DI condition, the teacher first explained the concept    with an inter-rater reliability of .92.
of variance, and its canonical formulation as the square of
                                   n         2
the standard deviation ( SD 2 = ( x − x )                          Results
                                  ∑ i           n ) using a data
                                   1                               Process PF groups generated on average 7 solutions (M =
analysis problem. Next, the teacher modeled the application        6.98, SD = 2.48) to the problem. Four categories emerged:
of the concept by working through several data analysis            a. Central tendencies (e.g., using mean, median, mode);
problems, highlighting common errors and misconceptions,           b. Qualitative methods (e.g., organizing data using dot
and drawing attention to critical features of the concept in             diagrams, frequency polygons, line graphs to examine
the process. The data analysis problems required students to             clustering and fluctuations patterns);
compare the variability in 2-3 given data sets, for example,       c. Frequency methods (e.g., counting the frequency with
comparing the variability in rainfall in two different months            which a player scored above, below, and at the mean to
of a year, or comparing the consistency of performance of                argue that the greater the frequency at the mean relative
three soccer players, and so on. To ensure students were                 to away from the mean, the better the consistency); and
engaged and motivated throughout, they were told that they         d. Deviation methods (e.g., range; calculating the sum of
will be asked to solve isomorphic problems after the teacher             year-on-year deviations to argue that the greater the
had worked through the examples with the class. Thereafter,              sum, the lower the consistency; calculating absolute
students worked face-to-face in triads on more data analysis             deviations to avoid deviations of opposite signs
problems so that they could benefit from the processes of                cancelling each other; calculating the average instead of
explanation and elaboration afforded by collaboration. The               the sum of the deviations).
teacher then discussed the solutions with the class. After            Elsewhere, we have described these student-generated
each period, students were given isomorphic data analysis          solutions in greater detail (Kapur, 2010b). Note that none of
                                                                   the groups were able to generate the canonical formulation
                                                                 2813

of SD. In contrast, analysis of DI students’ classroom work       canonical solutions (either through worked examples or
revealed that students relied only on the canonical               direct instruction) before getting them to apply these to
formulation to solve data analysis problems. This was not         solve problems on their own (Sweller, 2010).
surprising given that had been taught the canonical                  Experiment 1’s findings suggest that there is in fact a
formulation of SD, which is also easy to compute and apply.       utility in having students solve novel problems first. What
All students were accurately able to apply the concept of SD      prior knowledge differentiation affords in part is a
to solve the very problem that the PF students tried to           comparison and contrast between the various solutions—
generate a solution to. Finally, on the mean of the two self-     among the student-generated solutions as well as between
reported engagement ratings, there was no difference              the student-generated and canonical solutions. Specifically,
between the PF condition, M = 3.84, SD = .51, and the DI          these contrasts afford opportunities to attend to the
condition, M = 3.82, SD = .43.                                    following critical features of the targeted concept that are
   These process findings serve as a manipulation check           necessary to develop a deep understanding of the concept:
demonstrating that students in the PF condition experienced       1. What is the difference between the mean and the
“failure,” at least in the conventional sense of not being able         distribution around the mean?
to generate the canonical solutions. In contrast, DI students     2. What is the difference between a qualitative description
were not only just as engaged as PF students but also                   of the data (e.g., dot diagram, line graphs) and a
demonstrated successful application of the canonical                    quantitative description (e.g., range, SD)?
formulation to solve data analysis problems, including the        3. What is the difference between the frequency of a point
one that the PF students solved during the generation phase.            and its position relative to a fixed reference point?
The high engagement ratings and performance results also          4. Why must we take deviations from a fixed point?
suggest that the DI condition was not simply a case of poor       5. Why is the mean usually the fixed point; why can’t it be
instruction.                                                            the maximum or the minimum point, or even the
   Outcome On the pretest, no student demonstrated                      median or the mode?
canonical knowledge of SD, and there was no significant           6. Why must we take deviations from the mean for all the
difference between the conditions, F(1, 72) = 2.56, p = .114.           points; why not just choose the maximum and the
   Posttest performance on the three types of items formed              minimum point, or simply the range?
the three dependent variables. Controlling for the effect of      7. Why must deviations from the mean be made positive?
prior knowledge as measured by the pretest, F(4, 134) =           8. Why must we divide the sum of the squared deviations
1.89, p = .112, a MANCOVA revealed a significant                        by n; why not simply work with their or sum?
multivariate effect of condition, F(4, 134) = 16.802, p <         9. Why must we take the square root of the average of the
.001, partial η2 = .33. Interaction between prior knowledge             squared deviations?
and experimental condition was not significant.                   10. How do outliers affect SD?
                                                                     However, Experiment 1 raises two further questions:
Table 1: Experiment 1 posttest performance by item type           1. If exposure to both student-generated and canonical
Experiment 1                 PF            DI           p / η2          solutions is what is essential, then instead of getting
                           M (SD)        M (SD)                         students to generate solutions, why not simply let
ProceduralFluency 8.70 (2.07) 8.69 (2.19) ns                            students study the student-generated solutions first
Data Analysis            7.39 (1.94) 5.97 (2.48) .013*/.09              (e.g., in the form of well-designed worked examples)
Conceptual Insight 6.12 (2.38) 3.01 (1.93) .001*/.31                    and then give them the canonical solutions through
                                                                        direct instruction? Simply put, is it really necessary for
   PF students significantly outperformed their DI                      students to generate the solutions or can these be given
counterparts on data analysis and conceptual insight                    to them? Experiment 2 addresses this question.
problems without compromising on procedural fluency.              2. If what is essential is that students attend to the ten
                                                                        critical features, then why not simply tell students these
Discussion                                                              critical features? Why bother having them generate, and
                                                                        compare and contrast the solutions? Simply put, do
As hypothesized, the PF design invoked learning processes               students really need to generate before receiving the
that not only activated but also differentiated students’ prior         critical features, or would telling the critical features
knowledge (as evidenced by the diversity of student-                    without any generation work just as well? Experiment 3
generated solutions). Whereas PF students worked with the               addresses this question.
solutions that they generated and the canonical solutions
(that they received during direct instruction), DI students
worked with only the canonical ones. Hence, DI students
                                                                              Experiment 2: PF vs. Evaluation
worked with a smaller diversity of solutions, and                 The purpose of Experiment 2 was to examine the difference
consequently, their prior knowledge was arguably not as           between: a) having students generate solutions to solve a
differentiated as their PF counterparts. This was a               novel problem, and b) having them study and evaluate
significant difference between the conditions by design.          student-generated solutions (also see Roll, 2009).
Proponents of DI have repeatedly questioned the utility of
getting students to solve novel problems on their own.
Instead, they argue that students should be given the
                                                                2814

Participants                                                    reported engagement ratings were, on average, high, and
Participants were 54, ninth-grade mathematics students (14-     there was no difference between the PF condition, M = 4.07,
15 year olds) from two intact classes in an all-boys public     SD = .61, and the EV condition, M = 4.12, SD = .53.
school in Singapore.                                               Outcome On the pretest, no student demonstrated
                                                                canonical knowledge of SD, and there was no significant
Research Design                                                 difference between the conditions, F(1, 63) = 1.16, p = .285.
One class (n = 31) was assigned to the PF condition, and the       On the posttest ( α = .78), an item on near transfer was
other class (n = 23) to the ‘Evaluation’ (EV) condition. Both   added to increase the discriminatory power of the posttest.
classes were taught by the same teacher. The PF condition       The near transfer item required students to add data points
was exactly the same as in Experiment 1. The EV condition       to a given dataset without changing its mean and SD. Two
differed from the PF condition in one important aspect: The     raters independently scored the items using the same rubric
generation phase was replaced with an evaluation phase; the     as in Experiment 1 with an inter-rater reliability of .95.
subsequent direct instruction phase was the same as in the      Performance on the four types of items formed the four
PF condition.                                                   dependent variables. Controlling for the effect of prior
   Whereas PF students had to collaboratively generate          knowledge as measured by the pretest, F(4, 48) = 1.04, p =
solutions to solve the complex problem during the first two     .398, a MANCOVA revealed a significant multivariate
periods, EV students took the same two periods to               effect of condition, F(4, 48) = 3.34, p = .017, partial η2 =
collaboratively study and evaluate the peer-generated           .22. Interaction between prior knowledge and experimental
solutions (available from Experiment 1). To ensure that         condition was not significant.
students were motivated to understand the given solutions,
students were asked to evaluate and rank order the solutions    Table 2: Experiment 2 posttest performance by item type
so that they would indirectly be forced to compare and          Experiment 2                 PF           EV          p / η2
contrast the solutions. Each solution was presented on an A4                              M (SD)        M (SD)
sheet of paper with the prompt: “Evaluate whether this          Procedural Fluency 9.60 (0.98) 9.43 (1.73) ns
solution is a good measure of consistency. Explain and give     Data Analysis           9.83 (0.90) 9.34 (2.28) ns
reasons to support your evaluation.”                            Conceptual Insight 4.77 (1.02) 3.44 (1.67) .001*/.19
   The number of solutions given was pegged to the average      Near Transfer           7.50 (3.35) 5.08 (4.73) .039*/.08
number of solutions produced by the PF groups, that is,
seven. The most frequently-generated solutions by the PF           PF students significantly outperformed their EV
students were chosen for EV condition, and none of the          counterparts on conceptual insight and near transfer
chosen solutions contained misconceptions. The seven            problems without compromising on procedural fluency and
solutions included one on central tendencies, two on            data analysis. Consistent with Roll (2009), exposing
qualitative methods (dot diagram and line graph), two on        students to and having them evaluate student-generated
frequency methods (frequency of the mean and frequency of       solutions does not seem to be as efficacious as having them
the mean relative to away from the mean), and two on            generate those solutions before direct instruction.
deviation methods (sum of year-on-year deviation with
signs, and average year-on-year deviations without signs).                 Experiment 3: PF vs. Strong-DI
   Because student-generated solutions sometimes lack           The purpose of Experiment 3 was to compare PF condition
conceptual clarity in their presentation that may make it       with a strong DI condition, in which the teacher explicitly
difficult for other students to understand and evaluate them,   explains the 10 critical features.
they were converted into well-designed worked examples.
EV students received these solutions in the form of worked
                                                                Participants
examples one-by-one (counterbalanced for order), and were       Participants were 57, ninth-grade mathematics students (14-
given approximately 10-12 minutes for each. The remaining       15 year olds) from two intact classes in an all-boys public
time (approximately 30 minutes) was spent on rank ordering      school in Singapore.
the solutions. Finally, to ensure that EV groups understood
the student-generated solutions, the teacher and a research     Research Design
assistant conducted an in-situ check for understanding with     One class (n = 31) was assigned to the PF condition, and the
the EV groups by asking them to explain their                   other class (n = 26) to the ‘Strong-DI’ condition. Both
understanding of the solutions. Where students needed help      classes were taught by the same teacher. The PF condition
in understanding the solutions, it was readily provided         was exactly the same as in Experiment 1. The Strong-DI
because we did not want students’ lack of understanding to      condition was the same as in Experiment 1 except that the
adversely affect the fidelity of the EV condition.              teacher drew attention to the ten critical features during
                                                                instruction. While explaining each step of formulating and
Results                                                         calculating SD, the teacher explained the appropriate critical
Process PF groups produced on average just under 7              features relevant for that step. For example, when
solutions (M = 6.78, SD = 2.03) to the problem. As              explaining the concept of “deviation of a point from the
expected, these solutions fell into the four broad categories   mean”, the teacher discussed why deviations need to be
identified earlier. As in Experiment 1, the mean self-          from a fixed point, why the fixed point should be the mean,
                                                              2815

and why deviations must be positive. During subsequent          attend to critical features of the concept of variance, which
problem solving and feedback, the teacher repeatedly            in turn helped PF students better understand the concept
reinforced these critical features throughout the lessons.      when presented by the teacher during direct instruction
                                                                subsequently (Schwartz & Martin, 2004). Consequently, PF
Results                                                         students performed on par with DI students on procedural
Process PF groups produced on average just over 7               fluency, but significantly outperformed them on data
solutions (M = 7.24, SD = 2.56). These solutions fell into      analysis and conceptual insight. Although the limitations
the four broad categories identified earlier. DI students       inherent in quasi-experimental studies with intact
relied only on the canonical formulation to solve data          classrooms cannot be completely mitigated, note that both
analysis problems, and all were accurately able to apply the    the conditions were taught by the same teacher for the same
concept to solve the very problem that the PF students tried    amount of time, exposed students to the same materials
to generate solutions to. As in Experiments 1 and 2, the        (except that DI students were exposed to more data analysis
engagement ratings were on average high, and there was no       problems), and afforded students the opportunity to benefit
difference between the PF condition, M = 4.15, SD = .44,        from collaborative problem solving.
and the Strong-DI condition, M = 4.22, SD = .32.                   Experiment 2 further examined prior knowledge
                                                                differentiation by testing whether it was necessary for
   Outcome On the pretest, no student demonstrated
                                                                students to generate solutions themselves (to engender prior
canonical knowledge of SD, and there was no significant
                                                                knowledge differentiation), or can these solutions be simply
difference between the conditions, F(1, 55) = .25, p = .618.
                                                                given to the students to study and evaluate. Findings
   The posttest ( α = .79) was the same as in Experiment 2.
                                                                suggested that PF students performed significantly better on
Two raters independently scored the items using the same
                                                                conceptual insight and near transfer without compromising
rubric as in Experiment 2 with an inter-rater reliability of
                                                                on procedural fluency and data analysis.
.98. Controlling for the effect of prior knowledge as              Because Experiment 1 showed that students do not
measured by the pretest, F(4, 51) = .25, p = .907, a
                                                                necessarily attend to or notice deep critical features on their
MANCOVA revealed a significant multivariate effect of
                                                                own during direct instruction, Experiment 3 examined
condition, F(4, 51) = 2.65, p =.044, partial η2 = .17.          whether these features could simply be told to students as
Interaction between prior knowledge and experimental            part of direct instruction, or if it was more effective for
condition was not significant.
                                                                students to generate solutions before receiving these critical
                                                                features. Findings suggested that although direct instruction
Table 3: Experiment 3 posttest performance by item type         on the critical features was effective, having students
Experiment 3                 PF         Strong-DI      p / η2   generate solutions first was still better for developing deep
                          M (SD)         M (SD)                 conceptual insight.
Procedural Fluency 9.50 (1.01) 9.69 (1.00) ns                      In sum, therefore, all three experiments suggested that
Data Analysis           9.84 (0.90) 9.81 (0.98) ns              there is indeed an efficacy in having learners generate and
Conceptual Insight 4.44 (1.24) 3.55 (1.13) .007*/.13            explore representations and methods for solving problems
Near Transfer           7.89 (2.52) 7.06 (2.73) ns              on their own even if they do not formally know the
                                                                underlying concepts needed to solve the problems, and even
   PF students significantly outperformed their Strong-DI       if such un-supported problem solving leads to failure
counterparts on conceptual insight without compromising         initially. By failure, we mean that students were unable to
on procedural fluency. Effect on data analysis, which was       generate the canonical solutions by themselves. Of course,
significant in Experiment 1, was no longer significant in       one could argue that PF students were not really failing
Experiment 3. Effect on near transfer, which was significant    because they were engaged in processes that were germane
in Experiment 2, was no longer significant in Experiment 3.     for learning (Schmidt & Bjork, 1992). However, when we
It can be concluded that direct instruction on the critical     situate the PF design in the argument made by the
features appears to be helpful indeed. However, PF students     proponents of DI, the generation process is invariably seen
still maintained an edge in terms of conceptual insight.        as failure because the proponents of DI question the utility
Perhaps one could argue that exposure to sub-optimal            students generating solutions to novel problems. They argue
solutions in the PF condition can alone explain their better    that students should be given the canonical solutions (either
performance on conceptual insight items on the posttest.        through worked examples or direct instruction) before
While this explanation cannot be fully ruled out, Experiment    getting them to apply these to solve problems on their own
2 helps mitigate this concern because students in the           (Sweller, 2010).
Evaluation condition were also exposed to the sub-optimal          Implications of the above findings pose an interesting
solutions but they still did not perform as well as PF          dilemma for the limits of working memory (WM) capacity
students on conceptual insight.                                 as argued by cognitive load theorists: How is it that students
                                                                who had not learnt the concept of variance were able to
                   General Discussion                           generate multiple representations and solutions to a novel,
We reported on three quasi-experimental studies that helped     complex problem targeting that concept in the first place?
unpack the productive failure (PF) effect. Experiment 1         After all, a complex problem should in and of itself impose
showed that compared to DI, PF a) engendered better prior       a heavy cognitive load on a limited WM capacity, let alone
knowledge differentiation, and b) afforded opportunities to     one that targets a novel concept.
                                                              2816

   To resolve this dilemma, one only need realize that the       Schwartz, Nikol Rummel, and Katharina Westermann and
limits of WM only apply to new or yet-to-be learned              for their suggestions on the design of the experiments.
information not in the long-term memory (LTM) (Sweller,
2010). However, when dealing with previously stored                                       References
information in the LTM, these limits tend to be mitigated.       Brown, A., & Campione, J. (1994). Guided discovery in a
Indeed, as Kirschner et al. (2006) argued, “Any instructional      community of learners. In K. McGilly (Ed.), Classroom
theory that ignores the limits of working memory when              lessons: Integrating cognitive theory and classroom
dealing with novel information or ignores the disappearance        practice (pp. 229–270). Cambridge, MA: MIT Press.
of those limits when dealing with familiar information is        Chi, M. T. H., Glaser, R., & Farr, M. J. (1988). The nature
unlikely to be effective” (p. 77).                                 of expertise. Hillsdale, NJ: Erlbaum
   If the constraints of WM are contingent upon the novelty      diSessa, A. A., & Sherin, B. L. (2000). Meta-representation:
of information, and novelty is a function of how what a            An introduction. Journal of Mathematical Behavior,
learner already knows (stored in the LTM) is brought to            19(4), 385–398.
bear on the new concept being learnt, then it follows that       Hardiman, P., Pollatsek, A., & Weil, A. (1986). Learning to
activating relevant prior knowledge in the LTM can help            understand the balance beam. Cognition and Instruction,
mitigate the constraints of WM. This precisely what PF is          3, 1–30.
designed to do: by designing to activate prior knowledge,        Kapur, M. (2008). Productive failure. Cognition and
PF works to mitigate the WM constraints. This may explain          Instruction, 26(3), 379-424.
why PF students were able to generate a several solutions to     Kapur, M. (2009). Productive failure in mathematical
the novel problem. Furthermore, it can be argued that once a       problem solving. Instructional Science, 38(6), 523-550.
particular solution is generated, it forms a resource in the     Kapur, M. (2010b). Productive failure in learning the concept of
LTM for further generation, that is, generated solutions            variance. In S. Ohlsson & R. Catrambone (Eds.),
stored in the LTM can potentially interact with the WM to           Proceedings of the 32nd Annual Conference of the Cognitive
aid more generation. Finally, these generated structures also       Science Society (pp. 2727-2732). Austin, TX: Cognitive
become a powerful resource in the LTM that can interact             Science Society.
with WM and reduce the cognitive load during subsequent          Kapur, M. (2010a). A further study of productive failure in
direct instruction, thereby resulting in better learning of        mathematical problem solving: Unpacking the design
conceptual features during direct instruction. Both DI and         components. Instructional Science. DOI: 10.1007/s11251-
Strong-DI students did not have these LTM resources that           010-9144-3
they could leverage to learn better from direct instruction.     Kirschner, P. A., Sweller, J., & Clark, R. E. (2006). Why
Thus conceived, one can see why the process of evaluating          minimal guidance during instruction does not work.
student-generated solutions can impose a higher WM load            Educational Psychologist, 41(2), 75-86.
than actually generating those very solutions, and               Klahr, D., & Nigam, M. (2004). The equivalence of learning
consequently interfere with learning.                              paths in early science instruction: Effects of direct
   In sum, if what a learner already knows about a concept is      instruction and discovery learning. Psychological Science,
a critical determinant of either limiting or expanding the         15(10), 661–667.
WM capacity, then does not a commitment to cognitive load        Roll, I. (2009). Structured invention activities to prepare
theory entail a commitment to understanding whether and to         students for future learning: Means, mechanisms, and
what extent the targeted concept is novel to the learner?          cognitive processes. Thesis, Pittsburgh, PA.
However, in our reading, this is rarely taken up by the          Schmidt, R. A., & Bjork, R. A. (1992). New
proponents of DI. Their conception of prior knowledge              conceptualizations of practice: Common principles in
remains limited to canonical domain-specific knowledge,            three paradigms suggest new concepts for training.
which in turn, constrains one to work within the limiting          Psychological Science, 3(4), 207-217.
aspects of the working memory (e.g., Sweller & Cooper,           Schwartz, D. L., & Bransford, J. D. (1998). A time for
1985; Paas, 1992). However, if we allow for the possibility        telling. Cognition and Instruction, 16(4), 475-522.
that learners may have some prior knowledge and resources        Schwartz, D. L., & Martin, T. (2004). Inventing to prepare
about a concept they have yet to learn, could we not design        for future learning: The hidden efficiency of encouraging
tasks and activity structures to elicit this knowledge, and by     original student production in statistics instruction.
activating and working with these priors in the long-term          Cognition and Instruction, 22(2), 129-184.
memory, leverage the expandable aspects of working               Strand-Cary, M., & Klahr, D. (2008). Developing
memory capacity? At the very least, this is a theoretical          elementary science skills: Instructional effectiveness and
possibility that the cognitive load theory allows for, and one     path independence. Cognitive Development, 23(4), 488-
that should be explored.                                           511.
                                                                 Sweller, J. (1988). Cognitive load during problem solving:
                    Acknowledgements                               Effects on learning. Cognitive Science, 12, 257–285.
The research reported in this paper was funded by grants to      Tuovinen, J. E., & Sweller, J. (1999). A comparison of
the authors from the National Institute of Education of            cognitive load associated with discovery learning and
Singapore. The authors would like to thank Daniel                  worked examples. Journal of Educational Psychology,
                                                                   91, 334–341.
                                                               2817

