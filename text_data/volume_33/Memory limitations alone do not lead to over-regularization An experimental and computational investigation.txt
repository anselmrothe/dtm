UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Memory limitations alone do not lead to over-regularization: An experimental and
computational investigation
Permalink
https://escholarship.org/uc/item/7vk017n5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Author
Prefors, Amy
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                 University of California

                   Memory limitations alone do not lead to over-regularization:
                              An experimental and computational investigation
                                             Amy Perfors (amy.perfors@adelaide.edu.au)
                                         School of Psychology, University of Adelaide, Australia
                              Abstract                                      Although children’s tendency toward over-regularization is
   The “less is more” hypothesis suggests that one reason adults         well-established, the reason for the difference between adults
   and children differ in their language acquisition abilities is        and children is far from clear. The “less is more” hypothesis
   that they also differ in other cognitive capacities. According        suggests that over-regularization may be due to some aspect
   to one version, children’s relatively poor memory may make
   them more likely to over-regularize inconsistent input (Hudson        of children’s cognitive capacities, such as their poorer mem-
   Kam & Newport, 2005, 2009). This paper investigates this              ory. Adults do tend to over-regularize more when the input is
   hypothesis experimentally and computationally. Experiments            complex, when the probabilities involved are small (Hudson
   in which adults were placed under a high cognitive load dur-
   ing a language-learning task reveal that in adults, increased         Kam & Newport, 2009), or when lexical retrieval is more dif-
   load does not result in increased over-regularization. A com-         ficult (Hudson Kam & Chang, 2009). This may be because
   putational model offers a possible explanation for these results,     more complex input imposes more of a load on their cognitive
   demonstrating that over-regularization should occur only in the
   presence of memory limitations as well as a strong prior bias         resources. The “less is more” hypothesis is also supported
   for over-regularization. Taken together, these findings suggest       by computational work (Elman, 1993) suggesting that learn-
   that the difference in over-regularization between adults and         ing is easier when early input is simpler (although that work
   children may not be attributable solely to differences in mem-
   ory capacity between the two groups.                                  does not speak to the issue of over-regularization). In general,
   Keywords: language acquisition; over-regularization; statisti-        there has been little computational or experimental research
   cal learning; memory; computational modelling                         that directly measures or manipulates memory or processing
                                                                         speed and evaluates whether these are associated with differ-
                          Introduction                                   ent degrees of over-regularization in adults.
In many ways, ranging from phonetic perception to aspects
                                                                            In previous work I investigated whether adults placed un-
of syntax, children are superior language learners than adults.
Some argue that this is because language acquisition in chil-            der cognitive load over-regularized more (Perfors & Burns,
dren is guided by language-specific acquisition procedures,              2010). The logic was that if deficiencies in the particular ca-
                                                                         pacities involved in the load tasks are what cause children
whereas adult acquisition is directed by more domain-general
learning mechanisms (e.g., Bley-Vroman, 1990). However,                  to over-regularize, then adults under heavy load should be-
there are many other possibilities, since children and adults            have more like children in their pattern of over-regularization.
                                                                         Adults took part in a standard word-learning task, but in some
also differ profoundly in their cognitive capabilities, knowl-
edge, assumptions, and typical linguistic input. Learning a              conditions they also had to solve equations (OPERATIONAL
                                                                         LOAD ) or read sentences ( VERBAL LOAD ) in between word-
second language is made more difficult by interference from
the first language (e.g., Mayberry, 1993; Iverson et al., 2003),         learning trials. People did not over-regularize in any condi-
adult brains are less malleable than the brains of children              tion, regardless of load. However, because the additional load
                                                                         tasks were interspersed rather than concurrent, it is possible
(Elman et al., 1996; MacWhinney, 2005), and adults and chil-
dren differ in the nature of the social support (Snow, 1999)             that the load tasks did not interfere with memory enough to
and linguistic input (Fernald & Simon, 1984) they receive.               have an effect. In the first part of this paper I therefore report
                                                                         the results of an experiment that address this possibility by
   One hypothesis, often called “less is more”, suggests that
the relative cognitive deficits in children may actually help            placing adults under concurrent memory load. As before, the
                                                                         participants failed to over-regularize in all conditions.
with language acquisition, either by enabling them to isolate
and analyze the separate components of a linguistic stimu-                  The second part of the paper uses a simple computational
lus (Newport, 1990), or by leading them to over-regularize               model to explain these results. The model systematically
inconsistent input (Hudson Kam & Newport, 2005, 2009).                   explores how different degrees and types of memory lim-
Children do indeed over-regularize while adults do not. Deaf             itation affect over-regularization. It also investigates how
children exposed to the inconsistent sign language of hear-              memory limitations interact with prior biases for or against
ing parents will over-regularize that language and produce               over-regularization. Results indicate that over-regularization
regular grammatical forms (Singleton & Newport, 2004), as                only occurs when both memory limitations and a strong prior
will children exposed to inconsistent input in an artificial lan-        bias for over-regularization are present; neither alone is suf-
guage (Hudson Kam & Newport, 2005). By contrast, adult                   ficient. Taken together with the experimental findings, they
language learners are known to produce highly variable, in-              suggest that adult-child differences in over-regularization do
consistent utterances, even after years of experience with the           not emerge from differences in memory capacity alone; adults
language and after their grammars have stabilized (Johnson,              may additionally have different prior biases about how to re-
Shenkman, Newport, & Medin, 1996).                                       spond to inconsistent input.
                                                                     3274

                           Experiment                                     Results
50 adults were recruited from the University of Adelaide and              There are two natural questions we must answer.2 First, is the
surrounding community and were paid $10. Subjects com-                    load task difficult enough? Second, did participants in either
pleted a word-learning task in which they were taught 10                  of the load conditions over-regularize by producing the main
novel two-word labels. Interspersed with the word-learning                determiner more than 60% of the time?
task was an interference task that required people to memo-
rize a list of letters at the beginning of each trial and report          Was the load task difficult enough? There are two ways
that list at the end. Subjects in the HIGH LOAD condition                 to evaluate whether the load tasks were sufficiently challeng-
had to memorize six letters each time, and in the LOW LOAD                ing to the cognitive capacities of the participants, whilst still
condition they had to memorize three. These results are com-              being easy enough so that people could acquire at least some
pared to performance of an additional 25 subjects in a control            of the image-label mappings in the word-learning task. One
NO LOAD condition, as reported in Perfors and Burns (2010).               indication that people were taking the load task seriously is
   The word learning task was modelled after a similar task               that participants in both load conditions were reasonably ac-
described by Hudson Kam and Newport (2009). Their lan-                    curate in memorizing letters: HIGH LOAD averaged 56% of
guage contained 51 words, taught over the course of 9-12                  letters correct (a mean of 3.4 letters per trial) and LOW LOAD
days. Of critical interest was the evaluation of performance              averaged 85% correct (2.5 letters per trial).3 Another indica-
on the determiners, which were associated with nouns in                   tion is that participants learned fewer noun-image mappings
an inconsistent fashion: participants heard the main deter-               if they were in the load conditions. Each person’s answers
miner only 60% of the time. Conditions varied according to                were coded as correct if the noun they produced was identi-
how many other determiners there were (always evenly dis-                 cal to or phonologically similar to the correct noun for that
tributed). Participants were asked to provide the noun and                image (e.g., wolin instead of wolid). Participants performed
determiner associated with a scene and sentence and the fre-              above chance in all conditions, but significantly worse in
                                                                          HIGH LOAD (41%) and LOW LOAD (47%) than in NO LOAD
quency with which each determiner was produced was noted.
                                                                          (67%), suggesting that the interference tasks were, indeed,
   In order to remove extraneous elements of the task so as to
                                                                          imposing significant strain on their cognitive resources.4
focus on the determiner-production aspect, the “language” in
this experiment consisted of 10 nouns, all two-syllable non-              Did adults over-regularize more when under cognitive
sense words mapped to images representing common objects.                 load? Following Hudson Kam and Newport (2009), partic-
Each noun was followed by a one-syllable determiner: the                  ipants who did not get at least 9 out of the final 20 nouns
main determiner occurred 60% of the time, and each of the                 correct on the test trials were excluded.5 Then, on every valid
four noise determiners occurred 10% of the time.1 The spe-                trial (in which a correct noun was produced), I calculated the
cific image-label mapping and choice of main determiner was               percentage of time either the main determiner, any other de-
randomized for each participant.                                          terminer (noise), or no determiner was produced. Figure 1
   The task consisted of a total of 200 trials of image-label             demonstrates that there were no significant differences be-
pairs. On each trial, an image appeared on the computer                   tween conditions in terms of main determiner production:
screen and at the same time the person heard a female voice               that is, participants in the load conditions were not signifi-
provide the label: for instance, they might see a picture of a            cantly more likely to over-regularize.6
baby and hear churbit mot. In the NO LOAD condition, par-
ticipants went to the next trial by clicking a next button. In                2 In Perfors and Burns (2010) we addressed a third question:
the two load conditions, each image was preceded by a list of             whether lower performance on a separate working memory task pre-
letters to memorize (six letters in the HIGH LOAD condition               dicted greater over-regularization in the word learning task. I per-
                                                                          formed a similar analysis here and found no evidence for such a
and three in LOW LOAD), which was visible for 2.5 seconds.                relationship, but do not have space to describe this analysis in detail.
The image was displayed for 1.5 seconds and followed by                       3 To ensure that results were not due solely to participants who
a response phase in which participants reported the last set              did not take the load task seriously, all analyses were repeated after
                                                                          excluding participants who got fewer than 50% or 70% correct; in
of letters in order. At that point memorization accuracy and              both cases, all results are qualitatively identical.
time taken to respond were displayed, and when the partici-                   4 A one-way Anova on nouns correct by condition was signifi-
pant pressed next the next set of letters to memorize appeared.           cant: F(2, 72) = 7.56, p = 0.001. Post-hoc comparisons using the
                                                                          Tukey-Kremar test indicated that the mean score for the NO LOAD
   Learning was tested with 10 questions every 50 trials, for             condition (M=0.667, SD = 0.05) was significantly different than the
a total of 40 test questions. At each test, the participant was           mean for the HIGH LOAD (M = 0.407, SD = 0.05) and LOW LOAD
presented with an image and asked to verbally produce the                 (M = 0.473, S = 0.05) conditions, but the latter two were not signif-
                                                                          icantly different from each other.
label for it, which the experimenter (who was blind to the                    5 This resulted in keeping 23 subjects in the NO LOAD condition,
correct answers) wrote down. No feedback was given.                       15 in HIGH LOAD, and 19 in LOW LOAD. All analyses were also per-
                                                                          formed without this exclusion; results were qualitatively identical.
    1 Noun words used were: dragnip, raygler, churbit, tramdel, shel-         6 One-way Anova on main determiner production by condition:
bin, pugbo, wolid, foutray, nipag, and yeetom. Objects used were:         F(2, 49) = 2.05, p = 0.1393. To further explore this outcome, a
babies, balls, beds, birds, books, cars, cats, cups, dogs, and shoes.     post-hoc comparison using Tukey-Kramer indicated no significant
The five determiners were: mot, ped, sib, kag, and zuf.                   difference between any of the conditions compared pairwise.
                                                                      3275

                                                      Determiner production over all test trials                                                                    Consistency over all trials
                                            1                                                                                                              1
                                                                                                                                                                                                             Consistent noise
                                                                                                   No load
                                                                                                                                                                                                             Consistent main
                                           0.9                                                     High load                                              0.9
                                                                                                                                                                                                             Consistent none
                                                                                                   Low load                                                                                                  Not consistent
                                           0.8                                                                                                            0.8
             Proportion of time produced                                                                                      Proportion of all answers
                                           0.7                                                                                                            0.7
                                           0.6                                                                                                            0.6
                                           0.5                                                                                                            0.5
                                           0.4                                                                                                            0.4
                                           0.3                                                                                                            0.3
                                           0.2                                                                                                            0.2
                                           0.1                                                                                                            0.1
                                            0                                                                                                              0
                                                   Noise                Main                  None                                                              No load      High load     Low load
Figure 1: Performance by condition in determiner production. There                                                Figure 2: Individual consistency in determiner production by con-
was no significant difference between conditions in tendency to                                                   dition. For the most part, few participants showed any consistency
over-regularize. Error bars are standard error.                                                                   in their pattern of determiner usage, and those in the load conditions
                                                                                                                  did not tend to be more consistent.
   This is suggestive, but because it is an analysis of mean
performances this outcome may be hiding individual over-                                                          quency of different colors of flashing lights or cards in a deck.
regularization in different directions. To evaluate this possi-                                                     This situation is captured by the multinomial distribution,
bility, following Hudson Kam and Newport (2009) a “consis-                                                        where θi denotes the probability of outcome i and ∑ki=1 θi = 1.
tency threshold” of 90% was set: each participant was coded                                                       In a multinomial, the data for the observed outcomes y are
as consistent main, consistent noise, or consistent none if they                                                  generated from the underlying θ according to:
produced the determiner type in question on at least 90% of                                                                                                                                           k
                                                                                                                                                                                         k
the valid trials, and not consistent if they did not.7 Figure 2                                                                                                                                        ∏ θi i .
                                                                                                                                                                                                              y
                                                                                                                                                                p(y|θ) =                                                        (1)
shows that few participants were consistent in any way, and                                                                                                                          y1 . . . yk       i=1
differences between conditions were minor. In order to de-                                                           The task of the learner is to reason backward from the out-
termine if the tendency to over-regularize changed as they                                                        comes y to infer the nature of the underlying “true” distri-
acquired more of the language, analyses for both Figures 1                                                        bution θ. Which distribution is learned will depend on two
and 2 were repeated for the first and second half of testing.                                                     things: the nature of the data y and any prior beliefs about
Results were qualitatively similar for all analyses.                                                              what θ should look like.8 A natural, mathematically elegant,
   Hudson Kam and Newport (2005, 2009) hypothesize that                                                           and widely used prior for multinomial data is the Dirichlet
differences in cognitive capabilities between children and                                                        distribution (Gelman, Carlin, Stern, & Rubin, 2003). This
adults may lead to differences in regularization, either be-                                                      model uses a symmetric Dirichlet distribution, which imposes
cause children are less efficient at encoding memories, or be-                                                    no prior bias in favor of any one outcome more than another
cause they have more difficulty retrieving specific memory                                                        across the whole dataset. Symmetric Dirichlet distributions
forms. Either way, the theory suggests that children will over-                                                   have one parameter, α, which captures the degree to which
regularize some forms and fail to produce others, but adults                                                      each item (noun) is expected to be associated with only one
will store and retrieve the memories more veridically.                                                            outcome (determiner); it governs the extent of the bias for
   Another possibility is that children simply have a prior bias                                                  over-regularization. If α is very small, there is a strong bias
to favor regularization, whereas adults do not. This bias might                                                   for over-regularization: the model will assume that each noun
be language-specific (e.g., Bickerton, 1984) or more domain-                                                      is associated with only one determiner (although, because the
general; either way, it would result from something other than                                                    prior is symmetric, it will have no prior bias about which de-
age-related differences in memory capacity. In the next sec-                                                      terminer is most likely). When α = 1, there is no bias for
tion I use a computational model to investigate the expected                                                      over-regularization; it is assumed that each outcome will oc-
effects of both prior biases and memory limitations, and how                                                      cur with equal probability. I evaluate the role of the prior by
they trade off against each other.                                                                                considering four values of α: 1 (NO BIAS), 0.5 (WEAK BIAS),
                                                                                                                  0.05 (MEDIUM BIAS), and 0.005 (STRONG BIAS).
                                                 Computational analysis                                              In addition to varying the strength of the prior bias for
Most tasks in which there is the potential for over-                                                              over-regularization, it is necessary to also model the effects of
regularization can be described abstractly as tasks in which                                                      memory. How to do this is less obvious, but the most straight-
there are k possible outcomes and the learner must learn the                                                      forward possibilities are to capture memory limitations via a
distribution over those outcomes. In this experiment there                                                        corruption of the observed data y (which, in the uncorrupted
are six outcomes associated with each noun (five for each of
                                                                                                                      8 A complete absence of prior belief would mean that θ should
the determiners, and one for no determiner), while in a typi-
                                                                                                                  always match the observed distribution y precisely; such a learner
cal probability matching task, the outcomes might be the fre-                                                     would never generalize beyond the input at all. It is possible to have
                                                                                                                  very mild prior beliefs – e.g., the weak expectation that any outcome
   7 The   results do not change if the threshold is 70% or 80%.                                                  is equally likely – which would still enable some generalization.
                                                                                                               3276

              Drop; No bias              Drop; Weak bias           Drop; Medium bias              Drop; Strong bias
        1                           1                           1                             1
                                                                                                                             Consistent main
                                                                                                                             Consistent noise
      0.5                         0.5                         0.5                           0.5
                                                                                                                             Consistent none
                                                                                                                             Not consistent
        0                           0                           0                             0
           0% 20%40%60%80%90%          0% 20%40%60%80%90%          0% 20%40%60%80%90%            0% 20%40%60%80%90%
            Random; No bias           Random; Weak bias           Random; Medium bias           Random; Strong bias
        1                           1                           1                             1
      0.5                         0.5                         0.5                           0.5
        0                           0                           0                             0
           0% 20%40%60%80%90%          0% 20%40%60%80%90%          0% 20%40%60%80%90%            0% 20%40%60%80%90%
          Prior−based; No bias       Prior−based; Weak bias    Prior−based; Medium bias       Prior−based; Strong bias
        1                           1                           1                             1
      0.5                         0.5                         0.5                           0.5
        0                           0                           0                             0
           0% 20%40%60%80%90%          0% 20%40%60%80%90%          0% 20%40%60%80%90%            0% 20%40%60%80%90%
Figure 3: Model performance varying the strength of the prior bias (columns) and the effect of different kinds of memory limitation (rows).
Each graph shows the proportion of consistent classifications out of 50 iterations (on the y axis) as a function of the percentage of memory
affected (on the x axis): n% means that n% of the data are either dropped (DROP), flipped randomly (RANDOM), or reconstructed based on the
prior (PRIOR - BASED). Over-regularization only occurs when memory is limited and there is a medium-to-strong prior for over-regularization.
case, always precisely follows the proportions of the input in
                                                                                                                 P(y|θ, α)P(θ|α)
the experiment: one determiner occurs 60% of the time, and                                P(θ|y, α) = R              ′ , α)P(θ′ |α)dθ′
                                                                                                                                              (2)
four others occur 10% of the time).                                                                          θ′ P(y|θ
   How might memory corrupt the data? One possibility is                         Figure 3 shows expected performance by prior bias and
to assume, as a first approximation, that memory loss simply                 memory. To make the model results comparable to the exper-
means dropping data at random (the DROP condition). Drop-                    imental findings, consistency is calculated the same way as in
ping different proportions of the data would therefore map                   the experiment: e.g., consistent main means that on that itera-
onto differences in memory capacity. Another possibility is                  tion the model predicted that 90% or more of the determiners
to assume that memory limitations result in data being for-                  should be the main one. Each of the stacked bars reflects the
gotten and then reconstructed by the mind. A trivial way to                  proportion of runs (out of 50) in which the model achieved
reconstruct such data would be to randomly randomly reas-                    any of the kinds of consistency.
sign “forgotten” data to any of the possible determiners with                    There are two striking things about these results. First,
equal probability; this is the RANDOM condition. A more                      they demonstrate that simply having a prior bias for over-
natural reconstruction method might be to presume that for-                  regularization is insufficient to cause over-regularization.
gotten data is reconstructed according to the prior probability              This is because the quantity of data must also be small. In
(the PRIOR - BASED condition). This can be modelled using                    this model, memory limitations had the effect of limiting
the Chinese Restaurant Process:                                              the quantity of (accurate) data, but other data-limiting fac-
                                                                             tors might also include bottlenecks in the input or attentional
                                                          ni                 restrictions. The reason that a prior bias alone is insufficient
                 P(determiner i|previous data) =
                                                        N +α                 is because a sufficient quantity of data will always overcome
                                                          α                  any prior; a rational learner should think it much more likely
            P(new determiner|previous data) =
                                                        N +α                 that a given determiner actually occurs 60% of the time if it
                                                                             is observed in 600 out of 1000 observations rather than 3 out
where ni refers to the number of observations involving de-
                                                                             of 5. Because quantity of the data matters, a prior bias only
terminer i made so far, N is the number of observations total,
                                                                             has an effect when there is little veridical data available.
and α is the same parameter that captures the prior bias. In
                                                                                 The second implication of these results is that memory
fact, the Chinese Restaurant Process gives the same distribu-
                                                                             limitations alone do not result in over-regularization either.
tion as draws from a Dirichlet process, which is why it is a
                                                                             Memory limitations must occur along with some sort of prior
natural way to capture memory loss within this model.
                                                                             bias for over-regularization, whether it comes in when mem-
   Predictions about the expected distribution over outcomes
                                                                             ory is being reconstructed or when interpreting situations
given the data and the priors are given by Bayes Rule:9
                                                                             where there are few observations. The reason a prior bias
    9 The integral in the denominator is calculated by drawing 10,000        is necessary is because without it, memory limitations don’t
samples of θ from the Dirichlet distribution parameterized by α.             change the overall pattern of data. For instance, suppose
                                                                        3277

a learner was exposed to 10 determiners following the dis-              rather than to make adults act more like children by making
tribution in the data (6-1-1-1-1-0). If the learner randomly            it harder. It is possible that there is an inherent asymme-
forgot 60% of them, they would be unlikely to forget all of             try to adults’ performance: that it is relatively easy to make
the noise determiners and more likely to forget some of each            adults over-regularize less, but that getting them to regularize
type. Without a strong prior towards over-regularization, the           more is difficult. The computational model is consistent with
learner wouldn’t ignore the noise items that remain, and thus           this possibility, and such an asymmetry certainly exists in
would not over-regularize. Even in the extreme where 90%                decision-making problems, in which great efforts have been
of the data is forgotten, over-regularization should not occur:         made to stop adults from probability matching, to little avail
when there is very little data the prior is weighted more heav-         (e.g., Shanks, Tunney, & McCarthy, 2002).
ily, so without a prior for over-regularization, a learner given           The computational model in this paper was deliberately
very little data will assume that any outcome is possible.              chosen to be extremely simple in order to minimize the ex-
                                                                        tent to which the results are dependent on arbitrary modeling
                           Discussion                                   choices. There was only free parameter in the model (α) and
                                                                        it was systematically varied. The multinomial distribution
The “less is more” hypothesis suggests that one reason for
                                                                        is the most obvious and widely-used way of capturing dis-
the difference between adult and children in language acqui-
                                                                        tributional data in which many outcomes are likely, and the
sition is due to unequal cognitive capacities: children’s poor
                                                                        Dirichlet distribution is the most widely-used and mathemat-
memory may make them more likely to over-regularize in-
                                                                        ically elegant prior for multinomial data. Memory limitations
consistent input. In an experiment building on Perfors and
                                                                        were modeled simplistically, but in a way that captures to a
Burns (2010), adults were placed under a high cognitive load
                                                                        first approximation the different ways in which memory con-
and the effect of this manipulation was evaluated. Although
                                                                        straints might have an effect (either losing information or dis-
the cognitive load was strong enough to impair performance,
                                                                        torting it in different ways). Moreover, the qualitative results
increased load did not lead to increased over-regularization.
                                                                        were driven by model-independent factors: a prior bias is nec-
Modeling work demonstrates that over-regularization should
                                                                        essary because memory limitations alone do not change the
only emerge if the learner is has both a limited memory and a
                                                                        pattern of data remembered, and some sort of data-limiting
strong prior bias for over-regularization.
                                                                        mechanism (like a memory constraint) is necessary because
    Taken together, these results suggest that memory limita-           otherwise any prior bias for over-regularization will be over-
tions are necessary but not sufficient for over-regularization          whelmed by the inconsistent data in the input. It is therefore
to emerge, and therefore memory differences between chil-               unlikely that incorporating a more realistic memory model
dren and adults cannot be the only reason children but not              would change these results in any qualitative way, although
adults over-regularize. This finding is consistent with other           this topic is being explored further in my lab.
work showing that children with better memories or faster
                                                                           One assumption inherent in the model is that it is Bayesian,
processing speed actually do better at learning language (e.g.,
                                                                        meaning that it predicts the behavior of a rational learner.
Fernald, Perfors, & Marchman, 2006; Rose, Feldman, &
                                                                        This means that the importance of previous biases (the prior)
Jankowski, 2009). It maybe that children do have some sort
                                                                        and fitting the data (likelihood) are balanced in a particular
of prior bias favoring over-regularization that adults lack, but
                                                                        way (according to Bayes’ Rule). However, every model needs
it is worth considering possible limitations first.
                                                                        to perform some tradeoff between these two factors. Because
    It is theoretically possible that the load tasks were not diffi-    of this, models that weigh these tradeoffs differently might
cult enough to limit adults’ memories to the point that any ef-         vary quantitatively, but all models except for the most patho-
fects would be visible. However, this seems unlikely, for two           logical10 should show that over-regularization is more likely
reasons. First, the load tasks significantly impaired people’s          when the input is limited and the prior bias for it is strong.
ability to learn the nouns, indicating that they placed a heavy
                                                                           It is also worth noting that, although the model is Bayesian,
burden on the learners. Second, even in analyses where one
                                                                        this is not an ideal learning analysis; because the model in-
would expect poorer performance (e.g., on just the first half
                                                                        corporates different kinds of memory limitations, it should
of test trials, or including even participants who learned very
                                                                        be more properly understood as a “capacity-limited” rational
few nouns) there was no tendency toward over-regularization.
                                                                        model. It thus allows us to investigate what a rational learner
This suggests that the reason adults failed to over-regularize
                                                                        with certain capacity constraints might be expected to do.
was not that they simply found the task too easy. For similar
                                                                        This sort of approach is an important step toward bridging
reasons, it is unlikely that the simplicity of the task (learn-
                                                                        computational-level and process-level accounts of cognition.
ing noun-determiner pairings rather than full languages) is
                                                                           One simplification this model makes is that it is incapable
the reason for the findings; I will pursue this in future work.
                                                                        of learning that different kinds of items might be associated
    On first glance, these findings might appear to contradict          with very different distributions (e.g., that some nouns are
those of Hudson Kam and Chang (2009), who found that                    associated with only one determiner, but some are associated
over-regularization in adults could be diminished by improv-
ing the ease of lexical retrieval. However, they aimed to make             10 “Pathological” models include those that don’t learn at all from
adults less like children by making the cognitive load easier,          data or never generalize at all beyond the data.
                                                                    3278

with many). That extra complexity was unnecessary to model           Bley-Vroman, R. (1990). The logical problem of foreign language
this experiment, in which all items have the same distribution         learning. Linguistic Analysis, 20, 3–49.
                                                                     Derks, P., & Paclisanu, M. (1967). Simple strategies in binary pre-
of determiners and consistency is calculated across the entire         diction by children and adults. Jn. Exp. Psych., 73(2), 278–285.
dataset. Existing models corresponding to an extension of            Elman, J. (1993). Learning and development in neural networks:
this one have been used to capture complex phenomena in-               The importance of starting small. Cognition, 48, 71–99.
                                                                     Elman, J., Bates, E., Johnson, M., Karmiloff-Smith, A., Parisi, D.,
cluding word-learning biases (Kemp, Perfors, & Tenenbaum,              & Plunkett, K. (1996). Rethinking innateness: A connectionist
2007; Perfors & Tenenbaum, 2009) and verb construction                 perspective on development. Cambridge, MA: MIT Press.
learning (Perfors, Tenenbaum, & Wonnacott, 2010).                    Fernald, A., Perfors, A., & Marchman, V. (2006). Picking up speed
                                                                       in understanding: Speech processing efficiency and vocabulary
   How do we interpret the prior bias for over-regularization          growth across the 2nd year. Dev. Psych., 42(1), 98–116.
in the model? Independent evidence suggests that such a bias         Fernald, A., & Simon, T. (1984). Expanded information contours in
might be domain-general, since children over-regularize but            mothers’ speech to newborns. Dev. Psych., 20, 104–113.
                                                                     Flavell, J., Green, F., Flavell, E., Harris, P., & Astington, J. W.
adults do not even in non-linguistic domains like predicting           (1995). Children’s knowledge about thinking. Monographs of
which light will flash (e.g., Shanks et al., 2002; Weir, 1964;         the SRCD, 60(1).
Derks & Paclisanu, 1967) or how often a cause will result            Gelman, A., Carlin, J., Stern, H., & Rubin, D. (2003). Bayesian
                                                                       data analysis (2nd ed.). Chapman & Hall.
in a given effect (Schulz & Sommerville, 2006). That said,           Hudson Kam, C., & Chang, A. (2009). Investigating the cause of
the model incorporates no assumptions about the domain-                language regularization in adults: Memory constraints or learning
specificity or domain-generality of the prior. It encodes the          effects? Jn. of Exp. Psych.: Lng., Mem., & Cog., 35(3), 815–821.
                                                                     Hudson Kam, C., & Newport, E. (2005). Regularizing unpredictable
degree to which a bias for over-regularization exists, but the         variation: The roles of adult and child learners in language forma-
question of its origin is a matter for future work.                    tion and change. Lang. Lng. & Dev., 1(2), 151–195.
   One final important point should be made: these findings          Hudson Kam, C., & Newport, E. (2009). Getting it right by getting it
                                                                       wrong: When learners change languages. Cognitive Psychology,
are relevant only to the version of the “less is more” hypothe-        59, 30–66.
sis that makes reference to over-regularization (Hudson Kam          Iverson, P., Kuhl, P., Akahane-Yamada, R., Diesch, E., Tokura, Y.,
& Newport, 2005, 2009). The original theory is focused more            Kettermann, A., et al. (2003). A perceptual interference account
                                                                       of acquisition difficulties with non-native phonemes. Cognition,
on whether linguistic input is broken down into components             87, B47–B57.
or not (Newport, 1990); it suggests that as a result of their su-    Johnson, J., Shenkman, K., Newport, E., & Medin, D. (1996). Inde-
perior memories, adults may memorize entire frozen chunks              terminacy in the grammar of adult language learners. Journal of
                                                                       Memory and Language, 35, 335–352.
of the input, while children – who are only able to recall           Kemp, C., Perfors, A., & Tenenbaum, J. (2007). Learning over-
smaller portions – find it easier to isolate linguistic compo-         hypotheses with hierarchical Bayesian models. Developmental
nents. This paper is not relevant to that version of the “less         Science, 10(3), 307-321.
                                                                     MacWhinney, B. (2005). A unified model of language acquisition.
is more” hypothesis, since it postulates different mechanisms          In J. Kroll & A. De Groot (Eds.), Handbook of bilingualism: Psy-
and applies to different phenomena.                                    cholinguistic approaches (pp. 49–67). Oxford Univ. Press.
   It also remains possible that child-adult differences in over-    Mayberry, R. (1993). First-language acquisition after childhood
                                                                       differs from second-language acquisition: The case of american
regularization might be driven by cognitive factors that have          sign language. Jn. of Speech and Hearing Res., 36, 1258–1270.
effects beyond limiting or distorting input. Such differences        Newport, E. (1990). Maturational constraints on language learning.
could arise from variations in the ability to use metacognitive        Cognitive Science, 14, 11–28.
                                                                     Perfors, A., & Burns, N. (2010). Adult language learners under
strategies (e.g., Flavell, Green, Flavell, Harris, & Astington,        cognitive load do not over-regularize like children. In Proc. 32nd
1995). It may be that adults’ ability to introspect and rea-           Annual Conf. of the Cognitive Science Society (p. 2524-2529).
son about their own cognition makes them more likely to rely         Perfors, A., & Tenenbaum, J. (2009). Learning to learn cate-
                                                                       gories. In Proc. 31st Annual Conf. of the Cognitive Science Soci-
on explicit rather than implicit learning (Ullman, 2004) – a           ety (p. 136-141).
difference that has been hypothesized to be the root of child-       Perfors, A., Tenenbaum, J., & Wonnacott, E. (2010). Variability,
adult differences in language acquisition. A bias for over-            negative evidence, and the acquisition of verb argument construc-
                                                                       tions. Journal of Child Language, 37, 607-642.
regularization might result from a generalized preference for        Rose, S., Feldman, J., & Jankowski, J. (2009). A cognitive approach
simplicity on the part of children. A great deal of work re-           to the development of early language. Ch. Dev., 80(1), 134–150.
mains to be done to investigate the many possibilities that          Schulz, L., & Sommerville, J. (2006). God does not play dice:
                                                                       Causal determinism and preschoolers’ causal inferences. Child
remain open, but this work suggests that memory alone is not           Development, 77(2), 427–442.
the root of child-adult differences in the tendency to over-         Shanks, D., Tunney, R., & McCarthy, J. (2002). A re-examination
regularize inconsistent input.                                         of probability matching and rational choice. Jn. of Behavioral
                                                                       Decision Making, 15, 233–250.
                                                                     Singleton, J., & Newport, E. (2004). When learners surpass their
                     Acknowledgments                                   models: The acquisition of American Sign Language from incon-
                                                                       sistent input. Cognitive Psychology, 49, 370–407.
Thank you to Natalie May, Jia Ong, Kym McCormick, and                Snow, C. (1999). Social perspectives on the emergence of language.
Tin Yim Chuk for their help recruiting participants and run-           In B. MacWhinney (Ed.), The emergence of language (pp. 257–
ning the experiment.                                                   276). Mahwah, NJ: Lawrence Erlbaum Associates.
                                                                     Ullman, M. (2004). Contributions of memory circuits to language:
                                                                       The declarative/procedural model. Cognition, 92, 231–270.
                          References                                 Weir, M. (1964). Developmental changes in problem-solving strate-
Bickerton, D. (1984). The language bioprogram hypothesis. Behav-       gies. Psychological Review, 71, 473–490.
   ioral and Brain Sciences, 7, 173-221.
                                                                 3279

