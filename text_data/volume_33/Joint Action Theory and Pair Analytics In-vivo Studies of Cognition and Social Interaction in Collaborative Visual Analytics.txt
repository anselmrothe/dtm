UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Joint Action Theory and Pair Analytics: In-vivo Studies of Cognition and Social Interaction in
Collaborative Visual Analytics
Permalink
https://escholarship.org/uc/item/4wh394vp
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Arias-Hernandez, Richard
Kaastra, Linda T.
Fisher, Brian
Publication Date
2011-01-01
Peer reviewed
  eScholarship.org                                   Powered by the California Digital Library
                                                                       University of California

    Joint Action Theory and Pair Analytics: In-vivo Studies of Cognition and Social
                                   Interaction in Collaborative Visual Analytics
                                           Richard Arias-Hernandez (ariasher@sfu.ca)
                                       Simon Fraser University, SIAT, 250 - 13450 – 102 Avenue
                                                    Surrey, BC, V3T 0A3 CANADA
                                            Linda T. Kaastra (lkaastra@magic.ubc.ca)
                                 University of British Columbia, MAGIC, FSC 3640 - 2424 Main Mall,
                                                   Vancouver, BC, V6T 1Z4 CANADA
                                                   Brian Fisher (bfisher@sfu.ca)
                                        Simon Fraser University, SIAT, 250 - 13450 – 102 Avenue
                                                    Surrey, BC, V3T 0A3 CANADA
                              Abstract                                 Imagine a scenario in which two data analysts share a
   Herbert H. Clark’s Joint Action Theory (JAT) has been
                                                                       computer screen and jointly work on the analysis of air
   groundbreaking for understanding the social and cognitive           traffic data. The layout of the screen contains several
   mechanisms that allow people to effectively coordinate joint        frames. Each one with a different visual representation of
   actions in conversational, face-to-face settings. Using a           data for a commercial airline: a map, a table, and a bar
   method we call “Pair Analytics,” we have extended the               graph. One of the analysts notices a salient bump in the bar
   application of JAT to the study of analytical reasoning in          graph and the following interaction unfolds:
   computer-mediated, human-to-human interactions. Pair
   analytics (PA) sets a naturalistic scenario in which the social        Ben: Look at this [Ben moves the mouse and places it on the bar in the
   and cognitive role of human-human and human-computer                   chart that corresponds to “December”]
   interactions can be studied. In this paper, we support the             Anna: well, it’s December. You would expect a peak in air traffic.
   claim that coupling JAT and PA is an effective research
   strategy to capture and study three socio-cognitive
                                                                       In this interaction, Ben uses a deictic expression (“this”) that
   phenomena in collaborative visual analytics: (1) structuring
   and navigation of joint analysis; (2) management of joint           requires attention to a specific referent on one of the visual
   attention; (3) and signaling of cognitively demanding tasks.        representations of the data. In regular face-to-face
                                                                       conversation, deictic expressions are commonly used by
   Keywords: Joint Action Theory, Pair Analytics, Visual
                                                                       speakers, along with non-verbal signals, such as finger or
   Analytics, Analytic Reasoning.
                                                                       head pointing, to direct the attention of listeners to the
                                                                       referent implicit in the utterance (Clark, 2003). In our
                          Introduction
                                                                       example, Ben uses the mouse as a pointing device to
Joint Action Theory, Herbert H. Clark’s theory of language             visually direct the attention of Anne to the exact place in the
in use (Clark, 1996), is a well-established psycholinguistic           GUI where the object of the deictic expression can be
framework that has been very effective in bridging social              identified without ambiguity. This behavior, equivalent to
and cognitive understandings of human communication.                   finger pointing, makes use of the mouse as a communicative
One of its basic tenets is that conversational, face-to-face,          on-screen gesture rather than as an input device of a human-
interaction is the foundation of human communication and               computer interaction. In fact, the smaller size of the mouse
language. Clark strongly criticizes theories of language that          pointer makes it more effective than using finger pointing to
depart from this foundation by overemphasizing unilateral,             direct attention to a specific bar on a common 23-inch
cognitive, technological, or computational accounts that do            computer screen. The mouse-pointer is small enough not to
not build upon the basic social structure of interaction that          block the general view of the bar graph or to point to more
allowed language to emergence: face-to-face interaction.               than one bar at a time. According to Clark’s theory, this
From a strong foundation on this theory of language, we                specific behavior uses an object of the GUI, the mouse, as a
have begun to expand the scope of Joint Action Theory                  “material signal” (Clark, 2005), or as we refer to it in this
from human-to-human interaction toward computer-                       paper, as a communicative “on-screen gesture.” We claim
mediated, human-to-human interaction. Our emphasis is on               that on-screen gestures are some of the most effective
the use of Graphical User Interface (GUI) objects and                  linguistic mechanisms that humans use to coordinate
Human-Computer Interactions (HCI) as gestures by which                 collocated,           computer-mediated,           human-to-human
people mean things for others (Clark, 2005). The best way              interactions. On-screen gestures, just as body gestures
to illustrate this is with one example.                                (Clark & Brennan, 1991), reduce the number of words and
                                                                       interactions that otherwise would be needed to communicate
                                                                   3244

the same idea making communication less ambiguous and               Pair Analytics
more effective.                                                     In order to capture uses of language to solve coordination
                                                                    problems in collaborative, visual analytics, we have
This understanding of HCI in the context of human-to-               designed a method called “pair analytics” (Arias-Hernandez
human communication makes evident that interactive GUI              et al., 2011). Pair analytics (PA) is a method that generates
components can potentially serve psycho-linguistic                  verbal data about thought processes in a naturalistic human-
functions that have not been explored and are not currently         to-human interaction with visual analytic tools. This method
well understood in the visual analytics domain. This paper          is loosely based on “pair programming” from “extreme
presents an initial attempt to breach this gap by exploring         programming” software development methods (Gallis,
the role of on-screen gesturing in three socio-cognitive            Arisholm & Dyba, 2003). Pair analytics requires a dyad of
phenomena of collaborative visual analytics: (1) structuring        participants: one Subject Matter Expert (SME) and one
and navigation of joint analysis; (2) management of joint           Visual Analytics Expert (VAE). The dyad is given one
attention; (3) and signaling of cognitively demanding tasks.        analytical task, one data set, and one multi-screen computer
                                                                    with several visual analytics (VA) tools. The VAE has
                                                                    technical expertise in the operation of a suite of VA tools,
      Joint Action Theory and Pair Analytics                        but may lack the contextual knowledge that would be
                                                                    required to conduct meaningful analysis of the data set s/he
Joint Action Theory                                                 is working on. The SME, on the other hand, has expertise in
Joint Action Theory (JAT) is a structured, socio-cognitive,         a specific analytic domain, but no knowledge of the VA
theory of “language in use” developed by Herbert H. Clark           tools. The pairing of SME and VAE is designed to generate
(1996). For Clark, language use is an instantiation of a            a human-to-human dialog that makes explicit the mental
broader class of human practices: joint actions. In joint           models and cognitive processes of the SME and VAE
actions, individual participatory actions have to be                during their collaborative visual analysis. For example,
coordinated to produce the intended effect. This implies            during the analytic interaction, the SME may provide expert
coordinating content –what the participants intend to do, and       knowledge to suggest visual comparison of relevant
coordinating process –how the participants effectively              variables, detect patterns, and generate or test hypotheses.
coordinate their individual actions to produce the desired          The interaction of the dyad with the VA tool also generates
joint effect. From this perspective, language in use is             a human-artifact dialog in which machine-models interact
understood as a social process rather than as a mere                with human mental models. For example, visualizations
exchange of information between speakers and listeners. For         created by the dyad may result in unexpected outcomes that
example, as a social process, the design of utterances is           do not fit into existing mental models due to the way the VA
better approached as a participatory process that does not          tool handles the data. The analytical task and the dataset for
depend solely on the individual cognition and actions of the        pair analytics are selected from previous fieldwork studies
speaker but also on the cognition and gestures produced by          of analytical work in the specific domain of expertise of the
the listener. When a speaker detects a facial gesture from the      SME. Selecting a currently relevant analytical task and
listener indicating confusion in the middle of an utterance,        familiar datasets create a more naturalistic setting for
the speaker proceeds to elaborate or rephrase her wording           observations of analytical reasoning. Interactions between
without even waiting for an explicit, verbal request. Thus          participants, as well as between VAE and visual analytics
the construction of the utterance is better approached as a         tool are captured in video and screen capture.
joint action between speaker and listener rather than the
solely action of a speaker (Clark & Krych, 2004). The               There are several advantages that PA offers to cognitive
mechanisms that allow communication to be effective and             science research in visual analytics with respect to other
reduce ambiguity and confusion are the result of a socio-           commonly used methods, such as protocol analysis
cultural evolution of human language that has selected the          (Ericsson & Simon, 1993) or ethnographic methods
most effective ones. Clark argues that humans constantly            (Schneiderman & Plaisant, 2006). First, it is a non-intrusive
employ these mechanisms to solve coordination problems in           method that takes advantage of the natural and continuous
joint actions (e.g. turn-taking, accounting for delays,             flow of speech necessary to coordinate joint actions (Clark,
navigating joint actions, mutual monitoring of                      1996). Since communication between participants flows
understanding, sustaining joint attention, etc). Since              continuously in PA there is no need for a researcher to
collaborative visual analysis is an instance of a joint action,     prompt participants to keep talking, as they would do in
our starting theoretical point to apply joint action theory to      think-aloud, protocol analyses. This addresses one of the
visual analytics is that: humans will use language and will         limitations of “thinking-aloud” protocols in which once
work together to solve coordination problems in                     participants get immersed in the task, reduce or stop their
collaborative, visual analytics.                                    verbalizations demanding the researcher to interrupt
                                                                    participants to resume their “thinking-aloud” (Trickett et al.,
                                                                    2000), affecting reasoning processes such as insight
                                                                    generation (Schooler et al.,1993). Thus, PA provides more
                                                                3245

complete data about analytical reasoning with less external         structured. The objective was to generate and test
intervention. Second, PA provides an empirical entry point          hypotheses that could explain differences of unscheduled
to study not only individual cognitive processes but also           aircraft downtime by models of aircrafts in a commercial
social processes used to coordinate joint actions (e.g. use of      fleet. The maintenance dataset to be used for the analysis
gestures to signal delays in cognitive processes). In this          was structured and contained 45 fields and over 90,000
aspect, PA gets closer to what could be achieved by                 records. One pair analytics session was arranged for each
ethnographic, studies of cognition “in the wild” (Hutchins,         SME, for a total of four sessions. Pair analytic sessions
1995). Similar to field studies, PA is conducted in-situ, in        were conducted in-situ, over a period of four weeks in
collaborative settings where domain experts normally                September and October, 2009, and sessions had an average
conduct their analytical work. Thus, socio-cognitive                duration of 2 hours. Tableau®, a visual analytics tool, was
behaviors that occur in collocated, collaborative work              chosen by the visual analytics experts to be used in the pair
settings also occur in pair analytics. An advantage with            analytic sessions. Since the visualizations generated by
respect to ethnographic field studies of cognition is that PA       Tableau® during the sessions are mostly line and bar charts,
maximizes the richness of the data being captured for               no especial training was required for the SMEs to
content analysis by using screen and video capture.                 understand the visual representations of data. However a
                                                                    general introduction about the structure of the data and
                                                                    Tableau® was provided to each subject matter expert at the
Using JAT to analyze PA data                                        beginning of each session.
We use the video and screen data collected in the PA
sessions to transcribe and code all conversations, joint
actions and HCIs. First, we focus on transcribing all of the        Results
speech, verbal and non-verbal gestures used by participants         Our results showed that in effect, communication between
of pair analytics. Second, using screen capture data, we            participants flowed continuously during the pair analytics
complement the initial transcription with all of the human-         sessions, and there was no need for a researcher to prompt
computer interactions. Finally, we separate the transcription       participants to keep talking about their strategies, methods,
as sequences of joint actions, the basic analytical unit in         or findings. We observed no decreasing in the amount of
JAT. Clark’s methodology requires human-to-human                    verbalizations, even when participants were engaged in
conversation to be structured as a succession of hierarchical       cognitively demanding tasks.
joint actions; each one with an entry, a body, and an exit
(Clark, 1996; Bangerter & Clark, 2003). After organizing            The analysis of the JAT-informed coding scheme was
the transcripts in the hierarchical structure of joint actions,     organized around three socio-cognitive phenomena:
we move to a coding phase.
                                                                    Ad-hoc structuring and navigation of the pair analysis:
From an extensive review of the literature on JAT, we               One classic study by Bangerter & Clark (2003)
drafted an initial coding scheme to capture three socio-            demonstrated that in American English people structure and
cognitive phenomena in collaborative visual analytics:              navigate joint activities by using vertical and horizontal
navigation of joint actions between different analytical            markers. “Vertical markers” are verbal gestures, such as
phases, coordination of joint attention, and use of gestures        “okay,” and “all right,” that signal transitions between joint
to signal delays in joint actions produced by cognitive             activities. “Horizontal markers,” such as “yeah” and
workload (Arias-Hernandez et al., 2011). Using the coding           “mhmm,” on the other hand, are used to signal continuation
scheme, we code several pair analytic sessions and analyze          within a singular joint activity (Bangerter & Clark, 2003).
the results.                                                        By using vertical and horizontal markers, people create ad-
                                                                    hoc structures of joint actions and navigate through them in
                                                                    an orderly fashion. In our analysis of the pair analytics
                        Pilot Study                                 sessions, we found ample evidence of the use of vertical and
To test and refine this theoretical and methodological              horizontal markers to navigate pair analytics (Arias-
approach for the study of psycho-linguistic mechanisms              Hernandez et al., 2011). Moreover, we also found that the
used by analysts to solve coordination problems in                  resulting structure being produced by the use of markers
collaborative, visual analytics, we conducted a pilot study.        clearly distinguished the different analytical strategies,
                                                                    methods, and findings of the analysis. Using these markers,
Setting:                                                            we were able to map all of the different lines of reasoning
                                                                    being pursued by the participants. We called these lines of
Our study involved four subject matter experts (SMEs) in
                                                                    reasoning that corresponded to distinctive joint activities:
aircraft maintenance engineering and two visual analytics
                                                                    “analytical paths.” Each analytical path corresponded to a
experts (VAEs) from our laboratory. In collaboration with
                                                                    complete form of joint action, with markers to signal its
the SMEs, we agreed to work on a real analytical task that
                                                                    entry, its body, and its exit. The structure of analytical paths
the aircraft maintenance analysts were struggling with at the
                                                                    corresponded to a tree-like structure.
time. The analytical task was open-ended and loosely
                                                                3246

                                                                    joint activity. Since participants in joint activities
                                                                    continuously propose joint projects to each other, the
                                                                    attention of each participant needs to monitor the continuous
                                                                    flow of signals. If attention is not focused on the relevant
                                                                    signal, then the intention behind the signal will not be
                                                                    communicated and the joint action will fail (Clark, 1996). In
                                                                    face-to-face settings, participants establish that joint
                                                                    attention is in place through the use of salient perceptual
                                                                    phenomena, perceptual co-presence, and gestural indications
          Figure 1. Using “placing-for” gestures in                 such as tone of voice, mutual gaze, finger pointing, and
                          Tableau®.                                 verbal markers (Clark, 2003). One of the results of our
                                                                    analysis of on-screen gesturing was that participants used
During the analysis of human-computer interactions, we              “mouse pointing” as an extension of more traditional face-
also found that participants accompanied verbal, vertical           to-face mechanisms, either to direct the attention of the
markers with non-verbal, on-screen gestures. For example,           listener or to confirm to the speaker that attention was in the
Tableau® provides a history feature that allows users to            right place. In both cases, “mouse pointing” was used as a
create a visual timeline of different views that have been          “directing-to”(Clark, 2003) kind of signal. While in both
generated during the course of the analysis. Every time             cases the mouse was in the hands of the VAE, it was used
users want to save a view for later recall, they create a           for different purposes. In the first case, the VAE, acting as
snapshot of the current screen by either generating a new           the speaker, used the pointer to direct the attention of the
worksheet or duplicating the currently active worksheet.            listener (SME) to a visual object on the screen. On the other
This action saves the current state of the analysis and             hand, in the second case, the VAE, acting as the listener,
generates a new thumbnail representing the next analytical          used the pointer to direct the attention of the speaker (SME)
project (Fig. 1). This interaction with the tool is functional,     to the visual object on the screen where the attention of the
since its purpose is to save the state of the analysis and          VAE had been directed to by SME’s speech.
create a linear, visual history of several states saved.
However, during our analysis we found that the VAE                  The first case is equivalent to finger pointing or head
consistently produced this behavior in response to uses of          pointing in face-to-face interaction. Its purpose is to indicate
vertical markers, such as “so,” and “okay,” visually                the location of a referent mentioned in speech. In all of its
signaling a vertical transition between different analytical        instances it was executed by the VAE as speaker. Attention
paths. In doing so, her interaction also had a communicative        to this signal and proper identification of the object being
effect. By producing the interaction on a visually shared           signaled was necessary to eliminate ambiguities in the use
space and by timing it with vertical transitions, the VAE           of demonstrative pronouns (e.g. this, that) and adverbs (e.g.
communicated to the SME her tacit understanding that a              here, there) when referring to visible objects in the GUI. In
vertical transition was in effect, and that she was ready to        all of these gestures, the mouse was used to communicate
move to a next phase of analysis. We conceptualized this            rather that trigger events in the visual analytics tool. In other
“placing-a-new-thumbnail-in-the-history” behavior as an             words, “mouse pointing” corresponded to a computer-
“interactive marker,” or a computer-mediated marker.                mediated human-to-human interaction rather than a human-
Interactive markers are a subclass of on-screen gestures, and       computer interaction. Thus, it was better understood as an
non-verbal gestures, whose purpose is similar to that of            on-screen gesture.
vertical and horizontal markers. According to Clark (2003,
2005), this particular interactional marker corresponds to the      The following is an excerpt taken from the transcript of one
sub-category of “placing-for” gestures, since it visually           of the sessions that illustrates this first kind of “directing-to”
“places” a new snapshot in the history line. Its use                use of mouse pointing:
demonstrated that participants of pair analytics extended
their repertoire of body-centric vertical markers to                    SME: okay
                                                                        VAE: [clicks on the orange section of the bar "HOU"]
incorporate human-computer interactions and GUI elements
                                                                             lots leaving from Houston
as “material signals” (Clark, 2005) to help them navigate               SME: So, that's interesting
their joint analysis. Whether an insight was generated in the           VAE: yeah ... [clicks on the orange section of "DAL"]
conclusion of an analytical path, or a dead point was                        lots leaving from Dallas [clicks on label of the bar
                                                                             "DAL" on the X-axis]
reached, this on-screen gesture, “placing-a-new-thumbnail-
                                                                         SME: yeah
in-the-history,” served to communicate the tacit
understanding that a milestone in the analysis had been             The second case of mouse pointing is observed when the
reached and that a new analytical path was about to begin.          VAE is the listener, not the speaker. Its purpose is to
                                                                    provide confirmation that the listener’s attention is directed
Management of joint attention: Coordinated joint                    to the location or object where the speaker intends it to be.
attention is a pre-requisite for successful participation in a      In face-to-face interaction, gaze and body position fulfill a
                                                                3247

similar function. When the speaker points to an object in her                  their interaction, such as cognitively demanding tasks (e.g.
speech, she expects the listener to orient her body and gaze                   retrieving information from memory, understanding difficult
towards the object. This provides visual confirmation that                     questions, etc). When faced with these cognitively
joint attention is in place (Monk & Gale, 2002). However,                      demanding challenges, participants delay their response to
in our pair analytics data, we found that mouse pointing                       the other participant’s original request. However, due to the
provided a more nuanced and a more precise visual                              social context in which interaction occurs, the timing of
confirmation than that provided by gaze or orientation.                        response is crucial. Any delay in responding is open to
When the speaker (SME) was referring to an object on the                       several interpretations by the requester, some of which
screen (sometimes pointing at it, sometimes not) the listener                  could undermine the responder’s self-presentation
(VAE) would use the mouse to point at the object being                         (Goffman, 1978). In order to “save face” (Goffman, 1978),
discussed. This “confirming” behavior produces a visual cue                    people normally resort to the use of fillers, such as “uh” and
that informs exactly where the listener’s attention is located                 “um” to account for shorter delays, and self-talk to account
on the visual display. Gaze and orientation provide a more                     for longer delays (Smith & Clark, 1993). According to
general, but less precise, visual cue. Due to the many visual                  Smith and Clark (1993), self-talk is a strategy used in
features, objects, and the size of the screen, gaze and                        conversational settings to (1) inform about delays and (2)
orientation do not afford the same precision as mouse                          inform about engagement in the joint action. Based on this
pointing, which confirms exactly the object to where                           rationale, we coded for “self-talk” moments in our data and
attention is directed. The following excerpt illustrates an                    mapped the activities that participants were doing during
instance of “confirming” joint attention with the mouse:                       these moments (e.g. task and duration of the task). We
                                                                               found that most of these activities participants were engaged
    SME: so ... looking at that ... let's see the ... 200s are the             with during self-talk corresponded to human-computer
          orange
    VAE: [moves the mouse over one of the bars with a                          interactions. So, we decided to categorize, time and analyze
          visible orange stack] [inclines his head to read the                 each of these by participant.
          vertical labels] yeah, so ...
                                                                               We found that different than Smith and Clark’s studies on
“Self-talk” and on-screen gestures inform about                                answering questions, human-computer interactions in pair
cognitively demanding tasks: During our data analysis, we                      analytics during self-talk have the additional advantage of a
noticed that some of the joint activities were temporarily                     shared visual space (i.e. the interface) that provides
paused by one of the participants. The pauses, however,                        additional information about the progression of the task
were characterized not by participant reducing their                           while the delay is still in place. Every human-computer
verbalizations, but rather by participants switching to “self-                 interaction that co-occurred with self-talk, visually informed
talk.” Once the pause was finished, the participant would                      the requester about the progression of a cognitively
resume her participation in the joint activity. For example,                   demanding task that was being executed by the responder.
occasionally the VAE would get a request from the SME to                       In other words, the combination of self-talk and HCI, not
create a non-trivial view of the data. In response, the VAE                    only served the two purposes theorized by Smith and Clark,
would interact with the computer in solo mode, using self-                     but also served another function: (3) to visually inform
talk, and conducting several steps to produce the intended                     about the progression of the cognitively-demanding task
view. Once done, the VAE would resume conversation with                        that originated the delay.
the SME. The SME, on the other hand, also engaged in
similar kinds of behavior. When observing a new view of                        Our analysis also showed that all of the VAE activities
the data, the SME would stop interacting with the VAE to                       during self-talk involved HCIs. For example, in one instance
observe features of the view, use self-talk, and return to                     of an activity that we coded as: “confronting anomalies in a
conversation afterwards. The following excerpt from one of                     generated view,” the VAE had created a bar graph with
the sessions illustrates the VAE using self-talk in one pause                  information about air traffic in origin and destination
that lasted almost 11 seconds (self-talk in bold):                             airports. On the x-axis of the bar graph, the VAE plotted
                                                                               data by origin and destination airports (two variables), and
   VAE: why? [unchecks “300” from the checkbox of filters, leaving only
   “700” checked. The colors change to purple from green but the view          on the y-axis, she provided a count of annual flight from one
   remains unaltered. Checks and unchecks “300” twice more] (9 sec) …          specific origin to one specific destination (one variable).
   why those [using his palm to cover his face] overlap like that? (2 sec)     The SME asked the VAE to sort the bar graph by origin city
                                                                               (request), and the VAE proceed to select the view and
It is important to note that these pauses are not interruptions                clicked on the “sort descending” button (initiates response).
in the activity since both participants are still on-task and                  However, the resulting view did not corresponded to the
advancing the joint activity. These pauses are better                          expected sorted result triggering the VAE to initiate self-talk
conceptualized as delays caused by the cognitive demands                       (delay) while figuring out what was going on:
on participants generated by the ongoing task (Smith &
Clark, 1993). As Smith and Clark (1993) have noted, the                           VAE: I don't know how it is sorting it there [clicks on the Y-Axis,
social substratum of joint actions demands that participants                      selects the whole graph, clicks on sort-descending icon, updates the
                                                                                  view, gets the same result] (7-sec delay)
inform each other about problems that they encounter in
                                                                           3248

Our analysis showed that this unexpected result occurred             Reliability and Safety Data,” and “Boeing Support for
because two variables had been plotted on the x-axis                 Visual Analytics in Canada” (Fisher subgrant).
creating sub-groups of bar graphs: first, by destination city,
then, by origin city. In effect, sorting was occurring, but its
expected visual result (gradually decreasing bars) was not                                    References
visibly salient. In this case, the tool was sorting by the total
values of the first variable (destination city), in a                Arias-Hernandez, R, Kaastra, L.T., Green, T.M. & Fisher,
visualization that had this variable disaggregated by a                B. (2011). "Capturing Reasoning Processes in
second variable (origin city). In other words, sorting was             Collaborative Visual Analytics," Proc. HICSS-44 (CD-
occurring at the aggregated level of destination city (not             ROM), Computer Society Press (2011), 10 pages.
visible), and not at the more disaggregated level of origin          Bangerter, A. & Clark, H.H. (2003). Navigating joint
city (visible). One of the visual advantages of sorting simple         projects with dialogue. Cognitive Science, 27 (2), 195-
bar graphs is that visual perception quickly processes the             225.
differences in size between bars, reducing the cognitive load        Clark, H.H. (1996). Using language. Cambridge:
of trying to determine the same differences in a non-sorted            Cambridge University Press.
bar graph. However, in this case, sorting views with more            Clark, H.H. (2003). Pointing and placing. In: Kita, S. (ed.)
than one variable per axis in bar graphs did not produce               Pointing: Where language, culture, and cognition meet,
“visually-salient” and “intuitively-sorted” bar graphs,                Psychology Press, 243-268.
creating confusion and generating a delay. Here, the                 Clark, H.H. (2005). Coordinating with each other in a
unexpected visual outcome of the sorting process and the               material world. Discourse studies, 7 (4-5), 507-525.
consequential interactions to “fix it” were adding more              Clark, H.H. and Brennan, S.E. Grounding in
cognitive load rather than reducing it. This example                   communication. (1991). In: Resnick, L.B., Levine, J.M.
illustrates how analyzing the human-computer interactions              and Teasley, S.D. (eds.) Perspectives on socially shared
that co-occur with self-talk can point out to concrete                 cognition, Washington, DC: American Psychological
instances in which the visual analytic tool is not reducing            Association, 127-149.
the cognitive demands of the task at hand, but rather                Clark, H.H. and Krych, M.A. (2004). Speaking while
creating or increasing these demands.                                  monitoring addressees for understanding. Journal of
                                                                       Memory and Language, 50 (1), 62-81.
                                                                     Ericsson, K.A. and Simon, H.A. (1993). Protocol analysis:
                         Conclusion                                    Verbal reports as data (Rev. ed.). Cambridge: MIT Press.
Joint Action Theory (JAT), the Pair Analytics method (PA),           Gallis, H., Arisholm, E. and Dyba, T. (2003). An initial
and the results of the pilot study presented in this paper             framework for research on pair programming. Proc.
show that the JAT/PA research strategy provides a novel                ESEM, IEEE Computer Society.
and original approach to understanding some of the psycho-           Goffman, E. (1978). Response cries. Language, 54 (4), 787-
linguistics mechanisms that analysts deploy to solve                   815.
coordination problems in collocated, collaborative visual            Hutchins, E. (1995). Cognition in the Wild. Cambridge:
analytics. Future research using the JAT/PA research                   MIT Press.
strategy will address more directly the specific kinds of            Monk, A.F. and Gale, C. (2002). A look is worth a thousand
affordances that visual analytics tools offer to enable users          words: Full gaze awareness in video-mediated
to navigate analytical paths and mark milestones in their              conversation. Discourse Processes, 33 (3). 257-278.
analysis (e.g. structured history of the analysis process            Schooler, J.W., Ohlsson, S. and Brooks, K. (1993).
marking precise moments of insights). We will also                     Thoughts beyond words: When language overshadows
continue to explore the role of “self-talk” events during pair         insight, Journal of Experimental Psychology, 122 (2),
analytics as indicators of cognitive demanding tasks and to            166-183.
differentiate between cognitive load caused by the demands           Shneiderman, B. and Plaisant, C. (2006). Strategies for
of the analytic task from those caused by poor interface               evaluating information visualization tools: multi-
design. Experimental studies will also be conducted to test            dimensional in-depth long-term case studies. Proc. AVI
the efficacy of pair analytics in comparison to protocol               2006, ACM Press, 7-12.
analysis for keeping constant the flow of verbalization, even        Smith, V.L. and Clark, H.H. (1993). On the course of
during cognitively intensive tasks.                                    answering questions. Journal of Memory and Language,
                                                                       32, 25-38.
                                                                     Trickett, S.B., W.T. Fu, C.D. Schunn and J.G. Trafton,
                    Acknowledgments                                    (2000). From dipsy-doodles to streaming motions:
This research was supported by NSERC STPGP 336506                      Changes in representation in the analysis of visual
“Visual Analytics for Safety and Security,” MITACS                     scientific data. Proc. CogSci 2000. Erlbaum.
ACCELLERATE BC “Program to Evaluate and Improve
Visual Analytic Processes for Analyzing Maintainability,
                                                                 3249

