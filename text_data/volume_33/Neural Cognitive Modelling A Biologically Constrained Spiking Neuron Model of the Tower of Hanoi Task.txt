UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Neural Cognitive Modelling: A Biologically Constrained Spiking Neuron Model of the Tower of
Hanoi Task
Permalink
https://escholarship.org/uc/item/6kv930kg
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Stewart, Terrence
Eliasmith, Chris
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

                                                Neural Cognitive Modelling:
      A Biologically Constrained Spiking Neuron Model of the Tower of Hanoi Task
                                          Terrence C. Stewart (tcstewar@uwaterloo.ca)
                                            Chris Eliasmith (celiasmith@uwaterloo.ca)
                                      Centre for Theoretical Neuroscience, University of Waterloo
                                   200 University Avenue West, Waterloo, ON, N2L 3G1, Canada
                             Abstract                                     In previous work, we used this approach to create models
   We present a computational model capable of solving
                                                                       of list memory (Choo & Eliasmith, 2010), rule induction
   arbitrary Tower of Hanoi problems. All elements except              (Rasmussen & Eliasmith, 2010), the Wason card task
   visual input and motor output are implemented using 150,000         (Eliasmith, 2005), and action selection (Stewart, Choo, &
   LIF spiking neurons. Properties of these neurons (firing rate,      Eliasmith, 2010a). We have also argued that our action
   post-synaptic time constant, etc.) are set based on the neurons     selection model (based on the basal ganglia) is sufficient to
   in corresponding areas of the brain, and connectivity is            implement the basic functionality of a production system
   similarly constrained. Cortical components are all general-
                                                                       (Stewart & Eliasmith 2010).
   purpose modules (for storing state information and for storing
   and retrieving short-term memories of previous state                   This paper expands on this work to present the first
   information), and could be used for other tasks. The only           spiking neural model implementing rule following,
   task-specific components are particular synaptic connection         planning, and goal recall. The model conforms to the
   weights from cortex to basal ganglia and from thalamus to           known anatomy, connectivity, and neural properties of the
   cortex, which implement 19 context-specific rules. The              basal ganglia, thalamus, and cortex. The components of the
   model has a single free parameter (the synaptic connection          model are general-purpose, in that they could be used to
   weights of the input to short-term memory), and produces
   timing behaviour similar to that of human participants.             perform different tasks without changing any neural
                                                                       connections within the cortex. To define the task to be
   Keywords: Tower of Hanoi; neural engineering; cognitive             performed, we only need to set the synaptic connection
   architectures; computational neuroscience                           weights between the cortex and basal ganglia and between
                                                                       the thalamus and the cortex. This makes our work both a
                 Neural Cognitive Models                               neural explanation of a particular high-level cognitive task,
To explain human behaviour, cognitive scientists must                  and a general set of principles for creating neural models for
identify both what the brain does and how it does it. This             other such tasks.
involves finding the algorithms underlying cognitive
performance as well as determining how these algorithms                                  The Tower of Hanoi
are implemented within the brain through the interaction of            The task considered here is the Tower of Hanoi, which has a
neurons, neurotransmitters, and other physical components.             rich history in cognitive science as a problem solving task
   Our ongoing research is in the construction of large-scale          (e.g. Simon, 1975). Many symbolic (non-neural) cognitive
neural models capable of exhibiting complex cognitive                  models exist which match expert human behaviour well
behaviour such as planning, rule-following, and symbolic               (e.g. Altmann & Trafton, 2002). The task involves three
reasoning. The intent is to bridge the gap between cognitive           pegs and a fixed number of disks of different sizes with
theory and neuroscience, allowing the fields to interact in            holes in them such that they can be placed on the pegs.
both directions. With such a bridge, high-level cognitive              Given a starting position, the goal is to move the disks to a
theory would produce detailed low-level predictions as to              goal position, subject to the constraints that only one disk
the neural spiking patterns, connectivity, and so on that              can be moved at a time and a larger disk cannot be placed
support particular human behaviours. Neuroscience would                on top of a smaller disk.
in turn provide constraints on high-level algorithms,                     Figure 1 shows the optimal series of steps needed to solve
indicating what operations can be performed by neurons,                the four-disk Tower of Hanoi when all disks start on one
how accurate they can be, and how much time is needed.                 peg and must all be moved onto a different peg. There are
   Our approach uses the Neural Engineering Framework                  many algorithms that could be used to produce this series of
(NEF; Eliasmith & Anderson, 2003), a general method for                steps, and cognitive research on this task involves
constructing computational models whose components are                 determining which algorithm(s) people are using by
simulations of spiking neurons. The NEF provides a                     examining factors such as the time taken between steps and
method for defining how values can be represented in a                 the types of errors produced. Anderson, Kushmerick, and
distributed manner across a set of neurons. Most crucially,            Lebiere (1993) provide a variety of measures of human
it also allows us to determine how groups of neurons can be            performance on this task, and Figure 1 compares their
synaptically connected such that they will compute desired             empirical data to our model performance in terms of the
functions. This allows us to take a cognitive theory                   time delay between movements (only conditions where no
expressed in terms of numerical values and transformations             mistakes were made are considered here).
on those values and create a detailed neural model.
                                                                   656

   The basic algorithm used is the “Sophisticated Perceptual      accuracy of this calculation has been shown to depend on
Strategy” from Simon (1975). We start with the largest disk       the properties of the neurons themselves and the complexity
that is not in the correct location. We then examine the next     of the function computed, with a general result that the
smaller disk. If it blocks the move we want to make, then         mean squared error is inversely related to the number of
our new goal is to move that disk to the one peg where it         neurons in the group (Eliasmith & Anderson, 2003).
will not be in the way. We then iterate this algorithm, going        While the NEF can be used with any neuron model, the
back to previous goals once we have accomplished the              model presented here uses Leaky Integrate-and-Fire (LIF)
current one. The effects of this algorithm can be seen in         neurons. Current entering and leaking out of each neuron
Figure 1, since steps 1, 5, 9, and 13 show long pauses as a       affects the voltage. If this voltage reaches a threshold, the
new set of goals are established. For example, in step 1, we      neuron fires, resetting the voltage to zero for a refractory
have the goal of moving disk 4 to peg C, but in order to do       period. When a neuron fires, it releases current to all
that we must first move disk 3 to peg B, which requires           connected neurons. This post-synaptic current decays
moving disk 2 to peg C, which requires moving disk 1 to           exponentially over time at a rate τ that depends on the
peg B. These goals must be generated and stored so that           neurotransmitter and receptors involved (ranging from two
once disk 1 is moved to peg B we can remember to now              to hundreds of milliseconds). The various parameters of the
move disk 2 to peg C, rather than re-generating the entire        LIF model (refractory period, membrane resistance,
sequence of moves.                                                background current, post-synaptic time constant τ, etc.) are
   Non-neural symbolic cognitive models already exist             set based on neurophsyiological measurements of different
which fit the empirical data extremely well (e.g. Altmann &       types of neurons in different brain areas. The most
Trafton, 2002). However, they do not provide a neural             important of these from a functional perspective is the post-
explanation of the operations involved, and they do not           synaptic time constant τ which effectively controls how
provide a biological grounding of the various parameters          quickly the vector being represented can change.
used within the model.                                               To represent a numerical vector with a group of LIF
                                                                  neurons, the NEF uses preferred direction vectors, which
                                                                  have long been observed throughout the visual and motor
                                                                  cortices (e.g. Georgopoulos et al., 1986). Each neuron has
                                                                  a particular vector for which it will fire most strongly. The
                                                                  amount of current J flowing into the neuron is the dot
                                                                  product of the preferred vector e with the represented value
                                                                  x, times the neuron's gain α, plus the background current
                                                                  Jbias (Eq. 1). Preferred vectors are randomly chosen, and α
                                                                  and Jbias values are distributed to match average and
                                                                  maximal firing rates of real neurons. We can force a group
                                                                  of neurons to represent a vector x by directly adding the
                                                                  amount of current computed via Eq. 1. This is used to
                                                                  provide inputs to our simulation.
                                                                     Eq. 1 allows us to convert a value x into neural activity.
                                                                  We can also do the reverse and use the neural activity to
                                                                  estimate the value x that is being represented by computing
                                                                  the optimal decoding vectors d using Eq. 2. ai is the average
                                                                  firing rate for neuron i for a given value of x, and
  Figure 1: The sequence of moves to ideally solve the four-      integration is over all values of x. To estimate x, we add
  disk Tower of Hanoi (top). Time delay for expert human          together the output current of each neuron, weighted by d.
 performance (Anderson, Kushmerick, & Lebiere, 1993) and          This is the optimal least-squares linear estimate of x.
           our neural model is also shown (bottom).                  Most crucially, we can use d to calculate the synaptic
                                                                  connection weights that will compute particular operations.
        The Neural Engineering Framework                          To compute a linear operation where x is represented by one
                                                                  group and a second group should represent Mx, where M is
The Neural Engineering Framework makes two key
                                                                  an arbitrary matrix, we set the connection weights between
assertions. First, a group of neurons uses distributed
                                                                  neuron i in the first group and neuron j in the second group
encoding to represent a numerical vector, where different
                                                                  to ωij as per Eq. 3. For non-linear operations, we do the
patterns of activation indicate different values for that
                                                                  same, but compute a new set of d values via Eq. 4.
vector. Second, synaptic connection weights between
neurons can be defined so that particular operations can be             J = e⋅x J bias                                  (1)
computed. Thus, if one neural group is storing a vector with            d =    ij =∫ ai a j dx  j =∫ a j x dx
                                                                                 −1
                                                                                                                          (2)
three elements (e.g. [x,y,z]), then these could be connected
                                                                         ij = j e j M d i                               (3)
to a second neural group that would store two values
                                                                        d =   ij =∫ ai a j dx  j =∫ a j f  x  dx
                                                                          f x     −1
calculated from those three (e.g. [x*y,cos(y)+sin(z)]). The                                                               (4)
                                                              657

The NEF allows us to convert an algorithm in terms of               implement actions in two ways. Direct actions involve
vectors and calculations on those vectors into a neural             sending a particular vector to a cortical area (implemented
model. To use it to create cognitive models, we need to             as in Figure 2, but with connections going the other way).
express cognitive algorithms in terms of vectors. As a              Routing actions indicate that information should be sent
simple example, consider the case of storing state                  from one cortical area to another. These are implemented
information in one group of neurons and we want another             by having a neural group that takes input from the first
group of neurons to represent how similar that state is to          group and passes it on to the second (both connections
some desired state. This might be used as part of an                computed using Eq. 3 where M is the identity matrix). We
algorithm that says “IF state=A THEN....”                           then add a group of neurons in the thalamus which inhibit
   To convert this into vectors, we can consider the                all of the neurons in this middle group (ωij=-1), causing this
similarity measure to be a single number (a vector of               communication channel to do nothing most of the time. The
dimension 1). In contrast, the state can include many               thalamus can now implement the action of passing the
possible aspects, so we represent it as a high-dimensional          information between the cortical areas by inhibiting these
vector. In this paper, we use 128-dimensional vectors               inhibitory neurons (see Figure 3).
represented with 3000 neurons. Each neuron has a                       The basal ganglia model used is from Gurney, Prescott,
randomly chosen preferred vector e, and α and Jbias values          and Redgrave (2001), which is expressed in terms of vectors
chosen to give an average firing rate around 40Hz and a             and mathematical operations, making it natural to convert to
maximum firing rate of 200Hz. We can now use Eq. 1 to               spiking neurons using the NEF. We have shown (Stewart,
force the neurons to represent whatever state x we desire.          Choo, & Eliasmith, 2010a) that this model can reliably
   To compute the similarity between the current state x and        detect states and implement direct and routing actions. By
the particular state A, we connect these neurons to a smaller       setting the properties of neurons to those typical of the
group of 40 neurons representing a single number. To                neurons in these various brain regions, we found that direct
compute the similarity, we want to calculate the dot product        actions are performed in 34-44ms, while routing actions
between x and A. The synaptic connection weights that will          require 59-73ms (Stewart, Choo, & Eliasmith, 2010b).
do this are given by Eq. 3, where M is the vector A. Figure
2 shows that as the state value is adjusted, the firing rate of
the second group of neurons changes accordingly.
                                                                     Figure 3: The basal ganglia, thalamus, and cortex. Input to
Figure 2: Computing the similarity between the current state           basal ganglia is calculated as in Figure 2, with IF matrix
  and a specific state A. The straight line shows the correct        containing ideal states for each action. Output to thalamus
 answer as the state value varies over time. The jagged line          inhibits all actions except best one. Connections to cortex
 is the value represented by the similarity neurons, decoded          via THEN matrix implement actions. Gate connection has
  with Eq. 2. Spike times of these neurons are also shown.           ωij=-1. All other connections calculated using Eq. 3, with I
                                                                          as the identity matrix and [1] as a matrix of all 1's.
                     Action Selection                                   STN=subthalamic nucleous; GPi, GPe=globus pallidus
In previous work (Stewart, Choo, & Eliasmith, 2010a), we             internal, external; D1, D2 are distinct types of striatal cells.
developed a model of action selection that conformed to the
anatomy of the basal ganglia, thalamus, and cortex. Groups                                Cortical Modules
of neurons in the cortex represent state information, and           The action selection system is capable of controlled routing
connections between the cortex and basal ganglia compute            of information between cortical areas. To create a cognitive
the similarity between the current state and the ideal state        model, we need to specify what these cortical areas are and
for each action available to the agent (as in Figure 2). The        what operations they perform. These areas should be
role of the basal ganglia is to find the maximum of these           general-purpose, in that they should be useful for many
values, and its output to the thalamus should inhibit all           different tasks, not just the Tower of Hanoi, since we do not
actions except for the one action whose ideal state is closest      expect large-scale cortical change when learning the task.
to the current state. Connections from thalamus to cortex
                                                                658

   To implement the Tower of Hanoi algorithm, we need to            To store a set of goals, we compute the sum of the
keep track of three variables: the thing we are currently        combined vectors V=D4⊗C+D3⊗B+D2⊗C. To recall
attending to, the thing we are trying to move, and the           where we wanted to place a particular disk (e.g. D3), we
location we are trying to move it to. For this model, we         compute V∅D3, which gives a result of approximately B
assume these are stored in three separate cortical areas         (accuracy improves with increased dimensions).
referred to as ATTEND, WHAT, and WHERE.                             For our neural model of this process, we use Figure 6.
   These systems must be capable of maintaining their state.     The WHAT and WHERE values are combined and fed into
That is, given no input, they should continue to represent       the MEMORY. Since the MEMORY has a feedback
whatever vector they are currently representing. This            connection, any input will be added to its current value
requires feedback, as in Figure 4. Synaptic connections are      (MEMORY=MEMORY+α*WHAT⊗WHERE). The value
computed with Eq. 3, where M is the identity matrix I.           α (set to 0.01) controls how quickly the memory will store
However, given an input, the feedback loop should be             new information and forget old information. Thus, any time
disabled. This is done with inhibitory weights between the       a value is present in both the WHAT and WHERE neural
input and the feedback neurons (ωij=-1).                         groups, information about that pair will be stored in the
                                                                 memory. Once it is stored, to extract WHERE we planned
                                                                 to place a particular disk, we place its value in WHAT and
                                                                 nothing in WHERE. The value in RECALL should now be
                                                                 the vector for the peg we want to move it to.
                                                                    Our neural model also needs inputs and outputs. Creating
                                                                 a complete model of the visual and motor systems required
                                                                 for this task is outside the scope of this paper. Instead, we
                                                                 create neural groups and directly calculate via Eqs. 1 and 2
                                                                 what input currents should be fed to the vision system, and
                                                                 what actions are being indicated by the motor outputs. For
                                                                 input, we have the location of the currently attended object
                                                                 (ATTEND_LOC), the location of the object we are trying to
                                                                 move (WHAT_LOC), and the final end goal location of the
Figure 4: Maintaining and changing state. Input neurons are      object we are trying to move (GOAL_LOC). For output, we
   set to represent A from 0.1-0.2s, B from 0.3-0.4s, and A      have two motor areas for indicating what disk should be
  from 0.5-0.6s. Plotted similarity is between the decoded       moved (MOVE_WHAT) and where it should be moved to
vector from the state neurons and the randomly chosen ideal      (MOVE_WHERE). We also include a simple action that
  vectors for A and B. The state is successfully stored over     causes attention to move to the largest disk (i.e. sets the
    time and changes quickly when a new value is input.          value in ATTEND to the vector for the largest visible disk).
   The Tower of Hanoi algorithm also requires us to store
and recall old goals of what disk to place where. Storing a
single goal such as “disk 4 on peg C” would be easy: add
the vectors together (D4+C) and store the result using a
mechanism similar to that in Figure 4. However, multiple
                                                                                                             D4⊗ C
goals cannot be stored in this manner, as (D4+C)+(D3+B)
                                                                                                       D2⊗ C
cannot be distinguished from (D4+B)+(D3+C). This can be                                D3⊗ B
seen as an instance of the classic binding problem.
   Binding using vector representations has been addressed
by a family of approaches known as Vector Symbolic
Architectures (VSAs; Gayler, 2003). VSAs introduce a
mathematical operation that combines two vectors to
produce a third that is highly dissimilar (dot product near
zero) to either original vector. Since this operation is
reversible, we can add together the combined vectors, store
the result, and reliably extract the individual inputs.
   For our model, we follow Plate (2003) and use circular
convolution ⊗ to combine vectors and circular correlation         Figure 5: Goal memory. Vector pairs (D4,C; D3,B; D2,C)
∅ as an approximate inverse. These operations can be              are presented in sequence to WHAT and WHERE neurons
neurally implemented using Eqs. 3 and 4 as detailed in               for first 3 seconds, loading the memory (top). After 1
(Eliasmith, 2005), and we have argued this approach allows         second of no input, a recall is performed by putting D3 in
for complex structured symbol manipulation in neurons               WHAT and nothing in WHERE. The RECALL neurons
(Stewart & Eliasmith, 2009).                                       (bottom) now represent B, successfully recalling the goal.
                                                             659

  Figure 6: The Tower of Hanoi model. Connections are calculated as in Figures 3, 4, and 5. All state values project to basal
ganglia for action selection. Basal ganglia chooses best action, releasing inhibition on that one action in thalamus. Thalamus
projects values to state inputs (direct actions) and controls gates (routing actions) to implement the action. Inputs and outputs
are provided via visual and motor cortex, which are the only elements not done in spiking neurons. Total # neurons: 150,640.
              The Tower of Hanoi Model                               and C in WHERE. Next, we check if the object we are
                                                                     trying to move is in its target location.            If it is
The components described in the previous sections define
                                                                     (WHERE=WHAT_LOC), then we've already finished with
the vast majority of the neurons and synaptic connections
                                                                     this disk and need to go on to the next smallest disk (loading
within our model. We next need to define the set of internal
                                                                     D3 in WHAT and routing GOAL_LOC to WHERE).
actions the model can perform, and the conditions in which
                                                                        If the disk in WHAT is not where we are trying to move it
it should perform each action. These rules define the IF and
                                                                     to (WHERE is not equal to WHAT_LOC), then we need to
THEN matrices in Figure 3, and allow us to solve for the
                                                                     try to move it. First, we look at the next smaller disk (send
connections from cortex to basal ganglia (IF) and from the
                                                                     D3 to ATTEND). If we are attending a disk that is not the
thalamus to cortex (THEN).
                                                                     one we are trying to move (ATTEND is not WHAT) and if
   For each action, we determine what state the system
                                                                     it is not in the way (ATTEND_LOC is not WHAT_LOC or
should be in for that action to occur. We then connect the
                                                                     WHERE), then attend the next smaller disk. If it is in the
cortical state neurons to the basal ganglia using Eq. 3 where
                                                                     way (ATTEND_LOC=WHAT_LOC or ATTEND_LOC=
M is the vector representation of the ideal state, as in Figure
                                                                     WHERE), then we need to move it out of the way. To do
2. In addition, we can also create a neural group that will
                                                                     this, set a goal of moving the disk to the one peg where it
compute the dot product between two cortical states,
                                                                     will not be in the way. The peg that is out of the way can be
allowing us to define rules that will only apply if two states
                                                                     determined by sending the value A+B+C to WHAT and at
are the same (or different), regardless of what they are.
                                                                     the same time sending the values from WHAT_LOC (the
   To implement the effects of an action, we connect that
                                                                     peg the disk we're trying to move is on) and ATTEND_LOC
action's thalamic neurons to the cortical neurons we want to
                                                                     (the peg the disk we're looking at is on) to WHAT as well,
affect. Connection weights are found using Eq. 3, where M
                                                                     but multiplied by -1.        The result will be A+B+C-
is the vector V we want to send to that cortical area. If the
                                                                     WHAT_LOC-ATTEND_LOC, which is the third peg.
neurons are active (representing 1), the effect will be to add
                                                                        This algorithm, with a special case for use when attending
the vector 1*V=V to that area. If the action neurons are
                                                                     the smallest disk (D1 can always be moved, since nothing is
inhibited by the basal ganglia (as will be true for all actions      ever in its way, and if we've made it to D1 without finding
other than the current best one), the output will be 0*V=0.          anything in the way, then we can move the disk we're trying
The same approach is used for routing actions except M=-1,           to move), is sufficient for solving Tower of Hanoi.
which will inhibit the gate which is inhibiting the                  However, it does not make use of the memory system, so it
communication channel between the cortical areas.                    has to rebuild its plans each time. To address this, we first
   The algorithm is to ATTEND to the largest disk (placing           add a rule to do nothing if RECALL is not the same as
D4 in ATTEND). Next, we form a goal to place D4 in its               WHERE. This occurs if we've set a new goal, but there has
final location (route ATTEND to WHAT and GOAL_LOC                    not been enough time for the memory to hold it (see Figure
to WHERE). We now have D4 in ATTEND and WHAT                         5). Next, rules are added for the state where we have just
                                                                660

finished moving a disk. Instead of starting over from the           performance is in the right ballpark is highly encouraging,
beginning, we send the next largest disk to ATTEND and              and we expect to improve this by exploring modifications to
WHAT and route the value from RECALL to WHERE.                      the set of rules. For example, Altmann and Trafton (2002)
This recalls the goal location for the next largest disk and        add heuristics such as “whenever you move disk 2, move
continues the algorithm. All of this requires 19 actions.           disk 1 on top of it” and “don't undo your previous move”.
                                                                      Our ongoing research is to develop this model into a full
                                  Results                           neural cognitive architecture. This involves exploring the
The model is able to successfully solve the Tower of Hanoi,         use of the same cortical components in multiple tasks and
given any valid starting position and any valid target              identifying neurological constraints. We are also adding
position. It does occasionally make errors, and recovers            learning rules to adjust the IF weights into the basal ganglia
from them (analysis of these errors is ongoing).                    to improve performance over time, as this is where the
    Figure 7 shows particular measures from the model as it         dopamine implicated in reinforcement learning is found.
solves the task. The input to the basal ganglia is the
context-dependent utility of the 19 different actions it could                               References
perform. To demonstrate its successful action selection in          Altmann, E. M. & Trafton, J. G. (2002). Memory for goals:
these circumstances, the spiking output from the basal                An activation-based model. Cognitive Science, 26, 39-83.
ganglia to the thalamus is shown. Different groups of               Anderson J. R., Kushmerick, N., & Lebiere, C. (1993).
neurons stop firing at the same time, releasing the inhibition        Tower of Hanoi and goal structures. In Anderson, J. R.
in the thalamus, allowing that particular action to occur.            Rules of the Mind, L. Erlbaum Associates.
                                                                    Choo, F., Eliasmith, C. (2010). A Spiking Neuron Model of
                   Do nothing until
                   RECALL=W HERE    AT T END  Move disk 1             Serial-Order Recall. 32nd Annual Conference of the
                                    next disk                         Cognitive Science Society.
                                                 Move disk 2        Eliasmith, C. (2005). Cognition with neurons: A large-scale,
                                                                      biologically realistic model of the Wason task. 27th
                                                                      Annual Meeting of the Cognitive Science Society.
                                                                    Eliasmith, C. & Anderson, C. (2003). Neural Engineering:
                                                                      Computation, representation, and dynamics in
                                                                      neurobiological systems. Cambridge: MIT Press.
                                                                    Gayler, R. (2003). Vector symbolic architectures answer
                                                                      Jackendoff’s challenges for cognitive neuroscience.
                                                                      International Conference on Cognitive Science.
                                                                    Georgopoulos, A.P., Schwartz, A., & Kettner, R.E. (1986).
                                                                      Neuronal population coding of movement direction.
                                                                      Science, 233, 1416-1419.
                                                                    Gurney, K., Prescott, T., & Redgrave, P. (2001). A
                                                                      computational model of action selection in the basal
   Figure 7: Input to basal ganglia (top) and action selection
                                                                      ganglia. Biological Cybernetics 84, 401-423.
output to thalamus (bottom) during typical moves 1 and 2 of
                                                                    Rasmussen, D., Eliasmith, C. (2010). A neural model of
 the Tower of Hanoi task. Changing input reflects changing
                                                                      rule generation in inductive reasoning. 32nd Annual
    similarity between cortex states and ideal states for each
                                                                      Conference of the Cognitive Science Society.
      action. Utilities for four example rules are indicated.
                                                                    Simon, H. A. (1975). The functional equivalence of problem
Spiking output inhibits actions from being executed. At any
                                                                      solving skills. Cognitive Psychology, 7(2), 268–288.
  given time, one group of output neurons (corresponding to
                                                                    Stewart, T.C., Choo, X., & Eliasmith, C. (2010a). Symbolic
   the largest input) will stop firing (as seen in bottom spike
                                                                      reasoning in spiking neurons: A model of the cortex/basal
raster), releasing inhibition and allowing the action to occur.
                                                                      ganglia/thalamus loop. 32nd Annual Meeting of the
                                                                      Cognitive Science Society.
The average time delay between moves when no errors
                                                                    Stewart, T.C., Choo, X. & Eliasmith, C. (2010b). Dynamic
occur is shown in Figure 1, compared to human
                                                                      behaviour of a spiking model of action selection in the
performance. The model does not exactly match the
                                                                      basal ganglia. 10th Int. Conf. on Cognitive Modeling
empirical data. However, it should be noted that there is
                                                                    Stewart, T.C,, & Eliasmith, C. (2009). Compositionality
only one parameter in the entire model: the scaling factor α
                                                                      and biologically plausible models. In W. Hinzen, E.
in the memory system. All other timing parameters are
                                                                      Machery, & M. Werning (Eds.), Oxford Handbook of
taken from the neurophysiology of the various brain
                                                                      Compositionality.
regions. (The number of neurons in each group is also
                                                                    Stewart, T.C. & Eliasmith, C. (2010). Neural symbolic
freely chosen, but affects accuracy rather than timing).
                                                                      decision making: A scalable and realistic foundation for
    Our main result is that we can create a neural model at
                                                                      cognitive architectures. Proceedings of the 1st Annual
this level of complexity, implementing symbolic algorithms
                                                                      Meeting of the BICA Society.
in a non-symbolic manner. The fact that the model
                                                                661

