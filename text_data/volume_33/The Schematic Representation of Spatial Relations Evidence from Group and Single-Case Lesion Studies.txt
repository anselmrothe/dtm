UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Schematic Representation of Spatial Relations: Evidence from Group and Single-Case
Lesion Studies

Permalink
https://escholarship.org/uc/item/1dc6398m

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Kranjec, Alexander
Amorapanth, Prin
Chatterjee, Anjan

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Schematic Representation of Spatial Relations: Evidence from Group and
Single-Case Lesion Studies
Alexander Kranjec (akranjec@mail.med.upenn.edu)
Neurology Department, University of Pennsylvania
Philadelphia, PA 19104, USA
Prin Amorapanth (amorapan@mail.med.upenn.edu)
Neurology Department, University of Pennsylvania
Philadelphia, PA 19104, USA
Anjan Chatterjee (anjan@mail.med.upenn.edu)
Neurology Department, University of Pennsylvania
Philadelphia, PA 19104, USA
Abstract

transactions or seasonal events for example—before the
advent of full-blown symbolic writing systems (Tversky,
2001). What maps, pictograms and calendars have in
common is that each compacts a more complex reality into a
simplified, or “boiled down” representation that preserves
something about the meaning of the thing is represents.
Most generally, the term schema is used in this paper as any
kind of representation (external or cognitive) where some
level of perceptual detail has been abstracted away from a
complex scene or event while preserving critical aspects of
its analog qualities. Schemas, as such, occupy a
representational middle-ground: more abstract than very
concrete representations of objects, but unlike truly
symbolic representations, like words, a schema preserves
some of the spatial relational aspects of the thing it stands in
for. The most critical aspect of schemas, as the term will be
employed in the present paper, is that they occupy a
theoretically intermediate position between abstract words
and concrete percepts in a graded model of representation
(A Chatterjee, 2001; A. Chatterjee, 2010; Kranjec &
Chatterjee, 2010). Although dissociations on concrete word
and picture comprehension tasks have been reported
(Saffran, Coslett, Martin, & Boronat, 2003) intermediate
formats like schemas have not been thoroughly investigated.
We are interested in understanding whether the brain
distinguishes between paired-down, externalized depictions
of spatial schemas from other information formats like
words and pictures.
Perhaps because schemas are simple and ubiquitous, they
are easy to take for granted. We commonly use such
external, or explicit schemas when we find the appropriate
restroom, read a map, obey traffic signs or interpret graphs
and diagrams. What makes schemas so simple to use is also
what makes them so common across cultures, contexts and
academic disciplines. When people produce or use
schematic figures in an explicit manner, a small set of basic
spatial forms provides enough structure to convey discrete
meanings. Configurations of circles and lines in space can
describe complex relations among a wide array of concrete

To what extent are schematic representations neurally
distinguished from language on the one hand, and from rich
perceptual representations on the other? In a group lesion
study, matching tasks depicting categorical spatial relations
were used to probe for the comprehension of basic spatial
concepts across distinct representational formats (words,
pictures, schemas). Focused residual analyses using voxelbased lesion-symptom mapping (VLSM) suggest that left
hemisphere deficits in categorical spatial representation are
difficult to distinguish from deficits in naming such relations,
and that the right hemisphere plays a special role in extracting
schematic representations from richly textured pictures.
EE555, a patient with simultagnosia, performed six similar
matching tasks. On the only two tasks that did not include
matching to, or from, schemas, EE555 performed at chance
levels. EE555 was significantly better on schema tasks,
indicating that abstract analog representations make spatial
relations visible in a manner that symbols and complex
images do not.

Keywords: schemas; spatial relations; vlsm; case studies

Introduction
Can abstract meaning be represented without language?
Although it is clear that we can think about concrete
concepts without language, it is difficult to know how to
best characterize mental representations of abstract concepts
that are both meaningful and non-linguistic. A place to start
could involve observing how abstract semantic information
is intentionally transmitted without either the aid of words
or rich imagery. Abstract graphics have been used to convey
such meanings long before humans kept formal history.
Map-like cave drawings, rendered over 6,000 years ago,
appear to make use of simplified visual elements like dots,
lines and rectangles to represent the abstract spatial
topologies and arrangements of dwellings, paths or crops
(Chippindale & Nash, 2004; Smith, 1982). Pictograms and
calendars were used for communicating important, highly
abstract forms of cultural information—about commercial

417

or abstract entities that will be understood by the majority of
people. At the most fundamental level of schematic
representation, lines stand for barriers or surfaces, circles
stand for enclosed spaces, and arrows stand for paths
(Tversky, Zacks, Lee, & Heiser, 2000). These core
meanings are not arbitrary. Rather, the abstracted forms
themselves suggest the meaning of the primitive spatial
concept they aim to represent. This universal spatial
“vocabulary” suggests that a core set of conceptual
primitives underlies our use of schemas.
But can the meanings of abstract concepts be processed
without language-dependent mental representations? While
a good deal about spatial schemas has been written within
cognitive linguistics (Lakoff & Johnson, 1999; Mandler,
1992; Talmy, 2000), virtually nothing about their neural
organization is known. In cognitive neuroscience, research
in this general area has focused on the representation of
prepositions. Work by Friederici (Frederici, 1981)
demonstrated that Wernicke aphasics have impairments in
processing locative prepositions. Landau and Jackendoff
(1993) subsequently proposed that parietal cortex, by virtue
of being the terminus of the dorsal “where” pathway, might
process prepositions. This hypothesis was corroborated by
work from Damasio and colleagues demonstrating a role for
left supramarginal gyrus and inferior frontal gyrus in the
comprehension of locative prepositions (Damasio et al.,
2001); (Emmorey et al., 2002). Noordzij et al. (2008) also
found that understanding the kind of categorical spatial
relations expressed by locative prepositions was associated
with activation in the left supramarginal gyrus. And Wu et
al. (2007) found locative relations to be mediated by left
inferior frontal-parietal cortices. The overall picture that
emerges from both the literature on prepositions and that on
categorical spatial relations is one that strongly implicates
the left hemisphere over and above the right.
The current investigation concerns the neural organization
underlying our use of spatial schemas when thinking about
space. We are interested in how we access spatial
meanings—like we do when we use simple verbal labels to
describe the spatial relations of objects arrayed in
perceptually rich scenes, but also when we make use of
schemas. The current study attempts to distinguish between
those brain areas responsible for representing spatial
relations in (1) rich perceptual detail, (2) an intermediate
level of schematic abstraction as described above and (3)
language. Schemas are more concrete compared to the
arbitrary letters and sounds that represent a word like “IN”
and more abstract than photographs or drawings depicting
real world scenes in space.
Work from our lab, as well as others, implicates areas
within the left hemisphere, specifically inferior parietal lobe
and frontal operculum, as being involved in the
representation of categorical spatial relations of the type that
are encoded by locative prepositions (Amorapanth, Widick,
& Chatterjee, 2010; Damasio et al., 2001; Noordzij et al.,
2008; Tranel & Kemmerer, 2004; Wu, Waller, & Chatterjee,
2007).

The main hypotheses being tested in Experiment 1
concern the extent to which the left or right hemisphere
show a preference for schematic representation and the
extent to which schematic representations are distinguished
from language on the one hand and from rich perceptual
representations on the other. As suggested by previous
research, damage to the left hemisphere in areas postulated
to be critical for the representation of lexicalized categorical
spatial relations might, in parallel, compromise their
schematic representation. Alternatively, right hemisphere
areas critical for the representation of nonverbal spatial
information may be implicated in representing such abstract
meaning without language. The mediating role that schemas
are hypothesized to play between language and
perception—in representing the meaning of categorical
spatial relations—suggest that either of the above principles
of neural organization could be the case. We sought to test
the validity of these two alternative hypotheses. Experiment
2 then investigates whether such intermediate forms of
representation, because of their possible role in linking
language and perception, might facilitate comprehension in
a patient with severe spatio-visual deficits.

Stimuli
Word and Picture Selection
We selected four prepositions to serve as the words in our
matching tasks according to two main preposition classes
described in the literature (Talmy, 2000). Most simply:
topologic prepositions describe figure-ground relations that
vary along the dimensions of contact and degree of
enclosure, (i.e. IN and ON); and projective prepositions,
describe figure-ground relations that vary along the
dimensions of vertical or horizontal displacement (i.e.
ABOVE and BELOW). Each matching task used these 4
spatial concepts.
For the pictures in our matching tasks, we used realistic
color image stimuli. The selected pictures were designed to
unambiguously depict the same spatial relations as denoted
by the prepositions. The objects in these pictures consisted
of a small set of relatively common household or office
items that could function as the figure or ground object for
the locative relations being tested (e.g. a pair of scissors, a
mug, a fork, a cutting board). As much as possible, we used
the same objects, arranged in different ways, to depict
distinct lexicalized spatial relations.
We constructed schemas consisting of simple lines and
geometric forms using graphic-making tools in Photoshop.
The set of four schemas varied along parameters proposed
by Talmy (2000), such as containment, support, and degree
of separation.
The particular stimuli used in Experiments 1 and 2
differed although their structure was essentially identical.

Experiment 1: Group Study (VLSM)
Participants
17 right hemisphere damaged (RHD) and 17 left hemisphere
damaged (LHD) patients ranging from 48-85 years of age

418

(RHD: mean = 60.4; LHD: mean = 60.9) with chronic
lesions (of at least six months duration) were recruited from
the Focal Lesion Patient Database (Center for Cognitive
Neuroscience, University of Pennsylvania). The subjects
were not selected on the basis of specific behavioral criteria,
except that patients with a history of other neurological
disorders affecting the central nervous system or psychiatric
disorders are excluded from the patient database. All
subjects were native English speakers and right handed.

in a particular spatial relationship to one of four target
images containing different pairs of objects (Figure 1D).

Voxel-based lesion symptom mapping (VLSM)
analyses
Using brain-imaging software developed at the University
of Pennsylvania (www.voxbo.org), t-tests compared
behavioral scores between patients with and without lesions
at every voxel for each lesion map (RH and LH maps were
analyzed separately). We restricted our analyses to voxels in
which at least 2 patients had lesions. The t-map for each
analysis was thresholded to control the False Discovery
Rate (FDR) at q = 0.05. The procedure allows us to identify
a threshold that controls the expected proportion of false
positives. In our dataset, selecting a false discovery rate (q
value) of 0.05 yields a t threshold. This means that of the
total number of voxels in an analysis with t values
exceeding this threshold, the expected proportion of false
positives is 0.05.

Procedure
Spatial Matching tasks Incorporating the three basic types
of stimuli described above (words, pictures and schemas)
we used four matching tasks to investigate cognitive
processing across representational formats. All tasks
required participants to match a relation depicted in a probe
item to one of four target items. See Figures 1A-D. In
Experiment 1, each of the four tasks consisted of 22 trials.
Individual probe items depicted one of four discrete spatial
relations used in each task. All tasks in the present study
used two spatial probes representing topological relations
(IN or ON) and two representing projective relations
(ABOVE or BELOW).
Picture-schema matching This task was designed to assess
patients' abilities to abstract spatial concepts from different
photographic representations and match them to simplified
representations consisting of lines and geometric figures.
Patients were presented with a probe photographic image
situated adjacent to four schematic target images. (Fig. 1A)
Among the four targets to choose from, one correctly
depicted the spatial relationship in the probe image, one
depicted a within-class relation, and two depicted acrossclass relations. Foils were distributed as such in all four
tasks. For each task, subjects indicated which one of four
pictures or schemas depicted the correct answer either by
pointing or by reading the letter underneath a particular
image.
Word-schema matching This task was designed to test
patients' abilities to extract the appropriate spatial meaning
from locative prepositions and match them to simplified
schematic representations. Word probes were presented
adjacent to four target schemas as in the picture-schema
matching task (Figure 1B).
Word-picture matching This task was designed to test
patients' abilities to extract the appropriate spatial meaning
from locative prepositions and match them to one of four
photographic representations. Patients matched a probe
word to one of four target images containing different pairs
of objects (Figure 1C).

Figure 1: Types of matching tasks. (Group Study 1A-D;
Case Study 1A-F)
We incorporate residual analyses as part of our approach
to using VLSM to orthogonalize task processing
(Amorapanth et al., 2010). When performances across two
tasks are correlated, one can use VLSM to probe for
divergent brain-behavior correlations across the two tasks.

Picture-picture matching This task was designed to assess
patients' ability to generalize categorical spatial concepts
across different photographic representations. Patients
matched a probe photograph containing one pair of objects

419

By correlating the residual scores (of one task itself
correlated on another) with voxel damage, one can assess
regions of vulnerability for that task that cannot be
accounted for by vulnerability to the other task.

critical for the representation of one stimulus type over
another between matching tasks. This is the case because
VLSM residual analyses between two tasks not only
indicate brain areas critical for unique processing in one
task, but are also designed to remove the variability
explained by processing common to both.

Behavioral Results
Picture-schema task The LHD group was the most
impaired on this task (average accuracy=62.30%,
range=18.18-90.91%; SE=5.98). They scored significantly
lower than the RHD group [average accuracy = 82.09%,
range=54.55-95.46%; SE =2.60; t(32) = 2.93, p < .01].
Word-schema task The LHD group was the most impaired
on this task (average accuracy=66.48%, range=27.2795.45%; SE =5.39). They scored significantly lower than the
RHD group [average accuracy=88.24%, range=63.64100%; SE =2.65; t(32) = 3.47, p < .01].
Word-picture task Scores for the LHD group (average
accuracy=81.02%, range=32-100%; SE =5.60) were
significantly lower than for the RHD group [average
accuracy = 94.39%, range=82-100%; SE =1.43; t(32) = 2.23,
p < .05).
Picture-picture task The LHD group (average
accuracy=74.87%, range=23-95%; SE =4.25) was not
significantly different from the RHD group (average
accuracy = 80.75%, range=68-95%; SE =2.045)

Residual VLSM analyses
Residual analyses are shown in Figures 2c and 2d. By
design, for VLSM methods, greater behavioral variability
within groups is desirable to identify specific brain behavior
correlations. This greater behavioral variability within each
group maximizes the likelihood of finding statistically
robust differences within the group and minimizes the
likelihood of finding differences across groups.
In order to (1) determine if the right and left hemispheres
are differentially implicated in the representation of
schematic information and (2) test the hypothesis that the
hemispheres might differ in the extent to which they
distinguish between kinds of non-linguistic spatial
information, we conducted 3 residual analyses on 2 pairs of
matching tasks.
We residualized tasks against each other in order to
establish orthogonal measures for particular representational
formats (Amorapanth et al., 2010). By regressing
performance for one matching task onto another and
plotting the residual scores, we attempted to isolate
behavioral variance associated with processing within a
single representational format, or stimulus type (i.e. word,
picture, or schema). For the most revealing residual
analyses, matching tasks were paired in such a way that,
relative to the other, each was composed of one unique and
one common stimulus type. These pairings also ensured that
all stimulus types were included in each analysis. With such
paired comparisons, VLSM indicated the brain areas most

Figure 2: VLSM. (Lesion overlap 2A, B; Results 2C, D)
Word more than Picture (Word-Schema > PictureSchema) The corrected t-statistic threshold with a
significance level of p = .05 was 2.87112 for the LHD
group. There were no significant effects within the RHD
group. The word > picture residual analysis found that
lesions to the left middle frontal gyrus, premotor and
primary motor cortex, superior temporal gyrus and white
matter undercutting the supramarginal gyrus are
significantly correlated with impaired processing of word
stimuli compared to picture stimuli. (Figure 2c [top].)
Picture more than Word (Picture-Schema > WordSchema) The corrected t-statistic threshold with a
significance level of p =.05 was 4.38983 for the RHD
group. There were no significant effects for the LHD group.

420

The picture > word residual analysis found that lesions in
the right inferior, middle frontal and central gyri, and
primary motor cortex are significantly correlated with
impaired processing of picture stimuli compared to word
stimuli. (Figure 2c [bottom].)

tasks with schemas (schema-to-picture [S‐P]; word-toschema [W‐S]; schema-to-schema [S‐S]; picture-to-schema
[P‐S]) performance was significantly better than chance
(50%, 74%, 67%, 84% respectively, χ2, p’s < .01).
Accuracy results are summarized in Figure 3.

Schema more than Picture (Word-Schema > WordPicture) There were no significant effects for the LHD
group. The corrected t-statistic threshold with a significance
level of p =.05 was 5.09678 for the RHD group. The schema
> picture residual analysis found that lesions in the
supramarginal gyrus are significantly correlated with
impaired processing on schema stimuli compared to picture
stimuli. (Figure 2d.)
Results Summary The results of the residual analyses
suggest that verbal components of the matching tasks are
processed in the left hemisphere (WORD > PICTURE) and
pictorial components in the right hemisphere (PICTURE >
WORD). They further suggest that the right hemisphere
differentiates between distinct spatial formats (SCHEMA >
PICTURE).

Figure 3: Accuracy across all tasks for EE555 and controls.
Schemas appear to make spatial relations visible for a
patient with simultagnosia. These results provide general
insight as to how schemas facilitate spatial reasoning when
used in graphic depictions, and how such theoretically
intermediate representational structures could serve to link
perceptual and verbal representations of spatial relations in
the brain. It is our position that, (1) schemas are
intermediate representational structures that link pictures
and words; that they (2) preserve analog qualities like
pictures, but may be particularly useful, especially for an
individual with simultagnosia, because they may be (3)
processed more holistically like symbols

Experiment 2: Single Case Study
Simultagnosia presents an interesting case for the
investigation of schemas. If schemas help us to abstract
spatial relations from complex scenes, and aid relational
thinking, perhaps they might be especially helpful for an
individual with simultagnosia.

Participants
Patient EE555 (43 years old, 18 years education)
experienced three parietal lobe infarcts between May and
June of 2004. These events resulted in bilateral lesions
extending from the occipital lobes to middle parts of the
inferior parietal sulcus. Behavioral testing indicated
simultagnosia. EE555 was unable to comprehend more than
a one object simultaneously 30 months after her most recent
stroke. For example, she showed a complete local bias with
Navon Letters. (Berryhill, Fendrich, & Olson, 2009). An
age and education matched control group also participated
(N=5; meanage=51.4 years, meaneducation=17 years).

General Discussion
Simplified schematic representations appear ubiquitously in
maps and diagrams. Yet, little is known about the neural
instantiation of these important communicative devices. We
were interested in understanding the neural organization for
schematic representations of spatial relations. Considering
the intermediate representational status of schemas, and that
previous studies investigating locative spatial relations have
implicated both left and right hemisphere neural structures,
we wished to determine how schematic representations of
categorical relations might be related to verbal descriptors
on the one hand and to richly textured perceptual
representations on the other.
The simple meanings of prepositions when used to
describe concrete spatial relations, presented the prospect of
investigating the structure of the semantic system in a
particularly stark form. We investigated the neural basis of
spatial semantics by distinguishing between those meanings
associated with (1) phonological and orthographic
representations, or words, (2) richly textured images or
pictures and (3) simplified abstract images or schemas.
These schemas serve as intermediate structures between
words and rich perceptual scenes. One can summarize our
findings by saying that these systems appear to be
intertwined both functionally and anatomically. The left

Procedure
Spatial matching tasks The design of the case study was
very similar to that of the group study, however, in addition
to word-schema, picture-schema, word-picture, and picturepicture matching tasks, EE555 and controls also performed
two additional matching tasks: schema-word, and schemaschema (Fig1A-F). Each task consisted of 80 trials.

Results
Controls outperformed EE555 on all tasks [p’s <.01
(Crawford & Garthwaite, 2007)]. On the two tasks that did
not include matching to, or from, schemas (word-to-picture
[W‐P]; picture-to-picture [P‐P]) EE555 performed at chance
levels (20% and 25%, respectively; χ2, p’s > .3). For the

421

hemisphere does seem to be biased to process these kinds of
categorical spatial relations. However, we find no evidence
that the left hemisphere distinguishes between different
kinds of analog representations. Furthermore, categorical
spatial representation deficits in the left hemisphere are
difficult to distinguish from deficits associated with labeling
these relations verbally.
The observations from our left-brain damaged participants
In Experiment 1 should not be taken to infer that perceiving
categorical spatial relations in humans is solely a function of
the ability to name them. Data from our right-brain damaged
participants makes clear that deficits in these analog
categorical spatial relations do occur with right brain
damage, and that these deficits cannot be accounted for by
naming deficits. In addition, the right hemisphere
distinguishes between different kinds of analog spatial
representations (schemas vs. pictures). This result suggests
that the right hemisphere plays a special role in extracting
schematic representations from pictorial ones.
The evidence we found for the representation of
distinguishable forms of nonverbal spatial relational
information in the right hemisphere also suggests that
abstract meanings can be stored independently of left
hemisphere verbal representations. The fact that the right
hemisphere can make fine-tuned distinctions between
different kinds of nonverbal abstract categorical spatial
representations further suggests that image schema theories
may provide a valid construct for understanding how
primitive meanings can be represented without language.
The results of Experiment 2, suggest that the content of
schematic representations can bring spatial meaning to
awareness in a way that words by themselves cannot.

Crawford, J. R., & Garthwaite, P. H. (2007). Comparison of
a single case to a control or normative sample in
neuropsychology: Development of a Bayesian approach.
Cognitive Neuropsychology, 24(4), 343-372.
Damasio, H., Grabowski, T. J., Tranel, D., Ponto, L. L.,
Hichwa, R. D., & Damasio, A. R. (2001). Neural
correlates of naming actions and of naming spatial
relations. Neuroimage, 13(6 Pt 1), 1053-1064.
Emmorey, K., Damasio, H., McCullough, S., Grabowski,
T., Ponto, L. L., Hichwa, R. D., et al. (2002). Neural
systems underlying spatial language in American Sign
Language. Neuroimage, 17(2), 812-824.
Frederici, A. (1981). Production and comprehension of
prepositions in aphasia. Neuropsychologia, 19, 191-199.
Kranjec, A., & Chatterjee, A. (2010). Are temporal concepts
embodied? A challenge for cognitive neuroscience.
Frontiers
in
Psychology,
1(240),
doi:
10.3389/fpsyg.2010.00240.
Lakoff, G., & Johnson, M. (1999). Philosophy in the Flesh.
New York, NY: Basic Books.
Landau, B., & Jackendoff, R. (1993). "What" and "where"
in spatial language and spatial cognition. Behavioral and
Brain Sciences, 16, 217-265.
Mandler, J. M. (1992). How to build a baby: II. Conceptual
primitives. Psychological Review, 99(4), 587-604.
Noordzij, M. L., Neggers, S. F. W., Ramsey, N. F., &
Postma, A. (2008). Neural correlates of locative
prepositions. Neuropsychologia, 46, 1576-1580.
Saffran, E., Coslett, H., Martin, N., & Boronat, C. (2003).
Access to knowledge from pictures but not words in a
patient with progressive fluent aphasia. Language and
Cognitive Processes, 18(5/6), 725–757
Smith, C. (1982). The Emergence of 'Maps' in European
Rock Art: A Prehistoric Preoccupation with Place.
Imago Mundi, 34, 9-25.
Talmy, L. (2000). Towards a cognitive semantics: Concept
structuring systems. Cambridge, MA: The MIT Press.
Tranel, D., & Kemmerer, D. (2004). Neuroanatomical
correlates
of
locative
prepositions.
Cognitive
Neuropsychology, 21, 719-749.
Tversky, B. (2001). Spatial schemas in depictions. In M.
Gaddis (Ed.), Spatial Schemas and Abstract Thought
(pp. 79-111). Cambridge, MA: MIT Press.
Tversky, B., Zacks, J., Lee, P., & Heiser, J. (2000). Lines,
blobs,crosses,
and
arrows:
Diagrammatic
communication with schematic figures. In M. M
Anderson, P. Cheng & V. Haarslev (Eds.), Theory and
Application of Diagrams (pp. 221-230). Berlin:
Springer-Verlag.
Wu, D. H., Waller, S., & Chatterjee, A. (2007). The
functional neuroanatomy of thematic role and locative
relational knowledge. The Journal of Cognitive
Neuroscience, 19, 1542-1555.

Acknowledgements
This research was supported by the National Institutes of
Health [RO1 DC004817, RO1 DC008779] and the National
Science Foundation [subcontract under SBE0541957].

References
Amorapanth, P., Widick, P., & Chatterjee, A. (2010). The
Neural Basis for Spatial Relations. Journal of Cognitive
Neuroscience, 8, 1739-1753.
Berryhill, M. E., Fendrich, R., & Olson, I. R. (2009).
Impaired distance perception and size constancy
following
bilateral
occipitoparietal
damage.
Experimental Brain Research, 194(3), 381-393.
Chatterjee, A. (2001). Language and space: some
interactions. Trends in Cognitive Science, 5, 55-61.
Chatterjee, A. (2010). Disembodying Cognition. Language
and Cognition, 2(1), 79-116.
Chippindale, C., & Nash, G. (2004). The Figured
Landscapes of Rock-Art: Looking at Pictures in Place.
Cambridge, UK: Cambridge University Press.

422

