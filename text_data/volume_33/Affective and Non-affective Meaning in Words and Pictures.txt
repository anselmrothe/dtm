UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Affective and Non-affective Meaning in Words and Pictures
Permalink
https://escholarship.org/uc/item/8ss0g8x7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Lai, Vicky Tzuyin
Hagoort, Peter
Casasanto, Daniel
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                      Affective and Non-affective Meaning in Words and Pictures
                           Vicky Tzuyin Lai1                   Peter Hagoort1,2              Daniel Casasanto1,2,3
                          (vicky.lai@mpi.nl)              (peter.hagoort@mpi.nl)          (casasanto@alum.mit.edu)
                                       1
                                         Max Planck Institute for Psycholinguistics, Nijmegen, NL
                                  2
                                    Donders Center for Brain, Cognition, and Behaviour, Nijmegen, NL
                         3
                           Department of Psychology, The New School for Social Research, New York, USA
                              Abstract                                  affective information associated with the animals they see
                                                                        (e.g., safe or dangerous) might be very salient. If a person is
   When people see a snake, they are likely to activate both
   affective information (e.g., dangerous) and non-affective            taking a timed test for a biology class, however, and
   information (e.g., animal). According to the Affective               classifying animals according to their ontological categories,
   Primacy Hypothesis, the affective information has priority,          they might not even notice if some animals are more
   and its activation can precede identification of the ontological     dangerous than the others.
   category of a stimulus. Alternatively, according to the                 We propose a context-dependent view of affective and
   Cognitive Primacy Hypothesis, perceivers must know what              non-affective information processing. Rather than arguing
   they are looking at before they can make an affective
   judgment about it. We propose that neither hypothesis holds
                                                                        for the primacy one type of information over the other, we
   at all times. In two experiments, we show that the relative          suggest that the relative speed with which affective and non-
   speed with which affective and non-affective information gets        affective information gets activated in response to words
   activated by words and pictures depends upon the contexts in         and pictures should depend upon the contexts in which the
   which the stimuli are processed. These data support a view           stimuli are processed.
   according to which words and pictures do not “have”
   meanings; rather, they are cues to activate patterns of stored
   knowledge, the specifics of which are co-determined by the
                                                                                            Affective Primacy
   item itself and the context in which it occurs.                         Three lines of empirical evidence have been used to
                                                                        support the Affective Primacy Hypothesis, namely,
   Keywords: ad hoc cognition; affective primacy; cognitive             subliminal priming (Murphy & Zajonc, 1993), affective
   primacy; affective priming; context; emotion; task set inertia.      priming (Klauer & Musch, 2003), and neuropsychological
                                                                        evidence (LeDoux, 1996). However, as can be seen in the
                           Introduction                                 following, these data seem to support an affective-early
                                                                        theory, as opposed to an affect-precedes-non-affect theory.
When people see a snake, they are likely to activate both
                                                                           Subliminal priming studies in general show that briefly
affective information (e.g., snakes are dangerous) and non-
                                                                        presented affect-laden primes (e.g., smiling and angry faces)
affective information (e.g., snakes are animals). Which kind
                                                                        can influence the affective evaluation of the subsequent
of information is activated first? For decades, researchers
                                                                        unseen targets (e.g., Chinese ideographs). In contrast,
have debated the temporal priority of affective and non-
                                                                        briefly presented non-affective primes (e.g., big and small
affective processing. According to the Affective Primacy
                                                                        geometric shapes) cannot influence the non-affective
Hypothesis (Zajonc, 1980, 2000; Murphy & Zajonc, 1993;
                                                                        processing of the unseen targets (e.g., the size of the object
LeDoux, 1996), information relevant for affective responses
                                                                        the ideographs might represent). In the latter case, though, if
can be activated quickly and automatically, before
                                                                        the presentation duration is adjusted to allow for optimal
information about ontological kinds. Alternatively, the
                                                                        viewing, the classic semantic priming (e.g., doctor-nurse)
Cognitive Primacy Hypothesis (Lazarus, 1984; Storbeck,
                                                                        effects emerge. It is argued that affect can be activated first
Robinson, & McCourt, 2006; Calvo & Nummenmaa, 2007)
                                                                        with minimal exposure, prior to the activation of non-
posits that perceivers must know what they are looking at
                                                                        affective information.
before they can make an affective judgment about it.
                                                                           Affective priming refers to the phenomenon that
   The present study investigated whether one kind of
                                                                        positively- or negatively- valenced targets (e.g., sunshine)
information is activated faster than the other, in general, or
                                                                        can be primed when preceded by primes with congruent
whether the speed with which affective and non-affective1
                                                                        valence (e.g., love) compared to primes with incongruent
information gets activated varies with context. Imagine the
                                                                        valence (e.g., death). Affective priming occurs even when
following scenarios: If a person is hiking around in a
                                                                        attention is focused on another, concurrent verbal task
tropical jungle and is constantly reminded of possible
                                                                        (Calvo & Nummenmaa, 2007), suggesting the automaticity
poisonous animals and plants in the surroundings, the
                                                                        of affective evaluation (Fazio, 2001; Bargh, Chen, &
1
                                                                        Burrows, 1996). These data support the part of the claim in
  We use “non-affective” instead of “cognitive” to allow the            the Affective Primacy Hypothesis that affect can be elicited
possibility that both affective and non-affective meaning be            with virtually no non-affective processing.
considered aspects of cognitive processing.
                                                                    390

   Neuropsychological data also upport the immediateness            and targets, people rely on that dimension, even if the
of affective evaluation (LeDoux, 1996; Whalen, Rauch,               dimension is affective.
Etcoff, McInerney, Lee, & Jenike, 1998). It has been shown             The problem with the lack of affective priming effect is
that when it comes to processing emotional stimuli, a neural        similar to the lack of non-affective processing in subliminal
system that learns the emotional significance of these              priming. The null effects cannot strongly rule out the
stimuli is activated. This system is a shortcut for ensuring        existence of either kind of priming. In addition, the fact that
fast reaction to potentially life-threatening stimuli. The          Storbeck & Robinson (2004) actually found affective
shortcut can by-pass the neural system that allows us to            priming when the semantic categorization was restricted to
identify objects, people, events, etc.                              one category suggests that people are able to make use of
   These data indeed point to a fast and early processing of        affective information when the situation (context) requires
affect. However, it is not clear if these data strongly support     them to.
the temporal primacy of affective information. For example,            Recently, an eye-tracking study provided strong support
the null results for non-affective dimension in the subliminal      for the Cognitive Primacy Hypothesis. Nummenmaa,
priming literature do not rule out the possibility that such        Hyönä, & Calvo (2010) presented their participants with
information (e.g., size) can be elicited early in                   paired pictures of emotional and neutral scenes involving
circumstances where the information is made salient (e.g.,          humans and animals. They eye-tracked the participants’
finding the right size lego for building something in a lego        saccades when they did an affective categorization (pleasant
contest). Even if one non-affective dimension (e.g., size) is       or unpleasant) task and a non-affective categorization
indeed activated late, other non-affective dimensions (e.g.,        (animal or human) task. They found that while the saccades
color) may not be perceived late. Moreover, in those                for both kinds of tasks were fast, within ~220 msec, the
subliminal priming experiments, the affective and the non-          ontological categorization always preceded the affective
affective processing are not put directly in competition with       categorization, by ~40 msec in all their experiments.
each other. As for evidence coming from the affective               Interestingly, the item-wise affective and semantic
priming effect, the automaticity of affect seems similar to         recognition times were positively correlated and additive.
the automaticity of lexical-semantic (non-affective)                They suggested that this means that affective processing is
information observed in classic Stroop tasks. So, people            an additional stage that occurs after object identification and
cannot suppress affective evaluation while doing a verbal           recognition, consistent with models in which a serial
task. People also cannot suppress lexical access of “red”           processing is assumed.
even when their task is to verbally state the blue ink color of        Nummenmaa et al. (2010) show that, across 7
the printed word “red”. If these two kinds of information are       experiments, non-affective information is consistently
compatible and can be both viewed as a feature in a                 activated faster than affective information when participants
semantic-network, then there is no need to ask which feature        judge complex scenes. They interpret this finding as strong
must be always activated first. Lastly, the shortcut for the        evidence for the Cognitive Primacy Hypothesis, and suggest
fearful stimuli in the neural system seems valid, but such a        that, “[non-affective] processing of visual scenes is faster
neural circuit does not prevent parallel processing of the          than their affective processing and…semantic categorization
non-affective aspects of the emotional stimuli. Therefore,          precedes affective evaluation” (pg. 243). We suggest that
we can agree that affective processing is early, but cannot be      this robust result may have had much to do with the
certain about whether affective processing precedes non-            particular stimuli they used. For example, judging from the
affective processing.                                               example stimuli the authors provide, the photographs might
                                                                    have biased participants toward processing the non-
                    Cognitive Primacy                               affective, ontological information first because the
Evidence supporting the Cognitive Primacy Hypothesis                information relevant for determining whether a stimulus
primarily comes from studies showing the lack of affective          was an animal or a human was detectable from coarser-
priming (e.g., Storbeck & Robinson, 2004). Storbeck and             grained visual information (i.e., information with a lower
colleagues used prime-target pairs of positive/negative             spatial frequency) than the information relevant to
words orthogonally involving semantic dimensions of                 determining the pictures’ affective content (e.g., an
religion, animal, and texture. In one experiment, they had          emotional facial expression). It is no surprise if making
the participants do a lexical decision (word/nonword) task          judgments based on fine-grained information takes longer
on the target words. In another experiment, they had the            than making judgments based on coarse-grained
participants do an affective (good/bad) task. In both of the        information. If low-level visual factors were responsible for
experiments, they found significant facilitation when the           their results, it should be possible to observe a different
prime and target words were congruent along the semantic            pattern simply by performing a similar task with different
dimension, but not when the words were congruent along              stimuli.
the affective dimension. Interestingly, the affective priming
emerged when they restricted the prime-target pairs to one                     Context-Dependent Processing
semantic category (e.g., animal). They concluded that when          What determines which kind of information gets activated
people are left with only one dimension for relating primes         first? We suggest that neither Affective Primacy nor
                                                                391

Cognitive Primacy holds at all times. Furthermore, the               To test this proposal, we had participants process the same
stimuli themselves should not fully determine the relative           stimuli in different contexts.
primacy with which affective and non-affective information              To create the different contexts, we used a "Task-Set
gets activated, nor should the judgments that people make            Inertia" paradigm (Allport & Wylie, 2000). In this
on the stimuli. Instead, the context in which processing             paradigm, there are target trials and filler trials. The target
occurs should be able to modulate the relative speed with            trials contain stimuli (e.g., words) with characteristics
which affective and non-affective information gets                   varying in two orthogonal dimensions (e.g., affective, non-
activated, even when the stimuli themselves and the                  affective). The filler trials contain a different kind of stimuli
judgments people make on them are held constant. This                (e.g., scenes) that vary along the same dimensions as the
claim is motivated by the Ad Hoc Cognition framework,                target stimuli (e.g., affective, non-affective). The idea is that
according to which the role that words, pictures, and other          what the participants do for the filler trials will persist and
cues play in activating neurocognitive representations is            facilitate or interfere with the execution of the response for
inseparable from the role played by the context in which             the target trials. In other words, the filler trials serve as a
they are experienced (Casasanto & Lupyan, 2011).                     context that orients the participants toward a specific
   Examination of the past studies supports our proposal that        dimension of the stimuli during the target trials.
the processing priority of affective and non-affective                  In Experiment 1, we tested whether a context-dependent
information should be determined by context. First, the              account holds in word meaning. We used affective
literature reviewed so far suggests that neither affective nor       (positive/negative) and non-affective (animal/human) words
non-affective information must always be activated first.            as the target trials, and affective (pleasant/unpleasant) and
Second, corroborative evidence from electrophysiological             non-affective (indoor/outdoor) scenes as the filler trials. We
data suggests that both affective and non-affective                  predicted a context-congruent facilitation for the target word
information can be processed at an early, overlapping time           trials.
window. Some studies showed that affective processing can               In Experiment 2, we tested the context-dependent
be early. For example, one study demonstrated that the               processing using pictures. We swapped the target and the
emotional content of the visual cues can facilitate the              filler trials in Experiment 1, so that the scenes became the
sensory encoding of these stimuli, as revealed by a P100             targets, and the words became the fillers. We also predicted
component starting at ~100 msec (e.g., Schupp, Junghöfer,            a context-congruent facilitation for the target scene trials.
Weike, & Hamm, 2003). Another study using word stimuli
showed that the emotional tone of words can be identified at                                 Experiment 1
~80-120 msec, and can lead to differential processing                Experiment 1 tested the context-dependence of affective and
(Scott, O’Donnella, Leutholda, & Sereno, 2009). Other                non-affective information cued by words (targets), in the
studies showed that non-affective processing too can be              context of visual scenes (distractors). We predicted a
early. One study showed that rapid semantic analysis of              context-congruity effect: the relative speed with which
visual scenes can occur in less than 120 msec (Kirchner &            affective and non-affective information could be activated in
Thorpe, 2006). In terms of word processing, it has been              response to the target words should vary according to the
demonstrated that some lexical-semantic analysis can take            type of processing (affective or non-affective) participants
place at ~100 msec (Sereno, Brewer, & O'Donnell, 2003;               were required to perform on the distractor pictures.
Hauk, Davis, Ford, Pulvermüller, & Marslen-Wilson, 2006).
   In addition, affective priming literature indicates that such     Method
priming may be goal dependent. While many studies found
goal-independent affective evaluation (Bargh, Chaiken,               Participants Native Dutch-speaking undergraduates (N=27;
Raymond, & Hymes, 1996), one study found goal-                       mean age=22.6) at the Raboud University Nijmegen
dependent affective evaluation (Klauer & Musch, 2002).               participated in this experiment for payment. Of these
Klauer & Musch (2002) used prime-target pairs with words             participants, 13 were assigned to the affective context group
that can be categorized by an affective dimension and a non-         and 14 to the non-affective context group.
affective dimension. They had one group of participants do
an affective (positive/negative) task, and had another group         Materials and Design The stimuli consisted of 96 nouns,
do a non-affective task (e.g., upper-/lower- letter case, the        24 each of 4 types: positive-valence animals (e.g., konijntje
stimulus locations on the screen, color, etc.) They found            ‘bunny’, panda ‘panda’, etc.), negative-valence animals
priming effects only when the priming dimension was task-            (e.g., parasite, ‘parasite’, kakkerlak, ‘cockroach’, etc.),
relevant. Although the design of their study is not ideal due        positive-valence humans (e.g., prinses ‘princess’,
to a between-group comparison, these data are consistent             grootvader ‘grandfather’ etc.), and negative-valence humans
with a context-dependent processing account.                         (moordenaar ‘murderer’, pedofiel ‘pedophile’, etc.).
                                                                        A norming pretest was carried out to ensure the valence of
                                                                     the target words. 18 native Dutch speakers participated in
                    The Present Study                                the pretest for payment. Each participant was given 145
   The present paper aims at testing a context-dependent             nouns, one word at a time, and was to rate the valence of
account of affective and non-affective meaning processing.           each noun on a 9-point Self-Assessment Manikins scale
                                                                 392

(Lang, 1980), ranged from a smiling figure at the positive           Results and Discussion
end of the scale to a frowning one at the negative end. Based        Accuracy The accuracy was the number of correct
on the rating results, we chose 96 nouns that were clearly           responses divided by the overall number in the target trials.
valenced out of the original 145, for the purpose of                 3 participants were excluded due to their low accuracies
matching the clear-cut animal vs. human distinction. The             (<80%). 24 participants (Mean accuracy=89%, ±0.75%,
mean valence ratings were 6.78 (SD=0.59) for the positive            range 81-93%) were included in the following analysis.
nouns and 2.79 (SD=0.82) for the negative nouns. The                 Performance on the filler (scene) trials was not analyzed.
valence for the two types differed significantly, as
confirmed by a two-tailed t-test (t=27.29, p=.0001).2
   The 96 selected nouns were then divided into 2 blocks.
For each session, 12 of each of the 4 types of nouns were
randomly selected to be included in the first block, while the
remaining 12 of each type were presented in the second
block. The participants made affective judgments
(Positive/Negative) for one of these blocks, and non-
affective judgments (Animal/Human) for the other block.
The order of the blocks was counterbalanced between
participants.
   To create a biasing context, we adapted the Task-Set
Inertia paradigm. Randomly intermixed with the target word
judgments were an equal number of filler trials. The fillers
consisted of 96 photos of complex scenes, 24 each of 4
types: pleasant indoor, unpleasant indoor, pleasant outdoor,
unpleasant outdoor scenes. The valence of the pictures               Figure 1. Reaction times for the (word) targets when participants
(positive or negative) was rated by two independent coders.          made affective judgments (dark bars) and non-affective judgments
Inter-coder agreement was 100%. In the affective context             (light bars) in the affective context group (left bars) and the non-
group, the participants made affective judgments                     affective context group (right bars) in Experiment 1. The error bars
                                                                     indicate standard errors.
(pleasant/unpleasant) for all photos. In the non-affective
context group, the participants made non-affective
                                                                     Reaction Times Extreme reaction times (>5,000 msec)
(indoor/outdoor) judgments for all photos. Therefore, for
                                                                     were excluded (0.06% of the data). The averaged reaction
each participant, the biasing context was congruent with the
                                                                     times by item are summarized in Figure 1.
target judgments for one block and incongruent for the other
                                                                        To test the predicted effect of contextual modulation on
block.
                                                                     the reaction times, we carried out a linear mixed-effects
                                                                     regression model of context types (affective, non-affective)
Procedure
                                                                     x 2 judgment types (affective, non-affective). A significant
Participants sat in a comfortable chair about 90 cm from a
                                                                     interaction was found between the judgment type and the
monitor in a soundproof, dimly-lit experimental booth.
                                                                     context type [F(1,2069)=21.42, p=.0001]. Within the
Stimuli were presented on a computer monitor (resolution =
                                                                     affective context group (Figure 1, left bars), affective targets
1024 x 768 pixels). In a target (word) trial, the word was
                                                                     were judged faster than the non-affective targets
presented for 300 msec, followed by a dark screen until an
                                                                     [F(1,1059)=11.26, p=.001]. Within the non-affective context
(affective or non-affective) judgment was made. In a filler
                                                                     group (Figure 1, right bars), non-affective targets were
(scene) trial, the scene was presented for 500 msec, also
                                                                     judged faster than the affective targets [F(1,1039)=9.95,
followed by a dark screen until an (affective or non-
                                                                     p=.002]. Within the affective judgments (Figure 1, black
affective) judgment was made. Participants were instructed
                                                                     bars), the judgments were not significantly faster in the
to press the response keys (e.g., pleasant and unpleasant) as
                                                                     affective context than in the non-affective context
quickly and accurately as possible. The order of the key
                                                                     [F(1,24)=0.64, p=.43]. Within the non-affective judgments
assignments (left to right vs. right to left) was
                                                                     (Figure 1, grey bars), the judgments were not significantly
counterbalanced for both the affective and the non-affective
                                                                     faster in the non-affective context than in the affective
judgments across participants. Participants responded with
                                                                     context [F(1,24)=1.25, p=.27].
the index fingers of both hands. A brief practice was given
                                                                        As predicted, context mattered. When participants
at the beginning of the session, and a brief break was given
                                                                     attended to the affective dimension, their affective
between the two blocks during the session. Each session
                                                                     judgments about the word targets were facilitated. When
lasted approximately 15 minutes.
                                                                     participants were oriented toward the non-affective
                                                                     dimension, their non-affective judgments about the word
2
                                                                     targets were facilitated. The effect of context cannot be
  While the present design does not require the length, the log      attributed to superficial similarities between the responses
frequency, or the arousal of words in different categories to be
matched, we still matched these factors.
                                                                 393

during filler and target trials, since the effect was found       affective context than in the non-affective context
even when responses were dissimilar (e.g., indoor - human).       [F(1,24)=1.07, p=.31]. Within the non-affective judgments
                                                                  (Figure 2, grey bars), the judgments were significantly faster
                      Experiment 2                                in the non-affective context than in the affective context
Experiment 2 tested whether processing pictorial stimuli is       [F(1,24)=8.19, p=.009]. Therefore, the RT difference
also context-dependent, using a ‘mirror’ version of               between affective and non-affective target judgments varied
Experiment 1. The scenes were now used as target trials,          depending on the context.
and the words, filler trials. The context-dependent account
predicts an effect of congruity between the type of context
and the type of target judgments, regardless of the format of
the target stimuli (pictorial or verbal). Affective target
judgments should be faster in the context affective filler
judgments than in the context of non-affective filler
judgments, and vice versa for non-affective target
judgments.
Method
Participants 26 Native Dutch-speaking undergraduates
(mean age=21.4) at the Raboud University Nijmegen
participated payment. None of them previously took part in
Experiment 1. Among these participants, 13 were assigned
to the affective context group and 13 to the non-affective
context group.
                                                                  Figure 2. Reaction times for the (picture) targets when
Materials, Design, and Procedure The materials and the            participants made affective judgments (dark bars) and non-
procedure were the same as in Experiment 1. The design for        affective judgments (light bars) in the affective context
the words and scenes was reversed, so that the scenes             group (left bars) and the non-affective context group (right
became the targets (judgments manipulated within-subject)         bars) in Experiment 2. The error bars indicate standard
and the words became the context (judgments manipulated           errors.
between-subjects).
                                                                        To test whether the results of the two experiments
Results and Discussion                                            differed, we carried out a linear mixed effects regression of
Accuracy We excluded 2 participants due to low accuracy           2 experiments (word, picture) X 2 context types (affective,
(<80%) on the target (picture) trials. 24 participants (Mean      non-affective) X 2 judgment types (affective, non-affective).
accuracy=89%, ±0.67%, range 82-94%) were included in              There was no 3-way interaction [F(1,4155)=.15, p=.70],
the analysis. Performance on the filler (word) trials was not     suggesting no difference between when the target stimuli
analyzed.                                                         were words and when the target stimuli were pictures. Yet,
                                                                  the 2-way interactions observed in the previous analyses
Reaction Times Extreme reaction times (>5,000 msec)               still hold [F(1, 4156)=36.41, p=.0001].This means that there
were excluded (0.04% of the data). The averaged reaction          was little difference between the significant effects of
times by item are summarized in Figure 2. To test the             context types on judgment types between experiments.
predicted effect of contextual modulation on reaction times,
we carried out a linear mixed-effects regression model of 2
                                                                                     General Discussion
context types (affective, non-affective) X 2 judgment types       Changes in the context can determine the relative speed
(affective, non-affective). There was a significant               with which people make affective and non-affective
interaction between the judgment type and the context type        judgments on words and pictures. These findings challenge
[F(1,2086)=15.43, p=.0001], replicating Experiment 1.             both the Affective Primacy and the Cognitive Primacy
There was a main effect between the context types                 hypotheses. Our results support the Ad Hoc Cognition
[F(1,23)=4.30, p=0.05], and a main effect between the             framework, according to which words and pictures activate
judgment types [F(1,2089)=48.83, p=0.0001]. Within the            different neurocognitive representations every time they are
affective context group (Figure 2, left bars), affective          processed, the specifics of which are co-determined by the
judgments were made faster than the non-affective                 stimuli themselves and the contexts in which they occur
judgments [F(1,1062)= 51.26, p=.0001]. Within the non-            (Casasanto & Lupyan, 2011; see also Elman, 2004).
affective context group, affective targets were still judged         Although we obtained interactions of nearly identical
faster than the non-affective targets [F(1,1031)=5.85,            sizes for scenes and for words, which did not differ
p=.02]. Within the affective judgments (Figure 2, black           statistically across experiments 1 and 2, the details of the
bars), the judgments were not significantly faster in the         data were different descriptively. For the scene targets, the
                                                              394

affective judgments were made faster than the non-affective            Keller, F., Gunasekharan, S., Mayo, N., & Corley, M. (2009).
judgments, no matter what the context. On one possible                   Timing accuracy of Web experiments: A case study using the
explanation, the representations activated in response to                WebExp software package. Behavior Research Methods, 41(1),
scenes (in this case, detailed color photographs) may be                 1-12.
                                                                       Klauer, K. C., & Musch, J. (2003). Affective priming: Findings
more constrained by the stimuli themselves than is the case              and theories. In J. Musch & K. C. Klauer (Eds.), The
for words. Whereas words name generic types (e.g.,                       psychology of evaluation: Affective processes in cognition and
“puppy” can refer to any puppy) pictures depict a specific               emotion (pp. 7-50). Mahwah, NJ: Erlbaum.
instance of a type (e.g., a photo must be of a specific                Scott, G. G., O'Donnell, P. J., Leuthold, H., & Sereno, S. C.
puppy). Therefore, representations activated in response to              (2009). Early emotion word processing: Evidence from event-
photographs may be more constrained than representations                 related potentials. Biological Psychology, 80(1), 95-104.
activated in response to words (c.f., De Houwer & Hermans,             Storbeck, J., & Robinson, M. D. (2004). Preferences and
1994). Yet, importantly,              in both experiments,               inferences in encoding visual objects: A systematic comparison
representations varied as a function of cues-in-context,                 of semantic and affective priming. Personality and Social
                                                                         Psychology Bulletin, 30, 81-93.
belying any broad generalizations about the primacy of once
                                                                       Storbeck, J., Robinson, M. D., & McCourt, M. (2006). Semantic
kind of information (affective or non-affective) over the                processing precedes affect retrieval: The neurological case for
other.                                                                   cognitive primacy in visual processing. Review of General
                                                                         Psychology, 10, 41-55
                     Acknowledgments                                   Whalen PJ, Rauch SL, Etcoff NL, McInerney SC, Lee M, Jenike
We thank the research assistants in the Neurobiology of Language         MA. (1998). Masked presentations of emotional facial
Group at the Max Planck Institute of Psycholinguistics, Nijmegen.        expressions modulate amygdala activity without explicit
Research supported in part by a grant from the Junta de Andalucía        knowledge. Journal of Neuroscience, 1998; 18:411-418.
(P09-SEJ-4772) and a McDonnell Scholar Award to DC.                    Zajonc, R. (1980). Feeling and thinking: Preferences need no
                                                                         inferences. American Psychologist, 35, 151-175.
                         References                                    Zajonc, R. (2000). Feeling and thinking: Closing the debate over
Allport, A. & Wylie, G. (2000). ‘Task-switching’, stimulus-              the independence of affect. In J. P. Forgas (Ed.), Feeling and
  response bindings, and negative priming. In S. Monsell & J. S.         thinking: The role of affect in social cognition. Studies in
  Driver (Eds.), Control of cognitive processes: Attention and           emotion and social interaction (Vol. 2, pp. 31-58). New York:
  Performance XVIII. Cambridge: MIT press.                               Cambridge University Press.
Bargh, J. A., Chen, M., & Burrows, L. (1996). Automaticity of
  Social Behavior: Direct Effects of Trait Construct and
  Stereotype Activation on Action. Journal of Personality and
  Social Psychology, 71(2), 230-244.
Calvo, M. G., & Nummenmaa, L. (2007). Processing of unattended
  emotional visual scences. Journal of Experimental Psychology:
  General, 136, 347-369.
Casasanto, D. & Lupyan, G. (2011). Ad Hoc Cognition.
  Manuscript submitted for publication.
De Houwer, J., & Hermans, D. (1994). Differences in the affective
  processing of words and pictures. Cognition & Emotion, 8(1), 1-
  20.
Elman, J. L. (2004). An alternative view of the mental lexicon.
  Trends in Cognitive Sciences, 8(7), 301-306.
Fazio, R. H. (2001). On the automatic activation of associated
  evaluations: An overview. Cognition and Emotion, 15, 115-141.
Glaser, W., & Glaser, M. O. (1989). Context effects in Stroop-like
  word and picture processing. Journal of Experimental
  Psychology: General, 118(1), 13-42.
LeDoux, J. E. (1996). The emotional brain. New York, NY: Simon
  & Schuster.
Lang, P. J. (1980). Behavioral treatment and bio-behavioral
  assessment: computer applications. In J. B. Sidowski, J. H.
  Johnson, & T. A. Williams (Eds.), Technology in mental health
  care delivery systems (pp. 119-l37). Norwood, NJ: Ablex.
Lazarus, R. (1984). On the primacy of cognition. American
  Psychologist, 39, 124–129.
Murphy, S. T., & Zajonc, R. B. (1993). Affect, cognition, and
  awareness: affective priming with optimal and suboptimal
  stimulus exposures. Journal of Personality and Social
  Psychology, 64(5), 723-739.
Nummenmaa, L., Hyönä, J., & Calvo, M. G. (2010). Semantic
  Categorization Precedes Affective Evaluation of Visual Scenes.
  Journal of Experimental Psychology: General, 139(2), 222-246.
                                                                   395

