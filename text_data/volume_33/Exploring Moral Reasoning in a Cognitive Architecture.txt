UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Exploring Moral Reasoning in a Cognitive Architecture
Permalink
https://escholarship.org/uc/item/96r77534
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Iba, Wayne
Langley, Pat
Publication Date
2011-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                                     Exploring Moral Reasoning in
                                           a Cognitive Architecture
                             Wayne Iba                                              Pat Langley
                    Computer Science Department                 Institute for the Study of Learning and Expertise
                 Westmont College, 955 La Paz Road                  2164 Staunton Court, Palo Alto, CA 94306
                       Santa Barbara, CA 93108
                          Abstract                                                       Background
   Moral reasoning plays a significant but poorly under-          In this paper, we describe our attempt to model moral
   stood role in human action and interaction. Although
   studied by philosophers for millennia, considerable con-       cognition within an integrated cognitive architecture. As
   fusion surrounds the topic. Computational cognitive ar-        such, we draw upon work in three distinct disciplines –
   chitectures hold promise for shedding insight on how           philosophy, psychology and computer science – each of
   agents act and reason morally. We present a view of
   moral cognition and examine one implementation of that         which has its own body of literature. In this section we
   view in Icarus, a theory of the human cognitive archi-         point to a very small sample of work that has influenced
   tecture. This approach to moral behavior and reasoning         our thinking.
   leads us to suggest that morality is a special case of ev-
   eryday cognition. We discuss the implications of this             Although a distinction may be made between ethics
   view and outline our continuing research on these and          and morals, for our present purposes we will use the
   related questions.
                                                                  terms interchangeably. The point of an ethical theory
   Keywords: Machine ethics; Moral reasoning; Philoso-
   phy; Cognitive architectures.                                  is to provide guidelines for how to live “the good life”.
                                                                  As such, an ethical theory should identify the nature
                      Introduction                                of the good as well as provide a system for acting so
Moral reasoning has been a focus of study for millennia.          as to achieve the good. Here we are not advancing a
The human condition stems in large part from the col-             particular theory, but rather exploring how a specific
lective judgments and decisions that can be said to have          cognitive architecture could support moral reasoning of
moral valence. This suggests that it would be desir-              different types. However, it will help readers to have at
able to study this topic carefully. Nevertheless, our un-         least a basic familiarity of the main ethical theories for
derstanding of morally charged cognition is still incom-          discussions in later sections.
plete and uncertain. Since the introduction of comput-               The three dominant ethical theories and their primary
ers, many people have been fascinated with the prospect           initiators include the virtue ethics of Aristotle, deonto-
of writing programs that exhibit human intelligence. As           logical systems descending from Kant, and consequen-
with other aspects of intelligence, computational mod-            tialist theories following from Hume, Bentham, and Mill.
els can provide many insights into the nature of moral            In virtue ethics, one lives the good life by behaving in a
cognition.                                                        balanced manner, thereby exhibiting the virtues – nei-
   Although generally treated as a topic distinct from            ther too much nor too little of a given quality. Deon-
generic reasoning, we suggest here that moral cogni-              tological systems place value on fulfilling one’s duties or
tion is better viewed as a special case of practical cog-         obligations; commonly, this is viewed as following cer-
nition. Depending on the ethical approach one takes,              tain rules that prescribe how one ought to behave. Con-
moral dilemmas might be nothing other than the conse-             sequentialist theories assign different values to different
quence of bounded rationality. Perhaps our subjective             states and prescribe courses of action that result in states
experience when deliberating over a moral dilemma has             with the best values; utilitarianism is one particular form
more to do with an emotion than with the properties of            of consequentialism where actions are selected so as to
the problem that we are trying solve. These two factors           maximize the total good across the entire population.
– bounded rationality and emotional states – may be the              One approach to understanding moral reasoning is
actual source of moral dilemmas.                                  to observe and explain what people do when they are
   We start by distinguishing between three types of              faced with morally charged decisions (Baron & Ritov,
moral cognition: moral behavior, moral interpretation,            2009; Waldmann & Dieterich, 2007). In contrast to the
and moral decision making. Next we review Icarus, the             philosophical theories that prescriptively indicate what
cognitive architecture we have used to implement agents           “ought” to be done, this approach attempts to charac-
that exhibit forms of moral cognition. We discuss our             terize what actually takes place and why. Such studies
experiences with these agents and their broader implica-          provide hints and constraints on determining the nature
tions for accounts of this class of phenomena. In closing,        of moral decision making in humans (Spranca, Minsk, &
we suggest directions for future research that should fur-        Baron, 1991). For example, many of these studies sug-
ther clarify our understanding of moral cognition.                gest that people operate using a hybrid of deontic and
                                                              3381

consequentialist methods. The exact character of those          Moral interpretation
hybrids, in terms of both structure and process, continue
                                                                Although our concept of moral behavior need not in-
to be questions of interest without clear answers.
                                                                clude every conceivable action, the definition intention-
   Numerous AI researchers have considered the problem
                                                                ally provides wide latitude in coverage. Building on this
of designing and implementing computational systems
                                                                notion, we introduce moral interpretation as a concep-
that embody ethical theories and perform their actions
                                                                tual classification, or judgment, over agent behaviors
according to an ethical theory. A body of work in ma-
                                                                (McNaughton, 1988). Such a classification requires a
chine ethics has grown around this problem (M. Ander-
                                                                cognitive capacity to recognize and distinguish moral be-
son & Anderson, 2007; Moor, 2005; Powers, 2005; Grau,
                                                                havior from behavior that is amoral, and in addition the
2005). Much of the interest has centered on how compu-
                                                                ability to distinguish positive moral behavior from that
tational systems may be equipped to act ethically; the
                                                                which is negative. The behavior being observed and clas-
approaches that have been suggested naturally span the
                                                                sified may be produced another agent or it may be gen-
range of ethical theories. However, some have explored
                                                                erated by the observer itself.
how the process of implementing computational mod-
                                                                   Having effectively defined moral behavior as those ac-
els of ethical reasoning sheds light on theories of ethics
                                                                tions over which some agent can apply moral interpre-
in general (Guarini, 2005; Dehghani, Tomai, Forbus, &
                                                                tation, we should clarify the distinction between them.
Klenk, 2008; McLaren, 2005), which is our present con-
                                                                First, moral behavior applies to an observable action
cern. But unlike previous efforts, which have added new
                                                                whereas moral interpretation applies to the cognitive
mechanisms to account for moral reasoning, our work
                                                                process that makes sense of the observed action. Typ-
suggests that moral cognition is rather a variation of
                                                                ically, we think of the observable action as happening
everyday cognition. In the remainder of the paper, we
                                                                in the physical environment and the cognitive process as
attempt to explain this conclusion.
                                                                happening in the mental states and their transitions; but
        Categories of Moral Cognition                           technically the cognitive processes could themselves be
                                                                observed and would therefore be subject to moral inter-
We adopt three categories of cognition related to moral-
                                                                pretation. Although a special case could exist in which
ity. These provide a framework for thinking about com-
                                                                the observed mental process is the very one making the
putational models of morality in our ongoing and future
                                                                interpretation, in general the distinction is between two
work. These three categories may be thought of as layers,
                                                                quite different activities. Second, this distinction be-
where each provides prerequisite capabilities for subse-
                                                                tween moral interpretation and moral behavior lets us
quent types of cognition. We will refer to these categories
                                                                decompose the problem of designing moral agents into
as moral behavior, recognition, and decision making. Our
                                                                the problem of generating skills or behaviors that have
framework bears similarities to distinctions that have
                                                                moral associations and the problem of providing cogni-
been made elsewhere (McNaughton, 1988; Moor, 2005;
                                                                tive resources to appropriately interpret such behaviors.
Guarini, 2005).
                                                                Furthermore, it underlines the conceptual component of
Moral behavior                                                  morality apart from the behavioral component.
We start by defining moral behavior to be actions taken
                                                                Moral decision making
by an agent that may be evaluated by an observer as
having moral value (positive or negative). That is, the         Once we have an agent that can recognize and categorize
action may be viewed as conforming (or not) to certain          the behaviors exhibited by agents, we have the possibil-
moral standards. This observer-based approach obvi-             ity of making choices through moral decision making.
ates the inference of motives or even cognitive states in       In this context, agents use their moral awareness during
the actor. Likewise, it potentially encompasses a broad         problem solving to formulate or choose intentions that
range of behaviors as having moral values. As such, the         reflect their own held moral values or behavioral norms.
category serves more as a foundation or starting point          This moral reasoning would look different from agent
than as a selective and insightful distinction.                 to agent depending on the moral theories under which
   However, we stress that the category does include the        they are operating. For example, a deontological agent
universe of behaviors that we would want to consider            would prefer certain skills and actions while ruling out
when studying moral acts. Our observer can be either            others; this framework provides search pruning at the ac-
another agent in the environment in question or a privi-        tion level. Alternatively, a consequentialist agent would
leged observer with a god’s eye view. Furthermore, this         adopt particular intentions based on an evaluation of
definition excludes those behaviors that we would not           the outcomes; instead of directly pruning the operators
want to consider in this context. By definition, if no ob-      in the search space, this approach provides an evalua-
server deems a particular behavior to have moral value          tion function over outcomes that guides the selection of
then we do not want to consider it in this category, al-        a course of action. Thus, multiple ethical theories are
though in principle any behavior can have moral valence.        captured within our definition of moral reasoning.
                                                            3382

   As a consequence of this broad approach to moral cog-            like Prolog, the architecture infers a belief that instan-
nition, we are led to consider the possibility that moral           tiates a rule’s head whenever the body matches the cur-
reasoning is merely a special case of everyday reason-              rent situation. However, inference in Icarus operates in
ing. We explore this question in greater depth below,               a bottom-up manner that is driven by perceptions rather
and simply note here the outlines of this thinking. The             than by top-down queries.
mechanics of reasoning or problem solving as we think                  The architecture’s processes for skill execution, which
of them are unaffected by and completely unrelated to               build on the results of conceptual inference, let it carry
an agent’s moral values or restrictions on actions. In              out complex activities in the environment. Skill memory
other words, the reasoning process conducted by an                  consists of a set of skills, each with a head that speci-
agent would be identical whether it is reasoning about              fies the skill name and arguments, along with a body
recharging its energy source or about helping or harm-              that states conditions for application, a set of ordered
ing another agent. However, this equivalence of process             subskills, and a set of expected effects. Nonprimitive
cuts in both directions; we can also conclude from this             skills refer to other skills, again placing a hierarchical
that reasoning about how to obtain an energy recharge               structure on memory. Unlike inference, the execution
is actually a moral problem.                                        process operates in a top-down manner, attempting to
   Before closing our introduction of these three cate-             find paths through the skill hierarchy that let the agent
gories of moral cognition, we note that our definitions             make progress toward completing its current task.
primarily refer to actions – performing them, interpret-               Skill execution supports routine activities, but it can-
ing them, and planning them. We can relax this ref-                 not handle unfamiliar situations. For this purpose,
erence so as to apply our definitions to states as well.            Icarus includes a problem-solving mechanism that op-
That is, we might think of moral behavior as being in a             erates over both the skill and conceptual memories. This
state that may be viewed by an observer as having moral             involves using a variant of means-ends analysis that iden-
value. Likewise, moral interpretation can refer to the              tifies differences between the agent’s current beliefs and
conceptual capacity to recognize such states and moral              its desired goals, retrieves skill instances that would
reasoning may involve evaluating states rather than ac-             achieve one or more of the unsatisfied goals, and se-
tions with respect to moral values.1 This broader sense             lects one from this set. If the skill instance is applicable,
of these categories lets us explore moral issues in the             then Icarus executes it in the environment, generates
context of Icarus (Langley & Choi, 2006; Stracuzzi, Li,             a revised set of beliefs, and continues problem solving
Cleveland, & Langley, 2009), an architectural theory of             if necessary. If the skill’s conditions are not satisfied,
cognitive structures and processes to which we now turn.            the architecture generates a subproblem to achieve these
                                                                    conditions and calls the problem solver recursively. If the
              An Overview of Icarus
                                                                    system cannot retrieve any relevant skills, it chains off a
We have explored moral cognition in the context of                  conceptual clause instead. Successful solution of a sub-
Icarus, a unified theory of the human cognitive archi-              problem leads to continuation on the original task, with
tecture (Newell, 1990) that imposes constraints on mem-             Icarus backtracking when one of its selections does not
ory, performance processes, and learning mechanisms.                bear fruit.2
Within these constraints, the framework lets one design                In addition to offering a computational theory of cog-
and implement intelligent agents that accomplish a va-              nition, Icarus provides a programming language for de-
riety of tasks within many different domains. In these              veloping intelligent agents. Unlike other architectures,
respects, Icarus is similar to other cognitive architec-            it requires that such agents operate in an external envi-
tures such as Soar (Laird, Rosenbloom, & Newell, 1986)              ronment, typically simulated, that ground its concepts
and ACT-R (Anderson, 1993).                                         in observable percepts and that ground its skills in ex-
   Among a number of distinctions from these earlier ar-            ecutable actions. Icarus developers have constructed
chitectures, Icarus posits separate long-term memories              agents for a variety of such environments, including tra-
for storing concepts and skills. Conceptual inference is            ditional cognitive tasks like multi-column subtraction
the primary means by which Icarus agents make sense                 and the Tower of Hanoi to more complex environments
of the world. Conceptual memory comprises a set of                  that we will discuss shortly. In the next section, we
rules, each of which specifies a head and a body, the lat-          report our experiences with Icarus in a number of envi-
ter containing a set of percepts, a set of conceptual rela-         ronments that provide opportunities for moral cognition,
tions, and a set of Boolean tests. Nonprimitive concepts            along with their implications for this important aspect
may refer to other concepts in their bodies, imposing a             of mental processing.
hierarchical organization on memory. As in languages
   1                                                                    2
     The distinction between event and state is less clear than           The architecture also includes a module for learning new
it may seem; for example, qualitative reasoning about phys-         skills from successful problem solving, but it is not relevant
ical systems may involve thinking about extended periods of         to the current discussion. Langley and Choi (2006) provide
time as single states.                                              more details about Icarus’ representations and mechanisms.
                                                                3383

           Moral Cognition in Icarus                            that this traditional distinction becomes less clear when
                                                                one embeds it in a cognitive architecture that offers a
Our first foray into moral cognition involved Twig
                                                                variety of representations and mechanisms.
(Horswill, 2008, 2009), a physical simulator that sup-
ports a variety of object types, including humanoid                The task of moral decision making, in which the agent
agents that carry out low-level reactive behaviors like         must choose between two or more courses of action, in-
approaching a tree or picking up a nearby doll. We de-          troduces additional complications. Within Icarus, this
veloped a number of Twig scenarios, one in which some           situation arises most naturally in the context of prob-
people were surrounded by multiple dolls while others           lem solving, when the architecture must select among
had none. We created Icarus concepts recognizing rich           different skill instances that would achieve unsatisfied
and poor people and associated skills for redistributing        goals. At first glance, this appears to embody a con-
the wealth. As expected, this ‘Robin Hood’ agent re-            sequentialist view, but earlier versions of Icarus made
peatedly approached a wealthy person, carried one of            such choices randomly, and the current implementation
his dolls to a less fortunate person, and left it there.        bases them on how many goals a skill achieves and how
  Clearly, the Icarus agent in this scenario carries out        many of its conditions match. Thus, the problem solver
moral behavior, at least from some viewpoints, but its          takes consequences into account in generating candidate
activities are entirely routine and rule governed. The          actions, but not in selecting among them. Danielescu
system executes hierarchical skills in a conditional man-       et al. (2010) explain how this can lead to undesirable
ner to carry out complex activities, but the agent does         situations in a simulated driving environment.
not think about their outcome, making it an example                One reasonable response involves associating numeric
of deontic processing. However, we can also run the             values with conceptual predicates, including the goals
architecture in a different mode, where we provide the          and beliefs they support, as done in recent variants on
agent with one or more problems to be solved. In this           the basic Icarus architecture (Choi, 2011; Asgharbeygi,
case, the problem to be resolved is that no person should       Stracuzzi, & Langley, 2006). Taking these numeric anno-
have fewer than one doll when others have two or more.          tations into account when selecting skills during problem
In this setting, the Icarus problem solver detects the          solving would seem closer to a consequentialist treatment
unsatisfied goals, retrieves high-level skills that would       of moral decision making. However, Choi and Ohls-
achieve them, executes a subset of them in turn. This           son (2010) have explored another way to guide choice
variant comes closer to the consequentialist view, al-          in Icarus using constraints, which specify conceptual
though the details of skill execution remain rule guided.       relations that should (or should not) hold under cer-
Thus, Icarus supports a hybrid account of moral be-             tain conditions. They have extended the architecture
havior that incorporates ideas from both frameworks.            to carry out limited lookahead to determine whether a
  Now let us consider moral interpretation, that is, rec-       course of action would violate any constraints and, if
ognizing whether another agent’s behavior satisfies or          so, to avoid it. This variation has a decidedly deontic
violates one’s moral tenets. We have not tested Icarus          character, yet one can also imagine a modulation on this
for this ability directly, but elsewhere we have reported       idea that places numeric weights on constraints and uses
an extension to the architecture that lets it recognize in-     them to guide decisions. This hybrid approach would,
stances of complex temporal concepts (Stracuzzi et al.,         again, incorporate aspects of both moral frameworks.
2009). More specifically, we introduced mechanisms for             Our discussion so far has dealt entirely with moral
recording episodic traces of when beliefs become true           cognition that is tied to domain predicates that denote
and false, along with processes for matching temporal           spatial relations to objects and specific physical activi-
concepts against these traces. We demonstrated their            ties. However, some moral tenets revolve around more
use in recognizing instances of plays in simulated foot-        generic relationships. Examples include the golden rule
ball, a domain in which behavior is highly rule governed.       and Kant’s categorical imperative not to use other hu-
Although this work focused on the representation and in-        mans as means to ends. These appear to require more
terpretation of legal plays, we could have used the same        abstract relationships that avoid reference to domain-
means to recognize football behavior that was illegal.          specific predicates, and Icarus lacks both the ability to
  We can adapt this approach, in a fairly direct manner,        encode them or the mechanisms to operate over them.
to support moral interpretation. Clearly, this scheme           One might argue that interpretation and decision mak-
would reflect a deontic view, since it relies centrally on      ing about such abstract morals depends on a form of
using rules to determine the moral valence of an observed       metacognition (Cox, 2005) that operates over traces of
behavior stream. However, in related work, we have also         the agent’s mental processes, rather than over descrip-
shown how one can adapt means-ends problem solving to           tions of domain events. Other kinds of higher-level moral
explain the reasons for such behavior by chaining back-         cognition, such as not misleading another intentionally
ward from known goals through the episodic trace, which         or not causing unnecessary disappointment, depend on
provides a consequentialist overlay. As before, we see          the ability to ascribe beliefs, goals, and expectations to
                                                            3384

other agents. This is another arena in which we must            cision making in Twig and other domains. Experience
extend Icarus before it can provide complete coverage           with these agents should shed additional light on the
of moral cognition.                                             hypothesis that moral cognition and everyday cognition
                                                                are, to all intents and purposes, equivalent. Neverthe-
                      Discussion                                less, this remains a hypothesis, and we will look for sce-
Experience with constructing Icarus agents in a num-            narios that raise genuine distinctions between the two
ber of simulated environments suggests that the archi-          modes of thought.
tecture can support routine moral behavior and at least            Although considerable work remains, our approach
limited forms of moral interpretation and decision mak-         has already produced some encouraging insights. We
ing, although it also revealed that the framework can-          identified three categories of moral cognition and found
not currently handle more abstract kinds of moral cogni-        that each of them is supported, to some extent, by the
tion. Whether other cognitive architectures like ACT-R          Icarus architecture, although we also identified aspects
and Soar have similar capabilities remains to be seen,          that it does not currently address. We also found that
but we suspect they have analogous strengths and weak-          one can construct Icarus agents that reflect a deontic
nesses. Our analysis also suggested that Icarus can             or consequentialist view, as well as hybrid models that
model important aspects of both deontic and consequen-          incorporate ideas from both frameworks. We hope that
tialist views of moral cognition, although it most natu-        future research will let us clarify and expand on these
rally embodies a hybrid approach that incorporates ideas        initial insights.
from both traditions.
   Our examples relied primarily on structures and pro-                           Acknowledgements
cesses that Icarus already supports for other purposes.         This material is based on research sponsored by ONR un-
This suggests that, overall, moral cognition requires lit-      der agreement N00014-10-1-0487. We thank Paul Bello
tle or no additional representations or mechanisms that         and Mark Nelson for discussions that improved the con-
do not already serve another architectural need. We             tent of the paper, and we thank the anonymous review-
noted the benefits of associating numeric values with           ers for their comments. The views and conclusions con-
conceptual predicates in accounting for the direction and       tained herein are the authors’ and should not be inter-
strength of moral responses, as well as uses of conditional     preted as representing the official policies or endorse-
constraints in judging the acceptability of environmental       ments of ONR or the U. S. Government, either expressed
states. But again, these have been introduced into ver-         or implied.
sions of Icarus for reasons unrelated to moral cognition.
   These observations are consistent with our initial                                 References
claim that, despite the special treatment it has received       Anderson, J. (1993). Rules of the mind. Hillsdale, NJ:
in the literature, moral cognition does not differ in sub-        Lawrence Erlbaum.
stantive ways from everyday cognition. Many will find           Anderson, M., & Anderson, S. L. (2007). Machine ethics:
this conclusion surprising, but we believe that it merits         Creating an ethical intelligent agent. AI Magazine,
further consideration. An alternative phrasing that may           28 (4), 15–26.
be even more controversial is that all reasoning is an in-      Asgharbeygi, N., Stracuzzi, D., & Langley, P. (2006).
stance of moral reasoning. We hope to explore this and            Relational temporal difference learning. In Proceedings
related issues in future research.                                of the Twenty-Third International Conference on Ma-
                                                                  chine Learning (pp. 49–56). Pittsburgh, PA: IMLS.
               Concluding Remarks                               Baron, J., & Ritov, I. (2009). Protected values and omis-
We plan to extend our models of moral cognition in sev-           sion bias as deontological judgments. In D. M. Bartels,
eral directions. We are developing an improved inference          C. W. Bauman, L. J. Skitka, & D. L. Medin (Eds.),
module that uses abductive reasoning to support plan              Moral judgment and decision making. San Diego, CA:
understanding from partial observations, which should             Academic Press.
improve Icarus’ ability to carry out moral interpreta-          Choi, D. (2011). Reactive goal management in a cog-
tion. We are also developing mechanisms that generate             nitive architecture. Cognitive Systems Research, 12 ,
new problems in appropriate environmental situations,             293–308.
that prioritize them dynamically, and that abandon in-          Choi, D., & Ohlsson, S. (2010). Learning from failures
tentions when circumstances change or when repeated               for cognitive flexibility. In Proceedings of the Thirty-
attempts have not succeeded. Most important, we plan              Second Annual Conference of the Cognitive Science
to incorporate both numeric annotations on conceptual             Society. Hillsdale, NJ: Lawrence Erlbaum Associates.
predicates and conditional constraints, both of which will      Cox, M. T. (2005). Metacognition in computation: A
be useful in evaluating states.                                   selected history. In Proceedings of the AAAI Spring
   We intend to use these extensions to construct new             Symposium on Metacognition in Computation (pp. 1–
Icarus agents that exhibit moral interpretation and de-           17). Stanford, CA: AAAI Press.
                                                            3385

Danielescu, A., Stracuzzi, D. J., Li, N., & Langley, P.        Langley, P., & Choi, D. (2006). Learning recursive con-
  (2010). Learning from errors by counterfactual reason-         trol programs for problem solving. Journal of Machine
  ing in a unified cognitive architecture. In Proceedings        Learning Research, 7 , 493–518.
  of the Thirty-Second Annual Conference of the Cogni-         McLaren, B. M. (2005). Lessons in machine ethics from
  tive Science Society. Hillsdale, NJ: Lawrence Erlbaum          the perspective of two computational models of ethical
  Associates.                                                    reasoning. In Machine Ethics: Papers from the 2005
Dehghani, M., Tomai, E., Forbus, K., & Klenk, M.                 AAAI Fall Symposium. Menlo Park, CA: AAAI Press.
  (2008). An integrated reasoning approach to moral            McNaughton, D. (1988). Moral vision: An introduction
  decision-making. In Proceedings of the Twenty-Third            to ethics. Oxford, UK: Wiley-Blackwell.
  Conference on Artificial Intelligence. Menlo Park, CA:       Moor, J. H. (2005). The nature and importance of ma-
  AAAI Press.                                                    chine ethics. In Machine Ethics: Papers from the 2005
Grau, C. (2005). There is no “I” in “robot”: Robotic             AAAI Fall Symposium. Menlo Park, CA: AAAI Press.
  utilitarians and utilitarian robots. In Machine Ethics:      Newell, A. (1990). Unified theories of cognition. Cam-
  Papers from the 2005 AAAI Fall Symposium. Menlo                bridge, MA: Harvard University Press.
  Park, CA: AAAI Press.                                        Powers, T. M. (2005). Deontological machine ethics.
Guarini, M. (2005). Particularism and generalism: How            In Machine Ethics: Papers from the 2005 AAAI Fall
  AI can help us to better understand moral cognition.           Symposium. Menlo Park, CA: AAAI Press.
  In Machine Ethics: Papers from the 2005 AAAI Fall            Spranca, M., Minsk, E., & Baron, J. (1991). Omission
  Symposium. Menlo Park, CA: AAAI Press.                         and commission in judgment and choice. Journal of
Horswill, I. (2008). Lightweight procedural animation            Experimental Social Psychology, 27 , 76–105.
  with believable physical interactions. In Proceedings of     Stracuzzi, D. J., Li, N., Cleveland, G., & Langley, P.
  the Fourth Artificial Intelligence and Interactive Digi-       (2009). Representing and reasoning over time in a cog-
  tal Entertainment Conference. AAAI Press.                      nitive architecture. In Proceedings of the Thirty-First
Horswill, I. (2009). Very fast action selection for param-       Annual Conference of the Cognitive Science Society.
  eterized behaviors. In Proceedings of the Fifth Inter-         Hillsdale, NJ: Lawrence Erlbaum Associates.
  national Conference on Foundations of Digital Games.         Waldmann, M. R., & Dieterich, J. (2007). Throwing a
  Orlando, FL: ACM Press.                                        bomb on a person versus throwing a person on a bomb:
Laird, J. E., Rosenbloom, P. S., & Newell, A. (1986).            Intervention myopia in moral intuitions. Psychological
  Chunking in Soar: The anatomy of a general learning            Science, 18 (3), 247–253.
  mechanism. Machine Learning, 1 , 11–46.
                                                           3386

