UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Audience Design in the Generation of References to Famous People
Permalink
https://escholarship.org/uc/item/00n7c6mf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Kutlak, Roman
Van Deemter, Kees
Mellish, Chris
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

              Audience Design in the Generation of References to Famous People
                                                Roman Kutlak (r04rk9@abdn.ac.uk)
                                           Kees van Deemter (k.vdeemter@abdn.ac.uk)
                                                Chris Mellish (c.mellish@abdn.ac.uk)
                                                      Computing Science Department
                                                          University of Aberdeen
                                                           Aberdeen AB24 3UE
                                                                Scotland, UK
                              Abstract                                   computational research has focussed on small domains (typ-
                                                                         ically containing less than 10 objects) in situations that were
   This paper seeks to fill a gap in existing computational mod-
   els of the production of referring expressions, by addressing         simple enough that speakers and hearers could be guaranteed
   situations in which speakers have difficulty assessing what in-       to have the same information concerning the properties of the
   formation is available to their audience. The paper describes         objects in the domain. Mismatches in information are there-
   a two-part experiment where speakers were given the name of
   a famous person and had to create a description that would            fore seldom addressed in GRE. This has arguably limited the
   enable a hearer to identify the person, and hearers used the          interest and usefulness of these algorithms, because reference
   created descriptions to guess the name of the described per-          in daily life tends to be very different, involving large do-
   son. The experiment compares how confident hearers are that
   they have identified the referent and how well speakers can es-       mains, about which different people have different informa-
   timate this confidence. The results of the experiment suggest         tion. A notable exception to this tradition is the work of Sid-
   that speakers do not overestimate hearers’ confidence as the          dharthan & Copestake (2004) whose algorithm was designed
   psycholinguistic literature had led us to expect.
                                                                         to work in open domains.
   Keywords: Audience Design; Mutual Knowledge; Reference;
   Definite Descriptions; GRE
                                                                            The aim of the present study was to investigate reference in
                          Introduction                                   a situation where mismatches of information between speak-
Reference production has been investigated in two differ-                ers and hearers are normal and natural. Instead of focussing
ent research traditions: the psycholinguistic tradition and the          on small artificial situations (as is common in both above-
computational-linguistics tradition.                                     mentioned research traditions), we focussed on large domains
   Existing psycholinguistic research on reference has often             that are not directly observed, but remembered. More specif-
focussed on mismatches of information between speakers and               ically, we chose to focus on situations where speakers had
hearers. Researchers in this tradition have asked, for ex-               to describe famous people to hearers whom they did not per-
ample, how well speakers and hearers are able to take such               sonally know. A similar domain has been used by Nenkova,
mismatches into account when they produce or interpret re-               Siddharthan & McKeown (2005) to infer the cognitive sta-
ferring expressions (Horton & Keysar, 1996; Keysar, Barr,                tus of a referent. Since these famous people are not directly
Balin, & Brauner, 2000; Lane, Groisman, & Ferreira, 2006).               observed during the experiment, their properties can only be
They have typically done this by putting speakers and hearers            remembered from past experience, and this introduces differ-
in small and cleverly constructed artificial situations, where           ences of information between speakers or hearers. We wanted
there are things that speakers can observe, but hearers cannot           to know how referential behaviour is affected by these differ-
(or the other way round). The artificiality of these situations          ences.
has caused some researchers to question the validity of this
research (Brown-Schmidt, 2009; Brennan & Hanna, 2009).                      The results of our experiment will inform algorithms that
Nonetheless, the results are extremely interesting and have              are able to describe people in a way that is likely to benefit
led to an ongoing debate about the extent to which speak-                hearers. (See our section on Algorithm Implications) Algo-
ers “design” their utterances to maximise utility for their au-          rithms of this kind can help readers to digest the news, for
dience (Krauss & Fussell, 1991; Fussell & Krauss, 1992;                  example: the hearer clicks on a proper name (e.g., “Julian
Hanna, Tanenhaus, & Trueswell, 2003). The expression audi-               Assange”), whereupon the system responds with a descrip-
ence design (also, perspective taking) is associated with this           tion (e.g., “The founder of Wikileaks”, or “A former journal-
issue.                                                                   ist currently awaiting trial on charges of sexual misconduct”).
   Existing computational research on the generation of re-              This should help the hearer to know who the proper name
ferring expressions (GRE) has thrived in recent years (Dale              refers to. The usefulness of such algorithms along with an
& Reiter, 1995; Nenkova, Siddharthan, & McKeown, 2005;                   example of such a system is also described in Radev & McK-
Horacek, 2006; Mitchell, van Deemter, & Reiter, 2010). This              eown (1998).
                                                                     712

                      Audience Design                                                     Experiment Design
 Grice’s maxim of quantity states that speakers should make           The experiment was conducted online. Participants were pre-
 their contribution as informative as is required but should          sented with a website that described the experiment setup and
 not include more information than is required. Several re-           the two available tasks. Although we did not anticipate an in-
 searchers have pointed out that this kind of contribution re-        fluence of one task on the other one, participants were asked
 quires the speaker to take the perspective of the hearer into        to avoid doing both tasks or indicate in the comments which
 account (Krauss & Fussell, 1991; Nickerson, 1999). As has            task they had done first. Only the data from the first task at-
 been noted, one of the requirements of taking other’s per-           tempted by a participant were then used in the analysis.
 spectives is to estimate other’s knowledge relevant to the con-         The first task was describing famous people and the second
 versation (Clark & Marshall, 1981; Krauss & Fussell, 1991;           task was guessing the name of a famous person given a de-
 Fussell & Krauss, 1992; Horton & Keysar, 1996).                      scription of such a person. In each of the tasks we collected
    Fussell & Krauss (1992) report experiments that focus on          the description or the guessed name and asked the participants
 referring expressions and audience design. In their first ex-        to rate to what extent they agree with 3 additional statements.
 periment, participants were presented with pictures of men           For each of the presented statements participants could select
 prominent in business, politics, or entertainment. The partic-       one of the following agreement options:
 ipants were asked to rate how identifiable the stimulus person
 was on a 7-point scale (from not identifiable to very identifi-      •  Strongly agree
 able) for themselves and for other students. The participants        •  Agree
 were also asked to provide the name of the stimulus person if        •  Neither agree nor disagree
 they knew it. The identifiability of stimuli was defined as the      •  Disagree
 likelihood of knowing the stimulus person’s name. The ex-
                                                                      •  Strongly disagree
 periment showed that the participants could judge reasonably
 well the knowledge of others. The data also showed a bias in            Each of the tasks allowed for any additional comments.
 the direction of the participants’ knowledge. In other words,        The website also provided an introduction that informed the
 when a participant knew the name of the target person, he or         participant about the nature of the tasks and what kind of de-
 she believed that a higher proportion of people than in reality      scriptions we were interested in. In particular, we required
 would know the name. Similarly, when the participant did             participants to provide a description of a famous person that
 not know the name of the target person, he or she believed           would enable “a general reader” to identify the person given
 that a smaller proportion of people would know the person’s          the description.
 name. A similar pattern emerged from another experiment,
 where participants were estimating the proportion of students        Describing
 knowing a name of an everyday object. “Even items that were
                                                                      Each participant (speaker) in the description task was pre-
 identified by 10% or less of the subjects were estimated by
                                                                      sented with the name of a famous person. The participant
 those who knew its name to be identifiable to 40-80% of the
                                                                      could skip the person if he or she was not comfortable with
 population” (Fussell & Krauss, 1992).
                                                                      creating a description for the particular person (e.g., did not
    Another line of research has shown that speakers tend to          know the person). When the participant decided to write a
 overestimate the effectiveness of their communication. For           description for the presented person, he or she also addressed
 example, Keysar & Henly (2002) presented speakers with               the following three statements:
 ambiguous sentences, explained the ambiguity to the speak-
 ers and asked them to read such sentences to hearers. The          Sa I think a general reader will know who I mean
 experimenters were hoping that the speakers would try to dis-
                                                                    Sb I know several people of that description
 ambiguate the sentence meaning using prosody whenever that
 was possible. The speaker was then asked to assess the hear-       Sc I am sure about the facts in my description
 ers understanding. Similarly, the hearer was asked to select
 which meaning he or she believed the speaker intended, and           Naming
 indicate his or her certainty on a 5-point scale (1 = very un-       Each participant (hearer) in the naming task was presented
 certain, 5 = very certain). The results showed that speakers         with a description of a famous person. The participant could
 overestimate their ability to disambiguate (i.e., their estimate     skip the description if he or she did not want to guess the
 of a hearer’s certainty was higher than the speaker’s actual         name of the person. When the participant decided to guess
 certainty). Both speakers’ overestimate of hearers’ knowl-           the name of the described person, he or she also addressed
 edge and speakers’ overestimate of their effectiveness moti-         the following three statements:
 vate our hypothesis:
                                                                    Ha I am sure I know who this description refers to
H1 Speakers are more confident that the hearers will identify       Hb I am sure the name I provided is correct
    the referent given their description than hearers.              Hc I am sure about the facts in the description
                                                                  713

   The reason for having two very similar questions, Ha and              the descriptions produced (after all, if a speaker includes an
Hb , was to address the tip-of-the-tongue experience (Brown,             incorrect fact but believes it to be correct, his or her confi-
1991) where a person can not recall a particular name or a               dence in such fact can still be high.). This expectation was
word despite knowing it. Hb was not used in the analysis and             borne out by our findings, as the following analysis shows:
is not further discussed in this paper.                                  Set A The median [quartiles] rating for speakers and hear-
                           Results                                       ers respectively are 5 [4, 5] and 4 [3, 5]. The ratings of cer-
                                                                         tainty about the facts are significantly higher for the speakers
The experiment produced two related datasets; one with de-               (Mann-Whitney U = 37353, n1 = 215, n2 = 261, p < 0.01
scriptions and one with names. Each dataset was cleaned by               one-tailed). The graph in figure 1 below shows the percent-
removing non-native participants and descriptions that were              ages of answers corresponding to individual confidence lev-
not seen by any hearer. Whenever participants performed                  els.
both tasks, only the data from the first task were used.
   From the 34 native speakers (21 females, 12 males and one             Set B The median [quartiles] rating for speakers and hear-
not stated) only 29 native speakers (17 females, 11 males and            ers respectively are 5 [4, 5] and 5 [4, 5]. The ratings of cer-
1 not stated) produced descriptions that were viewed by na-              tainty about the facts are significantly higher for the speakers
tive hearers (11 males, 7 females). The total number of de-              (Mann-Whitney U = 22495, n1 = 180, n2 = 214, p < 0.01
scriptions and corresponding name guesses were 215 and 261               one-tailed). The graph in figure 2 shows the percentages of
respectively. The speakers produced on average 7.4 (sd 5.3)              answers corresponding to individual confidence levels.
descriptions and the hearers named on average 14.5 (sd 10.7)
descriptions.                                                                                                        Facts Certainty
   One problem that emerged during the analysis was the
                                                                                                            80
treatment of descriptions that were viewed but the hearer did
not guess the name of the famous person. We could either                                                                                 Speaker
                                                                                                                                         Hearer
                                                                               Percentage of descriptions
discard the unsuccessful name guesses and the corresponding                                                 60
descriptions or treat the unsuccessful name guesses as valid
guesses with the lowest rating (i.e., rating 1, see below) for
each of the statements. Both of the approaches seemed valid                                                 40
so we analysed both sets.
   The set that included the answers where the participant did
not guess the name of the described person was labeled A.                                                   20
The set B contains only the answers where the hearer guessed
the name of the described person. The set A has 215 descrip-
                                                                                                            0
tions and 261 name guesses (hearers did not guess the name
of the described person in 47 cases) and set B has 180 descrip-                                                  5   4      3        2       1
tions and 214 names. The reduced number of descriptions in
                                                                                                                         Certainty
set B is the result of removing descriptions where the hearers
did not guess the name of the described person. The hearers
incorrectly identified the referent 56 times (21%) in the set            Figure 1: The figure shows the confidence in facts. The data
A (this includes the cases where the hearer viewed a descrip-            represents set A.
tion but did not guess the name of the described person) and
9 times (4%) in the set B.                                                  Having performed a number of sanity tests, we proceeded
   The agreement levels were converted into numerical values             to test our main hypothesis, H1.
to allow analysis. The levels strongly agree to strongly dis-
agree were assigned values 5 to 1 where 5 denoted strongly               H1 : Speakers are more confident that the hearers
agree and 1 denoted strongly disagree. All calculations were             will identify the referent given their description
performed using the R statistical package (R Development                 than hearers
Core Team, 2010). We have used the Mann-Whitney U test
                                                                         Set A The median [quartiles] rating for speakers and hear-
to accommodate for ordinal values and non-normal distribu-
                                                                         ers respectively are 4 [4, 5] and 5 [3, 5]. The confidence of
tions.
                                                                         correct identification of the referent estimated by the speak-
Pre-hypothesis Tests                                                     ers is not significantly bigger than the confidence of hearers
A number of pre-tests were performed to make sure that our               (Mann-Whitney U = 27426, n1 = 215, n2 = 261, p > 0.5
experiment was measuring what we intended it to measure.                 one-tailed). The graph in figure 3 shows the percentage of
Given the experimental setup, for example, one would expect              answers.
that a speaker is more confident about the truth of the facts in         Set B The median [quartiles] rating for speakers and hear-
the descriptions that he or she produces than hearers are about          ers respectively are 4 [4, 5] and 5 [5, 5]. The confidence of
                                                                   714

                                                Facts Certainty                                                                     Confidence
                                   80                                                                                  80
                                                                    Speaker                                                                           Speaker
                                                                    Hearer                                                                            Hearers
      Percentage of descriptions                                                          Percentage of descriptions
                                   60                                                                                  60
                                   40                                                                                  40
                                   20                                                                                  20
                                   0                                                                                   0
                                          5     4      3        2       1                                                   5   4        3        2       1
                                                    Certainty                                                                        Confidence
Figure 2: The figure shows the confidence in facts. The data                        Figure 3: The figure shows the confidence in the identifica-
represents set B.                                                                   tion of the referent as estimated by speakers and as given by
                                                                                    hearers. The data represents set A
correct identification of the referent estimated by the speak-
ers is not significantly bigger than the confidence of hearers                      ploy a mechanism that determines when to stop adding prop-
(Mann-Whitney U = 14748, n1 = 180, n2 = 214, p = 1 one-                             erties. This stop condition is usually triggered when only the
tailed). The graph in figure 4 shows the percentage of an-                          referent matches the description. Furthermore, many algo-
swers.                                                                              rithms assume that the knowledge base contains only infor-
   The result for set B is interesting and it suggests that the                     mation known to the hearer or that the algorithm can deter-
converse of the tested hypothesis might be true and that hear-                      mine whether hearer knows a particular fact and avoid the
ers are in fact more confident than speakers. One possible                          inclusion of facts that are not known to the hearer.
reason for this result is the difference between the actual hear-                       A good example of this standard approach to GRE is the
ers and the fictitious hearers assumed by the speakers. The                         Incremental Algorithm (IA) of Dale and Reiter (Dale & Re-
speakers were instructed to assess how confident they are that                      iter, 1995). Simplifying considerably, this algorithm operates
a general reader will identify the person whereas the partic-                       by addressing the various properties available to the generator
ipants for the experiment were recruited through the linguist                       one by one, always including the property in the description
list, an email list for academics, who are likely to be more                        if it is true of the target referent and false of at least one other
knowledgeable than a general reader.                                                object in the domain. The IA uses no backtracking and stops
   A second explanation for this seemingly contradictory re-                        once the target referent is the only domain object of which all
sult might be the difference in the task at hand and the                            the properties included in the description hold true (or if there
tasks used by other researchers. Participants in our experi-                        are no properties left, in which case no referring expression
ment were estimating hearers’ confidence in identifying the                         is generated). Additionally, the algorithm makes sure that the
famous person. Participants in, for example, Fussell &                              description contains a property expressible as a noun; if no
Krauss (1992) were estimating the percentage of population                          such property is included by the mechanism outlined above,
that would recognise a famous person upon seeing that person                        one is added at the end of the algorithm. Although the IA
regardless of the confidence with which such identification                         will often produce descriptions that are slightly longer than
occurs. It thus might be the case that speakers overestimate                        logically necessary (i.e., they are not the shortest identifying
in one direction (e.g., estimating the commonality of a par-                        descriptions possible), the descriptions generated are always
ticular knowledge) and underestimate in other direction (e.g.,                      very short. A good way to understand the IA is as a com-
confidence of identification).                                                      putationally tractable approximation of the idea of generating
                                                                                    the shortest identifying description possible (cf. the Gricean
                                        Algorithm Implications                      maxim of Brevity, (Grice, 1975)). Other algorithms, such as
Traditionally, GRE algorithms take as an input the referent                         the Greedy Algorithm (Dale, 1992), can be seen in the same
and a description of the domain. The algorithm then deter-                          light.
mines which properties are true of the referent and composes                            Given that our domain consisted of famous (i.e., widely
them into an expression that is true of the referent but not                        known) people, it might be thought that speakers and hearers
of any other object in the domain. The algorithms also em-                          would mostly agree on the facts in the domain, but the dif-
                                                                              715

                                                 Confidence                           Given that most contemporary GRE algorithms favour
                                                                                   short descriptions and avoid information unknown to the
                                    80
                                                                                   hearer, they are unable to produce the above mentioned suc-
                                                                   Speaker         cessful descriptions. Engelhardt, Bailey & Ferreira (2006)
                                                                   Hearers
       Percentage of descriptions
                                    60
                                                                                   showed that hearers do not judge over-specified expressions
                                                                                   worse than concise ones and our hearers’ comments suggest
                                                                                   that such expressions can be beneficial. We propose that algo-
                                    40                                             rithms that generate referring expressions where the knowl-
                                                                                   edge can not be assumed to be shared by the speaker and the
                                                                                   hearer should include additional information to allow hearers
                                    20                                             to correctly identify the referent even if they differ over some
                                                                                   of the facts. If an incremental approach to GRE is chosen
                                                                                   (as in the IA of Dale and Reiter) It would also make sense
                                    0
                                                                                   to let the algorithm inspect properties in order of their famil-
                                         5   4        3        2       1           iarity, instead of their discriminatory value (as in the Greedy
                                                                                   Algorithm). One computationally feasible way in which the
                                                  Confidence
                                                                                   familiarity of a property might be assessed might be to link
                                                                                   this to the frequency of the property in a large corpus of text
 Figure 4: The figure shows the confidence in the identifica-                      (Sluis, Gatt, & van Deemter, 2007).
 tion of the referent as estimated by speakers and as given by
                                                                                      Our results have implications for algorithm testing as well.
 hearers. The data represents set B
                                                                                   Normally, GRE algorithms are tested by comparing their out-
                                                                                   put to a corpus of human-produced descriptions (Passonneau,
 ference in certainty between speakers and hearers about the                       2006; Jordan & Walker, 2005; Belz & Gatt, 2007). Normally
 facts was statistically significant (statements Sc and Hc ). A                    such a corpus includes descriptions by all speakers, regard-
 GRE algorithm for this domain will thus have to be robust                         less of their confidence. In situations like the ones we studied,
 against differences in knowledge between speakers and hear-                       where human-generated descriptions are at risk of being mis-
 ers. What might seem to be an appropriate description for one                     interpreted, one possible approach is to compare the output of
 person might be unintelligible for another.                                       the algorithms to the descriptions produced by speakers with
    Closer examination of the comments offered by hearers                          high confidence only. It seems reasonable to expect that this
 showed that they are very tolerant of the information speakers                    will help hearers to identify the described referent, but this is
 provided. It seems that hearers can not only accept descrip-                      an assumption that would need to be tested.
 tions that contain additional information previously unknown
 to hearers but also correctly interpret facts on which the hear-                                          Conclusion
 ers do not agree with the speakers. The text below shows
 three examples where hearers were not certain about the facts                     This paper described a two-part experiment in which speakers
 in the description but managed to correctly identify the refer-                   described famous people, and hearers attempted to guess the
 ent. The lines S1, S2 and S3 show speaker produced descrip-                       name of the described persons from these descriptions. We
 tions and lines H1, H2 and H3 show comments left by hearers                       were interested in finding out how well speakers can judge
 who viewed the corresponding description.                                         the success of their own descriptions, and how confident hear-
                                                                                   ers are that they have identified the referent. We were also
S1 This person is/was the inventor of the telephone.                               interested in how confident speakers and hearers are about
H1 There is some dispute.                                                          the facts in the descriptions. The results did not confirm
S2 This person is/was the Cambridge Professor of Theoretical                       that speakers overestimate the confidence with which hear-
   physics with Lou Gehrig’s disease.                                              ers identify the referent (relevant statements Sa and Ha in the
H2 Didn’t know he had Lou Gehrig’s disease, just knew he had                       Experiment Design section). The results suggests that hearers
   some degenerative illness.                                                      are more confident about the correct identification of the ref-
                                                                                   erent than speakers estimate, but this would have to be tested
S3 This person was credited with the invention of the tele-
                                                                                   in a separate experiment. We also found that hearers are less
   phone. He was also interested in flight and assisting the
                                                                                   certain of the facts provided by the speakers (relevant state-
   deaf.
                                                                                   ments Sc and Hc in section Experiment Design). We inter-
H3 I’m just responding to the “telephone” prompt, basically. I                     preted this as a disagreement between speakers’ and the hear-
   have no idea about the other info.                                              ers’ knowledge and we suggest that GRE algorithms should
    There were 14 cases where the hearer disagreed or strongly                     take this disagreement into consideration.
 disagreed with the facts provided in the description (statement                      The comments provided by hearers strongly indicate that
 Hc ) but only in 3 out of 14 cases did hearers incorrectly iden-                  their identification can be successful even when hearers do
 tify the referent.                                                                not agree with all of the facts in a description. The hearers
                                                                             716

successfully identified the described person in 11 out of 14          the fourth international natural language generation con-
cases where they did not agree with the facts used in the de-         ference (pp. 47–54). Morristown, NJ, USA: Association
scription.                                                            for Computational Linguistics.
   The main implications for the design of computational            Horton, W. S., & Keysar, B. (1996). When do speakers take
models are the following. In domains where there is a possi-          into account common ground? Cognition, 59(1), 91 - 117.
bility of mismatch between the knowledge of a speaker and           Jordan, P. W., & Walker, M. A. (2005). Learning content se-
the knowledge of a hearer, the algorithms should generate de-         lection rules for generating object descriptions in dialogue.
scriptions that are robust enough to allow hearers to identify        J. Artif. Int. Res., 24(1), 157–194.
the referent even in cases where such mismatch occurs. In           Keysar, B., Barr, D. J., Balin, J. A., & Brauner, J. S.
particular, we suggest that the GRE algorithms should inten-          (2000). Taking perspective in conversation: The role of
tionally over-specify the referring expressions in cases where        mutual knowledge in comprehension. Psychological Sci-
there is a risk of disagreement between the speaker’s and the         ence, 11(1), 32-38.
hearer’s knowledge.                                                 Keysar, B., & Henly, A. S. (2002). Speakers’ overestimation
                                                                      of their effectiveness. Psychological Science, 13(3), 207-
                     Acknowledgments                                  212.
We would like to thank the reviewers and the University of          Krauss, R. M., & Fussell, S. R. (1991). Perspective-taking in
Aberdeen NLG group for their valuable comments. This re-              communication: Representations of others’ knowledge in
search is sponsored by SICSA.                                         reference. Social Cognition, 9(1), 2–24.
                                                                    Lane, L. W., Groisman, M., & Ferreira, V. S. (2006). Don’t
                          References                                  talk about pink elephants! Psychological Science, 17(4),
Belz, A., & Gatt, A. (2007). The attribute selection for gre          273-277.
   challenge: Overview and evaluation results. In Proc. 2nd         Mitchell, M., van Deemter, K., & Reiter, E. (2010). Natural
   ucnlg workshop: Language generation and machine trans-             reference to objects in a visual domain. In Proceedings of
   lation (ucnlg+mt) (p. 75-83). Citeseer.                            the 6th international natural language generation confer-
Brennan, S., & Hanna, J. (2009). Partner-specific adaptation          ence (pp. 95–104). Stroudsburg, PA, USA: Association for
   in dialog. Topics in Cognitive Science, 1(2), 274–291.             Computational Linguistics.
Brown, A. S. (1991). A review of the tip-of-the-tongue expe-        Nenkova, A., Siddharthan, A., & McKeown, K. (2005). Au-
   rience. Psychological Bulletin, 109(2), 204 - 223.                 tomatically learning cognitive status for multi-document
Brown-Schmidt, S. (2009). Partner-specific interpretation of          summarization of newswire. In Proceedings of the confer-
   maintained referential precedents during interactive dialog.       ence on human language technology and empirical meth-
   Journal of memory and language, 61(2), 171–190.                    ods in natural language processing (pp. 241–248). Mor-
Clark, H. H., & Marshall, C. (1981). Definite reference and           ristown, NJ, USA: Association for Computational Linguis-
   mutual knowledge. In A. K. Joshi, B. Webber, & I. Sag              tics.
   (Eds.), Elements of discourse understanding (pp. 10–63).         Nickerson, R. S. (1999). How we know—and sometimes
   Cambridge University Press.                                        misjudge—what others know: Imputing one’s own knowl-
Dale, R. (1992). Generating referring expressions: Building           edge to others. Psychological Bulletin, 125(6), 737 - 759.
   descriptions in a domain of objects and processes. MIT           Passonneau, R. (2006). Measuring agreement on set-valued
   Press.                                                             items (MASI) for semantic and pragmatic annotation. In
Dale, R., & Reiter, E. (1995). Computational interpretations          Proc. 5th international conference on language resources
   of the gricean maxims in the generation of referring expres-       and evaluation (lrec-06) (pp. 831–836).
   sions. In Cognitive science (Vol. 19, pp. 233–263).              R Development Core Team. (2010). R: A language and
Engelhardt, P. E., Bailey, K. G., & Ferreira, F. (2006). Do           environment for statistical computing [Computer software
   speakers and listeners observe the gricean maxim of quan-          manual]. Vienna, Austria. (ISBN 3-900051-07-0)
   tity? Journal of Memory and Language, 54(4), 554 - 573.          Radev, D. R., & McKeown, K. (1998). Generating natural
Fussell, S. R., & Krauss, R. M. (1992). Coordination                  language summaries from multiple on-line sources. Com-
   of knowledge in communication: Effects of speakers’ as-            putational Linguistics, 24(3), 469-500.
   sumptions about what others know. Journal of Personality         Siddharthan, A., & Copestake, A. (2004). Generating refer-
   and Social Psychology, 62(3), 378 - 391.                           ring expressions in open domains. In Acl ’04: Proceedings
Grice, P. (1975). Logic and conversation. Syntax and Seman-           of the 42nd annual meeting on association for computa-
   tics, 3, 43–58.                                                    tional linguistics (p. 407). Morristown, NJ, USA: Associa-
Hanna, J. E., Tanenhaus, M. K., & Trueswell, J. C. (2003).            tion for Computational Linguistics.
   The effects of common ground and perspective on domains          Sluis, I. van der, Gatt, A., & van Deemter, K. (2007). Evalu-
   of referential interpretation. Journal of Memory and Lan-          ating algorithms for the generation of referring expressions
   guage, 49(1), 43 - 61.                                             using a balanced corpus.
Horacek, H. (2006). Generating references to parts of re-
   cursively structured objects. In Inlg ’06: Proceedings of
                                                                717

