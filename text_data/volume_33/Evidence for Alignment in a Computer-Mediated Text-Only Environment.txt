UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Evidence for Alignment in a Computer-Mediated Text-Only Environment

Permalink
https://escholarship.org/uc/item/1354g2c4

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Riordan, Monica
Dale, Rick
Kreuz, Roger
et al.

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Evidence for Alignment in a Computer-Mediated Text-Only
Environment
Monica A. Riordan (mschpers@memphis.edu)
Rick Dale (radale@memphis.edu)
Roger J. Kreuz (rkreuz@memphis.edu)
Andrew Olney (aolney@memphis.edu)
Department of Psychology, 202 Psychology Building, University of Memphis, Memphis, TN 38152 USA
Abstract
During interaction, people coordinate in both verbal (e.g.,
syntactically and semantically) and nonverbal (e.g., gestural and
prosodic) ways. This alignment has been suggested to be a result of
grounding or priming. In both cases, visual cues assist
understanding. This study explores how widely and how much
participants align in a text-only environment. Forty-two
participants debated a topic via Instant Messenger with a
confederate. Using length analyses, LIWC, and LSA, results show
punctuation and semantic alignment above chance between
interlocutors, and an increase in this alignment over time.
Affective alignment and alignment in parts of speech are weak,
and the nature of the debate nor nonverbal cues affected alignment.
These results extend previous theories of verbal alignment to textonly environments in which interlocutors lack visual cues during
interaction and propose theoretical implications for alignment.
However, lack of nonverbal alignment departs from face-to-face
findings, and theoretical implications for such results are
suggested.
Keywords: alignment; coordination; synchronization;
priming; computer-mediated communication

Introduction
During interaction, people synchronize (Marsh, Richardson,
& Schmidt, 2009) or align (Pickering & Garrod, 2004) in a
variety of ways. When two people communicate, their levels
of linguistic representation align by co-activating similar
words, sentence structures, and so on. For example, in
classic work by Bock (1986), participants were induced to
use the same syntactic structure (among two available)
when they were primed by its previous use by a confederate
(e.g., active/passive sentences; see also Branigan, Pickering,
& Cleland, 2000 and Haywood et al., 2005). This alignment
occurs at many verbal levels, including the phonological and
syntactic (e.g, Cleland & Pickering, 2003; Giles, Coupland,
& Coupland, 1991). In addition to this verbal alignment,
several researchers have found nonverbal alignment,
including postural alignment (e.g., Shockley, Santana, &
Fowler, 2003), alignment in the pitch and rate of speech
(Giles, Coupland, & Coupland, 1991) and other bodily
movements (e.g., Chartrand & Bargh, 1999).
This evidence for alignment has been gleaned from faceto-face human interlocutors. However, the lack of feedback
present in text-based communication environments may
impact the level of alignment. Clark and Brennan (1990)

show that alignment is reached through grounding, or the
establishment of mutual knowledge and beliefs, in which
interlocutors provide evidence of their understanding (e.g.,
attentiveness, eye contact) and seek this type of evidence
from their conversation partner. The reduction of this
feedback in a text-only environment suggests that the
process of alignment may be affected. In consideration of
this possibility, Brennan (1991) conducted a study in which
humans interacted with a computer program and found
significant levels of linguistic alignment. Branigan and
Pearson (2006) also found syntactic and lexical alignment in
an interaction between a computer and a human. The
utterances produced by the computer shaped the humans'
subsequent utterances. However, it is possible that such
alignment could be explained by the expectations the person
had regarding the computer's capabilities; the human may
have sought alignment as an accommodation to the
computer interface in order to establish effective
communication. This same alignment may not occur in a
text-based environment if these constraints are not expected.
The alignment of humans with computers suggests that
visual feedback is not necessary for alignment. To account
for this finding, a recent prominent theory of alignment
proposes that priming is a central mechanism underlying
alignment (see Ferreira & Bock, 2006, and Pickering &
Garrod, 2004 for review and debate). When two people
communicate, their levels of linguistic representation align
by co-activating similar words, sentence structures, and so
on. In this manner, the lack of visual feedback in text-only
environments does not affect alignment.
In order to test the persistence of verbal alignment
between interlocutors, we designed a task in which two
people communicate via text-based Instant Messenger. Not
only does this allow us to test for verbal alignment in a textonly environment, but also to look at alignment independent
of established methods of feedback (e.g., eye contact,
gesture, facial expression). The lack of visual contact
between interlocutors in a text-based interaction forces
people to establish a way to negotiate understanding and
feedback during conversation, the process of grounding that
may be responsible for important aspects of alignment
(Clark & Brennan, 1990). This process of grounding may be
linguistic or nonlinguistic.
Several researchers have argued that text-only
environments are rich with nonverbal cues of their own.

2411

Social information processing theory (Walther, 1992)
suggests that cues available in face-to-face communication
channels have comparable expressions in text-only
environments. Indeed, Walther and D'Addario (2001) found
that 98% of their sample recognized :) as a symbol of
happiness and :( as a symbol of sadness (emoticons for
anger, disgust, and fear ranged from 85% to 88%
consensus).
Harris and Paradice (2007) argue that these nonverbal
cues in CMC are primarily paralinguistic. Carey (1980)
identified five categories of paralinguistic cues in CMC:
vocal spelling, lexical surrogates, spatial arrays,
manipulation of grammatical markers, and minus features.
Vocal spelling and lexical surrogates use nonstandard
spelling that imitate vocal intonation or tone. Spatial arrays
are generally sequences of keyboard characters that
represent nonverbal behaviors, such as emoticons.
Manipulating markers may indicate pauses (…), express
attitude (!!!), or signal tone of voice (SHOUT). Minus
features refer to an absence of certain language standards
that are present in normal writing.
In the current experiment, we examine how people
communicate and align both verbally and nonverbally in a
text-only environment.

Method
Participants
Forty-two participants (11 males; mean age = 22.5 years,
SD = 7.5) completed the 30-minute session.

Procedure
This study was a joint project with two other researchers to
study turn-taking, argumentation, and alignment. To create
the necessary conditions to study all three elements, three
variables (topic, agreement, and nonverbal cues) were
counterbalanced to create eight between-subjects conditions.
A confederate was used to ensure counterbalancing of
agreement and nonverbal cues. Upon arrival, naive
participants met the confederate and then were assigned to
adjoining rooms with computers. The participant completed
a short questionnaire gathering demographic information.
Then participants read a short article about a topic
(supporting making Gardasil either a mandatory or
voluntary vaccination), and answered two questions to
ensure they read and understood the article. Participants
were then given instructions on how to use the chat program
and screen-recording software was activated. All
instructions given to participants were also given to
confederates to ensure participants remained naive to the
confederate's role.
The confederate was trained to manipulate two of the
variables: agreement and nonverbal cues. Depending on the
condition, the confederate either disagreed with the
participant's arguments or was undecided/neutral. The

confederate also either used nonverbal cues (capitalized
words, emoticons, and repeating punctuation such as !!! and
???) or did not use any nonverbal cues during the chat.
Several practice debates were conducted to ensure proper
execution of these manipulations, and, once the confederate
and participant entered their assigned rooms, reminders for
the condition were placed prominently on the confederate's
computer. The confederate remained unaware of any
possible analyses to be conducted on the data; she was only
told that analyses were to be conducted on the use of
nonverbal cues and the impact agreement may have on the
use of these cues.
Participants were instructed to debate the article they were
given, and to try to persuade the confederate to the point of
view of the article. Each chat lasted approximately 27
minutes, with a 2-minute warning given before the debate
was to end. Upon finishing the debate, participants were
given a short questionnaire asking whether they agreed with
the point of view of the topic they were assigned and
whether they had pre-existing knowledge about the topic.

Analyses
A transcript was generated for each debate. This transcript
was split into two files: one with the confederate's text and
one with the participant's text. In this manner, analyses of
the text could be carried out to compare the confederate and
participant on a variety of dimensions, and test the impact of
agreement on alignment.
Several dimensions of alignment were examined.
Previous research has found several levels of alignment,
ranging from posture to pronunciation; however, the
theories of grounding and priming remain largely referential
to visual and linguistic phenomena, respectively. The
current analyses sought to examine both these areas of
alignment, assessing nonverbal, punctuation, semantic, and
affective alignment, as well as alignment in the use of parts
of speech, in a text-only environment. Two computational
analyses were performed to assess such alignment.
LIWC. First, we employed the Linguistic Inquiry and
Word Count program (LIWC; Pennebaker et al., 2007),
which is a text analysis program that categorizes words from
a text file based on an internal dictionary. LIWC then
returns a percentage that reflects the number of words in a
category divided by the total number of words in the text,
thereby calculating the degree to which different categories
of words are used in a given text. The program contains a
total of 80 categories into which words may fit. These
categories include descriptive dimensions (e.g., total number
of words in text, average number of words per sentence),
linguistic dimensions (e.g., percentage of words in text that
are pronouns or verbs), dimensions of psychological
constructs (e.g., affect words, cognition words), dimensions
of personal concerns (e.g., leisure, work), paralinguistic

2412

dimensions (e.g., fillers, assent), and punctuation. The
internal dictionary has over 4,500 words and word stems.
LIWC has been shown to have validity as a measure of
emotional expression appearing in text (Kahn, Tobin,
Massey, & Anderson, 2007) and as a measure of detecting
attentional focus, thinking style, emotionality, social
relationships, and individual differences (Tausczik &
Pennebaker, 2010). LIWC has been used extensively in
several disciplines to examine text in online formats (e.g.,
Dino, Reysen, & Branscombe, 2009; Gill, French, Gergle,
& Oberlander, 2008).
LSA. Latent Semantic Analysis (LSA) is a computational
analysis that allows comparisons of the semantic context of
texts on many dimensions. Using this method, words and
texts that share similar contexts have similar semantic
dimensions, and thus have a high semantic similarity. While
LSA can locate texts on innumerable dimensions, prior
research (Landauer & Dumais, 1997) has shown that more
than 300 dimensions does not alter a text's similarity scores.
The semantic space that makes up these dimensions in our
analysis consists of the TASA corpus of high school
textbooks as well as several Wikipedia Web pages that
allow us to include more topic-centric dimensions. To
identify these Wikipedia pages, Wikipedia Miner (Milne
and Witten, 2009) was used. The Wikipedia Miner "wikify"
program uses word frequency information combined with
information about word-related concepts to identify which
words within a text would be linked to Wikipedia pages. By
entering text from all transcripts, 80 topics were identified
by Wikipedia Miner as central to our topic: among these
were terms such as "sexually transmitted disease,"
"vaccination," "promiscuity," "birth control," and "clinical
trial." The text from the Wikipedia pages of these
Wikipedia-Miner-identified terms was added to the
semantic space that includes the TASA corpus.

Results
Manipulation Check
The confederate was responsible for manipulating two
variables: agreement and nonverbal cues. Each transcript
was checked to ensure the correct condition was carried out.
The confederate was always accurate as to the agreement
conditions. In the nonverbal cues conditions, the confederate
was accurate for 39 of the 42 conversations; In the three
remaining conversations, all of which were assigned to the
no cues condition, the confederate used no more than two
cues throughout the conversation.

Length Alignment
Each conversation consisted of, on average, 32 turns with 29
words per turn, for an average of 939 words per transcript
and approximately 0.85 turns per minute. A significant
correlation exists between the average number of words in a
participant's turn and the average number of words in a

confederate's turn (r = .48, p < .01). This result is
significant because the confederate was unaware that such
analyses would be conducted.
A significant correlation exists between the total number
of words written by the participant in a transcript and the
total number of words written by the confederate in a
transcript (r = .59, p < .01). This finding occurs at the turnby-turn level as well, such that the interlocutors tended to
write the same number of words in each turn they took (r =
.39, p < .001).
A significant correlation also exists between the number
of words in the participants' shortest turns and the number of
words in the confederates' shortest turn (r = .72, p < .01);
the same was true of their longest turns (r = .31, p < .05).

LIWC Analysis
Several categories were chosen from among those offered
by LIWC for the current analysis. First, to detect alignment
in parts of speech, categories for word types were chosen
(i.e., verbs, prepositions, articles, adverbs, auxiliary verbs,
conjunctions, pronouns). Second, to detect affective
alignment, affect word categories were chosen (i.e., negative
emotion words, anger words, anxiety words, sadness words,
positive emotion words). Third, to detect semantic
alignment, a category of words for sexual expression was
chosen due to the nature of the article being debated. Last,
punctuation alignment was measured with the categories of
question marks, exclamation points, periods, commas,
colons, semicolons, dashes, apostrophes, quotation marks,
parentheses, and overall punctuation.
Results show alignment in several categories. Significant
correlations between the confederates' turns and the
participants' turns were found in the categories of pronouns
(r = .57, p < .001) and conjunctions (r = .34, p < .05),
suggesting alignment in parts of speech. However, the lack
of alignment in any other word category suggests that
alignment in these two word types is an effect of the debatestyle conversation; for example, "but you," "and I."
A significant correlation was also found for negative
emotion words (r = .35, p < .05), suggesting a small but
significant alignment of affect. Semantic alignment was also
present for sexual expressions (r = .40, p < .01) and
punctuation alignment was found in overall punctuation (r =
.37, p < .01), though not in any particular form of
punctuation. This lack of alignment in any particular form
of punctuation suggests that the confederate's use of
punctuation as a nonverbal cue did not result in additional
punctuation use from the participant; however, overall
punctuation alignment still stands.

LSA Analysis
Transcripts for each participant's and partnered confederate's
text were entered into LSA to conduct four different
analyses: first, to determine the level of semantic alignment
between the two interlocutors within each turn (alignment

2413

Agreement
To determine if the debate style of the conversation was a
factor in the results, transcripts were coded for whether the
confederate disagreed with or was undecided/neutral
towards the participant's stance on the topic. This factor was
added to the linear mixed-effects model and results show an
additional .03 (16.7%) added to the semantic alignment
score for those who disagreed with each other than those
who were neutral, though this result proved nonsignificant.

20%	  
15%	  
10%	  
5%	  

-­‐15%	  

Non-­‐Adjacent	  C-­‐P	  

-­‐10%	  

Adjacent	  Second	  
Speaker	  

-­‐5%	  

Adjacent	  First	  
Speaker	  

0%	  
Adjacent	  C-­‐P	  

% Change

between each turn given by the confederate/participant and
each adjacent turn given by the participant/confederate);
second, to determine the level of alignment of the first
speaker with herself (alignment between each turn the first
speaker takes and each subsequent turn the first speaker
takes); third, to determine the level of alignment of the
second speaker with himself (alignment between each turn
the second speaker takes and each subsequent turn the
second speaker takes); and fourth, to determine the level of
alignment between the interlocutors with one's turn and the
other's nonadjacent future turn (alignment between each
turn the confederate/participant takes and each secondsubsequent turn the participant/confederate takes).
In order to compare these findings with a baseline for
alignment that might happen by chance, turns within each
transcript were randomly shuffled and analyzed in
comparison to the non-shuffled results above. A comparison
of the coefficients of a linear mixed-effects model
(participant = random, analysis type = fixed) shows a
significant decrease in alignment between the confederate
and the participant when turns are shuffled than when they
are not (.30 vs. .32; p < .01). This significant effect persists
for comparisons of the additional analyses (see Figure 1).
Though alignment of adjacent turns between the
confederate and the participant was significantly higher than
a baseline, the participant and the confederate tended to
align more with him/herself than with each other. The
second analysis (alignment of the first-speaker's adjacent
turns) yields a marginal increase over the first analysis
(partner alignment) in alignment score (.34 vs. .32; p < .06).
The third analysis shows a significant increase (.35 vs. .32;
p < .05) in alignment score compared to the first analysis
(partner alignment). The fourth analysis indicates nonadjacent turn alignment between the confederate and the
participant, and shows a significant decrease in alignment
(.27 vs. .32; p < .001); this result shows that alignment
between the participant's and the confederate's adjacent
turns is higher than alignment between the participant's and
the confederate's alignment on present and non-adjacent
future turns. As one interlocutor changes the topic, the other
follows. This flow also creates increasing alignment over
time as interlocutors continue communicating; a 1.3%
increase in semantic alignment occurs with each new turn
contributed to a chat (assessed by the addition of turn
number to the linear model; p < .001).

Figure 1: Percentage of alignment increase or decrease
compared to baseline scores using LSA.

Nonverbal Alignment
The confederate used nonverbal cues such as repeating
punctuation types, emoticons, and capitalized words when
interacting with half of the participants. On average, the
confederate used 14 cues (SD = 9) in each of these
conversations. However, whether or not the confederate
used nonverbal cues was not related to whether the
participant used nonverbal cues (t(40) = .27, p = .79). To
determine if the number of times the confederate used
nonverbal cues influenced the number of times the
participant used nonverbal cues in a conversation, a
correlation was carried out; results show a nonsignificant
relationship (r = .23, p = .15).

Discussion
The current study attempts to detect whether verbal and
nonverbal alignment between human interlocutors occurs in
a text-only environment. Analyses show that people align in
sentence punctuation and semantically at high levels, but
evidence for alignment at the affective level or in parts of
speech is weak. This alignment occurs more highly withinsubjects than between-subjects, and is subject to increases
over time spent communicating with the interlocutor. The
nature of agreement in the conversation does not appear to
factor into alignment. Further, the presence of nonverbal
cues by the confederate did not affect the level of alignment.
As reviewed in the introduction, previous research has
found alignment, synchrony, and entrainment between
interlocutors. Our goal was to look for diffuse alignment
ongoing during text-based interaction. We indeed found
considerable alignment, as predicted, but there were some
limitations. Nonverbal alignment did not occur, though we
anticipated that it might.
Two possible hypotheses may explain this disparity when
compared to the high rates of face-to-face nonverbal

2414

alignment found in research. First, the textual nonverbal
cues in the current study may be inadequate representations
of nonverbal cues present in face-to-face research. Indeed,
several researchers (e.g., Derks, Bos, & Grumbkow, 2008;
Thompson & Foulger, 1996; Walther & D'Addario, 2001)
suggest that cues such as those used in the current study are
more deliberate and planned than spontaneous nonverbal
cues in face-to-face conversation such as prosody and facial
expression, and as a result are less representative of a
present state of emotion than they are of the intention or
motivation of a writer. For example, an emoticon used after
a negative comment does not indicate one smiling while
saying something mean, but that the comment was not
intended in a malicious manner. In the same line, Kreuz
(1996) asserts that certain typographic devices, such as
capitalization, underlining, and bold face, play a role in
denoting irony in written communication, rather than in
contributing in a manner comparable to face-to-face
nonverbal cues.
Second, it is possible that nonverbal alignment is, in fact,
verbal in CMC. Several researchers (e.g., Tidwell &
Walther, 2002; Walther & Tidwell, 1995) suggest that
interlocutors in a text-only environment tend to ask more
questions and disclose more information when
communicating. The use of common terms and development
of shared shorthand may signal intimacy.
The high rate of alignment between interlocutors may
suggest that the confederate herself is aligning with the
participant rather than jointly aligning with each other,
much as was seen in the computer-human tasks reviewed in
the introduction. However, this is unlikely to be the case;
both the confederate and the participant aligned more with
their own text than they did with each other's text, and these
rates of self-alignment were comparable. Furthermore, the
confederate was unaware of plans to conduct analyses on
any variables other than nonverbal cues and agreement,
which were strictly controlled between conditions and thus
unavailable as methods for her to align with the participant.
As mentioned at the outset, researchers have identified
different processes that may underlie this alignment, such as
grounding and priming. The current results show
widespread alignment, but we cannot assess exactly whether
one or the other is responsible. Based on the current results,
however, we can guess how both processes might work in
these cases.
The process of grounding may, in text-based
communication, be verbal in nature. The establishment of
mutual knowledge and beliefs would require the explicit
encoding of familiarity or liking. This encoding, rather than
being visual as in face-to-face conversations (e.g., eye
contact, facial expression) may instead be verbal (e.g., "I
like that," or "Do you like this?"; as Tidwell & Walther,
2002, and Walther & Tidwell, 1995, found). Further
analyses on the amount of disclosure and questions that
elicit opinions and knowledge would be informative.
Second, the process of priming appears to be a valid

theory of alignment at both high and low levels–in the
current study, punctuation and semantic content. However,
there are limitations to priming. Interlocutors did not align
the low level of use of parts of speech or at the high level of
affect. Priming appears to be inadequate as a theory for
alignment.
While further research would be necessary to establish the
interplay of such factors, the suggestion that both grounding
and priming occur in tandem is a possible explanation for
our results. Priming is inadequate as an explanation because
of the necessity to form a common ground of beliefs and
knowledge, which is established primarily through question
asking and explicit statements of liking. This questionanswer format results in the use of different parts of speech
and words of affect, and thus alignment is not found in these
areas. However, alignment at the semantic level and in the
punctuation of sentences would be found as the process of
grounding is established. It may be the case that as people
communicate more over time, and grounding is further
established, priming plays a larger role.
Further studies should examine the role of questionasking and answering in the process of grounding as well as
the process of alignment over time between interlocutors in
text-based environments. The possible interplay of these
two processes may account for many findings of alignment
at several levels of analysis, including online social tags
(Fu, Kannampallil, Kang, & He, 2010), online video game
chat (e.g., Herring, Kutz, Paolillo, & Zelenkauskaite, 2009)
and online Twitter conversation (e.g., Honeycutt & Herring,
2009).

Acknowledgements
The research was supported by the National Science
Foundation through grant HSD-0826825 awarded to Rick
Dale.

References
Bock, J. K. (1986). Syntactic persistence in language
production. Cognitive Psychology, 18, 355-387.
Brennan, S. E. (1991). Conversation with and through
computers. User Modeling and User-Adopted
Interaction, 1, 67-86.
Branigan, H. P. & Pearson, J. (2006). Alignment in humancomputer interaction. In K. Fischer (Ed.), How people
talk to computers, robots, and other artificial
communication partners (pp. 140-156). Universitaet
Bremen / Universitaet Freiburg: Report Series of the
Transregional Collaborative Research Center SFB/TR 8
Spatial Cognition.
Branigan, H.P., Pickering, M.J., & Cleland, A.A. (2000).
Syntactic co-ordination in dialogue. Cognition, 75, B13B25.
Carey, J. (1980). Paralanguage in computer mediated
communication. In N. K. Sondheimer (Ed.), The 18th

2415

annual meeting of the Association for Computational
Linguistics and parasession on topics in interactive
discourse: Proceedings of the conference (pp. 67-69).
Philadelphia: University of Pennsylvania.
Chartrand, T. L., & Bargh, J. A. (1999). The chameleon
effect: The perception-behavior link and social
interaction. Journal of Personality and Social
Psychology, 76, 893-910.
Clark, H. H. (1996). Using language. Cambridge:
Cambridge University Press.
Clark, H. H., & Brennan, S. A. (1991). Grounding in
Communication. In L.B. Resnick, J.M. Levine, & S.D.
Teasley (Eds.). Perspectives on socially shared cognition.
Washington: APA Books, 127-149.
Cleland A.A., & Pickering, M.J. (2006). Do writing and
speaking employ the same syntactic representations?
Journal of Memory and Language, 54, 185-198.
Derks, D., Bos, A. E. R., & von Grumbkow, J. (2008).
Emoticons in computer-mediated communication: Social
motives and social context. CyberPsychology &
Behavior, 11, 99-101.
Dino, A., Reysen, S., & Branscombe, N. R. (2009). Online
interactions between group members differing in status.
Journal of Language and Social Psychology, 28, 85-93.
Ferriera, V. S., & Bock, K. (2006). The functions of
structural priming. Language and Cognitive Processes,
21, 1011-1029.
Fu, W., Kannampallil, T., Kang, R., & He, J. (2010).
Semantic imitation in social tagging. ACM Transactions
on Computer-Human Interaction, 17, article 12.
Giles, H., Coupland, N., & Coupland, J. (1991).
Accommodation theory: Communication, context, and
consequence. In: H. Giles, J. Coupland, & N. Coupland
(Eds.), Contexts of accommodation: Developments in
applied sociolinguistics. Cambridge University Press, 168.
Gill, A., Gergle, D., French, R.M., & Oberlander, J. (2008).
Emotion rating from short blog texts. Proceedings of CHI
2008. New York: ACM Press, 1121-1124.
Harris, R. B., & Paradice, D. (2007). An investigation of the
computer-mediated communication of emotion. Journal
of Applied Sciences Research, 3, 2081-2090.
Haywood, S., Pickering, M.J., & Branigan, H.P. (2005). Do
speakers avoid ambiguity in dialogue? Psychological
Science, 16, 362-366.
Herring, S. C., Kutz, D. O., Paolillo, J. C., &
Zelenkauskaite, A. (2009). Fast talking, fast shooting:
Text chat in an online first-person game. Proceedings of
the forty-second Hawai'i International Conference on
System Sciences. Los Alamitos, CA: IEEE Press.
Honeycutt, C., & Herring, S. C. (2009). Beyond
microblogging: Conversation and collaboration via
Twitter. Proceedings of the forty-second Hawai'i
International Conference on System Sciences. Los
Alamitos, CA: IEEE Press.

Kahn, J. H., Tobin, R. M., Massey, A. E., & Anderson, J. A.
(2007). Measuring emotional expression with the
Linguistic Inquiry and Word Count. American Journal of
Psychology, 120, 263-286.
Kreuz, R. J. (1996). The use of verbal irony: Cues and
constraints. In J. S. Mio & A. N. Katz (Eds.), Metaphor:
Implications and applications (pp. 23-38). Mahwah, NJ:
Lawrence Erlbaum Associates.
Landauer, T. K., & Dumais, S. T. (1997). A solution to
Plato's problem: The latent semantic analysis theory of
acquisition, induction, and representation of knowledge.
Psychological Review, 104, 211-240.
Marsh, K. L., Richardson, M. J., & Schmidt, R. C. (2009).
Social connection through joint action and interpersonal
coordination. Topics in Cognitive Science, 1, 320-339.
Milne, D. and Witten, I.H. (2008) Learning to link with
Wikipedia. In Proceedings of the ACM Conference on
Information and Knowledge Management (CIKM'2008),
Napa Valley, CA.
Pennebaker, J.W., Booth, R.J., & Francis, M.E. (2007).
Linguistic Inquiry and Word Count: LIWC 2007. Austin,
TX: LIWC (www.liwc.net).
Pickering, M. J., & Garrod, S. (2004). The interactivealignment model: Developments and refinements.
Behavioral and Brain Sciences, 27, 212-225.
Shockley, K., Santana, M., & Fowler, C.A. (2003). Mutual
interpersonal postural constraints are involved in
cooperative conversation. Journal of Experimental
Psychology: Human Perception and Performance, 29,
326-332.
Tausczik Y.R., & Pennebaker, J.W. (2010). The
psychological meaning of words: LIWC and
computerized text analysis methods. Journal of Language
and Social Psychology, 29, 24-54.
Thompson, P. A., & Foulger, D. A. (1996). Effects of
pictographs and quoting on flaming in electronic mail.
Computers in Human Behavior, 12, 225-243.
Tidwell, L. C., & Walther, J. B. (2002). Computer mediated
communication effects on disclosure, impressions, and
interpersonal evaluations: Getting to know one another a
bit at a time. Human Communication Research, 28, 317348.
Walther, J. B. (1992). Interpersonal effects in computermediated interaction: A relational perspective.
Communication Research, 19, 52-90.
Walther, J. B., & D'Addario, K. P. (2001). The impacts of
emoticons on message interpretation in computermediated communication. Social Science Computer
Review, 19, 324-347.
Walther, J. B., & Tidwell, L. C. (1995). Nonverbal cues in
computer-mediated communication, and the effects of
chronemics on relational communication. Journal of
Organizational Computing, 5, 355-378.

2416

