UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Gesturing by aphasic speakers, how does it compare?
Permalink
https://escholarship.org/uc/item/5hb0b2hc
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Mol, Lisette
Krahmer, Emiel
Van de Sandt-Koenderman, Mieke
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                           Gesturing by aphasic speakers, how does it compare?
                                                   Lisette Mol (l.mol@uvt.nl)1
                                            Emiel Krahmer (e.j.krahmer@uvt.nl) 1
                                Mieke van de Sandt-Koenderman (m.sandt@rijndam.nl)2
           1
             Tilburg Center for Cognition and Communication (TiCC), School of Humanities, Tilburg University
                                    P.O. Box 90135, NL-5000 LE Tilburg, The Netherlands
     2
       Rotterdam Neurorehabilitation Research (RoNeRes) Rijndam Rehabilitation Centre, and Erasmus MC, dept.
                 of Rehabilitation Medicine, P.O. Box 23181, NL-3001 KD, Rotterdam, The Netherlands
                             Abstract                                gesture and speech production are complementary and can
We compared gesturing by aphasic speakers to that of healthy         compensate one another, which also underlies the Tradeoff
controls, to see if gesture degrades with speech, or can be          Hypothesis. This hypothesis states that “when speaking gets
compensatory. We found that gestures by aphasics were less           harder, speakers will rely relatively more on gestures”, and
informative than those of controls, and that gestures by people      vice versa (De Ruiter, Bangerter, & Dings, in press). Yet De
with severe aphasia were less informative than those by people       Ruiter et al. found only little evidence that people gesture
with mild aphasia. We also found that aphasics tended to use
fewer representation techniques in gesture than healthy controls     more when speech is harder. Rather, they found that gesture
who were asked to use gesture instead of speech. These results       and speech tended to express similar types of information,
suggest that in aphasia, gesture tends to degrade with speech,       consistent with the idea that gesture and speech are two
rather than it being compensatory. This implies that the             sides of a coin.
processes underlying speech and gesture production may be
tightly linked or shared.
                                                                     Gesture Production and Aphasia
Keywords: Aphasia, Gesture.                                          In light of the question of whether gesture and speech
                                                                     compensate for one another, it is interesting to study what
                          Introduction                               happens to gesture when speech breaks down, such as in
                                                                     aphasia. Aphasia is an acquired language disorder caused by
Gesture and Speech Production
                                                                     brain damage. It not only affects verbal expression, but has
When speaking, people oftentimes produce hand gestures,              an impact on all language modalities. In our current study
which are closely linked to their speech temporally (Chui,           we focus on aphasic people who have severe to mild
2005), structurally (Kita & Özyürek, 2003), and                      problems expressing themselves verbally.
semantically (e.g. McNeill, 2005). For example, when                    Numerous studies have shown that aphasic people still
asking a sales clerk for a sweater, gestures may indicate that       gesture spontaneously and frequently (Rose, 2006). People
we prefer a V-neck, a large front pocket, or one just like the       with fluent aphasia may even gesture more informatively
one we are wearing. Both the production of speech and the            than non-aphasic speakers (Carlomagno, Pandolfi, Martini,
production of gestures seem to be part of a speaker’s                Di Iasi, & Cristilli, 2005). Case studies and clinical
communicative effort (Kendon, 2004). Although different              experience confirm that some aphasic speakers use gesture
functions of gesture have also been recognized, such as              effectively to communicate (e.g. Goodwin, 2002). This
facilitating speech production (Krauss, 1998) and supporting         suggests that they may be able to partly compensate for their
cognition (Melinger & Kita, 2007), much empirical                    speech impairment with gesture. Yet does this mean their
evidence has been gathered for the idea that gestures are            gesturing is unimpaired?
communicative and are intended as such (e.g. Alibali,                   Studies that looked at gesturing by people with aphasia
Heath, & Myers, 2001; Beattie & Shovelton, 1999).                    have mostly used the gesture coding scheme developed by
  McNeill (2005) argued that speech and gesture co-express           McNeill (2005). For example, Carlomagno et al. looked at
idea units, which develop themselves into utterances. That           the informativeness of iconic gestures, which are gestures
is, that they are two sides of the same coin. In support of this     that mostly depict entities or movements. Yet when
idea, So, Kita, and Goldin-Meadow (2009) found that if               producing an iconic gesture, there are still different ways in
information was lacking in speech, it tended to be missing in        which we can depict (Cienki & Müller, 2008). For example,
gesture as well. However, Melinger and Levelt (2004) found           if we want to depict a sweater, we can outline the shape of
that speakers sometimes divide the content of their message          it, or we can pretend to put it on. And if we are talking about
across gesture and speech. They found that if critical spatial       a car, we can move our hands as though steering it, or we
information was expressed in gesture, it was more likely to          can let our hand represent the car, depicting its path with our
be omitted in speech. This goes well with the idea that              hand movement. So there is more to say about a gesture’s
                                                                 1454

form than just that it is an iconic gesture. And being able to     speakers may prefer different techniques than non-aphasic
produce a meaningful iconic gesture does not mean that all         speakers or gesturers, and there may be differences in the
these different representation techniques are intact.              techniques used by people with milder and more severe
Therefore, to know whether gesture is impaired in aphasia,         aphasia.
we need to study both its meaning and its form, and we need
to compare aphasic speakers to non-aphasic controls.                               Perception Experiments
  Cocks, Dipper, Middleton and Morgan (2010) drew a
detailed comparison between gestures produced by a                 Material
speaker (LT) with conduction aphasia and those of non-             We used video clips of 26 native Dutch stroke patients with
aphasic speakers. They found that LT’s gestures during             aphasia (17 male). Types of aphasia included: Global (8),
word finding problems differed from those accompanied              Broca (2), Wernicke (3), Anomic (1), Conduction (1), and
with fluent speech by herself and the control speaker. For         non-classifiable (7). For 4 patients the type of aphasia was
example, most of those gestures outlined shapes. They also         not known. The mean age was 56 years, range 37 – 70. The
found that the differences in LT’s gesturing paralleled the        mean time post-onset was 24 months, range 1 – 152. All
differences in her speech, suggesting that although LT could       patients gave their informed consent for the use of their data
still use gesture effectively, her gesture production was          for research purposes.
impaired, much like her speech production. Cocks et al. call         The patients were performing an experimental version of
for a study in which iconic gestures of a larger number of         the Scenario Test (Van der Meulen, Van de Sandt-
aphasic and non-aphasic speakers are compared. This is             Koenderman, Duivenvoorden, & Ribbers, 2009). This test
what we do in our current study.                                   measures a person’s ability to functionally communicate, in
                                                                   a dialogue setting. The clinician takes part in the
Present Study                                                      communication process and actively suggests the use of
To assess whether or not gesture tends to be impaired in           alternative means of communication, such as gesture. We
aphasic speakers, we compare gestures by 26 people with            used data from two subtasks. In the sweater task, the patient
milder or more severe aphasia to those of 17 non-aphasic           is explained a scenario in which they are in a store and want
controls. New to our approach is the combination of a              to buy a sweater. The clinician talks about a sales clerk
detailed gesture analysis with a larger number of aphasic          approaching and asking: “How may I help you?”. The
speakers. In addition, we not only compare gestures of             patient is then to communicate as though addressing the
aphasic speakers to those of control speakers, but also to         sales clerk, for example by saying: “I would like to buy a
gestures produced by controls when they were asked to              sweater”. In the accident task, the information to be
communicate by gesture alone. This gives us insight into           conveyed is more complex. The clinician explains a
how people with an unimpaired gesture production system            scenario in which the patient witnessed an accident, in
would compensate for speech with gesture.                          which a car hit a biker. A police officer then approaches the
  First, we look at the intelligibility of gestures. If aphasic    patient asking: “What happened?”. The patient is then to
speakers compensate for speech with gesture, we expect             explain what took place, as though addressing the officer.
their gestures will be more informative than those of non-            Apart from the videos of aphasic speakers, we also used
aphasic speakers, who can rely on speech more. Also, the           video data of non-aphasic controls, who were matched for
more impaired speech, the more informative gesture will be.        age and educational level, and did the same test items with a
Alternatively, if speech and gesture are two sides of a coin,      trained tester. They were allowed to speak on one subtask
and therefore also break down together, the opposite is            (verbal control) and were asked to communicate using
expected. We test this by means of three perception                gesture exclusively on the other (nonverbal control).
experiments, in which we separately assess the                        We cut out fragments of the videos of all people
informativeness of verbal and nonverbal communication of           performing the two subtasks, starting right after the final
people with milder and more severe aphasia and healthy             question posed by the clinician, and stopping right before
controls, on an easier and harder communication task.              the next change of turn. Out of these fragments, we made
  Second, we present a detailed analysis of the iconic and         three stimulus movies for our perception studies: one
deictic gestures produced by aphasics and controls, zooming        containing all fragments of aphasic speakers, one containing
in on their representation techniques. If their gesturing is       all fragments of the verbal controls, and one with all
unimpaired, the techniques used by aphasic speakers may            fragments of the nonverbal controls. For the aphasic
resemble the techniques used by non-aphasic speakers. If           speakers and the verbal controls, we created three versions
aphasic speakers compensate for speech with gesture, the           of these stimulus movies: one with just the video image and
techniques they employ may be similar to those of non-             no sound, one with sound and blank video, and one with
aphasics who are asked to communicate without speech. On           both image and sound. The clips of the nonverbal controls
the other hand, if their gesturing is impaired, this may affect    were video image only, that is, without sound.
some techniques more than others, and therefore aphasic
                                                               1455

Raters and Task                                                         Table 1: Means and standard deviations of the ratio of
Raters were native Dutch students from Tilburg University.                                 correct answers.
They performed a forced choice task, in which they were
asked to judge whether the person in each clip of the                                              Ratio Correct per Modality
stimulus movie was communicating that they wanted to buy             Group         Task          Visual      Audio        AV
a sweater, or that they had witnessed a car accident.                Severe        Sweater      .51 (.16)   .74 (.10)   .73 (.11)
  We did three separate perception studies, with different           Aphasia       Accident     .66 (.10)   .75 (.10)   .84 (.10)
raters. In the first study, we used the stimulus movies of the
                                                                     Mild          Sweater      .79 (.13)   .90 (.05)   .96 (.07)
aphasic speakers only. Raters saw the video clips without
                                                                     Aphasia       Accident     .70 (.14)   1.0 (.00)   1.0 (.00)
sound, heard the audio clips without video, or saw and heard
the video clips with sound. The second perception study was          Verbal        Sweater      .78 (.14)   1.0 (.00)   1.0 (.00)
similar, but with the stimulus movies of the verbal controls         Control       Accident     .74 (.11)   .99 (.03)   1.0 (.00)
instead. Finally, we also did a perception test with the             Nonverbal     Sweater      .95 (.06)       -           -
stimulus movie of the nonverbal controls.                            Control       Accident     .90 (.06)       -           -
Analysis                                                           The interaction between Group and Modality was not
Based on their score on the ANTAT test (Blomert, Koster,           significant, F < 1. There was a three-way interaction
& Kean, 1995), which is similar to the Scenario test but in        between Group, Task and Modality, F(2, 42) = 14.01, p <
which only verbal communication attributes to a patient’s          .001. Gestures of speakers with mild aphasia were
score, the aphasic speakers were divided into two groups.          particularly more informative than those of people with
Speakers with a score below 30 (out of 10 – 50) were               severe aphasia on the sweater task, whereas the difference in
labeled as speakers with severe aphasia, and speakers with a       informativeness of speech was larger on the accident task.
score above 30 were labeled as speakers with mild aphasia.            Our next analysis compares the judgment of clips from
Clearly, this division serves our statistical analysis rather      speakers with mild aphasia to that of clips from the controls
than it being meaningful at the level of an individual             when they were allowed to speak (verbal controls). We used
speaker. There were 11 speakers in the mild aphasia group          an ANOVA with Task as a within factor and Group and
and 15 in the severe aphasia group. Since we ran our               Modality as between factors. For clips from aphasic
perception experiments separately, we present three separate       speakers, there were 15 raters per cell, and for clips from
analyses of variance. For pairwise comparisons we used the         non-aphasic speakers there were 16 raters per cell, summing
LSD method, with a significance threshold of .05. Our              up to 93 raters in total.
dependent variable in each analysis is the ratio of correct           There was a main effect of Group, F(1, 87) = 4.05, p <
answers to all answers, averaged over raters.                      .05. The ratio of correct answers was higher when judging
                                                                   clips from the verbal controls (M = .92) compared to those
Results                                                            of speakers with mild aphasia (M = .89). There also was a
Table 1 shows the means and standard deviation of the ratio        main effect of Modality, F(2, 87) = 115.78, p < .001.
of correct answers, for clips from each group of ‘speakers’,       Performance was worse in the visual modality (M = .75),
for either task, and for each modality in which they were          compared to the audio (M = .97) and audiovisual modality
shown to the raters. Performance at chance level would             (M = .99). The interaction between Group and Modality was
render a score of .5. We first present an analysis of the study    not significant, F < 1.
with clips from the two groups of aphasic speakers. We                There was a two-way interaction between Modality and
performed an ANOVA with Group (Severe aphasia, Mild                Task, F(2, 87) = 15.75, p < .001. In the visual modality,
aphasia) and Task (Sweater, Accident) as within factors and        performance was slightly better on the sweater task, whereas
Modality (Visual, Audio, Audiovisual) as a between factor.         in the audio modality it was slightly better on the accident
There were 15 raters in each cell, 45 in total.                    task. There was a three-way interaction between Group,
  All factors showed a main effect. The ratio of correct           Modality, and Task, F(2, 87) = 7.09, p < .001. When
answers was higher when judging speakers with mild                 judging aphasic speakers, raters experienced a benefit from
aphasia (M = .89) compared to speakers with severe aphasia         access to visual information on top of audio information for
(M = .70), F(1, 42) = 205.70, p < .001. It was also higher         the sweater task. There was no such benefit for the accident
when judging clips from the accident task (M = .82) than of        task, or when judging verbal controls, because performance
the sweater task (M = .77), F(1, 42) = 10.16, p < .01.             on the audio only clips was already at ceiling.
Performance was worse with the visual presentation (M =              Lastly, we present an analysis comparing the judgment of
.66), compared to the audio-visual (M = .88) and audio             visually presented clips of the controls when they could
presentation (M = .85), F(2, 42) = 68.78, p < .001. The            speak and when they could not speak (nonverbal controls).
difference between the latter two showed a trend towards           There were 16 raters in each cell, 32 in total. Task was again
significance, p = .07.                                             the only within factor. There was a main effect of Group,
                                                               1456

F(1, 30) = 24.84, p < .001. The ratio of correct answers was       its contour (2D) or molding its shape (3D) were labeled as
higher for clips of nonverbal controls (M = .93) compared to       outlining/molding, for example drawing the outline of a
clips of verbal controls (M = .77). We did not find a main         sweater in the air. Gestures that depicted the handling of a
effect of Task, F < 1, but there was an interaction between        virtual object, such as holding the hands up as if using a
Group and Task, F(1, 30) = 8.85, p < .01. For verbal               steering wheel to depict a car, were labeled as handling.
controls, performance was better on clips of the sweater task      Gestures in which the hands represented an object, or in
whereas for nonverbal controls performance was better for          which the entire body depicted the body of another person
clips of the accident task.                                        were labeled as object/enact. Examples are moving an
                                                                   upright hand forward and then flipping it horizontally, to
Discussion                                                         depict that a biker fell, or shifting the upper body from a
Clips from speakers in the mild aphasia group were judged          vertical to a horizontal position, depicting the same event.
more accurately than clips from speakers in the severe             Although theoretically possible, we found it too opaque to
aphasia group for audio, video, and audiovisual clips. This        code deictic gestures into these categories. Therefore, such
indicates that nonverbal communication may break down              gestures were only labeled as deictic.
with verbal communication, rather than it taking on the role
of verbal communication. This is confirmed by the fact that        Analysis
clips from verbal controls were in turn judged better than         We conducted 4x2 ANOVAs with Group (levels: Severe
those of the mild aphasia group, independent of whether            aphasia, Mild aphasia, Verbal control, Nonverbal control)
they were presented visually, auditory, or audiovisually.          and Task (levels: Sweater, Accident) as fixed factors.
  The almost perfect scores on the clips of nonverbal              Pairwise comparisons were done using the LSD method,
controls show that, in principal, gesture can largely              with a significance threshold of .05. Our dependent
compensate for speech on this simple judgment task. It             variables are the mean proportion of gestures of a certain
therefore seems that people with (severe) aphasia cannot use       category that ‘speakers’ in a certain group produced. This is
gesture as freely as healthy controls to compensate for            because we are interested in the extent to which the different
speech. Yet although generally the audio information was           representation techniques are used by each group, rather
more informative than the visual information, the                  than in overall differences in gesture frequency.
audiovisual presentation sometimes rendered still higher
scores. This shows that information in gesture and speech          Results
was not fully redundant either. For some aphasic speakers,         Table 2 provides an overview of the proportion of gestures
seeing them too was apparently more informative than just          produced of each type, by each group of participants on
hearing them. This may mean that gesture did take on some          either task. Table 2 also shows the mean number of gestures
of the communicative burden.                                       produced of these types combined. Overall, more gestures
  Seeing a speaker of course provides more information than        were produced on the accident than on the sweater task, F(1,
just gestures. We think however that gesture was the most          78) = 13.09, p < .001. There also was a main effect of group
important nonverbal cue in our clips. Since many people            F(3, 78) = 8.42, p < .001. The two groups of aphasic
hardly spoke intelligibly, lip movements for instance were         speakers did not differ significantly in the mean number of
not very informative.                                              representational gestures produced. They produced more
                                                                   gestures than the verbal controls and fewer than the
                      Gesture Analysis                             nonverbal controls.
We coded the (co-speech) gestures in each of the clips used          Outlining/molding gestures were produced more with the
in our perception studies, starting with the scheme by             sweater task than with the accident task F(1, 65) = 4.18, p <
McNeill (2005). We coded all movements of the hands that           .05. Although there was no main effect of Group, post hoc
seemed relevant to the communication task and that co-             analysis showed that people with severe aphasia produced a
occurred with speech. Since the gestures, or rather                larger proportion of outlining/molding gestures than people
pantomimes, of the nonverbal controls always occurred              with mild aphasia. There was no significant interaction
without speech, these were coded despite the absence of            between Group and Task, yet on the accident task, the
speech. We currently focus on representational gestures,           severe aphasics also produced significantly more outlining/
that is, gestures referring to the content of the message being    molding gestures than the verbal and nonverbal controls.
conveyed. In our current sample these consisted of iconic            Handling gestures were produced more on the sweater
and deictic gestures. Deictic gestures for example include         than on the accident task, F(1, 65) = 9.92, p < .01. This is
locating objects in the gesture space and pointing gestures.       because the nonverbal controls were the only group who
  Based on work by Müller (2008), we further coded all             made considerable use of these gestures on the accident
iconic gestures into three categories, based on the                task, significantly more so than any other group. For the
representation technique used to depict. Gestures that             sweater task, there were no significant differences in the
outlined something in the gestures space, either by showing        proportion of handling gestures between the groups.
                                                               1457

         Table 2: Means and standard deviations of the proportion of each gesture type, for each group and either task.
                                                        Proportion of gestures per Group and Task
                                     Severe Aphasia        Mild Aphasia         Verbal Control      NonVerbal Control
                                       Sw       Acc         Sw         Acc        Sw        Acc        Sw         Acc
                                      N=15     N=15        N=11      N=11        N=8        N=9       N=9         N=8
                Outlining/Molding .33 (.36) .30 (.42)     .11 (.20) .11 (.16)   .33 (.47) .00 (.00)  .29 (.27) .06 (.12)
                Handling            .09 (.22) .03 (.06)   .13 (.35) .00 (.00)   .33 (.47) .00 (.00)  .23 (.22) .12 (.15)
                Object/Enact        .00 (.00) .05 (.16)   .00 (.00) .09 (.14)   .00 (.00) .00 (.00)  .05 (.10) .48 (.15)
                Deictic             .58 (.40) .61 (.41)   .77 (.37) .80 (.24)   .33 (.47) 1.0 (.00)  .43 (.17) .34 (.16)
                Mean N Gestures     2.3 (2.6) 4.6 (4.1)   3.0 (3.4) 5.7 (3.8)   .88 (1.1) 2.1 (1.8)  4.9 (1.5)  11 (8.9)
Object/enact gestures were produced more on the accident              replace speech. Many people were outlining features of a
task than on the sweater task, F(1, 65) = 29.08, p < .001.            sweater, such as a V-neck or sleeve length, with respect to
There also was a main effect of Group, F(3, 65) = 21.09, p <          their own body. Both groups of aphasics also used this
.001, and significant interaction between Group and Task,             technique on the sweater task, showing some similarity with
F(3, 65) = 13.25, p < .001. The nonverbal controls produced           the controls in the representation techniques used.
a larger proportion of object/enact gestures than all other             However, neither control group used outlining/molding
groups. This difference was larger on the accident task.              much on the accident task. The nonverbal controls hardly
  Deictic gestures were produced more on the accident task,           used molding gestures to depict vehicles like cars, or bikes.
F(1, 65) = 4.34, p < .05. There also was a main effect of             Yet the aphasics did sometimes do this, instead of using
Group, F(3, 65) = 4.86, p < .01 and a significant interaction,        techniques like object/enact or handling, like the nonverbal
F(3, 65) = 3.52, p < .02. Post hoc analysis showed that on            controls did. This may indicate that outlining/ molding was
the accident task, the nonverbal controls produced smaller            the only way of depicting in gesture that was available to
proportions of deictic gestures than any other group, and the         most aphasics. The severe aphasics made more use of
verbal controls produced more deictics than the severe                outlining/molding gestures than the mild aphasics, which
aphasics. On the sweater task, there were no significant              may indicate a greater need to depict in gesture, possibly
differences between the groups, though the moderate                   due to more word finding problems.
aphasics tended to produce more deictics than the verbal and            It thus may be the case that most aphasic speakers were
nonverbal controls, p values < .06.                                   unable to use the techniques of handling and object/enact to
                                                                      depict on the accident task. However, the verbal controls did
Discussion                                                            not use these techniques on the accident task either.
Clearly, the aphasic speakers were not using the same                 Therefore, given the task, these techniques may be more
techniques to depict in gesture as the healthy controls who           common for gestures replacing speech (pantomimes) than
were not allowed to speak. This was most apparent on the              for co-speech gestures. It would be interesting to test
accident task. While the nonverbal controls made frequent             whether aphasics can make use of these techniques when
use of object/enact and handling gestures, the aphasics               asked to pantomime. Although many aphasics were
hardly used these techniques when trying to describe the car          unsuccessful in explaining the accident scenario verbally,
accident. For example, the nonverbal controls used their              their attempts at speaking may have caused them to produce
hand to represent a biker that first drove and then fell (the         co-speech gestures rather than pantomimes. Our current data
hand changing orientation), or they pretended to be the biker         do not reveal whether aphasics would use different
that fell, moving their upper body sideways. Aphasic                  techniques when using pantomime.
speakers did not tend to use these object/enact techniques.
Also, the nonverbal controls held their hands as though                                    General Discussion
steering a car or a bike (handling). In our data sample, the          Our perception studies showed that gestures produced by
aphasic speakers never did this. So the aphasic speakers did          speakers with aphasia were less informative than gestures
not make use of the techniques of object/enact and handling           by non-aphasic speakers and by non-aphasics who used
to compensate for their speech impairment, despite these              gesture instead of speech. Moreover, gestures by people
techniques being very suitable to replace speech.                     with more severely impaired speech were less informative
  Both the verbal and the nonverbal controls produced a               than those of people with milder speech impairment. It
considerable proportion of outlining/molding gestures on              therefore seems that aphasic speakers could not compensate
the sweater task, indicating that on this task, this technique        for their impaired expressivity in speech by gesturing.
is suitable for producing co-speech gestures as well as to
                                                                 1458

Our analysis of gesture form showed that most people with         Carlomagno, S., Pandolfi, M., Martini, A., Di Iasi, G., &
aphasia may not be able to use all possible techniques for         Cristilli, C. (2005). Coverbal gestures in Alzheimer's type
depicting in gesture freely. It seems that especially              dementia. Cortex, 41(324-329).
techniques which require access to conceptual knowledge of        Chui, K. (2005). Temporal patterning of speech and iconic
the thing depicted (object/enact and handling), were used          gestures in conversational discourse. Journal of
relatively little by people with aphasia, while techniques         Pragmatics, 37(6), 871-887.
using perceptual features (outlining/molding) were still          Cienki, A., & Müller, C. (2008). Metaphor, gesture, and
available. There may thus be a problem translating                 thought. In R. W. Gibbs (Ed.), The Cambridge Handbook
conceptual knowledge into uttered speech and gesture (see          of Metaphor and Thought. Cambridge: Cambridge
                                                                   University Press.
McNeill & Duncan, 2010).
                                                                  Cocks, N., Dipper, L., Middleton, R., & Morgan, G. (2010).
  The finding that people with severe aphasia predominantly
                                                                   What can iconic gestures tell us about the language
use outlining/molding to depict in gesture is consistent with
                                                                   system? A case of conduction aphasia. International
the case study by Cocks et al. (2010), who found that LT
                                                                   Journal of Language & Communication Disorders, Early
used this type of gesturing frequently with difficulties in        Online Article, 1-14.
speech. This finding could be of use in clinical settings. For    De Ruiter, J. P., Bangerter, A., & Dings, P. (in press). The
example, such gestures may be particularly suitable for            interplay between gesture and speech in the production of
training purposes. Also, it may facilitate understanding           referring expressions: Investigating the tradeoff
when others are aware that aphasic speakers use these              hypothesis. Topics in Cognitive Science
gestures more widely than non-aphasic speakers.                   Goodwin, C. (Ed.). (2002). Conversation and Brain
  Our studies into the informativeness of gesture, and our         Damage. Oxford: Oxford University Press.
analysis of gestural representation techniques both suggest       Kendon, A. (2004). Gesture: Visible action as utterance.
that like speech, gesture is impaired in most people with          Cambridge: Cambridge University Press.
aphasia. It therefore seems that gesture and speech               Kita, S., & Özyürek, A. (2003). What does cross-linguistic
production are likely to break down together. This makes it        variation in semantic coordination of speech and gesture
likely, though not necessary, that the processes of speech         reveal?: Evidence for an interface representation of spatial
and gesture production draw on many of the same resources,         thinking and speaking. Journal of Memory and Language,
and share an underlying process (McNeill, 2005). Although          47, 16-32.
further research is needed to study the links between gesture     Krauss, R. M. (1998). Why do we gesture when we speak?
and speech production, our study contributes to the                Current Directions in Psychological Science, 7, 54-60.
accumulating evidence that these links are tight, rather than     McNeill, D. (2005). Gesture and Thought. Chicago and
gesture and speech production largely being separate               London: University of Chicago Press.
processes. This unfortunately limits aphasic speakers’            McNeill, D., & Duncan, S. (2010). Gesture and growth
                                                                   points in language disorders. In J. Guendouzi, F. Loncke
ability to communicate through co-speech gestures. Despite
                                                                   & M. J. Williams (Eds.), The handbook of psycholinguistic
these limitations, some of the gestures they produce are
                                                                   and cognitive processes. New York, London: Psychology
informative, and add information on top of speech.
                                                                   Press.
                                                                  Melinger, A., & Kita, S. (2007). Conceptualisation load
                   Acknowledgements                                triggers gesture production. Language and Cognitive
We gratefully acknowledge all speakers for allowing us to          Processes, 22(4), 473-500.
analyze their data, Renske Hoedemaker for collecting the          Melinger, A., & Levelt, W. J. M. (2004). Gesture and the
data of our control group, and Hans Westerbeek, Hanneke            communicative intention of the speaker. Gesture, 4(2),
Schoormans, and Manon Yassa for their help in the                  119-141.
perception studies.                                               Rose, M. L. (2006). The utility of arm and hand gestures in
                                                                   the treatment of aphasia. Advances in Speech-Language
                        References                                 Pathology, 8(2), 92-109.
Alibali, M. W., Heath, D. C., & Myers, H. J. (2001). Effects      So, W. C., Kita, S., & Goldin-Meadow, S. (2009). Using the
  of visibility between speaker and listener on gesture            hands to indentify who does what to whom: Gesture and
  production: Some gestures are meant to be seen. Journal          speech go hand-in-hand. Cognitive Science, 33, 115-125.
  of Memory and Language, 44, 169-188.                            Van der Meulen, I., Van de Sandt-Koenderman, W. M. E.,
Beattie, G., & Shovelton, H. (1999). Mapping the range of          Duivenvoorden, H. j., & Ribbers, G. M. (2009).
  information contained in the iconic hand gestures that           Measuring verbal and non-verbal communication in
                                                                   aphasia: reliability, validity, and sensitivity to change of
  accompany spontaneous speech. Journal of Language and
                                                                   the Scenario Test. International Journal of Language &
  Social Psychology, 18, 438-462.
Blomert, L., Koster, C., & Kean, M. L. (1995). Amsterdam-          Communication Disorders, 1-12.
  Nijmegen Test voor Alledaagse Taalvaardigheden
  (ANTAT). Lisse: Swets & Zeitlinger.
                                                              1459

