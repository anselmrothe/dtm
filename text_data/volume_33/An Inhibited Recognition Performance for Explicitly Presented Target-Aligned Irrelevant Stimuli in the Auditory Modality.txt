UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An Inhibited Recognition Performance for Explicitly Presented Target-Aligned Irrelevant
Stimuli in the Auditory Modality

Permalink
https://escholarship.org/uc/item/4g82f6ds

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Dewald, Andrew
Sinnett, Scott

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

An Inhibited Recognition Performance for Explicitly Presented Target-Aligned
Irrelevant Stimuli in the Auditory Modality
Andrew D. Dewald (adewald@hawaii.edu)
Department of Psychology, University of Hawaii at Manoa
2530 Dole Street, Honolulu, HI 96822
Scott Sinnett (ssinnett@hawaii.edu)
Department of Psychology, University of Hawaii at Manoa
2530 Dole Street, Honolulu, HI 96822
Abstract
Overtly presented, but ignored visual stimuli are inhibited in a
later recognition task if previously presented synchronously
with an attended visual target. Here, we extend these findings
to auditory presentations. Participants were required to
respond to immediate sound repetitions in a stream of
simultaneously presented spoken words, and later given a
surprise recognition test that measured recognition for the
unattended words. Words that had been simultaneously
presented with a sound repetition in the previous repetition
detection task were later recognized at levels significantly
below chance. These data suggest the existence of an
inhibitory mechanism that is exhibited in later recognition
tests for salient auditory information that was previously
unattended and had been simultaneously presented with an
attended auditory target in a separate task.

Introduction
Anecdotal and scientific evidence suggest that stimuli that
receive attention are more efficiently processed than stimuli
that go unattended (Ahissar & Hochstein, 1993; Broadbent,
1953; Cherry, 1953; Mack & Rock, 1998; Moray, 1954;
Sinnett, Costa, & Soto-Faraco, 2006; Spence & Squire,
2003; Triesman, 1960). However, a number of
investigations have demonstrated that unattended
information can nevertheless be processed and affect
behavior. For instance, researchers have explored how
information is processed when it is explicitly or implicitly
presented, and the fate of this information when it receives
or does not receive direct and focused attention (Rees,
Russell, Frith, & Driver, 1999, Seitz & Watanabe, 2003;
2005, Sinnett et al., 2006, Tsushima, Sasaki, & Watanabe,
2006; Tsushima, Seitz, & Watanabe, 2008, Swallow &
Jiang, 2010). However, the findings from these
investigations fail to yield a clear picture as to the degree to
which unattended stimuli can influence behavioral
processing. That is, while the presentation of unattended
information has consistently lead to behavioral effects, the
nature of these effects have ranged from facilitation to
inhibition depending on whether it was presented above or
below threshold (i.e., explicit awareness).
Watanabe, Náñez, and Sasaki (2001, see also Seitz &
Watanabe, 2003; 2005) demonstrated significant perceptual
learning enhancements in the absence of focused attention
for stimuli that were presented below the threshold for

visual awareness. Yet, more recently and contrary to these
findings, Tsushima and colleagues (Tsushima, Sasaki &
Watanabe, 2006; Tsushima, Seitz & Watanabe, 2008)
demonstrated that when the implicit stimulus is made
explicit (i.e., observable), a later inhibition is observed.
Accordingly, behavioral facilitation or inhibition appears to
be partly dependent on whether or not stimulus presentation
is sub- or superthreshold. Furthermore, collectively these
investigations indicate that the temporal relationship
between the irrelevant stimulus and an attended target in a
separate task is critical to observing these facilitatory or
inhibitory effects in a later recognition task.
Highlighting the need for temporal synchronicity
between attended and unattended stimuli, Seitz and
Watanabe’s (2003) participants viewed random moving dot
displays with a subthreshold amount of coherent motion
(see also Watanabe et al., 2001 for further examples using a
similar paradigm). Critically, the subthreshold motion did
not influence post exposure motion detection unless it had
previously been presented simultaneously with targets from
a secondary task (identify white target letters occurring in a
rapid serial visual presentation (RSVP) of black and white
letters). When this temporal alignment occurred, motion
detection improved when subsequently recognizing that
same direction after exposure, suggesting that the
subthreshold motion had been processed to a degree to
facilitate future judgments. Note, the exposure motion was
always subthreshold, thereby suggesting that the direction of
the motion was implicitly learned to a level sufficient to
affect later decisions on motion discrimination.
Being that performance enhancements for motions that
were not temporally aligned with targets from the secondary
task were never observed, the temporal relationship between
the task-relevant stimulus (presence of white letter) and the
task-irrelevant exposure stimulus (motion) appears to be
critical to the effect (Seitz & Watanabe, 2003; 2005). Thus,
it would appear that if two stimuli were presented
simultaneously, then the learning associated with attention
being directed to one stimulus would spill over to the other,
thereby facilitating processing of this unattended stimulus.
However, it is important to note that the irrelevant stimuli in
these investigations were exclusively implicit in nature. As
the mechanisms involved in implicit and explicit
information processing are likely different, it is important to

1158

explore what happens when the irrelevant motion stimuli is
explicitly presented during the exposure stage.
A recent investigation addresses this very question.
Tsushima et al (2008) conducted a similar experiment using
explicit rather than implicit motion during the exposure
stage. In this case, half of the dots in the motion display
moved in coherence, while participants simultaneously
performed the letter identification task. Interestingly, the
exact opposite findings were observed. That is, while
facilitation for subthreshold presentations were still
observed, performance for superthreshold motions that were
simultaneously presented with a task target from the letter
identification task was later inhibited. This is contrary to
what one might have expected, as higher motion coherence
would possibly be expected to lead to increased learning
effects due to the stronger coherence inducing a
strengthened perceptual signal (Britten, Shadlen, Newsome,
& Movshon, 1992). The behavioral findings were supported
by fMRI data showing an inhibition in brain activity in brain
areas associated with processing motion direction
(Tsushima et al., 2006). The authors concluded that if the
irrelevant stimulus is subthreshold in nature, then no
inhibitory mechanism is engaged, whereas an inhibitory
mechanism would be in place for superthreshold displays as
attention would be needed to be directed towards the task
target (letter detection) while at the same time ignore the
superthreshold and possibly distracting motion stimulus.
Assuming that the inhibitory and facilitatory effects for
simultaneously presented, but ignored, stimuli are driven by
whether the irrelevant stimulus is implicitly or explicitly
presented, it is important to extend these results to other
sensory modalities. Despite humans being dominated by the
visual sense (Colavita et al., 1974; Posner et al., 1980;
Sinnett et al., 2007 Spence et al., 2003), it is apparent that
the human perceptual experience is a result of multisensory
information. Thus, it is important to explore whether other
sensory modalities also process irrelevant information in the
same manner as the visual sense. For instance, Sinnett et al.
(2006) demonstrated that when attentional reservoirs were
depleted by a primary task, inattentional blindness (IB) for
spoken word perception was interrupted to the same degree
as visual word recognition.
A recent investigation by Dewald et al (2010) replicated
Sinnett et al.’s (2006) investigation in the visual modality,
but included an additional analysis for items that appeared
simultaneously with targets in the separate task. In this case,
an inhibition for visually presented words (explicitly
presented) was observed. That is, despite their overt
presentation and high degree of saliency (i.e., words), later
recognition performance was below chance levels. In the
present experiment we adapted the same IB paradigm to an
auditory presentation in which spoken words were overtly
presented at the same time as common everyday sounds,
with the primary task to detect target repetitions in the
sound stream, and the secondary task to recognize the
previously ignored words. If an inhibitory mechanism
operates in the visual modality for overtly presented

irrelevant information that is simultaneously presented with
a task target from a separate task (i.e., immediate sound
repetition), then an inhibition should be observed for that
irrelevant information in the auditory modality as well,
given evidence for a common encoding system for both
written and spoken words (Hanson, 1981). Alternatively, a
facilitatory mechanism similar to that observed for
subthreshold motion displays (Seitz & Watanabe, 2003),
would suggest improved perception rates for the irrelevant,
but simultaneously presented, words. However, it is difficult
to speculate that mechanisms observed for implicit
information will extend to explicitly presented stimuli.
Lastly, it should be noted that we are extrapolating findings
from a recognition task to elucidate mechanisms of
perception for previously presented, task-irrelevant, explicit
stimuli. Despite the possibility of a slight disconnection in
this argument, there are a number of studies that utilize this
same framework (i.e., Rees et al., 1999). This is
strengthened by findings that show a convergence between
recognition tasks and online fMRI findings suggesting that
depletions of attention affect word processing itself, rather
than any process (e.g., memory) during the later presented
recognition task (see Rees et al., 1999).

Method
Participants. Sixty participants (n=60) were recruited from
the University of Hawai’i at Manoa in exchange for course
credit. Participants were naïve to the experiment and had
normal or corrected to normal hearing. Written informed
consent was obtained before participation in the experiment
occurred.
Materials. A total of 150 one to two syllable, highfrequency English words (average length of 5 letters) were
selected from the MRC psycholinguistic database (Wilson,
1988). The overall average frequency of the 150 selected
words was 120 per million, ranging between 28 and 686. A
native English speaker’s voice was recorded reading the list
three times, after which three blind listeners chose the best
exemplar of each spoken word. In the event that the three
exemplars of a specific word were chosen by the listener, a
fourth listener was asked to decide which one was best. The
selected recordings were edited using sound editing
software so as to all contain the same length of presentation
length (350 ms) and average amplitude. The sound stimuli
were extracted from a database of 100 familiar sounds and
were also edited to 350 ms and for average amplitude
(downloaded
from
www.a1freesoundeffects.com,
01/02/2003, see Sinnett et al., 2006).
Design. To ensure an enhanced level of randomization, the
100 sounds were randomly separated into two equal groups,
while the 150 words were randomly divided into three equal
groups (similar average frequency). In each group of
sounds, half (25) were pre-selected and duplicated. These
repeated sounds acted as targets as each pair occurred in the

1159

auditory presentation as an immediate repetition. The
remaining 25 sounds were also duplicated, but their
positioning in the stream never allowed for an immediate
repetition. One hundred of the 150 words were overlaid on
each of the sounds, creating a block size of 100 sound-word
items. Across two blocks of presentation, half of these
words (i.e., 50) were target-aligned with a sound repetition
while the other half was non-aligned. Half of the different
sounds (25) were repeated in one block, while the other half
were repeated in the other block. The same 100 randomized
words superimposed were used in each block (note, a
superimposed word was never repeated within a block).
Therefore, across both blocks, each sound was displayed a
total of four times (once as a repeat and then two other times
as non-repeats in the complementary block). The words
were presented a total of two times throughout the
experiment, once in each block respectively.
The same principle was used when making streams of
items when the words were repeated (attending to words
condition). As there were 150 words and 100 sounds, six
different versions of the sound-word superimposed stimuli
were created for use in the attending to sounds condition as
well as the attending to words condition.
The surprise recognition test, administered after the
completion of the repetition detection task, consisted of 100
words from both the previously heard stream (50) as well as
never heard before foil words (50). The foils were words
that were used in a different version of the experiment (fully
randomized). The 50 non-foil words (i.e., words that had
been presented) in the surprise recognition test were words
that had either been temporally aligned with the taskrelevant target, (i.e., target-aligned; superimposed over the
immediate repetition of a sound), or had not been
temporally aligned with the task-relevant target (i.e., nonaligned; superimposed over non-immediately repeating
sounds) in the previous repetition detection task. The
surprise word recognition tasks were randomized and
presented
by
DMDX
software,
(http://www.u.arixona.edu/jforster/dmdx.htm), one at a
time, written in bold, capitalized letters in Arial font at a
size of 24 points (see also Sinnett et al., 2006 for a similar
design). An analogous version of the experiment was
created where the repeated targets were words rather than
sounds. All word repetitions followed this design. Care was
taken to ensure that sound-word combinations did not have
any semantic relationship.

Procedure
Participants were randomly assigned to one of two
conditions and required to perform a recognition detection
task (i.e., respond to immediate repetitions of either a word
or picture). One group was required to attend to the sound
stream (i.e., ignore the overlaid spoken words) and respond
to immediate sound repetitions, while the other group was
required to respond to immediate repetitions in the spoken
word stream, while ignoring the sounds. Participants

responded to repetitions by pressing the ‘G’ key on the
keyboard.
Each item in the sound-word presentation was presented
for 350 ms with a 150-ms inter-stimulus interval (ISI;
silence) between each item for a stimulus onset asynchrony
(SOA) of 500 ms (see Figure 1). Before the first
experimental block, a training block of eight trials was
given and repeated until participants were familiar and
comfortable with the task. Immediately after the repetition
detection task the surprise word recognition test was
administered. Participants were instructed to press the “V”
key if they had heard the word during the repetition
detection task or instead the “B” key if they had not heard
the word before.
The recognition test consisted of either foils and targetaligned words, or foils and non-aligned words. Each group
of, respective of the focus of attention during the repetition
detection task (attending to sounds n=30 vs. attending to
words, n=30), was divided in half and given one of the two
recognition tests (n=15 per group). Note, the presentation of
conditions and recognition tests was fully randomized.

Figure 1. Example of the task in which each sound-word stimulus
was presented for 350 ms and was then replaced by silence for 150
ms. Both the word- and sound-repetition detection tasks were
performed on the same streams. In the above figure, the word
“HOME” serves as the target-aligned word.

Results
Target detection accuracy in the primary task. An analysis
of the overall accuracy of the primary task of immediate
target repetition detection revealed that participants were
accurate at detecting target repetitions in the primary task,
(73% hit rate vs. 25% miss rate, t(59) = 11.57, p<.001).
Two-factor ANOVA of overall performance. A two-factor
ANOVA was conducted with all factors between
participants and as follows: focus of attention (attending to
sounds or attending to words) and alignment of targets
(target-aligned or non-aligned). A main effect for focus of
attention confirmed that word recognition performance was
significantly better when attention was directed to the
detecting repetitions in the word stream rather than the
picture stream, (F (1,59) = 23.37, p < .01). The main effect
of target alignment failed to reach significant (F (1,
59)=2.24 p < .11). Importantly, there was an interaction
between focus of attention and alignment of targets (F
(1,59) = 5.01, p <. 02). In order to understand the interaction
a series of planned t-tests were conducted.

1160

Target-aligned and non-aligned word recognition
performance. Recognition performance for target-aligned
words (i.e., words previously paired with immediately
repeated sounds) was compared with non-aligned words and
also against chance. When attending to spoken words in the
repetition task (rather than sounds), subsequent recognition
for target-aligned as well as non-aligned words were both
significantly better than chance performance (targetaligned: 58%, SE = 3.32, t(14) = 2.43, p = .029; nonaligned: 59%, SE = 1.66, t(14) = 5.69, p < .001). There were
no significant differences between target-aligned and nonaligned word performance after attending to the words
(t(14)= .37, p=.712; see Figure 2). Additionally, the hit rates
after attending to the words for target-aligned (58%) and
non-aligned (59%) words were both significantly greater
than the false alarm rates (33%, SE =2.56, t(9) = 3.68, p =
.001 and, 36%, SE = 2.81, t(9) = 3.25, p = .002,
respectively). Analysis of recognition performance after
attending to the sound stream confirmed that participants
were not different than chance at recognizing non-aligned
spoken words (50%, SE = 3.68, t(14) = 0.21, p = .831).
Critically, recognition performance was significantly
different from chance for target-aligned spoken words
(40%, SE = 3.38, t(14) = 2.54, p = .023). When compared to
each other, recognition for non-aligned words was
significantly better than target-aligned words (t(14) = 2.30,
p = .037; See Figure 2). Furthermore, when attending to the
sound stream the hit rate for target-aligned words (40%)
was significantly lower (i.e., inhibition) when compared
with the FA rate (51%, SE = 4.51 t(9) = 3.52, p = 0.01),
while there was no difference between hits and FAs in the
non-aligned recognition test (hits: 50%, SE = 3.68, FAs
52%, SE = 5.90, t(9) = .223 p = 0.829).

% Correct on Recognition Test

Overall surprise recognition performance. Recognition
performance for target-aligned words was compared with
non-aligned words and also against chance. Overall,
performance was significantly better after attending to the
spoken words when compared with after attending to the
sounds (56.3%, SE = 1.09 vs. 48.2%, SE = 1.05, t(29) =
6.85, p < 0.001). Performance after attending to the words
was significantly better than chance (t(29) = 5.76 , p
<0.001) while performance after attending to the sound
stream failed to be significantly better than chance (t(29) =
1.62, p = 0.115). Further demonstrating the enhancement of
word recognition when attention had been directed to the
word stream, significantly fewer false alarms (FAs) were
made when compared with hits (hits: 56%, SE = 1.05, FAs:
33%, SE = 2.25, t(19) = 5.89, p = 0.001), while there was no
difference between hits and false alarms when attention was
directed to the sounds (hits: 48%, SE = 1.09, FAs: 50%, SE=
3.55, t(19) = 1.39, p = 0.11).

60

Target-Aligned
Non-Aligned

50

40

30
Attending to Words

Attending to Sounds

Figure 2.Recognition percentages and standard error bars for
Target-Aligned (grey bars) and Non-Aligned (black bars) words in
the surprise word recognition test after attending to either the
spoken word stream (Left) or the sound stream (Right).

Discussion
The present experiment extends the findings of Sinnett et al.
(2006) in a number of ways. First, and in-line with their
report, we demonstrated that the auditory modality is
susceptible to inattentional blindness (i.e., deafness).
Despite not having the analogous visual condition
(although, see Dewald et al., 2010; Rees et al., 1999; Sinnett
et al., 2006 for examples with this condition), it is
reasonable to conclude that auditory word recognition is
significantly better after attending directly to the word
stream as opposed to attending to a distracting stream of
sounds. More specifically, participants were unable to later
recognize the words that had been simultaneously presented
with the sound stream, if attention had been directed to the
sound stream during the repetition detection task.
The second critical finding pertains to recognition
performance for words, after having attended the sound
stream, that had been presented at the same time as a sound
target in the primary task. Here we replicated the visual
findings of Dewald et al (2010) in the auditory modality.
That is, after having attended to the sound stream (rather
than a picture steam as in Dewald et al., 2010) in the
repetition detection task, subsequent word recognition for
target-aligned words (i.e., words presented at the exact
same moment as a sound repetition) was significantly below
chance. This suggests, as does Dewald et al (2010), a
possible inhibitory mechanism for overtly presented
irrelevant information that appears simultaneously with an
attended target.
The potential inhibition of the auditorily presented
target-aligned words when attention was directed to the
sound stream is of key interest. Many investigations have
demonstrated that unattended and irrelevant stimuli are
often not perceived when attentional resources are depleted
(Mack & Rock, 1998; Rees et al., 1999; Sinnett et al.,
2006), however only recently have investigators directly
compared the performance for target-aligned and nonaligned stimuli. In this case, it appears that either a
facilitation or inhibition can be observed, dependent on

1161

whether the irrelevant stimuli are presented above or below
threshold. Here, word recognition was inhibited for targetaligned words, despite word perception being arguably an
automatic process (Stroop, 1935; Lupker, 1984, see also
Shor, 1975 for an example of an auditory Stroop task).
Moreover, these investigations have typically focused on
visual presentations, whereas the present investigation
extends these results to the auditory modality.
While the inhibition effect observed here supports
research by Tsushima et al (2006, 2008), it fails to coincide
with recent findings by Swallow and Jiang (2010),
suggesting an “attentional boost” (i.e., facilitation) for
simultaneously presented information in a dual-task
paradigm (see also Lin et al., 2010 for a similar example of
a paradigm utilizing temporally aligned targets). In their
experiment, participants monitored a stream of pictures of
various scenes. While monitoring the stream, a series of
distractor items (small black superimposed squares) were
simultaneously paired with the presentation of each picture
presentation. Participants were required to remember as
many of the presented scenes as possible, in addition to
monitor the distractor stream for the presence of an “oddball” color change (i.e., the presence of a white square rather
than black squares). In a subsequent forced choice
recognition test for the picture scenes, an enhanced
recognition for pictures that had been presented
simultaneously with the presence of the target (i.e., the
‘odd-ball’ color change) in the distractor stream was
observed (i.e., the attentional boost effect).
Of particular note to Swallow and Jiang’s (2010)
findings is the fact that the pictures were presented
explicitly, much like the unattended words in our
investigation. The question then remains as to why they
observed a facilitation for target-aligned stimuli while our
findings demonstrate an inhibition? However, it should be
noted there is a significant procedural difference that could
explain the contradictory findings. Specifically, participants
in Swallow and Jiang’s experiment were required to attend
to both streams, whereas the participants here were
specifically instructed to attend to only one stream (i.e.,
ignore the other). This limitation alone could drive the
differences in findings between paradigms, but could also be
exacerbated by the nature of the stimuli chosen for the
recognition test (i.e., pictures in their experiment and words
in the present investigation).
It could be argued that the inhibition of previously heard
words that had been paired with a sound repetition target
does not follow the conclusions drawn by Seitz and
Watanabe (2003; see Seitz & Watanabe, 2005 for a review).
According to the framework provided by their
experimentation, an enhanced recognition performance for
words synchronized with task-relevant targets should have
been observed. That is, while the necessary temporal
synchronization between task-relevant and task-irrelevant
stimuli was present, enhanced perception for task-irrelevant
stimuli was not observed. The exact opposite was seen here,
in that there was an inhibition of performance for the

recognition of previously temporally aligned words with
repetition targets in the primary task. However, it should be
noted that participants were overtly presented with highly
salient words here, whereas Seitz and Watanabe utilized
subthreshold motion displays, making a direct comparison
from their experiment to ours difficult at best.
Accordingly, our findings dovetail with Tsushima et al.
(2008; see also Tsushima et al., 2006), who presented
motion displays with superthreshold (i.e., overt) motion
coherence. In this case, they observed an inhibition when
detecting similar motions that had been earlier presented
with task targets from a separate task, akin to the inhibition
we observed for auditory words. Therefore, the present
findings extend their findings not only to the auditory
modality, but also when using a stimulus arguably much
more salient than simply dot motion displays.
Although the conclusions of Tsushima et al (2006, 2008)
and the findings here both suggest that a strong irrelevant
feature will be inhibited rather than facilitated if presented
simultaneously with a target from a separate task, future
research could employ the paradigm from the present study
to investigate prolonged exposure rates through the
utilization of a larger number of trials and a smaller number
of target-aligned words to see if perception is enhanced,
rather than inhibited.

References
Ahissar, M., & Hochstein, S. (1993). Attentional control of
early perceptual learning. Proceedings of the
National Academy of Science, 90, 5718–5722.
Borst, A., & Egelhaaf, M. (1989). Principles of visual
motion detection. Trends in Neurosciences, 12(8),
297-306.
Bright, P., Moss, H., & Tyler, L. K. (2004). Unitary vs.
multiple semantics: PET studies of word and
picture processing. Brain and Language, 89, 417432.
Britten, K.H., Shalden, M.N., Newsome, W.T., & Movshon,
J.A. (1992). The analysis of visual motion: A
comparison of neuronal and psychophysical
performance. Journal of Neuroscience, 12, 47454765.
Dewald, A.D., Sinnett, S., & Doumas, L.A.A. (2010).
The inhibition and facilitation of stimuli can be
modulated by the focus of direct attention.
Proceedings of the Twenty-Eight Annual
Conference of the Cognitive Psychology Society
Driver, J., & Spence, C. (2004). Crossmodal spatial
attention: Evidence from human performance. In
C. Spence & J. Driver (Eds.),Crossmodal space and
crossmodal attention. Oxford, UK: Oxford
University Press.
Hanson, V.L. (1981). Processing of written and
spoken words: Evidence for common coding.
Memory and Cognition, 9(1), 93-100.

1162

Karni, A., & Sagi, D. (1993). The time course of
learning a visual skill. Nature 365, 250-252.
Lin, J.Y., Pype, A.D., Murray, & Boynton, G.M. (2010).
Enhanced memory for scenes presented at
relevant points in time. PLoS Biol, 8(3),
E1000337.
Lupker, S. J. (1984). Semantic priming without association:
A second look. Journal of Verbal Learning and
Verbal Behavior, 23, 709–733.
Peterson, S.E., Fox, P.T., Posner, M.I., Mintun, M., &
Raichle, M.E. (1989). Positron emission
tomographic studies of the processing of single
words. Journal of Cognitive Neuroscience,1(2),
153-170.
Rees, G., Russell, C., Frith, C. D., & Driver, J. (1999).
Inattentional blindness versus inattentional
amnesia for fixated but ignored words. Science,
286, 2504-2507.
Roelfsema, P. R., van Ooyen, A., & Watanabe, T. (2009).
Perceptual learning rules based on reinforces and
attention.Trends in Cognitive Sciences, 14(2), 6471.
Ruz, M. A., Worden, M. S., Tudela, P.O. & McCandliss, B.
D. (2005). Innattentional amnesia to words in a
high attentional load task. Journal of Cognitive
Neuroscience,
17, 768-776.
Seitz, A. R., Kim, R., & Shams, L. (2006). Sound
facilitates visual learning. Current Biology,16,
1422-1427.
Seitz, A. R. & Watanabe, T. (2003). Psychophysics: Is
subliminal learning really passive? Nature, 422,
36.
Seitz, A. R. & Watanabe, T. (2005). A unified model for
perceptual learning. Trends in Cognitive Science,
9 (7), 329-334.
Shor, R. E. (1975). An auditory analog of the Stroop test.
Journal of General Psychology, 93, 281-288.
Sinnett, S., Costa, A., & Soto-Faraco, S. (2006).
Manipulating inattentional blindness within and
across sensory modalities. Quarterly Journal of
experimental Psychology, 59(8), 1425-1442
Snodgrass, J. G., & Vanderwart, M. (1980). A standardized
set of 260 pictures: Norms for name agreement,
image agreement, familiarity, and v isual
complexity. Journal of Experimental Psychology:
Human Learning and Memory, 6, 174–215.
Spence, C. & Squire, S.B. (2003). Multisensory
integration: Maintaining the perceptual
synchrony. Current Biology, 13, R519-R521.
Stroop, J. R. (1935). Studies of interference in serial verbal
reactions. Journal of Experimental Psychology, 1
8,643-662.
Swallow K. M., & Jiang, Y. V. (2010). The attentional
boost effect: Transient increases in attention to one
task enhance performance in a second task.
Cognition, 115, 118-132.

Tootell, B., Silverman, M. S., & De Valois, R. L.
(1995). Spatial frequency columns in primary
visual cortex. Science, 214(4522), 813-815.
Tsushima, Y., Sasaki, Y., & Watanabe, T. (2006). Greater
disruption due to failure of inhibitory control on an
ambiguous distractor. Science, 314, 1786-1788.
Tsushima, Y., Seitz, A. R., & Watanabe, T. (2008). Taskirrelevant learning occurs only when the irrelevant
feature is weak.Current Biology,18(12), 516-517.
Watanabe, T., Náñez,Y., & Sasak, S. (2001). Perceptual
learning without perception. Nature, 413, 844–848.
Wilson, M. D. (1988). The MRC psycholinguistic database:
Machine readable dictionary, version 2.
Behavioural Research Methods, Instruments
andComputers, 20, 6-11.

1163

