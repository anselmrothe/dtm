UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A neuroplausible computational model of vision also exhibits asymmetry in developmental
category learning
Permalink
https://escholarship.org/uc/item/60h4m4gn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Ankit, Ankit Gupta
Devesh, Devesh Kumar Singh
Mukerjee, Amitabha Mukerjee
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       A neuroplausible computational model of vision also exhibits asymmetry in
                                            developmental category learning
              Ankit Gupta (ankit0370@gmail.com)                         Devesh Kumar Singh (deveshks@iitk.ac.in)
              Department of Electrical Engineering,                    Department of Computer Science and Engineering,
              Indian Institute of Technology Kanpur, India                   Indian Institute of Technology Kanpur, India
                                             Amitabha Mukerjee (amit@cse.iitk.ac.in)
                                           Department of Computer Science and Engineering,
                                               Indian Institute of Technology Kanpur, India
                               Abstract                                 same or different categories. Based on the novelty prefer-
                                                                        ence paradigm, it is expected that infants would look longer
   Computational models are increasingly used to explore possi-
   ble mechanisms underlying infant capability in various tasks.        at objects from the novel category. The asymmetry result,
   Often, such models do not work directly on perceptual data,          demonstrated by Quinn and co-workers nearly two decades
   but on hand-computed features of images; such models are             ago, is that infants who are habituated to cats demonstrate a
   open to the criticism that these high-level features may not be
   what is actually computed in the neural computation. Here we         preference for dogs as novel stimuli, whereas the preference
   explore the feasibility of the Serre-Poggio (S-P) model which        is weaker when habituated on dogs and exhibited a cat. Such
   emulates the early ventral stream of the primate visual cortex,      an asymmetry is especially surprising because it is assumed
   and constructs a probabilistic model of the tuned cells of the
   V4-IT cortex. In experiment 1, we use this system to model           that such young infants may not have had much exposure to
   asymmetry in visual category learning in early infancy (e.g.         the classes of cats and dogs per se, and that any priors they
   cats vs dogs), and show that surprisal for the novel category is     form are learned only from this immediate experience.
   higher when habituated on CAT than on DOG. In experiment
   2, we show that face habituation can be used to discriminate on         Quinn and co-workers conjectured that the asymmetry may
   full bodies. Experiment 3 demonstrates that superordinate cat-       have arisen due to greater variation among dogs, so that
   egory discriminations are easier than for the basic level. These
   experiments agree with earlier psychological data and partially      some novel cats may also be accepted on the DOG schema,
   validate the S-P model for such tasks.                               whereas the CAT schema is tighter and rejects most of the
                                                                        novel dogs (Quinn et al., 1993). This hypothesis was vali-
                          Introduction                                  dated using a perceptron network by Mareschal, French and
Infant perceptual ability has been demonstrated for a wide              Quinn (Mareschal et al., 2000), who found that certain fea-
range of visual tasks, and computational models are increas-            tures had lower spread among cats than among dogs. For the
ingly used to analyze possible mechanisms underlying such               simulation, they hand-computed ten traits from the images:
behaviour. However, using computational models in visual                head length, head width, eye separation, ear separation, ear
development is limited owing to the high dimensionality of              length, nose length, nose width, leg length, vertical extent,
visual data and the complexity of extracting meaningful struc-          horizontal extent. These features were then given as input to
tures from images. Thus, a review of computational simula-              a three-layer perceptron, which was trained to discriminate on
tion in development cites only two (out of thirty) papers for           cats and dogs over 250 epochs. The network error rates (used
perceptual categorization (Schlesinger & Parisi, 2001).                 internally in the backpropagation algorithm) were used as an
                                                                        analog for looking time, and results were shown to correlate
   Yet, the infant’s strongest cue to abstracting from the world
                                                                        with the original experiments on infants. Also, the gaussian
is perception, since its motor functions are under-developed.
                                                                        distribution of these features was computed and the features
Between two and six months, infants demonstrate increasing
                                                                        for the DOG were found to have a wider variation than that for
ability to discriminate a number of complex concepts, primar-
                                                                        the CAT. This analysis thus corroborated the the early sugges-
ily based on perception. Computational studies investigating
                                                                        tion that the asymmetry arose because the CAT class had less
infant visual perception can throw light on the the internal
                                                                        variability than the class DOG.
mechanisms for such learning, and also throw light on de-
bates such as degree of innateness, learnability, etc.                     However, such an approach is open to criticism since the
   One of the areas that has attracted considerable attention in        computation of high-level features requires that one is able
visual learning by infants is that of asymmetry in infant vi-           to decompose the image into ear, nose, eye etc. While there
sual categorization (e.g. DOG vs.CAT) (Mareschal, French,               is considerable evidence that the infant is sensitive to parts
& Quinn, 2000 ; Quinn, Eimas, & Rosenkrantz, 1993).                     of the face (Perrett & Benson, 1992), nonetheless the task
This intriguing phenomenon has attracted considerable atten-            of mapping from a raw image to such parallel data on faces
tion, and has also been addressed by a connectionist model              from different species remains a formidable challenge. The
(Mareschal et al., 2000). Here 3-6 month infants are shown              images, if we consider them to be the equivalent of 300 × 200
a series of images from a certain category, and their prefer-           pixels, have about 60,000 dimensions. The manually exe-
ential looking (or looking time) is analyzed for objects of the         cuted task of obtaining ten features from the image space in-
                                                                    2520

volves a mapping,say fman , from the original image I to these        using a “max” function. This gradually increases scale, speci-
ten features. Subsequently, the function learned by the neural        ficity, and translation invariance as we move up the hierarchy.
network, fL , operates a 10-dimensional feature space to ob-          There are four layers, the first of which roughly corresponds
tain a binary classification into CAT, DOG. The overall process       to simple cells in V1 that are tuned to orientation (layer S1).
is given as                                                           The max for each orientation is computed over a pool of S1
                                                                      cells, resulting in tolerance to position and scale within the vi-
                      fman            fL
             I ∈ RD −−→ x f ∈ R10 −→ {CAT, DOG}                       sual field. This layer, C1 passes its output to the next tuning
                                                                      layer, S2 which preferentially selects differing orientations
   where D represents the dimensionality of the image, be-            resulting in preferences for different shape primitives. It is
tween 104 and 106 pixels, say. Clearly, learning (or knowing          suggested that these may correspond to cells in V4 or in the
innately) a function such as fman is not a trivial matter. An-        superficial layers of V2. A large number of S2 cells learn their
other crucial question is - which ten features to choose for          responses based on random patches from the input. The final
the intermediate representation? Determining such a set of            C2 layer used in this work maximizes across cells tuned on
informative features from this heterogeneous dataset is itself        the same shape model, thus increasing invariance over scale
injecting a considerable amount of human knowledge into the           and position. It is this final computed C2 output which is used
process.                                                              in various object recognition tasks. The 4-layer hierarchy is
   A second problem with manually computing features is               described in Table1.
that only certain classes of experiments can be duplicated. In           In our experiments, we use this S-P model to compute the
one of the experiments of the Quinn group, the infant is habit-       C2 feature vectors for different sets of habituation images.
uated on face images and testing is done on full bodies (Quinn        TThese features are used to learn probability distributions for
& Eimas, 1996). Clearly, mapping the full-body images to the          the habituation category, which simulates the tuning of neu-
same ten feature vectors would defeat the very purpose of the         rons in late V4 / early IT for the given visual category. The
experiment, and assigning some other feature class to the test        final discrimination is done by applying these tuned C2 cells
images would make them incommensurate. Working directly               to the test image I. The steps from S1 through C2 may be
on image data provides a mechanism for handling these as-             thought of as a mapping fv s, which are then used in learning
pects, and we investigate this question in our experiment 2.          the cat, dog discrimination as follows:
Computational model of early ventral stream                                                  fvs           fL
                                                                                    I ∈ RD −→ xC2 ∈ Rn −→ {CAT, DOG}
Improved understanding of function in the neuroanatomical
circuits serving visual perception has led to considerable ad-        Here fvs is the feature mapping performed in the ventral
vances in computational models of the visual stream. In par-          stream. Note that unlike in the previous situation where fea-
ticular, the ventral stream from the V1, V2 and V4 areas of           tures corresponded to conscious, declarative elements, here
the visual cortex to the IT is part of the cortical computational     the features are subconscious and implicit. As in the earlier
processes thought to be responsible for object recognition or         situation, the learning component of the system now has to
“what” questions. This pathway has attracted considerable             learn a n dimensional discriminant function on this feature
interest from computational simulation. Tomaso Poggio’s               space, based on which it can discriminate the classes dogs
group, working on modeling various aspects of the primate             and cats.
visual system, has suggessted several models for this part of            The dimension n is a function of the number of training
the pathway. The model we adopt from (Serre, Kouh, et al.,            images that random patches are sampled from; for two sets
2005) seeks to replicate the gradual increase in complexity           of 16 images in the training set, this results in 512 C2 units.
of the preferred stimuli for neurons along the ventral stream,        This vector is then used for identifying a distribution. Finally,
culminating in tuned IT neurons which are believed to play a          we observe that this computational model has been tuned to
key role in object recognition (Tanaka, 1996).                        reflect single cell readings obtained from various sites in the
   The Serre-Poggio model takes a gray-scale image as in-             visual stream of adult monkeys. Even if we assume sufficient
put and performs four intermediate computations that com-             correspondence with human visual processes, the question of
bine processes in the early computation in the primate visual         relevance to the infant visual system remains. In this connec-
system. The first few hundred milliseconds in the retina and          tion we note that there is significant evidence that infants ex-
LGN involves identifying simple local maxima (e.g. center-            hibit orientation selectivity from an early stage (Wattam-Bell,
on) processes; these are combined to obtain orientation-tuned         1991) and the first stage in the Serre-Poggio model recruits
responses. In the S-P model, these are simulated by orienta-          orientation sensitive frequency filters. What is absent in the
tion tuned simple cells (S1) which constitute the first layer,        infant are model-based priors that would be present in adults
corresponding to the early part of the V1. The model has al-          based on experience with visual stimuli of cats and dogs.
ternating layers for tuning (simple, selective) and combining         However, this we do not assume, since our model is feed-
(complex, invariant) computation. The S-cells are tuned for           forward. On this basis, Serre has described the algorithm that
specific orientations or shapes, and the C-cells combine the          learns the vocabulary of tuned neurons as “developmental-
responses of the neighbouring S-cells in the previous layer           like”. Indeed, our experiment can be taken as a test for the
                                                                  2521

             Level                                         Functionalities
         Simple cells (S1)          Gabor filters, 16 spatial frequencies(=scales), 4 orientations
         Complex cells (C1)         Local max over a pool of S1 cells ; increase in tolerance to position and scale
         Composite feature cells    Combination of V1 like complex units at different orientations
         (S2)
         Complex        composite   Local pooling over S2 units with same selectivity but slightly different positions and scales ;
         feature cells (C2)         Same selectivity as S2 units but increased tolerance to position and size of the preferred stimulus
                          Table 1: Summary of layers in S-P model (based on (Serre, Wolf, & Poggio, 2005))
  Gabor Filter Parameter        Symbol      Parameter value                Modeling infant visual cognition
  Name
  Receptive field(RF) size          s       16 filters 7X7 to 37X37        Visual categorization processes in infants have been stud-
                                            (in steps of 2)                ied by many experimenters including Quinn and co-workers
  Orientation                       θ       0◦ , 45◦ , 90◦ , 135◦          primarily based on preferential looking paradigm (Quinn &
  Effective Width                   σ       0.0036s2 + 0.35s + 0.18        Eimas, 1996 ; Quinn et al., 1993) though looking time or elec-
  Aspect Ratio                      γ       0.3
  Wavelength                        λ       σ/0.8                          trophysiological methods (ERPs) have also been used (Quinn,
                                                                           Westerlund, & Nelson, 2006). Stimuli involved images of
Table 2: Parameters of the Gabor filter bank (Source: (Serre,              animals and other object classes, which were often cut-out
Wolf, & Poggio, 2005 ; Daptardar, 2009) )                                  (isolated) from the background and held up on sticks, or
                                                                           sometimes obscured to reveal only the face (Quinn & Eimas,
                                                                           1996). In many of these experiments, only one class was dis-
validity of such a claim for this model.                                   played (e.g. CAT, and the response was measured for a novel
                                                                           category such as DOG or some inanimate object such as CAR.
                                                                              In our experiments, we focused on the preferential looking
Application to object recognition                                          paradigms, which were modeled based on probability distri-
                                                                           butions computed on the input data set. Since there is no
In an object recognition task, the system is given a large                 reason to assume otherwise, we use a gaussian model for the
number of images of different objects, and these are labelled              probabilities. The probability for novel (test) images are com-
with the relevant object categories. C2 features are com-                  puted based on their C2 features x, of dimensionality n, com-
puted for all the images in the training set, and these are                puted from the images. It is assumed that these are sampled
used to train a classifier - typically, a support vector ma-               from a distribtution x ∼ N (µ, ∑), estimated from the training
chine (SVM) (Bishop, 2007), which performs the classifica-                 set:
tion. Now, given a new image, its C2 vector is computed and                                                                1
passed to the trained SVM which then assigns a class label to                         Pr(Itest |I1 , I2 , .., Im ) =                exp(−d 2 )  (1)
it. The model has reported 44% percentage average accuracy                                                           (2π)n/2 |∑|1/2
in discriminating more than a hundred object categories in the                                p
CALTECH-101 dataset (Serre, Wolf, Bileschi, Riesenhuber,                   where d =             (y − µ)T (∑)−1 (y − µ) and I1 , I2 ..., Im and
& Poggio, 2007). However, the model has some drawbacks                     x1 , x2 ..., xm are training set images and corresponding C2 fea-
on present (largely serial) computational architecture where               ture vectors; Itest , y are test stimuli and its C2 feature vector;
the computational load is very heavy due to the dense tuning               ∑ is the covariance matrix of x. If the Pr(Itest ) is greater than
and max operation and blind feature selection.                             some threshold τ then the image is acceptable as a member of
                                                                           the habituation class, else it is considered a novel class. We
    The model replicates the shape primitives computed in the              report results for a threshold at which instances of the habitu-
early ventral stream (upto early IT). The model relies on                  ation class would have been accepted, and also test the effect
dense orientation data, and not on global shape - hence it                 of other thresholds.
would not work for silhouette experiments, say. However,                      For estimating looking time, we assume that looking time
many images can still be categorized, and we report the sim-               is proportional to surprisal, - an information-theroetic notion
ulations for three such experiments.                                       and corresponding to the amount of information present in a
Implementation of Serre Poggio model For this work,                        single observation (Bishop, 2007). Surprisal is often corre-
the S-P algorithm was re-written in C++, since the available               lated to looking-time in cognitive models, e.g. in psycholin-
code in MATLAB was extremely slow (Daptardar, 2009) (im-                   guistics (Levy, 2008).
plementation available). OpenCV, OpenMP (libgomp), MPI                        Thus, an observation that is close to expectation gener-
(OpenMPI) and LibSVM libraries were used for this project.                 ates low surprisal, and highly deviant (novel) data generates
Table 2 describes the parameters used in the implementation                higher surprisal. Surprisal for novel test stimuli Itest with C2
of Gabor filter. The implemented model was tested on cate-                 feature vector y is defined as
gorization tasks and performed similarly to the original work
(Serre, Wolf, & Poggio, 2005).                                                        surprisal(Itest ) = −log {Pr(Itest |I1 , I2 , ...., Im )} (2)
                                                                      2522

Figure 1: Sample dataset: first 2 images from Quinn et al. (2001) and last two were from CAT-DOG database (2011)
Hence, we have surprisal(Itest ) = d 2 + c, where c is a con-      exemplars must be such that any individual instance does not
stant estimated from the Σ.                                        affect the overall performance of the model. Figure 1 shows
                                                                   the sample database used in earlier experiment and in our ex-
                    The experiments                                periment.
We conducted three experiments on the lines of three of the
experiments reported by Quinn and his group. In the first          Experiment 1: Asymmetry in category learning
experiment, the system was trained on 16 full-body images
from the categories CAT or DOG, and it computes a separate                                                         70
                                                                                                                        Novel CAT in DOG trained condition
                                                                                 Mean Novel Category Preference
                                                                                                                        Novel Dog in CAT trained condition
gaussian model for each of these classes on the C2 features.                                                       60
Next, it was shown a pair of individual images one of CAT                                                          50
and one of DOG. Unlike with human infants, while exhibiting                                                        40
                                                                                      Results (Percentage)
images, the learning is switched off, so that each episode ef-                                                     30
fectively replicates one experiment with an infant (albeit, the                                                    20
same one). Modeling looking time based on surprisal, our                                                           10
results are compared with experiments done on real infants                                                          0
                                                                                                                  Mareschal et al., 2000      Serre Poggio Model
with full-body images of these animals from (Mareschal et
al., 2000). We also report the incremental error rates in as-
signing test images to the habituation (training) category or      Figure 2: Comparison of mean percentage performance of
novel category.                                                    the asymmetry experiment done on infants (Mareschal et al.,
   Experiment 2 replicates the face to whole body learning         2000) with S-P model
referred to above (Quinn & Eimas, 1996). Here, we train on
16 face images from these two classes, and test on full-body           In this experiment, a set of habituation images Itraining was
images of CAT and DOG.                                             used to learn a distribution for a single category (in the C2
   Experiment 3 considers hierarchical categorization (Quinn,      feature vector space). Now, given two test images I1 and
2004 ; Behl-Chadha, 1996 ; Quinn et al., 2006). Here we            I2 , the image with higher surprisal will corresponds to lower
seek to demonstrate that distinctions between superordinate        conditional probability Pr(Ii |Itraining ) and which means high
categories (e.g. CAR vs CAT) is much more robust than basic        looking time. Different sets of 16 images from a single
categories such as CAT vs DOG.                                     category are randomly selected as Itraining for each trial of
                                                                   familiarization phase, resulting in an estimated distribution
Stimuli                                                            N (µ,∑). For testing, we choose all possible pairs of new test
We chose CAT, DOG image exemplars similar to those used            images objects from a set of 8 CAT and 8 DOG images. After
by (Quinn & Eimas, 1996 ; Quinn et al., 1993)), except that        training with the CAT category, situations where DOG images
in the original experiments, the figure objects were cut out       are preferred are compared with the preference for the CAT
from the background so as to avoid any distractors. This as-       images. The result (average over 5 runs), compares well with
sumes segmentation capability that an infant may or may not        the original infant experiment (Mareschal et al., 2000) (Fig-
have. We did some early tests which showed the system do-          ure 2).
ing almost as well on un-cropped images (without too much              Further, we tested the discrimination between these cate-
background) as with cropped; so all results are reported on        gories based on different training sets with 16 images of both
un-cropped images.                                                 categories, tested with a mix of cat and dog images. Un-
   Images of the animal standing sideways, on all fours, were      like the conditional probability maximization method in the
selected for the full-body experiment, while for face only         earlier single-category approaches, we use an SVM now to
case, images with the animal facing the viewer were chosen.        discriminate among the test images. When the model was
The image sets are available online (CAT-DOG database,             trained on 16 CAT images against 16 images from a mix of
2011).                                                             animals, its average categorization accuracy on 8+8 test im-
   The other issues are that a) a large number of image in-        ages was 65% for CAT and 55% of DOG images were found
stances are needed for category learning, and b) selection of      to be novel (Figure 3). Conversely, when trained on DOG, the
                                                                2523

test data categorization was 75% for dogs, and only 20% of
                                                                                                                                     Percentage Categorization                                   Percentage Categorization
                                                                                                                                                                 100                                                         100
                                                                                                                                                                  90                 CAT                                      90                 CAT
                                                                                                                                                                                     DOG                                                         DOG
cats were found to be novel - i.e. 80% of the cats were ac-                                                                                                       80                                                          80
                                                                                                                                                                  70                                                          70
cepted as dogs. To determine the stability of this result, we                                                                                                     60                                                          60
                                                                                                                                                                  50                                                          50
                                                                                                                                             Accuracy                                                    Accuracy
tested the result by choosing different subsets for training vs                                                                                                   40                                                          40
                                                                                                                                                                  30                                                          30
test images; the results of these tests, summarized in Fig. 4                                                                                                     20                                                          20
                                                                                                                                                                  10                                                          10
show a consistently better performance in recognizing CATs.                                                                                                        0
                                                                                                                                                                    Face Only        Full Body
                                                                                                                                                                                                                               0
                                                                                                                                                                                                                              Super Ordinate    Basic Level
This demonstrates that a) the model is able to discriminate the                                                                                                              Test Condition                                           Level of Complexity
novel full bodies after learning from few training exemplars,                                                                                                               (a)                                                         (b)
and b) there is a high degree of asymmetry in performance, as
in the original experiment. This suggests that an SVM classi-                                                                    Figure 5: Experiments 2 and 3: a. Role of facial informa-
fier in some respects may be behaving similar to mechanisms                                                                      tion in categorization of full body images of CAT and DOG;
in infants, though this is far from saying that infants are actu-                                                                b. Better categorization performance at superordinate (CAR
ally using such mechanisms.                                                                                                      vs ANIMAL) than at basic level (CAT vs DOG).
                                                                                          Exemplar from trained category
                                  Percentage Categorization Accuracy
                                                                                   Novel exemplars from trained category
                                                                       100          Novel exemplars from other category          lowest discriminating value to the highest. We report the True
                                                                        80                                                       Positive Rate (percentage of novel detections that are actually
                                                                                                                                 novel) vs the False Positive Rate(percentage of the non-novel
                                                                        60
                                                                                                                                 detections that were actually novel) for different thresholds
                                                                        40
                                                                                                                                 (Fig. 4.a). Regions for very high and very low thresholds are
                                                                        20                                                       noisy, but in the middle part, curves closer to the top left cor-
                                                                         0
                                                                                                                                 ner have better discrimination. Thus, the data trained on CAT
                                                                                       CAT                              DOG
                                                                                                   Training Condition
                                                                                                                                 is stronger for a range of feasible thresholds.
                                                                                                                                 Experiment 2: Face vs. Full-body
Figure 3: Categorization performance of S-P model for full                                                                       Quinn et al. (1993) ; Quinn et Eimas (1996) ; Quinn et al.
body images of CAT and DOG.                                                                                                      (2001) showed that shape or facial/head informations of cat
                                                                                                                                 and dog are sufficient for 3-4 month old infants to form cat-
                                                                                                                                 egorical representations that can discriminate based on full
                         1
                                                              Cat trained
                                                              Dog trained
                                                                                                                                 body images, but also demonstrates similar asymmetry. Ex-
                        0.8                                                                                                      periment 2 tests this, by training the model on face exemplars
   True Positive Rate
                        0.6                                                                                                      and testing on novel face images. When habituated on CAT,
                        0.4
                                                                                                                                 72.5% of novel category data (dogs) are preferred, whereas
                                                                                                                                 for DOG, only 40% for novel images are preferred (Fig. 5.a).
                        0.2
                                                                                                                                 In the next experiment, the training was on the face exemplars
                         0
                              0                                        0.2       0.4         0.6      0.8      1
                                                                                                                                 but the test image exemplars was novel full body exemplars.
                                                                             False Positive Rate                                 In this case the model was able to categorize 70% of the novel
                                                                                                                                 dogs and 55% of the novel cats accurately. The high catego-
Figure 4: (Left) True positive rate vs False positive rate,                                                                      rization accuracy in both experiments support the claim that
across all discriminating thresholds. The top left corner (0,1)                                                                  the head region provides signicant information for learning
implies perfect discrimination, and cat results are consistently                                                                 individuated category representations for cats and dog. Fur-
closer to it, hence better. (Right) A DOG image that has very                                                                    ther ramifications of this result, in a system without any prior
high acceptability in the CAT category.                                                                                          experiences for faces of any kind, are suggested in the con-
                                                                                                                                 clusion.
   The observed asymmetry in categorization performance for
the novel category implies that the model identifies DOG more                                                                    Experiment 3: Hierarchical categories
accurately after training on CAT, as compared to CAT after                                                                       When categories are organized in hierarchies, behavioral and
training on DOG. We also observe that high variability in                                                                        electrophysiological studies reveal that superordinate cate-
the dog category is indicated by some individuals who tend                                                                       gories are easier to learn (Quinn, 2004 ; Behl-Chadha, 1996 ;
to have greater acceptability in the cat category (lower con-                                                                    Quinn et al., 2006). We tested this result on images at the su-
ditional probability) than most cats (Fig. 4.b). On the whole,                                                                   perordinate level (CAR vs ANIMAL) and at basic level (CAT vs
this similarity to infant categorization results suggests that the                                                               DOG ). While the model was able to discriminate completely
model is able to capture the relevant attributes of infant visual                                                                at the upper level, at the basic level, only 50% of CAT and
learning.                                                                                                                        80% of DOG images are identified. (Fig. 5.b). This also tallies
   In order to consider the effect of the threshold, we com-                                                                     with the original results, thus suggesting that this computa-
pute the discrimination over all possible thresholds, from the                                                                   tional mechanism may be behaving similarly to some aspects
                                                                                                                              2524

of infant category learning.                                            60(2), 105 - 141.
                                                                      Bishop, C. M. (2007). Pattern recognition and machine
                         Conclusion                                     learning (1 éd.). Springer.
In this work we have shown that a computational model, orig-          Cat-dog database. (2011). (IITK Vision Group : http://
inally constructed based on the feedforward behaviour of the            www.cse.iitk.ac.in/˜vision/)
primate visual cortex, is able to replicate the infant visual re-     Daptardar, S. (2009). Explorations on a neurologically plau-
sponse in several scenarios, working directly on image data as          sible model of image object classification. Masters disserta-
opposed to hand-computed features. This procedure enables               tion, Dept CSE, IIT Kanpur. (code: http://code.google
a number of avenues for further testing of many other aspects           .com/p/object-classification-experiments/)
of infant (and adult) learning from image data. It also lends         Levy, R. (2008). Expectation-based syntactic comprehen-
further weight to the early suggestion that this asymmetry is           sion. Cognition, 106, 1126-1177.
due to a greater variation in the dogs than in cats.                  Mareschal, D., French, R. M., & Quinn, P. C. (2000). A
   The primary question we sought to answer is if the S-P               Connectionist Account of Asymmetric Category Learning
computational model exhibits behaviour similar to infant vi-            in Early Infancy. Developmental Psychology, 36(5), 635–
sual cognition, given that it was initially modeled on adult            645.
primates, albeit in a feedforward manner. The results of our          Perrett, M. W., D.and Hietanen J.K.and Oram, & Benson,
experiments appear to lend some support for this position,              P. J. (1992). Organization and functions of cells respon-
qualified by the absence of maturational and other aspects.             sive to faces in the temporal cortex. Philos. Trans. R. Soc.
   Another aspect on which the results may have some slight             London Ser., 335(1273)(1), 23–30.
bearing is the debate on whether the capability for face recog-       Quinn, P. C. (2004). Development of subordinate-level cat-
nition is innate. Though there is broad agreement that in-              egorization in 3- to 7-month-old infants. Child Develop-
fants have some degree of face preference at birth, whether             ment, 75, 886–899.
this is genetically encoded or not appears to be a matter of          Quinn, P. C., & Eimas, P. D. (1996). Perceptual Cues That
some debate (Johnson, 2001). The results of experiment 2                Permit Categorical Differentiation of Animal Species by
demonstrate the effectiveness of the face-only test in a sys-           Infants. Child Psychology, 6(1), 189 - 211.
tem which has absolutely no priors for faces. This suggests           Quinn, P. C., Eimas, P. D., & Rosenkrantz, S. L. (1993). Ev-
that faces may be recognized early as information rich visual           idence for representations of perceptually similar natural
elements, and hence attended to early on. This would result in          categories by 3-month-old and 4-month-old infants. Per-
face information being quickly assimilated into cortical struc-         ception, 22(4), 463–475.
tures. Thus, the experiment appears to indicate some degree           Quinn, P. C., Eimas, P. D., & Tarr, M. J. (2001). Percep-
of learnability for face competence.                                    tual Categorization of Cat and Dog Silhouettes by 3- to 4-
   More than the immediate relevance to these experiments on            Month-Old Infants. Child Psychology, 79(1), 78 - 94.
CAT - DOG asymmmetry, we feel that the technique presented            Quinn, P. C., Westerlund, A., & Nelson, C. A. (2006). Neural
here - the first end-to-end computational model to simulate             Markers of Categorization in 6-Month-Old Infants. Psy-
the visual behaviour of infants - may have broader implica-             chological Science, 17(1), 59-66.
tions. The capability for, and mechanisms of object recog-            Schlesinger, M., & Parisi, D. (2001). The Agent-Based Ap-
nition have a fundamental role in behaviour, and constructing           proach: A New Direction for Computational Models of De-
better models for it have not only improved our understanding           velopment. Developmental Review, 21(1), 121–146.
of cognition but also empowered a rich line of investigation          Serre, T., Kouh, M., Cadieu, C., Knoblich, U., Kreiman, G.,
in computational vision. Unlike earlier attempts at simulation          Poggio, T., et al. (2005). A theory of object recognition:
where the details of the visual processing had to be approxi-           Computations and circuits in the feedforward path of the
mated, now the internal mechanisms as posited by this model             ventral stream in primate visual cortex (Rapport technique
can be assessed for its relevance to a wide range of visual de-         No CBCL-259). MIT.
velopmental phenomena. Thus although this computational               Serre, T., Wolf, L., Bileschi, S., Riesenhuber, M., & Pog-
simulation holds considerable interest per se, the future value         gio, T. (2007). Robust object recognition with cortex-like
of this work may lie in the possibility of increasingly realistic       mechanisms. IEEE Tr. on Pattern Ana. and Mac. Int., 29,
simulation of developmental visual phenomena.                           411–426.
                                                                      Serre, T., Wolf, L., & Poggio, T. (2005). Object recognition
                      Acknowledgments                                   with features inspired by visual cortex. CVPR’05 -Volume
   We are thankful for help received from Sourabh Daptardar             02, 994–1000.
regarding running the C++ version of the S-P algorithm coded          Tanaka, K. (1996). Inferotemporal cortex and object vision.
by him.                                                                 Annual review of neuroscience, 19(1), 109–139.
                                                                      Wattam-Bell, J. (1991). Development of motion-specific cor-
                         References                                     tical responses in infancy. Vision Research, 31(2), 287 -
Behl-Chadha, G. (1996). Basic-level and superordinate-                  297.
   like categorical representations in early infancy. Cognition,
                                                                  2525

