UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Robot gaze does not reflexively cue human attention
Permalink
https://escholarship.org/uc/item/3pq1v9b0
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Admoni, Henny
Bank, Caroline
Tan, Joshua
et al.
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                             Robot gaze does not reflexively cue human attention
                    Henny Admoni, Caroline Bank, Joshua Tan, Mariya Toneva and Brian Scassellati
                                               Department of Computer Science, Yale University
                                                51 Prospect Street, New Haven, CT 06511 USA
                                  henny@cs.yale.edu, caroline.bank@yale.edu, joshua.tan@aya.yale.edu,
                                                   mariya.toneva@yale.edu, scaz@cs.yale.edu
                                Abstract                                   seems to be an early and reflexive skill for humans: children
   Joint visual attention is a critical aspect of typical human inter-     as young as three months old attend more quickly to a periph-
   actions. Psychophysics experiments indicate that people ex-             eral probe on cued trials than on uncued trials when the cue
   hibit strong reflexive attention shifts in the direction of another     is a human face (Hood, Willen, & Driver, 1998).
   person’s gaze, but not in the direction of non-social cues such
   as arrows. In this experiment, we ask whether robot gaze elicits           When cues are counterpredictive of probe location, how-
   the same reflexive cueing effect as human gaze. We consider             ever, social stimuli such as faces and eyes elicit different pat-
   two robots, Zeno and Keepon, to establish whether differences
   in cueing depend on level of robot anthropomorphism. Us-                terns of behavior than other directional stimuli. In counter-
   ing psychophysics methods for measuring attention by analyz-            predictive cueing paradigms, probes appear with significantly
   ing time to identification of a visual probe, we compare atten-         higher probability opposite the location cued by centrally-
   tion shifts elicited by five directional stimuli: a photograph of
   a human face, a line drawing of a human face, Zeno’s gaze,              located stimuli (Driver et al., 1999). For example, when the
   Keepon’s gaze and an arrow. Results indicate that all stimuli           centrally-located stimulus is directed toward the left, probes
   convey directional information, but that robots fail to elicit at-      have a 75% chance of appearing to the right of center, and
   tentional cueing effects that are evoked by non-robot stimuli,
   regardless of robot anthropomorphism.                                   vice versa. In counterpredictive experiments, it is beneficial
                                                                           for participants to orient attention away from the cued di-
                           Introduction                                    rection; therefore, shorter response times to probes in cued
Joint visual attention is an important aspect of typical so-               directions are attributed to reflexive or uncontrollable atten-
cial interactions. A single gaze communicates information—                 tion shifts. In contrast, shorter response times to probes
there are predators hiding behind that tree; a tasty source                in uncued (but predicted) locations are interpreted as voli-
of food is over there; you are crossing into my territory—                 tional orienting of attention. Counterpredictive experiments
and supports social conventions such as conversational turn-               reveal that participants reflexively orient in the direction of
taking and joint referencing. As robots become more inte-                  eyes (Driver et al., 1999) but volitionally orient away from
grated into daily human life, social interactions occur with               the direction of arrows (Friesen, Ristic, & Kingstone, 2004)
increasing frequency between humans and robots, as well:                   or extended tongues (Downing et al., 2004). A stimulus that is
robots assist nurses in hospitals, act as companions for the               ambiguously social will elicit reflexive attention shifts when
elderly, and interact with children in schools and in therapy.             presented to participants as a social cue (a picture of eyes),
In this paper, we investigate whether people are responsive to             but not when presented as a non-social cue (a picture of a
joint attention cues from robots. We focus on one aspect of                car) (Ristic & Kingstone, 2005). Furthermore, the effect of
joint attention: recognizing the direction of another person’s             this cue on reflexive attention persists if the cue is presented
gaze and shifting one’s own attention in that direction.                   first as social and then as non-social, but not vice versa. This
   Evidence from psychophysics suggests that typical humans                reflexive cueing effect seems strongest for faces, but not nec-
readily shift their attention in response to a directional cue,            essarily unique to them: arrows have also been shown to trig-
such as averted eyes or an arrow. In traditional non-predictive            ger reflexive orienting, with magnitude of reflexive orienting
cueing experiments, participants view a centrally-presented                toward arrow cues positively correlated with individuals’ vol-
stimulus followed by a peripherally-presented visual probe,                untary attention control (Tipples, 2008), suggesting that dis-
and press a keyboard key in response to the probe. Key                     similarities in attention directed at eyes and arrows are differ-
press response times are theoretically correlated with atten-              ences of magnitude (strong versus weak), rather than of kind
tion: participants will respond more quickly to probes located             (reflexive versus volitional).
in the direction to which they are already attending. Studies                 Eye-tracking and brain-imaging studies reveal similar re-
have found that when the stimulus contains directional infor-              sults. People make more erroneous eye saccades in the di-
mation (such as a face with averted eyes, or an arrow point-               rection of a “distracter” cue they are told to ignore if that cue
ing in one direction), people respond more quickly to probes               is a face, rather than an arrow (Ricciardelli, Bricolo, Agli-
at cued locations, in which the probe is on the same side as               oti, & Chelazzi, 2002). Functional MRI studies show that
indicated by the stimulus, than to probes at uncued locations,             the same cue activates different neural pathways depending
even when they are told that the cue does not indicate probe               on whether it is perceived as eyes or as a non-social direc-
location and should be ignored (Downing, Dodds, & Bray,                    tional image (Kingstone, Tipper, Ristic, & Ngan, 2004). At-
2004; Driver et al., 1999; Friesen & Kingstone, 1998; Lang-                tentional orienting to gaze cues and to arrow cues activates
ton & Bruce, 1999). Attention shifting via directional cue                 different cortical networks, with attentional orienting to arrow
                                                                       1983

cues relying on a pathway associated with voluntary shifts          gaze, with attendant reflexive shifts of attention in the gaze
of attention (Hietanen, Nummenmaa, Nyman, Parkkola, &               direction? Or will robots be perceived by humans as non-
Hämäläinen, 2006). In a different fMRI study, however, the       social entities, such as arrows or cars, allowing participants
same cue activated the same extensive cortical network re-          to override reflexive attention shifts in favor of volitional ori-
gardless of whether it was interpreted as an eye or an ar-          enting toward predicted probe locations? Because robots are
rowhead, though the eye cue more strongly engaged some              designed with varying levels of anthropomorphism, we use
parts of this network (Tipper, Handy, Giesbrecht, & King-           two robot stimuli, one from a very human-like robot called
stone, 2008).                                                       Zeno, and one from a less anthropomorphic robot named
   Psychologists have suggested that shared attention is a          Keepon. Cueing effects from human faces have been found to
precursor to developing a theory of mind for other people,          be stronger for schematic faces than for real faces (Hietanen
and that lacking ability to interpret others’ visual attention      & Leppänen, 2003), suggesting that cueing information con-
might indicate social disorders such as autism (Baron-Cohen,        tained in schematic faces is overshadowed by the complexity
1995). Children with autism fail to show preferential sen-          of real faces. For this reason, we also use two types of human
sitivity to socially relevant cues such as human gaze: they         face stimuli: a photograph of a human face and a line draw-
demonstrate similar response times to both arrows and faces         ing of a face. Finally, we use an arrow as a non-social but
on a counterpredictive cueing task (whereas typically devel-        directional stimulus.
oping children are cued by faces but not by arrows) (Senju,
Tojo, Dairoku, & Hasegawa, 2004), and they avoid shifting                                        Methods
their gaze in response to non-predictive gaze cues (Ristic et       This experiment employs two commercially available robot
al., 2005). Participants’ scores on the Autism-Spectrum Quo-        platforms. Zeno is produced by Hanson Robotics as a realis-
tient have also been negatively correlated with reflexive gaze      tic, expressive robot (Figure 1(c)). In addition to eyes and a
cueing magnitude (Bayliss, Pellegrino, & Tipper, 2005).             nose, Zeno’s face has human-like features such as eyebrows,
   In summary, evidence suggests that for non-predictive            lower eyelids, an expressive mouth, and hair. In contrast,
cues, both social and non-social directional stimuli elicit re-     Keepon’s features are less human-like (Figure 1(d)). Devel-
flexive attention shifts in cued directions, but that for coun-     oped by Hideki Kozima, Keepon is a 20 cm tall robot made of
terpredictive cues, socially relevant stimuli (such as human        two stacked yellow spheres of deformable rubber; its eyes are
faces) continue to elicit reflexive attention shifts while non-     white circles overlapped by smaller, concentric black circles
social directional stimuli, such as arrows, exhibit weak or no      and its nose is a black circle. Keepon’s deformable body and
reflexive attentional influence. This paper applies the psy-        eyes with sclera suggest biological features, but its form and
chophysical methods used to isolate attention shifts for faces      color (bright yellow) clearly indicate that it is robotic. The
and arrows to novel stimuli to inform the field of human-robot      aim of selecting such different robots is to identify whether
interactions (HRI). HRI is interested in how people perceive        human-like features are necessary to evoke the same (purport-
robots and how designers can create robots that interact nat-       edly social) response as to a human face.
urally with people. To date, there has been little research on         Participants were 41 male and 29 female Yale University
the cognitive effects of robots on human attention. As the          students between the ages of 18 and 34 (mean age 21.4). Each
presence of robots in day-to-day social situations increases,       participant was assigned to a single stimulus condition (hu-
however, it becomes important to evaluate robots’ cognitive         man, line drawing, Zeno, Keepon, or arrow). Participants
influence to better understand the roles robots can perform         were recruited in person or with flyers around campus, and
and to improve designs of human-assistive robots.                   were rewarded with candy at the end of the experiment.
   Some evidence suggests that robots can use gaze cues to
“leak” information to humans. In conversations between              Stimuli
robots and human participants, robots were able to define           The human gaze stimulus is a head-and-neck photograph of
participants’ roles (addressee, bystander, or eavesdropper)         a woman (Figure 1(a)). Her head subtends a visual angle of
through visual attention cues (Mutlu, Shiwa, Kanda, Ishig-          6.2 ◦ horizontally. Each eye subtends 1.0 ◦ and the center of
uro, & Hagita, 2009). Another study found that robots can           each eye is 1.2 ◦ to the right or left of center. This stimulus
influence people’s decisions in a game by shifting their eyes       was chosen as a social analogue to photographs of the robots.
briefly to a target, even when participants do not report see-         The line drawing stimulus, re-created from Friesen et al.
ing those cues (Mutlu, Yamaoka, Kanda, Ishiguro, & Hagita,          (2004), is a black-and-white line drawing of a face with cir-
2009). In the latter study, robot appearance influenced the ef-     cular eyes and nose, and a line for the mouth (Figure 1(b)).
fectiveness of gaze cues: Geminoid, a very human-like robot,        The head subtends 7.5 ◦ ; each eye subtends 1.0 ◦ and its center
was more effective at revealing intentions through gaze cues        is 1.0 ◦ left or right of image center, where the nose is located.
than Robovie, a robot with more abstract human features.            This stimulus has been previously shown to elicit both reflex-
   In this paper, we ask: will robots be treated like humans        ive and volitional shifts of attention (Friesen et al., 2004).
or like arrows? That is, will robot gaze be interpreted by hu-         Zeno is example of a highly anthropomorphic robot (Fig-
mans’ cognitive systems as a social cue on par with human           ure 1(c)). The Zeno stimulus is a head-and-neck photograph
                                                                1984

                     (a) Human gaze stimulus
                   (b) Line-drawn face stimulus
                                                                       Figure 2: Time course for a single (predicted) trial of the
                                                                       Keepon gaze condition. Setup is similar for other stimuli and
                                                                       gaze directions.
                      (c) Zeno gaze stimulus
                     (d) Keepon gaze stimulus
                                                                       Figure 3: Three types of trials were presented: cued, in which
                                                                       probe and gaze are congruent; predicted, in which probe loca-
                                                                       tion is opposite to gaze direction; and not-predicted-not-cued
                        (e) Arrow stimulus
                                                                       or NPNC, in which probe is on a different axis than gaze.
                                                                       Percentages indicate probability of occurrence.
Figure 1: Each subject was assigned to one of five stimulus
conditions. This figure shows the front, right, up and down
versions of each stimulus; left versions are mirrors of right-         the stimulus image. Each probe letter was 0.9 ◦ tall and wide,
facing versions and are omitted here for brevity.                      and was presented along the midline 4.8 ◦ from center. Cue
                                                                       and probe remained on screen until participants responded by
                                                                       pressing a keyboard key or until 2 seconds elapsed. (See Fig-
of the robot, with face subtending 6.7 ◦ horizontally (7.8 ◦ in-       ure 2 for an example.)
cluding hair) and each 1.0 ◦ eye located 1.3 ◦ to the left or             Following Friesen et al. (2004), for each trial of the cue-
right of center. Keepon is a less anthropomorphic robot (Fig-          ing condition, the probe had a 75% chance of appearing on
ure 1(d)). The Keepon stimulus is a full-body photograph of            the opposite (predicted) side of where the cue directed, and a
the robot, subtending 6.2 ◦ horizontally, with each 1.0 ◦ eye          25% chance of appearing in one of the other three locations
located 1.75 ◦ to the left and right of center.                        (approximately 8% chance each)—on the same side as where
   The arrow stimulus is 7.1 ◦ long and drawn over a 6.2 ◦ fixa-       the cue directed (cued), or orthogonal to the direction of the
tion cross; equal amounts of visual information are presented          cue (not-predicted-not-cued or NPNC), as shown in Figure 3.
at the head and tail of the arrow, thereby avoiding the pos-              Once participants responded to the probe or 2 seconds
sibility that cueing results simply from additional features in        elapsed, all images were replaced by a prompt asking par-
the cued direction (Figure 1(e)).                                      ticipants to press any key to proceed to the next trial.
   Each stimulus had left-, right-, up- and down-facing vari-
ants (see Figure 1). In a single trial of the cueing condition,        Procedure
the front-facing variant was presented for 500 milliseconds,           Participants were seated approximately 60 cm in front of a 29
followed by one of the other (“turned”) variants. After a 400          cm by 18 cm laptop screen. They were told which stimulus
millisecond SOA (or a 600 millisecond SOA in human and                 they would observe and the sequence of images they would
Zeno conditions), a probe letter, either “T” or “L,” appeared          see during the experiment (as in Figure 2). Participants were
on the screen either above, below, to the left, or to the right of     told they would first observe a front-facing stimulus, replaced
                                                                   1985

      Stimulus     Trial type    Avg. RT (ms)     SD     N
      Human        cued              444           46
                   predicted         428           54   15
                   NPNC              462           61
      Line         cued              458           73
                   predicted         449           73   16
                   NPNC              474           70
      Zeno         cued              473          147
                   predicted         452          108   13
                   NPNC              473          116
      Keepon       cued              464           65
                   predicted         428           52   14
                   NPNC              469           55
      Arrow        cued              453           66
                   predicted         433           44   12
                   NPNC              461           53
Table 1: Average response times and standard deviations, in
milliseconds, for all participants (rounded to the nearest mil-
lisecond). Each row represents a stimulus condition separated         Figure 4: Mean response times in milliseconds for each trial
into trial types. The last column indicates the number of par-        type and stimulus condition. A single asterisk indicates sig-
ticipants in each condition.                                          nificant differences (p < 0.05), a double asterisk indicates
                                                                      borderline significant differences (p < 0.10).
by a “turned” stimulus, then a probe letter (“T” or “L”). They
were also informed that the probe was three times more likely         between-subjects variable and trial type (cued, predicted and
to appear on the side opposite where the gaze or symbol di-           NPNC) as the within-subjects variable revealed significant
rected. Participants were asked to press the keyboard key of          main effects for trial type (F(2, 130) = 19.819, p < 0.001)
the letter appearing on the screen as quickly and accurately          though not for stimulus condition (F(4, 65) = 0.196, p =
as possible. These instructions were also presented textually         0.939). There was no interaction between stimulus type and
on the screen before the start of the experiment. Key press           trial type (F(8, 130) = .673, p = 0.703).
response times were recorded for analysis.                               Because there was a significant main effect of trial type,
   All participants saw 99 trials, consisting of 96 test trials       we further analyzed the data within each stimulus condition
and 3 additional practice trials drawn at random from the test        with a repeated measures analysis of variance on trial type,
trials and presented first. The set of test trials comprised 72       which found significant main effects for trial type on most
predicted trials (the probe appeared opposite where the cue           conditions (human: F(2, 28) = 3.675, p = 0.038; line draw-
indicated), 8 cued trials (the probe appeared on the side in-         ing: F(2, 30) = 4.328, p = 0.022; Zeno: F(2, 26) = 3.409,
dicated by the cue), and 16 NPNC trials (the probe appeared           p = 0.048; Keepon: F(2, 26) = 13.558, p < 0.001), and
on a different axis than the one directed by the cue), with “T”       borderline significance main effects in the arrow condition
and “L” presented equally frequently.                                 (F(2, 22) = 2.672, p = 0.091). In all conditions, pairwise
                                                                      comparisons reveal that each stimulus elicited significantly
                            Results                                   faster response times to predicted than to NPNC trials (hu-
Mean response times and standard deviations are listed by             man: mean difference = 33.921, sd = 8.764, p = 0.002; line
condition and trial type in Table 1. Figure 4 shows mean              drawing: mean difference = 24.892, sd = 5.902, p = 0.001;
response times by stimulus condition and trial type.                  Zeno: mean difference = 24.515, sd = 8.335, p = 0.011;
   Data from four participants were excluded for non-                 Keepon: mean difference = 39.878, sd = 9.410, p = 0.001;
compliance (not following directions to respond as quickly            arrow: mean difference = 27.875, sd = 11.120, p = 0.029).
as possible, or pressing keys at random as evidenced by high          Only in the robot conditions, however, were there significant
error rates). Trials in which participants incorrectly identi-        or borderline-significant differences between predicted and
fied probe letters, response times exceeded 1.5 seconds, or           cued trials as well (Zeno: mean difference = 23.746, sd =
response times were less than 100 ms were treated as errors           12.712, p = 0.084; Keepon: mean difference = 36.698, sd =
and excluded from analysis. The error rate was 3.9% for ana-          8.613, p = 0.001).
lyzed data. In total, results from 70 particpants across the five
conditions were analyzed, as shown in Table 1.                                                 Discussion
   A repeated measures analysis of variance with stimulus             Results suggest that participants recognized the directional
type (human, line drawing, Zeno, Keepon, and arrow) as the            significance of all stimuli, but only responded to the cueing
                                                                  1986

significance of non-robot stimuli. Though they were able to          than common directional symbols or social entities.
extract directional information from robot gaze, participants           Previous studies (e.g., Friesen et al., 2004; Tipples, 2008)
in either robot condition were not susceptible to reflexively        use a similar counterpredictive experimental design in which
reorienting in the direction of robot gaze, in contrast to par-      participants are asked to press a key when any probe ap-
ticipants in face and arrow conditions.                              pears. This detection task elicits covert attention shifts, in
   Response times were statistically faster for predicted tri-       which participants’ eyes do not move (in fact, Friesen et al.
als than for baseline NPNC trials in all stimulus conditions,        (2004) tracked several participants’ eyes to ensure that they
which indicates that participants directed their attention to-       did not shift). The task in the current experiment requires
ward predicted locations—where they expected a stimulus to           identifying probes (either “T” or “L”) by pressing correspond-
appear—more than toward not-predicted not-cued (NPNC)                ing keyboard keys, so results from this identification task are
locations. For robot stimuli (Zeno and Keepon), response             not directly comparable to results from previous detection-
times were also statistically faster for predicted than for cued     based experiments. It would be interesting, however, to ana-
trials (borderline significance in the Zeno case, p = 0.084).        lyze covert attention effects of various robots using detection
In other words, participants directed their attention signifi-       tasks. Some robotics studies (e.g., Mutlu, Yamaoka, et al.,
cantly more quickly toward predicted locations than toward           2009; Mutlu, Shiwa, et al., 2009) suggest that highly anthro-
cued locations, and thus show no evidence of having been             pomorphic robots are more successful than less anthropomor-
cued by robot gaze: participants in robot conditions attended        phic robots at conveying intentions through gaze, suggesting
to cued locations just as infrequently as NPNC locations that        that robot anthropomorphism influences covert attention.
were neither cued nor predicted. In contrast, response times            Attentional cueing is more pronounced with schematic
were not significantly different between predicted and cued          drawings of faces than with real faces (Hietanen & Leppänen,
trials in the non-robot conditions (human face, line drawing         2003), so this study included both a photograph of a hu-
of a face, and arrow). Participants in these conditions were         man face and a line drawing of a face as stimuli. Both
not significantly more attentive to predicted than to cued lo-       faces elicited significantly faster responses to predicted ver-
cations; in fact, Figure 4 shows that cued trial response times      sus NPNC trials, but not to predicted versus cued trials.
were, on average, greater than predicted trial response times        Though the arrow stimulus also showed this effect statis-
but less than NPNC trial response times. This suggests that          tically, differences between NPNC and cued trial response
non-robot stimuli attracted participants’ reflexive attention to     times are larger for the two social stimuli, with 17.183 ms
cued locations despite the fact that participants were no more       average difference for the human face, and 16.140 ms aver-
motivated to look at cued locations than at NPNC locations.          age difference for the line drawing, compared with 7.548 ms
   This counterpredictive cueing task involved four possible         average difference for the arrow.
probe locations on each trial: a cued location, in the direction        Some stimuli were tested at 400 ms SOA (line drawing, ar-
of gaze or pointing; a predicted location, opposite the cued         row, and Keepon) while others were tested at a 600 ms SOA.
location, where participants were told probes were likely to         This represents a methodological change undertaken partway
appear; and two not-predicted not-cued locations (NPNC),             through the experiment, in order to align more precisely with
which have the same probability of probes appearing at each          previous research. Both SOA times are within the thresh-
of them as at the cued location. NPNC trials provide a good          old for “short” SOAs as described by Friesen et al. (2004),
baseline because they involve an identical task (responding to       and reflexive cueing effects have been found at up to 600 ms
a probe with a key press) but do not represent cued or pre-          SOAs (Friesen et al., 2004; Tipples, 2008). Therefore, we
dicted locations. In this study, participants were significantly     believe these SOAs to be comparable.
faster at responding to probes at predicted locations than at           This study provides some of the first insight into cognitive
NPNC locations for every stimulus, revealing that they rec-          processing of robot stimuli, using psychophysical techniques
ognized the direction indicated by the stimulus and used that        common in cognitive psychology but largely unused in the
to inform them of predicted probe position.                          field of human-robot interaction (HRI). There is significant
   In contrast, participants in both robot conditions were also      information to be gained from analyzing the cognitive effects
significantly faster at responding to probes at predicted loca-      of robots on human attention, both for cognitive scientists in-
tions than those at cued locations. In essence, participants         terested in which features cue attention, and robot designers
seem to be ignoring the natural interpretation of robot gaze         interested in creating robots that engage in natural social in-
in favor of the counterpredictive interpretation demanded            teractions with people. Robot stimuli provide a “real life”
by the task. This behavior has been observed in children             testbed for cognitive attention experiments by allowing re-
with autism, who are able to ignore non-predictive gaze              searchers to manipulate robotic features to test theories about
cues, while their typically-developing peers are susceptible         what features cue reflexive attention. Robot designers can
to reflexive cueing from non-predictive stimuli (Ristic et al.,      use this information in their designs, which would improve
2005). The fact that robots do not seem to cue reflexive at-         robot usability by allowing people to employ the same social
tention, in a way that even non-social stimuli such as arrows        cues with robots as they do with other humans. The current
do, suggests that robots are cognitively processed differently       study suggests that these two robots, Zeno and Keepon, are
                                                                 1987

unable to cue human attention in this task the way real faces,          Baron-Cohen, S. (1999). Gaze perception triggers reflexive
schematic faces, or even arrows do. These results should be             visuospatial orienting. Visual Cognition, 6(5), 509–540.
further explored to identify what kinds of visual manipula-           Friesen, C. K., & Kingstone, A. (1998). The eyes have it!
tions can make robots appear reflexively social.                        Reflexive orienting is triggered by nonpredictive gaze. Psy-
                                                                        chonomic Bulletin and Review, 5(3), 490–495.
                        Conclusions                                   Friesen, C. K., Ristic, J., & Kingstone, A. (2004). Attentional
Human eyes elicit strong attentional shifts in the direction            effects of counterpredictive gaze and arrow cues. Journal
of their gaze, even when this shift is detrimental to view-             of Experimental Psychology: Human Perception and Per-
ers’ goals, while non-social directional cues such as arrows            formance, 30(2), 319–329.
have demonstrated weaker attentional cueing effects. Little           Hietanen, J. K., & Leppänen, J. M. (2003, December). Does
evidence currently exists for the cognitive effects of robot            facial expression affect attention orienting by gaze direc-
gaze cues, however. Using an established counterpredictive              tion cues? Journal of Experimental Psychology: Human
cueing experiment, we analyzed the attentional influence of             Perception and Performance, 29(6), 1228–1243.
two robots that vary in level of anthropomorphism, and com-           Hietanen, J. K., Nummenmaa, L., Nyman, M. J., Parkkola,
pared our findings to attentional effects of human faces and            R., & Hämäläinen, H. (2006). Automatic attention orient-
arrows. Results indicate that all of the stimuli conveyed di-           ing by social and symbolic cues activates different neural
rectional information to participants, but that neither robot           networks: An fMRI study. NeuroImage, 33, 406–413.
stimulus evoked reflexive attentional cueing, though all non-         Hood, B. M., Willen, J. D., & Driver, J. (1998, March).
robot stimuli elicited this effect. These findings suggest that         Adult’s eyes trigger shifts of visual attention in human in-
when participants are motivated to look away from a directed            fants. Psychological Science, 9(2).
location, common directional symbols still engage an auto-            Kingstone, A., Tipper, C., Ristic, J., & Ngan, E. (2004). The
matic attention shift to the directed location, while robots do         eyes have it!: An fMRI investigation. Brain and Cognition,
not. This paper is among the first to apply psychophysical              55, 269–271.
techniques to the analysis of cognitive effects of robot ap-          Langton, S. R. H., & Bruce, V. (1999). Reflexive visual
pearance, and further experimentation using these techniques            orienting in response to the social attention of others. Visual
might reveal what features influence natural social responses           Cognition, 6(5), 541–567.
from people, and may help robot designers who are interested          Mutlu, B., Shiwa, T., Kanda, T., Ishiguro, H., & Hagita,
in creating social robots.                                              N. (2009, March). Footing in human-robot conversations:
                                                                        How robots might shape participant roles using gaze cues.
                    Acknowledgments                                     In Human robot interactions (HRI’09) (pp. 61–68). La
                                                                        Jolla, California, USA: ACM.
Thank you to Brian Scholl, Lisa Brandes, Brad Hayes, Tay-             Mutlu, B., Yamaoka, F., Kanda, T., Ishiguro, H., & Hagita,
lor Brown and Anna Blazejowskyj for help in devising, con-              N. (2009, March). Nonverbal leakage in robots: Com-
ducting, and presenting this research. This work is supported           munication of intentions through seemingly unintentional
by NSF awards #0835767 (Understanding Regulation of Vi-                 behavior. In Human robot interactions (HRI’09). La Jolla,
sual Attention in Autism through Robots and Human Social                California, USA: ACM.
Development) and #0968538 (Modeling Agency and Inten-                 Ricciardelli, P., Bricolo, E., Aglioti, S. M., & Chelazzi, L.
tions in Dynamic Environments as a Precursor to Efficient               (2002, December). My eyes want to look where your eyes
Human-Computer Interaction), the DARPA Computer Sci-                    are looking: Exploring the tendency to imitate another in-
ence Futures II program, Microsoft and the Sloan Foundation.            dividual’s gaze. NeuroReport, 13(17), 2259–2264.
This work was made possible through a software grant from             Ristic, J., & Kingstone, A. (2005). Taking control of reflexive
QNX Software Systems Ltd and hardware grants by Ugobe                   social attention. Cognition, 94, B55–B65.
Inc. The first author is supported by an NSF Graduate Re-             Ristic, J., Mottron, L., Friesen, C. K., Iarocci, G., Burack,
search Fellowship.                                                      J. A., & Kingstone, A. (2005). Eyes are special but not for
                                                                        everyone: The case of autism. Cognitive Brain Research,
                         References
                                                                        24, 715–718. (Short communication)
Baron-Cohen, S. (1995). Mindblindness: An essay on autism             Senju, A., Tojo, Y., Dairoku, H., & Hasegawa, T. (2004,
   and theory of mind. Cambridge, MA: MIT Press.                        March). Reflexive orienting in response to eye gaze and
Bayliss, A. P., Pellegrino, G. di, & Tipper, S. P. (2005).              an arrow in children with and without autism. Journal of
   Sex differences in eye gaze and symbolic cueing of atten-            Child Psychology and Psychiatry, 45(3), 445–458.
   tion. The Quarterly Journal of Experimental Psychology,            Tipper, C. M., Handy, T. C., Giesbrecht, B., & Kingstone, A.
   58A(4), 631–650.                                                     (2008). Brain responses to biological relevance. Journal of
Downing, P. E., Dodds, C. M., & Bray, D. (2004). Why does               Cognitive Neuroscience, 20(5), 879–891.
   the gaze of others direct visual attention. Visual Cognition,      Tipples, J. (2008). Orienting to counterpredictive gaze and
   11(1), 71–79.                                                        arrow cues. Perception and Psychophysics, 70(1), 77–87.
Driver, J., Davis, G., Ricciardelli, P., Kidd, P., Maxwell, E., &
                                                                  1988

