UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning near-optimal search in a minimal explore/exploit task
Permalink
https://escholarship.org/uc/item/1536g0xd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Sang, Ke
Todd, Peter
Goldstone, Robert
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                   Learning near-optimal search in a minimal explore/exploit task
             Ke Sang (kesang@indiana.edu), Peter M. Todd (pmtodd), Robert L. Goldstone (rgoldsto)
               Cognitive Science Program and Department of Psychological and Brain Sciences, Indiana University
                                           1101 E. 10th Street, Bloomington, IN 47405 USA
                              Abstract                                    The same tradeoff between exploiting what you already
   How well do people search an environment for non-depleting
                                                                       have and exploring further to find something preferable
   resources of different quality, where it is necessary to switch     applies to humans. For instance, should you take the parking
   between exploring for new resources and exploiting those            space you have just found or keep driving closer to your
   already found? Employing a simple card selection task to            destination hoping to find a better one? Should you stick
   study exploitation and exploration, we find that the total          with your current job, or partner, or brand of coffee, or
   resources accrued, the number of switches between exploring         explore further to see if there are better options to be found?
   and exploiting, and the number of trials until stable                  Many researchers have focused on aspects of exploration
   exploitation becomes more similar to those of the optimal
   strategy as experience increases across searches. Subjects          versus exploitation. Optimal decision mechanisms and
   learned to adjust their effective (implicit) thresholds for         heuristic rules of thumb have been proposed to model when
   exploitation toward the optimal threshold over 30 searches.         animals leave patches to find new ones (Charnov, 1976;
   Those implicit thresholds decrease over turns within each           Bell, 1991; Livoreil & Giraldeau, 1997; Wajnberg,
   search, just as the optimal threshold does, but subjects’           Fauvegue, & Pons, 2000). Mathematicians have studied
   explicitly stated exploitation threshold increases over turns.      optimal stopping problems where the task is to decide when
   Nonetheless, both the explicit and learned implicit thresholds
                                                                       to stop the exploration phase of search and exploit a
   produced performance close to optimal.
                                                                       particular chosen option; Ferguson (1989) reviews work on
   Keywords: exploration; exploitation; explore/exploit tradeoff;      one well-known form of this task, the so-called Secretary
   optimal search; threshold strategy.                                 Problem. Todd and Miller (1999) applied this kind of
                                                                       framework to the problem of searching for a mate, studying
                         Introduction                                  the simple heuristics that could work well to stop
Search is a ubiquitous requirement of everyday life.                   exploratory search once an appropriate partner was
Scientists need to search for information to help their                encountered, and Beckage, Todd, Penke, and Asendorpf
research; web users use search engines like Google to get              (2009) found evidence of use of such rules by people
whatever they are interested in from the internet; companies           searching for mates at speed-dating events. Lee (2006)
search for the best candidates for their job openings;                 developed Hierarchical Bayesian models to account for
consumers searching in supermarkets with hundreds of                   human decision making on an optimal stopping problem.
brands of candies have to decide if they have found one that              Different resource types and environmental structures call
is good enough or if they should explore to find something             for different search strategies. Thus, how well humans
even tastier.                                                          perform in experiments involving the exploration/
   In many real life situations, to search (or explore) or to          exploitation tradeoff depends on the task details, which
stop searching (and exploit the fruits of the search) is a key         influence not only optimal search strategies, but also the
issue for making better decisions. Organisms have to make              actual strategies employed by subjects. In this paper we
tradeoffs between exploration and exploitation so as to                focus on search behavior in a resource-accumulation setting,
improve their success in the environment. Consider a                   in which individuals make a series of decisions as to
honeybee searching for nectar in flowers. Suppose the                  whether to explore to find a new resource or exploit a
honeybee has visited a particular plant and found most of              previously-encountered one, accumulating value from both
the nectar in its flowers. The bee must decide whether it is           newly-found and previously-discovered, currently-exploited
worth spending more time to find still more nectar on this             resources as they search.
plant, exploiting it further, or whether it would be better off
leaving this plant and exploring to look for another. Staying                                  Search Task
too long on the flowers of this plant is wasteful, and the bee         In the experiment, individuals had to accrue as many points
should move to another plant with higher initial rate of               from cards as possible over a 20-turn game. At each turn, a
nectar supply; however, leaving that initial flower plant too          subject could either explore by flipping over a card with
early is also suboptimal because travelling between resource           unknown points from a card deck, or exploit a card already
patches will cost time and energy, and there is uncertainty            uncovered by selecting it from a computer screen. With this
about the resource levels of flowers that have not yet been            accumulation of resources (e.g. points) during both
visited. To maximize intake of nectar, the bee needs a                 exploration and exploitation and the ability to return to
decision rule that balances exploration of new resource sites          previously-found items, this search task resembles a non-
with exploitation of known resource sites (Charnov, 1976).             competitive foraging task with non-depleting resources.
                                                                   2800

   Note that these task settings differ from the classic                             100
Secretary Problem and the widely studied patch-foraging
                                                                                     90
problem. Compared to the Secretary Problem, individuals in
                                                                                     80
our experiment have knowledge of the outcome distribution
(card values are uniformly distributed from 1 to 99). They                           70
can switch from exploitation back to exploration (even                               60
                                                                        Card Value
though this is never done by the optimal strategy), whereas                          50
the Secretary Problem involves searching (exploring) until a                         40
single option is chosen (exploited). Individuals are also able                       30
to go back and exploit previous items, and they receive                              20
points in both exploration and exploitation phases, whereas                          10
the Secretary Problem payoff is determined solely by the                              0
final choice made. In a typical patch-foraging problem,                                    2   4   6    8   10
                                                                                                             Turn
                                                                                                                    12   14   16   18   20
foragers usually do not know the distribution of resources in
                                                                        Figure 1: Optimal threshold curve. Over turns, the
patches, exploring between patches has costs, and exploiting
                                                                   optimal threshold for exploiting the highest drawn card falls
a patch makes its value go down over time (depleting
                                                                            from about 80 on turn 1 to 50 on turn 20.
resources), so that foragers usually do go back and exploit
previously-found patches even though they could.
   Many possible rules could describe subjects’ behavior in                                            Experiment
our search task. These include intertia-based rules (subjects      191 subjects were recruited for the experiment from the
have a tendency to repeat the previous action, be it               Indiana University psychology student subject pool. They
exploration or exploitation), impatience-based rules (after        were told that their goal was to accumulate as many points
some number of turns doing one action, individuals lose            as possible in each search game, by flipping over cards
patience and switch to the alternative action), and threshold      whenever they wanted or taking the points from cards
rules (switch from explore to exploit when a value above a         already exposed on the screen. Subjects were also informed
particular threshold is found). We focus here on threshold         that the point values for cards ranged from 1 to 99, with
rules, in part because that is the form of the optimal strategy.   equal probability (i.e., card values were uniformly
                                                                   distributed between 1 and 99), selected with replacement.
                    Optimal Strategy                                  In the experiment, a turn refers to one time of either
To judge how well subjects perform, it is useful to                exploration or exploitation, and every trial contains 20 turns.
understand the optimal strategy for the given task settings in     The interface for the experiment is shown in Figure 2. Every
                                                                   card had its value displayed on it. In the first of the 20 turns,
our experiment. The optimal strategy is to use a decreasing
threshold, switching from exploration to exploitation              the subject must explore, flipping over the top card on the
whenever the best card seen so far exceeds the current             deck. After seeing its value and having that added to their
threshold level. According to the optimal strategy, the            accumulating points, subjects could do either of two actions
decreasing threshold curve only depends on the range of            on the second turn (and all subsequent turns): select a new
card values (highest and lowest) and the total number of           card from the deck (exploring), or select one of the cards
turns in one search game.                                          that he/she had already turned over (exploiting). The screen
   Let H denote the highest possible value for a card, L           displayed the number of turns taken, the total points
denote the lowest possible value, N denote the total number        obtained thus far for this trial, and the highest card value
of turns in one game, n denote the current turn within the         seen so far in the trial (by showing that card’s point value in
game, and dn denote the optimal threshold value for the nth        red on the card, while all other cards were shown in green).
turn.                                                                 For example, in Figure 2, four cards have been taken from
  Also let:                                                        the card deck, with the first three values in green while the
  A = (N−n)∙(H2+H),                                                highest card value, 91, is in a larger red font. The screen
  B = (H+L)∙(H−L+1),                                               shows that the number of turns taken thus far is 15, there are
  C = (N−n)∙(2H+1) + 2(H−L+1),                                     5 turns left, and the total points so far for this trial is 1245.
                                                                   The number of points received by the subject on each turn in
                                                                   this trial is also listed beside the deck. On this 16th turn, the
                                                                   subject should decide whether he/she wants to exploit the
  then dn =
                                                                   highest value 91 again, as they have done for the previous
                                                                   12 turns, or explore the deck hoping for a higher card value.
  What would the threshold curve look like? In our                    After each of the 30 independent trials, subjects were told
experiment, H=99, L=1, and N=20. The threshold curve for           the points they received and the points that the optimal
these values is plotted in Figure 1.                               strategy would have earned. After finishing all 30 trials,
                                                                   subjects reported their explicit threshold—the minimum
                                                                   value of the maximum card seen so far that would lead them
                                                               2801

to exploit that value rather than explore by flipping over a        distributions of these starting-final-exploitation turns for
new card from the deck, for turns 2, 5, 9, 13, 17, and 20.          both the actual data and the optimal strategy. Compared to
                                                                    the optimal strategy, the distribution of the actual data has a
                                                                    long fat tail, which means that some subjects explored even
                                                                    until the very end and did not exploit a high value when
                                                                    they found it (which is likely—if someone explores for 10
                                                                    turns, the probability that he/she will see a value larger than
                                                                    80 is about 90%).
                                                                                            Starting Turns for Subjects                       Starting Turns for Optimal Strategy
                                                                                     1200                                                  1200
                                                                                     1000                                                  1000
                                                                                     800                                                    800
                                                                         Frequency                                             Frequency
                                                                                     600                                                    600
                                                                                     400                                                    400
  Figure 2: The interface of the experiment. The face-down
card in the lower-left corner represents the deck of unknown                         200                                                    200
cards, while the four cards in the upper portion of the screen
                                                                                       0                                                      0
                 represent turned-over cards.                                                 5       10
                                                                                                      Turn
                                                                                                               15         20                        5       10
                                                                                                                                                            Turn
                                                                                                                                                                     15       20
                          Results
                                                                          Figure 3: Frequency distributions of starting turns for
Across all of the turns taken by all subjects (191∙30∙20 =              final exploitation phase, for subjects (left) and optimal
114600 turns), there was 73.3% exploitation and 26.7%                                       strategy (right).
exploration. For the optimal strategy, there is more
exploitation: 81%. Subjects’ mean total points per 20-turn          Explicit and Implicit Thresholds
trial was 1528 (SD 266); for optimal, it was 1601.
                                                                    At the end of the experiment, we asked subjects to declare
                                                                    the minimum card value that they would have been satisfied
Switch and Exploitation
                                                                    with, and hence stop exploring and instead exploit this card
The optimal strategy dictates that there would be at most           for the rest of the turns. We asked them to disclose this
one switch from exploration to exploitation per 20 turn             value for turns 2, 5, 9, 13, 17, and 20. These values can be
trial—whenever the highest card seen so far exceeds the             treated as indicating subjects’ explicit thresholds; they are
current threshold level. Subjects, by contrast, might switch        plotted in Figure 4, linearly interpolated. Generally speaking,
back from exploitation to exploration for many reasons,             this is an increasing curve, which moves in the opposite
including intrinsic randomness, boredom, or changing                direction of the optimal threshold over turns.
strategies over time. And then as the end of the trial                 At the individual level, we categorized subjects into four
approaches, they may well switch to exploitation again to           different types according to the trends of their explicit
take advantage of previously found high values. The data            thresholds. If the reported thresholds at those 6 turns
indicates that subjects switch between exploration and              remained the same, subjects were classified as ‘Constant’; if
exploitation a mean of 1.83 times per trial.                        the values increased at least once and never decreased,
   In general, after some point subjects switch to                  subjects were classified as ‘Increasing’; if the values
exploitation and only exploit for the rest of the turns until       decreased at least once and never increased, subjects were
the end of the trial. The turn where this continuing                classified as ‘Decreasing’; otherwise, they were labeled as
exploitation begins depends on the search strategy used. For        ‘Mixed’. Among 188 subjects (3 were excluded due to
example, a strategy with a constant threshold of 90 would           incomplete questionnaires), 71 subjects were Increasing, 47
lead to a later mean switch point than the optimal strategy         were Decreasing, 19 were Constant, and 51 were Mixed.
does, because cards exceeding this high threshold are less          Not only is the general trend of the mean explicit threshold
common than cards exceeding the decreasing optimal                  increasing over turns, but there are also far more subjects
threshold. The mean of the starting turn for this continuing        classified as individually ‘Increasing’ than ‘Decreasing’.
exploitation is 7.35 across all subjects. We also simulated            As mentioned above, we focus on the threshold rule that
data for the same number (191*30 = 5730) of trials                  subjects may use. In addition to subjects’ explicit thresholds,
following the optimal strategy, and found the mean starting         we also analyzed the implicit thresholds that underlie their
turn for continuing exploitation to be 5.14. Accordingly,           actual actions in the experiment. To estimate subjects’
people continue exploring for longer than optimal, but only         implicit thresholds, one way is to treat the implicit
by about two turns. Figure 3 shows the frequency                    thresholds at different turns as parameters of cognitive
                                                                 2802

models and use the maximum likelihood estimation (MLE)                                   Threshold Performances
method to estimate them. Here we propose two models,                                     The explicit, implicit, and optimal thresholds show
both of which have a stepwise threshold. The reason for
                                                                                         considerable differences, with the first increasing over turns,
using stepwise rather than continuous threshold models is
                                                                                         while the implicit and optimal decrease. Moreover, in
that we want the estimates of the implicit thresholds to
                                                                                         Figure 4, most parts of the implicit threshold are below the
match up with the 6 separate explicitly reported thresholds.
   Model A has 6 parameters, each representing a part of a                               optimal. How do these differences in threshold values play
stepwise threshold. Let Ti (1≤i≤6) be the 6 parameters; then                             out in terms of actual search performance? Does the
T1-T6 respectively represent the thresholds that apply across                            explicitly stated threshold work better than the implicit
turns 1-2, 3-5, 6-9, 10-13, 14-17 and 18-20. For each of                                 threshold derived from subjects’ actual choices, and how do
these ranges of turns and corresponding Ti the model is:                                 both compare with the optimal strategy?
                                                                                            To answer these questions, first we linearly interpolated
                                                                                         the explicit and implicit thresholds between the 6 known
                                                                                         data points (turns 2, 5, 9, 13, 17, and 20) to obtain threshold
Pr(explore) is the probability of exploration on the current
turn, Max is the highest card value seen (on the table) before                           values for all 19 turns (2-20), as shown in Figure 4. Then we
the current turn, and Ti has a range from 1 to 99.                                       performed 100,000 simulation runs for each of the three
   Model B is nested with Model A, but has another free                                  thresholds. The frequency distributions of performance
parameter, the sensitivity parameter s. It is a positive value                           (points per trial) for each are shown in Figure 5. All three
that reflects how strongly the subject follows this threshold                            distributions are negatively skewed. The frequency
rule—if s is large, then subjects usually make a choice that                             distribution of the implicit threshold is slightly more similar
is consistent with the threshold Ti, and if s is small, there can                        to that of the optimal strategy than is the explicit distribution,
be a lot of randomness in the subject’s choices. The model                               but all three are very similar. The mean and median of
at each step for Ti is:                                                                  performance following the optimal strategy are 1601 and
                                                                                         1635; for the implicit threshold, 1595 and 1621; and for the
                                                                                         explicit threshold, 1592 and 1603. The mean of subjects’
   We used MLE to estimate parameter values of the two                                   actual performance on each trial, 1528, is a little farther
models for each individual. To select the model describing                               away from the optimal performance, perhaps because of
the data better, the Bayesian Information Criterion (BIC)                                noise in subjects’ choices or their use of different rules.
                                                                                                                    4                                                 4                                                  4
                                                                                                                 x 10                                              x 10                                               x 10
was used to compare models. Because most of the                                                             3                                                 3                                                  3
parameter estimations are negatively skewed, here we chose                                                 2.5                                               2.5                                                2.5
the median, rather than mean, of the index BICm of each
model (Busemeyer & Stout, 2002). The model with smaller                                                     2                                                 2                                                  2
BICm is preferred. The results show that 2*BICModelA = 335.6,
                                                                                               Frequency                                         Frequency                                          Frequency
                                                                                                           1.5                                               1.5                                                1.5
and 2*BICModelB = 316.8. Hence Model B is selected to
estimate the 6 threshold parameters and the parameter s.                                                    1                                                 1                                                  1
   Because the parameter distributions are skewed, the                                                     0.5                                               0.5                                                0.5
median is used to represent their central tendency. The
median of s is 0.13. Medians of implicit threshold                                                          0
                                                                                                            500      1000       1500      2000
                                                                                                                                                              0
                                                                                                                                                              500      1000       1500       2000
                                                                                                                                                                                                                 0
                                                                                                                                                                                                                 500      1000      1500        2000
                                                                                                             Performance of Optimal Threshold                  Performance of Implicit Threshold                  Performance of Explicit Threshold
parameters are shown Figure 4. The implicit threshold curve
is decreasing over turns.
                                                                                             Figure 5: Frequency Distributions of Performance (Points
                     100
                                                                           optimal           Earned) by the Optimal, Implicit, and Explicit Thresholds.
                     90                                                    implicit
                                                                           explicit
                     80                                                                  Learning Effects
                     70
                                                                                         Although subjects do not know or follow exactly the
                     60
                                                                                         optimal strategy, their implicit and explicit thresholds
        Card Value
                     50                                                                  perform quite well—considering the noise in the actual data,
                     40                                                                  these thresholds achieve impressively close to optimal
                     30                                                                  results. How does this happen? Are subjects consistent in
                     20                                                                  their performance across the 30 trials, or do they learn and
                     10                                                                  improve based on the feedback provided after each trial?
                      0
                                                                                            To find out, we divided subjects’ data into three parts
                           2   4   6   8   10
                                                Turn
                                                       12   14   16   18       20
                                                                                         according to trials. Data from the first trial to the 10th trial
                                                                                         form the first part (F); the middle 10 trials are the second
      Figure 4: Explicit, implicit, and optimal thresholds.                              part (M); and the last 10 trials are the third part (L). Across
                                                                                      2803

the three parts, we analyzed number of switches per trial,                                     combined all subjects’ data of each subset together, and
the turn number on which continuing exploitation                                               treated them as if they came from only one subject. s in
commenced, and actual performance; these measures are                                          Model B is a parameter of individuals’ sensitivity. Given
shown in Table 1. Clearly, all three measures improved                                         that all subjects’ trials are combined together in each subset,
from the first to the last 10 trials, all coming closer to the                                 the s in each section should be the same. In other words, it is
optimal strategy. The frequency distributions of the starting                                  no longer necessary to include this parameter s. Therefore
turn of continuing exploitation of the three parts are shown                                   instead of using Model B, Model A was selected to estimate
in Figure 6 along with the optimal threshold’s distribution.                                   the implicit threshold for each section.
Again over trials, the distribution becomes more similar to                                       The three implicit thresholds for the different trials are
the optimal one. Thus overall, learning occurs in terms of                                     plotted in Figure 7, together with the optimal threshold.
avoiding repeated switching between exploring and                                              Basically, after turn 6, the implicit threshold value at each
exploiting, and sticking to exploiting high-valued cards                                       turn becomes smaller as the experiment continues (going
earlier, yielding increasing performance as well.                                              from F to M to L). Overall, experience with the task leads
                                                                                               subjects to more robustly use turn number as a factor in
              Table 1: Learning effects across trials from F to L.                             determining their thresholds.
                                                                                                  For the first few turns, no matter which strategy someone
                             Number           Starting                    Performance          uses, it is very important to set threshold values high enough
                             of               turn of final                                    to achieve a good performance. Consider the optimal
                             switches         exploitation                                     strategy: the mean of the optimal threshold from turn 1 to
              F              2.57             8.77                        1492                 turn 5 is around 80. If you explore consecutively for 5 times,
              M              1.54             6.9                         1539                 the probability that you get at least one value higher than 80
              L              1.39             6.39                        1553                 among these 5 turns is about 70%. Most of time, this would
              Optimal        1                5.08                        1601                 let you achieve a good total score. But if you used a lower
                                                                                               threshold value in the beginning, this would harm the final
                      First 10 trials                               Middle 10 trials
                                                                                               score substantially. Subjects also appear to learn this over
            400                                           400                                  multiple trials from F to M and L, increasing their implicit
            300                                           300
                                                                                               thresholds before turn 5.
Frequency                                     Frequency
                                                                                                                  100
            200                                           200
                                                                                                                  90
            100                                           100
                                                                                                                  80
             0                                             0                                                      70
                  5       10        15   20                     5        10       15   20
                           Turn                                           Turn                                    60
                                                                                                     Card Value
                      Last 10 trials                                Optimal strategy
            400                                           400                                                     50
                                                                                                                  40
            300                                           300
Frequency                                     Frequency
                                                                                                                  30
            200                                           200                                                               optimal
                                                                                                                  20
                                                                                                                            first10Implicit
                                                                                                                            middle10Implicit
            100                                           100                                                     10
                                                                                                                            last10Implicit
                                                                                                                   0
             0                                             0                                                            2   4      6      8    10          12   14   16   18   20
                  5       10        15   20                     5        10       15   20
                                                                                                                                                    Turn
                           Turn                                           Turn
       Figure 6: Distributions of turn number on which                                             Figure 7: Implicit threshold curves found for the first,
 continuing exploitation commenced, changing over trials.                                          middle, and last trials across subjects (F, M, L), and the
Continued exploitation commences earlier as more trials are                                                            optimal threshold.
  completed, and come close to the optimal distribution.
                                                                                                  One interesting result is that after turn 5, implicit
   Finally, Model A was applied to each of the three parts of                                  threshold curves diverge from the optimal one, and more
the data to estimate the implicit threshold across subjects for                                strongly with more learning. Also surprisingly, the implicit
each of the ranges of trials. Because each subject only has                                    thresholds go below 50 in M and L by the final turns (and it
10 trials in each subset of the data, fewer data points can                                    should never be appropriate to set a threshold for exploiting
contribute to the modeling process, and if we tried to model                                   that is less than the mean value obtained from exploring,
implicit thresholds for subjects individually in these data                                    here 50). We think two possible reasons can account for
subsets, there would be many subjects that both Model A                                        these patterns. First, this could the result of noisy data
and Model B would not fit well. To solve this problem, we
                                                                                            2804

toward the end of each search trial. Given that subjects           exploit, and how that plays out across different search
switch from exploring to exploiting at some point as turns         settings, including information search on the Web, as well
go up, most of the data points at the end of turns involve         as priming effects between settings. Finally, different
exploiting a previously-found high value, rather than              populations may make the explore/exploit tradeoff in
exploring the deck, so there is little data about when             different ways, with some clinical populations emphasizing
subjects would be willing to explore late in each trial. To        one aspect of search over the other (Hills, 2006); fMRI
maximize the log likelihood, Model B prefers to lower the          could also be useful in exploring these differences, as well
corresponding threshold values as much as possible for             as giving insights into the neural mechanisms used in search
those final turns, which would cause the implicit thresholds       and whether they vary across different domains. By
to become quite low (if also unreliable). The second reason        stripping search down to a setting where exploration and
is that subjects may really learn rules that direct them to        exploitation are most prominent, these comparisons may
decrease the implicit threshold for the last several turns.        help us elucidate the underlying strategies more effectively.
These explanations will be tested in further experiments.
                                                                                       Acknowledgments
                         Conclusions                               We thank Ross Branscombe, Jerome R. Busemeyer, Woo-
The current paper addresses the issue of how people search         Young Ahn, and Thomas T. Hills for their help with this
an environment consisting of non-depleting resources by            research. We also acknowledge the support of National
choosing between exploration and exploitation. The results         Science Foundation REESE grant 0910218.
indicate that subjects perform close to optimally, and get
better over time with learning based on feedback. Subjects’                                 References
mean total points per trial, number of switches between            Beckage, N., Todd, P.M., Penke, L., and Asendorpf, J.B.
exploring and exploiting, and number of turns before                 (2009). Testing sequential patterns in human mate choice
starting continued exploitation become more similar to those         using speed dating. In Niels Taatgen and Hedderik van
of the optimal strategy as they go through more trials of            Rijn (Eds.), Proceedings of the 2009 Cognitive Science
searching. Subjects also appeared to adjust their implicit           Conference (pp. 2365-2370).
thresholds toward the optimal solution. The adjustment             Bell, W. J. (1991). Searching behaviour: The behavioural
leads to a final implicit threshold that achieved a cumulative       ecology of finding resources. New York: Chapman/Hall.
score quite close to the optimal one—even though that final        Busemeyer, J.R., & Stout, J.C. (2002). A contribution of
implicit threshold has a simple linear shape, quite different        cognitive decision models to clinical assessment:
from the accelerating falloff seen in the optimal threshold.         Decomposing performance on the Bechara gambling task.
It could be that the learning process is more adept at               Psychological Assessment, 14, 253-262.
constructing a simple linear rule of this form than what           Charnov, E.L. (1976). Optimal foraging: The marginal value
optimal performance calls for; however, in this setting at            theorem. Theoretical Population Biology, 9, 129–136.
least, performance hardly suffers as a consequence.                Ferguson, T.S. (1989). Who solved the secretary problem?
   However, subjects themselves did not correctly report             Statistical Science, 4(3), 282–296.
their use of a threshold that decreased over turns in each         Hills, T. T. (2006). Animal foraging and the evolution of
search trial: When asked to explicitly specify their                  goal-directed cognition. Cognitive Science, 30, 3–41.
thresholds, they stated ones that changed in the opposite          Lee, M. D. (2006). A hierarchical Bayesian model of human
direction of the implicit and optimal thresholds. This may           decision-making on an optimal stopping problem.
have been due to subjects with little introspective insight          Cognitive Science, 30, 555-580.
just proposing that their threshold should increase as the         Livoreil, B., & Giraldeau, L.-A. (1997). Patch departure
trials increase, without thinking much more about the                decisions by spice finches foraging singly or in groups.
problem. In short, subjects do not explicitly know what is           Animal Behavior, 54, 967–977.
optimal nor what they are actually doing, as is often found        Nisbett, R.E., & Wilson, T.D. (1977). Telling more than we
in decision making tasks (Nisbett & Wilson, 1977), but they          can       know:       Verbal     reports     on      mental
still get closer to optimal through a learning process.              processes. Psychological Review, 84, 231-259.
   There are several future directions that we are exploring.      Todd, P.M., & Miller, G.F. (1999). From pride and
In the current project, the resources are non-depleting, and         prejudice to persuasion: Satisficing in mate search. In G.
subjects have the ability to repeatedly shift between                Gigerenzer, P.M. Todd, and the ABC Research Group,
exploration and exploitation. But we can also use this setup         Simple heuristics that make us smart. New York: Oxford
to simulate depleting resources as in patch-based foraging           University Press.
and single choice searches with no recall as in the Secretary      Wajnberg, E., Fauvegue, X., & Pons, O. (2000). Patch
Problem, and investigate subjects’ ability to learn                  leaving decision rules and the marginal value theorem: An
appropriate strategies in those settings. We can also look           experimental analysis and a simulation model. Behavioral
for individual differences in tendency to explore versus             Ecology, 11, 577–586.
                                                               2805

