UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Account of Everyday Abductive Inference
Permalink
https://escholarship.org/uc/item/34n5277r
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Bridewell, Will
Langley, Pat
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                        A Computational Account of
                                       Everyday Abductive Inference
                             Will Bridewell                                        Pat Langley
              Center for Biomedical Informatics Research               Computing Science and Engineering
                Stanford University, Stanford, CA 94305           Arizona State University, Tempe, AZ 85287
                           Abstract                              These assumptions place important constraints on the
   In this paper, we review the main qualitative charac-         architecture’s account of conceptual inference. For in-
   teristics of everyday inference in human cognition and        stance, most reasoning is driven by observations of the
   present a computational account that is consistent with       world rather than by queries. Moreover, on each cycle
   them. This includes both a representational framework
   and associated processes that produce abductive expla-        Icarus must update beliefs in ways that incorporate re-
   nations in a flexible, incremental, and efficient manner.     cent inputs. Both constraints differ from those usually
   We clarify our approach with examples and report some         placed on computational treatments of reasoning.
   initial empirical results. In closing, we examine related
   work and suggest directions for future research.                 Although we have developed Icarus agents that op-
   Keywords: conceptual inference, abduction, plausible          erate in a variety of simulated environments and have
   inference, cognitive architecture                             shown their qualitative behavior is similar to humans’
                                                                 in many ways, the architecture’s inference module has
            Background and Motivation                            always been its weakest link. Although data-driven and
The ability to draw inferences from knowledge and ob-            automatic, its mechanisms for generating beliefs are im-
servations is one of the distinguishing features of human        plausible on a number of fronts. Two drawbacks are that
cognition. However, although people can, with some de-           it supports only deductive reasoning and that it works in
liberation, carry out the forms of deductive reasoning           an exhaustive manner. We intend the approach reported
associated with traditional logic, their inference often         in this paper to address these and other limitations.
appears to operate quite differently, in a spontaneous              In the next section, we review some qualitative charac-
and almost effortless fashion. Such reasoning underlies          teristics of everyday inference that our account should re-
much of our ability to understand language, but it also          flect. After this, we describe the representational and or-
supports many other aspects of human behavior. We                ganizational structures that our framework uses to sup-
will refer to this cognitive activity as everyday inference      port reasoning, and then present the mechanisms that
to distinguish it from deliberate deductive reasoning.           operate over them to produce beliefs. We clarify these
   In this paper, we present a novel computational ac-           processes with illustrative examples and discuss scenar-
count of such everyday inference. Following Cassimatis,          ios on which we have tested them empirically. We con-
Bello, and Langley (2008), our goal is not to match the          clude by discussing related research on plausible infer-
details of behavior in specific experimental studies, but        ence, noting limitations and directions for future work,
rather to offer a high-level explanation of this ability in      and summarizing our contributions.
humans that is consistent with all of its main qualita-
tive characteristics. This seems appropriate given that,            Characteristics of Everyday Inference
to our knowledge, no existing computational models sat-
isfy this basic criterion.                                       We should begin by describing the inference-related phe-
   We intend to embed our computational account of in-           nomena that we desire to explain. Again, our concern is
ference in Icarus, a theory of the human cognitive archi-        not with details like reaction time or error rate on specific
tecture that we have described at length elsewhere (e.g.,        tasks but with the broad characteristics that humans ex-
Langley, Choi, & Rogers, 2009). This framework in-               hibit in their everyday inference. We view these as simi-
cludes modules for conceptual inference, skill execution,        lar to what Newell and Simon (1976) refer to as ‘laws of
problem solving, and skill acquisition. We will not re-          qualitative structure’, in that they provide a framework
view Icarus in detail here, but we should recount three          within which to cast specific models. We will treat these
key assumptions relevant to the current work:                    characteristics as constraints on mechanisms that could
                                                                 support human-like abilities to understand incomplete,
 • humans always operate in some environment that                ambiguous information from complex environments.
    provides information about their situation;                   • Everyday inference deals with understanding or inter-
 • human cognition occurs over time, with each cycle                 preting experience. The primary aim is not to prove
    drawing on inference to guide skill execution and                that some statements follow from others, but rather
    problem solving; and                                             to make sense of observed facts and events. Like
 • the inference process combines environmental input                deduction, this process combines general rules with
    with conceptual knowledge to produce beliefs.                    specific beliefs to infer other beliefs, but everyday in-
                                                             2289

  ference has an explanatory character that attempts          Taken together, these characteristics of everyday infer-
  to connect observations into a coherent whole. This         ence suggest a model that differs radically from the usual
  suggests that everyday reasoning is abductive in na-        computational accounts of reasoning, which take their
  ture, since the acknowledged purpose of abduction is        inspiration from logical deduction. Earlier models of ab-
  to construct explanations (Peirce, 1878).                   ductive inference satisfy some constraints but not oth-
• Everyday inference relies on plausible reasoning, in        ers, indicating the need for a new approach. In the next
  that it does not depend on taking deductively valid         two sections, we present a computational model of every-
  steps which guarantee that the premises imply the           day reasoning that is consistent with all the constraints,
  conclusion. Rather, it draws conclusions about the          starting with its representational assumptions and then
  situation consistent with its general knowledge but         discussing the mechanisms that operate over them.
  not required by it. This feature lets humans make
  inferences unavailable to purely deductive reasoners.         Representations for Everyday Inference
• Everyday inference relies on flexible processing. Al-       As noted earlier, we intend our computational account of
  though people can utilize general rules of the sort         everyday inference to replace the current inference mod-
  identified with deductive reasoning, they apply these       ule in the Icarus architecture. The existing module
  rules in a fluid manner, chaining forward or backward       has clear drawbacks, but it also makes some represen-
  as needed. In this way, they can handle unpredictable       tational and organizational commitments that we wish
  inputs which may include some predicates that do            to retain. One such assumption is the clear distinction
  not appear in any rule consequents and others that          between generic concepts and concrete beliefs. Another
  do not appear in any antecedents. This fluid access to      is the hierarchical organization of conceptual knowledge.
  relevant knowledge lets humans reason in situations         A third supposition concerns the relational character of
  that confound unidirectional approaches to inference.       concepts and beliefs, which often describe environmental
• Everyday reasoning regularly makes default assump-          configurations among two or more entities.
  tions. This feature interacts with flexible operation          The new inference framework retains all these commit-
  by activating partially matched rules and enabling in-      ments. As in Icarus, conceptual knowledge takes the
  ference with incomplete information. The introduc-          form of Horn clauses that specify a generalized conse-
  tion of deductively unfounded but abductively use-          quent in terms of generalized antecedents. For instance,
  ful beliefs has many applications, one being inference      Table 1 shows a number of such conceptual rules related
  about others’ mental states—their beliefs, goals, and       to diseases and research projects. These rules are def-
  intentions. Such plausible assumptions support addi-        initional in the sense that an antecedent serves mainly
  tional inferences that can explain future observations.     as shorthand to summarize situations described by the
• Everyday inference typically involves constructing a        antecedents. However, as we will see, the logic-like nota-
  single explanation. Although abduction is often cast        tion does not mean that the inference mechanism must
  as search through a space of competing hypothe-             interpret the rules as deductive implications. It is a com-
  ses, in most cases humans generate a single account         mon misconception that logical formalisms can be used
  that covers most observations at hand. Even when            in only an inflexible, deductive manner.
  anomalies lead to belief revisions, people usually re-         As the example illustrates, conceptual rules take a
  tain one explanatory structure, rather than framing         relational form. The consequent involves a predicate
  alternatives and selecting one after evaluating them.       with associated arguments, whereas the antecedent is
• Everyday reasoning operates in an on-line, incremen-        a set of such structures. Terms like ?person and ?s1
  tal manner . Humans process new facts or observa-           are pattern-match variables that must bind to constants
  tions as they arrive, typically incorporating them into     during matching. The framework supports hierarchy by
  an existing account. Inference also has an anytime          letting predicates in the antecedent of some rules appear
  character, in that the reasoner produces at least shal-     in the consequents of others, much as in languages like
  low explanations rapidly, but can generate richer ones      Prolog. Beliefs take the form of instantiated literals that
  given additional time. Together, these suggest that         consist of a predicate and its constant arguments. The
  human reasoners incrementally refine and elaborate          framework assumes three types of belief: ones that come
  explanations as they process new information.               from external perception or communication, like those
• Everyday inference relies on very efficient operations.     in Table 2; ones inferred from a rule’s consequent; and
  Processing time appears unaffected by size of the           default assumptions based on a rule’s antecedents.
  knowledge base, suggesting a mechanism that relies             A third, albeit inherently transient, type of mental
  on local refinement in response to new results. These       structure is the rule instance. These objects take the
  features do not imply any guarantees of complete-           same form as generic conceptual rules but have domain
  ness. Many plausible inferences are never made, but         or Skolem constants in place of variables. Thus, rather
  those that are occur in an almost effortless manner.        than making general claims about the nature of the
                                                          2290

Table 1: Some conceptual rules that support everyday              Table 2: Initial observations driving an example of ev-
inference about illness.                                          eryday inference in the illness domain.
   (has-flu ?person) ⇐                                               1.  (member-of Ann muri-project)
        (has-symptom ?person ?s1) (fever ?s1)                        2.  (member-of Bob muri-project)
        (has-symptom ?person ?s2) (cough ?s2)
                                                                     3.  (has-symptom Ann s1)
   (has-food-poisoning ?person) ⇐
        (has-symptom ?person ?s1) (fever ?s1)                        4.  (fever s1)
        (has-symptom ?person ?s2) (vomiting ?s2)                     5.  (has-symptom Bob s2)
   (has-lung-cancer ?person) ⇐                                       6.  (cough s2)
        (has-symptom ?person ?s1) (cough ?s1)
        (has-symptom ?person ?s2) (yellow-teeth ?s2)
   (caught-flu ?person1 ?person2) ⇐
                                                                  cycle the inference mechanism has access to a set of be-
        (at-meetings ?person1 ?project) (has-flu ?person1)        liefs, some originating from outside as observed facts and
        (at-meetings ?person2 ?project) (has-flu ?person2)        others inferred on previous rounds. These literals con-
   (project ?project) ⇐                                           stitute the contents of the agent’s working memory. We
        (member-of ?person1 ?project)                             hypothesize that the inference process does not match
        (paid-from ?person1 ?project)
        (at-meetings ?person1 ?project)                           rules against all these elements, as in production-system
                                                                  frameworks like Soar (Laird et al., 1987), but that it se-
                                                                  lects one of them as the focus of cognitive attention.1 For
world, they make specific claims about a particular sit-          example, given the literals in Table 2, the system might
uation. Such rule instances serve as hypothetical con-            select (has-symptom Ann s1) as the current focus. For
nections among candidate beliefs, some of which do not            now, we will assume this choice is arbitrary, but later we
yet appear in short-term memory. These structures are             will consider ways to guide the selection process.
created, evaluated, and often discarded during inference.            Once AbRA has selected some literal L from work-
   The final type of mental element is the justification,         ing memory, it uses this element as an anchor to drive
which is a longer-lived variant of a rule instance. Simi-         rule instantiation and application. To this end, the sys-
larly, these structures contain literals that are grounded        tem finds all rules that have one or more antecedent or
with domain and Skolem constants but, in this case, they          consequent that unify with L. For instance, the has-flu,
serve to connect the beliefs that appear in them. In ef-          has-food-poisoning, and has-lung-cancer rules in Table 1
fect, justifications act as the glue that binds beliefs to        include the has-symptom predicate that unifies with the
each other, creating a supporting lattice of observations         focus. If a rule unifies with the focus literal in multiple
and assumptions. Notably, our framework does not dis-             ways, then AbRA considers each possibility. For each
tinguish between justifications that are valid deductions         candidate rule R, it also finds existing literals that are
from observations and those that involve assumptions.             identical, after bindings substitutions, with R’s other an-
   We can view the collection of beliefs, conceptual rules,       tecedents or consequents. For example, one can extend
and justifications as a tentative explanation for a collec-       the match of the has-flu rule to include the literal (fever
tion of facts. The resulting structure is a lattice of beliefs    s1), which is identical to the existing belief.
attached to the window of the world by observations. We              After the inference mechanism has found all rule in-
will see shortly that, as the explanation expands to cover        stances that connect with the current focus of attention,
more observations and increases its internal connectivity,        it selects one of these candidates. As before, we will as-
it becomes more cohesive and, hopefully, more coherent.           sume for now that this choice is arbitrary. AbRA applies
                                                                  the selected rule instance to carry out an inference step.
     Mechanisms for Everyday Inference
                                                                  This involves generating new literals for antecedents or
Now that we have described the structures on which ev-            consequents that do not exactly match existing beliefs
eryday inference is based, we can describe the mecha-             after the instantiation phase. When an antecedent or
nisms that operate over them. Recall that the purpose             consequent includes unbound variables, the system uses
of inference is not only to infer new beliefs from other          Skolem constants for those terms; if the same unbound
beliefs, but also to explain how they relate to each other.       variable appears in multiple rule elements, it uses the
Also remember that we are concerned with agents like              same Skolem for each occurrence. In our example, AbRA
humans that exist over time, observing a few facts and            infers three new beliefs—(has-flu Ann), (has-symptom
processing them before encountering additional ones.              Ann sk1), and (cough sk1)—only two of which include
Moreover, the inference process must support plausible,           Skolems. Note that some inferences correspond to an-
flexible reasoning in partially observable settings.              tecedents, while others relate to consequents.
   Our computational framework, which we call AbRA,
                                                                      1
posits that inference operates in cycles which alternate                This idea bears some resemblance to ACT-R’s (Anderson
                                                                  et al., 2004) reliance on buffers that hold single elements, but
between selecting a current belief on which to focus and          we have been influenced more by Cassimatis et al.’s (2010)
chaining off this belief through a rule instance. On each         Polyscheme, which controls inference in a similar manner.
                                                              2291

   Having selected a justification from the available can-     of varying value, we need ways to identify promising
didates, the inference system adds it to the growing ex-       ones. Although there is a growing movement to char-
planation. This step involves storing the justification,       acterize cognition as a statistical process, we hold that
adding new beliefs, and creating links that connect these      there are other psychologically plausible heuristics that
memory elements. New inferences become explicit be-            inform reasoning. These come into play when selecting
liefs in short-term memory, whereas justifications appear      a focus of attention and selecting a rule to chain off it.
as separate structures used primarily by heuristics that          Our current implementation uses two main heuris-
we discuss shortly. To this end, AbRA creates pointers         tics to guide the focus of attention. First, since AbRA
between each justification and beliefs that it supports.       works incrementally and assimilates new observations,
   After the system has generated one or more new beliefs      it prefers observations or inferred belief that are more
and their associated justifications, it continues the pro-     recent. Even though older beliefs can influence new in-
cess. On the next cycle, it selects another literal as the     ferences, they tend not to drive them. Second, we adapt
focus of attention, finds rules with antecedents or conse-     the idea of essential explanations (Fischer et al., 1991),
quents that unify with the focus, selects a rule instance      in that the system prefers beliefs that unify with fewer
to apply, and so on. This continues until the process can      rules in long-term memory. The intuition is that, given a
generate no other beliefs or until time runs out. Because      single candidate, rule selection is trivial and having fewer
AbRA assumes the agent operates in an external envi-           options means there are fewer wrong choices. Moreover,
ronment, literals that correspond to observations may          beliefs created by earlier inference steps provide a richer
enter memory on any cycle, providing material to drive         context for evaluating and deciding among later ones.
inference. In principle, it can reach a quiescent state in        Our abductive inference mechanism also incorporates
which no further inferences arise, but this will not occur     heuristics for selecting which rule instance to chain off
as long as novel content arrives from outside.                 the focal belief. The main technique is inspired by Tha-
   If the inference system operated entirely in the fash-      gard’s (2007) theory of explanatory coherence. After
ion just described, working memory would overflow with         finding all rule instances that unify with the current
Skolems, each representing some new object. For this           focus, AbRA scores these candidates in terms of the
reason, another mechanism flushes literals once their          average coherence of existing beliefs that match its an-
Skolems unify with domain constants. Returning to our          tecedent and consequents. We define a belief’s coherence
example, suppose AbRA has focused on (cough s2). Not           as the number of existing justifications that include it,
only would the rules for has-flu and has-lung-cancer ap-       plus a boost if it was observed rather than inferred.
ply, but so would the justification from the previous step,
                                                                  To illustrate this measure, consider the domain we in-
which yielded (cough sk1). Suppose the system chooses
                                                               troduced in Tables 1 and 2. Suppose AbRA focuses on
to unify the focus with this prior justification, produc-
                                                               (has-symptom Ann s1). The rules for (1) has-flu, (2)
ing the literals (has-symptom Ann s2) and (cough s2).
                                                               has-food-poisoning, and (3) has-lung-cancer are all po-
During this step, it recognizes that the new candidate
                                                               tential candidates. Each of these will create their own set
specializes an existing justification, which it then re-
                                                               of assumptions, such as (has-flu Ann), (cough sk), and
moves. Other justifications that supported the beliefs
                                                               (has-symptom Ann sk), where sk is a placeholder for a
(cough sk1) or (has-symptom Ann sk1) are then trans-
                                                               Skolem constant. However, instances (1) and (2) will
ferred to their more specific counterparts.
                                                               also include (fever s1), which is also a fact. If we award
   The mechanism we have just described incorporates
                                                               observations one point, then the instances (1) and (2)
all the constraints outlined earlier. The set of generated
                                                               will score 2/5 and (3) will score 1/5. Suppose the system
beliefs together with the justifications that link them
                                                               selects (1) as one of the best-scoring candidates. Then
constitute an explanation that indicates the system’s un-
                                                               during the next cycle, the beliefs (has-flu Ann), (has-
derstanding of the facts. The resulting inferences are not
                                                               symptom Ann sk), and (cough sk) will be worth one
deductively valid, but each reasoning step is nevertheless
                                                               point, whereas the other two beliefs will be worth two.
plausible. The process uses rules flexibly, chaining off
                                                               As beliefs become more connected, their scores increase,
either antecedents or consequents, and it introduces de-
                                                               which gives them more influence over time.
fault assumptions as necessary. Moreover, the approach
creates and extends a single explanation in an incremen-          Experience suggests that locally calculated coherence
tal manner that, because it relies on local computations,      is insufficient to reliably produce plausible explana-
is efficient and scalable.                                     tions. Often several candidate rule instances have similar
                                                               scores, especially during the initial stages of inference,
                                                               leading to ill-informed choices before various strands of
       Heuristics for Everyday Inference
                                                               an explanation are connected. In response, we intro-
The mechanisms described in the previous section rely          duced another heuristic which favors rule instances that
on heuristics to guide the decisions that drive infer-         are on a path that links the focus to other beliefs. This
ence. Since there are often many potential inferences          lookahead procedure starts by finding all rules that could
                                                           2292

match the focus. If they contain literals that might in         Table 3: Precision, recall, and accuracy scores on Mon-
turn unify with existing beliefs, then AbRA scores each         roe plan recognition corpus. Accuracy scores for Markov
such rule as if that second unification had occurred. Oth-      logic and Bayesian abductive logic are based on recall av-
erwise, it branches out through rules that might unify          eraged over 1000 cases, with credit awarded for partial
with other literals in that rule, recurring until connecting    matches (Raghavan & Mooney, 2010).
with an existing belief. The rule instance that chained
off the focus then receives the coherence score of the leaf                                     100%     75%    50%    25%
of that path. Ties are resolved by extending the process
up to a maximum depth. This method has consistently               AbRA (precision)               74%     74%    64%    64%
improved the plausibility of explanations.                        AbRA (recall)                  85%     74%    50%    29%
                                                                  AbRA (accuracy)                70%     53%    31%    11%
                  Empirical Results                               Markov logic networks          79%     37%    17%      7%
                                                                  Bayesian abductive logic       92%     57%    25%      9%
We have tested our approach to inference on a variety
of domains. One of the least complex involves the rules
in Table 1, which specify a folk theory of disease. Given          In summary, our computational model of inference re-
the six facts from Table 2, AbRA reliably generates an          liably produces plausible inferences in a number of do-
explanation that infers both Ann and Bob have the flu.          mains using mechanisms that are consistent with the
The reasoning involved is nontrivial, and earlier versions      constraints outlined earlier in the paper. This suggests
would infer different sets of diseases, sometimes assigning     the approach provides a reasonable qualitative account
multiple diseases to the same person. Introduction of           for the main features of everyday reasoning in humans.
the lookahead procedure coupled with the heuristic for
essential explanations stabilized the ability to generate                Related Research on Abduction
the most plausible solution.                                    Throughout this paper, we have cast everyday infer-
   Exploring AbRA’s behavior on more complex prob-              ence in the mold of abductive reasoning (Josephson &
lems required a larger set of domain rules. For this pur-       Josephson, 1996). This has been a relatively small
pose, we used Ng and Mooney’s (1992) knowledge base             but important area of cognitive science for nearly four
about a storytelling domain, stated as 107 rules for in-        decades. One of the earliest medical expert systems,
terpreting events like “Bill gave the bus driver a token”       INTERNIST-I, relied on specialized abductive mecha-
and “Bill went to a liquor store and pointed a gun at the       nisms (Miller et al., 1982). Later systems combined the
owner.” The number of observations per story varies,            representational power of predicate logic with a weighted
but each involves around ten literals. Whereas early            form of abduction, where assumptions incur a cost, with
versions of our system tended to confound events (e.g.,         applications including language understanding (Hobbs
inferring that Bill stopped at a restaurant before robbing      et al., 1993) and plan recognition (Appelt & Pollack,
the liquor store), the version with the stronger heuristics     1992). A number of more recent efforts have replaced
just described produce plausible, well supported beliefs        these weights with probabilities on rules and assump-
across several examples.                                        tions.2 For instance, Charniak and Goldman (1991) have
   We have also obtained preliminary results on plan            used Bayesian inference to carry out plan recognition,
recognition, where the system infers the plan that pro-         whereas Kate and Mooney (2009) have adapted Markov
duced a sequence of observed actions when given a hier-         logic and developed their own approach, Bayesian ab-
archical plan library and those actions. For this evalua-       ductive logic, for the same task.
tion, we selected 100 cases from the Monroe Plan Corpus            Most of these systems address the first four constraints
(Blaylock & Allen, 2005) and encoded the plan library           identified earlier, in that they generate explanations
as 50 rules, roughly one for each method. We measured           through plausible, flexible forms of reasoning that pro-
AbRA’s ability both to reconstruct the entire original          duce default assumptions when needed. However, they
plan and to recover the top-level literal (predicate and        all carry out extensive search through the space of ex-
arguments) that generated each sequence. To determine           planations, and thus violate the single-explanation con-
how early it can infer a plan during execution, we gave         straint. Moreover, they are invariably provided with all
AbRA the first 25%, 50%, 75%, and 100% of the trace.            observations at the outset, so they do not model the in-
Table 3 reports precision and recall on full plan recov-        cremental character of human abductive inference. In
ery for each percentage, along with accuracy on recov-          addition, because these methods carry out global eval-
ering the top-level plan. The table also presents results       uation of candidate explanations, their run times scale
from Raghavan and Mooney (2010) for Markov logic and            poorly with the size of the knowledge base and thus lack
Bayesian abductive logic programs. These are not di-                2
                                                                      Inference over Bayesian networks involves a form of ad-
rectly comparable, being based on a larger sample, but          buction, but this framework does not support the relational
they suggest the three approaches have similar abilities.       representations required for many reasoning tasks.
                                                            2293

the efficiency of human inference. In contrast, our ap-                               References
proach satisfies all seven constraints mentioned earlier.
   We should note that our focus on coherence rather           Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S.,
than on posterior probabilities has been influenced by           Lebiere, C., & Qin, Y. (2004). An integrated theory
two earlier efforts. Thagard’s (2007) model is guided by         of the mind. Psychological Review, 111, 1036–1060.
this metric, but it compiles candidate explanations into       Appelt, D. E., & Pollack, M. E. (1992). Weighted ab-
an influence network before evaluating them, so it does          duction for plan ascription. User Modeling and User-
not satisfy the constraint of incremental processing. Ng         Adapted Interaction, 2, 1–25.
and Mooney’s (1992) ACCEL system, which also uses a            Blaylock, B., & Allen, J. (2005). Generating artificial
form of coherence, operates incrementally, but it main-          corpora for plan recognition. Proceedings of the Tenth
tains multiple explanations rather than one account and          International Conference on User Modeling (pp. 179–
evaluates them globally rather than locally, which raises        188). Edinburgh: Springer.
concerns about efficiency.                                     Cassimatis, N. L., Bello, P., & Langley, P. (2008). Abil-
                                                                 ity, breadth and parsimony in computational mod-
               Concluding Remarks                                els of higher-order cognition. Cognitive Science, 32 ,
                                                                 1304–1322.
In this paper, we reviewed the main qualitative char-
                                                               Charniak, E., & Goldman, R. (1991). A probabilistic
acteristics of everyday human inference and proposed a
                                                                 model of plan recognition. Proceedings of the Confer-
computational account of this process. Our framework
                                                                 ence of the American Association for Artificial Intel-
includes a set of representational assumptions about con-
                                                                 ligence (pp. 160–165). Anaheim, CA: AAAI Press.
ceptual knowledge, beliefs, and justifications that relate
them. The account posits a control mechanism that al-          Fischer, O., Goel, A., Svirbely, J. R., & Smith, J. W.
ternates between selecting a belief on which to focus            (1991). The role of essential explanation in abduction.
cognitive attention and selecting a rule instance that           Artificial Intelligence in Medicine, 3, 181–191.
produces new beliefs. In addition, it includes heuristics      Hobbs, J. R., Stickel, M. E., Appelt, D. E., & Martin,
to guide selection of beliefs and rule instances in ways         P. (1993). Interpretation as abduction. Artificial In-
that drive inference toward coherent explanations. The           telligence, 63, 69–142.
framework supports a flexible form of plausible reason-        Kate, R. J., & Mooney, R. J. (2009). Probabilistic abduc-
ing that generates default assumptions; the mechanism            tion using Markov logic networks. Proceedings of the
incrementally extends a single explanation using local           Workshop on Plan, Activity, and Intent Recognition.
evaluation criteria that support efficient processing. To      Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987).
our knowledge, it is the first computational theory that         Soar: An architecture for general intelligence. Artifi-
is consistent with all of these key qualitative features of      cial Intelligence, 33 , 1–64.
everyday inference in humans.                                  Langley, P., Choi, D., & Rogers, S. (2009). Acquisition
   Nevertheless, our account remains incomplete in some          of hierarchical reactive skills in a unified cognitive ar-
important ways. The mechanisms cannot detect incon-              chitecture. Cognitive Systems Research, 10 , 316–332.
sistencies between previous beliefs and new facts or infer-    Miller, R. A., Pople, H. E. J., Myers, J. D. (1982).
ences, and they cannot revise beliefs in ways that repair        Internist-1: An experimental computer-based diagnos-
such problems. Neither can they operate over tempo-              tic consultant for general internal medicine. New Eng-
ral constraints that specify orderings on components of          land Journal of Medicine, 307, 468–476.
events. Most important, they cannot represent or reason        Newell, A., & Simon, H. A. (1976). Computer science as
about the beliefs, goals, and intentions of other agents,        empirical enquiry: Symbols and search. Communica-
which is required by many instances of natural language.         tions of the ACM , 19 , 113-126.
However, we believe the framework lends itself naturally       Ng, H. T., & Mooney, R. J. (1992). Abductive plan
to extensions that handle these challenges, and we are           recognition and diagnosis: A comprehensive empiri-
working actively to extend our mechanisms to address             cal evaluation. Proceedings of the Third International
them. The result will be a more complete account of              Conference on Principles of Knowledge Representa-
how everyday inference underlies human cognition.                tion and Reasoning (pp. 499–508). Cambridge, MA.
                                                               Peirce, C. S. (1878). Deduction, induction, and hypoth-
                 Acknowledgements                                esis. Popular Science Monthly, 13 , 470–482.
This material is based on research sponsored by ONR            Raghavan, S., & Mooney, R. J. (2010). Bayesian ab-
under agreement N00014-09-1-1029. The views and con-             ductive logic programs. Proceedings of the AAAI-10
clusions contained herein are the authors’ and should            Workshop on Statistical Relational AI (pp. 82–87).
not be interpreted as representing the official policies or    Thagard, P. (2007). Coherence, truth, and the develop-
endorsements of ONR or the U. S. Government, either              ment of scientific knowledge. Philosophy of Science,
expressed or implied.                                            74, 28–47.
                                                           2294

