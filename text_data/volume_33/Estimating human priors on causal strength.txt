UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Estimating human priors on causal strength
Permalink
https://escholarship.org/uc/item/7261z146
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Yeung, Saiwing
Griffiths, Thomas
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                   Estimating human priors on causal strength
                                                Saiwing Yeung (saiwing@berkeley.edu)
                                         Thomas L. Griffiths (tom griffiths@berkeley.edu)
                                      Department of Psychology, University of California, Berkeley
                                                       Berkeley, CA. 94720-1650 USA
                               Abstract                                 longer the probability that an agent selects a particular hy-
   Bayesian models of human causal induction rely on assump-
                                                                        pothesis converges to the prior probability of that hypothesis
   tions about people’s priors that have not been extensively           (Griffiths & Kalish, 2007). Simulating this process of iterated
   tested. We empirically estimated human priors on the strength        learning in the laboratory thus provides a way to estimate peo-
   of causal relationships using iterated learning, an experimen-       ple’s priors (Kalish et al., 2007). In fact, there is no need for
   tal method where people make inferences from data generated
   based on their own responses in previous trials. This method         data to be passed between people — we can just generate the
   produced a prior on causal strength that was quite different         data that people see on one trial based on their responses in a
   from priors previously proposed in the literature on causal          previous trial (Griffiths et al., 2008).
   induction. The predictions of Bayesian models using differ-
   ent priors were then compared against human judgments of                The plan for the rest of the paper is as follows. The
   strength of causal relationships. The empirical priors estimated     next section summarizes previous work on modeling human
   via iterated learning resulted in the best predictions.
   Keywords: Causal learning; Bayesian inference; Probabilistic         causal induction, focusing on analyses based on causal graph-
   judgment; Iterated learning                                          ical models. We then introduce the basic ideas behind iterated
                                                                        learning and present our experimental investigation of human
                           Introduction                                 priors on causal strength. Next we compare the predictions
Causal induction involves inferring the relationship between            produced by a model using the empirical priors with previous
causes and effects. This problem has attracted the attention of         models. Finally we conclude the paper by discussing the im-
cognitive scientists because it is an important skill that peo-         plications of these results for understanding causal induction.
ple rely on every day in order to understand the causal rela-
tionships in their environment. Traditionally, psychological                      Models of human causal induction
models of human causal induction have focused on various                The British philosopher David Hume pointed out that people
schemes for comparing the probability of an effect occurring            are not “able to comprehend any force or power by which the
in the presence and absence of a cause (e.g., Ward & Jenk-              cause operates, or any connexion between it and its supposed
ins, 1965; Cheng, 1997). However, recent work has explored              effect” (Hume, 1739/2004, p. 47), suggesting that causal rela-
connections between ideas from Bayesian statistics and hu-              tionships need to be inferred from the observed contingencies
man cognition, using causal graphical models to precisely               of cause and effect. A number of models have been proposed
define the problem of causal induction (Griffiths & Tenen-              to account for how this inference might be made, with the
baum, 2005; Lu, Yuille, Liljeholm, Cheng, & Holyoak, 2008)              goal of predicting human judgments about causal relation-
and to formalize the effects of prior knowledge (Griffiths &            ships from contingency data.
Tenenbaum, 2009). A key part of these Bayesian models is to
precisely specify the prior knowledge that people have about
                                                                        Models based on cause-effect probabilities
the strength of causal relationships. In previous models of             The ∆P model (Ward & Jenkins, 1965) proposed that human
human causal induction, priors on the strength of causal re-            make inferences about causal strength based on the contrast
lationships were specified in two ways — either as uniform              between P(e+ |c+ ) and P(e+ |c− ), where e and c represent the
priors by appealing to the principle of indifference (Griffiths         effect (or outcome) and cause, and superscripts of + and −
& Tenenbaum, 2005), or as generic priors based on assump-               represent their presence or absence. ∆P is formally expressed
tions about the abstract properties of the causal system (Lu et         as ∆P = P(e+ |c+ ) - P(e+ |c− ). It captures the intuition that a
al., 2008). In this paper, we present a new approach to esti-           cause is strong if it significantly increases the probability of
mating human priors on causal strength, using the method of             the outcome occurring relative to its base rate.
iterated learning (Kalish, Griffiths, & Lewandowsky, 2007;                 Cheng (1997) argued that ∆P was just a measure of co-
Griffiths, Christian, & Kalish, 2008).                                  variation and not one of causality. She further proposed the
   Iterated learning was originally proposed as a simple                theory of causal power, in which human judgments of causal
model of the cultural transmission of languages (Kirby,                 strength equals the probability of the cause in question pro-
2001). In this case, we imagine a chain of agents, where each           duces the effect in the absence of all other causes. For exam-
agent observes data generated by the previous agent (such as            ple, the power model for a generative cause can be expressed
                                                                                         ∆P
a set of utterances), forms a hypothesis about the process that         as power = 1−P(e  + |c− ) . The causal power model provided bet-
generated those data (such as a language), and then gener-              ter fit than ∆P for some human data. However, there have
ates new data to pass to the next agent. If the agents select           been debates about the lack of fit to human data for both mod-
hypotheses using Bayesian inference, then as the chain gets             els (see Buehner & Cheng, 1997; Lober & Shanks, 2000).
                                                                    1709

Models based on Bayesian statistics                                        where P(e|c; w0 , w1 ) is given by the noisy-OR or noisy-AND-
Griffiths and Tenenbaum (2005) proposed a Bayesian frame-                  NOT as above. We can thus compute a posterior distribution
work for studying causal induction. This framework uses                    over w0 and w1 given D by applying Bayes’ rule, with
causal graphical models to distinguish between causal struc-
ture – whether or not a link between two variables exists – and                         P(w0 , w1 |D) ∝ P(D|w0 , w1 )P(w0 , w1 )         (2)
causal strength – the strength of that relationship. Griffiths
                                                                           where P(w0 , w1 ) is the prior on w0 and w1 . Estimates of w0
and Tenenbaum gave a Bayesian account of learning causal
                                                                           and w1 can thenR be obtained by taking the posterior expecta-
structure. Lu et al. (2008) recently showed how this approach
                                                                           tion, with w̄i = 01 wi P(w0 , w1 |D) dwi for i ∈ 0, 1.
could be extended to infer causal strength.
   Causal graphical models are probabilistic models in which               Priors on causal strength
a graph is used to denote the causal relationships between                 In order to evaluate the posterior distribution in Equation 2,
variables (Pearl, 2000; Spirtes, Glymour, & Scheines, 2001).               or to integrate over causal strength to evaluate causal struc-
In the graph, nodes represent variables and edges represent                tures as in Griffiths and Tenenbaum (2005), the prior on the
the causal connection between those variables. Following                   causal strengths w0 and w1 needs to be specified. Griffiths
Griffiths and Tenenbaum (2005) and Lu et al. (2008), we fo-                and Tenenbaum assumed a uniform prior on both variables
cus on causal systems in which there are three variables: the              in their Bayesian structure learning model. However, Lu et
background cause B, the potential cause C, and the effect E.               al. (2008) argued that human reasoning are better approxi-
Assuming both B and C can cause E, this relationship can                   mated using a model that incorporated generic priors — a
be expressed in a graph in which there are edges going from                theoretically driven prior that makes systematic assumptions
both B and C to E. We assume B is always present and is                    about the abstract properties of a system. They argued that
generative, increasing the probability of the outcome, while               people have preference for causal models with fewer causes
C can be present or absent, and generative or preventive. We               (Lombrozo, 2007), and for causes that minimize complex
further assume that E cannot occur unless B or C caused it.                interactions (Novick & Cheng, 2004). Based on these ar-
Inferences are based on contingency data, which can be sum-                guments, they specified the sparse and strong (SS) prior as
marized in a 2 × 2 contingency table indicating the frequen-               P(w0 , w1 ) ∝ e−α(1+w0 −w1 ) + e−α(1−w0 +w1 ) in the generative
cies with which all combinations of the presence and absence               case and P(w0 , w1 ) ∝ e−α(1−w0 +1−w1 ) + e−α(1−w0 +w1 ) in the
of C and E co-occur.                                                       preventive case (Lu et al., 2008). α in the formulae is a free
   Although the graph structure specifies the causal relation-             parameter and is fixed at 5 in their analysis. In the gen-
ships among variables, the exact nature of those relation-                 erative case, this formulation gives higher prior probability
ships is not clear without specifying their functional form.               when one of the causes (B or C) is very strong and the other
Noisy-OR (for generative causes) and noisy-AND-NOT (for                    is very weak; in the preventive case, this formulation gives
preventive causes) parameterizations have been used to char-               higher prior probability when B is very strong and C is either
acterize the functional forms of causal relationships in pre-              very strong or very weak. Although Lu et al.’s model based
vious models of causal induction (Cheng, 1997; Griffiths                   on generic priors provided a good fit to human judgments in
& Tenenbaum, 2005). Each cause is assumed to have the                      their experiments, there are infinitely many possible priors on
power to cause (or prevent) the effect independently, doing                causal strength, of which this is just a single possibility.
so with a probability that reflects its strength. We denote
the strength of B and C as w0 and w1 respectively. The                         Using iterated learning to estimate human
noisy-OR gives the probability of observing the effect E as                                priors on causal strength
P(e+ |c; w0 , w1 ) = 1 − (1 − w0 )(1 − w1 )c where c is a binary
value representing the presence or absence of C, while the                 Previous work such as Lu et al.’s evaluated different propos-
noisy-AND-NOT gives P(e+ |c; w0 , w1 ) = w0 (1 − w1 )c .                   als about priors on causal strength by testing predictions of
   Having specified the full causal model, we can use this                 specific models implementing those priors. Here, we take a
model to infer the strength of B and C from the observed con-              different approach, using an experimental method based on
tingency data.1 These data indicate the frequency with which               iterated learning to directly estimate human priors on causal
cause and effect co-occur. We will use N(e, c) to denote the               strength. When used as a model of cultural transmission, iter-
number of cases falling into each cell of the contingency ta-              ated learning refers to a process in which a sequence of agents
ble, with e ranging over e+ and e− , and c ranging over c+ or              each learns from data generated by the previous agent. For-
c− . For any particular value of w0 and w1 , the probability of            mally, the n-th agent observes data d (n) and forms a hypothe-
the observed contingency data D is                                         sis h(n) about the process that generated those data, then goes
                                                                           on to generate the data d (n+1) which is given to the next agent.
              P(D|w0 , w1 ) = ∏ P(e|c; w0 , w1 )N(e,c)             (1)     This defines a Markov chain on hypothesis-data pairs. If the
                                e,c                                        agents select a hypothesis by sampling from the posterior dis-
    1 We focus on the problem of estimating causal strength, but the       tribution p(h|d) ∝ p(d|h)p(h) and then generate data by sam-
prior we estimate on causal strengths can also be used to infer causal     pling from the corresponding likelihood function p(d|h), then
structure (as in Griffiths & Tenenbaum, 2005; Lu et al., 2008).            this Markov chain is a Gibbs sampler for the joint distribution
                                                                       1710

p(d, h) = p(d|h)p(h). As n becomes large, the distribution
of (dn , hn ) converges to this joint distribution, and the prob-
ability that the nth learner selects a particular hypothesis h
converges to p(h) (for details, see Griffiths & Kalish, 2007).
   Convergence of iterated learning to the prior suggests that
it might be used as a method for empirically estimating hu-
man priors. Laboratory simulations of iterated learning, with
data being passed between people, support this idea: Func-
tions (Kalish et al., 2007) and concepts (Griffiths et al.,
2008) transmitted through iterated learning quickly converge
to forms that are consistent with priors established in previous
research. However, there is no need for data to be transmit-
ted between people for this to occur: A feedback process can
be established for a single individual that has the appropriate          Figure 1: Screenshot of the generative condition of the exper-
statistical structure, where people form hypotheses about data           iment. The participant is assessing the strength of the cause
that are generated based on their responses on previous tri-             C, w1 .
als. This kind of within-subjects design has previously been
used to explore people’s inductive biases in concept learn-              Participants then received instructions familiarizing them
ing, producing equivalent results to a between-subjects design           with the controls that they would use in the experiment. Each
(Griffiths et al., 2008). We now explore whether a similar ap-           trial (50 total) was presented on a separate screen (see Fig-
proach can identify people’s prior on causal strength.                   ure 1). In each trial participants saw data in the form of two
                                                                         samples, one that was not exposed to the protein (c− ) and
Methods                                                                  one that was (c+ ). The data were presented graphically us-
Participants. Participants were recruited from the Univer-               ing pictures that showed the total number of DNA strands in
sity of California, Berkeley, subject pool, and online (Ama-             each sample as well as the number that expressed the gene,
zon Mechanical Turk). Participants from the subject pool                 providing complete contingency data N(e, c).
received course credit, while online participants received a                After observing these contingencies, participants were
small payment. Only data from participants who completed at              asked to make two judgments involving hypothetical samples.
least 95% of the trials are included in the analysis. In the gen-        The instructions were:
erative condition, there were 20 and 52 participants from the               Suppose that there is a sample of 100 DNA strands and these
university subject pool and online respectively. In the preven-             strands were not exposed to the protein, in how many of them
tive condition, there were 33 and 51 participants from these                would the gene be turned on?
groups.                                                                     Suppose that there is a sample of 100 DNA strands and that
                                                                            the gene is currently off in all those DNA strands. If these
   Stimuli and Procedure. Following Lu et al. (2008), we                    100 strands were exposed to the protein, in how many of them
presented the experiment using a cover story of a bio-genetics              would the gene be turned on?
company testing the influence of proteins on the expression
                                                                         These questions were phrased to elicit judgments of w0 and
of genes. The experiment was run in a web browser. In the
                                                                         w1 , based on stimuli from previous research (e.g., Lu et al.,
generative condition, participants were told:
                                                                         2008). Participants responded using a slider. Live feedback
   In this experiment, please imagine that you are a researcher          showing the proportion of expressed genes was shown as the
   working for a bio-technology company and you are studying             slider was moved. Participants could adjust the slider until
   the relationship between genes and proteins concerning gene
   expression.                                                           they were satisfied with their response, before clicking the
                                                                         submit button to record their response and go to the next trial.
   Gene expression is the process by which information from a
   gene is used in synthesizing RNA or other proteins; it controls       The instructions for the preventive condition were similar, ex-
   the structure and functions of cells or other genes. This process     cept that the protein was characterized as having preventive
   may or may not be modulated by the presence of proteins. You          power, and the hypothetical sample used in the second ques-
   are given a number of gene/protein pairs and your job is to
   make assessments concerning the effect of these proteins on           tion was assumed to have the gene currently expressed in all
   the expression of the genes.                                          100 DNA strands.
   There are a number of trials in this experiment. Each trial in-          A within-subjects iterated learning design was used. There
   volves a different gene and a different protein. In each trial,       were four transmission chains with ten iterations each. The
   DNA strands extracted from hair samples would be exposed to           data that initiated each chain were generated by sampling a
   the protein and the expression of the gene would be assessed.
   You will see the results from two samples of DNA strands. One         contingency table from predetermined initial values of w0 and
   sample consists of DNA strands that had not been exposed to           w1 . These initial values were chosen to be distinct so that the
   the protein while the other sample consists of DNA strands that       differences between responses from different chains could be
   had been exposed to that protein. In both samples, you will see
   the number of gene expression resulted but no other informa-          used to diagnose convergence. The initial data for the four de-
   tion will be provided.                                                pendent chains were drawn from distributions with (w0 , w1 )
                                                                     1711

parameters of (0.2, 0.2), (0.2, 0.8), (0.8, 0.2), and (0.8, 0.8).     24.50, p < 0.868; in w1 chain, F(1, 284) = 0.8742, MSE =
Each contingency table had a total of 16 cases where the              1073, p = 0.351). The results were similar in the preven-
cause was present, and 16 where the cause was absent, with            tive condition. The w0 ratings retained influences from ini-
the number of times the effect occurred being generated via a         tial values (F(1, 334) = 83.474, MSE = 98949, p < 0.001),
binomial draw with parameter P(e+ |c; w0 , w1 ). In all subse-        but the w1 ratings are not significantly different (F(1, 334) =
quent trials, data were generated based on the w0 and w1 val-         1.831, MSE = 2480.9, p = 0.177). Again, there were no inter-
ues the participant produced in the previous trial in the same        actions (w0 chain: F(1, 332) = 0.557, MSE = 663, p = 0.456;
chain. These values were taken directly from the estimates            w1 chain: F(1, 332) = 1.136, MSE = 1530.0, p = 0.287).
that the participants produced in response to the two ques-              This pattern of results suggests that the w1 values had con-
tions about hypothetical samples. For example, if on iteration        verged while the w0 values still retained some influence of
n of a particular chain the participant’s responses were f0 and       initialization. Inspection of the data showed that the empirical
 f1 (out of 100) for the two questions, then the data presented       priors for w0 has most of its density residing on regions close
at iteration n + 1 of chain would be drawn using w0 = f0 /100         to 0 or 1 and that individual chains were attracted to these
and w1 = f1 /100.                                                     modes, only rarely moving between them, and thus might re-
    To evaluate the performance of different Bayesian models,         quire longer chain in order to guarantee convergence. How-
we added a fifth chain in which the contingencies that were           ever, the final iteration of each chain still gives a reasonably
presented did not depend on participants’ previous responses.         clear picture of the prior. Additionally, since this study fo-
This is not really a “chain” as all of these trials were in fact      cuses on the human judgment of the potential cause C, whose
independent, but we retain the name for convenience in expo-          inference is based on w1 , the non-convergence of w0 does not
sition and in contrast to the dependent chains. This chain pro-       prevent us from continuing our analysis using this data.
vided the additional benefit of preventing participants from             Figure 2 shows the density of the empirical priors based on
being able to easily guess or approximate the stimulus gener-         the responses from the final iteration of all chains, smoothed
ation algorithm (Griffiths et al., 2008). For the independent         via kernel density estimation with a bivariate normal kernel
chain both w0 and w1 were sampled from a uniform distribu-            (Venables & Ripley, 2002). The generative SS priors gives
tion on (0, 1) on each trial, and were then used to generate          high probability to regions where only one of w0 or w1 is high,
contingencies as in the dependent chains. There were thus a           while the empirical priors generally prefers w1 to be high,
total of five chains and 50 trials per participant. The order of      with the distribution on w0 being more uniform but has peaks
trials between chains was randomized within each iteration.           near both 0 and 1. A similar pattern appears in the empirical
                                                                      priors for the preventive case, which is quite different from
Results                                                               the prediction under the SS priors in which either w0 and w1
The results from the university and online subject pools were         are both high or w0 is high and w1 is low. Moreover, the prior
similar to each other. We ran a Mann-Whitney U test on the            density is generally lower away from the corners. This char-
162 and 179 contingencies where we have data from both                acteristic of the empirical prior points to some degree of pref-
pools. Only 4 and 2 contingencies (respectively for genera-           erence for deterministic causal systems, consistent with pre-
tive and preventive conditions) resulted in significant differ-       vious research on human causal induction (Griffiths & Tenen-
ences (with p < .05). None of these differences were sig-             baum, 2009; Schulz & Sommerville, 2006).
nificant if Bonferroni correction is applied. Therefore results
from these two sources were combined.                                       Comparing models to human judgments
    Analyses of the dependent chains focused on the final iter-       We can now compare Bayesian models based on the three dif-
ation of all chains, as this iteration was most likely to reflect     ferent priors – uniform (Griffiths & Tenenbaum, 2005), sparse
the prior distribution. To test for convergence, we compared          and strong (Lu et al., 2008), and the empirical priors esti-
the distribution of both ratings as a function of the values used     mated by iterated learning – with human judgments of causal
to initiate each chain. ANOVA tests with the initial values of        strength. Since all three Bayesian models use the same like-
w0 and w1 as factors was run for strength estimates of both           lihood function and differ only in the priors, the predictions
w0 and w1 in each condition. The result showed a statistically        are not radically different. However, the models do differ in
significant effect of initial values in the human ratings in the
final iteration of both conditions for w0 but not w1 .
    Means and standard deviations from the final iteration of         Table 1: Mean and s.d. of the human ratings in the final iter-
all chains are shown in Table 1. In the generative condi-             ation, separated by initial parameterization.
tion, the w0 ratings from chains of higher initial w0 values
                                                                            Chain    Causal      Small             Large
remains higher than those from chains of lower initial w0 val-                       direction   initial condition initial condition
ues (F(1, 286) = 79.568, MSE = 97314, p < 0.001). On the
                                                                            w0       Gen.        30.708 (35.498)   67.472 (34.438)
other hand, there were no significant differences in w1 ratings             w0       Gen.        29.577 (34.475)   63.899 (34.384)
between chains of different initial w1 values (F(1, 286) =                  w1       Prev.       81.979 (30.729)   85.479 (28.641)
1.000, MSE = 882.0, p = 0.318). There were no interac-                      w1       Prev.       72.065 (38.289)   77.500 (35.271)
tions in either chain (in w0 chain, F(1, 284) = 0.028, MSE =
                                                                  1712

                                                                                                                                   Human responses                                        Uniform                                              SS                                         Empirical
                                                          Generative
                                                                                                  Generative
                                                                                                                                                            100                                                1.0                                              1.0                                            1.0
                                                                                                                          15                                                 15                                                 15                                               15
                                                                                                                                                            80                                                 0.8                                              0.8                                            0.8
                                                                                                                          10                                                 10                                                 10                                               10
                                                                                                               N(e+|c−)                                           N(e+|c−)                                           N(e+|c−)                                         N(e+|c−)
                                                                                                                                                            60                                                 0.6                                              0.6                                            0.6
                                                                                                                                                            40                                                 0.4                                              0.4                                            0.4
                                                                                                                          5                                                  5                                                  5                                                5
                          14                                                                                                                                20                                                 0.2                                              0.2                                            0.2
                                                                                                                          0                                 0                0                                 0.0              0                               0.0              0                             0.0
                          12                                                                                                   0      5          10   15                          0   5          10       15                         0   5          10    15                          0   5          10   15
                                                                                                                                          N(e+|c+)                                        N(e+|c+)                                           N(e+|c+)                                         N(e+|c+)
                          10                                                                                                       Human responses                                        Uniform                                              SS                                         Empirical
            Probability
                                                                                                                                                            100                                                1.0                                              1.0                                            1.0
                                                                                                  Preventive
                                                                                                                          15                                                 15                                                 15                                               15
                              8
                                                                                                                                                            80                                                 0.8                                              0.8                                            0.8
                                                                                                                          10                                                 10                                                 10                                               10
                                                                                                               N(e+|c−)                                           N(e+|c−)                                           N(e+|c−)                                         N(e+|c−)
                              6                                                                                                                             60                                                 0.6                                              0.6                                            0.6
                                                                                                                                                            40                                                 0.4                                              0.4                                            0.4
                              4                                                                                           5                                                  5                                                  5                                                5
                                                                                                                                                            20                                                 0.2                                              0.2                                            0.2
                              2                                                                                           0                                 0                0                                 0.0              0                               0.0              0                             0.0
                                                                                                                               0      5          10   15                          0   5          10       15                         0   5          10    15                          0   5          10   15
                                                                                                                                             +   +                                           +   +                                              +   +                                            +   +
                                                                                                                                          N(e |c )                                        N(e |c )                                           N(e |c )                                         N(e |c )
                              0
                              1
                                  0.8                                                      1
                                        0.6                                          0.8          Figure 3: Comparison of human responses with predictions
                                              0.4                              0.6
                                                    0.2
                                                                   0.2
                                                                         0.4                      from Bayesian models using uniform, SS, and empirical pri-
                                          w1               0   0
                                                                          w0                      ors. The grids represent the contingencies with N(e+ , c+ ) and
                                                                                                  N(e+ , c− ) on the horizontal and vertical axes respectively.
                                                          Preventive
                                                                                                  Cells with gray stripes show contingencies that did not ap-
                                                                                                  pear in the experiment. Some contingencies are more likely
                              6                                                                   because of sampling.
                              5
                              4
                                                                                                  Table 2: Comparison of model performance on independent
                Probability
                              3
                                                                                                  chain trials of our experiment.
                              2
                              1
                                                                                                       Causal
                                                                                                       direction                                           Metric                                               Uniform                                               SS                  Empirical
                              0
                              1
                                  0.8                                                      1
                                                                                                       Generative                                          Correlation (r)                                        0.7414                                  0.5620                                  0.7876
                                        0.6                                          0.8               Generative                                          Adj. RMSD                                             22.4774                                 29.6693                                 15.5900
                                              0.4                              0.6
                                                                         0.4
                                                    0.2
                                                                   0.2                                 Preventive                                          Correlation (r)                                        0.6544                                  0.6415                                  0.6679
                                          w1               0   0
                                                                          w0                           Preventive                                          Adj. RMSD                                             22.0802                                 23.3648                                 19.0560
Figure 2: Empirical priors estimated by iterated learning, for
both generative and preventive cases.                                                             are not uncommon. This is expected because of our more
                                                                                                  comprehensive data set, with many different contingencies,
how they treat cases with middling causal strength, as can be                                     and as a result, higher variability in mean human judgments.
seen by comparing the plots in Figure 3.                                                          For example, there were eight contingencies (in each causal
   The stimuli and, therefore, human data used in most prior                                      direction) in Experiment 1 of Lu et al. (2008) whereas there
studies (e.g. Lu et al., 2008) are not randomly selected and                                      were 184 and 191 contingencies in our experiment, in the
were chosen by researchers in order to compare model perfor-                                      generative and preventive case respectively.
mance under specific scenarios. For example, if a researcher                                         In order to take into account the differences in the sam-
is interested in comparing the ∆P model versus the causal                                         ple size of the human responses, we also evaluated the
power model, often only contingencies that produce radically                                      models using adjustedrRMSD. We calculated this score
different predictions under the two models will be selected                                                                                                                                                (xˆi −xi )2     1
                                                                                                  as Adjusted RMSD =                                                                                 ∑i         sei / ∑ j se j                                 where xi are the
as stimuli. Although this approach is useful in differentiating
models in specific scenarios, it does not necessarily reflect                                     means of the human responses, x̂i are model predictions, and
causal induction more generally. We opted for a more general                                      sei are the standard errors. This metric assigns higher weight
approach and used the responses produced in the indepen-                                          to contingencies where more human data are available (thus
dent chains from our experiment, where trials were generated                                      lower sampling error) and where variability is smaller. Con-
using uniformly distributed w0 and w1 values and therefore                                        tingencies where the standard error could not be computed
covered a wide range of contingencies.                                                            were omitted from the analysis. With this metric, the em-
                                                                                                  pirical priors again made better predictions than the other
   The performance of the models was evaluated using Pear-
                                                                                                  two models, particularly in the generative direction. Figure 4
son’s correlation coefficient (r) and an adjusted root-mean-
                                                                                                  compares the performance of models using the SS and empir-
square deviations (RMSD) score. The correlation r compares
                                                                                                  ical priors in terms of adjusted RMSD at every set of contin-
the mean human judgment with model predictions. All three
                                                                                                  gencies that appeared in the experiment.
models performed quite well based on the Pearson’s correla-
tion coefficient (r) with the empirical model having the high-
est correlation. The results are shown in Table 2. Overall, the
                                                                                                                                                                                            Discussion
r metrics in this experiment are lower compared to those in                                       We have presented the first direct estimate of human priors
prior studies (e.g. Lu et al., 2008) where values of r over 0.95                                  on the strength of causal relationships, using iterated learn-
                                                                                               1713

                Performance (Generative)                        Performance (Preventive)            pend on the complexity of the causal system.
           15
                                           60
                                                           15                                          Finally, our results also raise questions concerning how
                                                                                           15
                                                                                                    models of causal induction should be compared. Most past
                                                                                           10
           10                              40              10                                       causal inference literature evaluate model fit by comparing
N(e+|c−)                                        N(e+|c−)
                                                                                           5
                                                                                                    model predictions with human responses at specific contin-
                                           20                                              0
           5                                               5                                        gencies. These contingencies were usually chosen to high-
                                                                                           −5
                                           0                                                        light the different predictions made by the models of interest.
                                                                                           −10
           0                                               0                                        The independent chains used in our experiment provided a
                0      5         10   15                        0      5         10   15
                           N(e+|c+)                                        N(e+|c+)                 picture of human causal strength judgments for a remarkably
                                                                                                    wide range of contingencies. Establishing a broad database
Figure 4: Comparison of model predictions. These two plots                                          for objectively comparing models of human causal induction
compare the performance of the Bayesian model with the em-                                          is an important challenge for future research.
pirical priors against that with the SS priors. The grids repre-
                                                                                                    Acknowledgments. This work was supported by grant number FA-
sent the contingencies with N(e+ , c+ ) in x-axis and N(e+ , c− )
                                                                                                    9550-10-1-0232 from the Air Force Office of Scientific Research,
in y-axis. The value at each grid is the difference of the error
                                                                                                    and the McDonnell Causal Collaborative.
of the models (compared to the mean human result). Pos-
itive values (lighter grids) represent better performance for                                                                 References
the empirical prior model; negative values represent better                                         Buehner, M., & Cheng, P. (1997). Causal induction: The power
performance for the SS prior model. Only data from the in-                                            PC theory versus the Rescorla-Wagner model. In Proceedings of
dependent chains are plotted here.                                                                    the nineteenth annual conference of the cognitive science society:
                                                                                                      August 7-10, 1997, stanford university (p. 55).
                                                                                                    Cheng, P. (1997). From covariation to causation: A causal power
                                                                                                      theory. Psychological Review, 104(2), 367–405.
ing. The resulting empirical priors were markedly different                                         Griffiths, T., Christian, B., & Kalish, M. (2008). Using category
from previously proposed theory-based priors. We also found                                           structures to test iterated learning as a method for identifying in-
that the empirical priors predict human judgments better than                                         ductive biases. Cognitive Science, 32(1), 68–107.
                                                                                                    Griffiths, T., & Kalish, M. (2007). Language evolution by iterated
these previously proposed priors. However, there are a num-                                           learning with Bayesian agents. Cognitive Science: A Multidisci-
ber of important issues that need to be explored in future                                            plinary Journal, 31(3), 441–480.
work, including giving a more comprehensive characteriza-                                           Griffiths, T., & Tenenbaum, J. (2005). Structure and strength in
                                                                                                      causal induction. Cognitive Psychology, 51(4), 334–384.
tion of priors across different causal scenarios, dealing with                                      Griffiths, T., & Tenenbaum, J. (2009). Theory-based causal induc-
more complex causal systems, and determining an objective                                             tion. Psychological Review, 116(4), 661–716.
method for evaluating models of causal induction.                                                   Hume, D. (1739/2004). An Enquiry Concerning Human Under-
                                                                                                      standing. Dover Publications.
   The gene expression cover story we used in our experi-                                           Kalish, M., Griffiths, T., & Lewandowsky, S. (2007). Iterated learn-
ment is similar to cover stories used in numerous prior ex-                                           ing: Intergenerational knowledge transmission reveals inductive
periments on causal induction (Lu et al., 2008; Griffiths &                                           biases. Psychonomic Bulletin & Review, 14(2), 288.
                                                                                                    Kirby, S. (2001). Spontaneous evolution of linguistic structure:
Tenenbaum, 2005; Lober & Shanks, 2000). These medical                                                 An iterated learning model of the emergence of regularity and
cover stories are used because they provide plausible causal                                          irregularity. IEEE Journal of Evolutionary Computation, 5, 102-
relationships between variables, and the functional form of                                           110.
                                                                                                    Lober, K., & Shanks, D. (2000). Is causal induction based on causal
these relationships is simple. However, it is possible that prior                                     power? Critique of Cheng (1997). Psychological Review, 107(1),
knowledge might influence the form of the priors that people                                          195–212.
use when reasoning about this particular scenario, such that                                        Lombrozo, T. (2007). Simplicity and probability in causal explana-
                                                                                                      tion. Cognitive Psychology, 55(3), 232–257.
the empirical priors we estimated might not generalize well                                         Lu, H., Yuille, A., Liljeholm, M., Cheng, P., & Holyoak, K. (2008).
to other causal domains. It is also possible that cultural dif-                                       Bayesian generic priors for causal learning. Psychological Re-
ferences might influence the form of the priors. Having es-                                           view, 115(4), 955–984.
                                                                                                    Novick, L., & Cheng, P. (2004). Assessing Interactive Causal Influ-
tablished that iterated learning can be used to investigate pri-                                      ence. Psychological Review, 111(2), 455–485.
ors on causal strength, we anticipate that this approach can be                                     Pearl, J. (2000). Causality: Models, reasoning, and inference. Cam-
used to explore how priors vary across scenarios and cultures.                                        bridge University Press.
                                                                                                    Schulz, L. E., & Sommerville, J. (2006). God does not play dice:
   By focusing on the simplest possible causal structure, our                                         Causal determinism and children’s inferences about unobserved
study did not address how people reason about causal sys-                                             causes. Child Development, 77, 427-442.
                                                                                                    Spirtes, P., Glymour, C., & Scheines, R. (2001). Causation, predic-
tems where more than one non-background cause is present.                                             tion, and search. The MIT Press.
This reflects a general phenomenon in the study of human                                            Venables, W., & Ripley, B. (2002). Modern applied statistics with
causal induction, where investigation of systems involving                                            S. Springer-Verlag.
                                                                                                    Ward, W., & Jenkins, H. (1965). The display of information and
multiple causes is rare. However, some recent studies have                                            the judgment of contingency. Canadian Journal of Psychology,
examined how people estimate the strength of multiple causes                                          19(3), 231–241.
(e.g., Novick & Cheng, 2004). Adapting the methods used in
these studies to an iterated learning setting might provide a
way to investigate whether the priors that people adopt de-
                                                                                                 1714

