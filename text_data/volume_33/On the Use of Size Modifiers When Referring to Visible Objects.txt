UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
On the Use of Size Modifiers When Referring to Visible Objects
Permalink
https://escholarship.org/uc/item/0mx287f3
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)
Authors
Mitchell, Margaret
Van Deemter, Kees
Reiter, Ehud
Publication Date
2011-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                 On the Use of Size Modifiers When Referring to Visible Objects
                             Margaret Mitchell                    Kees van Deemter              Ehud Reiter
                           (m.mitchell@abdn.ac.uk)            (k.vdeemter@abdn.ac.uk) (e.reiter@abdn.ac.uk)
                                         Computing Science Department, University of Aberdeen
                                                          Aberdeen, Scotland, U.K.
                              Abstract                                   individual-axis size modifiers (“tall”, “thin”) emerging in dif-
                                                                         ferent contexts. Additionally, we are able to confirm earlier
   We present a study on how people use size modifiers when
   referring to visible objects. We find strong evidence that the        findings on modifier preferences grounded in physical object
   selection of modifiers like tall, thin, and big is brought about      properties (Hermann & Deutsch, 1976), and further build on
   by several interacting factors, including how a target object’s       these results. This research will inform a natural language
   physical dimensions differ from another object of the same
   type, and the relationship between the target object’s individ-       generation (NLG) system that refers to real-world items nat-
   ual dimensions. Findings from this study are used to inform           urally, and provides a fundamental connection linking natural
   the design of a referring expression generation algorithm ca-         language generation to a vision-based input.
   pable of referring to objects naturally, providing a further link
   between visual cues and corresponding linguistic forms.
   Keywords: size adjectives; size modifiers; visual features; re-
                                                                                       Background and Motivation
   ferring expression generation                                         Methods for reasoning about the basic properties common to
                                                                         all visual scenes have isolated the properties of color, loca-
                          Introduction                                   tion, size, and type as the building blocks for visual refer-
Over the past two decades, detailed psycholinguistic mod-                ence (Roy & Pentland, 2002; Skočaj et al., 2007). Detailed
els of utterance planning have emerged (Ferreira & Swets,                accounts of several of these factors have been developed, in-
2002; Griffin & Bock, 2000; Levelt, 1989; Levelt, Roelofs,               cluding how to produce natural expressions with appropriate
& Meyer, 1999). These models seek to explain the relation-               use of color modifiers (Mojsilović, 2005) and spatial descrip-
ship between thought and language, connecting internal men-              tions (Gorniak & Roy, 2004; Kelleher et al., 2005).
tal processes to the timing and structure of produced expres-               However, our knowledge of how people use size modifi-
sions. A significant amount of recent work has focused on                cation to refer to an object is extremely limited. There has
the relationship between the visual world and the references             been considerable research on the behavior of size modi-
used to identify items therein (Bock, Irwin, Davidson, & Lev-            fiers for other purposes, such as the semantics of dimensional
elt, 2003; Henderson & Ferreira, 2004), but this research has            modifiers (Bierwisch & Lang, 1989; Eilers, Oller, & Elling-
been underutilized in computational approaches to modeling               ton, 1974; Tucker, 1998; Morzycki, 2009), the acquisition
a language generation process (Dale & Reiter, 1995; Krah-                of the meaning of such modifiers (Bartlett, 1976), when di-
mer, van Erk, & Verleg, 2003).                                           mensional modifiers are used (Brown-Schmidt & Tanenhaus,
   It has been well established that dimensional modifiers,              2006; Sedivy, Tanenhaus, Chambers, & Carlson, 1999), and
such as those denoting size, play a central role in reference            how language reflects dimensional properties such as height
to objects in a visual scene, particularly when objects of               and width (Landau & Jackendoff, 1993; Landau, 2001). We
the same type are in the scene (Brown-Schmidt & Tanen-                   also know roughly how to choose between different forms of
haus, 2006; Sedivy, 2003). This property of reference is                 a size adjective (“larger”, “largest”) (van Deemter, 2004).
not only important for work in referring expression gener-                  A primary open question this research leaves is whether
ation (REG) that uses size modifiers (Kelleher, Costello, &              people distinguish objects by focusing on one single dimen-
Genabith, 2005; van Deemter, 2004; Viethen & Dale, 2008),                sion or by combining dimensions, and how these are realized
but it offers a clear link between language generation and               as surface forms. Given information about an object’s height
machine vision techniques that provide detailed information              and width, it is unclear how it will be referred to.
about an object’s physical dimensions (Friedland, Jantz, &                  Most REG algorithms presuppose that referents are indi-
Rojas, 2005; Zheng, Yuille, & Tu, 2010). Systematically ma-              viduated using “absolute” properties, whose applicability to
nipulating the visual feature of size to develop an account of           a referent does not depend on the context in which the refer-
how size is used in reference furthers the goal of developing            ent appears. Size is no exception. Dale and Reiter (1995), for
a grounded semantic core for natural language (Gorniak &                 example, let their algorithms start from a Knowledge Base in
Roy, 2004), tying visual perception to linguistic reference.             which some objects are listed explicitly as large, while others
   In this study, we seek to better understand the relationship          are listed as small. Van Deemter (2000, 2004) modifies this
between an object’s dimensions and the words used to iden-               procedure by storing actual sizes (e.g., in centimeters) in the
tify it. We evaluate three hypotheses that explore this relation-        Knowledge Base, making the decision of whether something
ship. Our results suggest that the selection of size modifiers is        is larger or smaller context dependent. However, neither of
governed by several interacting and competing factors, with              these approaches pays attention to the choice between words
preferences for overall size modifiers (“big”, “small”) versus           like “big” and “tall”; presumably, this choice is made by a
                                                                     3091

 later module that translates properties into words.                          overall size modifier will be produced more often than an
     But these words may mean something very different and                    individual-axis size modifier.
 reflect different properties of a referent. For example, con-          H3 When two dimensions differ in opposite directions be-
 sider an object A that is taller and wider than an object B. It              tween a referent object and another object of the same type,
 is true that A is taller than B; it is true that A is wider than B;          an individual-axis size modifier will be produced more of-
 it is also true that A is bigger than B. All three words may be              ten than an overall size modifier.
 appropriate to refer to A, and we do not know whether there
 is a preference for one over the other. Landau and Jackend-                  It is relatively straightforward to write a deterministic algo-
 off (1993) point out that a modifier like “big” selects different        rithm capturing what we predict the majority of people will
 dimensions depending on the nature of the object, and tends              do when there is a difference in at least one dimension be-
 to be used in cases where an object is large in either two or            tween two similar objects, and we sketch such an algorithm
 all three of its dimensions, while modifiers like “thick” and            in Figure 1. Note that some aspects are still left unspecified,
 “thin” may be applied when an object extends in a single di-             and the algorithm does not address how large a difference
 mension.                                                                 must be in order to be salient – clearly, some differences be-
     Some information about what to expect in a computa-                  tween referent and comparator may be too small to elicit a
 tional model of size modification is provided by Hermann and             corresponding modifier. This is an area for future work.
 Deutsch (1976), who find that subjects are more likely to use                Lines 2–3 and 9–10 represent H2 , returning an overall size
 words like “fat” rather than “short” when a candle is much               modifier depending on the differences between dimensions.
 fatter but only a little shorter than a comparator. In another           Lines 2, 4–7; and 9, 11–14 roughly represent H3 , and call
 vein of computational work, Roy (2002) finds that words like             to a second function motivated by Hermann and Deutsch
 “small” and “large” cluster together, but that “tall” is placed          (1976), LARGEST- DIMENSION - DIFF, which returns the di-
 in a separate cluster. A second clustering approach based on             mension with the greater difference. Lines 2, 8; 9, 15; and
 visual properties finds that “thin” is associated most strongly          16–18 represent H1 . The final size modifier structure is sent
 with surface area, and only weakly with height-to-width ratio.           to the GENERATE function, requesting an overall size modi-
     These findings suggest that the dimensional properties of            fier (<over>), or an individual-axis size modifier picking out
 a referent may be reasoned about to produce different kinds              a specific axis (<ind, width> or <ind, height>), along with
 of expressions. An REG algorithm that generates natural ref-             whether the modifier should capture a larger (+) or smaller (-)
 erence to visible objects should be equipped to handle this              difference. Thus, for example, (<over>, +) could be realized
 variation, and building such an algorithm can aid in modeling            as “large” or “big”, while (<ind, height>, -) could be realized
 how people use size modification.                                        as “short”.
     We therefore set out to examine how the words proposed to            r = referent object, d = object of the same type (comparator)
 refer to specific axes, like “tall” and “thick”, are used differ-        rh , rw = referent height, referent width
 ently than words proposed to refer to overall size, like “large”         dh , dw = comparator height, comparator width
 and “small”. The first type we will call individual-axis size            01. GenSizeMod(r, d):
 modifiers and the second overall size modifiers.1 Our hy-                02. if rh > dh :
                                                                          03.        if rw > dw : generate(<over>, +)
 potheses are designed to formalize aspects of size reference             04.        elif rw < dw :
 that have been implied by earlier work (e.g., Landau and Jack-           05.           if largest-dimension-diff(rh , rw , dh , dw ) == width:
 endoff (1993)), but have not yet been systematically tested.             06.               generate(<ind, width>, -)
                                                                          07.           else: generate(<ind, height>, +)
 This provides a basis from which to design an REG algorithm              08.        else: generate(<ind, height>, +)
 that refers to an object’s size.                                         09. elif rh < dh :
                                                                          10.        if rw < dw : generate(<over>, -)
                                                                          11.        elif rw > dw :
                            Experiments                                   12.           if largest-dimension-diff(rh , rw , dh , dw ) == width:
 We examine what happens when a referent object is different              13.               generate(<ind, width>, +)
 in size from a comparator object (1) along a single axis; (2)            14.           else: generate(<ind, height>, -)
                                                                          15.        else: generate(<ind, height>, -)
 along two axes, in the same direction (both axes larger or both          16. else:
 smaller); and (3) along two axes, in opposite directions (one            17.        if rw > dw : generate(<ind, width>, +)
 axis larger, one smaller). Our hypotheses are listed below.              18.        elif rw < dw : generate(<ind, width>, -)
H1 When a single dimension differs between a referent object                  Figure 1: Initial algorithm for generating size modifiers.
     and another object of the same type, an individual-axis size
                                                                              However, we expect that this is not the whole story, and
     modifier will be produced more often than an overall size
                                                                          return to this issue in the last section.
     modifier.
                                                                              We consider size differences in two different gradations:
H2 When two dimensions differ in the same direction between               A small negative difference (-, 10/11th size) or a small posi-
     a referent object and another object of the same type, an            tive difference (+, 11/10th size) between the axis of the refer-
      1 Note that individual-axis size modifiers may occasionally pick    ent and the corresponding axis of the comparator; and a large
 out more than one axis, e.g., as in the word “thick”.                    negative difference (- -, 4/5th size) or large positive difference
                                                                      3092

                                                                           E XPERIMENT 2: D IFFERENCES OF DEGREE , MATCHING
                                                                       ACROSS DIMENSIONS . Responses were elicited for objects
                                                                       with height/width combinations of ++/++, ++/+, +/++, +/+, -
                                                                       -/- -, - -/-, -/- - and -/- (8 conditions). Each target item differed
                                                                       from its comparator item in two dimensions and in the same
Figure 2: Example stimuli: sponges (++/- -), books (-/0),
                                                                       direction for each; the target item was either bigger overall or
boards (- -/- -), and brownies (++/0).
                                                                       smaller overall than the comparator.
                                                                           E XPERIMENT 3: D IFFERENCES OF DEGREE , DIFFERENT
(++, 5/4th size) between the two axes. These are operational-          POLARITIES ACROSS DIMENSIONS . Responses were elicited
izations of what it means for height and width to be different,        for objects with height/width combinations of ++/- -, - -/++,
and serve as a starting point to sample the space of height and        ++/-, -/++, +/- -, - -/+, +/- and -/+ (8 conditions). Each target
width contrasts. Values for these measurements are provided            item differed from its comparator item in two dimensions and
in Table 1.                                                            in the opposite direction for each; the target item had one axis
   The stimuli in this study were photographs of real-world            bigger and one axis smaller than the comparator.
objects, physically cut and shaped into different sizes. This              For each experiment, we followed a Latin square design
follows work in developing computational models that bridge            where all participants saw each of the four object types, with
the symbolic realm of language with the physical realm of              two examples per condition. This yielded 16 experimental
real-world referents (Herzog & Wazinski, 1994; Roy & Re-               stimuli per participant. Each experiment had two subgroups,
iter, 2005; Tanenhaus, Spivey-Knowlton, Eberhard, & Se-                where one half (10 participants) saw 2 stimuli per condition,
divy, 1995).                                                           and the other half (10 participants) saw the other 2 stimuli per
                                                                       condition.
Method                                                                     Stimuli in each experiment were intermixed with the 24
                                                                       filler pictures, consisting of spatulas, Legos, and shoes. Spat-
Participants 95 subjects collected using Amazon’s Me-                  ulas appeared in groups of three and Legos and shoes ap-
chanical Turk (Amazon, 2008) were paid for their participa-            peared as sets of two. Most objects in filler conditions could
tion. 87 of these participants labeled themselves as “Native”          be distinguished using part-whole phrases, e.g., “the one with
or “Fluent”. From this set, we randomly chose a subset of              the red Lego” or “the shoe with the laces untied”. In total,
60 total participants, spread evenly as groups of 20 in each of        each subject provided responses for 40 object pictures. Each
our three experiments.                                                 picture was 400 pixels wide x 300 pixels high, and could be
Materials Several different objects were used to elicit size           enlarged to 700 x 525 by clicking on it. Pictures were pre-
modifiers. These objects were sponges, boards, books, and              sented in random order, and experimental groups were as-
brownies. All objects were rectilinear solids, varied along            signed randomly.
their height and width dimensions. The objects were inter-             Procedure Instructions informed participants that they had
mixed with fillers, discussed in further detail below.                 been chosen as “the thrower”, tossing objects down a tube
   Each object appeared to the right of a comparator object of         to a person below, and their goal was to clearly identify the
the same type (see Figure 2). The target object could appear           object on the right so that the person below could pick it up.
in 24 different sizes, created by combinations of 5 gradations             Responses were manually corrected for spelling and nor-
relative to the comparator object on both the object’s hori-           malized for punctuation and capitalization. For each expres-
zontal and vertical axes: smaller (- -); a little smaller, (-); no     sion, we annotate the modifiers as being an individual-axis
difference (0); a little larger, (+); and larger, (++). The 25th       size modifier (ind.), overall size modifier (over.), or other.
possible size, no difference from the comparator on both the           Each single-dimensional modifier was annotated by three
horizontal and vertical axes, was not included. The differ-            postgraduates as being a height modifier or a width modifier.
ence between the height and width of the target object itself          We use the annotations from the annotator who had the high-
was different across the different objects. All target objects         est agreement with the other two, with a Cohen’s kappa of
had the same relative ratio of difference from the comparator          0.90 (95% CI, 0.87–0.94) and 0.71 (0.66–0.76). Table 2 lists
on each axis.                                                          the vocabulary and modifier types based on this data. Most
Design We conducted three experiments, addressing each                 base modifiers have corresponding comparative (ending in
of our hypotheses. The design for each was dimension (2:               -er) and superlative (ending in -est) forms.
height, width) x degree of difference (2: small, large) x direc-
tion of difference (2: bigger, smaller).                                                                Results
   E XPERIMENT 1: D IFFERENCES OF DEGREE , SINGLE                      Results are based on the 320 responses for each experiment.
DIMENSION .        Responses were elicited for objects with            Each response to the test stimuli is counted as either including
height/width combinations of ++/0, 0/++, +/0, 0/+, -/0, 0/-,           or not including an individual-axis size modifier (0 or 1) and
- -/0 and 0/- - (8 conditions). Each target item differed from         including or not including an overall size modifier (0 or 1).
its comparator item in one dimension.                                  Note that the two are not exclusive. For each participant, we
                                                                   3093

                                       Table 1: Measurements for objects along each axis (in cm).
                                                  height                                             width
                 object
                               ++         +        0          -          --        ++       +         0        -       --
                 brownies      11.25      9.90     9.00       8.18       7.20      11.25    9.90      9.00     8.18    7.20
                 sponges       6.25       5.50     5.00       4.54       4.00      12.50    11.00     10.00    9.09    8.00
                 books         25.00      22.00    20.00      18.18      16.00     6.25     5.50      5.00     4.55    4.00
                 boards        19.05      16.76    15.24      13.84      12.19     25.4     22.35     20.32    18.47   16.26
                    Table 2: Size vocabulary.                               type, an overall size modifier will be produced more often
                                                                            than an individual-axis size modifier.
           height:    high long narrow short skinny slender
  ind.                                                                         We find a strong trend to include overall size modifiers,
                      squat tall thick thin
                                                                            with such modifiers occurring in an average of 11.3 responses
           width:     fat lengthy long narrow skinny slim
                                                                            per participant. Individual-axis size modifiers occur in an av-
                      thick thin wide
                                                                            erage of 5.4 responses. The difference in this distribution is
  over.               big large small
                                                                            significant (t = −4.914, d f = 19, p < .001).
                   Table 3: Example responses.                                 H3 : When two dimensions differ in opposite directions
                                                                            between a referent object and another object of the same
   condition      object        expression                                  type, an individual-axis size modifier will be produced
   h++w++         books         taller fatter book                          more often than an overall size modifier.
   h+w- -         sponges       taller sponge                                  We find that when two dimensions differ in opposite direc-
   h- -w++        boards        the shorter and slightly wider              tions, individual-axis size modifiers are chosen in an average
                                board with a diagonal top side              of 12.3 responses per participant, while overall size modifiers
   h0w+           brownies      longer brownie                              are chosen in an average of 2.4 responses. The difference in
   h- -w- -       boards        smaller board                               this distribution is significant (t = 8.866, d f = 19, p < .001).
                                                                               Based on these results, we can confirm Hypotheses 2 and
sum the total number of responses with each type of modifier.               3. Overall size modifiers tend to be used when both axes
This provides two sets for a two-tailed paired t-test in each of            are different from a comparator in the same direction, and
our analyses.                                                               individual-axis size modifiers tend to be used when both axes
   Examples of normalized responses are given in Table 3.                   are different from a comparator in opposite directions. Re-
Table 4 provides the proportions of responses that included an              sults are significant at α = .01. We cannot reject a null hy-
individual-axis size modifier, an overall size modifier, both,              pothesis in favor of Hypothesis 1; we do not see a signifi-
or neither for each experiment.                                             cant difference in the distribution of size modifier types when
   H1 : When a single dimension differs between a referent                  a single axis is different between a target and a comparator.
object and another object of the same type, an individual-                  Further factors that may be affecting participant responses are
axis size modifier will be produced more often than an                      discussed in the next section.
overall size modifier.                                                         We have illustrated some basic principles of how people
   We do not find a strong trend to include individual-axis                 use size in reference. However, these experiments also pro-
size modifiers, with such modifiers occurring in an average of              vide much richer information on how people use size. One
8.4 responses per participant, compared to 6.1 responses on                 immediate question these findings leave is whether it is com-
average containing an overall size modifier. The difference is              mon to include two individual-axis modifiers, each referring
not significant (t = 1.382, d f = 19, p = 0.183).2                          to a separate axis, when the objects have differences of de-
   H2 : When two dimensions differ in the same direction                    gree, different polarities across dimensions (Experiment 3).
between a referent object and another object of the same                    We find that this occurs in a minority of responses (mean =
                                                                            4.8), while it is significantly more common (mean = 11.2) to
Table 4: Proportion of responses including either 1+                        include just one individual-axis size modifier, an overall size
individual-axis size modifiers, 1+ overall size modifiers, both,            modifier, or neither (t = −4.292, d f = 19, p < .001).
or neither.                                                                    We can also confirm the findings in Hermann and Deutsch
       Experiment       ind.       over.      both     neither              (1976). Based on responses to Experiment 2 and Experiment
       1                50.0%      35.6%      2.5%     11.9%                3, in conditions where there is a large difference and a small
       2                29.1%      65.9%      4.7%     0.3%                 difference (++/+, +/++, ++/-, -/++, - -/-, -/- -, - -/+, +/- -), if
       3                70.6%      8.8%       6.3%     14.4%                an individual-axis size modifier is chosen, that modifier will
                                                                            refer to the larger difference more often than the smaller dif-
    2 Preliminary analysis on a larger dataset suggests that this trend     ference (mean for large difference = 3.4; small difference =
may become significant, and we leave this for future work.                  2.6, t = 3.629, d f = 38, p < .001).
                                                                        3094

A.                                 B.
                                                                       of how the dimensional properties of objects may be reasoned
                                                                       about in a computational model, taking into account a target
                                                                       object’s position with respect to a comparator when selecting
                                                                       a size modifier type.
                                                                          An obvious area for further analysis concerns the determin-
                                                                       ism of the size algorithm. The majority of our data comports
                                                                       with the algorithm sketched in Figure 1, however, this data is
                                                                       probabilistic; the algorithm is not. Assigning probabilities to
                                                                       each of the conditional statements may help to better capture
                                                                       how people use size modification.
Figure 3: Count of overall size modifiers for different
height/width ratios in Experiment 1 (A) and Experiment 2                         Implications and Future Research
(B), with linear regression. Ratios shown are for the largest          This study suggests that the selection of size modifier when
axis divided by the smaller axis.                                      referring to real-world objects in the presence of another ob-
                                                                       ject is influenced by at least two factors:
                      Further Analysis
This data supports the idea that the selection of size modifier       1. Whether one or both axes differ from a comparator.
is in a large part determined by dimensional differences be-          2. Which axis is the most different from a comparator.
tween an object and another object of the same type, with a
                                                                       And may be influenced by two further factors:
difference along two axes in different directions correspond-
ing to size modifiers like “tall” and “thin”, and a difference        1. The location of the target object relative to the comparator.
along two axes in the same direction corresponding to size            2. How similar in size the two axes of the target object are.
modifiers like “small” and “big”.
   These experiments have also shed some light on some of                 In future work, we hope to explore our post-hoc findings
the other factors that may affect the selection of size modifier.      and refine the algorithm, developing mechanisms for reason-
One trend that emerges in the data is the relationship between         ing about the relative size difference between dimensions of
the selection of individual-axis or overall size modifier and          the referent object, and including information about where
the ratio between the height and width of the target object it-        the referent object is placed relative to a comparator. Extend-
self. Although we did not design the study to test this aspect,        ing this task to elicit responses from more participants may
our data indicate that the closer the object is to a square shape,     be used to assign weights to each of the conditions currently
e.g., the smaller the difference between height and width, the         in place, and provide the size algorithm with a probability
more likely participants are to use an overall size modifier           distribution over different possible surface forms. A better
like big or small. Figure 3 illustrates this trend, where the x-       understanding of when a difference is small enough not to
axis is the ratio between the larger axis (height or width) and        be salient would help connect this algorithm more closely to
the smaller axis (height or width) for each stimulus, and the          a visual input, placing constraints on when the conditional
y-axis is the number of responses to the stimulus that include         statements outlined above apply.
an overall size modifier. In the data from Experiment 2, this             This research reasons about the interplay between two di-
trend is quite strong, r2 = 0.95 (p < .001). Across conditions         mensions, height and width. Scaling up to three dimensions
with only height or width differing from the comparator ob-            would help further develop a model of how size modifiers are
ject (Experiment 1) – the conditions where we did not find a           used in the real world. It may be the case that the patterns of
tendency to use overall size modifiers – there is also a trend,        individual-axis and overall size modifiers change when there
r2 = 0.57 (p < .001). Further testing is necessary to examine          is a third visible dimension available. We also hope to ad-
this effect.                                                           dress situations where there are several similar objects, and
   This suggests that the selection of individual versus overall       situations where the target referent is a set of objects. Further
size modifier may be influenced by the difference in height            work may also examine how this research extends to other
and width from the comparator object as well as the differ-            kinds of object shapes; this study has focused on rectilin-
ence between height and width of the target object itself.             ear solids, but whether modifiers pick out the axes for height,
Individual-axis size modifiers may be used when only one               width, and depth in less rectangular objects, or objects with
axis of the target is different from the comparator, however, as       irregular shapes, remains an open question.
the axes of the target itself converge in size, there is a marked
increase in preference for overall size modifiers.                                         Acknowledgments
   We also find a preference to use height modifiers over              We would like to thank Ellen Gurman Bard for invaluable
width modifiers, across the three experiments (mean for                guidance and the anonymous reviewers for useful sugges-
height = 6.3, width = 4.7; t = 4.409, d f = 59, p < .001). This        tions. This research is sponsored by the Scottish Informatics
may reflect that the objects are presented side by side, their         and Computer Science Alliance (SICSA) and the Overseas
heights directly comparable. This brings to light another facet        Research Students Award Scheme (ORSAS).
                                                                   3095

                         References                                 Landau, B., & Jackendoff, R. (1993). “What” and “where”
                                                                      in spatial language and spatial cognition. Behavioral and
Amazon. (2008). Amazon mechanical turk: Artificial artifi-
                                                                      Brain Sciences, 16, 217–265.
  cial intelligence.
                                                                    Levelt, W. J. M. (1989). Speaking: From intention to articu-
Bartlett, E. J. (1976). Sizing things up: the acquisition of
                                                                      lation. Cambridge, MA: MIT Press.
  the meaning of dimensional adjectives. Journal of Child
                                                                    Levelt, W. J. M., Roelofs, A. P. A., & Meyer, A. S. (1999). A
  Language, 3(02), 205–219.
                                                                      theory of lexical access in speech production. Behavioral
Bierwisch, M., & Lang, E. (Eds.). (1989). Dimensional ad-
                                                                      and Brain Sciences, 22, 1–37.
  jectives : grammatical structure and conceptual interpre-
                                                                    Mojsilović, A. (2005). A computational model for color
  tation. New York: Springer-Verlag.
                                                                      naming and describing color composition of images. IEEE
Bock, J. K., Irwin, D. E., Davidson, D. J., & Levelt, W. J. M.
                                                                      Transactions of Image Processing, 14(5), 690–699.
  (2003). Minding the clock. Journal of Memory and Lan-
                                                                    Morzycki, M. (2009). Degree modification of gradable
  guage, 48, 653–685.
                                                                      nouns: size adjectives and adnominal degree morphemes.
Brown-Schmidt, S., & Tanenhaus, M. K. (2006). Watch-
                                                                      Natural Language Semantics, 17(2), 175–203.
  ing the eyes when talking about size: An investigation of
                                                                    Roy, D., & Reiter, E. (2005). Connecting language to the
  message formulation and utterance planning. Journal of
                                                                      world. Artificial Intelligence, 167, 1–12.
  Memory and Language, 54, 592–609.
                                                                    Roy, D. K. (2002). Learning visually-grounded words and
Dale, R., & Reiter, E. (1995). Computational interpretations
                                                                      syntax for a scene description task. Computer Speech and
  of the gricean maxims in the generation of referring expres-
                                                                      Language, 16, 353–385.
  sions. Cognitive Science, 19, 233–263.
                                                                    Roy, D. K., & Pentland, A. (2002). Learning words from
Eilers, R. E., Oller, D. K., & Ellington, J. (1974). The ac-          sights and sounds: A computational model. Cognitive Sci-
  quisition of word-meaning for dimensional adjectives: the           ence, 26, 113–146.
  long and short of it. Journal of Child Language, 1(02),           Sedivy, J. C. (2003). Pragmatic versus form-based accounts
  195–204.                                                            of referential contrast: Evidence for effects of informativity
Ferreira, F., & Swets, B. (2002). How incremental is lan-             expectations. Journal of Psycholinguistic Research, 32, 3–
  guage production? evidence from the production of utter-            23.
  ances requiring the computation of arithmetic sums. Jour-         Sedivy, J. C., Tanenhaus, M., Chambers, C., & Carlson,
  nal of Memory and Learning, 46, 57–84.                              G. (1999). Achieving incremental semantic interpreta-
Friedland, G., Jantz, K., & Rojas, R. (2005). SIOX: simple            tion through contextual representation. Cognition, 71, 109–
  interactive object extraction in still images. Proceedings of       147.
  the Seventh IEEE International Symposium on Multimedia,           Skočaj, D., Berginc, G., Ridge, B., Vanek, O., Hutter, M., &
  253–259.                                                            Hewes, N. (2007). A system for continuous learning of vi-
Gorniak, P., & Roy, D. (2004). Grounded semantic compo-               sual concepts. Proceedings of the International Conference
  sition for visual scenes. Journal of Artificial Intelligence        on Computer Vision Systems.
  Research, 21, 429–470.                                            Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K. M.,
Griffin, Z. M., & Bock, K. (2000). What the eyes say about            & Sedivy, J. C. (1995). Integration of visual and linguistic
  speaking. Psychological Science, 11, 274–279.                       information in spoken language comprehension. Science,
Henderson, J. M., & Ferreira, F. (2004). The interface of lan-        268, 1632–1634.
  guage, vision, and action: Eye movements and the visual           Tucker, G. (1998). The lexicogrammar of adjectives: A sys-
  world. New York, NY: Psychology Press.                              temic functional approach to lexis. London: Cassell.
Hermann, T., & Deutsch, W. (1976). Psychologie der objek-           van Deemter, K. (2000). Generating vague descriptions. Pro-
  tbenennung. Bern: Huber Verlag.                                     ceedings of the First Natural Language Generation Confer-
Herzog, G., & Wazinski, P. (1994). Visual translator: Linking         ence, 12–16.
  perceptions and natural language descriptions. Artificial         van Deemter, K. (2004). Generating referring expressions
  Intelligence Review, 8(2/3), 175–187.                               that involve gradable properties. Computational Linguis-
Kelleher, J., Costello, F., & Genabith, J. van. (2005). Dy-           tics, 32(2), 195–222.
  namically structuring, updating and interrelating represen-       Viethen, J., & Dale, R. (2008). The use of spatial rela-
  tations of visual and linguistic discourse context. Artificial      tions in referring expression generation. Proceedings of
  Intelligence, 167, 62–102.                                          the Fifth International Natural Language Generation Con-
Krahmer, E., van Erk, S., & Verleg, A. (2003). Graph-based            ference, 59–67.
  generation of referring expressions. Computational Lin-           Zheng, S., Yuille, A., & Tu, Z. (2010). Detecting object
  guistics, 29(1), 53–72.                                             boundaries using low-, middle-, and high-level informa-
Landau, B. (2001). Perceptual units and their mapping with            tion. Journal of Computer Vision and Image Understand-
  language. In T. Shipley & P. Kellman (Eds.), From frag-             ing, 114(19), 1055–1067.
  ments to objects: Segmentation and grouping in vision. The
  Netherlands: Elsevier.
                                                                3096

