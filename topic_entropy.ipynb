{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus, textcorpus\n",
    "import numpy as np\n",
    "from gensim.matutils import hellinger\n",
    "import time\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata_new = pickle.load(open('output/dtm_processed_output.p', 'rb'))\n",
    "# load data\n",
    "doc_year=alldata_new['docs_per_year']\n",
    "doc_ids =[0]+list(np.cumsum(doc_year))\n",
    "\n",
    "term_topic = alldata_new['term_topic']# term_topic is n_years*n_topics*n_terms\n",
    "terms = alldata_new['terms']\n",
    "\n",
    "doc_topicyrs = alldata_new['doc_topic']\n",
    "\n",
    "doc_topic = []\n",
    "for year in range(len(term_topic)):    \n",
    "    doc_topic.append(alldata_new['doc_topic'][doc_ids[year]:doc_ids[year+1]])# doc_topic is nyear*n_docs given year*n_topics\n",
    "# rename topics by the hand-picked names\n",
    "topic_labels = pickle.load(open('topicnames.p','rb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def totvar(p,q):\n",
    "    maxdist=np.max(abs(p-q))\n",
    "    maxid=np.argmax(abs(p-q))\n",
    "    return [maxdist,maxid]\n",
    "def JSD(P, Q):\n",
    "    _P = P / norm(P, ord=1)\n",
    "    _Q = Q / norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    dist=0.5 * (entropy(_P, _M) + entropy(_Q, _M))    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# entropy change within a topic -- which topic's content has changed most in the past years\n",
    "epsilon = 1e-15\n",
    "ntopics = 20\n",
    "topicdelta=np.empty((ntopics,len(term_topic))) # distance from previous year: jenson-shannon distance\n",
    "topicshift=np.empty(ntopics) # distance from 2000 to 2017\n",
    "topicdelta_tv=np.empty((ntopics,len(term_topic))) # distance from previous year: total variance\n",
    "topicshift_tv=np.empty(ntopics) # distance from 2000 to 2017:total variance\n",
    "\n",
    "\n",
    "deltaterm=[]\n",
    "shiftterm=[]\n",
    "for k in range(ntopics):\n",
    "    sftterms=[]\n",
    "    for iyear in range(len(term_topic)):    \n",
    "        topic = term_topic[iyear][k]\n",
    "        # why not using KL: 1) avoid asymetry 2) avoid inf\n",
    "        topic = topic/sum(topic)\n",
    "        topicdelta[k,iyear] = JSD(topic,term_topic[max(iyear-1,0)][k]) # jensen-shannon distance\n",
    "        [topicdelta_tv[k,iyear],maxterm]=totvar(topic,term_topic[max(iyear-1,0)][k]) # maxterm: term of biggest change from previous year\n",
    "        sftterms.append(terms[maxterm])\n",
    "    topicshift[k] = JSD(term_topic[-1][k],term_topic[0][k])\n",
    "    [topicshift_tv[k],maxterm]=totvar(term_topic[-1][k],term_topic[0][k])\n",
    "    shiftterm.append(terms[maxterm]) # biggest shift from 2017 to 2000\n",
    "    deltaterm.append(sftterms) # biggest delta from prev year: max term for every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color',\n",
       " 'estimate',\n",
       " 'estimate',\n",
       " 'estimate',\n",
       " 'estimate',\n",
       " 'dot',\n",
       " 'dot',\n",
       " 'dot',\n",
       " 'judgment',\n",
       " 'trial',\n",
       " 'trial',\n",
       " 'trial',\n",
       " 'trial',\n",
       " 'trial',\n",
       " 'trial',\n",
       " 'trial',\n",
       " 'trial',\n",
       " 'bias']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaterm[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shiftidx=np.argsort(-topicshift)\n",
    "for idx in shiftidx:\n",
    "    print(topic_labels[idx]+': %.3f'%topicshift[idx])\n",
    "\n",
    "print('total variance:')\n",
    "shiftidx=np.argsort(-topicshift_tv)\n",
    "for idx in shiftidx:\n",
    "    print(topic_labels[idx]+': %.3f'%topicshift_tv[idx]+' max shift word:'+shiftterm[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: get the raise and fall terms for each topic...just copy the other code; set the jsd as titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the topic distribution for each year (should correspond to the topic evolution trend...can't find that code right now)\n",
    "ntopics = len(topic_labels)\n",
    "ptop_years = []\n",
    "entrop_years = []\n",
    "for iyear in range(len(term_topic)):    \n",
    "    ptopics = np.zeros(ntopics)\n",
    "    for doc in doc_topic[iyear]:\n",
    "        ptopics+=doc\n",
    "    ptopics = ptopics/sum(ptopics)\n",
    "    ptop_years.append(ptopics)\n",
    "    entrop_years.append(entropy(ptopics))\n",
    "print(entrop_years)\n",
    "\n",
    "# plot the entropy change across years\n",
    "years = np.arange(len(term_topic))+2000\n",
    "plt.plot(years,entrop_years,'-o')\n",
    "plt.xlabel('year')\n",
    "plt.title('entropy of topic distribution')\n",
    "plt.show()\n",
    "\n",
    "# could be done: find the paper with highest / lowest entropy; find the topic with highest/lowest entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KL-divergence across years\n",
    "kl_years = []\n",
    "\n",
    "gap=1\n",
    "for iyear in range(len(term_topic)-gap):    \n",
    "#    kl_years.append(entropy(ptop_years[iyear],ptop_years[iyear+gap]))\n",
    "    kl_years.append(entropy(ptop_years[iyear+gap],ptop_years[iyear]))# sanity check: reverse the direction of KL. not differen\n",
    "plt.plot(years[gap:],kl_years,'-o')\n",
    "plt.xlabel('year')\n",
    "plt.title('KL div with the previous year')\n",
    "plt.show()\n",
    "\n",
    "# TODO: eye-balling the distribution overlayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tentative conclusion**\n",
    "- the diversity of topics seem to increase over years\n",
    "- 2002 has a relatively less diverse topic distribution while 2013 was pretty diverse.\n",
    "\n",
    "- the year-to-year difference has been decreasing across years...it's like the field is changing more slowly? doesn't make sense to me..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# entropy of topics\n",
    "for iyear in range(len(term_topic)):\n",
    "    print('\\n Year='+str(years[iyear]))\n",
    "    entrop_terms=[]\n",
    "    for k in range(ntopics):\n",
    "        topic = term_topic[iyear][k] # already normalized\n",
    "        entrop_terms.append(entropy(topic))\n",
    "    sorted_H = np.sort(entrop_terms)\n",
    "    idx = np.argsort(entrop_terms)\n",
    "    [print(topic_labels[idx[j]]+':'+str(sorted_H[j])) for j in range(len(idx))]\n",
    "# turns out the ranking of entropy is pretty stable over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(term_topic[iyear][3])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
